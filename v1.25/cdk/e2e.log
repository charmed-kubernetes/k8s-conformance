I1112 11:58:40.247796      19 e2e.go:116] Starting e2e run "9f11ea07-55ae-48b5-a2d0-18d79ec42f84" on Ginkgo node 1
Nov 12 11:58:40.269: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1668254319 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Nov 12 11:58:40.487: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 11:58:40.489: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 12 11:58:40.512: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 12 11:58:40.536: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 12 11:58:40.536: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Nov 12 11:58:40.536: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 12 11:58:40.540: INFO: e2e test version: v1.25.4
Nov 12 11:58:40.541: INFO: kube-apiserver version: v1.25.4
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Nov 12 11:58:40.541: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 11:58:40.547: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.060 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 12 11:58:40.487: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 11:58:40.489: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Nov 12 11:58:40.512: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Nov 12 11:58:40.536: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Nov 12 11:58:40.536: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
    Nov 12 11:58:40.536: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Nov 12 11:58:40.540: INFO: e2e test version: v1.25.4
    Nov 12 11:58:40.541: INFO: kube-apiserver version: v1.25.4
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 12 11:58:40.541: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 11:58:40.547: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 11:58:40.579
Nov 12 11:58:40.579: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 11:58:40.58
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 11:58:40.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 11:58:40.613
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 11/12/22 11:58:40.616
Nov 12 11:58:40.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc" in namespace "projected-3826" to be "Succeeded or Failed"
Nov 12 11:58:40.639: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.644446ms
Nov 12 11:58:42.648: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016444715s
Nov 12 11:58:44.644: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Running", Reason="", readiness=true. Elapsed: 4.012860495s
Nov 12 11:58:46.645: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Running", Reason="", readiness=false. Elapsed: 6.013236778s
Nov 12 11:58:48.644: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.012543934s
STEP: Saw pod success 11/12/22 11:58:48.644
Nov 12 11:58:48.644: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc" satisfied condition "Succeeded or Failed"
Nov 12 11:58:48.649: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc container client-container: <nil>
STEP: delete the pod 11/12/22 11:58:48.666
Nov 12 11:58:48.683: INFO: Waiting for pod downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc to disappear
Nov 12 11:58:48.687: INFO: Pod downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 11:58:48.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3826" for this suite. 11/12/22 11:58:48.691
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":1,"skipped":11,"failed":0}
------------------------------
• [SLOW TEST] [8.121 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 11:58:40.579
    Nov 12 11:58:40.579: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 11:58:40.58
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 11:58:40.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 11:58:40.613
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 11/12/22 11:58:40.616
    Nov 12 11:58:40.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc" in namespace "projected-3826" to be "Succeeded or Failed"
    Nov 12 11:58:40.639: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.644446ms
    Nov 12 11:58:42.648: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016444715s
    Nov 12 11:58:44.644: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Running", Reason="", readiness=true. Elapsed: 4.012860495s
    Nov 12 11:58:46.645: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Running", Reason="", readiness=false. Elapsed: 6.013236778s
    Nov 12 11:58:48.644: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.012543934s
    STEP: Saw pod success 11/12/22 11:58:48.644
    Nov 12 11:58:48.644: INFO: Pod "downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc" satisfied condition "Succeeded or Failed"
    Nov 12 11:58:48.649: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc container client-container: <nil>
    STEP: delete the pod 11/12/22 11:58:48.666
    Nov 12 11:58:48.683: INFO: Waiting for pod downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc to disappear
    Nov 12 11:58:48.687: INFO: Pod downwardapi-volume-6d48343a-21af-441e-aadb-eefb42d00efc no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 11:58:48.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3826" for this suite. 11/12/22 11:58:48.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 11:58:48.706
Nov 12 11:58:48.706: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 11:58:48.707
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 11:58:48.723
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 11:58:48.726
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-e693641b-ff42-48c1-8d97-a485aa0555be 11/12/22 11:58:48.728
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 11:58:48.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4220" for this suite. 11/12/22 11:58:48.736
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":2,"skipped":23,"failed":0}
------------------------------
• [0.041 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 11:58:48.706
    Nov 12 11:58:48.706: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 11:58:48.707
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 11:58:48.723
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 11:58:48.726
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-e693641b-ff42-48c1-8d97-a485aa0555be 11/12/22 11:58:48.728
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 11:58:48.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4220" for this suite. 11/12/22 11:58:48.736
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 11:58:48.748
Nov 12 11:58:48.748: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 11:58:48.749
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 11:58:48.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 11:58:48.834
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3790 11/12/22 11:58:48.836
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 11/12/22 11:58:48.844
Nov 12 11:58:48.896: INFO: Found 0 stateful pods, waiting for 3
Nov 12 11:58:58.904: INFO: Found 2 stateful pods, waiting for 3
Nov 12 11:59:08.906: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 11:59:08.906: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 11:59:08.906: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 12 11:59:18.904: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 11:59:18.904: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 11:59:18.904: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 11:59:18.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 11:59:19.142: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 11:59:19.142: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 11:59:19.142: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/12/22 11:59:29.166
Nov 12 11:59:29.191: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/12/22 11:59:29.191
STEP: Updating Pods in reverse ordinal order 11/12/22 11:59:39.222
Nov 12 11:59:39.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 11:59:39.404: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 12 11:59:39.404: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 11:59:39.404: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 11:59:59.435: INFO: Waiting for StatefulSet statefulset-3790/ss2 to complete update
STEP: Rolling back to a previous revision 11/12/22 12:00:09.45
Nov 12 12:00:09.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:00:09.636: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:00:09.636: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:00:09.636: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:00:19.685: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 11/12/22 12:00:29.71
Nov 12 12:00:29.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:00:29.857: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 12 12:00:29.857: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:00:29.857: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 12:00:39.890: INFO: Deleting all statefulset in ns statefulset-3790
Nov 12 12:00:39.894: INFO: Scaling statefulset ss2 to 0
Nov 12 12:00:49.919: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:00:49.924: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 12:00:49.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3790" for this suite. 11/12/22 12:00:49.955
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":3,"skipped":34,"failed":0}
------------------------------
• [SLOW TEST] [121.218 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 11:58:48.748
    Nov 12 11:58:48.748: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 11:58:48.749
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 11:58:48.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 11:58:48.834
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3790 11/12/22 11:58:48.836
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 11/12/22 11:58:48.844
    Nov 12 11:58:48.896: INFO: Found 0 stateful pods, waiting for 3
    Nov 12 11:58:58.904: INFO: Found 2 stateful pods, waiting for 3
    Nov 12 11:59:08.906: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 11:59:08.906: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 11:59:08.906: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
    Nov 12 11:59:18.904: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 11:59:18.904: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 11:59:18.904: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 11:59:18.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 11:59:19.142: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 11:59:19.142: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 11:59:19.142: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/12/22 11:59:29.166
    Nov 12 11:59:29.191: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/12/22 11:59:29.191
    STEP: Updating Pods in reverse ordinal order 11/12/22 11:59:39.222
    Nov 12 11:59:39.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 11:59:39.404: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 12 11:59:39.404: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 11:59:39.404: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 11:59:59.435: INFO: Waiting for StatefulSet statefulset-3790/ss2 to complete update
    STEP: Rolling back to a previous revision 11/12/22 12:00:09.45
    Nov 12 12:00:09.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:00:09.636: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:00:09.636: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:00:09.636: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:00:19.685: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 11/12/22 12:00:29.71
    Nov 12 12:00:29.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-3790 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:00:29.857: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 12 12:00:29.857: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:00:29.857: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 12:00:39.890: INFO: Deleting all statefulset in ns statefulset-3790
    Nov 12 12:00:39.894: INFO: Scaling statefulset ss2 to 0
    Nov 12 12:00:49.919: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:00:49.924: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 12:00:49.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3790" for this suite. 11/12/22 12:00:49.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:00:49.975
Nov 12 12:00:49.975: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:00:49.976
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:00:49.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:00:50.002
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-fa04abf9-c222-46f1-81d1-4e502c472f94 11/12/22 12:00:50.01
STEP: Creating the pod 11/12/22 12:00:50.018
Nov 12 12:00:50.035: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62" in namespace "projected-9584" to be "running and ready"
Nov 12 12:00:50.042: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.777787ms
Nov 12 12:00:50.042: INFO: The phase of Pod pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:00:52.050: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014995219s
Nov 12 12:00:52.050: INFO: The phase of Pod pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:00:54.047: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62": Phase="Running", Reason="", readiness=true. Elapsed: 4.012313023s
Nov 12 12:00:54.047: INFO: The phase of Pod pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62 is Running (Ready = true)
Nov 12 12:00:54.047: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-fa04abf9-c222-46f1-81d1-4e502c472f94 11/12/22 12:00:54.068
STEP: waiting to observe update in volume 11/12/22 12:00:54.075
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 12:01:58.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9584" for this suite. 11/12/22 12:01:58.449
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":4,"skipped":148,"failed":0}
------------------------------
• [SLOW TEST] [68.483 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:00:49.975
    Nov 12 12:00:49.975: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:00:49.976
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:00:49.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:00:50.002
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-fa04abf9-c222-46f1-81d1-4e502c472f94 11/12/22 12:00:50.01
    STEP: Creating the pod 11/12/22 12:00:50.018
    Nov 12 12:00:50.035: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62" in namespace "projected-9584" to be "running and ready"
    Nov 12 12:00:50.042: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.777787ms
    Nov 12 12:00:50.042: INFO: The phase of Pod pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:00:52.050: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014995219s
    Nov 12 12:00:52.050: INFO: The phase of Pod pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:00:54.047: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62": Phase="Running", Reason="", readiness=true. Elapsed: 4.012313023s
    Nov 12 12:00:54.047: INFO: The phase of Pod pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62 is Running (Ready = true)
    Nov 12 12:00:54.047: INFO: Pod "pod-projected-configmaps-d5052211-c5cd-4f13-9a88-e797dd763f62" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-fa04abf9-c222-46f1-81d1-4e502c472f94 11/12/22 12:00:54.068
    STEP: waiting to observe update in volume 11/12/22 12:00:54.075
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 12:01:58.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9584" for this suite. 11/12/22 12:01:58.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:01:58.46
Nov 12 12:01:58.460: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:01:58.461
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:01:58.492
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:01:58.494
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:01:58.528
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:01:59.154
STEP: Deploying the webhook pod 11/12/22 12:01:59.166
STEP: Wait for the deployment to be ready 11/12/22 12:01:59.186
Nov 12 12:01:59.205: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 12 12:02:01.221: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:03.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:05.226: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 12:02:07.225
STEP: Verifying the service has paired with the endpoint 11/12/22 12:02:07.24
Nov 12 12:02:08.240: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/12/22 12:02:08.246
STEP: create a namespace for the webhook 11/12/22 12:02:08.267
STEP: create a configmap should be unconditionally rejected by the webhook 11/12/22 12:02:08.279
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:02:08.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3251" for this suite. 11/12/22 12:02:08.375
STEP: Destroying namespace "webhook-3251-markers" for this suite. 11/12/22 12:02:08.385
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":5,"skipped":155,"failed":0}
------------------------------
• [SLOW TEST] [10.020 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:01:58.46
    Nov 12 12:01:58.460: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:01:58.461
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:01:58.492
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:01:58.494
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:01:58.528
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:01:59.154
    STEP: Deploying the webhook pod 11/12/22 12:01:59.166
    STEP: Wait for the deployment to be ready 11/12/22 12:01:59.186
    Nov 12 12:01:59.205: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 12 12:02:01.221: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:03.228: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:05.226: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 1, 59, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 12:02:07.225
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:02:07.24
    Nov 12 12:02:08.240: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/12/22 12:02:08.246
    STEP: create a namespace for the webhook 11/12/22 12:02:08.267
    STEP: create a configmap should be unconditionally rejected by the webhook 11/12/22 12:02:08.279
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:02:08.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-3251" for this suite. 11/12/22 12:02:08.375
    STEP: Destroying namespace "webhook-3251-markers" for this suite. 11/12/22 12:02:08.385
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:02:08.483
Nov 12 12:02:08.483: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename aggregator 11/12/22 12:02:08.484
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:08.51
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:08.514
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Nov 12 12:02:08.520: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 11/12/22 12:02:08.521
Nov 12 12:02:08.876: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 12 12:02:10.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:12.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:14.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:16.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:18.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:20.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:22.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:24.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:26.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:28.973: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:30.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:02:33.102: INFO: Waited 123.170169ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 11/12/22 12:02:33.175
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/12/22 12:02:33.18
STEP: List APIServices 11/12/22 12:02:33.188
Nov 12 12:02:33.197: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Nov 12 12:02:33.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3106" for this suite. 11/12/22 12:02:33.468
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":6,"skipped":188,"failed":0}
------------------------------
• [SLOW TEST] [24.995 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:02:08.483
    Nov 12 12:02:08.483: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename aggregator 11/12/22 12:02:08.484
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:08.51
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:08.514
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Nov 12 12:02:08.520: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 11/12/22 12:02:08.521
    Nov 12 12:02:08.876: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Nov 12 12:02:10.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:12.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:14.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:16.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:18.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:20.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:22.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:24.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:26.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:28.973: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:30.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 2, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:02:33.102: INFO: Waited 123.170169ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 11/12/22 12:02:33.175
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/12/22 12:02:33.18
    STEP: List APIServices 11/12/22 12:02:33.188
    Nov 12 12:02:33.197: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Nov 12 12:02:33.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-3106" for this suite. 11/12/22 12:02:33.468
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:02:33.486
Nov 12 12:02:33.486: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 12:02:33.487
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:33.511
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:33.518
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/12/22 12:02:33.522
Nov 12 12:02:33.538: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1518  609afb05-5bb9-4cd0-be95-67301513569a 3390 0 2022-11-12 12:02:33 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-12 12:02:33 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lg55m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lg55m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 12:02:33.538: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-1518" to be "running and ready"
Nov 12 12:02:33.543: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.501248ms
Nov 12 12:02:33.543: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:02:35.549: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.010754253s
Nov 12 12:02:35.549: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Nov 12 12:02:35.549: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 11/12/22 12:02:35.549
Nov 12 12:02:35.550: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1518 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:02:35.550: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:02:35.550: INFO: ExecWithOptions: Clientset creation
Nov 12 12:02:35.550: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1518/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 11/12/22 12:02:35.655
Nov 12 12:02:35.655: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1518 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:02:35.655: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:02:35.656: INFO: ExecWithOptions: Clientset creation
Nov 12 12:02:35.656: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1518/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 12:02:35.734: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 12:02:35.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1518" for this suite. 11/12/22 12:02:35.757
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":7,"skipped":224,"failed":0}
------------------------------
• [2.281 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:02:33.486
    Nov 12 12:02:33.486: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 12:02:33.487
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:33.511
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:33.518
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/12/22 12:02:33.522
    Nov 12 12:02:33.538: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1518  609afb05-5bb9-4cd0-be95-67301513569a 3390 0 2022-11-12 12:02:33 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-12 12:02:33 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lg55m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lg55m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 12:02:33.538: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-1518" to be "running and ready"
    Nov 12 12:02:33.543: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 4.501248ms
    Nov 12 12:02:33.543: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:02:35.549: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.010754253s
    Nov 12 12:02:35.549: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Nov 12 12:02:35.549: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 11/12/22 12:02:35.549
    Nov 12 12:02:35.550: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1518 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:02:35.550: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:02:35.550: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:02:35.550: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1518/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 11/12/22 12:02:35.655
    Nov 12 12:02:35.655: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1518 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:02:35.655: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:02:35.656: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:02:35.656: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1518/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 12:02:35.734: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 12:02:35.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1518" for this suite. 11/12/22 12:02:35.757
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:02:35.769
Nov 12 12:02:35.769: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename endpointslice 11/12/22 12:02:35.77
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:35.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:35.795
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 11/12/22 12:02:35.798
STEP: getting /apis/discovery.k8s.io 11/12/22 12:02:35.8
STEP: getting /apis/discovery.k8s.iov1 11/12/22 12:02:35.802
STEP: creating 11/12/22 12:02:35.803
STEP: getting 11/12/22 12:02:35.824
STEP: listing 11/12/22 12:02:35.829
STEP: watching 11/12/22 12:02:35.833
Nov 12 12:02:35.833: INFO: starting watch
STEP: cluster-wide listing 11/12/22 12:02:35.835
STEP: cluster-wide watching 11/12/22 12:02:35.839
Nov 12 12:02:35.839: INFO: starting watch
STEP: patching 11/12/22 12:02:35.84
STEP: updating 11/12/22 12:02:35.849
Nov 12 12:02:35.859: INFO: waiting for watch events with expected annotations
Nov 12 12:02:35.859: INFO: saw patched and updated annotations
STEP: deleting 11/12/22 12:02:35.859
STEP: deleting a collection 11/12/22 12:02:35.88
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 12 12:02:35.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5693" for this suite. 11/12/22 12:02:35.917
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":8,"skipped":226,"failed":0}
------------------------------
• [0.157 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:02:35.769
    Nov 12 12:02:35.769: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename endpointslice 11/12/22 12:02:35.77
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:35.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:35.795
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 11/12/22 12:02:35.798
    STEP: getting /apis/discovery.k8s.io 11/12/22 12:02:35.8
    STEP: getting /apis/discovery.k8s.iov1 11/12/22 12:02:35.802
    STEP: creating 11/12/22 12:02:35.803
    STEP: getting 11/12/22 12:02:35.824
    STEP: listing 11/12/22 12:02:35.829
    STEP: watching 11/12/22 12:02:35.833
    Nov 12 12:02:35.833: INFO: starting watch
    STEP: cluster-wide listing 11/12/22 12:02:35.835
    STEP: cluster-wide watching 11/12/22 12:02:35.839
    Nov 12 12:02:35.839: INFO: starting watch
    STEP: patching 11/12/22 12:02:35.84
    STEP: updating 11/12/22 12:02:35.849
    Nov 12 12:02:35.859: INFO: waiting for watch events with expected annotations
    Nov 12 12:02:35.859: INFO: saw patched and updated annotations
    STEP: deleting 11/12/22 12:02:35.859
    STEP: deleting a collection 11/12/22 12:02:35.88
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 12 12:02:35.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5693" for this suite. 11/12/22 12:02:35.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:02:35.929
Nov 12 12:02:35.929: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename job 11/12/22 12:02:35.933
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:35.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:35.965
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 11/12/22 12:02:35.97
STEP: Ensuring job reaches completions 11/12/22 12:02:35.978
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 12 12:02:49.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5193" for this suite. 11/12/22 12:02:49.989
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":9,"skipped":237,"failed":0}
------------------------------
• [SLOW TEST] [14.070 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:02:35.929
    Nov 12 12:02:35.929: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename job 11/12/22 12:02:35.933
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:35.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:35.965
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 11/12/22 12:02:35.97
    STEP: Ensuring job reaches completions 11/12/22 12:02:35.978
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 12 12:02:49.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5193" for this suite. 11/12/22 12:02:49.989
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:02:50
Nov 12 12:02:50.000: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename subpath 11/12/22 12:02:50.001
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:50.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:50.072
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 12:02:50.074
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-7c7x 11/12/22 12:02:50.095
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:02:50.095
Nov 12 12:02:50.107: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7c7x" in namespace "subpath-8579" to be "Succeeded or Failed"
Nov 12 12:02:50.118: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Pending", Reason="", readiness=false. Elapsed: 10.679673ms
Nov 12 12:02:52.123: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 2.015438289s
Nov 12 12:02:54.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 4.017538874s
Nov 12 12:02:56.126: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 6.018254581s
Nov 12 12:02:58.124: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 8.017089738s
Nov 12 12:03:00.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 10.017595919s
Nov 12 12:03:02.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 12.017461189s
Nov 12 12:03:04.124: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 14.016270707s
Nov 12 12:03:06.124: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 16.016765761s
Nov 12 12:03:08.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 18.017212058s
Nov 12 12:03:10.126: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 20.018408418s
Nov 12 12:03:12.132: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=false. Elapsed: 22.024823825s
Nov 12 12:03:14.126: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.018474393s
STEP: Saw pod success 11/12/22 12:03:14.126
Nov 12 12:03:14.126: INFO: Pod "pod-subpath-test-configmap-7c7x" satisfied condition "Succeeded or Failed"
Nov 12 12:03:14.131: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-configmap-7c7x container test-container-subpath-configmap-7c7x: <nil>
STEP: delete the pod 11/12/22 12:03:14.141
Nov 12 12:03:14.157: INFO: Waiting for pod pod-subpath-test-configmap-7c7x to disappear
Nov 12 12:03:14.161: INFO: Pod pod-subpath-test-configmap-7c7x no longer exists
STEP: Deleting pod pod-subpath-test-configmap-7c7x 11/12/22 12:03:14.161
Nov 12 12:03:14.162: INFO: Deleting pod "pod-subpath-test-configmap-7c7x" in namespace "subpath-8579"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 12:03:14.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8579" for this suite. 11/12/22 12:03:14.171
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":10,"skipped":249,"failed":0}
------------------------------
• [SLOW TEST] [24.182 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:02:50
    Nov 12 12:02:50.000: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename subpath 11/12/22 12:02:50.001
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:02:50.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:02:50.072
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 12:02:50.074
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-7c7x 11/12/22 12:02:50.095
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:02:50.095
    Nov 12 12:02:50.107: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-7c7x" in namespace "subpath-8579" to be "Succeeded or Failed"
    Nov 12 12:02:50.118: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Pending", Reason="", readiness=false. Elapsed: 10.679673ms
    Nov 12 12:02:52.123: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 2.015438289s
    Nov 12 12:02:54.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 4.017538874s
    Nov 12 12:02:56.126: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 6.018254581s
    Nov 12 12:02:58.124: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 8.017089738s
    Nov 12 12:03:00.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 10.017595919s
    Nov 12 12:03:02.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 12.017461189s
    Nov 12 12:03:04.124: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 14.016270707s
    Nov 12 12:03:06.124: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 16.016765761s
    Nov 12 12:03:08.125: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 18.017212058s
    Nov 12 12:03:10.126: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=true. Elapsed: 20.018408418s
    Nov 12 12:03:12.132: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Running", Reason="", readiness=false. Elapsed: 22.024823825s
    Nov 12 12:03:14.126: INFO: Pod "pod-subpath-test-configmap-7c7x": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.018474393s
    STEP: Saw pod success 11/12/22 12:03:14.126
    Nov 12 12:03:14.126: INFO: Pod "pod-subpath-test-configmap-7c7x" satisfied condition "Succeeded or Failed"
    Nov 12 12:03:14.131: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-configmap-7c7x container test-container-subpath-configmap-7c7x: <nil>
    STEP: delete the pod 11/12/22 12:03:14.141
    Nov 12 12:03:14.157: INFO: Waiting for pod pod-subpath-test-configmap-7c7x to disappear
    Nov 12 12:03:14.161: INFO: Pod pod-subpath-test-configmap-7c7x no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-7c7x 11/12/22 12:03:14.161
    Nov 12 12:03:14.162: INFO: Deleting pod "pod-subpath-test-configmap-7c7x" in namespace "subpath-8579"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 12:03:14.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8579" for this suite. 11/12/22 12:03:14.171
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:14.182
Nov 12 12:03:14.182: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename proxy 11/12/22 12:03:14.185
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:14.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:14.211
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Nov 12 12:03:14.216: INFO: Creating pod...
Nov 12 12:03:14.229: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7664" to be "running"
Nov 12 12:03:14.238: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 8.490802ms
Nov 12 12:03:16.243: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.014127937s
Nov 12 12:03:16.243: INFO: Pod "agnhost" satisfied condition "running"
Nov 12 12:03:16.243: INFO: Creating service...
Nov 12 12:03:16.256: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/DELETE
Nov 12 12:03:16.267: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 12:03:16.267: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/GET
Nov 12 12:03:16.280: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 12 12:03:16.280: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/HEAD
Nov 12 12:03:16.286: INFO: http.Client request:HEAD | StatusCode:200
Nov 12 12:03:16.286: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/OPTIONS
Nov 12 12:03:16.293: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 12:03:16.293: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/PATCH
Nov 12 12:03:16.300: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 12:03:16.300: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/POST
Nov 12 12:03:16.306: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 12:03:16.306: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/PUT
Nov 12 12:03:16.314: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 12 12:03:16.314: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/DELETE
Nov 12 12:03:16.323: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 12:03:16.323: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/GET
Nov 12 12:03:16.334: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 12 12:03:16.334: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/HEAD
Nov 12 12:03:16.345: INFO: http.Client request:HEAD | StatusCode:200
Nov 12 12:03:16.345: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/OPTIONS
Nov 12 12:03:16.356: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 12:03:16.356: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/PATCH
Nov 12 12:03:16.365: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 12:03:16.365: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/POST
Nov 12 12:03:16.376: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 12:03:16.377: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/PUT
Nov 12 12:03:16.390: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 12 12:03:16.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7664" for this suite. 11/12/22 12:03:16.397
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":11,"skipped":250,"failed":0}
------------------------------
• [2.225 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:14.182
    Nov 12 12:03:14.182: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename proxy 11/12/22 12:03:14.185
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:14.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:14.211
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Nov 12 12:03:14.216: INFO: Creating pod...
    Nov 12 12:03:14.229: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7664" to be "running"
    Nov 12 12:03:14.238: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 8.490802ms
    Nov 12 12:03:16.243: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.014127937s
    Nov 12 12:03:16.243: INFO: Pod "agnhost" satisfied condition "running"
    Nov 12 12:03:16.243: INFO: Creating service...
    Nov 12 12:03:16.256: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/DELETE
    Nov 12 12:03:16.267: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 12:03:16.267: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/GET
    Nov 12 12:03:16.280: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 12 12:03:16.280: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/HEAD
    Nov 12 12:03:16.286: INFO: http.Client request:HEAD | StatusCode:200
    Nov 12 12:03:16.286: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/OPTIONS
    Nov 12 12:03:16.293: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 12:03:16.293: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/PATCH
    Nov 12 12:03:16.300: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 12:03:16.300: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/POST
    Nov 12 12:03:16.306: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 12:03:16.306: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/pods/agnhost/proxy/some/path/with/PUT
    Nov 12 12:03:16.314: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 12 12:03:16.314: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/DELETE
    Nov 12 12:03:16.323: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 12:03:16.323: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/GET
    Nov 12 12:03:16.334: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 12 12:03:16.334: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/HEAD
    Nov 12 12:03:16.345: INFO: http.Client request:HEAD | StatusCode:200
    Nov 12 12:03:16.345: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/OPTIONS
    Nov 12 12:03:16.356: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 12:03:16.356: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/PATCH
    Nov 12 12:03:16.365: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 12:03:16.365: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/POST
    Nov 12 12:03:16.376: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 12:03:16.377: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-7664/services/test-service/proxy/some/path/with/PUT
    Nov 12 12:03:16.390: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 12 12:03:16.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-7664" for this suite. 11/12/22 12:03:16.397
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:16.408
Nov 12 12:03:16.408: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:03:16.408
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:16.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:16.433
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/12/22 12:03:16.437
Nov 12 12:03:16.451: INFO: Waiting up to 5m0s for pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433" in namespace "emptydir-2127" to be "Succeeded or Failed"
Nov 12 12:03:16.457: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.885557ms
Nov 12 12:03:18.463: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011814511s
Nov 12 12:03:20.462: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01010108s
STEP: Saw pod success 11/12/22 12:03:20.462
Nov 12 12:03:20.462: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433" satisfied condition "Succeeded or Failed"
Nov 12 12:03:20.467: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-b325b65d-8520-424c-8ce1-1d7fd371f433 container test-container: <nil>
STEP: delete the pod 11/12/22 12:03:20.486
Nov 12 12:03:20.503: INFO: Waiting for pod pod-b325b65d-8520-424c-8ce1-1d7fd371f433 to disappear
Nov 12 12:03:20.507: INFO: Pod pod-b325b65d-8520-424c-8ce1-1d7fd371f433 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:03:20.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2127" for this suite. 11/12/22 12:03:20.511
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":12,"skipped":254,"failed":0}
------------------------------
• [4.125 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:16.408
    Nov 12 12:03:16.408: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:03:16.408
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:16.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:16.433
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/12/22 12:03:16.437
    Nov 12 12:03:16.451: INFO: Waiting up to 5m0s for pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433" in namespace "emptydir-2127" to be "Succeeded or Failed"
    Nov 12 12:03:16.457: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433": Phase="Pending", Reason="", readiness=false. Elapsed: 5.885557ms
    Nov 12 12:03:18.463: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011814511s
    Nov 12 12:03:20.462: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01010108s
    STEP: Saw pod success 11/12/22 12:03:20.462
    Nov 12 12:03:20.462: INFO: Pod "pod-b325b65d-8520-424c-8ce1-1d7fd371f433" satisfied condition "Succeeded or Failed"
    Nov 12 12:03:20.467: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-b325b65d-8520-424c-8ce1-1d7fd371f433 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:03:20.486
    Nov 12 12:03:20.503: INFO: Waiting for pod pod-b325b65d-8520-424c-8ce1-1d7fd371f433 to disappear
    Nov 12 12:03:20.507: INFO: Pod pod-b325b65d-8520-424c-8ce1-1d7fd371f433 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:03:20.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2127" for this suite. 11/12/22 12:03:20.511
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:20.535
Nov 12 12:03:20.535: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 12:03:20.536
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:20.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:20.558
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 11/12/22 12:03:20.56
STEP: Creating a ResourceQuota 11/12/22 12:03:25.565
STEP: Ensuring resource quota status is calculated 11/12/22 12:03:25.572
STEP: Creating a ReplicaSet 11/12/22 12:03:27.577
STEP: Ensuring resource quota status captures replicaset creation 11/12/22 12:03:27.592
STEP: Deleting a ReplicaSet 11/12/22 12:03:29.599
STEP: Ensuring resource quota status released usage 11/12/22 12:03:29.611
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 12:03:31.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7646" for this suite. 11/12/22 12:03:31.622
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":13,"skipped":259,"failed":0}
------------------------------
• [SLOW TEST] [11.102 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:20.535
    Nov 12 12:03:20.535: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 12:03:20.536
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:20.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:20.558
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 11/12/22 12:03:20.56
    STEP: Creating a ResourceQuota 11/12/22 12:03:25.565
    STEP: Ensuring resource quota status is calculated 11/12/22 12:03:25.572
    STEP: Creating a ReplicaSet 11/12/22 12:03:27.577
    STEP: Ensuring resource quota status captures replicaset creation 11/12/22 12:03:27.592
    STEP: Deleting a ReplicaSet 11/12/22 12:03:29.599
    STEP: Ensuring resource quota status released usage 11/12/22 12:03:29.611
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 12:03:31.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7646" for this suite. 11/12/22 12:03:31.622
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:31.641
Nov 12 12:03:31.641: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 12:03:31.642
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:31.665
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:31.67
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 11/12/22 12:03:31.673
STEP: setting up watch 11/12/22 12:03:31.673
STEP: submitting the pod to kubernetes 11/12/22 12:03:31.778
STEP: verifying the pod is in kubernetes 11/12/22 12:03:31.791
STEP: verifying pod creation was observed 11/12/22 12:03:31.798
Nov 12 12:03:31.798: INFO: Waiting up to 5m0s for pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525" in namespace "pods-3225" to be "running"
Nov 12 12:03:31.803: INFO: Pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525": Phase="Pending", Reason="", readiness=false. Elapsed: 4.687428ms
Nov 12 12:03:33.808: INFO: Pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525": Phase="Running", Reason="", readiness=true. Elapsed: 2.010004504s
Nov 12 12:03:33.808: INFO: Pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525" satisfied condition "running"
STEP: deleting the pod gracefully 11/12/22 12:03:33.813
STEP: verifying pod deletion was observed 11/12/22 12:03:33.824
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 12:03:36.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3225" for this suite. 11/12/22 12:03:36.117
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":14,"skipped":304,"failed":0}
------------------------------
• [4.485 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:31.641
    Nov 12 12:03:31.641: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 12:03:31.642
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:31.665
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:31.67
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 11/12/22 12:03:31.673
    STEP: setting up watch 11/12/22 12:03:31.673
    STEP: submitting the pod to kubernetes 11/12/22 12:03:31.778
    STEP: verifying the pod is in kubernetes 11/12/22 12:03:31.791
    STEP: verifying pod creation was observed 11/12/22 12:03:31.798
    Nov 12 12:03:31.798: INFO: Waiting up to 5m0s for pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525" in namespace "pods-3225" to be "running"
    Nov 12 12:03:31.803: INFO: Pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525": Phase="Pending", Reason="", readiness=false. Elapsed: 4.687428ms
    Nov 12 12:03:33.808: INFO: Pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525": Phase="Running", Reason="", readiness=true. Elapsed: 2.010004504s
    Nov 12 12:03:33.808: INFO: Pod "pod-submit-remove-3223a348-ff01-452e-ad56-fac650bb9525" satisfied condition "running"
    STEP: deleting the pod gracefully 11/12/22 12:03:33.813
    STEP: verifying pod deletion was observed 11/12/22 12:03:33.824
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 12:03:36.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3225" for this suite. 11/12/22 12:03:36.117
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:36.127
Nov 12 12:03:36.127: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:03:36.128
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:36.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:36.203
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 11/12/22 12:03:36.206
Nov 12 12:03:36.221: INFO: Waiting up to 5m0s for pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018" in namespace "projected-9191" to be "Succeeded or Failed"
Nov 12 12:03:36.228: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018": Phase="Pending", Reason="", readiness=false. Elapsed: 7.024908ms
Nov 12 12:03:38.234: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01356064s
Nov 12 12:03:40.233: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012339498s
STEP: Saw pod success 11/12/22 12:03:40.233
Nov 12 12:03:40.233: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018" satisfied condition "Succeeded or Failed"
Nov 12 12:03:40.238: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018 container client-container: <nil>
STEP: delete the pod 11/12/22 12:03:40.247
Nov 12 12:03:40.268: INFO: Waiting for pod downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018 to disappear
Nov 12 12:03:40.273: INFO: Pod downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 12:03:40.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9191" for this suite. 11/12/22 12:03:40.283
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":15,"skipped":309,"failed":0}
------------------------------
• [4.166 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:36.127
    Nov 12 12:03:36.127: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:03:36.128
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:36.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:36.203
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 11/12/22 12:03:36.206
    Nov 12 12:03:36.221: INFO: Waiting up to 5m0s for pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018" in namespace "projected-9191" to be "Succeeded or Failed"
    Nov 12 12:03:36.228: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018": Phase="Pending", Reason="", readiness=false. Elapsed: 7.024908ms
    Nov 12 12:03:38.234: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01356064s
    Nov 12 12:03:40.233: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012339498s
    STEP: Saw pod success 11/12/22 12:03:40.233
    Nov 12 12:03:40.233: INFO: Pod "downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018" satisfied condition "Succeeded or Failed"
    Nov 12 12:03:40.238: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018 container client-container: <nil>
    STEP: delete the pod 11/12/22 12:03:40.247
    Nov 12 12:03:40.268: INFO: Waiting for pod downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018 to disappear
    Nov 12 12:03:40.273: INFO: Pod downwardapi-volume-57042da5-7098-4d86-92b6-7db7d72d6018 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 12:03:40.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9191" for this suite. 11/12/22 12:03:40.283
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:40.297
Nov 12 12:03:40.297: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:03:40.298
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:40.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:40.324
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-341160a0-d2d0-4fac-b84b-12cbde7653ea 11/12/22 12:03:40.327
STEP: Creating a pod to test consume configMaps 11/12/22 12:03:40.334
Nov 12 12:03:40.347: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8" in namespace "projected-1031" to be "Succeeded or Failed"
Nov 12 12:03:40.354: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.203561ms
Nov 12 12:03:42.364: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015893436s
Nov 12 12:03:44.361: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013082864s
STEP: Saw pod success 11/12/22 12:03:44.361
Nov 12 12:03:44.361: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8" satisfied condition "Succeeded or Failed"
Nov 12 12:03:44.365: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 12:03:44.374
Nov 12 12:03:44.394: INFO: Waiting for pod pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8 to disappear
Nov 12 12:03:44.398: INFO: Pod pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 12:03:44.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1031" for this suite. 11/12/22 12:03:44.403
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":16,"skipped":334,"failed":0}
------------------------------
• [4.119 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:40.297
    Nov 12 12:03:40.297: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:03:40.298
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:40.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:40.324
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-341160a0-d2d0-4fac-b84b-12cbde7653ea 11/12/22 12:03:40.327
    STEP: Creating a pod to test consume configMaps 11/12/22 12:03:40.334
    Nov 12 12:03:40.347: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8" in namespace "projected-1031" to be "Succeeded or Failed"
    Nov 12 12:03:40.354: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.203561ms
    Nov 12 12:03:42.364: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015893436s
    Nov 12 12:03:44.361: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013082864s
    STEP: Saw pod success 11/12/22 12:03:44.361
    Nov 12 12:03:44.361: INFO: Pod "pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8" satisfied condition "Succeeded or Failed"
    Nov 12 12:03:44.365: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 12:03:44.374
    Nov 12 12:03:44.394: INFO: Waiting for pod pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8 to disappear
    Nov 12 12:03:44.398: INFO: Pod pod-projected-configmaps-a94cbbe1-acce-489f-9d95-ef65e4ea17f8 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 12:03:44.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1031" for this suite. 11/12/22 12:03:44.403
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:44.417
Nov 12 12:03:44.417: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:03:44.419
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:44.443
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:44.45
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:03:44.476
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:03:44.913
STEP: Deploying the webhook pod 11/12/22 12:03:44.925
STEP: Wait for the deployment to be ready 11/12/22 12:03:44.942
Nov 12 12:03:44.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:03:46.981
STEP: Verifying the service has paired with the endpoint 11/12/22 12:03:46.994
Nov 12 12:03:47.994: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Nov 12 12:03:48.000: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7360-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 12:03:48.514
STEP: Creating a custom resource that should be mutated by the webhook 11/12/22 12:03:48.539
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:03:51.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-660" for this suite. 11/12/22 12:03:51.132
STEP: Destroying namespace "webhook-660-markers" for this suite. 11/12/22 12:03:51.139
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":17,"skipped":351,"failed":0}
------------------------------
• [SLOW TEST] [6.821 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:44.417
    Nov 12 12:03:44.417: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:03:44.419
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:44.443
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:44.45
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:03:44.476
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:03:44.913
    STEP: Deploying the webhook pod 11/12/22 12:03:44.925
    STEP: Wait for the deployment to be ready 11/12/22 12:03:44.942
    Nov 12 12:03:44.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:03:46.981
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:03:46.994
    Nov 12 12:03:47.994: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Nov 12 12:03:48.000: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7360-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 12:03:48.514
    STEP: Creating a custom resource that should be mutated by the webhook 11/12/22 12:03:48.539
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:03:51.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-660" for this suite. 11/12/22 12:03:51.132
    STEP: Destroying namespace "webhook-660-markers" for this suite. 11/12/22 12:03:51.139
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:51.241
Nov 12 12:03:51.241: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 12:03:51.242
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:51.263
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:51.269
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-6020/configmap-test-67e5d27a-1f29-43c9-a84b-b8d027dcaea7 11/12/22 12:03:51.272
STEP: Creating a pod to test consume configMaps 11/12/22 12:03:51.278
Nov 12 12:03:51.294: INFO: Waiting up to 5m0s for pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486" in namespace "configmap-6020" to be "Succeeded or Failed"
Nov 12 12:03:51.298: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486": Phase="Pending", Reason="", readiness=false. Elapsed: 4.412207ms
Nov 12 12:03:53.306: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486": Phase="Running", Reason="", readiness=false. Elapsed: 2.012463926s
Nov 12 12:03:55.305: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010946689s
STEP: Saw pod success 11/12/22 12:03:55.305
Nov 12 12:03:55.305: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486" satisfied condition "Succeeded or Failed"
Nov 12 12:03:55.309: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486 container env-test: <nil>
STEP: delete the pod 11/12/22 12:03:55.322
Nov 12 12:03:55.345: INFO: Waiting for pod pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486 to disappear
Nov 12 12:03:55.349: INFO: Pod pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 12:03:55.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6020" for this suite. 11/12/22 12:03:55.354
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":18,"skipped":390,"failed":0}
------------------------------
• [4.124 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:51.241
    Nov 12 12:03:51.241: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 12:03:51.242
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:51.263
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:51.269
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-6020/configmap-test-67e5d27a-1f29-43c9-a84b-b8d027dcaea7 11/12/22 12:03:51.272
    STEP: Creating a pod to test consume configMaps 11/12/22 12:03:51.278
    Nov 12 12:03:51.294: INFO: Waiting up to 5m0s for pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486" in namespace "configmap-6020" to be "Succeeded or Failed"
    Nov 12 12:03:51.298: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486": Phase="Pending", Reason="", readiness=false. Elapsed: 4.412207ms
    Nov 12 12:03:53.306: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486": Phase="Running", Reason="", readiness=false. Elapsed: 2.012463926s
    Nov 12 12:03:55.305: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010946689s
    STEP: Saw pod success 11/12/22 12:03:55.305
    Nov 12 12:03:55.305: INFO: Pod "pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486" satisfied condition "Succeeded or Failed"
    Nov 12 12:03:55.309: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486 container env-test: <nil>
    STEP: delete the pod 11/12/22 12:03:55.322
    Nov 12 12:03:55.345: INFO: Waiting for pod pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486 to disappear
    Nov 12 12:03:55.349: INFO: Pod pod-configmaps-cd82087c-493c-4fcd-aac6-0337b46a6486 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 12:03:55.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6020" for this suite. 11/12/22 12:03:55.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:03:55.37
Nov 12 12:03:55.370: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:03:55.371
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:55.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:55.445
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-7302 11/12/22 12:03:55.447
STEP: creating a selector 11/12/22 12:03:55.447
STEP: Creating the service pods in kubernetes 11/12/22 12:03:55.447
Nov 12 12:03:55.447: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 12 12:03:55.488: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7302" to be "running and ready"
Nov 12 12:03:55.499: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.200692ms
Nov 12 12:03:55.499: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:03:57.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017214218s
Nov 12 12:03:57.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:03:59.506: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017807553s
Nov 12 12:03:59.506: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:01.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01711581s
Nov 12 12:04:01.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:03.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.01727s
Nov 12 12:04:03.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:05.504: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016123322s
Nov 12 12:04:05.504: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:07.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.017029134s
Nov 12 12:04:07.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:09.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.016903073s
Nov 12 12:04:09.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:11.508: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.02056657s
Nov 12 12:04:11.509: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:13.506: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.017903082s
Nov 12 12:04:13.506: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:15.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.016996873s
Nov 12 12:04:15.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:04:17.507: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.018902637s
Nov 12 12:04:17.507: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 12 12:04:17.507: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 12 12:04:17.512: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7302" to be "running and ready"
Nov 12 12:04:17.517: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.059551ms
Nov 12 12:04:17.517: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 12 12:04:17.517: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 12 12:04:17.521: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7302" to be "running and ready"
Nov 12 12:04:17.527: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.043155ms
Nov 12 12:04:17.527: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 12 12:04:17.527: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/12/22 12:04:17.532
Nov 12 12:04:17.551: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7302" to be "running"
Nov 12 12:04:17.559: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.367554ms
Nov 12 12:04:19.566: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015041568s
Nov 12 12:04:19.566: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 12 12:04:19.571: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-7302" to be "running"
Nov 12 12:04:19.575: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.754054ms
Nov 12 12:04:19.575: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 12 12:04:19.578: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 12 12:04:19.578: INFO: Going to poll 192.168.249.20 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 12 12:04:19.583: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.249.20:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7302 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:04:19.583: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:04:19.585: INFO: ExecWithOptions: Clientset creation
Nov 12 12:04:19.585: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7302/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.249.20%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 12:04:19.670: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 12 12:04:19.670: INFO: Going to poll 192.168.27.74 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 12 12:04:19.674: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.27.74:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7302 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:04:19.674: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:04:19.675: INFO: ExecWithOptions: Clientset creation
Nov 12 12:04:19.675: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7302/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.27.74%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 12:04:19.747: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 12 12:04:19.747: INFO: Going to poll 192.168.128.199 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 12 12:04:19.752: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.128.199:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7302 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:04:19.752: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:04:19.752: INFO: ExecWithOptions: Clientset creation
Nov 12 12:04:19.752: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7302/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.128.199%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 12:04:19.823: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 12 12:04:19.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7302" for this suite. 11/12/22 12:04:19.828
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":19,"skipped":427,"failed":0}
------------------------------
• [SLOW TEST] [24.467 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:03:55.37
    Nov 12 12:03:55.370: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:03:55.371
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:03:55.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:03:55.445
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-7302 11/12/22 12:03:55.447
    STEP: creating a selector 11/12/22 12:03:55.447
    STEP: Creating the service pods in kubernetes 11/12/22 12:03:55.447
    Nov 12 12:03:55.447: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 12 12:03:55.488: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7302" to be "running and ready"
    Nov 12 12:03:55.499: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.200692ms
    Nov 12 12:03:55.499: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:03:57.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.017214218s
    Nov 12 12:03:57.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:03:59.506: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017807553s
    Nov 12 12:03:59.506: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:01.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01711581s
    Nov 12 12:04:01.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:03.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.01727s
    Nov 12 12:04:03.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:05.504: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016123322s
    Nov 12 12:04:05.504: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:07.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.017029134s
    Nov 12 12:04:07.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:09.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.016903073s
    Nov 12 12:04:09.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:11.508: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.02056657s
    Nov 12 12:04:11.509: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:13.506: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.017903082s
    Nov 12 12:04:13.506: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:15.505: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.016996873s
    Nov 12 12:04:15.505: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:04:17.507: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.018902637s
    Nov 12 12:04:17.507: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 12 12:04:17.507: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 12 12:04:17.512: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7302" to be "running and ready"
    Nov 12 12:04:17.517: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.059551ms
    Nov 12 12:04:17.517: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 12 12:04:17.517: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 12 12:04:17.521: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7302" to be "running and ready"
    Nov 12 12:04:17.527: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.043155ms
    Nov 12 12:04:17.527: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 12 12:04:17.527: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/12/22 12:04:17.532
    Nov 12 12:04:17.551: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7302" to be "running"
    Nov 12 12:04:17.559: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.367554ms
    Nov 12 12:04:19.566: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015041568s
    Nov 12 12:04:19.566: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 12 12:04:19.571: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-7302" to be "running"
    Nov 12 12:04:19.575: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.754054ms
    Nov 12 12:04:19.575: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 12 12:04:19.578: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 12 12:04:19.578: INFO: Going to poll 192.168.249.20 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 12:04:19.583: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.249.20:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7302 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:04:19.583: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:04:19.585: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:04:19.585: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7302/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.249.20%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 12:04:19.670: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 12 12:04:19.670: INFO: Going to poll 192.168.27.74 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 12:04:19.674: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.27.74:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7302 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:04:19.674: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:04:19.675: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:04:19.675: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7302/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.27.74%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 12:04:19.747: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 12 12:04:19.747: INFO: Going to poll 192.168.128.199 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 12:04:19.752: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.128.199:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7302 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:04:19.752: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:04:19.752: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:04:19.752: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7302/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.128.199%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 12:04:19.823: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 12 12:04:19.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-7302" for this suite. 11/12/22 12:04:19.828
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:04:19.841
Nov 12 12:04:19.841: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:04:19.842
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:19.861
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:19.865
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 11/12/22 12:04:19.872
STEP: waiting for available Endpoint 11/12/22 12:04:19.88
STEP: listing all Endpoints 11/12/22 12:04:19.882
STEP: updating the Endpoint 11/12/22 12:04:19.89
STEP: fetching the Endpoint 11/12/22 12:04:19.898
STEP: patching the Endpoint 11/12/22 12:04:19.902
STEP: fetching the Endpoint 11/12/22 12:04:19.912
STEP: deleting the Endpoint by Collection 11/12/22 12:04:19.917
STEP: waiting for Endpoint deletion 11/12/22 12:04:19.929
STEP: fetching the Endpoint 11/12/22 12:04:19.931
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:04:19.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5768" for this suite. 11/12/22 12:04:19.94
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":20,"skipped":443,"failed":0}
------------------------------
• [0.113 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:04:19.841
    Nov 12 12:04:19.841: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:04:19.842
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:19.861
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:19.865
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 11/12/22 12:04:19.872
    STEP: waiting for available Endpoint 11/12/22 12:04:19.88
    STEP: listing all Endpoints 11/12/22 12:04:19.882
    STEP: updating the Endpoint 11/12/22 12:04:19.89
    STEP: fetching the Endpoint 11/12/22 12:04:19.898
    STEP: patching the Endpoint 11/12/22 12:04:19.902
    STEP: fetching the Endpoint 11/12/22 12:04:19.912
    STEP: deleting the Endpoint by Collection 11/12/22 12:04:19.917
    STEP: waiting for Endpoint deletion 11/12/22 12:04:19.929
    STEP: fetching the Endpoint 11/12/22 12:04:19.931
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:04:19.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5768" for this suite. 11/12/22 12:04:19.94
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:04:19.956
Nov 12 12:04:19.956: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:04:19.957
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:19.975
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:19.981
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 11/12/22 12:04:19.987
Nov 12 12:04:20.007: INFO: Waiting up to 5m0s for pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6" in namespace "emptydir-6519" to be "Succeeded or Failed"
Nov 12 12:04:20.016: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.034721ms
Nov 12 12:04:22.026: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019282499s
Nov 12 12:04:24.021: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014913897s
STEP: Saw pod success 11/12/22 12:04:24.022
Nov 12 12:04:24.022: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6" satisfied condition "Succeeded or Failed"
Nov 12 12:04:24.026: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6 container test-container: <nil>
STEP: delete the pod 11/12/22 12:04:24.035
Nov 12 12:04:24.050: INFO: Waiting for pod pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6 to disappear
Nov 12 12:04:24.055: INFO: Pod pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:04:24.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6519" for this suite. 11/12/22 12:04:24.059
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":21,"skipped":448,"failed":0}
------------------------------
• [4.114 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:04:19.956
    Nov 12 12:04:19.956: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:04:19.957
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:19.975
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:19.981
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/12/22 12:04:19.987
    Nov 12 12:04:20.007: INFO: Waiting up to 5m0s for pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6" in namespace "emptydir-6519" to be "Succeeded or Failed"
    Nov 12 12:04:20.016: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.034721ms
    Nov 12 12:04:22.026: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019282499s
    Nov 12 12:04:24.021: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014913897s
    STEP: Saw pod success 11/12/22 12:04:24.022
    Nov 12 12:04:24.022: INFO: Pod "pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6" satisfied condition "Succeeded or Failed"
    Nov 12 12:04:24.026: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:04:24.035
    Nov 12 12:04:24.050: INFO: Waiting for pod pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6 to disappear
    Nov 12 12:04:24.055: INFO: Pod pod-cbb93ca2-85f6-49ed-8af3-7e53241fa8a6 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:04:24.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6519" for this suite. 11/12/22 12:04:24.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:04:24.077
Nov 12 12:04:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 12:04:24.079
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:24.099
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:24.102
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Nov 12 12:04:24.115: INFO: Waiting up to 5m0s for pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7" in namespace "container-probe-6333" to be "running and ready"
Nov 12 12:04:24.124: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.880183ms
Nov 12 12:04:24.124: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:04:26.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 2.014608557s
Nov 12 12:04:26.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:28.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 4.014727814s
Nov 12 12:04:28.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:30.133: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 6.017416956s
Nov 12 12:04:30.133: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:32.128: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 8.013288745s
Nov 12 12:04:32.129: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:34.131: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 10.015935792s
Nov 12 12:04:34.131: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:36.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 12.015026873s
Nov 12 12:04:36.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:38.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 14.014402151s
Nov 12 12:04:38.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:40.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 16.014555115s
Nov 12 12:04:40.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:42.129: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 18.013776564s
Nov 12 12:04:42.129: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:44.137: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 20.021736629s
Nov 12 12:04:44.137: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
Nov 12 12:04:46.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=true. Elapsed: 22.014368631s
Nov 12 12:04:46.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = true)
Nov 12 12:04:46.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7" satisfied condition "running and ready"
Nov 12 12:04:46.135: INFO: Container started at 2022-11-12 12:04:24 +0000 UTC, pod became ready at 2022-11-12 12:04:44 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 12:04:46.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6333" for this suite. 11/12/22 12:04:46.14
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":22,"skipped":536,"failed":0}
------------------------------
• [SLOW TEST] [22.074 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:04:24.077
    Nov 12 12:04:24.078: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 12:04:24.079
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:24.099
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:24.102
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Nov 12 12:04:24.115: INFO: Waiting up to 5m0s for pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7" in namespace "container-probe-6333" to be "running and ready"
    Nov 12 12:04:24.124: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.880183ms
    Nov 12 12:04:24.124: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:04:26.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 2.014608557s
    Nov 12 12:04:26.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:28.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 4.014727814s
    Nov 12 12:04:28.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:30.133: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 6.017416956s
    Nov 12 12:04:30.133: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:32.128: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 8.013288745s
    Nov 12 12:04:32.129: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:34.131: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 10.015935792s
    Nov 12 12:04:34.131: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:36.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 12.015026873s
    Nov 12 12:04:36.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:38.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 14.014402151s
    Nov 12 12:04:38.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:40.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 16.014555115s
    Nov 12 12:04:40.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:42.129: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 18.013776564s
    Nov 12 12:04:42.129: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:44.137: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=false. Elapsed: 20.021736629s
    Nov 12 12:04:44.137: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = false)
    Nov 12 12:04:46.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7": Phase="Running", Reason="", readiness=true. Elapsed: 22.014368631s
    Nov 12 12:04:46.130: INFO: The phase of Pod test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7 is Running (Ready = true)
    Nov 12 12:04:46.130: INFO: Pod "test-webserver-8caf4326-d122-4c9a-8940-70b8719d30a7" satisfied condition "running and ready"
    Nov 12 12:04:46.135: INFO: Container started at 2022-11-12 12:04:24 +0000 UTC, pod became ready at 2022-11-12 12:04:44 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 12:04:46.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6333" for this suite. 11/12/22 12:04:46.14
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:04:46.153
Nov 12 12:04:46.154: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:04:46.154
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:46.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:46.174
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 11/12/22 12:04:46.183
Nov 12 12:04:46.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 create -f -'
Nov 12 12:04:47.122: INFO: stderr: ""
Nov 12 12:04:47.122: INFO: stdout: "pod/pause created\n"
Nov 12 12:04:47.122: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 12 12:04:47.123: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8208" to be "running and ready"
Nov 12 12:04:47.131: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.29203ms
Nov 12 12:04:47.131: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-14-110' to be 'Running' but was 'Pending'
Nov 12 12:04:49.135: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.012917523s
Nov 12 12:04:49.135: INFO: Pod "pause" satisfied condition "running and ready"
Nov 12 12:04:49.135: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 11/12/22 12:04:49.136
Nov 12 12:04:49.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 label pods pause testing-label=testing-label-value'
Nov 12 12:04:49.254: INFO: stderr: ""
Nov 12 12:04:49.254: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 11/12/22 12:04:49.254
Nov 12 12:04:49.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get pod pause -L testing-label'
Nov 12 12:04:49.331: INFO: stderr: ""
Nov 12 12:04:49.331: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 11/12/22 12:04:49.331
Nov 12 12:04:49.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 label pods pause testing-label-'
Nov 12 12:04:49.417: INFO: stderr: ""
Nov 12 12:04:49.417: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 11/12/22 12:04:49.417
Nov 12 12:04:49.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get pod pause -L testing-label'
Nov 12 12:04:49.536: INFO: stderr: ""
Nov 12 12:04:49.536: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 11/12/22 12:04:49.536
Nov 12 12:04:49.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 delete --grace-period=0 --force -f -'
Nov 12 12:04:49.618: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 12:04:49.618: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 12 12:04:49.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get rc,svc -l name=pause --no-headers'
Nov 12 12:04:49.731: INFO: stderr: "No resources found in kubectl-8208 namespace.\n"
Nov 12 12:04:49.731: INFO: stdout: ""
Nov 12 12:04:49.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 12 12:04:49.804: INFO: stderr: ""
Nov 12 12:04:49.804: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:04:49.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8208" for this suite. 11/12/22 12:04:49.809
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":23,"skipped":545,"failed":0}
------------------------------
• [3.665 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:04:46.153
    Nov 12 12:04:46.154: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:04:46.154
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:46.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:46.174
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 11/12/22 12:04:46.183
    Nov 12 12:04:46.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 create -f -'
    Nov 12 12:04:47.122: INFO: stderr: ""
    Nov 12 12:04:47.122: INFO: stdout: "pod/pause created\n"
    Nov 12 12:04:47.122: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Nov 12 12:04:47.123: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8208" to be "running and ready"
    Nov 12 12:04:47.131: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.29203ms
    Nov 12 12:04:47.131: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-14-110' to be 'Running' but was 'Pending'
    Nov 12 12:04:49.135: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.012917523s
    Nov 12 12:04:49.135: INFO: Pod "pause" satisfied condition "running and ready"
    Nov 12 12:04:49.135: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 11/12/22 12:04:49.136
    Nov 12 12:04:49.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 label pods pause testing-label=testing-label-value'
    Nov 12 12:04:49.254: INFO: stderr: ""
    Nov 12 12:04:49.254: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 11/12/22 12:04:49.254
    Nov 12 12:04:49.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get pod pause -L testing-label'
    Nov 12 12:04:49.331: INFO: stderr: ""
    Nov 12 12:04:49.331: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 11/12/22 12:04:49.331
    Nov 12 12:04:49.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 label pods pause testing-label-'
    Nov 12 12:04:49.417: INFO: stderr: ""
    Nov 12 12:04:49.417: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 11/12/22 12:04:49.417
    Nov 12 12:04:49.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get pod pause -L testing-label'
    Nov 12 12:04:49.536: INFO: stderr: ""
    Nov 12 12:04:49.536: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 11/12/22 12:04:49.536
    Nov 12 12:04:49.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 delete --grace-period=0 --force -f -'
    Nov 12 12:04:49.618: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 12:04:49.618: INFO: stdout: "pod \"pause\" force deleted\n"
    Nov 12 12:04:49.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get rc,svc -l name=pause --no-headers'
    Nov 12 12:04:49.731: INFO: stderr: "No resources found in kubectl-8208 namespace.\n"
    Nov 12 12:04:49.731: INFO: stdout: ""
    Nov 12 12:04:49.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8208 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 12 12:04:49.804: INFO: stderr: ""
    Nov 12 12:04:49.804: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:04:49.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8208" for this suite. 11/12/22 12:04:49.809
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:04:49.821
Nov 12 12:04:49.822: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:04:49.823
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:49.84
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:49.843
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 11/12/22 12:04:49.845
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/12/22 12:04:49.846
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 12:04:49.847
STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/12/22 12:04:49.847
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/12/22 12:04:49.848
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 12:04:49.848
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 12:04:49.849
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:04:49.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9010" for this suite. 11/12/22 12:04:49.853
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":24,"skipped":578,"failed":0}
------------------------------
• [0.041 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:04:49.821
    Nov 12 12:04:49.822: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:04:49.823
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:49.84
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:49.843
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 11/12/22 12:04:49.845
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/12/22 12:04:49.846
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 12:04:49.847
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/12/22 12:04:49.847
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/12/22 12:04:49.848
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 12:04:49.848
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/12/22 12:04:49.849
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:04:49.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9010" for this suite. 11/12/22 12:04:49.853
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:04:49.864
Nov 12 12:04:49.864: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 12:04:49.865
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:49.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:49.888
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-ba0c5f1a-49bc-4cf3-8d0a-866065b80928 11/12/22 12:04:49.892
STEP: Creating a pod to test consume secrets 11/12/22 12:04:49.898
Nov 12 12:04:49.907: INFO: Waiting up to 5m0s for pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103" in namespace "secrets-2970" to be "Succeeded or Failed"
Nov 12 12:04:49.912: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801149ms
Nov 12 12:04:51.917: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010190351s
Nov 12 12:04:53.917: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009437015s
STEP: Saw pod success 11/12/22 12:04:53.917
Nov 12 12:04:53.917: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103" satisfied condition "Succeeded or Failed"
Nov 12 12:04:53.921: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 12:04:53.93
Nov 12 12:04:53.945: INFO: Waiting for pod pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103 to disappear
Nov 12 12:04:53.948: INFO: Pod pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 12:04:53.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2970" for this suite. 11/12/22 12:04:53.955
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":25,"skipped":584,"failed":0}
------------------------------
• [4.102 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:04:49.864
    Nov 12 12:04:49.864: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 12:04:49.865
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:49.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:49.888
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-ba0c5f1a-49bc-4cf3-8d0a-866065b80928 11/12/22 12:04:49.892
    STEP: Creating a pod to test consume secrets 11/12/22 12:04:49.898
    Nov 12 12:04:49.907: INFO: Waiting up to 5m0s for pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103" in namespace "secrets-2970" to be "Succeeded or Failed"
    Nov 12 12:04:49.912: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801149ms
    Nov 12 12:04:51.917: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010190351s
    Nov 12 12:04:53.917: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009437015s
    STEP: Saw pod success 11/12/22 12:04:53.917
    Nov 12 12:04:53.917: INFO: Pod "pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103" satisfied condition "Succeeded or Failed"
    Nov 12 12:04:53.921: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:04:53.93
    Nov 12 12:04:53.945: INFO: Waiting for pod pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103 to disappear
    Nov 12 12:04:53.948: INFO: Pod pod-secrets-8605a975-d4ce-4547-8e24-2742a2d54103 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 12:04:53.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2970" for this suite. 11/12/22 12:04:53.955
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:04:53.969
Nov 12 12:04:53.969: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename svc-latency 11/12/22 12:04:53.97
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:53.991
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:53.995
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Nov 12 12:04:53.998: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2747 11/12/22 12:04:53.999
I1112 12:04:54.016175      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2747, replica count: 1
I1112 12:04:55.066953      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1112 12:04:56.067139      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 12:04:56.183: INFO: Created: latency-svc-8jj6l
Nov 12 12:04:56.198: INFO: Got endpoints: latency-svc-8jj6l [29.866958ms]
Nov 12 12:04:56.229: INFO: Created: latency-svc-nkw66
Nov 12 12:04:56.239: INFO: Got endpoints: latency-svc-nkw66 [41.254816ms]
Nov 12 12:04:56.246: INFO: Created: latency-svc-z46wn
Nov 12 12:04:56.258: INFO: Got endpoints: latency-svc-z46wn [59.908758ms]
Nov 12 12:04:56.264: INFO: Created: latency-svc-s5gzz
Nov 12 12:04:56.271: INFO: Got endpoints: latency-svc-s5gzz [71.710982ms]
Nov 12 12:04:56.275: INFO: Created: latency-svc-xwp9q
Nov 12 12:04:56.288: INFO: Got endpoints: latency-svc-xwp9q [88.979935ms]
Nov 12 12:04:56.292: INFO: Created: latency-svc-rtdm2
Nov 12 12:04:56.302: INFO: Got endpoints: latency-svc-rtdm2 [103.204118ms]
Nov 12 12:04:56.308: INFO: Created: latency-svc-kqzw9
Nov 12 12:04:56.317: INFO: Created: latency-svc-h8jkn
Nov 12 12:04:56.321: INFO: Got endpoints: latency-svc-kqzw9 [122.159734ms]
Nov 12 12:04:56.332: INFO: Got endpoints: latency-svc-h8jkn [133.130783ms]
Nov 12 12:04:56.332: INFO: Created: latency-svc-jbldx
Nov 12 12:04:56.340: INFO: Got endpoints: latency-svc-jbldx [140.57344ms]
Nov 12 12:04:56.345: INFO: Created: latency-svc-47m4h
Nov 12 12:04:56.350: INFO: Got endpoints: latency-svc-47m4h [150.526818ms]
Nov 12 12:04:56.350: INFO: Created: latency-svc-tpzg6
Nov 12 12:04:56.358: INFO: Got endpoints: latency-svc-tpzg6 [158.989884ms]
Nov 12 12:04:56.366: INFO: Created: latency-svc-txq8s
Nov 12 12:04:56.376: INFO: Got endpoints: latency-svc-txq8s [177.039636ms]
Nov 12 12:04:56.379: INFO: Created: latency-svc-spnwp
Nov 12 12:04:56.388: INFO: Got endpoints: latency-svc-spnwp [189.243902ms]
Nov 12 12:04:56.393: INFO: Created: latency-svc-tsggw
Nov 12 12:04:56.399: INFO: Got endpoints: latency-svc-tsggw [200.638822ms]
Nov 12 12:04:56.402: INFO: Created: latency-svc-szwt4
Nov 12 12:04:56.409: INFO: Got endpoints: latency-svc-szwt4 [210.220902ms]
Nov 12 12:04:56.412: INFO: Created: latency-svc-tjgkv
Nov 12 12:04:56.419: INFO: Got endpoints: latency-svc-tjgkv [220.434298ms]
Nov 12 12:04:56.523: INFO: Created: latency-svc-64dzr
Nov 12 12:04:56.527: INFO: Created: latency-svc-rpd6z
Nov 12 12:04:56.527: INFO: Created: latency-svc-bt5kk
Nov 12 12:04:56.527: INFO: Created: latency-svc-cn2qv
Nov 12 12:04:56.529: INFO: Created: latency-svc-2725n
Nov 12 12:04:56.530: INFO: Created: latency-svc-tpq89
Nov 12 12:04:56.530: INFO: Created: latency-svc-frvj5
Nov 12 12:04:56.530: INFO: Created: latency-svc-dmnch
Nov 12 12:04:56.530: INFO: Created: latency-svc-x5l59
Nov 12 12:04:56.535: INFO: Created: latency-svc-mzxqz
Nov 12 12:04:56.535: INFO: Created: latency-svc-4nntz
Nov 12 12:04:56.535: INFO: Created: latency-svc-j5lzb
Nov 12 12:04:56.537: INFO: Created: latency-svc-t6gjq
Nov 12 12:04:56.539: INFO: Created: latency-svc-xlbmm
Nov 12 12:04:56.539: INFO: Created: latency-svc-htjf9
Nov 12 12:04:56.556: INFO: Got endpoints: latency-svc-cn2qv [298.260446ms]
Nov 12 12:04:56.563: INFO: Got endpoints: latency-svc-64dzr [241.745111ms]
Nov 12 12:04:56.568: INFO: Got endpoints: latency-svc-rpd6z [266.441559ms]
Nov 12 12:04:56.569: INFO: Got endpoints: latency-svc-bt5kk [228.891756ms]
Nov 12 12:04:56.572: INFO: Got endpoints: latency-svc-t6gjq [332.244166ms]
Nov 12 12:04:56.573: INFO: Got endpoints: latency-svc-j5lzb [285.496929ms]
Nov 12 12:04:56.582: INFO: Got endpoints: latency-svc-frvj5 [205.619211ms]
Nov 12 12:04:56.586: INFO: Created: latency-svc-khr2s
Nov 12 12:04:56.593: INFO: Got endpoints: latency-svc-htjf9 [261.26183ms]
Nov 12 12:04:56.597: INFO: Got endpoints: latency-svc-2725n [326.042318ms]
Nov 12 12:04:56.599: INFO: Got endpoints: latency-svc-xlbmm [210.345728ms]
Nov 12 12:04:56.602: INFO: Got endpoints: latency-svc-tpq89 [244.121094ms]
Nov 12 12:04:56.613: INFO: Got endpoints: latency-svc-x5l59 [193.151327ms]
Nov 12 12:04:56.616: INFO: Got endpoints: latency-svc-dmnch [216.497408ms]
Nov 12 12:04:56.622: INFO: Got endpoints: latency-svc-khr2s [65.245622ms]
Nov 12 12:04:56.622: INFO: Got endpoints: latency-svc-4nntz [212.990444ms]
Nov 12 12:04:56.623: INFO: Got endpoints: latency-svc-mzxqz [271.877819ms]
Nov 12 12:04:56.745: INFO: Created: latency-svc-k9z86
Nov 12 12:04:56.754: INFO: Created: latency-svc-qg94f
Nov 12 12:04:56.762: INFO: Created: latency-svc-p8272
Nov 12 12:04:56.777: INFO: Created: latency-svc-cxz2t
Nov 12 12:04:56.779: INFO: Created: latency-svc-49hld
Nov 12 12:04:56.780: INFO: Created: latency-svc-ffdft
Nov 12 12:04:56.780: INFO: Created: latency-svc-24sfp
Nov 12 12:04:56.781: INFO: Created: latency-svc-6ttkg
Nov 12 12:04:56.781: INFO: Created: latency-svc-4t4kx
Nov 12 12:04:56.781: INFO: Created: latency-svc-gmvmf
Nov 12 12:04:56.781: INFO: Created: latency-svc-gllkh
Nov 12 12:04:56.781: INFO: Created: latency-svc-fg4jg
Nov 12 12:04:56.782: INFO: Created: latency-svc-zzgtx
Nov 12 12:04:56.780: INFO: Created: latency-svc-fs59z
Nov 12 12:04:56.782: INFO: Got endpoints: latency-svc-k9z86 [159.181132ms]
Nov 12 12:04:56.782: INFO: Created: latency-svc-8l9bq
Nov 12 12:04:56.785: INFO: Got endpoints: latency-svc-qg94f [182.546663ms]
Nov 12 12:04:56.790: INFO: Got endpoints: latency-svc-4t4kx [221.392469ms]
Nov 12 12:04:56.792: INFO: Got endpoints: latency-svc-cxz2t [175.964656ms]
Nov 12 12:04:56.792: INFO: Got endpoints: latency-svc-fg4jg [210.549114ms]
Nov 12 12:04:56.801: INFO: Got endpoints: latency-svc-fs59z [231.733756ms]
Nov 12 12:04:56.807: INFO: Got endpoints: latency-svc-ffdft [194.81318ms]
Nov 12 12:04:56.810: INFO: Got endpoints: latency-svc-zzgtx [236.211511ms]
Nov 12 12:04:56.814: INFO: Got endpoints: latency-svc-p8272 [191.772719ms]
Nov 12 12:04:56.814: INFO: Got endpoints: latency-svc-6ttkg [217.039586ms]
Nov 12 12:04:56.817: INFO: Created: latency-svc-6rk6l
Nov 12 12:04:56.835: INFO: Created: latency-svc-jsljf
Nov 12 12:04:56.840: INFO: Created: latency-svc-m6km2
Nov 12 12:04:56.845: INFO: Created: latency-svc-cp64s
Nov 12 12:04:56.847: INFO: Got endpoints: latency-svc-gllkh [275.586114ms]
Nov 12 12:04:56.858: INFO: Created: latency-svc-s9txf
Nov 12 12:04:56.867: INFO: Created: latency-svc-dt9hn
Nov 12 12:04:56.879: INFO: Created: latency-svc-wd49w
Nov 12 12:04:56.892: INFO: Got endpoints: latency-svc-8l9bq [328.684387ms]
Nov 12 12:04:56.899: INFO: Created: latency-svc-gvwvw
Nov 12 12:04:56.906: INFO: Created: latency-svc-6lxbp
Nov 12 12:04:56.936: INFO: Created: latency-svc-brqb9
Nov 12 12:04:56.940: INFO: Created: latency-svc-59k7f
Nov 12 12:04:56.940: INFO: Created: latency-svc-lfm7f
Nov 12 12:04:56.947: INFO: Got endpoints: latency-svc-gmvmf [353.927205ms]
Nov 12 12:04:56.964: INFO: Created: latency-svc-7nnc4
Nov 12 12:04:56.993: INFO: Got endpoints: latency-svc-24sfp [370.434741ms]
Nov 12 12:04:57.008: INFO: Created: latency-svc-25hxj
Nov 12 12:04:57.046: INFO: Got endpoints: latency-svc-49hld [447.758925ms]
Nov 12 12:04:57.064: INFO: Created: latency-svc-w6l7s
Nov 12 12:04:57.092: INFO: Got endpoints: latency-svc-6rk6l [309.707813ms]
Nov 12 12:04:57.107: INFO: Created: latency-svc-tzjrl
Nov 12 12:04:57.140: INFO: Got endpoints: latency-svc-jsljf [349.954585ms]
Nov 12 12:04:57.155: INFO: Created: latency-svc-7cx8q
Nov 12 12:04:57.196: INFO: Got endpoints: latency-svc-m6km2 [411.106ms]
Nov 12 12:04:57.217: INFO: Created: latency-svc-tg2bk
Nov 12 12:04:57.242: INFO: Got endpoints: latency-svc-cp64s [449.852222ms]
Nov 12 12:04:57.258: INFO: Created: latency-svc-lnc4j
Nov 12 12:04:57.293: INFO: Got endpoints: latency-svc-s9txf [501.109484ms]
Nov 12 12:04:57.308: INFO: Created: latency-svc-dkmgg
Nov 12 12:04:57.344: INFO: Got endpoints: latency-svc-dt9hn [543.077849ms]
Nov 12 12:04:57.359: INFO: Created: latency-svc-gztl5
Nov 12 12:04:57.396: INFO: Got endpoints: latency-svc-wd49w [585.793788ms]
Nov 12 12:04:57.409: INFO: Created: latency-svc-zm4pn
Nov 12 12:04:57.444: INFO: Got endpoints: latency-svc-gvwvw [636.772858ms]
Nov 12 12:04:57.459: INFO: Created: latency-svc-fj2hq
Nov 12 12:04:57.493: INFO: Got endpoints: latency-svc-6lxbp [679.038424ms]
Nov 12 12:04:57.511: INFO: Created: latency-svc-wl945
Nov 12 12:04:57.541: INFO: Got endpoints: latency-svc-59k7f [649.20577ms]
Nov 12 12:04:57.555: INFO: Created: latency-svc-gv2vq
Nov 12 12:04:57.592: INFO: Got endpoints: latency-svc-brqb9 [744.715358ms]
Nov 12 12:04:57.608: INFO: Created: latency-svc-jr2cp
Nov 12 12:04:57.643: INFO: Got endpoints: latency-svc-lfm7f [828.721317ms]
Nov 12 12:04:57.656: INFO: Created: latency-svc-hzxtl
Nov 12 12:04:57.691: INFO: Got endpoints: latency-svc-7nnc4 [743.707665ms]
Nov 12 12:04:57.704: INFO: Created: latency-svc-rz876
Nov 12 12:04:57.745: INFO: Got endpoints: latency-svc-25hxj [751.731827ms]
Nov 12 12:04:57.764: INFO: Created: latency-svc-vswtw
Nov 12 12:04:57.793: INFO: Got endpoints: latency-svc-w6l7s [746.836626ms]
Nov 12 12:04:57.810: INFO: Created: latency-svc-lz4dh
Nov 12 12:04:57.840: INFO: Got endpoints: latency-svc-tzjrl [748.255201ms]
Nov 12 12:04:57.853: INFO: Created: latency-svc-6s8n5
Nov 12 12:04:57.895: INFO: Got endpoints: latency-svc-7cx8q [754.691867ms]
Nov 12 12:04:57.909: INFO: Created: latency-svc-fhnwl
Nov 12 12:04:57.945: INFO: Got endpoints: latency-svc-tg2bk [748.52219ms]
Nov 12 12:04:57.962: INFO: Created: latency-svc-r7bxg
Nov 12 12:04:57.994: INFO: Got endpoints: latency-svc-lnc4j [751.507618ms]
Nov 12 12:04:58.007: INFO: Created: latency-svc-fm2vq
Nov 12 12:04:58.044: INFO: Got endpoints: latency-svc-dkmgg [750.63978ms]
Nov 12 12:04:58.066: INFO: Created: latency-svc-4jxhx
Nov 12 12:04:58.092: INFO: Got endpoints: latency-svc-gztl5 [747.414699ms]
Nov 12 12:04:58.108: INFO: Created: latency-svc-jhsvt
Nov 12 12:04:58.141: INFO: Got endpoints: latency-svc-zm4pn [745.271161ms]
Nov 12 12:04:58.158: INFO: Created: latency-svc-xbxrh
Nov 12 12:04:58.215: INFO: Got endpoints: latency-svc-fj2hq [770.560333ms]
Nov 12 12:04:58.231: INFO: Created: latency-svc-gsl6q
Nov 12 12:04:58.243: INFO: Got endpoints: latency-svc-wl945 [749.918415ms]
Nov 12 12:04:58.259: INFO: Created: latency-svc-pqkd4
Nov 12 12:04:58.291: INFO: Got endpoints: latency-svc-gv2vq [750.123823ms]
Nov 12 12:04:58.305: INFO: Created: latency-svc-4j7v4
Nov 12 12:04:58.345: INFO: Got endpoints: latency-svc-jr2cp [752.106055ms]
Nov 12 12:04:58.359: INFO: Created: latency-svc-m4bvw
Nov 12 12:04:58.391: INFO: Got endpoints: latency-svc-hzxtl [747.93082ms]
Nov 12 12:04:58.411: INFO: Created: latency-svc-ljks5
Nov 12 12:04:58.442: INFO: Got endpoints: latency-svc-rz876 [749.533583ms]
Nov 12 12:04:58.461: INFO: Created: latency-svc-2xvd2
Nov 12 12:04:58.492: INFO: Got endpoints: latency-svc-vswtw [746.779905ms]
Nov 12 12:04:58.509: INFO: Created: latency-svc-kzfgg
Nov 12 12:04:58.543: INFO: Got endpoints: latency-svc-lz4dh [748.940668ms]
Nov 12 12:04:58.559: INFO: Created: latency-svc-k727g
Nov 12 12:04:58.592: INFO: Got endpoints: latency-svc-6s8n5 [752.337848ms]
Nov 12 12:04:58.610: INFO: Created: latency-svc-dpp8s
Nov 12 12:04:58.642: INFO: Got endpoints: latency-svc-fhnwl [746.569495ms]
Nov 12 12:04:58.660: INFO: Created: latency-svc-vbb2s
Nov 12 12:04:58.695: INFO: Got endpoints: latency-svc-r7bxg [750.340673ms]
Nov 12 12:04:58.709: INFO: Created: latency-svc-nkr7h
Nov 12 12:04:58.743: INFO: Got endpoints: latency-svc-fm2vq [748.496428ms]
Nov 12 12:04:58.756: INFO: Created: latency-svc-rl9lx
Nov 12 12:04:58.793: INFO: Got endpoints: latency-svc-4jxhx [748.571797ms]
Nov 12 12:04:58.809: INFO: Created: latency-svc-c7t2k
Nov 12 12:04:58.844: INFO: Got endpoints: latency-svc-jhsvt [752.060102ms]
Nov 12 12:04:58.863: INFO: Created: latency-svc-gvqjp
Nov 12 12:04:58.893: INFO: Got endpoints: latency-svc-xbxrh [751.476285ms]
Nov 12 12:04:58.910: INFO: Created: latency-svc-z86kv
Nov 12 12:04:58.944: INFO: Got endpoints: latency-svc-gsl6q [729.294ms]
Nov 12 12:04:58.962: INFO: Created: latency-svc-ckl5h
Nov 12 12:04:58.991: INFO: Got endpoints: latency-svc-pqkd4 [747.476464ms]
Nov 12 12:04:59.012: INFO: Created: latency-svc-sf7pl
Nov 12 12:04:59.047: INFO: Got endpoints: latency-svc-4j7v4 [755.896684ms]
Nov 12 12:04:59.070: INFO: Created: latency-svc-qzhxf
Nov 12 12:04:59.091: INFO: Got endpoints: latency-svc-m4bvw [746.726166ms]
Nov 12 12:04:59.106: INFO: Created: latency-svc-9cpcd
Nov 12 12:04:59.143: INFO: Got endpoints: latency-svc-ljks5 [751.248819ms]
Nov 12 12:04:59.158: INFO: Created: latency-svc-nd45d
Nov 12 12:04:59.196: INFO: Got endpoints: latency-svc-2xvd2 [754.202697ms]
Nov 12 12:04:59.218: INFO: Created: latency-svc-nhvjz
Nov 12 12:04:59.251: INFO: Got endpoints: latency-svc-kzfgg [758.468918ms]
Nov 12 12:04:59.290: INFO: Created: latency-svc-7qgmj
Nov 12 12:04:59.299: INFO: Got endpoints: latency-svc-k727g [756.103105ms]
Nov 12 12:04:59.315: INFO: Created: latency-svc-ffk44
Nov 12 12:04:59.345: INFO: Got endpoints: latency-svc-dpp8s [752.539607ms]
Nov 12 12:04:59.360: INFO: Created: latency-svc-gft5m
Nov 12 12:04:59.391: INFO: Got endpoints: latency-svc-vbb2s [748.915594ms]
Nov 12 12:04:59.406: INFO: Created: latency-svc-rfgf6
Nov 12 12:04:59.443: INFO: Got endpoints: latency-svc-nkr7h [747.548567ms]
Nov 12 12:04:59.462: INFO: Created: latency-svc-ddp9t
Nov 12 12:04:59.494: INFO: Got endpoints: latency-svc-rl9lx [751.608225ms]
Nov 12 12:04:59.510: INFO: Created: latency-svc-zrbmc
Nov 12 12:04:59.541: INFO: Got endpoints: latency-svc-c7t2k [747.693454ms]
Nov 12 12:04:59.556: INFO: Created: latency-svc-5h84q
Nov 12 12:04:59.593: INFO: Got endpoints: latency-svc-gvqjp [748.309636ms]
Nov 12 12:04:59.605: INFO: Created: latency-svc-xpr8x
Nov 12 12:04:59.644: INFO: Got endpoints: latency-svc-z86kv [751.295006ms]
Nov 12 12:04:59.658: INFO: Created: latency-svc-9x95g
Nov 12 12:04:59.694: INFO: Got endpoints: latency-svc-ckl5h [749.162912ms]
Nov 12 12:04:59.707: INFO: Created: latency-svc-kqlv8
Nov 12 12:04:59.747: INFO: Got endpoints: latency-svc-sf7pl [756.348187ms]
Nov 12 12:04:59.766: INFO: Created: latency-svc-9xf8q
Nov 12 12:04:59.793: INFO: Got endpoints: latency-svc-qzhxf [746.024646ms]
Nov 12 12:04:59.807: INFO: Created: latency-svc-m2bvl
Nov 12 12:04:59.846: INFO: Got endpoints: latency-svc-9cpcd [754.717309ms]
Nov 12 12:04:59.870: INFO: Created: latency-svc-lvhmn
Nov 12 12:04:59.894: INFO: Got endpoints: latency-svc-nd45d [750.94333ms]
Nov 12 12:04:59.910: INFO: Created: latency-svc-4svt5
Nov 12 12:04:59.947: INFO: Got endpoints: latency-svc-nhvjz [750.233069ms]
Nov 12 12:04:59.963: INFO: Created: latency-svc-8jlpg
Nov 12 12:04:59.992: INFO: Got endpoints: latency-svc-7qgmj [740.264854ms]
Nov 12 12:05:00.009: INFO: Created: latency-svc-4hhmx
Nov 12 12:05:00.064: INFO: Got endpoints: latency-svc-ffk44 [765.539462ms]
Nov 12 12:05:00.081: INFO: Created: latency-svc-qlvps
Nov 12 12:05:00.108: INFO: Got endpoints: latency-svc-gft5m [763.258051ms]
Nov 12 12:05:00.124: INFO: Created: latency-svc-g2f7t
Nov 12 12:05:00.145: INFO: Got endpoints: latency-svc-rfgf6 [753.326891ms]
Nov 12 12:05:00.161: INFO: Created: latency-svc-c9wvk
Nov 12 12:05:00.191: INFO: Got endpoints: latency-svc-ddp9t [748.188027ms]
Nov 12 12:05:00.215: INFO: Created: latency-svc-4jhhb
Nov 12 12:05:00.243: INFO: Got endpoints: latency-svc-zrbmc [748.434965ms]
Nov 12 12:05:00.261: INFO: Created: latency-svc-pjbvc
Nov 12 12:05:00.297: INFO: Got endpoints: latency-svc-5h84q [756.380367ms]
Nov 12 12:05:00.316: INFO: Created: latency-svc-7gckh
Nov 12 12:05:00.344: INFO: Got endpoints: latency-svc-xpr8x [751.76478ms]
Nov 12 12:05:00.360: INFO: Created: latency-svc-r7npv
Nov 12 12:05:00.392: INFO: Got endpoints: latency-svc-9x95g [747.828495ms]
Nov 12 12:05:00.408: INFO: Created: latency-svc-qd5hg
Nov 12 12:05:00.443: INFO: Got endpoints: latency-svc-kqlv8 [749.883745ms]
Nov 12 12:05:00.457: INFO: Created: latency-svc-f2mg4
Nov 12 12:05:00.495: INFO: Got endpoints: latency-svc-9xf8q [747.471904ms]
Nov 12 12:05:00.514: INFO: Created: latency-svc-slkww
Nov 12 12:05:00.541: INFO: Got endpoints: latency-svc-m2bvl [747.953869ms]
Nov 12 12:05:00.559: INFO: Created: latency-svc-wl2h7
Nov 12 12:05:00.593: INFO: Got endpoints: latency-svc-lvhmn [746.277509ms]
Nov 12 12:05:00.610: INFO: Created: latency-svc-ggz6v
Nov 12 12:05:00.641: INFO: Got endpoints: latency-svc-4svt5 [747.300863ms]
Nov 12 12:05:00.658: INFO: Created: latency-svc-7pbh2
Nov 12 12:05:00.692: INFO: Got endpoints: latency-svc-8jlpg [744.780662ms]
Nov 12 12:05:00.706: INFO: Created: latency-svc-lcdps
Nov 12 12:05:00.744: INFO: Got endpoints: latency-svc-4hhmx [752.711931ms]
Nov 12 12:05:00.758: INFO: Created: latency-svc-b9kg9
Nov 12 12:05:00.792: INFO: Got endpoints: latency-svc-qlvps [728.07649ms]
Nov 12 12:05:00.809: INFO: Created: latency-svc-l6q22
Nov 12 12:05:00.844: INFO: Got endpoints: latency-svc-g2f7t [735.148477ms]
Nov 12 12:05:00.860: INFO: Created: latency-svc-7h2zc
Nov 12 12:05:00.893: INFO: Got endpoints: latency-svc-c9wvk [748.359357ms]
Nov 12 12:05:00.907: INFO: Created: latency-svc-49nmv
Nov 12 12:05:00.943: INFO: Got endpoints: latency-svc-4jhhb [751.133982ms]
Nov 12 12:05:00.959: INFO: Created: latency-svc-h482t
Nov 12 12:05:00.992: INFO: Got endpoints: latency-svc-pjbvc [748.474967ms]
Nov 12 12:05:01.006: INFO: Created: latency-svc-754xm
Nov 12 12:05:01.046: INFO: Got endpoints: latency-svc-7gckh [748.402916ms]
Nov 12 12:05:01.067: INFO: Created: latency-svc-w4kts
Nov 12 12:05:01.095: INFO: Got endpoints: latency-svc-r7npv [750.70476ms]
Nov 12 12:05:01.110: INFO: Created: latency-svc-zxg5d
Nov 12 12:05:01.145: INFO: Got endpoints: latency-svc-qd5hg [753.153821ms]
Nov 12 12:05:01.168: INFO: Created: latency-svc-l5lnk
Nov 12 12:05:01.194: INFO: Got endpoints: latency-svc-f2mg4 [750.751669ms]
Nov 12 12:05:01.223: INFO: Created: latency-svc-xs54k
Nov 12 12:05:01.245: INFO: Got endpoints: latency-svc-slkww [749.591926ms]
Nov 12 12:05:01.283: INFO: Created: latency-svc-b8zmx
Nov 12 12:05:01.313: INFO: Got endpoints: latency-svc-wl2h7 [771.794589ms]
Nov 12 12:05:01.347: INFO: Created: latency-svc-vzk2j
Nov 12 12:05:01.349: INFO: Got endpoints: latency-svc-ggz6v [756.068712ms]
Nov 12 12:05:01.388: INFO: Created: latency-svc-88szr
Nov 12 12:05:01.403: INFO: Got endpoints: latency-svc-7pbh2 [762.358297ms]
Nov 12 12:05:01.421: INFO: Created: latency-svc-phz2j
Nov 12 12:05:01.441: INFO: Got endpoints: latency-svc-lcdps [749.415579ms]
Nov 12 12:05:01.463: INFO: Created: latency-svc-hc8n6
Nov 12 12:05:01.495: INFO: Got endpoints: latency-svc-b9kg9 [750.956472ms]
Nov 12 12:05:01.514: INFO: Created: latency-svc-6n7lp
Nov 12 12:05:01.558: INFO: Got endpoints: latency-svc-l6q22 [766.065417ms]
Nov 12 12:05:01.590: INFO: Created: latency-svc-98bbq
Nov 12 12:05:01.595: INFO: Got endpoints: latency-svc-7h2zc [751.110107ms]
Nov 12 12:05:01.611: INFO: Created: latency-svc-g2n7l
Nov 12 12:05:01.644: INFO: Got endpoints: latency-svc-49nmv [750.855485ms]
Nov 12 12:05:01.671: INFO: Created: latency-svc-gsqzd
Nov 12 12:05:01.704: INFO: Got endpoints: latency-svc-h482t [761.128512ms]
Nov 12 12:05:01.731: INFO: Created: latency-svc-btp7v
Nov 12 12:05:01.757: INFO: Got endpoints: latency-svc-754xm [764.712558ms]
Nov 12 12:05:01.774: INFO: Created: latency-svc-ct4gc
Nov 12 12:05:01.796: INFO: Got endpoints: latency-svc-w4kts [750.108846ms]
Nov 12 12:05:01.813: INFO: Created: latency-svc-h6hkn
Nov 12 12:05:01.841: INFO: Got endpoints: latency-svc-zxg5d [745.516457ms]
Nov 12 12:05:01.859: INFO: Created: latency-svc-xgtss
Nov 12 12:05:01.893: INFO: Got endpoints: latency-svc-l5lnk [748.103924ms]
Nov 12 12:05:01.907: INFO: Created: latency-svc-r4298
Nov 12 12:05:01.945: INFO: Got endpoints: latency-svc-xs54k [750.244664ms]
Nov 12 12:05:01.967: INFO: Created: latency-svc-cdwls
Nov 12 12:05:01.994: INFO: Got endpoints: latency-svc-b8zmx [749.028062ms]
Nov 12 12:05:02.013: INFO: Created: latency-svc-72wjq
Nov 12 12:05:02.044: INFO: Got endpoints: latency-svc-vzk2j [730.893891ms]
Nov 12 12:05:02.063: INFO: Created: latency-svc-6z89l
Nov 12 12:05:02.094: INFO: Got endpoints: latency-svc-88szr [745.436884ms]
Nov 12 12:05:02.120: INFO: Created: latency-svc-gzm5w
Nov 12 12:05:02.144: INFO: Got endpoints: latency-svc-phz2j [740.23512ms]
Nov 12 12:05:02.160: INFO: Created: latency-svc-tb85w
Nov 12 12:05:02.194: INFO: Got endpoints: latency-svc-hc8n6 [752.71527ms]
Nov 12 12:05:02.211: INFO: Created: latency-svc-p6wxc
Nov 12 12:05:02.244: INFO: Got endpoints: latency-svc-6n7lp [748.728759ms]
Nov 12 12:05:02.263: INFO: Created: latency-svc-fp8rm
Nov 12 12:05:02.294: INFO: Got endpoints: latency-svc-98bbq [735.237538ms]
Nov 12 12:05:02.312: INFO: Created: latency-svc-xznpq
Nov 12 12:05:02.355: INFO: Got endpoints: latency-svc-g2n7l [760.107729ms]
Nov 12 12:05:02.370: INFO: Created: latency-svc-5wdrw
Nov 12 12:05:02.393: INFO: Got endpoints: latency-svc-gsqzd [748.755729ms]
Nov 12 12:05:02.415: INFO: Created: latency-svc-rztb4
Nov 12 12:05:02.445: INFO: Got endpoints: latency-svc-btp7v [740.863829ms]
Nov 12 12:05:02.462: INFO: Created: latency-svc-27n7g
Nov 12 12:05:02.495: INFO: Got endpoints: latency-svc-ct4gc [737.962103ms]
Nov 12 12:05:02.512: INFO: Created: latency-svc-7bc2p
Nov 12 12:05:02.544: INFO: Got endpoints: latency-svc-h6hkn [748.076789ms]
Nov 12 12:05:02.560: INFO: Created: latency-svc-mwxf5
Nov 12 12:05:02.595: INFO: Got endpoints: latency-svc-xgtss [754.279449ms]
Nov 12 12:05:02.612: INFO: Created: latency-svc-rw4wp
Nov 12 12:05:02.642: INFO: Got endpoints: latency-svc-r4298 [748.800133ms]
Nov 12 12:05:02.657: INFO: Created: latency-svc-r2gdg
Nov 12 12:05:02.694: INFO: Got endpoints: latency-svc-cdwls [748.733043ms]
Nov 12 12:05:02.716: INFO: Created: latency-svc-hfh9f
Nov 12 12:05:02.744: INFO: Got endpoints: latency-svc-72wjq [749.819292ms]
Nov 12 12:05:02.762: INFO: Created: latency-svc-gh4pq
Nov 12 12:05:02.793: INFO: Got endpoints: latency-svc-6z89l [748.462874ms]
Nov 12 12:05:02.806: INFO: Created: latency-svc-z2tcb
Nov 12 12:05:02.845: INFO: Got endpoints: latency-svc-gzm5w [750.490302ms]
Nov 12 12:05:02.860: INFO: Created: latency-svc-qkc4w
Nov 12 12:05:02.893: INFO: Got endpoints: latency-svc-tb85w [749.1057ms]
Nov 12 12:05:02.909: INFO: Created: latency-svc-q666z
Nov 12 12:05:02.942: INFO: Got endpoints: latency-svc-p6wxc [748.057416ms]
Nov 12 12:05:02.958: INFO: Created: latency-svc-jfqg7
Nov 12 12:05:02.992: INFO: Got endpoints: latency-svc-fp8rm [747.62317ms]
Nov 12 12:05:03.011: INFO: Created: latency-svc-28pxh
Nov 12 12:05:03.042: INFO: Got endpoints: latency-svc-xznpq [748.49362ms]
Nov 12 12:05:03.059: INFO: Created: latency-svc-qf8bq
Nov 12 12:05:03.093: INFO: Got endpoints: latency-svc-5wdrw [738.25584ms]
Nov 12 12:05:03.108: INFO: Created: latency-svc-gnvjr
Nov 12 12:05:03.147: INFO: Got endpoints: latency-svc-rztb4 [753.898598ms]
Nov 12 12:05:03.162: INFO: Created: latency-svc-ctwnl
Nov 12 12:05:03.196: INFO: Got endpoints: latency-svc-27n7g [751.269316ms]
Nov 12 12:05:03.226: INFO: Created: latency-svc-bwgsz
Nov 12 12:05:03.251: INFO: Got endpoints: latency-svc-7bc2p [755.67509ms]
Nov 12 12:05:03.275: INFO: Created: latency-svc-6sj44
Nov 12 12:05:03.301: INFO: Got endpoints: latency-svc-mwxf5 [756.555997ms]
Nov 12 12:05:03.349: INFO: Created: latency-svc-rmmbw
Nov 12 12:05:03.365: INFO: Got endpoints: latency-svc-rw4wp [769.370405ms]
Nov 12 12:05:03.398: INFO: Got endpoints: latency-svc-r2gdg [755.216685ms]
Nov 12 12:05:03.403: INFO: Created: latency-svc-dctbn
Nov 12 12:05:03.416: INFO: Created: latency-svc-wnj7j
Nov 12 12:05:03.445: INFO: Got endpoints: latency-svc-hfh9f [751.61105ms]
Nov 12 12:05:03.461: INFO: Created: latency-svc-q2vv2
Nov 12 12:05:03.494: INFO: Got endpoints: latency-svc-gh4pq [749.94607ms]
Nov 12 12:05:03.511: INFO: Created: latency-svc-4nhp8
Nov 12 12:05:03.542: INFO: Got endpoints: latency-svc-z2tcb [749.136838ms]
Nov 12 12:05:03.559: INFO: Created: latency-svc-zt4mq
Nov 12 12:05:03.597: INFO: Got endpoints: latency-svc-qkc4w [751.640728ms]
Nov 12 12:05:03.615: INFO: Created: latency-svc-mqxgb
Nov 12 12:05:03.645: INFO: Got endpoints: latency-svc-q666z [751.709341ms]
Nov 12 12:05:03.659: INFO: Created: latency-svc-bvxmx
Nov 12 12:05:03.691: INFO: Got endpoints: latency-svc-jfqg7 [748.994108ms]
Nov 12 12:05:03.705: INFO: Created: latency-svc-lrn69
Nov 12 12:05:03.744: INFO: Got endpoints: latency-svc-28pxh [752.491503ms]
Nov 12 12:05:03.760: INFO: Created: latency-svc-r2472
Nov 12 12:05:03.798: INFO: Got endpoints: latency-svc-qf8bq [755.498766ms]
Nov 12 12:05:03.813: INFO: Created: latency-svc-7c666
Nov 12 12:05:03.841: INFO: Got endpoints: latency-svc-gnvjr [747.425679ms]
Nov 12 12:05:03.856: INFO: Created: latency-svc-mzbg2
Nov 12 12:05:03.896: INFO: Got endpoints: latency-svc-ctwnl [748.628604ms]
Nov 12 12:05:03.919: INFO: Created: latency-svc-gg9pd
Nov 12 12:05:03.945: INFO: Got endpoints: latency-svc-bwgsz [748.481125ms]
Nov 12 12:05:03.961: INFO: Created: latency-svc-grqx4
Nov 12 12:05:03.994: INFO: Got endpoints: latency-svc-6sj44 [742.680587ms]
Nov 12 12:05:04.012: INFO: Created: latency-svc-v52j8
Nov 12 12:05:04.045: INFO: Got endpoints: latency-svc-rmmbw [743.778511ms]
Nov 12 12:05:04.094: INFO: Got endpoints: latency-svc-dctbn [728.951613ms]
Nov 12 12:05:04.141: INFO: Got endpoints: latency-svc-wnj7j [743.069843ms]
Nov 12 12:05:04.198: INFO: Got endpoints: latency-svc-q2vv2 [752.592222ms]
Nov 12 12:05:04.245: INFO: Got endpoints: latency-svc-4nhp8 [749.988751ms]
Nov 12 12:05:04.294: INFO: Got endpoints: latency-svc-zt4mq [752.004651ms]
Nov 12 12:05:04.344: INFO: Got endpoints: latency-svc-mqxgb [746.814971ms]
Nov 12 12:05:04.397: INFO: Got endpoints: latency-svc-bvxmx [752.192197ms]
Nov 12 12:05:04.440: INFO: Got endpoints: latency-svc-lrn69 [748.956503ms]
Nov 12 12:05:04.507: INFO: Got endpoints: latency-svc-r2472 [762.044164ms]
Nov 12 12:05:04.542: INFO: Got endpoints: latency-svc-7c666 [744.015996ms]
Nov 12 12:05:04.591: INFO: Got endpoints: latency-svc-mzbg2 [749.587953ms]
Nov 12 12:05:04.648: INFO: Got endpoints: latency-svc-gg9pd [752.401798ms]
Nov 12 12:05:04.695: INFO: Got endpoints: latency-svc-grqx4 [749.373002ms]
Nov 12 12:05:04.742: INFO: Got endpoints: latency-svc-v52j8 [748.020268ms]
Nov 12 12:05:04.742: INFO: Latencies: [41.254816ms 59.908758ms 65.245622ms 71.710982ms 88.979935ms 103.204118ms 122.159734ms 133.130783ms 140.57344ms 150.526818ms 158.989884ms 159.181132ms 175.964656ms 177.039636ms 182.546663ms 189.243902ms 191.772719ms 193.151327ms 194.81318ms 200.638822ms 205.619211ms 210.220902ms 210.345728ms 210.549114ms 212.990444ms 216.497408ms 217.039586ms 220.434298ms 221.392469ms 228.891756ms 231.733756ms 236.211511ms 241.745111ms 244.121094ms 261.26183ms 266.441559ms 271.877819ms 275.586114ms 285.496929ms 298.260446ms 309.707813ms 326.042318ms 328.684387ms 332.244166ms 349.954585ms 353.927205ms 370.434741ms 411.106ms 447.758925ms 449.852222ms 501.109484ms 543.077849ms 585.793788ms 636.772858ms 649.20577ms 679.038424ms 728.07649ms 728.951613ms 729.294ms 730.893891ms 735.148477ms 735.237538ms 737.962103ms 738.25584ms 740.23512ms 740.264854ms 740.863829ms 742.680587ms 743.069843ms 743.707665ms 743.778511ms 744.015996ms 744.715358ms 744.780662ms 745.271161ms 745.436884ms 745.516457ms 746.024646ms 746.277509ms 746.569495ms 746.726166ms 746.779905ms 746.814971ms 746.836626ms 747.300863ms 747.414699ms 747.425679ms 747.471904ms 747.476464ms 747.548567ms 747.62317ms 747.693454ms 747.828495ms 747.93082ms 747.953869ms 748.020268ms 748.057416ms 748.076789ms 748.103924ms 748.188027ms 748.255201ms 748.309636ms 748.359357ms 748.402916ms 748.434965ms 748.462874ms 748.474967ms 748.481125ms 748.49362ms 748.496428ms 748.52219ms 748.571797ms 748.628604ms 748.728759ms 748.733043ms 748.755729ms 748.800133ms 748.915594ms 748.940668ms 748.956503ms 748.994108ms 749.028062ms 749.1057ms 749.136838ms 749.162912ms 749.373002ms 749.415579ms 749.533583ms 749.587953ms 749.591926ms 749.819292ms 749.883745ms 749.918415ms 749.94607ms 749.988751ms 750.108846ms 750.123823ms 750.233069ms 750.244664ms 750.340673ms 750.490302ms 750.63978ms 750.70476ms 750.751669ms 750.855485ms 750.94333ms 750.956472ms 751.110107ms 751.133982ms 751.248819ms 751.269316ms 751.295006ms 751.476285ms 751.507618ms 751.608225ms 751.61105ms 751.640728ms 751.709341ms 751.731827ms 751.76478ms 752.004651ms 752.060102ms 752.106055ms 752.192197ms 752.337848ms 752.401798ms 752.491503ms 752.539607ms 752.592222ms 752.711931ms 752.71527ms 753.153821ms 753.326891ms 753.898598ms 754.202697ms 754.279449ms 754.691867ms 754.717309ms 755.216685ms 755.498766ms 755.67509ms 755.896684ms 756.068712ms 756.103105ms 756.348187ms 756.380367ms 756.555997ms 758.468918ms 760.107729ms 761.128512ms 762.044164ms 762.358297ms 763.258051ms 764.712558ms 765.539462ms 766.065417ms 769.370405ms 770.560333ms 771.794589ms 828.721317ms]
Nov 12 12:05:04.742: INFO: 50 %ile: 748.255201ms
Nov 12 12:05:04.742: INFO: 90 %ile: 755.67509ms
Nov 12 12:05:04.742: INFO: 99 %ile: 771.794589ms
Nov 12 12:05:04.742: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Nov 12 12:05:04.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2747" for this suite. 11/12/22 12:05:04.75
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":26,"skipped":600,"failed":0}
------------------------------
• [SLOW TEST] [10.791 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:04:53.969
    Nov 12 12:04:53.969: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename svc-latency 11/12/22 12:04:53.97
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:04:53.991
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:04:53.995
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Nov 12 12:04:53.998: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-2747 11/12/22 12:04:53.999
    I1112 12:04:54.016175      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2747, replica count: 1
    I1112 12:04:55.066953      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1112 12:04:56.067139      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 12:04:56.183: INFO: Created: latency-svc-8jj6l
    Nov 12 12:04:56.198: INFO: Got endpoints: latency-svc-8jj6l [29.866958ms]
    Nov 12 12:04:56.229: INFO: Created: latency-svc-nkw66
    Nov 12 12:04:56.239: INFO: Got endpoints: latency-svc-nkw66 [41.254816ms]
    Nov 12 12:04:56.246: INFO: Created: latency-svc-z46wn
    Nov 12 12:04:56.258: INFO: Got endpoints: latency-svc-z46wn [59.908758ms]
    Nov 12 12:04:56.264: INFO: Created: latency-svc-s5gzz
    Nov 12 12:04:56.271: INFO: Got endpoints: latency-svc-s5gzz [71.710982ms]
    Nov 12 12:04:56.275: INFO: Created: latency-svc-xwp9q
    Nov 12 12:04:56.288: INFO: Got endpoints: latency-svc-xwp9q [88.979935ms]
    Nov 12 12:04:56.292: INFO: Created: latency-svc-rtdm2
    Nov 12 12:04:56.302: INFO: Got endpoints: latency-svc-rtdm2 [103.204118ms]
    Nov 12 12:04:56.308: INFO: Created: latency-svc-kqzw9
    Nov 12 12:04:56.317: INFO: Created: latency-svc-h8jkn
    Nov 12 12:04:56.321: INFO: Got endpoints: latency-svc-kqzw9 [122.159734ms]
    Nov 12 12:04:56.332: INFO: Got endpoints: latency-svc-h8jkn [133.130783ms]
    Nov 12 12:04:56.332: INFO: Created: latency-svc-jbldx
    Nov 12 12:04:56.340: INFO: Got endpoints: latency-svc-jbldx [140.57344ms]
    Nov 12 12:04:56.345: INFO: Created: latency-svc-47m4h
    Nov 12 12:04:56.350: INFO: Got endpoints: latency-svc-47m4h [150.526818ms]
    Nov 12 12:04:56.350: INFO: Created: latency-svc-tpzg6
    Nov 12 12:04:56.358: INFO: Got endpoints: latency-svc-tpzg6 [158.989884ms]
    Nov 12 12:04:56.366: INFO: Created: latency-svc-txq8s
    Nov 12 12:04:56.376: INFO: Got endpoints: latency-svc-txq8s [177.039636ms]
    Nov 12 12:04:56.379: INFO: Created: latency-svc-spnwp
    Nov 12 12:04:56.388: INFO: Got endpoints: latency-svc-spnwp [189.243902ms]
    Nov 12 12:04:56.393: INFO: Created: latency-svc-tsggw
    Nov 12 12:04:56.399: INFO: Got endpoints: latency-svc-tsggw [200.638822ms]
    Nov 12 12:04:56.402: INFO: Created: latency-svc-szwt4
    Nov 12 12:04:56.409: INFO: Got endpoints: latency-svc-szwt4 [210.220902ms]
    Nov 12 12:04:56.412: INFO: Created: latency-svc-tjgkv
    Nov 12 12:04:56.419: INFO: Got endpoints: latency-svc-tjgkv [220.434298ms]
    Nov 12 12:04:56.523: INFO: Created: latency-svc-64dzr
    Nov 12 12:04:56.527: INFO: Created: latency-svc-rpd6z
    Nov 12 12:04:56.527: INFO: Created: latency-svc-bt5kk
    Nov 12 12:04:56.527: INFO: Created: latency-svc-cn2qv
    Nov 12 12:04:56.529: INFO: Created: latency-svc-2725n
    Nov 12 12:04:56.530: INFO: Created: latency-svc-tpq89
    Nov 12 12:04:56.530: INFO: Created: latency-svc-frvj5
    Nov 12 12:04:56.530: INFO: Created: latency-svc-dmnch
    Nov 12 12:04:56.530: INFO: Created: latency-svc-x5l59
    Nov 12 12:04:56.535: INFO: Created: latency-svc-mzxqz
    Nov 12 12:04:56.535: INFO: Created: latency-svc-4nntz
    Nov 12 12:04:56.535: INFO: Created: latency-svc-j5lzb
    Nov 12 12:04:56.537: INFO: Created: latency-svc-t6gjq
    Nov 12 12:04:56.539: INFO: Created: latency-svc-xlbmm
    Nov 12 12:04:56.539: INFO: Created: latency-svc-htjf9
    Nov 12 12:04:56.556: INFO: Got endpoints: latency-svc-cn2qv [298.260446ms]
    Nov 12 12:04:56.563: INFO: Got endpoints: latency-svc-64dzr [241.745111ms]
    Nov 12 12:04:56.568: INFO: Got endpoints: latency-svc-rpd6z [266.441559ms]
    Nov 12 12:04:56.569: INFO: Got endpoints: latency-svc-bt5kk [228.891756ms]
    Nov 12 12:04:56.572: INFO: Got endpoints: latency-svc-t6gjq [332.244166ms]
    Nov 12 12:04:56.573: INFO: Got endpoints: latency-svc-j5lzb [285.496929ms]
    Nov 12 12:04:56.582: INFO: Got endpoints: latency-svc-frvj5 [205.619211ms]
    Nov 12 12:04:56.586: INFO: Created: latency-svc-khr2s
    Nov 12 12:04:56.593: INFO: Got endpoints: latency-svc-htjf9 [261.26183ms]
    Nov 12 12:04:56.597: INFO: Got endpoints: latency-svc-2725n [326.042318ms]
    Nov 12 12:04:56.599: INFO: Got endpoints: latency-svc-xlbmm [210.345728ms]
    Nov 12 12:04:56.602: INFO: Got endpoints: latency-svc-tpq89 [244.121094ms]
    Nov 12 12:04:56.613: INFO: Got endpoints: latency-svc-x5l59 [193.151327ms]
    Nov 12 12:04:56.616: INFO: Got endpoints: latency-svc-dmnch [216.497408ms]
    Nov 12 12:04:56.622: INFO: Got endpoints: latency-svc-khr2s [65.245622ms]
    Nov 12 12:04:56.622: INFO: Got endpoints: latency-svc-4nntz [212.990444ms]
    Nov 12 12:04:56.623: INFO: Got endpoints: latency-svc-mzxqz [271.877819ms]
    Nov 12 12:04:56.745: INFO: Created: latency-svc-k9z86
    Nov 12 12:04:56.754: INFO: Created: latency-svc-qg94f
    Nov 12 12:04:56.762: INFO: Created: latency-svc-p8272
    Nov 12 12:04:56.777: INFO: Created: latency-svc-cxz2t
    Nov 12 12:04:56.779: INFO: Created: latency-svc-49hld
    Nov 12 12:04:56.780: INFO: Created: latency-svc-ffdft
    Nov 12 12:04:56.780: INFO: Created: latency-svc-24sfp
    Nov 12 12:04:56.781: INFO: Created: latency-svc-6ttkg
    Nov 12 12:04:56.781: INFO: Created: latency-svc-4t4kx
    Nov 12 12:04:56.781: INFO: Created: latency-svc-gmvmf
    Nov 12 12:04:56.781: INFO: Created: latency-svc-gllkh
    Nov 12 12:04:56.781: INFO: Created: latency-svc-fg4jg
    Nov 12 12:04:56.782: INFO: Created: latency-svc-zzgtx
    Nov 12 12:04:56.780: INFO: Created: latency-svc-fs59z
    Nov 12 12:04:56.782: INFO: Got endpoints: latency-svc-k9z86 [159.181132ms]
    Nov 12 12:04:56.782: INFO: Created: latency-svc-8l9bq
    Nov 12 12:04:56.785: INFO: Got endpoints: latency-svc-qg94f [182.546663ms]
    Nov 12 12:04:56.790: INFO: Got endpoints: latency-svc-4t4kx [221.392469ms]
    Nov 12 12:04:56.792: INFO: Got endpoints: latency-svc-cxz2t [175.964656ms]
    Nov 12 12:04:56.792: INFO: Got endpoints: latency-svc-fg4jg [210.549114ms]
    Nov 12 12:04:56.801: INFO: Got endpoints: latency-svc-fs59z [231.733756ms]
    Nov 12 12:04:56.807: INFO: Got endpoints: latency-svc-ffdft [194.81318ms]
    Nov 12 12:04:56.810: INFO: Got endpoints: latency-svc-zzgtx [236.211511ms]
    Nov 12 12:04:56.814: INFO: Got endpoints: latency-svc-p8272 [191.772719ms]
    Nov 12 12:04:56.814: INFO: Got endpoints: latency-svc-6ttkg [217.039586ms]
    Nov 12 12:04:56.817: INFO: Created: latency-svc-6rk6l
    Nov 12 12:04:56.835: INFO: Created: latency-svc-jsljf
    Nov 12 12:04:56.840: INFO: Created: latency-svc-m6km2
    Nov 12 12:04:56.845: INFO: Created: latency-svc-cp64s
    Nov 12 12:04:56.847: INFO: Got endpoints: latency-svc-gllkh [275.586114ms]
    Nov 12 12:04:56.858: INFO: Created: latency-svc-s9txf
    Nov 12 12:04:56.867: INFO: Created: latency-svc-dt9hn
    Nov 12 12:04:56.879: INFO: Created: latency-svc-wd49w
    Nov 12 12:04:56.892: INFO: Got endpoints: latency-svc-8l9bq [328.684387ms]
    Nov 12 12:04:56.899: INFO: Created: latency-svc-gvwvw
    Nov 12 12:04:56.906: INFO: Created: latency-svc-6lxbp
    Nov 12 12:04:56.936: INFO: Created: latency-svc-brqb9
    Nov 12 12:04:56.940: INFO: Created: latency-svc-59k7f
    Nov 12 12:04:56.940: INFO: Created: latency-svc-lfm7f
    Nov 12 12:04:56.947: INFO: Got endpoints: latency-svc-gmvmf [353.927205ms]
    Nov 12 12:04:56.964: INFO: Created: latency-svc-7nnc4
    Nov 12 12:04:56.993: INFO: Got endpoints: latency-svc-24sfp [370.434741ms]
    Nov 12 12:04:57.008: INFO: Created: latency-svc-25hxj
    Nov 12 12:04:57.046: INFO: Got endpoints: latency-svc-49hld [447.758925ms]
    Nov 12 12:04:57.064: INFO: Created: latency-svc-w6l7s
    Nov 12 12:04:57.092: INFO: Got endpoints: latency-svc-6rk6l [309.707813ms]
    Nov 12 12:04:57.107: INFO: Created: latency-svc-tzjrl
    Nov 12 12:04:57.140: INFO: Got endpoints: latency-svc-jsljf [349.954585ms]
    Nov 12 12:04:57.155: INFO: Created: latency-svc-7cx8q
    Nov 12 12:04:57.196: INFO: Got endpoints: latency-svc-m6km2 [411.106ms]
    Nov 12 12:04:57.217: INFO: Created: latency-svc-tg2bk
    Nov 12 12:04:57.242: INFO: Got endpoints: latency-svc-cp64s [449.852222ms]
    Nov 12 12:04:57.258: INFO: Created: latency-svc-lnc4j
    Nov 12 12:04:57.293: INFO: Got endpoints: latency-svc-s9txf [501.109484ms]
    Nov 12 12:04:57.308: INFO: Created: latency-svc-dkmgg
    Nov 12 12:04:57.344: INFO: Got endpoints: latency-svc-dt9hn [543.077849ms]
    Nov 12 12:04:57.359: INFO: Created: latency-svc-gztl5
    Nov 12 12:04:57.396: INFO: Got endpoints: latency-svc-wd49w [585.793788ms]
    Nov 12 12:04:57.409: INFO: Created: latency-svc-zm4pn
    Nov 12 12:04:57.444: INFO: Got endpoints: latency-svc-gvwvw [636.772858ms]
    Nov 12 12:04:57.459: INFO: Created: latency-svc-fj2hq
    Nov 12 12:04:57.493: INFO: Got endpoints: latency-svc-6lxbp [679.038424ms]
    Nov 12 12:04:57.511: INFO: Created: latency-svc-wl945
    Nov 12 12:04:57.541: INFO: Got endpoints: latency-svc-59k7f [649.20577ms]
    Nov 12 12:04:57.555: INFO: Created: latency-svc-gv2vq
    Nov 12 12:04:57.592: INFO: Got endpoints: latency-svc-brqb9 [744.715358ms]
    Nov 12 12:04:57.608: INFO: Created: latency-svc-jr2cp
    Nov 12 12:04:57.643: INFO: Got endpoints: latency-svc-lfm7f [828.721317ms]
    Nov 12 12:04:57.656: INFO: Created: latency-svc-hzxtl
    Nov 12 12:04:57.691: INFO: Got endpoints: latency-svc-7nnc4 [743.707665ms]
    Nov 12 12:04:57.704: INFO: Created: latency-svc-rz876
    Nov 12 12:04:57.745: INFO: Got endpoints: latency-svc-25hxj [751.731827ms]
    Nov 12 12:04:57.764: INFO: Created: latency-svc-vswtw
    Nov 12 12:04:57.793: INFO: Got endpoints: latency-svc-w6l7s [746.836626ms]
    Nov 12 12:04:57.810: INFO: Created: latency-svc-lz4dh
    Nov 12 12:04:57.840: INFO: Got endpoints: latency-svc-tzjrl [748.255201ms]
    Nov 12 12:04:57.853: INFO: Created: latency-svc-6s8n5
    Nov 12 12:04:57.895: INFO: Got endpoints: latency-svc-7cx8q [754.691867ms]
    Nov 12 12:04:57.909: INFO: Created: latency-svc-fhnwl
    Nov 12 12:04:57.945: INFO: Got endpoints: latency-svc-tg2bk [748.52219ms]
    Nov 12 12:04:57.962: INFO: Created: latency-svc-r7bxg
    Nov 12 12:04:57.994: INFO: Got endpoints: latency-svc-lnc4j [751.507618ms]
    Nov 12 12:04:58.007: INFO: Created: latency-svc-fm2vq
    Nov 12 12:04:58.044: INFO: Got endpoints: latency-svc-dkmgg [750.63978ms]
    Nov 12 12:04:58.066: INFO: Created: latency-svc-4jxhx
    Nov 12 12:04:58.092: INFO: Got endpoints: latency-svc-gztl5 [747.414699ms]
    Nov 12 12:04:58.108: INFO: Created: latency-svc-jhsvt
    Nov 12 12:04:58.141: INFO: Got endpoints: latency-svc-zm4pn [745.271161ms]
    Nov 12 12:04:58.158: INFO: Created: latency-svc-xbxrh
    Nov 12 12:04:58.215: INFO: Got endpoints: latency-svc-fj2hq [770.560333ms]
    Nov 12 12:04:58.231: INFO: Created: latency-svc-gsl6q
    Nov 12 12:04:58.243: INFO: Got endpoints: latency-svc-wl945 [749.918415ms]
    Nov 12 12:04:58.259: INFO: Created: latency-svc-pqkd4
    Nov 12 12:04:58.291: INFO: Got endpoints: latency-svc-gv2vq [750.123823ms]
    Nov 12 12:04:58.305: INFO: Created: latency-svc-4j7v4
    Nov 12 12:04:58.345: INFO: Got endpoints: latency-svc-jr2cp [752.106055ms]
    Nov 12 12:04:58.359: INFO: Created: latency-svc-m4bvw
    Nov 12 12:04:58.391: INFO: Got endpoints: latency-svc-hzxtl [747.93082ms]
    Nov 12 12:04:58.411: INFO: Created: latency-svc-ljks5
    Nov 12 12:04:58.442: INFO: Got endpoints: latency-svc-rz876 [749.533583ms]
    Nov 12 12:04:58.461: INFO: Created: latency-svc-2xvd2
    Nov 12 12:04:58.492: INFO: Got endpoints: latency-svc-vswtw [746.779905ms]
    Nov 12 12:04:58.509: INFO: Created: latency-svc-kzfgg
    Nov 12 12:04:58.543: INFO: Got endpoints: latency-svc-lz4dh [748.940668ms]
    Nov 12 12:04:58.559: INFO: Created: latency-svc-k727g
    Nov 12 12:04:58.592: INFO: Got endpoints: latency-svc-6s8n5 [752.337848ms]
    Nov 12 12:04:58.610: INFO: Created: latency-svc-dpp8s
    Nov 12 12:04:58.642: INFO: Got endpoints: latency-svc-fhnwl [746.569495ms]
    Nov 12 12:04:58.660: INFO: Created: latency-svc-vbb2s
    Nov 12 12:04:58.695: INFO: Got endpoints: latency-svc-r7bxg [750.340673ms]
    Nov 12 12:04:58.709: INFO: Created: latency-svc-nkr7h
    Nov 12 12:04:58.743: INFO: Got endpoints: latency-svc-fm2vq [748.496428ms]
    Nov 12 12:04:58.756: INFO: Created: latency-svc-rl9lx
    Nov 12 12:04:58.793: INFO: Got endpoints: latency-svc-4jxhx [748.571797ms]
    Nov 12 12:04:58.809: INFO: Created: latency-svc-c7t2k
    Nov 12 12:04:58.844: INFO: Got endpoints: latency-svc-jhsvt [752.060102ms]
    Nov 12 12:04:58.863: INFO: Created: latency-svc-gvqjp
    Nov 12 12:04:58.893: INFO: Got endpoints: latency-svc-xbxrh [751.476285ms]
    Nov 12 12:04:58.910: INFO: Created: latency-svc-z86kv
    Nov 12 12:04:58.944: INFO: Got endpoints: latency-svc-gsl6q [729.294ms]
    Nov 12 12:04:58.962: INFO: Created: latency-svc-ckl5h
    Nov 12 12:04:58.991: INFO: Got endpoints: latency-svc-pqkd4 [747.476464ms]
    Nov 12 12:04:59.012: INFO: Created: latency-svc-sf7pl
    Nov 12 12:04:59.047: INFO: Got endpoints: latency-svc-4j7v4 [755.896684ms]
    Nov 12 12:04:59.070: INFO: Created: latency-svc-qzhxf
    Nov 12 12:04:59.091: INFO: Got endpoints: latency-svc-m4bvw [746.726166ms]
    Nov 12 12:04:59.106: INFO: Created: latency-svc-9cpcd
    Nov 12 12:04:59.143: INFO: Got endpoints: latency-svc-ljks5 [751.248819ms]
    Nov 12 12:04:59.158: INFO: Created: latency-svc-nd45d
    Nov 12 12:04:59.196: INFO: Got endpoints: latency-svc-2xvd2 [754.202697ms]
    Nov 12 12:04:59.218: INFO: Created: latency-svc-nhvjz
    Nov 12 12:04:59.251: INFO: Got endpoints: latency-svc-kzfgg [758.468918ms]
    Nov 12 12:04:59.290: INFO: Created: latency-svc-7qgmj
    Nov 12 12:04:59.299: INFO: Got endpoints: latency-svc-k727g [756.103105ms]
    Nov 12 12:04:59.315: INFO: Created: latency-svc-ffk44
    Nov 12 12:04:59.345: INFO: Got endpoints: latency-svc-dpp8s [752.539607ms]
    Nov 12 12:04:59.360: INFO: Created: latency-svc-gft5m
    Nov 12 12:04:59.391: INFO: Got endpoints: latency-svc-vbb2s [748.915594ms]
    Nov 12 12:04:59.406: INFO: Created: latency-svc-rfgf6
    Nov 12 12:04:59.443: INFO: Got endpoints: latency-svc-nkr7h [747.548567ms]
    Nov 12 12:04:59.462: INFO: Created: latency-svc-ddp9t
    Nov 12 12:04:59.494: INFO: Got endpoints: latency-svc-rl9lx [751.608225ms]
    Nov 12 12:04:59.510: INFO: Created: latency-svc-zrbmc
    Nov 12 12:04:59.541: INFO: Got endpoints: latency-svc-c7t2k [747.693454ms]
    Nov 12 12:04:59.556: INFO: Created: latency-svc-5h84q
    Nov 12 12:04:59.593: INFO: Got endpoints: latency-svc-gvqjp [748.309636ms]
    Nov 12 12:04:59.605: INFO: Created: latency-svc-xpr8x
    Nov 12 12:04:59.644: INFO: Got endpoints: latency-svc-z86kv [751.295006ms]
    Nov 12 12:04:59.658: INFO: Created: latency-svc-9x95g
    Nov 12 12:04:59.694: INFO: Got endpoints: latency-svc-ckl5h [749.162912ms]
    Nov 12 12:04:59.707: INFO: Created: latency-svc-kqlv8
    Nov 12 12:04:59.747: INFO: Got endpoints: latency-svc-sf7pl [756.348187ms]
    Nov 12 12:04:59.766: INFO: Created: latency-svc-9xf8q
    Nov 12 12:04:59.793: INFO: Got endpoints: latency-svc-qzhxf [746.024646ms]
    Nov 12 12:04:59.807: INFO: Created: latency-svc-m2bvl
    Nov 12 12:04:59.846: INFO: Got endpoints: latency-svc-9cpcd [754.717309ms]
    Nov 12 12:04:59.870: INFO: Created: latency-svc-lvhmn
    Nov 12 12:04:59.894: INFO: Got endpoints: latency-svc-nd45d [750.94333ms]
    Nov 12 12:04:59.910: INFO: Created: latency-svc-4svt5
    Nov 12 12:04:59.947: INFO: Got endpoints: latency-svc-nhvjz [750.233069ms]
    Nov 12 12:04:59.963: INFO: Created: latency-svc-8jlpg
    Nov 12 12:04:59.992: INFO: Got endpoints: latency-svc-7qgmj [740.264854ms]
    Nov 12 12:05:00.009: INFO: Created: latency-svc-4hhmx
    Nov 12 12:05:00.064: INFO: Got endpoints: latency-svc-ffk44 [765.539462ms]
    Nov 12 12:05:00.081: INFO: Created: latency-svc-qlvps
    Nov 12 12:05:00.108: INFO: Got endpoints: latency-svc-gft5m [763.258051ms]
    Nov 12 12:05:00.124: INFO: Created: latency-svc-g2f7t
    Nov 12 12:05:00.145: INFO: Got endpoints: latency-svc-rfgf6 [753.326891ms]
    Nov 12 12:05:00.161: INFO: Created: latency-svc-c9wvk
    Nov 12 12:05:00.191: INFO: Got endpoints: latency-svc-ddp9t [748.188027ms]
    Nov 12 12:05:00.215: INFO: Created: latency-svc-4jhhb
    Nov 12 12:05:00.243: INFO: Got endpoints: latency-svc-zrbmc [748.434965ms]
    Nov 12 12:05:00.261: INFO: Created: latency-svc-pjbvc
    Nov 12 12:05:00.297: INFO: Got endpoints: latency-svc-5h84q [756.380367ms]
    Nov 12 12:05:00.316: INFO: Created: latency-svc-7gckh
    Nov 12 12:05:00.344: INFO: Got endpoints: latency-svc-xpr8x [751.76478ms]
    Nov 12 12:05:00.360: INFO: Created: latency-svc-r7npv
    Nov 12 12:05:00.392: INFO: Got endpoints: latency-svc-9x95g [747.828495ms]
    Nov 12 12:05:00.408: INFO: Created: latency-svc-qd5hg
    Nov 12 12:05:00.443: INFO: Got endpoints: latency-svc-kqlv8 [749.883745ms]
    Nov 12 12:05:00.457: INFO: Created: latency-svc-f2mg4
    Nov 12 12:05:00.495: INFO: Got endpoints: latency-svc-9xf8q [747.471904ms]
    Nov 12 12:05:00.514: INFO: Created: latency-svc-slkww
    Nov 12 12:05:00.541: INFO: Got endpoints: latency-svc-m2bvl [747.953869ms]
    Nov 12 12:05:00.559: INFO: Created: latency-svc-wl2h7
    Nov 12 12:05:00.593: INFO: Got endpoints: latency-svc-lvhmn [746.277509ms]
    Nov 12 12:05:00.610: INFO: Created: latency-svc-ggz6v
    Nov 12 12:05:00.641: INFO: Got endpoints: latency-svc-4svt5 [747.300863ms]
    Nov 12 12:05:00.658: INFO: Created: latency-svc-7pbh2
    Nov 12 12:05:00.692: INFO: Got endpoints: latency-svc-8jlpg [744.780662ms]
    Nov 12 12:05:00.706: INFO: Created: latency-svc-lcdps
    Nov 12 12:05:00.744: INFO: Got endpoints: latency-svc-4hhmx [752.711931ms]
    Nov 12 12:05:00.758: INFO: Created: latency-svc-b9kg9
    Nov 12 12:05:00.792: INFO: Got endpoints: latency-svc-qlvps [728.07649ms]
    Nov 12 12:05:00.809: INFO: Created: latency-svc-l6q22
    Nov 12 12:05:00.844: INFO: Got endpoints: latency-svc-g2f7t [735.148477ms]
    Nov 12 12:05:00.860: INFO: Created: latency-svc-7h2zc
    Nov 12 12:05:00.893: INFO: Got endpoints: latency-svc-c9wvk [748.359357ms]
    Nov 12 12:05:00.907: INFO: Created: latency-svc-49nmv
    Nov 12 12:05:00.943: INFO: Got endpoints: latency-svc-4jhhb [751.133982ms]
    Nov 12 12:05:00.959: INFO: Created: latency-svc-h482t
    Nov 12 12:05:00.992: INFO: Got endpoints: latency-svc-pjbvc [748.474967ms]
    Nov 12 12:05:01.006: INFO: Created: latency-svc-754xm
    Nov 12 12:05:01.046: INFO: Got endpoints: latency-svc-7gckh [748.402916ms]
    Nov 12 12:05:01.067: INFO: Created: latency-svc-w4kts
    Nov 12 12:05:01.095: INFO: Got endpoints: latency-svc-r7npv [750.70476ms]
    Nov 12 12:05:01.110: INFO: Created: latency-svc-zxg5d
    Nov 12 12:05:01.145: INFO: Got endpoints: latency-svc-qd5hg [753.153821ms]
    Nov 12 12:05:01.168: INFO: Created: latency-svc-l5lnk
    Nov 12 12:05:01.194: INFO: Got endpoints: latency-svc-f2mg4 [750.751669ms]
    Nov 12 12:05:01.223: INFO: Created: latency-svc-xs54k
    Nov 12 12:05:01.245: INFO: Got endpoints: latency-svc-slkww [749.591926ms]
    Nov 12 12:05:01.283: INFO: Created: latency-svc-b8zmx
    Nov 12 12:05:01.313: INFO: Got endpoints: latency-svc-wl2h7 [771.794589ms]
    Nov 12 12:05:01.347: INFO: Created: latency-svc-vzk2j
    Nov 12 12:05:01.349: INFO: Got endpoints: latency-svc-ggz6v [756.068712ms]
    Nov 12 12:05:01.388: INFO: Created: latency-svc-88szr
    Nov 12 12:05:01.403: INFO: Got endpoints: latency-svc-7pbh2 [762.358297ms]
    Nov 12 12:05:01.421: INFO: Created: latency-svc-phz2j
    Nov 12 12:05:01.441: INFO: Got endpoints: latency-svc-lcdps [749.415579ms]
    Nov 12 12:05:01.463: INFO: Created: latency-svc-hc8n6
    Nov 12 12:05:01.495: INFO: Got endpoints: latency-svc-b9kg9 [750.956472ms]
    Nov 12 12:05:01.514: INFO: Created: latency-svc-6n7lp
    Nov 12 12:05:01.558: INFO: Got endpoints: latency-svc-l6q22 [766.065417ms]
    Nov 12 12:05:01.590: INFO: Created: latency-svc-98bbq
    Nov 12 12:05:01.595: INFO: Got endpoints: latency-svc-7h2zc [751.110107ms]
    Nov 12 12:05:01.611: INFO: Created: latency-svc-g2n7l
    Nov 12 12:05:01.644: INFO: Got endpoints: latency-svc-49nmv [750.855485ms]
    Nov 12 12:05:01.671: INFO: Created: latency-svc-gsqzd
    Nov 12 12:05:01.704: INFO: Got endpoints: latency-svc-h482t [761.128512ms]
    Nov 12 12:05:01.731: INFO: Created: latency-svc-btp7v
    Nov 12 12:05:01.757: INFO: Got endpoints: latency-svc-754xm [764.712558ms]
    Nov 12 12:05:01.774: INFO: Created: latency-svc-ct4gc
    Nov 12 12:05:01.796: INFO: Got endpoints: latency-svc-w4kts [750.108846ms]
    Nov 12 12:05:01.813: INFO: Created: latency-svc-h6hkn
    Nov 12 12:05:01.841: INFO: Got endpoints: latency-svc-zxg5d [745.516457ms]
    Nov 12 12:05:01.859: INFO: Created: latency-svc-xgtss
    Nov 12 12:05:01.893: INFO: Got endpoints: latency-svc-l5lnk [748.103924ms]
    Nov 12 12:05:01.907: INFO: Created: latency-svc-r4298
    Nov 12 12:05:01.945: INFO: Got endpoints: latency-svc-xs54k [750.244664ms]
    Nov 12 12:05:01.967: INFO: Created: latency-svc-cdwls
    Nov 12 12:05:01.994: INFO: Got endpoints: latency-svc-b8zmx [749.028062ms]
    Nov 12 12:05:02.013: INFO: Created: latency-svc-72wjq
    Nov 12 12:05:02.044: INFO: Got endpoints: latency-svc-vzk2j [730.893891ms]
    Nov 12 12:05:02.063: INFO: Created: latency-svc-6z89l
    Nov 12 12:05:02.094: INFO: Got endpoints: latency-svc-88szr [745.436884ms]
    Nov 12 12:05:02.120: INFO: Created: latency-svc-gzm5w
    Nov 12 12:05:02.144: INFO: Got endpoints: latency-svc-phz2j [740.23512ms]
    Nov 12 12:05:02.160: INFO: Created: latency-svc-tb85w
    Nov 12 12:05:02.194: INFO: Got endpoints: latency-svc-hc8n6 [752.71527ms]
    Nov 12 12:05:02.211: INFO: Created: latency-svc-p6wxc
    Nov 12 12:05:02.244: INFO: Got endpoints: latency-svc-6n7lp [748.728759ms]
    Nov 12 12:05:02.263: INFO: Created: latency-svc-fp8rm
    Nov 12 12:05:02.294: INFO: Got endpoints: latency-svc-98bbq [735.237538ms]
    Nov 12 12:05:02.312: INFO: Created: latency-svc-xznpq
    Nov 12 12:05:02.355: INFO: Got endpoints: latency-svc-g2n7l [760.107729ms]
    Nov 12 12:05:02.370: INFO: Created: latency-svc-5wdrw
    Nov 12 12:05:02.393: INFO: Got endpoints: latency-svc-gsqzd [748.755729ms]
    Nov 12 12:05:02.415: INFO: Created: latency-svc-rztb4
    Nov 12 12:05:02.445: INFO: Got endpoints: latency-svc-btp7v [740.863829ms]
    Nov 12 12:05:02.462: INFO: Created: latency-svc-27n7g
    Nov 12 12:05:02.495: INFO: Got endpoints: latency-svc-ct4gc [737.962103ms]
    Nov 12 12:05:02.512: INFO: Created: latency-svc-7bc2p
    Nov 12 12:05:02.544: INFO: Got endpoints: latency-svc-h6hkn [748.076789ms]
    Nov 12 12:05:02.560: INFO: Created: latency-svc-mwxf5
    Nov 12 12:05:02.595: INFO: Got endpoints: latency-svc-xgtss [754.279449ms]
    Nov 12 12:05:02.612: INFO: Created: latency-svc-rw4wp
    Nov 12 12:05:02.642: INFO: Got endpoints: latency-svc-r4298 [748.800133ms]
    Nov 12 12:05:02.657: INFO: Created: latency-svc-r2gdg
    Nov 12 12:05:02.694: INFO: Got endpoints: latency-svc-cdwls [748.733043ms]
    Nov 12 12:05:02.716: INFO: Created: latency-svc-hfh9f
    Nov 12 12:05:02.744: INFO: Got endpoints: latency-svc-72wjq [749.819292ms]
    Nov 12 12:05:02.762: INFO: Created: latency-svc-gh4pq
    Nov 12 12:05:02.793: INFO: Got endpoints: latency-svc-6z89l [748.462874ms]
    Nov 12 12:05:02.806: INFO: Created: latency-svc-z2tcb
    Nov 12 12:05:02.845: INFO: Got endpoints: latency-svc-gzm5w [750.490302ms]
    Nov 12 12:05:02.860: INFO: Created: latency-svc-qkc4w
    Nov 12 12:05:02.893: INFO: Got endpoints: latency-svc-tb85w [749.1057ms]
    Nov 12 12:05:02.909: INFO: Created: latency-svc-q666z
    Nov 12 12:05:02.942: INFO: Got endpoints: latency-svc-p6wxc [748.057416ms]
    Nov 12 12:05:02.958: INFO: Created: latency-svc-jfqg7
    Nov 12 12:05:02.992: INFO: Got endpoints: latency-svc-fp8rm [747.62317ms]
    Nov 12 12:05:03.011: INFO: Created: latency-svc-28pxh
    Nov 12 12:05:03.042: INFO: Got endpoints: latency-svc-xznpq [748.49362ms]
    Nov 12 12:05:03.059: INFO: Created: latency-svc-qf8bq
    Nov 12 12:05:03.093: INFO: Got endpoints: latency-svc-5wdrw [738.25584ms]
    Nov 12 12:05:03.108: INFO: Created: latency-svc-gnvjr
    Nov 12 12:05:03.147: INFO: Got endpoints: latency-svc-rztb4 [753.898598ms]
    Nov 12 12:05:03.162: INFO: Created: latency-svc-ctwnl
    Nov 12 12:05:03.196: INFO: Got endpoints: latency-svc-27n7g [751.269316ms]
    Nov 12 12:05:03.226: INFO: Created: latency-svc-bwgsz
    Nov 12 12:05:03.251: INFO: Got endpoints: latency-svc-7bc2p [755.67509ms]
    Nov 12 12:05:03.275: INFO: Created: latency-svc-6sj44
    Nov 12 12:05:03.301: INFO: Got endpoints: latency-svc-mwxf5 [756.555997ms]
    Nov 12 12:05:03.349: INFO: Created: latency-svc-rmmbw
    Nov 12 12:05:03.365: INFO: Got endpoints: latency-svc-rw4wp [769.370405ms]
    Nov 12 12:05:03.398: INFO: Got endpoints: latency-svc-r2gdg [755.216685ms]
    Nov 12 12:05:03.403: INFO: Created: latency-svc-dctbn
    Nov 12 12:05:03.416: INFO: Created: latency-svc-wnj7j
    Nov 12 12:05:03.445: INFO: Got endpoints: latency-svc-hfh9f [751.61105ms]
    Nov 12 12:05:03.461: INFO: Created: latency-svc-q2vv2
    Nov 12 12:05:03.494: INFO: Got endpoints: latency-svc-gh4pq [749.94607ms]
    Nov 12 12:05:03.511: INFO: Created: latency-svc-4nhp8
    Nov 12 12:05:03.542: INFO: Got endpoints: latency-svc-z2tcb [749.136838ms]
    Nov 12 12:05:03.559: INFO: Created: latency-svc-zt4mq
    Nov 12 12:05:03.597: INFO: Got endpoints: latency-svc-qkc4w [751.640728ms]
    Nov 12 12:05:03.615: INFO: Created: latency-svc-mqxgb
    Nov 12 12:05:03.645: INFO: Got endpoints: latency-svc-q666z [751.709341ms]
    Nov 12 12:05:03.659: INFO: Created: latency-svc-bvxmx
    Nov 12 12:05:03.691: INFO: Got endpoints: latency-svc-jfqg7 [748.994108ms]
    Nov 12 12:05:03.705: INFO: Created: latency-svc-lrn69
    Nov 12 12:05:03.744: INFO: Got endpoints: latency-svc-28pxh [752.491503ms]
    Nov 12 12:05:03.760: INFO: Created: latency-svc-r2472
    Nov 12 12:05:03.798: INFO: Got endpoints: latency-svc-qf8bq [755.498766ms]
    Nov 12 12:05:03.813: INFO: Created: latency-svc-7c666
    Nov 12 12:05:03.841: INFO: Got endpoints: latency-svc-gnvjr [747.425679ms]
    Nov 12 12:05:03.856: INFO: Created: latency-svc-mzbg2
    Nov 12 12:05:03.896: INFO: Got endpoints: latency-svc-ctwnl [748.628604ms]
    Nov 12 12:05:03.919: INFO: Created: latency-svc-gg9pd
    Nov 12 12:05:03.945: INFO: Got endpoints: latency-svc-bwgsz [748.481125ms]
    Nov 12 12:05:03.961: INFO: Created: latency-svc-grqx4
    Nov 12 12:05:03.994: INFO: Got endpoints: latency-svc-6sj44 [742.680587ms]
    Nov 12 12:05:04.012: INFO: Created: latency-svc-v52j8
    Nov 12 12:05:04.045: INFO: Got endpoints: latency-svc-rmmbw [743.778511ms]
    Nov 12 12:05:04.094: INFO: Got endpoints: latency-svc-dctbn [728.951613ms]
    Nov 12 12:05:04.141: INFO: Got endpoints: latency-svc-wnj7j [743.069843ms]
    Nov 12 12:05:04.198: INFO: Got endpoints: latency-svc-q2vv2 [752.592222ms]
    Nov 12 12:05:04.245: INFO: Got endpoints: latency-svc-4nhp8 [749.988751ms]
    Nov 12 12:05:04.294: INFO: Got endpoints: latency-svc-zt4mq [752.004651ms]
    Nov 12 12:05:04.344: INFO: Got endpoints: latency-svc-mqxgb [746.814971ms]
    Nov 12 12:05:04.397: INFO: Got endpoints: latency-svc-bvxmx [752.192197ms]
    Nov 12 12:05:04.440: INFO: Got endpoints: latency-svc-lrn69 [748.956503ms]
    Nov 12 12:05:04.507: INFO: Got endpoints: latency-svc-r2472 [762.044164ms]
    Nov 12 12:05:04.542: INFO: Got endpoints: latency-svc-7c666 [744.015996ms]
    Nov 12 12:05:04.591: INFO: Got endpoints: latency-svc-mzbg2 [749.587953ms]
    Nov 12 12:05:04.648: INFO: Got endpoints: latency-svc-gg9pd [752.401798ms]
    Nov 12 12:05:04.695: INFO: Got endpoints: latency-svc-grqx4 [749.373002ms]
    Nov 12 12:05:04.742: INFO: Got endpoints: latency-svc-v52j8 [748.020268ms]
    Nov 12 12:05:04.742: INFO: Latencies: [41.254816ms 59.908758ms 65.245622ms 71.710982ms 88.979935ms 103.204118ms 122.159734ms 133.130783ms 140.57344ms 150.526818ms 158.989884ms 159.181132ms 175.964656ms 177.039636ms 182.546663ms 189.243902ms 191.772719ms 193.151327ms 194.81318ms 200.638822ms 205.619211ms 210.220902ms 210.345728ms 210.549114ms 212.990444ms 216.497408ms 217.039586ms 220.434298ms 221.392469ms 228.891756ms 231.733756ms 236.211511ms 241.745111ms 244.121094ms 261.26183ms 266.441559ms 271.877819ms 275.586114ms 285.496929ms 298.260446ms 309.707813ms 326.042318ms 328.684387ms 332.244166ms 349.954585ms 353.927205ms 370.434741ms 411.106ms 447.758925ms 449.852222ms 501.109484ms 543.077849ms 585.793788ms 636.772858ms 649.20577ms 679.038424ms 728.07649ms 728.951613ms 729.294ms 730.893891ms 735.148477ms 735.237538ms 737.962103ms 738.25584ms 740.23512ms 740.264854ms 740.863829ms 742.680587ms 743.069843ms 743.707665ms 743.778511ms 744.015996ms 744.715358ms 744.780662ms 745.271161ms 745.436884ms 745.516457ms 746.024646ms 746.277509ms 746.569495ms 746.726166ms 746.779905ms 746.814971ms 746.836626ms 747.300863ms 747.414699ms 747.425679ms 747.471904ms 747.476464ms 747.548567ms 747.62317ms 747.693454ms 747.828495ms 747.93082ms 747.953869ms 748.020268ms 748.057416ms 748.076789ms 748.103924ms 748.188027ms 748.255201ms 748.309636ms 748.359357ms 748.402916ms 748.434965ms 748.462874ms 748.474967ms 748.481125ms 748.49362ms 748.496428ms 748.52219ms 748.571797ms 748.628604ms 748.728759ms 748.733043ms 748.755729ms 748.800133ms 748.915594ms 748.940668ms 748.956503ms 748.994108ms 749.028062ms 749.1057ms 749.136838ms 749.162912ms 749.373002ms 749.415579ms 749.533583ms 749.587953ms 749.591926ms 749.819292ms 749.883745ms 749.918415ms 749.94607ms 749.988751ms 750.108846ms 750.123823ms 750.233069ms 750.244664ms 750.340673ms 750.490302ms 750.63978ms 750.70476ms 750.751669ms 750.855485ms 750.94333ms 750.956472ms 751.110107ms 751.133982ms 751.248819ms 751.269316ms 751.295006ms 751.476285ms 751.507618ms 751.608225ms 751.61105ms 751.640728ms 751.709341ms 751.731827ms 751.76478ms 752.004651ms 752.060102ms 752.106055ms 752.192197ms 752.337848ms 752.401798ms 752.491503ms 752.539607ms 752.592222ms 752.711931ms 752.71527ms 753.153821ms 753.326891ms 753.898598ms 754.202697ms 754.279449ms 754.691867ms 754.717309ms 755.216685ms 755.498766ms 755.67509ms 755.896684ms 756.068712ms 756.103105ms 756.348187ms 756.380367ms 756.555997ms 758.468918ms 760.107729ms 761.128512ms 762.044164ms 762.358297ms 763.258051ms 764.712558ms 765.539462ms 766.065417ms 769.370405ms 770.560333ms 771.794589ms 828.721317ms]
    Nov 12 12:05:04.742: INFO: 50 %ile: 748.255201ms
    Nov 12 12:05:04.742: INFO: 90 %ile: 755.67509ms
    Nov 12 12:05:04.742: INFO: 99 %ile: 771.794589ms
    Nov 12 12:05:04.742: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Nov 12 12:05:04.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-2747" for this suite. 11/12/22 12:05:04.75
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:04.761
Nov 12 12:05:04.761: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replication-controller 11/12/22 12:05:04.762
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:04.783
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:04.785
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Nov 12 12:05:04.789: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/12/22 12:05:04.821
STEP: Checking rc "condition-test" has the desired failure condition set 11/12/22 12:05:04.83
STEP: Scaling down rc "condition-test" to satisfy pod quota 11/12/22 12:05:05.84
Nov 12 12:05:05.852: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 11/12/22 12:05:05.852
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 12:05:05.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5565" for this suite. 11/12/22 12:05:05.865
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":27,"skipped":603,"failed":0}
------------------------------
• [1.112 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:04.761
    Nov 12 12:05:04.761: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replication-controller 11/12/22 12:05:04.762
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:04.783
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:04.785
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Nov 12 12:05:04.789: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/12/22 12:05:04.821
    STEP: Checking rc "condition-test" has the desired failure condition set 11/12/22 12:05:04.83
    STEP: Scaling down rc "condition-test" to satisfy pod quota 11/12/22 12:05:05.84
    Nov 12 12:05:05.852: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 11/12/22 12:05:05.852
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 12:05:05.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5565" for this suite. 11/12/22 12:05:05.865
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:05.877
Nov 12 12:05:05.877: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:05:05.879
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:05.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:05.902
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2999 11/12/22 12:05:05.904
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 12:05:05.918
STEP: creating service externalsvc in namespace services-2999 11/12/22 12:05:05.918
STEP: creating replication controller externalsvc in namespace services-2999 11/12/22 12:05:05.942
I1112 12:05:05.953323      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2999, replica count: 2
I1112 12:05:09.005504      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 11/12/22 12:05:09.01
Nov 12 12:05:09.036: INFO: Creating new exec pod
Nov 12 12:05:09.045: INFO: Waiting up to 5m0s for pod "execpodj2l4l" in namespace "services-2999" to be "running"
Nov 12 12:05:09.053: INFO: Pod "execpodj2l4l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.418685ms
Nov 12 12:05:11.060: INFO: Pod "execpodj2l4l": Phase="Running", Reason="", readiness=true. Elapsed: 2.014804702s
Nov 12 12:05:11.060: INFO: Pod "execpodj2l4l" satisfied condition "running"
Nov 12 12:05:11.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2999 exec execpodj2l4l -- /bin/sh -x -c nslookup clusterip-service.services-2999.svc.cluster.local'
Nov 12 12:05:11.369: INFO: stderr: "+ nslookup clusterip-service.services-2999.svc.cluster.local\n"
Nov 12 12:05:11.369: INFO: stdout: "Server:\t\t10.152.183.100\nAddress:\t10.152.183.100#53\n\nclusterip-service.services-2999.svc.cluster.local\tcanonical name = externalsvc.services-2999.svc.cluster.local.\nName:\texternalsvc.services-2999.svc.cluster.local\nAddress: 10.152.183.84\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2999, will wait for the garbage collector to delete the pods 11/12/22 12:05:11.369
Nov 12 12:05:11.436: INFO: Deleting ReplicationController externalsvc took: 11.393771ms
Nov 12 12:05:11.537: INFO: Terminating ReplicationController externalsvc pods took: 101.009115ms
Nov 12 12:05:13.484: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:05:13.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2999" for this suite. 11/12/22 12:05:13.517
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":28,"skipped":621,"failed":0}
------------------------------
• [SLOW TEST] [7.652 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:05.877
    Nov 12 12:05:05.877: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:05:05.879
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:05.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:05.902
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2999 11/12/22 12:05:05.904
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 12:05:05.918
    STEP: creating service externalsvc in namespace services-2999 11/12/22 12:05:05.918
    STEP: creating replication controller externalsvc in namespace services-2999 11/12/22 12:05:05.942
    I1112 12:05:05.953323      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2999, replica count: 2
    I1112 12:05:09.005504      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 11/12/22 12:05:09.01
    Nov 12 12:05:09.036: INFO: Creating new exec pod
    Nov 12 12:05:09.045: INFO: Waiting up to 5m0s for pod "execpodj2l4l" in namespace "services-2999" to be "running"
    Nov 12 12:05:09.053: INFO: Pod "execpodj2l4l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.418685ms
    Nov 12 12:05:11.060: INFO: Pod "execpodj2l4l": Phase="Running", Reason="", readiness=true. Elapsed: 2.014804702s
    Nov 12 12:05:11.060: INFO: Pod "execpodj2l4l" satisfied condition "running"
    Nov 12 12:05:11.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2999 exec execpodj2l4l -- /bin/sh -x -c nslookup clusterip-service.services-2999.svc.cluster.local'
    Nov 12 12:05:11.369: INFO: stderr: "+ nslookup clusterip-service.services-2999.svc.cluster.local\n"
    Nov 12 12:05:11.369: INFO: stdout: "Server:\t\t10.152.183.100\nAddress:\t10.152.183.100#53\n\nclusterip-service.services-2999.svc.cluster.local\tcanonical name = externalsvc.services-2999.svc.cluster.local.\nName:\texternalsvc.services-2999.svc.cluster.local\nAddress: 10.152.183.84\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-2999, will wait for the garbage collector to delete the pods 11/12/22 12:05:11.369
    Nov 12 12:05:11.436: INFO: Deleting ReplicationController externalsvc took: 11.393771ms
    Nov 12 12:05:11.537: INFO: Terminating ReplicationController externalsvc pods took: 101.009115ms
    Nov 12 12:05:13.484: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:05:13.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2999" for this suite. 11/12/22 12:05:13.517
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:13.534
Nov 12 12:05:13.534: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replication-controller 11/12/22 12:05:13.535
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:13.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:13.559
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 11/12/22 12:05:13.562
STEP: When the matched label of one of its pods change 11/12/22 12:05:13.57
Nov 12 12:05:13.576: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 12 12:05:18.584: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 11/12/22 12:05:18.601
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 12:05:18.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1425" for this suite. 11/12/22 12:05:18.638
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":29,"skipped":686,"failed":0}
------------------------------
• [SLOW TEST] [5.125 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:13.534
    Nov 12 12:05:13.534: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replication-controller 11/12/22 12:05:13.535
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:13.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:13.559
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 11/12/22 12:05:13.562
    STEP: When the matched label of one of its pods change 11/12/22 12:05:13.57
    Nov 12 12:05:13.576: INFO: Pod name pod-release: Found 0 pods out of 1
    Nov 12 12:05:18.584: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/12/22 12:05:18.601
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 12:05:18.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1425" for this suite. 11/12/22 12:05:18.638
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:18.664
Nov 12 12:05:18.664: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replicaset 11/12/22 12:05:18.665
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:18.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:18.777
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Nov 12 12:05:18.814: INFO: Creating ReplicaSet my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880
Nov 12 12:05:18.831: INFO: Pod name my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880: Found 0 pods out of 1
Nov 12 12:05:23.841: INFO: Pod name my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880: Found 1 pods out of 1
Nov 12 12:05:23.841: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880" is running
Nov 12 12:05:23.841: INFO: Waiting up to 5m0s for pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh" in namespace "replicaset-4476" to be "running"
Nov 12 12:05:23.846: INFO: Pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh": Phase="Running", Reason="", readiness=true. Elapsed: 4.766976ms
Nov 12 12:05:23.846: INFO: Pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh" satisfied condition "running"
Nov 12 12:05:23.846: INFO: Pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:18 +0000 UTC Reason: Message:}])
Nov 12 12:05:23.846: INFO: Trying to dial the pod
Nov 12 12:05:28.871: INFO: Controller my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880: Got expected result from replica 1 [my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh]: "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 12:05:28.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4476" for this suite. 11/12/22 12:05:28.881
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":30,"skipped":733,"failed":0}
------------------------------
• [SLOW TEST] [10.227 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:18.664
    Nov 12 12:05:18.664: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replicaset 11/12/22 12:05:18.665
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:18.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:18.777
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Nov 12 12:05:18.814: INFO: Creating ReplicaSet my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880
    Nov 12 12:05:18.831: INFO: Pod name my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880: Found 0 pods out of 1
    Nov 12 12:05:23.841: INFO: Pod name my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880: Found 1 pods out of 1
    Nov 12 12:05:23.841: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880" is running
    Nov 12 12:05:23.841: INFO: Waiting up to 5m0s for pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh" in namespace "replicaset-4476" to be "running"
    Nov 12 12:05:23.846: INFO: Pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh": Phase="Running", Reason="", readiness=true. Elapsed: 4.766976ms
    Nov 12 12:05:23.846: INFO: Pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh" satisfied condition "running"
    Nov 12 12:05:23.846: INFO: Pod "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:18 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:20 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:20 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:05:18 +0000 UTC Reason: Message:}])
    Nov 12 12:05:23.846: INFO: Trying to dial the pod
    Nov 12 12:05:28.871: INFO: Controller my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880: Got expected result from replica 1 [my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh]: "my-hostname-basic-93a55358-27c1-41a7-b96a-832d17f0d880-2zwsh", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 12:05:28.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4476" for this suite. 11/12/22 12:05:28.881
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:28.894
Nov 12 12:05:28.894: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:05:28.895
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:28.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:28.93
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-d57c6ac4-2403-49ab-911f-75ab4c0bd6fe 11/12/22 12:05:28.936
STEP: Creating a pod to test consume secrets 11/12/22 12:05:28.944
Nov 12 12:05:28.957: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb" in namespace "projected-9405" to be "Succeeded or Failed"
Nov 12 12:05:28.974: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 17.442682ms
Nov 12 12:05:30.979: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0226479s
Nov 12 12:05:32.980: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023235668s
STEP: Saw pod success 11/12/22 12:05:32.98
Nov 12 12:05:32.980: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb" satisfied condition "Succeeded or Failed"
Nov 12 12:05:32.985: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb container projected-secret-volume-test: <nil>
STEP: delete the pod 11/12/22 12:05:32.994
Nov 12 12:05:33.040: INFO: Waiting for pod pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb to disappear
Nov 12 12:05:33.044: INFO: Pod pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 12:05:33.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9405" for this suite. 11/12/22 12:05:33.05
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":31,"skipped":744,"failed":0}
------------------------------
• [4.234 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:28.894
    Nov 12 12:05:28.894: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:05:28.895
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:28.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:28.93
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-d57c6ac4-2403-49ab-911f-75ab4c0bd6fe 11/12/22 12:05:28.936
    STEP: Creating a pod to test consume secrets 11/12/22 12:05:28.944
    Nov 12 12:05:28.957: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb" in namespace "projected-9405" to be "Succeeded or Failed"
    Nov 12 12:05:28.974: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 17.442682ms
    Nov 12 12:05:30.979: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0226479s
    Nov 12 12:05:32.980: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023235668s
    STEP: Saw pod success 11/12/22 12:05:32.98
    Nov 12 12:05:32.980: INFO: Pod "pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb" satisfied condition "Succeeded or Failed"
    Nov 12 12:05:32.985: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:05:32.994
    Nov 12 12:05:33.040: INFO: Waiting for pod pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb to disappear
    Nov 12 12:05:33.044: INFO: Pod pod-projected-secrets-a4f31248-c946-4a84-bc79-68ac01df89eb no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 12:05:33.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9405" for this suite. 11/12/22 12:05:33.05
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:33.128
Nov 12 12:05:33.130: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename limitrange 11/12/22 12:05:33.131
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:33.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:33.156
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 11/12/22 12:05:33.158
STEP: Setting up watch 11/12/22 12:05:33.158
STEP: Submitting a LimitRange 11/12/22 12:05:33.262
STEP: Verifying LimitRange creation was observed 11/12/22 12:05:33.273
STEP: Fetching the LimitRange to ensure it has proper values 11/12/22 12:05:33.273
Nov 12 12:05:33.278: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 12 12:05:33.278: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 11/12/22 12:05:33.278
STEP: Ensuring Pod has resource requirements applied from LimitRange 11/12/22 12:05:33.288
Nov 12 12:05:33.305: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 12 12:05:33.305: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 11/12/22 12:05:33.305
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/12/22 12:05:33.315
Nov 12 12:05:33.333: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Nov 12 12:05:33.333: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 11/12/22 12:05:33.333
STEP: Failing to create a Pod with more than max resources 11/12/22 12:05:33.34
STEP: Updating a LimitRange 11/12/22 12:05:33.347
STEP: Verifying LimitRange updating is effective 11/12/22 12:05:33.356
STEP: Creating a Pod with less than former min resources 11/12/22 12:05:35.362
STEP: Failing to create a Pod with more than max resources 11/12/22 12:05:35.374
STEP: Deleting a LimitRange 11/12/22 12:05:35.378
STEP: Verifying the LimitRange was deleted 11/12/22 12:05:35.392
Nov 12 12:05:40.399: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 11/12/22 12:05:40.399
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Nov 12 12:05:40.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-1107" for this suite. 11/12/22 12:05:40.416
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":32,"skipped":745,"failed":0}
------------------------------
• [SLOW TEST] [7.296 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:33.128
    Nov 12 12:05:33.130: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename limitrange 11/12/22 12:05:33.131
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:33.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:33.156
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 11/12/22 12:05:33.158
    STEP: Setting up watch 11/12/22 12:05:33.158
    STEP: Submitting a LimitRange 11/12/22 12:05:33.262
    STEP: Verifying LimitRange creation was observed 11/12/22 12:05:33.273
    STEP: Fetching the LimitRange to ensure it has proper values 11/12/22 12:05:33.273
    Nov 12 12:05:33.278: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 12 12:05:33.278: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 11/12/22 12:05:33.278
    STEP: Ensuring Pod has resource requirements applied from LimitRange 11/12/22 12:05:33.288
    Nov 12 12:05:33.305: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 12 12:05:33.305: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 11/12/22 12:05:33.305
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/12/22 12:05:33.315
    Nov 12 12:05:33.333: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Nov 12 12:05:33.333: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 11/12/22 12:05:33.333
    STEP: Failing to create a Pod with more than max resources 11/12/22 12:05:33.34
    STEP: Updating a LimitRange 11/12/22 12:05:33.347
    STEP: Verifying LimitRange updating is effective 11/12/22 12:05:33.356
    STEP: Creating a Pod with less than former min resources 11/12/22 12:05:35.362
    STEP: Failing to create a Pod with more than max resources 11/12/22 12:05:35.374
    STEP: Deleting a LimitRange 11/12/22 12:05:35.378
    STEP: Verifying the LimitRange was deleted 11/12/22 12:05:35.392
    Nov 12 12:05:40.399: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 11/12/22 12:05:40.399
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Nov 12 12:05:40.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-1107" for this suite. 11/12/22 12:05:40.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:40.429
Nov 12 12:05:40.429: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:05:40.43
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:40.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:40.456
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 11/12/22 12:05:40.458
Nov 12 12:05:40.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov 12 12:05:40.552: INFO: stderr: ""
Nov 12 12:05:40.552: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 11/12/22 12:05:40.552
Nov 12 12:05:40.552: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov 12 12:05:40.552: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5212" to be "running and ready, or succeeded"
Nov 12 12:05:40.558: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.599695ms
Nov 12 12:05:40.558: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-14-110' to be 'Running' but was 'Pending'
Nov 12 12:05:42.564: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.012128627s
Nov 12 12:05:42.564: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov 12 12:05:42.564: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 11/12/22 12:05:42.564
Nov 12 12:05:42.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator'
Nov 12 12:05:42.714: INFO: stderr: ""
Nov 12 12:05:42.714: INFO: stdout: "I1112 12:05:41.334571       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/vjqw 516\nI1112 12:05:41.534794       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/dz2t 343\nI1112 12:05:41.735179       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/62m 417\nI1112 12:05:41.935539       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/qklm 391\nI1112 12:05:42.134740       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/789k 515\nI1112 12:05:42.335089       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/q7pq 330\nI1112 12:05:42.535616       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/qgjk 509\n"
STEP: limiting log lines 11/12/22 12:05:42.714
Nov 12 12:05:42.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --tail=1'
Nov 12 12:05:42.892: INFO: stderr: ""
Nov 12 12:05:42.892: INFO: stdout: "I1112 12:05:42.734919       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/gbnl 548\n"
Nov 12 12:05:42.892: INFO: got output "I1112 12:05:42.734919       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/gbnl 548\n"
STEP: limiting log bytes 11/12/22 12:05:42.892
Nov 12 12:05:42.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --limit-bytes=1'
Nov 12 12:05:43.075: INFO: stderr: ""
Nov 12 12:05:43.075: INFO: stdout: "I"
Nov 12 12:05:43.075: INFO: got output "I"
STEP: exposing timestamps 11/12/22 12:05:43.075
Nov 12 12:05:43.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --tail=1 --timestamps'
Nov 12 12:05:43.184: INFO: stderr: ""
Nov 12 12:05:43.184: INFO: stdout: "2022-11-12T12:05:43.135837621Z I1112 12:05:43.135680       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/tg9 588\n"
Nov 12 12:05:43.184: INFO: got output "2022-11-12T12:05:43.135837621Z I1112 12:05:43.135680       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/tg9 588\n"
STEP: restricting to a time range 11/12/22 12:05:43.184
Nov 12 12:05:45.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --since=1s'
Nov 12 12:05:45.839: INFO: stderr: ""
Nov 12 12:05:45.839: INFO: stdout: "I1112 12:05:44.935507       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/nlkt 306\nI1112 12:05:45.134965       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/9vh 345\nI1112 12:05:45.335301       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/qrk 265\nI1112 12:05:45.535652       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/ghbn 420\nI1112 12:05:45.734930       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/mrp 327\n"
Nov 12 12:05:45.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --since=24h'
Nov 12 12:05:45.987: INFO: stderr: ""
Nov 12 12:05:45.987: INFO: stdout: "I1112 12:05:41.334571       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/vjqw 516\nI1112 12:05:41.534794       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/dz2t 343\nI1112 12:05:41.735179       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/62m 417\nI1112 12:05:41.935539       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/qklm 391\nI1112 12:05:42.134740       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/789k 515\nI1112 12:05:42.335089       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/q7pq 330\nI1112 12:05:42.535616       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/qgjk 509\nI1112 12:05:42.734919       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/gbnl 548\nI1112 12:05:42.935254       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/qjgr 549\nI1112 12:05:43.135680       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/tg9 588\nI1112 12:05:43.334917       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/6jk 430\nI1112 12:05:43.535296       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/sg7 224\nI1112 12:05:43.735668       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8szb 578\nI1112 12:05:43.934971       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/qq69 413\nI1112 12:05:44.135328       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/phpr 224\nI1112 12:05:44.334621       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/786 468\nI1112 12:05:44.534779       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/gv54 490\nI1112 12:05:44.735112       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/js7 342\nI1112 12:05:44.935507       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/nlkt 306\nI1112 12:05:45.134965       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/9vh 345\nI1112 12:05:45.335301       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/qrk 265\nI1112 12:05:45.535652       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/ghbn 420\nI1112 12:05:45.734930       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/mrp 327\nI1112 12:05:45.935261       1 logs_generator.go:76] 23 POST /api/v1/namespaces/kube-system/pods/xs5f 530\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Nov 12 12:05:45.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 delete pod logs-generator'
Nov 12 12:05:47.490: INFO: stderr: ""
Nov 12 12:05:47.490: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:05:47.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5212" for this suite. 11/12/22 12:05:47.499
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":33,"skipped":779,"failed":0}
------------------------------
• [SLOW TEST] [7.082 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:40.429
    Nov 12 12:05:40.429: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:05:40.43
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:40.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:40.456
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 11/12/22 12:05:40.458
    Nov 12 12:05:40.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Nov 12 12:05:40.552: INFO: stderr: ""
    Nov 12 12:05:40.552: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 11/12/22 12:05:40.552
    Nov 12 12:05:40.552: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Nov 12 12:05:40.552: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5212" to be "running and ready, or succeeded"
    Nov 12 12:05:40.558: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.599695ms
    Nov 12 12:05:40.558: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-14-110' to be 'Running' but was 'Pending'
    Nov 12 12:05:42.564: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.012128627s
    Nov 12 12:05:42.564: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Nov 12 12:05:42.564: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 11/12/22 12:05:42.564
    Nov 12 12:05:42.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator'
    Nov 12 12:05:42.714: INFO: stderr: ""
    Nov 12 12:05:42.714: INFO: stdout: "I1112 12:05:41.334571       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/vjqw 516\nI1112 12:05:41.534794       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/dz2t 343\nI1112 12:05:41.735179       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/62m 417\nI1112 12:05:41.935539       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/qklm 391\nI1112 12:05:42.134740       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/789k 515\nI1112 12:05:42.335089       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/q7pq 330\nI1112 12:05:42.535616       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/qgjk 509\n"
    STEP: limiting log lines 11/12/22 12:05:42.714
    Nov 12 12:05:42.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --tail=1'
    Nov 12 12:05:42.892: INFO: stderr: ""
    Nov 12 12:05:42.892: INFO: stdout: "I1112 12:05:42.734919       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/gbnl 548\n"
    Nov 12 12:05:42.892: INFO: got output "I1112 12:05:42.734919       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/gbnl 548\n"
    STEP: limiting log bytes 11/12/22 12:05:42.892
    Nov 12 12:05:42.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --limit-bytes=1'
    Nov 12 12:05:43.075: INFO: stderr: ""
    Nov 12 12:05:43.075: INFO: stdout: "I"
    Nov 12 12:05:43.075: INFO: got output "I"
    STEP: exposing timestamps 11/12/22 12:05:43.075
    Nov 12 12:05:43.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --tail=1 --timestamps'
    Nov 12 12:05:43.184: INFO: stderr: ""
    Nov 12 12:05:43.184: INFO: stdout: "2022-11-12T12:05:43.135837621Z I1112 12:05:43.135680       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/tg9 588\n"
    Nov 12 12:05:43.184: INFO: got output "2022-11-12T12:05:43.135837621Z I1112 12:05:43.135680       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/tg9 588\n"
    STEP: restricting to a time range 11/12/22 12:05:43.184
    Nov 12 12:05:45.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --since=1s'
    Nov 12 12:05:45.839: INFO: stderr: ""
    Nov 12 12:05:45.839: INFO: stdout: "I1112 12:05:44.935507       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/nlkt 306\nI1112 12:05:45.134965       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/9vh 345\nI1112 12:05:45.335301       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/qrk 265\nI1112 12:05:45.535652       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/ghbn 420\nI1112 12:05:45.734930       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/mrp 327\n"
    Nov 12 12:05:45.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 logs logs-generator logs-generator --since=24h'
    Nov 12 12:05:45.987: INFO: stderr: ""
    Nov 12 12:05:45.987: INFO: stdout: "I1112 12:05:41.334571       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/vjqw 516\nI1112 12:05:41.534794       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/dz2t 343\nI1112 12:05:41.735179       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/62m 417\nI1112 12:05:41.935539       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/qklm 391\nI1112 12:05:42.134740       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/789k 515\nI1112 12:05:42.335089       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/q7pq 330\nI1112 12:05:42.535616       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/qgjk 509\nI1112 12:05:42.734919       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/gbnl 548\nI1112 12:05:42.935254       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/qjgr 549\nI1112 12:05:43.135680       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/tg9 588\nI1112 12:05:43.334917       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/6jk 430\nI1112 12:05:43.535296       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/sg7 224\nI1112 12:05:43.735668       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/8szb 578\nI1112 12:05:43.934971       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/qq69 413\nI1112 12:05:44.135328       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/phpr 224\nI1112 12:05:44.334621       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/786 468\nI1112 12:05:44.534779       1 logs_generator.go:76] 16 GET /api/v1/namespaces/kube-system/pods/gv54 490\nI1112 12:05:44.735112       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/js7 342\nI1112 12:05:44.935507       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/nlkt 306\nI1112 12:05:45.134965       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/9vh 345\nI1112 12:05:45.335301       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/qrk 265\nI1112 12:05:45.535652       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/kube-system/pods/ghbn 420\nI1112 12:05:45.734930       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/mrp 327\nI1112 12:05:45.935261       1 logs_generator.go:76] 23 POST /api/v1/namespaces/kube-system/pods/xs5f 530\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Nov 12 12:05:45.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5212 delete pod logs-generator'
    Nov 12 12:05:47.490: INFO: stderr: ""
    Nov 12 12:05:47.490: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:05:47.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5212" for this suite. 11/12/22 12:05:47.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:47.513
Nov 12 12:05:47.514: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 12:05:47.514
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:47.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:47.54
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 11/12/22 12:05:47.548
STEP: submitting the pod to kubernetes 11/12/22 12:05:47.548
Nov 12 12:05:47.566: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" in namespace "pods-58" to be "running and ready"
Nov 12 12:05:47.571: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741268ms
Nov 12 12:05:47.571: INFO: The phase of Pod pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:05:49.576: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=true. Elapsed: 2.010344643s
Nov 12 12:05:49.576: INFO: The phase of Pod pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0 is Running (Ready = true)
Nov 12 12:05:49.576: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/12/22 12:05:49.581
STEP: updating the pod 11/12/22 12:05:49.587
Nov 12 12:05:50.101: INFO: Successfully updated pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0"
Nov 12 12:05:50.101: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" in namespace "pods-58" to be "terminated with reason DeadlineExceeded"
Nov 12 12:05:50.105: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=true. Elapsed: 3.669454ms
Nov 12 12:05:52.113: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=true. Elapsed: 2.011489358s
Nov 12 12:05:54.113: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=false. Elapsed: 4.012016722s
Nov 12 12:05:56.110: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.009431119s
Nov 12 12:05:56.111: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 12:05:56.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-58" for this suite. 11/12/22 12:05:56.116
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":34,"skipped":834,"failed":0}
------------------------------
• [SLOW TEST] [8.611 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:47.513
    Nov 12 12:05:47.514: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 12:05:47.514
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:47.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:47.54
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 11/12/22 12:05:47.548
    STEP: submitting the pod to kubernetes 11/12/22 12:05:47.548
    Nov 12 12:05:47.566: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" in namespace "pods-58" to be "running and ready"
    Nov 12 12:05:47.571: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741268ms
    Nov 12 12:05:47.571: INFO: The phase of Pod pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:05:49.576: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=true. Elapsed: 2.010344643s
    Nov 12 12:05:49.576: INFO: The phase of Pod pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0 is Running (Ready = true)
    Nov 12 12:05:49.576: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/12/22 12:05:49.581
    STEP: updating the pod 11/12/22 12:05:49.587
    Nov 12 12:05:50.101: INFO: Successfully updated pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0"
    Nov 12 12:05:50.101: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" in namespace "pods-58" to be "terminated with reason DeadlineExceeded"
    Nov 12 12:05:50.105: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=true. Elapsed: 3.669454ms
    Nov 12 12:05:52.113: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=true. Elapsed: 2.011489358s
    Nov 12 12:05:54.113: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Running", Reason="", readiness=false. Elapsed: 4.012016722s
    Nov 12 12:05:56.110: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.009431119s
    Nov 12 12:05:56.111: INFO: Pod "pod-update-activedeadlineseconds-baef6517-7733-4a23-88c7-05d9e93edbb0" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 12:05:56.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-58" for this suite. 11/12/22 12:05:56.116
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:05:56.125
Nov 12 12:05:56.125: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:05:56.126
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:56.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:56.157
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 11/12/22 12:05:56.176
Nov 12 12:05:56.176: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2" in namespace "kubelet-test-1803" to be "completed"
Nov 12 12:05:56.184: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.453444ms
Nov 12 12:05:58.190: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014136704s
Nov 12 12:06:00.191: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015390334s
Nov 12 12:06:00.191: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 12:06:00.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1803" for this suite. 11/12/22 12:06:00.206
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":35,"skipped":834,"failed":0}
------------------------------
• [4.091 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:05:56.125
    Nov 12 12:05:56.125: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:05:56.126
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:05:56.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:05:56.157
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 11/12/22 12:05:56.176
    Nov 12 12:05:56.176: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2" in namespace "kubelet-test-1803" to be "completed"
    Nov 12 12:05:56.184: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.453444ms
    Nov 12 12:05:58.190: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014136704s
    Nov 12 12:06:00.191: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015390334s
    Nov 12 12:06:00.191: INFO: Pod "agnhost-host-aliases8533326b-eddd-4aec-9616-16f088346ed2" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 12:06:00.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-1803" for this suite. 11/12/22 12:06:00.206
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:06:00.216
Nov 12 12:06:00.217: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename init-container 11/12/22 12:06:00.217
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:00.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:00.243
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 11/12/22 12:06:00.252
Nov 12 12:06:00.253: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 12:06:03.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-409" for this suite. 11/12/22 12:06:03.514
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":36,"skipped":835,"failed":0}
------------------------------
• [3.309 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:06:00.216
    Nov 12 12:06:00.217: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename init-container 11/12/22 12:06:00.217
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:00.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:00.243
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 11/12/22 12:06:00.252
    Nov 12 12:06:00.253: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 12:06:03.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-409" for this suite. 11/12/22 12:06:03.514
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:06:03.527
Nov 12 12:06:03.527: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename events 11/12/22 12:06:03.528
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:03.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:03.552
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 11/12/22 12:06:03.554
Nov 12 12:06:03.562: INFO: created test-event-1
Nov 12 12:06:03.569: INFO: created test-event-2
Nov 12 12:06:03.574: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 11/12/22 12:06:03.574
STEP: delete collection of events 11/12/22 12:06:03.58
Nov 12 12:06:03.580: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/12/22 12:06:03.622
Nov 12 12:06:03.622: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 12 12:06:03.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5891" for this suite. 11/12/22 12:06:03.631
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":37,"skipped":853,"failed":0}
------------------------------
• [0.114 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:06:03.527
    Nov 12 12:06:03.527: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename events 11/12/22 12:06:03.528
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:03.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:03.552
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 11/12/22 12:06:03.554
    Nov 12 12:06:03.562: INFO: created test-event-1
    Nov 12 12:06:03.569: INFO: created test-event-2
    Nov 12 12:06:03.574: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 11/12/22 12:06:03.574
    STEP: delete collection of events 11/12/22 12:06:03.58
    Nov 12 12:06:03.580: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/12/22 12:06:03.622
    Nov 12 12:06:03.622: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 12 12:06:03.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5891" for this suite. 11/12/22 12:06:03.631
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:06:03.65
Nov 12 12:06:03.651: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 12:06:03.651
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:03.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:03.675
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Nov 12 12:06:03.679: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 12 12:06:03.696: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 12 12:06:08.701: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 12:06:08.701
Nov 12 12:06:08.701: INFO: Creating deployment "test-rolling-update-deployment"
Nov 12 12:06:08.712: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 12 12:06:08.723: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 12 12:06:10.736: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 12 12:06:10.741: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 12:06:10.756: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-1855  7b95763a-0013-47de-890a-6f7b40ea4fb3 7041 1 2022-11-12 12:06:08 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-12 12:06:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038173c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 12:06:08 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-12 12:06:10 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 12:06:10.761: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-1855  b46b746a-28d7-49e4-87ff-ec277746a1bb 7031 1 2022-11-12 12:06:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 7b95763a-0013-47de-890a-6f7b40ea4fb3 0xc00393ae67 0xc00393ae68}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:06:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b95763a-0013-47de-890a-6f7b40ea4fb3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00393af18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:06:10.761: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 12 12:06:10.761: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-1855  6b4e57b9-3dcd-4953-9446-d27338c1d870 7040 2 2022-11-12 12:06:03 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 7b95763a-0013-47de-890a-6f7b40ea4fb3 0xc00393ad3f 0xc00393ad50}] [] [{e2e.test Update apps/v1 2022-11-12 12:06:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b95763a-0013-47de-890a-6f7b40ea4fb3\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00393ae08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:06:10.766: INFO: Pod "test-rolling-update-deployment-78f575d8ff-7hcgl" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-7hcgl test-rolling-update-deployment-78f575d8ff- deployment-1855  ccca83e3-23c5-4be6-8017-190db574799c 7030 0 2022-11-12 12:06:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff b46b746a-28d7-49e4-87ff-ec277746a1bb 0xc003817787 0xc003817788}] [] [{kube-controller-manager Update v1 2022-11-12 12:06:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b46b746a-28d7-49e4-87ff-ec277746a1bb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.34\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kkjff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kkjff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.34,StartTime:2022-11-12 12:06:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:06:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://f1eff2b9472ca359864ff0cbca889f387360595f14a176ad8c52aca9bad8eb9a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 12:06:10.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1855" for this suite. 11/12/22 12:06:10.77
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":38,"skipped":859,"failed":0}
------------------------------
• [SLOW TEST] [7.128 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:06:03.65
    Nov 12 12:06:03.651: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 12:06:03.651
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:03.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:03.675
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Nov 12 12:06:03.679: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Nov 12 12:06:03.696: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 12 12:06:08.701: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 12:06:08.701
    Nov 12 12:06:08.701: INFO: Creating deployment "test-rolling-update-deployment"
    Nov 12 12:06:08.712: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Nov 12 12:06:08.723: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Nov 12 12:06:10.736: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Nov 12 12:06:10.741: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 12:06:10.756: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-1855  7b95763a-0013-47de-890a-6f7b40ea4fb3 7041 1 2022-11-12 12:06:08 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-12 12:06:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038173c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 12:06:08 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-12 12:06:10 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 12:06:10.761: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-1855  b46b746a-28d7-49e4-87ff-ec277746a1bb 7031 1 2022-11-12 12:06:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 7b95763a-0013-47de-890a-6f7b40ea4fb3 0xc00393ae67 0xc00393ae68}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:06:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b95763a-0013-47de-890a-6f7b40ea4fb3\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00393af18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:06:10.761: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Nov 12 12:06:10.761: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-1855  6b4e57b9-3dcd-4953-9446-d27338c1d870 7040 2 2022-11-12 12:06:03 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 7b95763a-0013-47de-890a-6f7b40ea4fb3 0xc00393ad3f 0xc00393ad50}] [] [{e2e.test Update apps/v1 2022-11-12 12:06:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7b95763a-0013-47de-890a-6f7b40ea4fb3\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00393ae08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:06:10.766: INFO: Pod "test-rolling-update-deployment-78f575d8ff-7hcgl" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-7hcgl test-rolling-update-deployment-78f575d8ff- deployment-1855  ccca83e3-23c5-4be6-8017-190db574799c 7030 0 2022-11-12 12:06:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff b46b746a-28d7-49e4-87ff-ec277746a1bb 0xc003817787 0xc003817788}] [] [{kube-controller-manager Update v1 2022-11-12 12:06:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b46b746a-28d7-49e4-87ff-ec277746a1bb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:06:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.34\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kkjff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kkjff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:06:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.34,StartTime:2022-11-12 12:06:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:06:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://f1eff2b9472ca359864ff0cbca889f387360595f14a176ad8c52aca9bad8eb9a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 12:06:10.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1855" for this suite. 11/12/22 12:06:10.77
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:06:10.779
Nov 12 12:06:10.779: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 12:06:10.78
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:10.799
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:10.805
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 11/12/22 12:06:10.809
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 11/12/22 12:06:10.817
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 11/12/22 12:06:10.817
STEP: creating a pod to probe DNS 11/12/22 12:06:10.817
STEP: submitting the pod to kubernetes 11/12/22 12:06:10.817
Nov 12 12:06:10.833: INFO: Waiting up to 15m0s for pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8" in namespace "dns-7049" to be "running"
Nov 12 12:06:10.840: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.310895ms
Nov 12 12:06:12.845: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012611865s
Nov 12 12:06:14.845: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012862779s
Nov 12 12:06:16.846: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013065326s
Nov 12 12:06:18.858: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Running", Reason="", readiness=true. Elapsed: 8.025704036s
Nov 12 12:06:18.858: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8" satisfied condition "running"
STEP: retrieving the pod 11/12/22 12:06:18.858
STEP: looking for the results for each expected name from probers 11/12/22 12:06:18.863
Nov 12 12:06:18.888: INFO: DNS probes using dns-7049/dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8 succeeded

STEP: deleting the pod 11/12/22 12:06:18.888
STEP: deleting the test headless service 11/12/22 12:06:18.918
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 12:06:18.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7049" for this suite. 11/12/22 12:06:18.958
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":39,"skipped":864,"failed":0}
------------------------------
• [SLOW TEST] [8.187 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:06:10.779
    Nov 12 12:06:10.779: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 12:06:10.78
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:10.799
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:10.805
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 11/12/22 12:06:10.809
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     11/12/22 12:06:10.817
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7049.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     11/12/22 12:06:10.817
    STEP: creating a pod to probe DNS 11/12/22 12:06:10.817
    STEP: submitting the pod to kubernetes 11/12/22 12:06:10.817
    Nov 12 12:06:10.833: INFO: Waiting up to 15m0s for pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8" in namespace "dns-7049" to be "running"
    Nov 12 12:06:10.840: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.310895ms
    Nov 12 12:06:12.845: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012611865s
    Nov 12 12:06:14.845: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012862779s
    Nov 12 12:06:16.846: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013065326s
    Nov 12 12:06:18.858: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8": Phase="Running", Reason="", readiness=true. Elapsed: 8.025704036s
    Nov 12 12:06:18.858: INFO: Pod "dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 12:06:18.858
    STEP: looking for the results for each expected name from probers 11/12/22 12:06:18.863
    Nov 12 12:06:18.888: INFO: DNS probes using dns-7049/dns-test-2ba30b63-b9f4-4111-a414-57bfdc5e81a8 succeeded

    STEP: deleting the pod 11/12/22 12:06:18.888
    STEP: deleting the test headless service 11/12/22 12:06:18.918
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 12:06:18.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7049" for this suite. 11/12/22 12:06:18.958
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:06:18.972
Nov 12 12:06:18.972: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 12:06:18.973
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:19.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:19.008
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 12:07:19.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5497" for this suite. 11/12/22 12:07:19.049
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":40,"skipped":905,"failed":0}
------------------------------
• [SLOW TEST] [60.091 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:06:18.972
    Nov 12 12:06:18.972: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 12:06:18.973
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:06:19.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:06:19.008
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 12:07:19.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5497" for this suite. 11/12/22 12:07:19.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:07:19.068
Nov 12 12:07:19.068: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 12:07:19.07
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:19.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:19.101
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-d432138b-adc9-4d99-ae1c-9576c8dc6c0d 11/12/22 12:07:19.106
STEP: Creating a pod to test consume secrets 11/12/22 12:07:19.114
Nov 12 12:07:19.131: INFO: Waiting up to 5m0s for pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe" in namespace "secrets-1265" to be "Succeeded or Failed"
Nov 12 12:07:19.142: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.169051ms
Nov 12 12:07:21.148: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017031746s
Nov 12 12:07:23.149: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018084781s
Nov 12 12:07:25.149: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018142786s
STEP: Saw pod success 11/12/22 12:07:25.149
Nov 12 12:07:25.149: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe" satisfied condition "Succeeded or Failed"
Nov 12 12:07:25.153: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe container secret-env-test: <nil>
STEP: delete the pod 11/12/22 12:07:25.167
Nov 12 12:07:25.182: INFO: Waiting for pod pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe to disappear
Nov 12 12:07:25.191: INFO: Pod pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 12 12:07:25.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1265" for this suite. 11/12/22 12:07:25.197
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":41,"skipped":910,"failed":0}
------------------------------
• [SLOW TEST] [6.144 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:07:19.068
    Nov 12 12:07:19.068: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 12:07:19.07
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:19.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:19.101
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-d432138b-adc9-4d99-ae1c-9576c8dc6c0d 11/12/22 12:07:19.106
    STEP: Creating a pod to test consume secrets 11/12/22 12:07:19.114
    Nov 12 12:07:19.131: INFO: Waiting up to 5m0s for pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe" in namespace "secrets-1265" to be "Succeeded or Failed"
    Nov 12 12:07:19.142: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Pending", Reason="", readiness=false. Elapsed: 11.169051ms
    Nov 12 12:07:21.148: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017031746s
    Nov 12 12:07:23.149: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018084781s
    Nov 12 12:07:25.149: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018142786s
    STEP: Saw pod success 11/12/22 12:07:25.149
    Nov 12 12:07:25.149: INFO: Pod "pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe" satisfied condition "Succeeded or Failed"
    Nov 12 12:07:25.153: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe container secret-env-test: <nil>
    STEP: delete the pod 11/12/22 12:07:25.167
    Nov 12 12:07:25.182: INFO: Waiting for pod pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe to disappear
    Nov 12 12:07:25.191: INFO: Pod pod-secrets-5f3947b4-2fcc-44a6-a4db-26eb4fffccfe no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 12:07:25.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1265" for this suite. 11/12/22 12:07:25.197
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:07:25.211
Nov 12 12:07:25.212: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename events 11/12/22 12:07:25.214
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:25.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:25.236
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 11/12/22 12:07:25.238
STEP: get a list of Events with a label in the current namespace 11/12/22 12:07:25.259
STEP: delete a list of events 11/12/22 12:07:25.264
Nov 12 12:07:25.264: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/12/22 12:07:25.298
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 12 12:07:25.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7452" for this suite. 11/12/22 12:07:25.307
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":42,"skipped":940,"failed":0}
------------------------------
• [0.106 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:07:25.211
    Nov 12 12:07:25.212: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename events 11/12/22 12:07:25.214
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:25.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:25.236
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 11/12/22 12:07:25.238
    STEP: get a list of Events with a label in the current namespace 11/12/22 12:07:25.259
    STEP: delete a list of events 11/12/22 12:07:25.264
    Nov 12 12:07:25.264: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/12/22 12:07:25.298
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 12 12:07:25.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-7452" for this suite. 11/12/22 12:07:25.307
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:07:25.324
Nov 12 12:07:25.325: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:07:25.325
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:25.346
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:25.349
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-10511e0c-0ce0-4524-a4de-f7c5ed504a05 11/12/22 12:07:25.351
STEP: Creating a pod to test consume configMaps 11/12/22 12:07:25.358
Nov 12 12:07:25.369: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324" in namespace "projected-6425" to be "Succeeded or Failed"
Nov 12 12:07:25.373: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324": Phase="Pending", Reason="", readiness=false. Elapsed: 4.459565ms
Nov 12 12:07:27.378: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009172497s
Nov 12 12:07:29.380: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011619155s
STEP: Saw pod success 11/12/22 12:07:29.38
Nov 12 12:07:29.381: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324" satisfied condition "Succeeded or Failed"
Nov 12 12:07:29.385: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 12:07:29.394
Nov 12 12:07:29.452: INFO: Waiting for pod pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324 to disappear
Nov 12 12:07:29.457: INFO: Pod pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 12:07:29.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6425" for this suite. 11/12/22 12:07:29.462
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":43,"skipped":983,"failed":0}
------------------------------
• [4.161 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:07:25.324
    Nov 12 12:07:25.325: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:07:25.325
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:25.346
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:25.349
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-10511e0c-0ce0-4524-a4de-f7c5ed504a05 11/12/22 12:07:25.351
    STEP: Creating a pod to test consume configMaps 11/12/22 12:07:25.358
    Nov 12 12:07:25.369: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324" in namespace "projected-6425" to be "Succeeded or Failed"
    Nov 12 12:07:25.373: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324": Phase="Pending", Reason="", readiness=false. Elapsed: 4.459565ms
    Nov 12 12:07:27.378: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009172497s
    Nov 12 12:07:29.380: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011619155s
    STEP: Saw pod success 11/12/22 12:07:29.38
    Nov 12 12:07:29.381: INFO: Pod "pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324" satisfied condition "Succeeded or Failed"
    Nov 12 12:07:29.385: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 12:07:29.394
    Nov 12 12:07:29.452: INFO: Waiting for pod pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324 to disappear
    Nov 12 12:07:29.457: INFO: Pod pod-projected-configmaps-f937c8b8-057d-4231-943a-a02a797dd324 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 12:07:29.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6425" for this suite. 11/12/22 12:07:29.462
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:07:29.487
Nov 12 12:07:29.488: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:07:29.488
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:29.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:29.517
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 11/12/22 12:07:29.521
Nov 12 12:07:29.521: INFO: Creating e2e-svc-a-dzwbs
Nov 12 12:07:29.537: INFO: Creating e2e-svc-b-jqsvp
Nov 12 12:07:29.565: INFO: Creating e2e-svc-c-7qllf
STEP: deleting service collection 11/12/22 12:07:29.604
Nov 12 12:07:29.666: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:07:29.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5599" for this suite. 11/12/22 12:07:29.676
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":44,"skipped":1001,"failed":0}
------------------------------
• [0.209 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:07:29.487
    Nov 12 12:07:29.488: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:07:29.488
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:29.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:29.517
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 11/12/22 12:07:29.521
    Nov 12 12:07:29.521: INFO: Creating e2e-svc-a-dzwbs
    Nov 12 12:07:29.537: INFO: Creating e2e-svc-b-jqsvp
    Nov 12 12:07:29.565: INFO: Creating e2e-svc-c-7qllf
    STEP: deleting service collection 11/12/22 12:07:29.604
    Nov 12 12:07:29.666: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:07:29.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5599" for this suite. 11/12/22 12:07:29.676
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:07:29.697
Nov 12 12:07:29.697: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:07:29.698
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:29.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:29.721
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  11/12/22 12:07:29.724
Nov 12 12:07:29.739: INFO: Waiting up to 5m0s for pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427" in namespace "svcaccounts-8771" to be "Succeeded or Failed"
Nov 12 12:07:29.750: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427": Phase="Pending", Reason="", readiness=false. Elapsed: 10.58792ms
Nov 12 12:07:31.755: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015538326s
Nov 12 12:07:33.756: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016971153s
STEP: Saw pod success 11/12/22 12:07:33.756
Nov 12 12:07:33.756: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427" satisfied condition "Succeeded or Failed"
Nov 12 12:07:33.761: INFO: Trying to get logs from node ip-172-31-14-110 pod test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 12:07:33.771
Nov 12 12:07:33.788: INFO: Waiting for pod test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427 to disappear
Nov 12 12:07:33.793: INFO: Pod test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 12 12:07:33.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8771" for this suite. 11/12/22 12:07:33.798
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":45,"skipped":1006,"failed":0}
------------------------------
• [4.110 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:07:29.697
    Nov 12 12:07:29.697: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:07:29.698
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:29.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:29.721
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  11/12/22 12:07:29.724
    Nov 12 12:07:29.739: INFO: Waiting up to 5m0s for pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427" in namespace "svcaccounts-8771" to be "Succeeded or Failed"
    Nov 12 12:07:29.750: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427": Phase="Pending", Reason="", readiness=false. Elapsed: 10.58792ms
    Nov 12 12:07:31.755: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015538326s
    Nov 12 12:07:33.756: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016971153s
    STEP: Saw pod success 11/12/22 12:07:33.756
    Nov 12 12:07:33.756: INFO: Pod "test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427" satisfied condition "Succeeded or Failed"
    Nov 12 12:07:33.761: INFO: Trying to get logs from node ip-172-31-14-110 pod test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 12:07:33.771
    Nov 12 12:07:33.788: INFO: Waiting for pod test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427 to disappear
    Nov 12 12:07:33.793: INFO: Pod test-pod-0ca79d24-d915-4a3e-82a9-8a55daf99427 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 12 12:07:33.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8771" for this suite. 11/12/22 12:07:33.798
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:07:33.808
Nov 12 12:07:33.808: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-runtime 11/12/22 12:07:33.809
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:33.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:33.832
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/12/22 12:07:33.846
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/12/22 12:07:53.978
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/12/22 12:07:53.982
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/12/22 12:07:53.992
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/12/22 12:07:53.992
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/12/22 12:07:54.021
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/12/22 12:07:57.047
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/12/22 12:07:59.065
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/12/22 12:07:59.074
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/12/22 12:07:59.074
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/12/22 12:07:59.105
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/12/22 12:08:00.122
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/12/22 12:08:03.146
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/12/22 12:08:03.155
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/12/22 12:08:03.156
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 12:08:03.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3779" for this suite. 11/12/22 12:08:03.265
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":46,"skipped":1009,"failed":0}
------------------------------
• [SLOW TEST] [29.467 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:07:33.808
    Nov 12 12:07:33.808: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-runtime 11/12/22 12:07:33.809
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:07:33.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:07:33.832
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/12/22 12:07:33.846
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/12/22 12:07:53.978
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/12/22 12:07:53.982
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/12/22 12:07:53.992
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/12/22 12:07:53.992
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/12/22 12:07:54.021
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/12/22 12:07:57.047
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/12/22 12:07:59.065
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/12/22 12:07:59.074
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/12/22 12:07:59.074
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/12/22 12:07:59.105
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/12/22 12:08:00.122
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/12/22 12:08:03.146
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/12/22 12:08:03.155
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/12/22 12:08:03.156
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 12:08:03.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3779" for this suite. 11/12/22 12:08:03.265
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:08:03.276
Nov 12 12:08:03.276: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 12:08:03.276
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:03.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:03.307
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 11/12/22 12:08:03.322
STEP: watching for Pod to be ready 11/12/22 12:08:03.334
Nov 12 12:08:03.336: INFO: observed Pod pod-test in namespace pods-8121 in phase Pending with labels: map[test-pod-static:true] & conditions []
Nov 12 12:08:03.341: INFO: observed Pod pod-test in namespace pods-8121 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  }]
Nov 12 12:08:03.360: INFO: observed Pod pod-test in namespace pods-8121 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  }]
Nov 12 12:08:04.814: INFO: Found Pod pod-test in namespace pods-8121 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 11/12/22 12:08:04.819
STEP: getting the Pod and ensuring that it's patched 11/12/22 12:08:04.831
STEP: replacing the Pod's status Ready condition to False 11/12/22 12:08:04.84
STEP: check the Pod again to ensure its Ready conditions are False 11/12/22 12:08:04.86
STEP: deleting the Pod via a Collection with a LabelSelector 11/12/22 12:08:04.86
STEP: watching for the Pod to be deleted 11/12/22 12:08:04.885
Nov 12 12:08:04.887: INFO: observed event type MODIFIED
Nov 12 12:08:06.818: INFO: observed event type MODIFIED
Nov 12 12:08:07.819: INFO: observed event type MODIFIED
Nov 12 12:08:07.829: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 12:08:07.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8121" for this suite. 11/12/22 12:08:07.844
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":47,"skipped":1016,"failed":0}
------------------------------
• [4.579 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:08:03.276
    Nov 12 12:08:03.276: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 12:08:03.276
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:03.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:03.307
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 11/12/22 12:08:03.322
    STEP: watching for Pod to be ready 11/12/22 12:08:03.334
    Nov 12 12:08:03.336: INFO: observed Pod pod-test in namespace pods-8121 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Nov 12 12:08:03.341: INFO: observed Pod pod-test in namespace pods-8121 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  }]
    Nov 12 12:08:03.360: INFO: observed Pod pod-test in namespace pods-8121 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  }]
    Nov 12 12:08:04.814: INFO: Found Pod pod-test in namespace pods-8121 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:04 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:04 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:08:03 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 11/12/22 12:08:04.819
    STEP: getting the Pod and ensuring that it's patched 11/12/22 12:08:04.831
    STEP: replacing the Pod's status Ready condition to False 11/12/22 12:08:04.84
    STEP: check the Pod again to ensure its Ready conditions are False 11/12/22 12:08:04.86
    STEP: deleting the Pod via a Collection with a LabelSelector 11/12/22 12:08:04.86
    STEP: watching for the Pod to be deleted 11/12/22 12:08:04.885
    Nov 12 12:08:04.887: INFO: observed event type MODIFIED
    Nov 12 12:08:06.818: INFO: observed event type MODIFIED
    Nov 12 12:08:07.819: INFO: observed event type MODIFIED
    Nov 12 12:08:07.829: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 12:08:07.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8121" for this suite. 11/12/22 12:08:07.844
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:08:07.855
Nov 12 12:08:07.855: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename daemonsets 11/12/22 12:08:07.856
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:07.875
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:07.878
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 11/12/22 12:08:07.909
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:08:07.918
Nov 12 12:08:07.926: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:07.926: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:07.933: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:08:07.933: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:08:08.940: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:08.941: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:08.945: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 12 12:08:08.945: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:08:09.939: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:09.939: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:09.944: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 12:08:09.944: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 11/12/22 12:08:09.948
Nov 12 12:08:09.967: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:09.967: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:09.972: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:08:09.972: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:08:10.985: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:10.985: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:10.993: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:08:10.993: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:08:11.983: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:11.983: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:11.993: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:08:11.993: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:08:12.985: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:12.985: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:12.992: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:08:12.992: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:08:13.977: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:13.977: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:08:13.983: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 12:08:13.983: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:08:13.988
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3840, will wait for the garbage collector to delete the pods 11/12/22 12:08:13.988
Nov 12 12:08:14.054: INFO: Deleting DaemonSet.extensions daemon-set took: 11.102784ms
Nov 12 12:08:14.155: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.479272ms
Nov 12 12:08:16.159: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:08:16.159: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 12 12:08:16.164: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7783"},"items":null}

Nov 12 12:08:16.168: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7783"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:08:16.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3840" for this suite. 11/12/22 12:08:16.192
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":48,"skipped":1018,"failed":0}
------------------------------
• [SLOW TEST] [8.347 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:08:07.855
    Nov 12 12:08:07.855: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename daemonsets 11/12/22 12:08:07.856
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:07.875
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:07.878
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 11/12/22 12:08:07.909
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:08:07.918
    Nov 12 12:08:07.926: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:07.926: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:07.933: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:08:07.933: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:08:08.940: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:08.941: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:08.945: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 12 12:08:08.945: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:08:09.939: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:09.939: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:09.944: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 12:08:09.944: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 11/12/22 12:08:09.948
    Nov 12 12:08:09.967: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:09.967: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:09.972: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:08:09.972: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:08:10.985: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:10.985: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:10.993: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:08:10.993: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:08:11.983: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:11.983: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:11.993: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:08:11.993: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:08:12.985: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:12.985: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:12.992: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:08:12.992: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:08:13.977: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:13.977: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:08:13.983: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 12:08:13.983: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:08:13.988
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3840, will wait for the garbage collector to delete the pods 11/12/22 12:08:13.988
    Nov 12 12:08:14.054: INFO: Deleting DaemonSet.extensions daemon-set took: 11.102784ms
    Nov 12 12:08:14.155: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.479272ms
    Nov 12 12:08:16.159: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:08:16.159: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 12 12:08:16.164: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7783"},"items":null}

    Nov 12 12:08:16.168: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7783"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:08:16.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3840" for this suite. 11/12/22 12:08:16.192
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:08:16.203
Nov 12 12:08:16.203: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:08:16.204
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:16.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:16.231
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-26df87d5-ab09-48ce-9c8e-dc5c98bdcf9e 11/12/22 12:08:16.234
STEP: Creating a pod to test consume secrets 11/12/22 12:08:16.243
Nov 12 12:08:16.265: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2" in namespace "projected-1883" to be "Succeeded or Failed"
Nov 12 12:08:16.274: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.789819ms
Nov 12 12:08:18.281: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015255511s
Nov 12 12:08:20.279: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013693774s
STEP: Saw pod success 11/12/22 12:08:20.279
Nov 12 12:08:20.279: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2" satisfied condition "Succeeded or Failed"
Nov 12 12:08:20.284: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 12:08:20.293
Nov 12 12:08:20.309: INFO: Waiting for pod pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2 to disappear
Nov 12 12:08:20.318: INFO: Pod pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 12:08:20.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1883" for this suite. 11/12/22 12:08:20.328
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":49,"skipped":1019,"failed":0}
------------------------------
• [4.138 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:08:16.203
    Nov 12 12:08:16.203: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:08:16.204
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:16.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:16.231
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-26df87d5-ab09-48ce-9c8e-dc5c98bdcf9e 11/12/22 12:08:16.234
    STEP: Creating a pod to test consume secrets 11/12/22 12:08:16.243
    Nov 12 12:08:16.265: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2" in namespace "projected-1883" to be "Succeeded or Failed"
    Nov 12 12:08:16.274: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.789819ms
    Nov 12 12:08:18.281: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015255511s
    Nov 12 12:08:20.279: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013693774s
    STEP: Saw pod success 11/12/22 12:08:20.279
    Nov 12 12:08:20.279: INFO: Pod "pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2" satisfied condition "Succeeded or Failed"
    Nov 12 12:08:20.284: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:08:20.293
    Nov 12 12:08:20.309: INFO: Waiting for pod pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2 to disappear
    Nov 12 12:08:20.318: INFO: Pod pod-projected-secrets-cfcf5f36-7499-407e-818e-1cae22ac8ba2 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 12:08:20.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1883" for this suite. 11/12/22 12:08:20.328
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:08:20.344
Nov 12 12:08:20.344: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 12:08:20.345
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:20.376
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:20.379
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 11/12/22 12:08:20.382
Nov 12 12:08:20.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e" in namespace "downward-api-2322" to be "Succeeded or Failed"
Nov 12 12:08:20.403: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.819791ms
Nov 12 12:08:22.413: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019320105s
Nov 12 12:08:24.410: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016645935s
STEP: Saw pod success 11/12/22 12:08:24.41
Nov 12 12:08:24.411: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e" satisfied condition "Succeeded or Failed"
Nov 12 12:08:24.418: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e container client-container: <nil>
STEP: delete the pod 11/12/22 12:08:24.427
Nov 12 12:08:24.443: INFO: Waiting for pod downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e to disappear
Nov 12 12:08:24.447: INFO: Pod downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 12:08:24.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2322" for this suite. 11/12/22 12:08:24.459
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":50,"skipped":1056,"failed":0}
------------------------------
• [4.125 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:08:20.344
    Nov 12 12:08:20.344: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 12:08:20.345
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:20.376
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:20.379
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 11/12/22 12:08:20.382
    Nov 12 12:08:20.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e" in namespace "downward-api-2322" to be "Succeeded or Failed"
    Nov 12 12:08:20.403: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.819791ms
    Nov 12 12:08:22.413: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019320105s
    Nov 12 12:08:24.410: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016645935s
    STEP: Saw pod success 11/12/22 12:08:24.41
    Nov 12 12:08:24.411: INFO: Pod "downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e" satisfied condition "Succeeded or Failed"
    Nov 12 12:08:24.418: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e container client-container: <nil>
    STEP: delete the pod 11/12/22 12:08:24.427
    Nov 12 12:08:24.443: INFO: Waiting for pod downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e to disappear
    Nov 12 12:08:24.447: INFO: Pod downwardapi-volume-50b1c2da-d37d-4c61-998f-a72303021e6e no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 12:08:24.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2322" for this suite. 11/12/22 12:08:24.459
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:08:24.472
Nov 12 12:08:24.472: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 12:08:24.473
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:24.5
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:24.506
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 11/12/22 12:08:24.509
STEP: Creating a ResourceQuota 11/12/22 12:08:29.516
STEP: Ensuring resource quota status is calculated 11/12/22 12:08:29.524
STEP: Creating a ReplicationController 11/12/22 12:08:31.53
STEP: Ensuring resource quota status captures replication controller creation 11/12/22 12:08:31.546
STEP: Deleting a ReplicationController 11/12/22 12:08:33.553
STEP: Ensuring resource quota status released usage 11/12/22 12:08:33.564
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 12:08:35.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7154" for this suite. 11/12/22 12:08:35.576
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":51,"skipped":1082,"failed":0}
------------------------------
• [SLOW TEST] [11.114 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:08:24.472
    Nov 12 12:08:24.472: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 12:08:24.473
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:24.5
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:24.506
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 11/12/22 12:08:24.509
    STEP: Creating a ResourceQuota 11/12/22 12:08:29.516
    STEP: Ensuring resource quota status is calculated 11/12/22 12:08:29.524
    STEP: Creating a ReplicationController 11/12/22 12:08:31.53
    STEP: Ensuring resource quota status captures replication controller creation 11/12/22 12:08:31.546
    STEP: Deleting a ReplicationController 11/12/22 12:08:33.553
    STEP: Ensuring resource quota status released usage 11/12/22 12:08:33.564
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 12:08:35.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7154" for this suite. 11/12/22 12:08:35.576
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:08:35.586
Nov 12 12:08:35.586: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 12:08:35.587
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:35.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:35.611
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-48fd7ad2-270b-456e-8334-0bc9eee05391 in namespace container-probe-8405 11/12/22 12:08:35.614
Nov 12 12:08:35.629: INFO: Waiting up to 5m0s for pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391" in namespace "container-probe-8405" to be "not pending"
Nov 12 12:08:35.636: INFO: Pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391": Phase="Pending", Reason="", readiness=false. Elapsed: 6.382719ms
Nov 12 12:08:37.642: INFO: Pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391": Phase="Running", Reason="", readiness=true. Elapsed: 2.012951239s
Nov 12 12:08:37.643: INFO: Pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391" satisfied condition "not pending"
Nov 12 12:08:37.643: INFO: Started pod liveness-48fd7ad2-270b-456e-8334-0bc9eee05391 in namespace container-probe-8405
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:08:37.643
Nov 12 12:08:37.647: INFO: Initial restart count of pod liveness-48fd7ad2-270b-456e-8334-0bc9eee05391 is 0
STEP: deleting the pod 11/12/22 12:12:38.406
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 12:12:38.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8405" for this suite. 11/12/22 12:12:38.431
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":52,"skipped":1082,"failed":0}
------------------------------
• [SLOW TEST] [242.855 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:08:35.586
    Nov 12 12:08:35.586: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 12:08:35.587
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:08:35.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:08:35.611
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-48fd7ad2-270b-456e-8334-0bc9eee05391 in namespace container-probe-8405 11/12/22 12:08:35.614
    Nov 12 12:08:35.629: INFO: Waiting up to 5m0s for pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391" in namespace "container-probe-8405" to be "not pending"
    Nov 12 12:08:35.636: INFO: Pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391": Phase="Pending", Reason="", readiness=false. Elapsed: 6.382719ms
    Nov 12 12:08:37.642: INFO: Pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391": Phase="Running", Reason="", readiness=true. Elapsed: 2.012951239s
    Nov 12 12:08:37.643: INFO: Pod "liveness-48fd7ad2-270b-456e-8334-0bc9eee05391" satisfied condition "not pending"
    Nov 12 12:08:37.643: INFO: Started pod liveness-48fd7ad2-270b-456e-8334-0bc9eee05391 in namespace container-probe-8405
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:08:37.643
    Nov 12 12:08:37.647: INFO: Initial restart count of pod liveness-48fd7ad2-270b-456e-8334-0bc9eee05391 is 0
    STEP: deleting the pod 11/12/22 12:12:38.406
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 12:12:38.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8405" for this suite. 11/12/22 12:12:38.431
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:12:38.442
Nov 12 12:12:38.442: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 12:12:38.443
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:12:38.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:12:38.467
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-a4404f42-15c0-4bda-84f3-3355d432c02f in namespace container-probe-9346 11/12/22 12:12:38.47
Nov 12 12:12:38.482: INFO: Waiting up to 5m0s for pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f" in namespace "container-probe-9346" to be "not pending"
Nov 12 12:12:38.491: INFO: Pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.012345ms
Nov 12 12:12:40.496: INFO: Pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f": Phase="Running", Reason="", readiness=true. Elapsed: 2.0142731s
Nov 12 12:12:40.496: INFO: Pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f" satisfied condition "not pending"
Nov 12 12:12:40.496: INFO: Started pod liveness-a4404f42-15c0-4bda-84f3-3355d432c02f in namespace container-probe-9346
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:12:40.496
Nov 12 12:12:40.501: INFO: Initial restart count of pod liveness-a4404f42-15c0-4bda-84f3-3355d432c02f is 0
Nov 12 12:13:00.566: INFO: Restart count of pod container-probe-9346/liveness-a4404f42-15c0-4bda-84f3-3355d432c02f is now 1 (20.064546411s elapsed)
STEP: deleting the pod 11/12/22 12:13:00.566
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 12:13:00.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9346" for this suite. 11/12/22 12:13:00.588
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":53,"skipped":1086,"failed":0}
------------------------------
• [SLOW TEST] [22.162 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:12:38.442
    Nov 12 12:12:38.442: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 12:12:38.443
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:12:38.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:12:38.467
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-a4404f42-15c0-4bda-84f3-3355d432c02f in namespace container-probe-9346 11/12/22 12:12:38.47
    Nov 12 12:12:38.482: INFO: Waiting up to 5m0s for pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f" in namespace "container-probe-9346" to be "not pending"
    Nov 12 12:12:38.491: INFO: Pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.012345ms
    Nov 12 12:12:40.496: INFO: Pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f": Phase="Running", Reason="", readiness=true. Elapsed: 2.0142731s
    Nov 12 12:12:40.496: INFO: Pod "liveness-a4404f42-15c0-4bda-84f3-3355d432c02f" satisfied condition "not pending"
    Nov 12 12:12:40.496: INFO: Started pod liveness-a4404f42-15c0-4bda-84f3-3355d432c02f in namespace container-probe-9346
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:12:40.496
    Nov 12 12:12:40.501: INFO: Initial restart count of pod liveness-a4404f42-15c0-4bda-84f3-3355d432c02f is 0
    Nov 12 12:13:00.566: INFO: Restart count of pod container-probe-9346/liveness-a4404f42-15c0-4bda-84f3-3355d432c02f is now 1 (20.064546411s elapsed)
    STEP: deleting the pod 11/12/22 12:13:00.566
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 12:13:00.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9346" for this suite. 11/12/22 12:13:00.588
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:00.605
Nov 12 12:13:00.605: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-pred 11/12/22 12:13:00.607
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:00.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:00.627
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 12 12:13:00.633: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 12 12:13:00.643: INFO: Waiting for terminating namespaces to be deleted...
Nov 12 12:13:00.646: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
Nov 12 12:13:00.653: INFO: nginx-ingress-controller-kubernetes-worker-vpz52 from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:20 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.653: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 12:13:00.653: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.653: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 12 12:13:00.653: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 12:13:00.653: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 12:13:00.653: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 12:13:00.653: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
Nov 12 12:13:00.661: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.661: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 12 12:13:00.661: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.661: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 12:13:00.661: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.662: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 12 12:13:00.662: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.662: INFO: 	Container coredns ready: true, restart count 0
Nov 12 12:13:00.662: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.662: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 12 12:13:00.662: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
Nov 12 12:13:00.662: INFO: 	Container metrics-server ready: true, restart count 0
Nov 12 12:13:00.662: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 12 12:13:00.662: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.662: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 12 12:13:00.662: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.662: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 12 12:13:00.662: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 12:13:00.662: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 12:13:00.662: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 12:13:00.662: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
Nov 12 12:13:00.668: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
Nov 12 12:13:00.668: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 12:13:00.669: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 12:13:00.669: INFO: 	Container e2e ready: true, restart count 0
Nov 12 12:13:00.669: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 12:13:00.669: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 12:13:00.669: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 12:13:00.669: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 11/12/22 12:13:00.669
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1726d53f7dcb7466], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 11/12/22 12:13:00.705
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:13:01.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3419" for this suite. 11/12/22 12:13:01.705
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":54,"skipped":1104,"failed":0}
------------------------------
• [1.113 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:00.605
    Nov 12 12:13:00.605: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-pred 11/12/22 12:13:00.607
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:00.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:00.627
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 12 12:13:00.633: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 12 12:13:00.643: INFO: Waiting for terminating namespaces to be deleted...
    Nov 12 12:13:00.646: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
    Nov 12 12:13:00.653: INFO: nginx-ingress-controller-kubernetes-worker-vpz52 from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:20 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.653: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 12:13:00.653: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.653: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 12 12:13:00.653: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 12:13:00.653: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 12:13:00.653: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 12:13:00.653: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
    Nov 12 12:13:00.661: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.661: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 12 12:13:00.661: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.661: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 12:13:00.661: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.662: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.662: INFO: 	Container coredns ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.662: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
    Nov 12 12:13:00.662: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.662: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.662: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 12:13:00.662: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 12:13:00.662: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
    Nov 12 12:13:00.668: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
    Nov 12 12:13:00.668: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 12:13:00.669: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 12:13:00.669: INFO: 	Container e2e ready: true, restart count 0
    Nov 12 12:13:00.669: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 12:13:00.669: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 12:13:00.669: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 12:13:00.669: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 11/12/22 12:13:00.669
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1726d53f7dcb7466], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 11/12/22 12:13:00.705
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:13:01.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3419" for this suite. 11/12/22 12:13:01.705
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:01.719
Nov 12 12:13:01.719: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename endpointslice 11/12/22 12:13:01.72
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:01.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:01.742
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Nov 12 12:13:01.767: INFO: Endpoints addresses: [172.31.30.106 172.31.95.4] , ports: [6443]
Nov 12 12:13:01.767: INFO: EndpointSlices addresses: [172.31.30.106 172.31.95.4] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 12 12:13:01.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-419" for this suite. 11/12/22 12:13:01.772
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":55,"skipped":1113,"failed":0}
------------------------------
• [0.062 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:01.719
    Nov 12 12:13:01.719: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename endpointslice 11/12/22 12:13:01.72
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:01.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:01.742
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Nov 12 12:13:01.767: INFO: Endpoints addresses: [172.31.30.106 172.31.95.4] , ports: [6443]
    Nov 12 12:13:01.767: INFO: EndpointSlices addresses: [172.31.30.106 172.31.95.4] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 12 12:13:01.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-419" for this suite. 11/12/22 12:13:01.772
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:01.782
Nov 12 12:13:01.782: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:13:01.783
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:01.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:01.822
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Nov 12 12:13:01.829: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:13:08.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3837" for this suite. 11/12/22 12:13:08.101
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":56,"skipped":1121,"failed":0}
------------------------------
• [SLOW TEST] [6.329 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:01.782
    Nov 12 12:13:01.782: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:13:01.783
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:01.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:01.822
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Nov 12 12:13:01.829: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:13:08.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3837" for this suite. 11/12/22 12:13:08.101
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:08.116
Nov 12 12:13:08.116: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename namespaces 11/12/22 12:13:08.116
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:08.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:08.14
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 11/12/22 12:13:08.143
Nov 12 12:13:08.150: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 11/12/22 12:13:08.15
Nov 12 12:13:08.159: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 11/12/22 12:13:08.16
Nov 12 12:13:08.172: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:13:08.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7044" for this suite. 11/12/22 12:13:08.179
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":57,"skipped":1148,"failed":0}
------------------------------
• [0.074 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:08.116
    Nov 12 12:13:08.116: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename namespaces 11/12/22 12:13:08.116
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:08.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:08.14
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 11/12/22 12:13:08.143
    Nov 12 12:13:08.150: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 11/12/22 12:13:08.15
    Nov 12 12:13:08.159: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 11/12/22 12:13:08.16
    Nov 12 12:13:08.172: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:13:08.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7044" for this suite. 11/12/22 12:13:08.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:08.192
Nov 12 12:13:08.192: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:13:08.193
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:08.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:08.219
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 11/12/22 12:13:08.221
Nov 12 12:13:08.234: INFO: Waiting up to 5m0s for pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de" in namespace "emptydir-3892" to be "Succeeded or Failed"
Nov 12 12:13:08.243: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054828ms
Nov 12 12:13:10.249: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013914225s
Nov 12 12:13:12.250: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015026282s
Nov 12 12:13:14.248: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013763378s
STEP: Saw pod success 11/12/22 12:13:14.248
Nov 12 12:13:14.248: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de" satisfied condition "Succeeded or Failed"
Nov 12 12:13:14.253: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de container test-container: <nil>
STEP: delete the pod 11/12/22 12:13:14.274
Nov 12 12:13:14.289: INFO: Waiting for pod pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de to disappear
Nov 12 12:13:14.293: INFO: Pod pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:13:14.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3892" for this suite. 11/12/22 12:13:14.297
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":58,"skipped":1182,"failed":0}
------------------------------
• [SLOW TEST] [6.114 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:08.192
    Nov 12 12:13:08.192: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:13:08.193
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:08.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:08.219
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/12/22 12:13:08.221
    Nov 12 12:13:08.234: INFO: Waiting up to 5m0s for pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de" in namespace "emptydir-3892" to be "Succeeded or Failed"
    Nov 12 12:13:08.243: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054828ms
    Nov 12 12:13:10.249: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013914225s
    Nov 12 12:13:12.250: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015026282s
    Nov 12 12:13:14.248: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013763378s
    STEP: Saw pod success 11/12/22 12:13:14.248
    Nov 12 12:13:14.248: INFO: Pod "pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de" satisfied condition "Succeeded or Failed"
    Nov 12 12:13:14.253: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de container test-container: <nil>
    STEP: delete the pod 11/12/22 12:13:14.274
    Nov 12 12:13:14.289: INFO: Waiting for pod pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de to disappear
    Nov 12 12:13:14.293: INFO: Pod pod-29d0b18b-9a5d-4729-8370-7b3e10aae8de no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:13:14.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3892" for this suite. 11/12/22 12:13:14.297
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:14.306
Nov 12 12:13:14.306: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:13:14.307
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:14.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:14.326
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 11/12/22 12:13:14.329
Nov 12 12:13:14.341: INFO: Waiting up to 5m0s for pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d" in namespace "emptydir-747" to be "Succeeded or Failed"
Nov 12 12:13:14.344: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.570997ms
Nov 12 12:13:16.353: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012353611s
Nov 12 12:13:18.350: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009216393s
STEP: Saw pod success 11/12/22 12:13:18.35
Nov 12 12:13:18.350: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d" satisfied condition "Succeeded or Failed"
Nov 12 12:13:18.355: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-f644d799-184b-4b64-ba43-9e6d35948e9d container test-container: <nil>
STEP: delete the pod 11/12/22 12:13:18.366
Nov 12 12:13:18.382: INFO: Waiting for pod pod-f644d799-184b-4b64-ba43-9e6d35948e9d to disappear
Nov 12 12:13:18.387: INFO: Pod pod-f644d799-184b-4b64-ba43-9e6d35948e9d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:13:18.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-747" for this suite. 11/12/22 12:13:18.394
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":59,"skipped":1183,"failed":0}
------------------------------
• [4.109 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:14.306
    Nov 12 12:13:14.306: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:13:14.307
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:14.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:14.326
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 11/12/22 12:13:14.329
    Nov 12 12:13:14.341: INFO: Waiting up to 5m0s for pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d" in namespace "emptydir-747" to be "Succeeded or Failed"
    Nov 12 12:13:14.344: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.570997ms
    Nov 12 12:13:16.353: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012353611s
    Nov 12 12:13:18.350: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009216393s
    STEP: Saw pod success 11/12/22 12:13:18.35
    Nov 12 12:13:18.350: INFO: Pod "pod-f644d799-184b-4b64-ba43-9e6d35948e9d" satisfied condition "Succeeded or Failed"
    Nov 12 12:13:18.355: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-f644d799-184b-4b64-ba43-9e6d35948e9d container test-container: <nil>
    STEP: delete the pod 11/12/22 12:13:18.366
    Nov 12 12:13:18.382: INFO: Waiting for pod pod-f644d799-184b-4b64-ba43-9e6d35948e9d to disappear
    Nov 12 12:13:18.387: INFO: Pod pod-f644d799-184b-4b64-ba43-9e6d35948e9d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:13:18.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-747" for this suite. 11/12/22 12:13:18.394
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:18.417
Nov 12 12:13:18.417: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:13:18.419
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:18.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:18.449
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Nov 12 12:13:18.452: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:13:19.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1348" for this suite. 11/12/22 12:13:19.491
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":60,"skipped":1190,"failed":0}
------------------------------
• [1.095 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:18.417
    Nov 12 12:13:18.417: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:13:18.419
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:18.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:18.449
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Nov 12 12:13:18.452: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:13:19.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1348" for this suite. 11/12/22 12:13:19.491
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:19.513
Nov 12 12:13:19.513: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replication-controller 11/12/22 12:13:19.514
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:19.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:19.547
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 11/12/22 12:13:19.589
Nov 12 12:13:19.605: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7549" to be "running and ready"
Nov 12 12:13:19.614: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 8.616434ms
Nov 12 12:13:19.614: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:13:21.620: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.014931911s
Nov 12 12:13:21.620: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Nov 12 12:13:21.620: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 11/12/22 12:13:21.624
STEP: Then the orphan pod is adopted 11/12/22 12:13:21.631
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 12:13:22.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7549" for this suite. 11/12/22 12:13:22.646
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":61,"skipped":1213,"failed":0}
------------------------------
• [3.142 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:19.513
    Nov 12 12:13:19.513: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replication-controller 11/12/22 12:13:19.514
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:19.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:19.547
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 11/12/22 12:13:19.589
    Nov 12 12:13:19.605: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7549" to be "running and ready"
    Nov 12 12:13:19.614: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 8.616434ms
    Nov 12 12:13:19.614: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:13:21.620: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.014931911s
    Nov 12 12:13:21.620: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Nov 12 12:13:21.620: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 11/12/22 12:13:21.624
    STEP: Then the orphan pod is adopted 11/12/22 12:13:21.631
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 12:13:22.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7549" for this suite. 11/12/22 12:13:22.646
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:22.661
Nov 12 12:13:22.661: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:13:22.662
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:22.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:22.692
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:13:22.72
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:13:23.357
STEP: Deploying the webhook pod 11/12/22 12:13:23.368
STEP: Wait for the deployment to be ready 11/12/22 12:13:23.384
Nov 12 12:13:23.405: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:13:25.419
STEP: Verifying the service has paired with the endpoint 11/12/22 12:13:25.441
Nov 12 12:13:26.441: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 11/12/22 12:13:26.446
STEP: create a pod 11/12/22 12:13:26.469
Nov 12 12:13:26.478: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2145" to be "running"
Nov 12 12:13:26.484: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.064486ms
Nov 12 12:13:28.490: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012557327s
Nov 12 12:13:28.490: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 11/12/22 12:13:28.49
Nov 12 12:13:28.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=webhook-2145 attach --namespace=webhook-2145 to-be-attached-pod -i -c=container1'
Nov 12 12:13:28.598: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:13:28.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2145" for this suite. 11/12/22 12:13:28.613
STEP: Destroying namespace "webhook-2145-markers" for this suite. 11/12/22 12:13:28.622
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":62,"skipped":1296,"failed":0}
------------------------------
• [SLOW TEST] [6.033 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:22.661
    Nov 12 12:13:22.661: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:13:22.662
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:22.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:22.692
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:13:22.72
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:13:23.357
    STEP: Deploying the webhook pod 11/12/22 12:13:23.368
    STEP: Wait for the deployment to be ready 11/12/22 12:13:23.384
    Nov 12 12:13:23.405: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:13:25.419
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:13:25.441
    Nov 12 12:13:26.441: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 11/12/22 12:13:26.446
    STEP: create a pod 11/12/22 12:13:26.469
    Nov 12 12:13:26.478: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-2145" to be "running"
    Nov 12 12:13:26.484: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.064486ms
    Nov 12 12:13:28.490: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012557327s
    Nov 12 12:13:28.490: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 11/12/22 12:13:28.49
    Nov 12 12:13:28.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=webhook-2145 attach --namespace=webhook-2145 to-be-attached-pod -i -c=container1'
    Nov 12 12:13:28.598: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:13:28.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2145" for this suite. 11/12/22 12:13:28.613
    STEP: Destroying namespace "webhook-2145-markers" for this suite. 11/12/22 12:13:28.622
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:28.706
Nov 12 12:13:28.706: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sysctl 11/12/22 12:13:28.707
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:28.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:28.757
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 11/12/22 12:13:28.76
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 12:13:28.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-4014" for this suite. 11/12/22 12:13:28.774
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":63,"skipped":1298,"failed":0}
------------------------------
• [0.079 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:28.706
    Nov 12 12:13:28.706: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sysctl 11/12/22 12:13:28.707
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:28.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:28.757
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 11/12/22 12:13:28.76
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 12:13:28.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-4014" for this suite. 11/12/22 12:13:28.774
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:28.791
Nov 12 12:13:28.791: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 12:13:28.792
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:28.809
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:28.814
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-96e20d5d-e71d-4a86-86b1-4f6acc578b89 11/12/22 12:13:28.817
STEP: Creating a pod to test consume configMaps 11/12/22 12:13:28.828
Nov 12 12:13:28.841: INFO: Waiting up to 5m0s for pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9" in namespace "configmap-4243" to be "Succeeded or Failed"
Nov 12 12:13:28.847: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.692846ms
Nov 12 12:13:30.854: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012986244s
Nov 12 12:13:32.853: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011870582s
STEP: Saw pod success 11/12/22 12:13:32.853
Nov 12 12:13:32.854: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9" satisfied condition "Succeeded or Failed"
Nov 12 12:13:32.859: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9 container configmap-volume-test: <nil>
STEP: delete the pod 11/12/22 12:13:32.867
Nov 12 12:13:32.889: INFO: Waiting for pod pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9 to disappear
Nov 12 12:13:32.896: INFO: Pod pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 12:13:32.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4243" for this suite. 11/12/22 12:13:32.902
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":64,"skipped":1369,"failed":0}
------------------------------
• [4.121 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:28.791
    Nov 12 12:13:28.791: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 12:13:28.792
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:28.809
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:28.814
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-96e20d5d-e71d-4a86-86b1-4f6acc578b89 11/12/22 12:13:28.817
    STEP: Creating a pod to test consume configMaps 11/12/22 12:13:28.828
    Nov 12 12:13:28.841: INFO: Waiting up to 5m0s for pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9" in namespace "configmap-4243" to be "Succeeded or Failed"
    Nov 12 12:13:28.847: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.692846ms
    Nov 12 12:13:30.854: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012986244s
    Nov 12 12:13:32.853: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011870582s
    STEP: Saw pod success 11/12/22 12:13:32.853
    Nov 12 12:13:32.854: INFO: Pod "pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9" satisfied condition "Succeeded or Failed"
    Nov 12 12:13:32.859: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9 container configmap-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:13:32.867
    Nov 12 12:13:32.889: INFO: Waiting for pod pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9 to disappear
    Nov 12 12:13:32.896: INFO: Pod pod-configmaps-93dabe71-8432-44f7-8911-c236bbc12fd9 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 12:13:32.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4243" for this suite. 11/12/22 12:13:32.902
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:32.916
Nov 12 12:13:32.916: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename daemonsets 11/12/22 12:13:32.917
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:32.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:32.954
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 11/12/22 12:13:32.994
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:13:33.004
Nov 12 12:13:33.009: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:13:33.009: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:13:33.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:13:33.015: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:13:34.027: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:13:34.027: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:13:34.034: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:13:34.034: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:13:35.020: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:13:35.020: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:13:35.025: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 12:13:35.025: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 11/12/22 12:13:35.029
Nov 12 12:13:35.033: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 11/12/22 12:13:35.034
Nov 12 12:13:35.045: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 11/12/22 12:13:35.045
Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: ADDED
Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.048: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.048: INFO: Found daemon set daemon-set in namespace daemonsets-4023 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 12 12:13:35.048: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 11/12/22 12:13:35.048
STEP: watching for the daemon set status to be patched 11/12/22 12:13:35.055
Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: ADDED
Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.057: INFO: Observed daemon set daemon-set in namespace daemonsets-4023 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
Nov 12 12:13:35.057: INFO: Found daemon set daemon-set in namespace daemonsets-4023 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Nov 12 12:13:35.057: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:13:35.064
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4023, will wait for the garbage collector to delete the pods 11/12/22 12:13:35.064
Nov 12 12:13:35.136: INFO: Deleting DaemonSet.extensions daemon-set took: 16.885289ms
Nov 12 12:13:35.236: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.37092ms
Nov 12 12:13:38.042: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:13:38.042: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 12 12:13:38.049: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9012"},"items":null}

Nov 12 12:13:38.054: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9012"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:13:38.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4023" for this suite. 11/12/22 12:13:38.083
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":65,"skipped":1404,"failed":0}
------------------------------
• [SLOW TEST] [5.176 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:32.916
    Nov 12 12:13:32.916: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename daemonsets 11/12/22 12:13:32.917
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:32.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:32.954
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 11/12/22 12:13:32.994
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:13:33.004
    Nov 12 12:13:33.009: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:13:33.009: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:13:33.015: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:13:33.015: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:13:34.027: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:13:34.027: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:13:34.034: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:13:34.034: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:13:35.020: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:13:35.020: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:13:35.025: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 12:13:35.025: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 11/12/22 12:13:35.029
    Nov 12 12:13:35.033: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 11/12/22 12:13:35.034
    Nov 12 12:13:35.045: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 11/12/22 12:13:35.045
    Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: ADDED
    Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.047: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.048: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.048: INFO: Found daemon set daemon-set in namespace daemonsets-4023 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 12 12:13:35.048: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 11/12/22 12:13:35.048
    STEP: watching for the daemon set status to be patched 11/12/22 12:13:35.055
    Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: ADDED
    Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.057: INFO: Observed daemon set daemon-set in namespace daemonsets-4023 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 12 12:13:35.057: INFO: Observed &DaemonSet event: MODIFIED
    Nov 12 12:13:35.057: INFO: Found daemon set daemon-set in namespace daemonsets-4023 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Nov 12 12:13:35.057: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:13:35.064
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4023, will wait for the garbage collector to delete the pods 11/12/22 12:13:35.064
    Nov 12 12:13:35.136: INFO: Deleting DaemonSet.extensions daemon-set took: 16.885289ms
    Nov 12 12:13:35.236: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.37092ms
    Nov 12 12:13:38.042: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:13:38.042: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 12 12:13:38.049: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9012"},"items":null}

    Nov 12 12:13:38.054: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9012"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:13:38.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4023" for this suite. 11/12/22 12:13:38.083
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:38.093
Nov 12 12:13:38.094: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename watch 11/12/22 12:13:38.094
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:38.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:38.119
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 11/12/22 12:13:38.121
STEP: creating a new configmap 11/12/22 12:13:38.122
STEP: modifying the configmap once 11/12/22 12:13:38.138
STEP: closing the watch once it receives two notifications 11/12/22 12:13:38.151
Nov 12 12:13:38.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9019 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:13:38.152: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9020 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 11/12/22 12:13:38.152
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/12/22 12:13:38.163
STEP: deleting the configmap 11/12/22 12:13:38.165
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/12/22 12:13:38.173
Nov 12 12:13:38.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9021 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:13:38.174: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9022 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 12:13:38.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7953" for this suite. 11/12/22 12:13:38.184
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":66,"skipped":1411,"failed":0}
------------------------------
• [0.099 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:38.093
    Nov 12 12:13:38.094: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename watch 11/12/22 12:13:38.094
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:38.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:38.119
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 11/12/22 12:13:38.121
    STEP: creating a new configmap 11/12/22 12:13:38.122
    STEP: modifying the configmap once 11/12/22 12:13:38.138
    STEP: closing the watch once it receives two notifications 11/12/22 12:13:38.151
    Nov 12 12:13:38.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9019 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:13:38.152: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9020 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 11/12/22 12:13:38.152
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/12/22 12:13:38.163
    STEP: deleting the configmap 11/12/22 12:13:38.165
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/12/22 12:13:38.173
    Nov 12 12:13:38.174: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9021 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:13:38.174: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7953  6cb37a7f-c0d8-43ae-93de-551559eaf623 9022 0 2022-11-12 12:13:38 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-12 12:13:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 12:13:38.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7953" for this suite. 11/12/22 12:13:38.184
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:38.195
Nov 12 12:13:38.195: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:13:38.196
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:38.214
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:38.218
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-78cab668-6fef-4a65-9888-dd0917d17d3c 11/12/22 12:13:38.22
STEP: Creating a pod to test consume secrets 11/12/22 12:13:38.227
Nov 12 12:13:38.238: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c" in namespace "projected-7435" to be "Succeeded or Failed"
Nov 12 12:13:38.249: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.31642ms
Nov 12 12:13:40.254: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016194814s
Nov 12 12:13:42.256: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017490729s
STEP: Saw pod success 11/12/22 12:13:42.256
Nov 12 12:13:42.256: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c" satisfied condition "Succeeded or Failed"
Nov 12 12:13:42.260: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c container projected-secret-volume-test: <nil>
STEP: delete the pod 11/12/22 12:13:42.269
Nov 12 12:13:42.288: INFO: Waiting for pod pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c to disappear
Nov 12 12:13:42.293: INFO: Pod pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 12:13:42.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7435" for this suite. 11/12/22 12:13:42.298
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":67,"skipped":1423,"failed":0}
------------------------------
• [4.112 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:38.195
    Nov 12 12:13:38.195: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:13:38.196
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:38.214
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:38.218
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-78cab668-6fef-4a65-9888-dd0917d17d3c 11/12/22 12:13:38.22
    STEP: Creating a pod to test consume secrets 11/12/22 12:13:38.227
    Nov 12 12:13:38.238: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c" in namespace "projected-7435" to be "Succeeded or Failed"
    Nov 12 12:13:38.249: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.31642ms
    Nov 12 12:13:40.254: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016194814s
    Nov 12 12:13:42.256: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017490729s
    STEP: Saw pod success 11/12/22 12:13:42.256
    Nov 12 12:13:42.256: INFO: Pod "pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c" satisfied condition "Succeeded or Failed"
    Nov 12 12:13:42.260: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:13:42.269
    Nov 12 12:13:42.288: INFO: Waiting for pod pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c to disappear
    Nov 12 12:13:42.293: INFO: Pod pod-projected-secrets-8e304d1b-c468-4a29-9356-510fd6a33b3c no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 12:13:42.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7435" for this suite. 11/12/22 12:13:42.298
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:42.308
Nov 12 12:13:42.308: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename security-context-test 11/12/22 12:13:42.309
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:42.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:42.331
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Nov 12 12:13:42.348: INFO: Waiting up to 5m0s for pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10" in namespace "security-context-test-4520" to be "Succeeded or Failed"
Nov 12 12:13:42.356: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10": Phase="Pending", Reason="", readiness=false. Elapsed: 7.698577ms
Nov 12 12:13:44.362: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013923457s
Nov 12 12:13:46.361: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013419192s
Nov 12 12:13:46.361: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 12:13:46.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4520" for this suite. 11/12/22 12:13:46.366
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":68,"skipped":1430,"failed":0}
------------------------------
• [4.069 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:42.308
    Nov 12 12:13:42.308: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename security-context-test 11/12/22 12:13:42.309
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:42.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:42.331
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Nov 12 12:13:42.348: INFO: Waiting up to 5m0s for pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10" in namespace "security-context-test-4520" to be "Succeeded or Failed"
    Nov 12 12:13:42.356: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10": Phase="Pending", Reason="", readiness=false. Elapsed: 7.698577ms
    Nov 12 12:13:44.362: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013923457s
    Nov 12 12:13:46.361: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013419192s
    Nov 12 12:13:46.361: INFO: Pod "busybox-user-65534-1092ff7d-d9d7-472c-8c15-16a7d7e98f10" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 12:13:46.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4520" for this suite. 11/12/22 12:13:46.366
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:46.381
Nov 12 12:13:46.381: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename proxy 11/12/22 12:13:46.382
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:46.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:46.413
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 11/12/22 12:13:46.448
STEP: creating replication controller proxy-service-pt59b in namespace proxy-1766 11/12/22 12:13:46.449
I1112 12:13:46.469329      19 runners.go:193] Created replication controller with name: proxy-service-pt59b, namespace: proxy-1766, replica count: 1
I1112 12:13:47.520979      19 runners.go:193] proxy-service-pt59b Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1112 12:13:48.521068      19 runners.go:193] proxy-service-pt59b Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 12:13:48.526: INFO: setup took 2.108171219s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/12/22 12:13:48.526
Nov 12 12:13:48.533: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 7.238945ms)
Nov 12 12:13:48.534: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 7.065916ms)
Nov 12 12:13:48.535: INFO: (0) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 8.018972ms)
Nov 12 12:13:48.535: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 8.189366ms)
Nov 12 12:13:48.536: INFO: (0) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.162107ms)
Nov 12 12:13:48.537: INFO: (0) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 10.430407ms)
Nov 12 12:13:48.539: INFO: (0) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 12.269658ms)
Nov 12 12:13:48.542: INFO: (0) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 14.796154ms)
Nov 12 12:13:48.542: INFO: (0) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 14.61517ms)
Nov 12 12:13:48.542: INFO: (0) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 15.101765ms)
Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 15.846332ms)
Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 16.375177ms)
Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 16.014411ms)
Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 16.803095ms)
Nov 12 12:13:48.547: INFO: (0) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 19.741647ms)
Nov 12 12:13:48.548: INFO: (0) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 20.594083ms)
Nov 12 12:13:48.554: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 6.380202ms)
Nov 12 12:13:48.556: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 8.047438ms)
Nov 12 12:13:48.557: INFO: (1) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 9.067086ms)
Nov 12 12:13:48.559: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 10.808652ms)
Nov 12 12:13:48.560: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.268782ms)
Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 12.700671ms)
Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 13.032987ms)
Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 12.832266ms)
Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 12.604688ms)
Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 12.989784ms)
Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.028141ms)
Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 13.015833ms)
Nov 12 12:13:48.562: INFO: (1) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.992289ms)
Nov 12 12:13:48.562: INFO: (1) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 13.816788ms)
Nov 12 12:13:48.565: INFO: (1) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 16.684288ms)
Nov 12 12:13:48.566: INFO: (1) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 17.591825ms)
Nov 12 12:13:48.572: INFO: (2) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 5.977141ms)
Nov 12 12:13:48.573: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 6.797304ms)
Nov 12 12:13:48.575: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.084977ms)
Nov 12 12:13:48.576: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 9.587138ms)
Nov 12 12:13:48.576: INFO: (2) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 10.075723ms)
Nov 12 12:13:48.576: INFO: (2) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 9.965019ms)
Nov 12 12:13:48.577: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 10.113922ms)
Nov 12 12:13:48.579: INFO: (2) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 13.270105ms)
Nov 12 12:13:48.579: INFO: (2) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 13.385874ms)
Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 13.464586ms)
Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 13.471599ms)
Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 13.622076ms)
Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 13.773863ms)
Nov 12 12:13:48.585: INFO: (2) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 18.908367ms)
Nov 12 12:13:48.585: INFO: (2) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 18.978917ms)
Nov 12 12:13:48.585: INFO: (2) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 18.940446ms)
Nov 12 12:13:48.591: INFO: (3) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 5.522481ms)
Nov 12 12:13:48.595: INFO: (3) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 9.651854ms)
Nov 12 12:13:48.595: INFO: (3) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.750889ms)
Nov 12 12:13:48.596: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 10.247697ms)
Nov 12 12:13:48.596: INFO: (3) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 10.56433ms)
Nov 12 12:13:48.597: INFO: (3) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 10.90928ms)
Nov 12 12:13:48.597: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.188973ms)
Nov 12 12:13:48.598: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.368109ms)
Nov 12 12:13:48.598: INFO: (3) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 12.891837ms)
Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 13.220827ms)
Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 13.574369ms)
Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 13.602659ms)
Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 13.687836ms)
Nov 12 12:13:48.600: INFO: (3) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.955575ms)
Nov 12 12:13:48.601: INFO: (3) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 15.044343ms)
Nov 12 12:13:48.602: INFO: (3) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 16.278192ms)
Nov 12 12:13:48.615: INFO: (4) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 12.087589ms)
Nov 12 12:13:48.615: INFO: (4) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.248403ms)
Nov 12 12:13:48.615: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.442629ms)
Nov 12 12:13:48.616: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 14.058382ms)
Nov 12 12:13:48.618: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 15.423303ms)
Nov 12 12:13:48.618: INFO: (4) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 15.465342ms)
Nov 12 12:13:48.619: INFO: (4) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 15.958328ms)
Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 17.689115ms)
Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 17.670709ms)
Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 17.999366ms)
Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 17.619119ms)
Nov 12 12:13:48.622: INFO: (4) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 18.843527ms)
Nov 12 12:13:48.622: INFO: (4) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 19.130784ms)
Nov 12 12:13:48.623: INFO: (4) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 20.391943ms)
Nov 12 12:13:48.623: INFO: (4) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.089601ms)
Nov 12 12:13:48.637: INFO: (4) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 34.458766ms)
Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 25.217734ms)
Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 25.172749ms)
Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 25.330324ms)
Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 25.405456ms)
Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 25.695185ms)
Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 25.654824ms)
Nov 12 12:13:48.664: INFO: (5) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 26.33877ms)
Nov 12 12:13:48.665: INFO: (5) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 26.24813ms)
Nov 12 12:13:48.665: INFO: (5) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 26.673771ms)
Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 28.040811ms)
Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 29.024936ms)
Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 28.994471ms)
Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 29.508606ms)
Nov 12 12:13:48.668: INFO: (5) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 29.175414ms)
Nov 12 12:13:48.668: INFO: (5) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 29.331184ms)
Nov 12 12:13:48.668: INFO: (5) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 29.794628ms)
Nov 12 12:13:48.680: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 11.28933ms)
Nov 12 12:13:48.683: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.12671ms)
Nov 12 12:13:48.683: INFO: (6) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.555334ms)
Nov 12 12:13:48.686: INFO: (6) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 17.324618ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 21.798044ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 21.55296ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 21.733344ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 21.806426ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 21.938258ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 22.64501ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 22.48729ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 22.073017ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 22.148665ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 22.284223ms)
Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 22.354179ms)
Nov 12 12:13:48.694: INFO: (6) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 25.296306ms)
Nov 12 12:13:48.704: INFO: (7) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.303216ms)
Nov 12 12:13:48.705: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 10.63609ms)
Nov 12 12:13:48.706: INFO: (7) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.134267ms)
Nov 12 12:13:48.707: INFO: (7) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 12.669261ms)
Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 15.980967ms)
Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 16.06161ms)
Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 15.941681ms)
Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 15.819312ms)
Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 16.066014ms)
Nov 12 12:13:48.712: INFO: (7) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 17.256058ms)
Nov 12 12:13:48.712: INFO: (7) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 17.416847ms)
Nov 12 12:13:48.712: INFO: (7) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 17.62547ms)
Nov 12 12:13:48.713: INFO: (7) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 18.306397ms)
Nov 12 12:13:48.714: INFO: (7) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 18.97107ms)
Nov 12 12:13:48.714: INFO: (7) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 19.121415ms)
Nov 12 12:13:48.719: INFO: (7) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 23.485517ms)
Nov 12 12:13:48.732: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.429224ms)
Nov 12 12:13:48.732: INFO: (8) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.514798ms)
Nov 12 12:13:48.739: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 20.47555ms)
Nov 12 12:13:48.739: INFO: (8) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 20.1994ms)
Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 21.233486ms)
Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 21.341547ms)
Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 21.088744ms)
Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 21.130292ms)
Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.566665ms)
Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 21.596713ms)
Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 21.687312ms)
Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 21.672983ms)
Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 21.718624ms)
Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 21.922106ms)
Nov 12 12:13:48.742: INFO: (8) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 22.501571ms)
Nov 12 12:13:48.742: INFO: (8) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 22.88426ms)
Nov 12 12:13:48.754: INFO: (9) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.787504ms)
Nov 12 12:13:48.754: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 11.924801ms)
Nov 12 12:13:48.754: INFO: (9) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 11.853906ms)
Nov 12 12:13:48.755: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 12.050739ms)
Nov 12 12:13:48.755: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 12.420713ms)
Nov 12 12:13:48.758: INFO: (9) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 14.970696ms)
Nov 12 12:13:48.759: INFO: (9) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 16.358583ms)
Nov 12 12:13:48.760: INFO: (9) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 18.244514ms)
Nov 12 12:13:48.761: INFO: (9) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 18.021368ms)
Nov 12 12:13:48.761: INFO: (9) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 18.571253ms)
Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 21.14923ms)
Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 21.579545ms)
Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 22.262496ms)
Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 21.861786ms)
Nov 12 12:13:48.765: INFO: (9) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 22.846018ms)
Nov 12 12:13:48.767: INFO: (9) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 23.999089ms)
Nov 12 12:13:48.780: INFO: (10) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 12.74089ms)
Nov 12 12:13:48.782: INFO: (10) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 14.887055ms)
Nov 12 12:13:48.782: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.873618ms)
Nov 12 12:13:48.786: INFO: (10) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 18.974495ms)
Nov 12 12:13:48.786: INFO: (10) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 19.146207ms)
Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 19.327464ms)
Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 19.814611ms)
Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 19.744451ms)
Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 19.549836ms)
Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 19.789646ms)
Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 19.923017ms)
Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 20.067338ms)
Nov 12 12:13:48.788: INFO: (10) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 21.103428ms)
Nov 12 12:13:48.789: INFO: (10) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 21.672844ms)
Nov 12 12:13:48.789: INFO: (10) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 21.701251ms)
Nov 12 12:13:48.790: INFO: (10) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 23.056983ms)
Nov 12 12:13:48.796: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 5.825127ms)
Nov 12 12:13:48.803: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.229645ms)
Nov 12 12:13:48.804: INFO: (11) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 12.692369ms)
Nov 12 12:13:48.804: INFO: (11) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.81522ms)
Nov 12 12:13:48.807: INFO: (11) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 15.668307ms)
Nov 12 12:13:48.809: INFO: (11) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 17.149106ms)
Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 20.41104ms)
Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 19.811511ms)
Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 20.404489ms)
Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 19.663851ms)
Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.452908ms)
Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 20.023826ms)
Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 21.129348ms)
Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 21.508888ms)
Nov 12 12:13:48.813: INFO: (11) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 21.795698ms)
Nov 12 12:13:48.814: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 21.635216ms)
Nov 12 12:13:48.821: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 6.836617ms)
Nov 12 12:13:48.825: INFO: (12) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 10.770728ms)
Nov 12 12:13:48.827: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.865213ms)
Nov 12 12:13:48.827: INFO: (12) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 12.57114ms)
Nov 12 12:13:48.830: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 15.606341ms)
Nov 12 12:13:48.831: INFO: (12) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 16.940793ms)
Nov 12 12:13:48.831: INFO: (12) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 16.502939ms)
Nov 12 12:13:48.832: INFO: (12) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 17.6555ms)
Nov 12 12:13:48.833: INFO: (12) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 18.866654ms)
Nov 12 12:13:48.838: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 23.778095ms)
Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 25.685548ms)
Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 24.956335ms)
Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 25.255532ms)
Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 25.100269ms)
Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 25.75788ms)
Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 25.310101ms)
Nov 12 12:13:48.850: INFO: (13) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.552445ms)
Nov 12 12:13:48.851: INFO: (13) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 10.549098ms)
Nov 12 12:13:48.852: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 11.699444ms)
Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 13.495849ms)
Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 13.774082ms)
Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.888224ms)
Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 14.072988ms)
Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 14.215814ms)
Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.143307ms)
Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 14.158798ms)
Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 14.651441ms)
Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 14.888046ms)
Nov 12 12:13:48.857: INFO: (13) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 16.53235ms)
Nov 12 12:13:48.857: INFO: (13) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 16.828153ms)
Nov 12 12:13:48.858: INFO: (13) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 17.41735ms)
Nov 12 12:13:48.860: INFO: (13) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 19.595119ms)
Nov 12 12:13:48.873: INFO: (14) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 13.183599ms)
Nov 12 12:13:48.874: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 13.194562ms)
Nov 12 12:13:48.873: INFO: (14) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.728822ms)
Nov 12 12:13:48.874: INFO: (14) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 13.032702ms)
Nov 12 12:13:48.875: INFO: (14) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 13.80597ms)
Nov 12 12:13:48.879: INFO: (14) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 18.274389ms)
Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 20.160254ms)
Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 20.14397ms)
Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 21.27811ms)
Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 21.335956ms)
Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 20.515303ms)
Nov 12 12:13:48.882: INFO: (14) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 20.796554ms)
Nov 12 12:13:48.885: INFO: (14) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 24.73493ms)
Nov 12 12:13:48.887: INFO: (14) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 27.028327ms)
Nov 12 12:13:48.889: INFO: (14) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 28.29495ms)
Nov 12 12:13:48.892: INFO: (14) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 31.340022ms)
Nov 12 12:13:48.899: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 5.85869ms)
Nov 12 12:13:48.900: INFO: (15) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 8.417024ms)
Nov 12 12:13:48.900: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 7.77964ms)
Nov 12 12:13:48.900: INFO: (15) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 7.855928ms)
Nov 12 12:13:48.901: INFO: (15) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 9.648331ms)
Nov 12 12:13:48.902: INFO: (15) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 9.068488ms)
Nov 12 12:13:48.903: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.078079ms)
Nov 12 12:13:48.904: INFO: (15) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 11.272683ms)
Nov 12 12:13:48.904: INFO: (15) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.409081ms)
Nov 12 12:13:48.905: INFO: (15) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 12.105329ms)
Nov 12 12:13:48.905: INFO: (15) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 13.143013ms)
Nov 12 12:13:48.906: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 13.947594ms)
Nov 12 12:13:48.907: INFO: (15) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 15.59256ms)
Nov 12 12:13:48.909: INFO: (15) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 17.573383ms)
Nov 12 12:13:48.914: INFO: (15) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 21.171052ms)
Nov 12 12:13:48.914: INFO: (15) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.386571ms)
Nov 12 12:13:48.920: INFO: (16) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 5.350811ms)
Nov 12 12:13:48.921: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 6.466693ms)
Nov 12 12:13:48.923: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 8.063786ms)
Nov 12 12:13:48.924: INFO: (16) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 9.363336ms)
Nov 12 12:13:48.926: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 10.832922ms)
Nov 12 12:13:48.926: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 11.525832ms)
Nov 12 12:13:48.926: INFO: (16) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.737353ms)
Nov 12 12:13:48.928: INFO: (16) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 13.647612ms)
Nov 12 12:13:48.931: INFO: (16) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 16.118383ms)
Nov 12 12:13:48.931: INFO: (16) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 16.101832ms)
Nov 12 12:13:48.931: INFO: (16) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 16.698076ms)
Nov 12 12:13:48.934: INFO: (16) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 18.672679ms)
Nov 12 12:13:48.934: INFO: (16) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 19.239638ms)
Nov 12 12:13:48.934: INFO: (16) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 19.76448ms)
Nov 12 12:13:48.937: INFO: (16) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 22.154834ms)
Nov 12 12:13:48.938: INFO: (16) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 23.117748ms)
Nov 12 12:13:48.947: INFO: (17) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 8.706625ms)
Nov 12 12:13:48.948: INFO: (17) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.908535ms)
Nov 12 12:13:48.949: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.981101ms)
Nov 12 12:13:48.949: INFO: (17) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 10.743735ms)
Nov 12 12:13:48.950: INFO: (17) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 11.129339ms)
Nov 12 12:13:48.951: INFO: (17) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 12.523513ms)
Nov 12 12:13:48.951: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.900636ms)
Nov 12 12:13:48.952: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 12.831472ms)
Nov 12 12:13:48.952: INFO: (17) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 13.313845ms)
Nov 12 12:13:48.952: INFO: (17) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 14.222213ms)
Nov 12 12:13:48.954: INFO: (17) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 15.357583ms)
Nov 12 12:13:48.954: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 15.404199ms)
Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 16.048394ms)
Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 16.761339ms)
Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 16.957866ms)
Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 16.533395ms)
Nov 12 12:13:48.961: INFO: (18) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 5.879661ms)
Nov 12 12:13:48.965: INFO: (18) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 8.727394ms)
Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 9.647589ms)
Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 9.716113ms)
Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 9.865089ms)
Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 10.351352ms)
Nov 12 12:13:48.967: INFO: (18) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 11.31038ms)
Nov 12 12:13:48.967: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 10.486616ms)
Nov 12 12:13:48.967: INFO: (18) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.071553ms)
Nov 12 12:13:48.968: INFO: (18) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 11.938211ms)
Nov 12 12:13:48.972: INFO: (18) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 15.4476ms)
Nov 12 12:13:48.973: INFO: (18) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 16.394751ms)
Nov 12 12:13:48.975: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 18.879358ms)
Nov 12 12:13:48.976: INFO: (18) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 19.56927ms)
Nov 12 12:13:48.976: INFO: (18) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 20.217781ms)
Nov 12 12:13:48.976: INFO: (18) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 20.093062ms)
Nov 12 12:13:48.983: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 6.330385ms)
Nov 12 12:13:48.984: INFO: (19) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 7.755383ms)
Nov 12 12:13:48.985: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 7.342864ms)
Nov 12 12:13:48.987: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 10.337799ms)
Nov 12 12:13:48.987: INFO: (19) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 10.428578ms)
Nov 12 12:13:48.988: INFO: (19) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 10.670673ms)
Nov 12 12:13:48.988: INFO: (19) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 11.557286ms)
Nov 12 12:13:48.989: INFO: (19) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.427233ms)
Nov 12 12:13:48.990: INFO: (19) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 13.504263ms)
Nov 12 12:13:48.990: INFO: (19) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.121905ms)
Nov 12 12:13:48.991: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.266972ms)
Nov 12 12:13:48.991: INFO: (19) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 13.877203ms)
Nov 12 12:13:48.991: INFO: (19) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 14.974289ms)
Nov 12 12:13:48.993: INFO: (19) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 15.818346ms)
Nov 12 12:13:48.994: INFO: (19) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 16.536018ms)
Nov 12 12:13:49.001: INFO: (19) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 23.983482ms)
STEP: deleting ReplicationController proxy-service-pt59b in namespace proxy-1766, will wait for the garbage collector to delete the pods 11/12/22 12:13:49.002
Nov 12 12:13:49.076: INFO: Deleting ReplicationController proxy-service-pt59b took: 18.903496ms
Nov 12 12:13:49.177: INFO: Terminating ReplicationController proxy-service-pt59b pods took: 101.032126ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 12 12:13:51.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1766" for this suite. 11/12/22 12:13:51.491
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":69,"skipped":1501,"failed":0}
------------------------------
• [SLOW TEST] [5.130 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:46.381
    Nov 12 12:13:46.381: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename proxy 11/12/22 12:13:46.382
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:46.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:46.413
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 11/12/22 12:13:46.448
    STEP: creating replication controller proxy-service-pt59b in namespace proxy-1766 11/12/22 12:13:46.449
    I1112 12:13:46.469329      19 runners.go:193] Created replication controller with name: proxy-service-pt59b, namespace: proxy-1766, replica count: 1
    I1112 12:13:47.520979      19 runners.go:193] proxy-service-pt59b Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I1112 12:13:48.521068      19 runners.go:193] proxy-service-pt59b Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 12:13:48.526: INFO: setup took 2.108171219s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/12/22 12:13:48.526
    Nov 12 12:13:48.533: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 7.238945ms)
    Nov 12 12:13:48.534: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 7.065916ms)
    Nov 12 12:13:48.535: INFO: (0) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 8.018972ms)
    Nov 12 12:13:48.535: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 8.189366ms)
    Nov 12 12:13:48.536: INFO: (0) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.162107ms)
    Nov 12 12:13:48.537: INFO: (0) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 10.430407ms)
    Nov 12 12:13:48.539: INFO: (0) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 12.269658ms)
    Nov 12 12:13:48.542: INFO: (0) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 14.796154ms)
    Nov 12 12:13:48.542: INFO: (0) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 14.61517ms)
    Nov 12 12:13:48.542: INFO: (0) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 15.101765ms)
    Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 15.846332ms)
    Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 16.375177ms)
    Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 16.014411ms)
    Nov 12 12:13:48.543: INFO: (0) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 16.803095ms)
    Nov 12 12:13:48.547: INFO: (0) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 19.741647ms)
    Nov 12 12:13:48.548: INFO: (0) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 20.594083ms)
    Nov 12 12:13:48.554: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 6.380202ms)
    Nov 12 12:13:48.556: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 8.047438ms)
    Nov 12 12:13:48.557: INFO: (1) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 9.067086ms)
    Nov 12 12:13:48.559: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 10.808652ms)
    Nov 12 12:13:48.560: INFO: (1) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.268782ms)
    Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 12.700671ms)
    Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 13.032987ms)
    Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 12.832266ms)
    Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 12.604688ms)
    Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 12.989784ms)
    Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.028141ms)
    Nov 12 12:13:48.561: INFO: (1) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 13.015833ms)
    Nov 12 12:13:48.562: INFO: (1) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.992289ms)
    Nov 12 12:13:48.562: INFO: (1) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 13.816788ms)
    Nov 12 12:13:48.565: INFO: (1) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 16.684288ms)
    Nov 12 12:13:48.566: INFO: (1) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 17.591825ms)
    Nov 12 12:13:48.572: INFO: (2) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 5.977141ms)
    Nov 12 12:13:48.573: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 6.797304ms)
    Nov 12 12:13:48.575: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.084977ms)
    Nov 12 12:13:48.576: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 9.587138ms)
    Nov 12 12:13:48.576: INFO: (2) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 10.075723ms)
    Nov 12 12:13:48.576: INFO: (2) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 9.965019ms)
    Nov 12 12:13:48.577: INFO: (2) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 10.113922ms)
    Nov 12 12:13:48.579: INFO: (2) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 13.270105ms)
    Nov 12 12:13:48.579: INFO: (2) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 13.385874ms)
    Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 13.464586ms)
    Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 13.471599ms)
    Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 13.622076ms)
    Nov 12 12:13:48.580: INFO: (2) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 13.773863ms)
    Nov 12 12:13:48.585: INFO: (2) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 18.908367ms)
    Nov 12 12:13:48.585: INFO: (2) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 18.978917ms)
    Nov 12 12:13:48.585: INFO: (2) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 18.940446ms)
    Nov 12 12:13:48.591: INFO: (3) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 5.522481ms)
    Nov 12 12:13:48.595: INFO: (3) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 9.651854ms)
    Nov 12 12:13:48.595: INFO: (3) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.750889ms)
    Nov 12 12:13:48.596: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 10.247697ms)
    Nov 12 12:13:48.596: INFO: (3) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 10.56433ms)
    Nov 12 12:13:48.597: INFO: (3) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 10.90928ms)
    Nov 12 12:13:48.597: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.188973ms)
    Nov 12 12:13:48.598: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.368109ms)
    Nov 12 12:13:48.598: INFO: (3) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 12.891837ms)
    Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 13.220827ms)
    Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 13.574369ms)
    Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 13.602659ms)
    Nov 12 12:13:48.599: INFO: (3) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 13.687836ms)
    Nov 12 12:13:48.600: INFO: (3) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.955575ms)
    Nov 12 12:13:48.601: INFO: (3) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 15.044343ms)
    Nov 12 12:13:48.602: INFO: (3) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 16.278192ms)
    Nov 12 12:13:48.615: INFO: (4) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 12.087589ms)
    Nov 12 12:13:48.615: INFO: (4) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.248403ms)
    Nov 12 12:13:48.615: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.442629ms)
    Nov 12 12:13:48.616: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 14.058382ms)
    Nov 12 12:13:48.618: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 15.423303ms)
    Nov 12 12:13:48.618: INFO: (4) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 15.465342ms)
    Nov 12 12:13:48.619: INFO: (4) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 15.958328ms)
    Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 17.689115ms)
    Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 17.670709ms)
    Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 17.999366ms)
    Nov 12 12:13:48.620: INFO: (4) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 17.619119ms)
    Nov 12 12:13:48.622: INFO: (4) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 18.843527ms)
    Nov 12 12:13:48.622: INFO: (4) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 19.130784ms)
    Nov 12 12:13:48.623: INFO: (4) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 20.391943ms)
    Nov 12 12:13:48.623: INFO: (4) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.089601ms)
    Nov 12 12:13:48.637: INFO: (4) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 34.458766ms)
    Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 25.217734ms)
    Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 25.172749ms)
    Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 25.330324ms)
    Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 25.405456ms)
    Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 25.695185ms)
    Nov 12 12:13:48.663: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 25.654824ms)
    Nov 12 12:13:48.664: INFO: (5) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 26.33877ms)
    Nov 12 12:13:48.665: INFO: (5) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 26.24813ms)
    Nov 12 12:13:48.665: INFO: (5) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 26.673771ms)
    Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 28.040811ms)
    Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 29.024936ms)
    Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 28.994471ms)
    Nov 12 12:13:48.667: INFO: (5) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 29.508606ms)
    Nov 12 12:13:48.668: INFO: (5) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 29.175414ms)
    Nov 12 12:13:48.668: INFO: (5) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 29.331184ms)
    Nov 12 12:13:48.668: INFO: (5) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 29.794628ms)
    Nov 12 12:13:48.680: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 11.28933ms)
    Nov 12 12:13:48.683: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.12671ms)
    Nov 12 12:13:48.683: INFO: (6) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.555334ms)
    Nov 12 12:13:48.686: INFO: (6) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 17.324618ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 21.798044ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 21.55296ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 21.733344ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 21.806426ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 21.938258ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 22.64501ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 22.48729ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 22.073017ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 22.148665ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 22.284223ms)
    Nov 12 12:13:48.691: INFO: (6) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 22.354179ms)
    Nov 12 12:13:48.694: INFO: (6) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 25.296306ms)
    Nov 12 12:13:48.704: INFO: (7) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.303216ms)
    Nov 12 12:13:48.705: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 10.63609ms)
    Nov 12 12:13:48.706: INFO: (7) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.134267ms)
    Nov 12 12:13:48.707: INFO: (7) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 12.669261ms)
    Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 15.980967ms)
    Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 16.06161ms)
    Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 15.941681ms)
    Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 15.819312ms)
    Nov 12 12:13:48.711: INFO: (7) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 16.066014ms)
    Nov 12 12:13:48.712: INFO: (7) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 17.256058ms)
    Nov 12 12:13:48.712: INFO: (7) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 17.416847ms)
    Nov 12 12:13:48.712: INFO: (7) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 17.62547ms)
    Nov 12 12:13:48.713: INFO: (7) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 18.306397ms)
    Nov 12 12:13:48.714: INFO: (7) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 18.97107ms)
    Nov 12 12:13:48.714: INFO: (7) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 19.121415ms)
    Nov 12 12:13:48.719: INFO: (7) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 23.485517ms)
    Nov 12 12:13:48.732: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.429224ms)
    Nov 12 12:13:48.732: INFO: (8) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.514798ms)
    Nov 12 12:13:48.739: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 20.47555ms)
    Nov 12 12:13:48.739: INFO: (8) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 20.1994ms)
    Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 21.233486ms)
    Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 21.341547ms)
    Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 21.088744ms)
    Nov 12 12:13:48.740: INFO: (8) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 21.130292ms)
    Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.566665ms)
    Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 21.596713ms)
    Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 21.687312ms)
    Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 21.672983ms)
    Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 21.718624ms)
    Nov 12 12:13:48.741: INFO: (8) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 21.922106ms)
    Nov 12 12:13:48.742: INFO: (8) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 22.501571ms)
    Nov 12 12:13:48.742: INFO: (8) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 22.88426ms)
    Nov 12 12:13:48.754: INFO: (9) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.787504ms)
    Nov 12 12:13:48.754: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 11.924801ms)
    Nov 12 12:13:48.754: INFO: (9) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 11.853906ms)
    Nov 12 12:13:48.755: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 12.050739ms)
    Nov 12 12:13:48.755: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 12.420713ms)
    Nov 12 12:13:48.758: INFO: (9) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 14.970696ms)
    Nov 12 12:13:48.759: INFO: (9) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 16.358583ms)
    Nov 12 12:13:48.760: INFO: (9) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 18.244514ms)
    Nov 12 12:13:48.761: INFO: (9) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 18.021368ms)
    Nov 12 12:13:48.761: INFO: (9) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 18.571253ms)
    Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 21.14923ms)
    Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 21.579545ms)
    Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 22.262496ms)
    Nov 12 12:13:48.764: INFO: (9) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 21.861786ms)
    Nov 12 12:13:48.765: INFO: (9) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 22.846018ms)
    Nov 12 12:13:48.767: INFO: (9) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 23.999089ms)
    Nov 12 12:13:48.780: INFO: (10) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 12.74089ms)
    Nov 12 12:13:48.782: INFO: (10) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 14.887055ms)
    Nov 12 12:13:48.782: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.873618ms)
    Nov 12 12:13:48.786: INFO: (10) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 18.974495ms)
    Nov 12 12:13:48.786: INFO: (10) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 19.146207ms)
    Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 19.327464ms)
    Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 19.814611ms)
    Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 19.744451ms)
    Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 19.549836ms)
    Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 19.789646ms)
    Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 19.923017ms)
    Nov 12 12:13:48.787: INFO: (10) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 20.067338ms)
    Nov 12 12:13:48.788: INFO: (10) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 21.103428ms)
    Nov 12 12:13:48.789: INFO: (10) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 21.672844ms)
    Nov 12 12:13:48.789: INFO: (10) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 21.701251ms)
    Nov 12 12:13:48.790: INFO: (10) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 23.056983ms)
    Nov 12 12:13:48.796: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 5.825127ms)
    Nov 12 12:13:48.803: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.229645ms)
    Nov 12 12:13:48.804: INFO: (11) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 12.692369ms)
    Nov 12 12:13:48.804: INFO: (11) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.81522ms)
    Nov 12 12:13:48.807: INFO: (11) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 15.668307ms)
    Nov 12 12:13:48.809: INFO: (11) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 17.149106ms)
    Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 20.41104ms)
    Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 19.811511ms)
    Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 20.404489ms)
    Nov 12 12:13:48.811: INFO: (11) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 19.663851ms)
    Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.452908ms)
    Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 20.023826ms)
    Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 21.129348ms)
    Nov 12 12:13:48.812: INFO: (11) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 21.508888ms)
    Nov 12 12:13:48.813: INFO: (11) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 21.795698ms)
    Nov 12 12:13:48.814: INFO: (11) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 21.635216ms)
    Nov 12 12:13:48.821: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 6.836617ms)
    Nov 12 12:13:48.825: INFO: (12) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 10.770728ms)
    Nov 12 12:13:48.827: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 12.865213ms)
    Nov 12 12:13:48.827: INFO: (12) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 12.57114ms)
    Nov 12 12:13:48.830: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 15.606341ms)
    Nov 12 12:13:48.831: INFO: (12) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 16.940793ms)
    Nov 12 12:13:48.831: INFO: (12) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 16.502939ms)
    Nov 12 12:13:48.832: INFO: (12) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 17.6555ms)
    Nov 12 12:13:48.833: INFO: (12) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 18.866654ms)
    Nov 12 12:13:48.838: INFO: (12) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 23.778095ms)
    Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 25.685548ms)
    Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 24.956335ms)
    Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 25.255532ms)
    Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 25.100269ms)
    Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 25.75788ms)
    Nov 12 12:13:48.840: INFO: (12) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 25.310101ms)
    Nov 12 12:13:48.850: INFO: (13) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.552445ms)
    Nov 12 12:13:48.851: INFO: (13) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 10.549098ms)
    Nov 12 12:13:48.852: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 11.699444ms)
    Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 13.495849ms)
    Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 13.774082ms)
    Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.888224ms)
    Nov 12 12:13:48.854: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 14.072988ms)
    Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 14.215814ms)
    Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 14.143307ms)
    Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 14.158798ms)
    Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 14.651441ms)
    Nov 12 12:13:48.855: INFO: (13) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 14.888046ms)
    Nov 12 12:13:48.857: INFO: (13) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 16.53235ms)
    Nov 12 12:13:48.857: INFO: (13) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 16.828153ms)
    Nov 12 12:13:48.858: INFO: (13) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 17.41735ms)
    Nov 12 12:13:48.860: INFO: (13) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 19.595119ms)
    Nov 12 12:13:48.873: INFO: (14) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 13.183599ms)
    Nov 12 12:13:48.874: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 13.194562ms)
    Nov 12 12:13:48.873: INFO: (14) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.728822ms)
    Nov 12 12:13:48.874: INFO: (14) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 13.032702ms)
    Nov 12 12:13:48.875: INFO: (14) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 13.80597ms)
    Nov 12 12:13:48.879: INFO: (14) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 18.274389ms)
    Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 20.160254ms)
    Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 20.14397ms)
    Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 21.27811ms)
    Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 21.335956ms)
    Nov 12 12:13:48.881: INFO: (14) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 20.515303ms)
    Nov 12 12:13:48.882: INFO: (14) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 20.796554ms)
    Nov 12 12:13:48.885: INFO: (14) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 24.73493ms)
    Nov 12 12:13:48.887: INFO: (14) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 27.028327ms)
    Nov 12 12:13:48.889: INFO: (14) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 28.29495ms)
    Nov 12 12:13:48.892: INFO: (14) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 31.340022ms)
    Nov 12 12:13:48.899: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 5.85869ms)
    Nov 12 12:13:48.900: INFO: (15) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 8.417024ms)
    Nov 12 12:13:48.900: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 7.77964ms)
    Nov 12 12:13:48.900: INFO: (15) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 7.855928ms)
    Nov 12 12:13:48.901: INFO: (15) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 9.648331ms)
    Nov 12 12:13:48.902: INFO: (15) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 9.068488ms)
    Nov 12 12:13:48.903: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.078079ms)
    Nov 12 12:13:48.904: INFO: (15) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 11.272683ms)
    Nov 12 12:13:48.904: INFO: (15) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 11.409081ms)
    Nov 12 12:13:48.905: INFO: (15) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 12.105329ms)
    Nov 12 12:13:48.905: INFO: (15) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 13.143013ms)
    Nov 12 12:13:48.906: INFO: (15) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 13.947594ms)
    Nov 12 12:13:48.907: INFO: (15) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 15.59256ms)
    Nov 12 12:13:48.909: INFO: (15) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 17.573383ms)
    Nov 12 12:13:48.914: INFO: (15) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 21.171052ms)
    Nov 12 12:13:48.914: INFO: (15) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 21.386571ms)
    Nov 12 12:13:48.920: INFO: (16) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 5.350811ms)
    Nov 12 12:13:48.921: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 6.466693ms)
    Nov 12 12:13:48.923: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 8.063786ms)
    Nov 12 12:13:48.924: INFO: (16) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 9.363336ms)
    Nov 12 12:13:48.926: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 10.832922ms)
    Nov 12 12:13:48.926: INFO: (16) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 11.525832ms)
    Nov 12 12:13:48.926: INFO: (16) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.737353ms)
    Nov 12 12:13:48.928: INFO: (16) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 13.647612ms)
    Nov 12 12:13:48.931: INFO: (16) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 16.118383ms)
    Nov 12 12:13:48.931: INFO: (16) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 16.101832ms)
    Nov 12 12:13:48.931: INFO: (16) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 16.698076ms)
    Nov 12 12:13:48.934: INFO: (16) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 18.672679ms)
    Nov 12 12:13:48.934: INFO: (16) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 19.239638ms)
    Nov 12 12:13:48.934: INFO: (16) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 19.76448ms)
    Nov 12 12:13:48.937: INFO: (16) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 22.154834ms)
    Nov 12 12:13:48.938: INFO: (16) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 23.117748ms)
    Nov 12 12:13:48.947: INFO: (17) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 8.706625ms)
    Nov 12 12:13:48.948: INFO: (17) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.908535ms)
    Nov 12 12:13:48.949: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 9.981101ms)
    Nov 12 12:13:48.949: INFO: (17) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 10.743735ms)
    Nov 12 12:13:48.950: INFO: (17) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 11.129339ms)
    Nov 12 12:13:48.951: INFO: (17) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 12.523513ms)
    Nov 12 12:13:48.951: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 12.900636ms)
    Nov 12 12:13:48.952: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 12.831472ms)
    Nov 12 12:13:48.952: INFO: (17) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 13.313845ms)
    Nov 12 12:13:48.952: INFO: (17) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 14.222213ms)
    Nov 12 12:13:48.954: INFO: (17) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 15.357583ms)
    Nov 12 12:13:48.954: INFO: (17) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 15.404199ms)
    Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 16.048394ms)
    Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 16.761339ms)
    Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 16.957866ms)
    Nov 12 12:13:48.955: INFO: (17) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 16.533395ms)
    Nov 12 12:13:48.961: INFO: (18) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 5.879661ms)
    Nov 12 12:13:48.965: INFO: (18) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 8.727394ms)
    Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 9.647589ms)
    Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 9.716113ms)
    Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 9.865089ms)
    Nov 12 12:13:48.966: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 10.351352ms)
    Nov 12 12:13:48.967: INFO: (18) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 11.31038ms)
    Nov 12 12:13:48.967: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 10.486616ms)
    Nov 12 12:13:48.967: INFO: (18) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.071553ms)
    Nov 12 12:13:48.968: INFO: (18) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 11.938211ms)
    Nov 12 12:13:48.972: INFO: (18) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 15.4476ms)
    Nov 12 12:13:48.973: INFO: (18) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 16.394751ms)
    Nov 12 12:13:48.975: INFO: (18) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 18.879358ms)
    Nov 12 12:13:48.976: INFO: (18) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 19.56927ms)
    Nov 12 12:13:48.976: INFO: (18) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 20.217781ms)
    Nov 12 12:13:48.976: INFO: (18) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 20.093062ms)
    Nov 12 12:13:48.983: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">test<... (200; 6.330385ms)
    Nov 12 12:13:48.984: INFO: (19) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 7.755383ms)
    Nov 12 12:13:48.985: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt/proxy/rewriteme">test</a> (200; 7.342864ms)
    Nov 12 12:13:48.987: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 10.337799ms)
    Nov 12 12:13:48.987: INFO: (19) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:462/proxy/: tls qux (200; 10.428578ms)
    Nov 12 12:13:48.988: INFO: (19) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:1080/proxy/rewriteme">... (200; 10.670673ms)
    Nov 12 12:13:48.988: INFO: (19) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/: <a href="/api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:443/proxy/tlsrewritem... (200; 11.557286ms)
    Nov 12 12:13:48.989: INFO: (19) /api/v1/namespaces/proxy-1766/pods/https:proxy-service-pt59b-wbhnt:460/proxy/: tls baz (200; 11.427233ms)
    Nov 12 12:13:48.990: INFO: (19) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname2/proxy/: bar (200; 13.504263ms)
    Nov 12 12:13:48.990: INFO: (19) /api/v1/namespaces/proxy-1766/services/http:proxy-service-pt59b:portname1/proxy/: foo (200; 13.121905ms)
    Nov 12 12:13:48.991: INFO: (19) /api/v1/namespaces/proxy-1766/pods/proxy-service-pt59b-wbhnt:162/proxy/: bar (200; 13.266972ms)
    Nov 12 12:13:48.991: INFO: (19) /api/v1/namespaces/proxy-1766/pods/http:proxy-service-pt59b-wbhnt:160/proxy/: foo (200; 13.877203ms)
    Nov 12 12:13:48.991: INFO: (19) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname2/proxy/: tls qux (200; 14.974289ms)
    Nov 12 12:13:48.993: INFO: (19) /api/v1/namespaces/proxy-1766/services/https:proxy-service-pt59b:tlsportname1/proxy/: tls baz (200; 15.818346ms)
    Nov 12 12:13:48.994: INFO: (19) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname2/proxy/: bar (200; 16.536018ms)
    Nov 12 12:13:49.001: INFO: (19) /api/v1/namespaces/proxy-1766/services/proxy-service-pt59b:portname1/proxy/: foo (200; 23.983482ms)
    STEP: deleting ReplicationController proxy-service-pt59b in namespace proxy-1766, will wait for the garbage collector to delete the pods 11/12/22 12:13:49.002
    Nov 12 12:13:49.076: INFO: Deleting ReplicationController proxy-service-pt59b took: 18.903496ms
    Nov 12 12:13:49.177: INFO: Terminating ReplicationController proxy-service-pt59b pods took: 101.032126ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 12 12:13:51.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1766" for this suite. 11/12/22 12:13:51.491
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:51.512
Nov 12 12:13:51.512: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:13:51.513
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:51.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:51.561
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 11/12/22 12:13:51.567
Nov 12 12:13:51.583: INFO: Waiting up to 5m0s for pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5" in namespace "emptydir-8028" to be "Succeeded or Failed"
Nov 12 12:13:51.595: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.883908ms
Nov 12 12:13:53.600: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017488802s
Nov 12 12:13:55.603: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019795128s
STEP: Saw pod success 11/12/22 12:13:55.603
Nov 12 12:13:55.603: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5" satisfied condition "Succeeded or Failed"
Nov 12 12:13:55.610: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-03901968-616d-4856-b7c1-a981ca38b0e5 container test-container: <nil>
STEP: delete the pod 11/12/22 12:13:55.619
Nov 12 12:13:55.635: INFO: Waiting for pod pod-03901968-616d-4856-b7c1-a981ca38b0e5 to disappear
Nov 12 12:13:55.639: INFO: Pod pod-03901968-616d-4856-b7c1-a981ca38b0e5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:13:55.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8028" for this suite. 11/12/22 12:13:55.646
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":70,"skipped":1506,"failed":0}
------------------------------
• [4.143 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:51.512
    Nov 12 12:13:51.512: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:13:51.513
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:51.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:51.561
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 11/12/22 12:13:51.567
    Nov 12 12:13:51.583: INFO: Waiting up to 5m0s for pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5" in namespace "emptydir-8028" to be "Succeeded or Failed"
    Nov 12 12:13:51.595: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5": Phase="Pending", Reason="", readiness=false. Elapsed: 11.883908ms
    Nov 12 12:13:53.600: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017488802s
    Nov 12 12:13:55.603: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019795128s
    STEP: Saw pod success 11/12/22 12:13:55.603
    Nov 12 12:13:55.603: INFO: Pod "pod-03901968-616d-4856-b7c1-a981ca38b0e5" satisfied condition "Succeeded or Failed"
    Nov 12 12:13:55.610: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-03901968-616d-4856-b7c1-a981ca38b0e5 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:13:55.619
    Nov 12 12:13:55.635: INFO: Waiting for pod pod-03901968-616d-4856-b7c1-a981ca38b0e5 to disappear
    Nov 12 12:13:55.639: INFO: Pod pod-03901968-616d-4856-b7c1-a981ca38b0e5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:13:55.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8028" for this suite. 11/12/22 12:13:55.646
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:55.658
Nov 12 12:13:55.658: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 12:13:55.659
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:55.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:55.684
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 11/12/22 12:13:55.686
STEP: Getting a ResourceQuota 11/12/22 12:13:55.694
STEP: Updating a ResourceQuota 11/12/22 12:13:55.699
STEP: Verifying a ResourceQuota was modified 11/12/22 12:13:55.714
STEP: Deleting a ResourceQuota 11/12/22 12:13:55.719
STEP: Verifying the deleted ResourceQuota 11/12/22 12:13:55.729
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 12:13:55.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3565" for this suite. 11/12/22 12:13:55.741
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":71,"skipped":1542,"failed":0}
------------------------------
• [0.092 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:55.658
    Nov 12 12:13:55.658: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 12:13:55.659
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:55.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:55.684
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 11/12/22 12:13:55.686
    STEP: Getting a ResourceQuota 11/12/22 12:13:55.694
    STEP: Updating a ResourceQuota 11/12/22 12:13:55.699
    STEP: Verifying a ResourceQuota was modified 11/12/22 12:13:55.714
    STEP: Deleting a ResourceQuota 11/12/22 12:13:55.719
    STEP: Verifying the deleted ResourceQuota 11/12/22 12:13:55.729
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 12:13:55.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3565" for this suite. 11/12/22 12:13:55.741
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:55.751
Nov 12 12:13:55.751: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 12:13:55.752
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:55.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:55.826
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-7ed7408e-9f2b-4221-94d9-fa4c56ce33e6 11/12/22 12:13:55.84
STEP: Creating configMap with name cm-test-opt-upd-213aa8dc-db5b-4b30-9f4f-dc70eb3d207c 11/12/22 12:13:55.845
STEP: Creating the pod 11/12/22 12:13:55.851
Nov 12 12:13:55.866: INFO: Waiting up to 5m0s for pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128" in namespace "configmap-3242" to be "running and ready"
Nov 12 12:13:55.875: INFO: Pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128": Phase="Pending", Reason="", readiness=false. Elapsed: 9.370287ms
Nov 12 12:13:55.875: INFO: The phase of Pod pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:13:57.880: INFO: Pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128": Phase="Running", Reason="", readiness=true. Elapsed: 2.014499321s
Nov 12 12:13:57.881: INFO: The phase of Pod pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128 is Running (Ready = true)
Nov 12 12:13:57.881: INFO: Pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-7ed7408e-9f2b-4221-94d9-fa4c56ce33e6 11/12/22 12:13:57.909
STEP: Updating configmap cm-test-opt-upd-213aa8dc-db5b-4b30-9f4f-dc70eb3d207c 11/12/22 12:13:57.92
STEP: Creating configMap with name cm-test-opt-create-3e3682bc-1a7e-4e51-83cb-35ecd65a3372 11/12/22 12:13:57.926
STEP: waiting to observe update in volume 11/12/22 12:13:57.932
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 12:13:59.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3242" for this suite. 11/12/22 12:13:59.977
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":72,"skipped":1543,"failed":0}
------------------------------
• [4.235 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:55.751
    Nov 12 12:13:55.751: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 12:13:55.752
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:13:55.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:13:55.826
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-7ed7408e-9f2b-4221-94d9-fa4c56ce33e6 11/12/22 12:13:55.84
    STEP: Creating configMap with name cm-test-opt-upd-213aa8dc-db5b-4b30-9f4f-dc70eb3d207c 11/12/22 12:13:55.845
    STEP: Creating the pod 11/12/22 12:13:55.851
    Nov 12 12:13:55.866: INFO: Waiting up to 5m0s for pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128" in namespace "configmap-3242" to be "running and ready"
    Nov 12 12:13:55.875: INFO: Pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128": Phase="Pending", Reason="", readiness=false. Elapsed: 9.370287ms
    Nov 12 12:13:55.875: INFO: The phase of Pod pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:13:57.880: INFO: Pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128": Phase="Running", Reason="", readiness=true. Elapsed: 2.014499321s
    Nov 12 12:13:57.881: INFO: The phase of Pod pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128 is Running (Ready = true)
    Nov 12 12:13:57.881: INFO: Pod "pod-configmaps-128e8abf-1496-4906-b6ce-573cfeeb9128" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-7ed7408e-9f2b-4221-94d9-fa4c56ce33e6 11/12/22 12:13:57.909
    STEP: Updating configmap cm-test-opt-upd-213aa8dc-db5b-4b30-9f4f-dc70eb3d207c 11/12/22 12:13:57.92
    STEP: Creating configMap with name cm-test-opt-create-3e3682bc-1a7e-4e51-83cb-35ecd65a3372 11/12/22 12:13:57.926
    STEP: waiting to observe update in volume 11/12/22 12:13:57.932
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 12:13:59.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3242" for this suite. 11/12/22 12:13:59.977
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:13:59.986
Nov 12 12:13:59.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:13:59.987
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:00.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:00.011
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 11/12/22 12:14:00.014
Nov 12 12:14:00.027: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07" in namespace "projected-6545" to be "Succeeded or Failed"
Nov 12 12:14:00.031: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07": Phase="Pending", Reason="", readiness=false. Elapsed: 4.211464ms
Nov 12 12:14:02.041: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013891955s
Nov 12 12:14:04.037: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009597512s
STEP: Saw pod success 11/12/22 12:14:04.037
Nov 12 12:14:04.037: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07" satisfied condition "Succeeded or Failed"
Nov 12 12:14:04.042: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07 container client-container: <nil>
STEP: delete the pod 11/12/22 12:14:04.061
Nov 12 12:14:04.076: INFO: Waiting for pod downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07 to disappear
Nov 12 12:14:04.081: INFO: Pod downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 12:14:04.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6545" for this suite. 11/12/22 12:14:04.087
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":73,"skipped":1551,"failed":0}
------------------------------
• [4.111 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:13:59.986
    Nov 12 12:13:59.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:13:59.987
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:00.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:00.011
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 11/12/22 12:14:00.014
    Nov 12 12:14:00.027: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07" in namespace "projected-6545" to be "Succeeded or Failed"
    Nov 12 12:14:00.031: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07": Phase="Pending", Reason="", readiness=false. Elapsed: 4.211464ms
    Nov 12 12:14:02.041: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013891955s
    Nov 12 12:14:04.037: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009597512s
    STEP: Saw pod success 11/12/22 12:14:04.037
    Nov 12 12:14:04.037: INFO: Pod "downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07" satisfied condition "Succeeded or Failed"
    Nov 12 12:14:04.042: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07 container client-container: <nil>
    STEP: delete the pod 11/12/22 12:14:04.061
    Nov 12 12:14:04.076: INFO: Waiting for pod downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07 to disappear
    Nov 12 12:14:04.081: INFO: Pod downwardapi-volume-a923b8e9-9c89-4f2f-9c8e-eedbf9381b07 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 12:14:04.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6545" for this suite. 11/12/22 12:14:04.087
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:14:04.099
Nov 12 12:14:04.099: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:14:04.099
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:04.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:04.121
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Nov 12 12:14:04.155: INFO: Waiting up to 5m0s for pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767" in namespace "svcaccounts-5844" to be "running"
Nov 12 12:14:04.159: INFO: Pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767": Phase="Pending", Reason="", readiness=false. Elapsed: 4.381664ms
Nov 12 12:14:06.164: INFO: Pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767": Phase="Running", Reason="", readiness=true. Elapsed: 2.009687405s
Nov 12 12:14:06.164: INFO: Pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767" satisfied condition "running"
STEP: reading a file in the container 11/12/22 12:14:06.164
Nov 12 12:14:06.165: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5844 pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 11/12/22 12:14:06.301
Nov 12 12:14:06.301: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5844 pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 11/12/22 12:14:06.414
Nov 12 12:14:06.414: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5844 pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Nov 12 12:14:06.558: INFO: Got root ca configmap in namespace "svcaccounts-5844"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 12 12:14:06.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5844" for this suite. 11/12/22 12:14:06.566
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":74,"skipped":1562,"failed":0}
------------------------------
• [2.476 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:14:04.099
    Nov 12 12:14:04.099: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:14:04.099
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:04.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:04.121
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Nov 12 12:14:04.155: INFO: Waiting up to 5m0s for pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767" in namespace "svcaccounts-5844" to be "running"
    Nov 12 12:14:04.159: INFO: Pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767": Phase="Pending", Reason="", readiness=false. Elapsed: 4.381664ms
    Nov 12 12:14:06.164: INFO: Pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767": Phase="Running", Reason="", readiness=true. Elapsed: 2.009687405s
    Nov 12 12:14:06.164: INFO: Pod "pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767" satisfied condition "running"
    STEP: reading a file in the container 11/12/22 12:14:06.164
    Nov 12 12:14:06.165: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5844 pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 11/12/22 12:14:06.301
    Nov 12 12:14:06.301: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5844 pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 11/12/22 12:14:06.414
    Nov 12 12:14:06.414: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5844 pod-service-account-c2c4529a-4213-42d2-ae23-a04363d8e767 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Nov 12 12:14:06.558: INFO: Got root ca configmap in namespace "svcaccounts-5844"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 12 12:14:06.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5844" for this suite. 11/12/22 12:14:06.566
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:14:06.575
Nov 12 12:14:06.575: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-webhook 11/12/22 12:14:06.575
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:06.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:06.609
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/12/22 12:14:06.611
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 12:14:07.206
STEP: Deploying the custom resource conversion webhook pod 11/12/22 12:14:07.221
STEP: Wait for the deployment to be ready 11/12/22 12:14:07.235
Nov 12 12:14:07.249: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:14:09.272
STEP: Verifying the service has paired with the endpoint 11/12/22 12:14:09.289
Nov 12 12:14:10.289: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Nov 12 12:14:10.294: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Creating a v1 custom resource 11/12/22 12:14:12.844
STEP: v2 custom resource should be converted 11/12/22 12:14:12.853
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:14:13.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3229" for this suite. 11/12/22 12:14:13.381
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":75,"skipped":1568,"failed":0}
------------------------------
• [SLOW TEST] [6.949 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:14:06.575
    Nov 12 12:14:06.575: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-webhook 11/12/22 12:14:06.575
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:06.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:06.609
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/12/22 12:14:06.611
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 12:14:07.206
    STEP: Deploying the custom resource conversion webhook pod 11/12/22 12:14:07.221
    STEP: Wait for the deployment to be ready 11/12/22 12:14:07.235
    Nov 12 12:14:07.249: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:14:09.272
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:14:09.289
    Nov 12 12:14:10.289: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Nov 12 12:14:10.294: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Creating a v1 custom resource 11/12/22 12:14:12.844
    STEP: v2 custom resource should be converted 11/12/22 12:14:12.853
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:14:13.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-3229" for this suite. 11/12/22 12:14:13.381
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:14:13.54
Nov 12 12:14:13.541: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename cronjob 11/12/22 12:14:13.542
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:13.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:13.585
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 11/12/22 12:14:13.592
STEP: Ensuring a job is scheduled 11/12/22 12:14:13.61
STEP: Ensuring exactly one is scheduled 11/12/22 12:15:01.616
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/12/22 12:15:01.62
STEP: Ensuring the job is replaced with a new one 11/12/22 12:15:01.626
STEP: Removing cronjob 11/12/22 12:16:01.631
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 12 12:16:01.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5259" for this suite. 11/12/22 12:16:01.647
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":76,"skipped":1599,"failed":0}
------------------------------
• [SLOW TEST] [108.117 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:14:13.54
    Nov 12 12:14:13.541: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename cronjob 11/12/22 12:14:13.542
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:14:13.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:14:13.585
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 11/12/22 12:14:13.592
    STEP: Ensuring a job is scheduled 11/12/22 12:14:13.61
    STEP: Ensuring exactly one is scheduled 11/12/22 12:15:01.616
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/12/22 12:15:01.62
    STEP: Ensuring the job is replaced with a new one 11/12/22 12:15:01.626
    STEP: Removing cronjob 11/12/22 12:16:01.631
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 12 12:16:01.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5259" for this suite. 11/12/22 12:16:01.647
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:16:01.66
Nov 12 12:16:01.660: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 12:16:01.661
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:01.688
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:01.691
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/12/22 12:16:01.693
Nov 12 12:16:01.693: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:16:04.865: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:16:15.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7686" for this suite. 11/12/22 12:16:15.327
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":77,"skipped":1618,"failed":0}
------------------------------
• [SLOW TEST] [13.677 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:16:01.66
    Nov 12 12:16:01.660: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 12:16:01.661
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:01.688
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:01.691
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/12/22 12:16:01.693
    Nov 12 12:16:01.693: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:16:04.865: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:16:15.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-7686" for this suite. 11/12/22 12:16:15.327
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:16:15.339
Nov 12 12:16:15.340: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 12:16:15.342
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:15.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:15.363
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 11/12/22 12:16:15.366
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4730.svc.cluster.local;sleep 1; done
 11/12/22 12:16:15.374
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4730.svc.cluster.local;sleep 1; done
 11/12/22 12:16:15.374
STEP: creating a pod to probe DNS 11/12/22 12:16:15.374
STEP: submitting the pod to kubernetes 11/12/22 12:16:15.375
Nov 12 12:16:15.392: INFO: Waiting up to 15m0s for pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48" in namespace "dns-4730" to be "running"
Nov 12 12:16:15.402: INFO: Pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48": Phase="Pending", Reason="", readiness=false. Elapsed: 9.969205ms
Nov 12 12:16:17.409: INFO: Pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48": Phase="Running", Reason="", readiness=true. Elapsed: 2.017214598s
Nov 12 12:16:17.409: INFO: Pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48" satisfied condition "running"
STEP: retrieving the pod 11/12/22 12:16:17.409
STEP: looking for the results for each expected name from probers 11/12/22 12:16:17.414
Nov 12 12:16:17.420: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.425: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.431: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.436: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.440: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.446: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.450: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.455: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
Nov 12 12:16:17.455: INFO: Lookups using dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4730.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4730.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local jessie_udp@dns-test-service-2.dns-4730.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4730.svc.cluster.local]

Nov 12 12:16:22.507: INFO: DNS probes using dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48 succeeded

STEP: deleting the pod 11/12/22 12:16:22.507
STEP: deleting the test headless service 11/12/22 12:16:22.528
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 12:16:22.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4730" for this suite. 11/12/22 12:16:22.566
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":78,"skipped":1640,"failed":0}
------------------------------
• [SLOW TEST] [7.241 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:16:15.339
    Nov 12 12:16:15.340: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 12:16:15.342
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:15.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:15.363
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 11/12/22 12:16:15.366
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4730.svc.cluster.local;sleep 1; done
     11/12/22 12:16:15.374
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4730.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4730.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4730.svc.cluster.local;sleep 1; done
     11/12/22 12:16:15.374
    STEP: creating a pod to probe DNS 11/12/22 12:16:15.374
    STEP: submitting the pod to kubernetes 11/12/22 12:16:15.375
    Nov 12 12:16:15.392: INFO: Waiting up to 15m0s for pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48" in namespace "dns-4730" to be "running"
    Nov 12 12:16:15.402: INFO: Pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48": Phase="Pending", Reason="", readiness=false. Elapsed: 9.969205ms
    Nov 12 12:16:17.409: INFO: Pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48": Phase="Running", Reason="", readiness=true. Elapsed: 2.017214598s
    Nov 12 12:16:17.409: INFO: Pod "dns-test-d80a0262-53f0-401c-97f3-ede884e01d48" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 12:16:17.409
    STEP: looking for the results for each expected name from probers 11/12/22 12:16:17.414
    Nov 12 12:16:17.420: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.425: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.431: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.436: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.440: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.446: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.450: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.455: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4730.svc.cluster.local from pod dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48: the server could not find the requested resource (get pods dns-test-d80a0262-53f0-401c-97f3-ede884e01d48)
    Nov 12 12:16:17.455: INFO: Lookups using dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4730.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4730.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4730.svc.cluster.local jessie_udp@dns-test-service-2.dns-4730.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4730.svc.cluster.local]

    Nov 12 12:16:22.507: INFO: DNS probes using dns-4730/dns-test-d80a0262-53f0-401c-97f3-ede884e01d48 succeeded

    STEP: deleting the pod 11/12/22 12:16:22.507
    STEP: deleting the test headless service 11/12/22 12:16:22.528
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 12:16:22.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4730" for this suite. 11/12/22 12:16:22.566
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:16:22.584
Nov 12 12:16:22.584: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 12:16:22.586
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:22.602
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:22.604
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-dd711183-54a9-4c9a-8064-105b22b69ee2 11/12/22 12:16:22.608
STEP: Creating a pod to test consume configMaps 11/12/22 12:16:22.62
Nov 12 12:16:22.633: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085" in namespace "configmap-8105" to be "Succeeded or Failed"
Nov 12 12:16:22.641: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.551326ms
Nov 12 12:16:24.645: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012283627s
Nov 12 12:16:26.648: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015008799s
STEP: Saw pod success 11/12/22 12:16:26.648
Nov 12 12:16:26.648: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085" satisfied condition "Succeeded or Failed"
Nov 12 12:16:26.653: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 12:16:26.67
Nov 12 12:16:26.688: INFO: Waiting for pod pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085 to disappear
Nov 12 12:16:26.692: INFO: Pod pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 12:16:26.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8105" for this suite. 11/12/22 12:16:26.697
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":79,"skipped":1692,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:16:22.584
    Nov 12 12:16:22.584: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 12:16:22.586
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:22.602
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:22.604
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-dd711183-54a9-4c9a-8064-105b22b69ee2 11/12/22 12:16:22.608
    STEP: Creating a pod to test consume configMaps 11/12/22 12:16:22.62
    Nov 12 12:16:22.633: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085" in namespace "configmap-8105" to be "Succeeded or Failed"
    Nov 12 12:16:22.641: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085": Phase="Pending", Reason="", readiness=false. Elapsed: 7.551326ms
    Nov 12 12:16:24.645: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012283627s
    Nov 12 12:16:26.648: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015008799s
    STEP: Saw pod success 11/12/22 12:16:26.648
    Nov 12 12:16:26.648: INFO: Pod "pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085" satisfied condition "Succeeded or Failed"
    Nov 12 12:16:26.653: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 12:16:26.67
    Nov 12 12:16:26.688: INFO: Waiting for pod pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085 to disappear
    Nov 12 12:16:26.692: INFO: Pod pod-configmaps-ac302690-5b71-422d-b39e-15eeba840085 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 12:16:26.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8105" for this suite. 11/12/22 12:16:26.697
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:16:26.708
Nov 12 12:16:26.709: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename cronjob 11/12/22 12:16:26.709
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:26.732
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:26.736
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 11/12/22 12:16:26.739
STEP: Ensuring more than one job is running at a time 11/12/22 12:16:26.745
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/12/22 12:18:00.751
STEP: Removing cronjob 11/12/22 12:18:00.756
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 12 12:18:00.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7432" for this suite. 11/12/22 12:18:00.775
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":80,"skipped":1712,"failed":0}
------------------------------
• [SLOW TEST] [94.090 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:16:26.708
    Nov 12 12:16:26.709: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename cronjob 11/12/22 12:16:26.709
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:16:26.732
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:16:26.736
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 11/12/22 12:16:26.739
    STEP: Ensuring more than one job is running at a time 11/12/22 12:16:26.745
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/12/22 12:18:00.751
    STEP: Removing cronjob 11/12/22 12:18:00.756
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 12 12:18:00.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-7432" for this suite. 11/12/22 12:18:00.775
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:18:00.798
Nov 12 12:18:00.799: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename job 11/12/22 12:18:00.799
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:00.83
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:00.842
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 11/12/22 12:18:00.845
STEP: Ensuring active pods == parallelism 11/12/22 12:18:00.876
STEP: Orphaning one of the Job's Pods 11/12/22 12:18:02.882
Nov 12 12:18:03.405: INFO: Successfully updated pod "adopt-release-8xb4c"
STEP: Checking that the Job readopts the Pod 11/12/22 12:18:03.405
Nov 12 12:18:03.405: INFO: Waiting up to 15m0s for pod "adopt-release-8xb4c" in namespace "job-4949" to be "adopted"
Nov 12 12:18:03.412: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 6.194197ms
Nov 12 12:18:05.421: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.015773434s
Nov 12 12:18:05.421: INFO: Pod "adopt-release-8xb4c" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 11/12/22 12:18:05.421
Nov 12 12:18:05.935: INFO: Successfully updated pod "adopt-release-8xb4c"
STEP: Checking that the Job releases the Pod 11/12/22 12:18:05.935
Nov 12 12:18:05.935: INFO: Waiting up to 15m0s for pod "adopt-release-8xb4c" in namespace "job-4949" to be "released"
Nov 12 12:18:05.941: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 5.363814ms
Nov 12 12:18:07.946: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.010568929s
Nov 12 12:18:07.946: INFO: Pod "adopt-release-8xb4c" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 12 12:18:07.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4949" for this suite. 11/12/22 12:18:07.951
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":81,"skipped":1714,"failed":0}
------------------------------
• [SLOW TEST] [7.164 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:18:00.798
    Nov 12 12:18:00.799: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename job 11/12/22 12:18:00.799
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:00.83
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:00.842
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 11/12/22 12:18:00.845
    STEP: Ensuring active pods == parallelism 11/12/22 12:18:00.876
    STEP: Orphaning one of the Job's Pods 11/12/22 12:18:02.882
    Nov 12 12:18:03.405: INFO: Successfully updated pod "adopt-release-8xb4c"
    STEP: Checking that the Job readopts the Pod 11/12/22 12:18:03.405
    Nov 12 12:18:03.405: INFO: Waiting up to 15m0s for pod "adopt-release-8xb4c" in namespace "job-4949" to be "adopted"
    Nov 12 12:18:03.412: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 6.194197ms
    Nov 12 12:18:05.421: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.015773434s
    Nov 12 12:18:05.421: INFO: Pod "adopt-release-8xb4c" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 11/12/22 12:18:05.421
    Nov 12 12:18:05.935: INFO: Successfully updated pod "adopt-release-8xb4c"
    STEP: Checking that the Job releases the Pod 11/12/22 12:18:05.935
    Nov 12 12:18:05.935: INFO: Waiting up to 15m0s for pod "adopt-release-8xb4c" in namespace "job-4949" to be "released"
    Nov 12 12:18:05.941: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 5.363814ms
    Nov 12 12:18:07.946: INFO: Pod "adopt-release-8xb4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.010568929s
    Nov 12 12:18:07.946: INFO: Pod "adopt-release-8xb4c" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 12 12:18:07.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4949" for this suite. 11/12/22 12:18:07.951
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:18:07.964
Nov 12 12:18:07.964: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 12:18:07.966
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:07.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:07.989
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Nov 12 12:18:08.005: INFO: Waiting up to 2m0s for pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" in namespace "var-expansion-7460" to be "container 0 failed with reason CreateContainerConfigError"
Nov 12 12:18:08.013: INFO: Pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.306084ms
Nov 12 12:18:10.020: INFO: Pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015029273s
Nov 12 12:18:10.020: INFO: Pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 12 12:18:10.020: INFO: Deleting pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" in namespace "var-expansion-7460"
Nov 12 12:18:10.032: INFO: Wait up to 5m0s for pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 12:18:12.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7460" for this suite. 11/12/22 12:18:12.068
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":82,"skipped":1724,"failed":0}
------------------------------
• [4.114 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:18:07.964
    Nov 12 12:18:07.964: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 12:18:07.966
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:07.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:07.989
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Nov 12 12:18:08.005: INFO: Waiting up to 2m0s for pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" in namespace "var-expansion-7460" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 12 12:18:08.013: INFO: Pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.306084ms
    Nov 12 12:18:10.020: INFO: Pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015029273s
    Nov 12 12:18:10.020: INFO: Pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 12 12:18:10.020: INFO: Deleting pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" in namespace "var-expansion-7460"
    Nov 12 12:18:10.032: INFO: Wait up to 5m0s for pod "var-expansion-9a3bc227-6478-44b1-940c-fa067301037d" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 12:18:12.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7460" for this suite. 11/12/22 12:18:12.068
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:18:12.08
Nov 12 12:18:12.081: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:18:12.081
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:12.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:12.105
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-3517 11/12/22 12:18:12.107
STEP: creating service affinity-nodeport in namespace services-3517 11/12/22 12:18:12.107
STEP: creating replication controller affinity-nodeport in namespace services-3517 11/12/22 12:18:12.13
I1112 12:18:12.145472      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-3517, replica count: 3
I1112 12:18:15.197088      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 12:18:15.217: INFO: Creating new exec pod
Nov 12 12:18:15.227: INFO: Waiting up to 5m0s for pod "execpod-affinityjh8cj" in namespace "services-3517" to be "running"
Nov 12 12:18:15.234: INFO: Pod "execpod-affinityjh8cj": Phase="Pending", Reason="", readiness=false. Elapsed: 7.249879ms
Nov 12 12:18:17.243: INFO: Pod "execpod-affinityjh8cj": Phase="Running", Reason="", readiness=true. Elapsed: 2.015796876s
Nov 12 12:18:17.243: INFO: Pod "execpod-affinityjh8cj" satisfied condition "running"
Nov 12 12:18:18.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 12 12:18:18.412: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Nov 12 12:18:18.412: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:18:18.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.52 80'
Nov 12 12:18:18.575: INFO: stderr: "+ nc -v -t -w 2 10.152.183.52 80\n+ echo hostName\nConnection to 10.152.183.52 80 port [tcp/http] succeeded!\n"
Nov 12 12:18:18.575: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:18:18.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 31638'
Nov 12 12:18:18.724: INFO: stderr: "+ nc -v -t+  -w 2echo 172.31.89.190 hostName 31638\n\nConnection to 172.31.89.190 31638 port [tcp/*] succeeded!\n"
Nov 12 12:18:18.724: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:18:18.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.14.110 31638'
Nov 12 12:18:18.925: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.14.110 31638\nConnection to 172.31.14.110 31638 port [tcp/*] succeeded!\n"
Nov 12 12:18:18.925: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:18:18.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:31638/ ; done'
Nov 12 12:18:19.189: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n"
Nov 12 12:18:19.189: INFO: stdout: "\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj"
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
Nov 12 12:18:19.189: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-3517, will wait for the garbage collector to delete the pods 11/12/22 12:18:19.213
Nov 12 12:18:19.276: INFO: Deleting ReplicationController affinity-nodeport took: 8.092752ms
Nov 12 12:18:19.376: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.255974ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:18:21.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3517" for this suite. 11/12/22 12:18:21.518
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":83,"skipped":1749,"failed":0}
------------------------------
• [SLOW TEST] [9.447 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:18:12.08
    Nov 12 12:18:12.081: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:18:12.081
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:12.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:12.105
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-3517 11/12/22 12:18:12.107
    STEP: creating service affinity-nodeport in namespace services-3517 11/12/22 12:18:12.107
    STEP: creating replication controller affinity-nodeport in namespace services-3517 11/12/22 12:18:12.13
    I1112 12:18:12.145472      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-3517, replica count: 3
    I1112 12:18:15.197088      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 12:18:15.217: INFO: Creating new exec pod
    Nov 12 12:18:15.227: INFO: Waiting up to 5m0s for pod "execpod-affinityjh8cj" in namespace "services-3517" to be "running"
    Nov 12 12:18:15.234: INFO: Pod "execpod-affinityjh8cj": Phase="Pending", Reason="", readiness=false. Elapsed: 7.249879ms
    Nov 12 12:18:17.243: INFO: Pod "execpod-affinityjh8cj": Phase="Running", Reason="", readiness=true. Elapsed: 2.015796876s
    Nov 12 12:18:17.243: INFO: Pod "execpod-affinityjh8cj" satisfied condition "running"
    Nov 12 12:18:18.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 12 12:18:18.412: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Nov 12 12:18:18.412: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:18:18.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.52 80'
    Nov 12 12:18:18.575: INFO: stderr: "+ nc -v -t -w 2 10.152.183.52 80\n+ echo hostName\nConnection to 10.152.183.52 80 port [tcp/http] succeeded!\n"
    Nov 12 12:18:18.575: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:18:18.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 31638'
    Nov 12 12:18:18.724: INFO: stderr: "+ nc -v -t+  -w 2echo 172.31.89.190 hostName 31638\n\nConnection to 172.31.89.190 31638 port [tcp/*] succeeded!\n"
    Nov 12 12:18:18.724: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:18:18.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.14.110 31638'
    Nov 12 12:18:18.925: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.14.110 31638\nConnection to 172.31.14.110 31638 port [tcp/*] succeeded!\n"
    Nov 12 12:18:18.925: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:18:18.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3517 exec execpod-affinityjh8cj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:31638/ ; done'
    Nov 12 12:18:19.189: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:31638/\n"
    Nov 12 12:18:19.189: INFO: stdout: "\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj\naffinity-nodeport-47stj"
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Received response from host: affinity-nodeport-47stj
    Nov 12 12:18:19.189: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-3517, will wait for the garbage collector to delete the pods 11/12/22 12:18:19.213
    Nov 12 12:18:19.276: INFO: Deleting ReplicationController affinity-nodeport took: 8.092752ms
    Nov 12 12:18:19.376: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.255974ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:18:21.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3517" for this suite. 11/12/22 12:18:21.518
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:18:21.529
Nov 12 12:18:21.529: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename daemonsets 11/12/22 12:18:21.53
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:21.548
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:21.551
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Nov 12 12:18:21.591: INFO: Create a RollingUpdate DaemonSet
Nov 12 12:18:21.602: INFO: Check that daemon pods launch on every node of the cluster
Nov 12 12:18:21.611: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:21.611: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:21.619: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:18:21.619: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:18:22.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:22.626: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:22.630: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:18:22.631: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:18:23.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:23.626: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:23.630: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:18:23.630: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:18:24.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:24.627: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:24.632: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:18:24.632: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:18:25.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:25.627: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:25.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 12:18:25.631: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Nov 12 12:18:25.631: INFO: Update the DaemonSet to trigger a rollout
Nov 12 12:18:25.644: INFO: Updating DaemonSet daemon-set
Nov 12 12:18:28.670: INFO: Roll back the DaemonSet before rollout is complete
Nov 12 12:18:28.685: INFO: Updating DaemonSet daemon-set
Nov 12 12:18:28.685: INFO: Make sure DaemonSet rollback is complete
Nov 12 12:18:28.693: INFO: Wrong image for pod: daemon-set-cs84q. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Nov 12 12:18:28.693: INFO: Pod daemon-set-cs84q is not available
Nov 12 12:18:28.697: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:28.697: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:29.706: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:29.707: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:30.705: INFO: Pod daemon-set-fwmmp is not available
Nov 12 12:18:30.710: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:18:30.710: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:18:30.727
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4413, will wait for the garbage collector to delete the pods 11/12/22 12:18:30.727
Nov 12 12:18:30.796: INFO: Deleting DaemonSet.extensions daemon-set took: 14.376886ms
Nov 12 12:18:30.896: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.29278ms
Nov 12 12:18:32.301: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:18:32.301: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 12 12:18:32.306: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10634"},"items":null}

Nov 12 12:18:32.311: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10634"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:18:32.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4413" for this suite. 11/12/22 12:18:32.333
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":84,"skipped":1756,"failed":0}
------------------------------
• [SLOW TEST] [10.813 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:18:21.529
    Nov 12 12:18:21.529: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename daemonsets 11/12/22 12:18:21.53
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:21.548
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:21.551
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Nov 12 12:18:21.591: INFO: Create a RollingUpdate DaemonSet
    Nov 12 12:18:21.602: INFO: Check that daemon pods launch on every node of the cluster
    Nov 12 12:18:21.611: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:21.611: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:21.619: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:18:21.619: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:18:22.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:22.626: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:22.630: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:18:22.631: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:18:23.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:23.626: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:23.630: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:18:23.630: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:18:24.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:24.627: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:24.632: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:18:24.632: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:18:25.626: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:25.627: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:25.631: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 12:18:25.631: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Nov 12 12:18:25.631: INFO: Update the DaemonSet to trigger a rollout
    Nov 12 12:18:25.644: INFO: Updating DaemonSet daemon-set
    Nov 12 12:18:28.670: INFO: Roll back the DaemonSet before rollout is complete
    Nov 12 12:18:28.685: INFO: Updating DaemonSet daemon-set
    Nov 12 12:18:28.685: INFO: Make sure DaemonSet rollback is complete
    Nov 12 12:18:28.693: INFO: Wrong image for pod: daemon-set-cs84q. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Nov 12 12:18:28.693: INFO: Pod daemon-set-cs84q is not available
    Nov 12 12:18:28.697: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:28.697: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:29.706: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:29.707: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:30.705: INFO: Pod daemon-set-fwmmp is not available
    Nov 12 12:18:30.710: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:18:30.710: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:18:30.727
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4413, will wait for the garbage collector to delete the pods 11/12/22 12:18:30.727
    Nov 12 12:18:30.796: INFO: Deleting DaemonSet.extensions daemon-set took: 14.376886ms
    Nov 12 12:18:30.896: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.29278ms
    Nov 12 12:18:32.301: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:18:32.301: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 12 12:18:32.306: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"10634"},"items":null}

    Nov 12 12:18:32.311: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"10634"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:18:32.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4413" for this suite. 11/12/22 12:18:32.333
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:18:32.346
Nov 12 12:18:32.346: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename watch 11/12/22 12:18:32.347
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:32.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:32.382
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 11/12/22 12:18:32.385
STEP: creating a new configmap 11/12/22 12:18:32.386
STEP: modifying the configmap once 11/12/22 12:18:32.396
STEP: changing the label value of the configmap 11/12/22 12:18:32.409
STEP: Expecting to observe a delete notification for the watched object 11/12/22 12:18:32.421
Nov 12 12:18:32.421: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10641 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:18:32.422: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10642 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:18:32.422: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10643 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 11/12/22 12:18:32.422
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/12/22 12:18:32.436
STEP: changing the label value of the configmap back 11/12/22 12:18:42.438
STEP: modifying the configmap a third time 11/12/22 12:18:42.45
STEP: deleting the configmap 11/12/22 12:18:42.461
STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/12/22 12:18:42.47
Nov 12 12:18:42.470: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10706 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:18:42.470: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10707 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:18:42.471: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10708 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 12:18:42.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6029" for this suite. 11/12/22 12:18:42.48
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":85,"skipped":1793,"failed":0}
------------------------------
• [SLOW TEST] [10.146 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:18:32.346
    Nov 12 12:18:32.346: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename watch 11/12/22 12:18:32.347
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:32.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:32.382
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 11/12/22 12:18:32.385
    STEP: creating a new configmap 11/12/22 12:18:32.386
    STEP: modifying the configmap once 11/12/22 12:18:32.396
    STEP: changing the label value of the configmap 11/12/22 12:18:32.409
    STEP: Expecting to observe a delete notification for the watched object 11/12/22 12:18:32.421
    Nov 12 12:18:32.421: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10641 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:18:32.422: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10642 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:18:32.422: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10643 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:32 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 11/12/22 12:18:32.422
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/12/22 12:18:32.436
    STEP: changing the label value of the configmap back 11/12/22 12:18:42.438
    STEP: modifying the configmap a third time 11/12/22 12:18:42.45
    STEP: deleting the configmap 11/12/22 12:18:42.461
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/12/22 12:18:42.47
    Nov 12 12:18:42.470: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10706 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:18:42.470: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10707 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:18:42.471: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6029  c68145a0-8519-42d5-928c-adbc96413644 10708 0 2022-11-12 12:18:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-12 12:18:42 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 12:18:42.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-6029" for this suite. 11/12/22 12:18:42.48
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:18:42.494
Nov 12 12:18:42.494: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename watch 11/12/22 12:18:42.495
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:42.515
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:42.522
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 11/12/22 12:18:42.525
STEP: starting a background goroutine to produce watch events 11/12/22 12:18:42.529
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/12/22 12:18:42.529
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 12:18:45.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3089" for this suite. 11/12/22 12:18:45.351
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":86,"skipped":1819,"failed":0}
------------------------------
• [2.913 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:18:42.494
    Nov 12 12:18:42.494: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename watch 11/12/22 12:18:42.495
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:42.515
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:42.522
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 11/12/22 12:18:42.525
    STEP: starting a background goroutine to produce watch events 11/12/22 12:18:42.529
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/12/22 12:18:42.529
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 12:18:45.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-3089" for this suite. 11/12/22 12:18:45.351
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:18:45.41
Nov 12 12:18:45.410: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 12:18:45.411
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:45.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:45.431
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 11/12/22 12:18:45.434
STEP: waiting for pod running 11/12/22 12:18:45.447
Nov 12 12:18:45.447: INFO: Waiting up to 2m0s for pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" in namespace "var-expansion-5275" to be "running"
Nov 12 12:18:45.455: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131": Phase="Pending", Reason="", readiness=false. Elapsed: 7.587725ms
Nov 12 12:18:47.460: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131": Phase="Running", Reason="", readiness=true. Elapsed: 2.01291942s
Nov 12 12:18:47.460: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" satisfied condition "running"
STEP: creating a file in subpath 11/12/22 12:18:47.461
Nov 12 12:18:47.465: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5275 PodName:var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:18:47.465: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:18:47.466: INFO: ExecWithOptions: Clientset creation
Nov 12 12:18:47.466: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5275/pods/var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 11/12/22 12:18:47.54
Nov 12 12:18:47.544: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5275 PodName:var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:18:47.544: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:18:47.545: INFO: ExecWithOptions: Clientset creation
Nov 12 12:18:47.545: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5275/pods/var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 11/12/22 12:18:47.616
Nov 12 12:18:48.134: INFO: Successfully updated pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131"
STEP: waiting for annotated pod running 11/12/22 12:18:48.134
Nov 12 12:18:48.134: INFO: Waiting up to 2m0s for pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" in namespace "var-expansion-5275" to be "running"
Nov 12 12:18:48.138: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131": Phase="Running", Reason="", readiness=true. Elapsed: 3.875857ms
Nov 12 12:18:48.138: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" satisfied condition "running"
STEP: deleting the pod gracefully 11/12/22 12:18:48.138
Nov 12 12:18:48.138: INFO: Deleting pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" in namespace "var-expansion-5275"
Nov 12 12:18:48.149: INFO: Wait up to 5m0s for pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 12:19:22.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5275" for this suite. 11/12/22 12:19:22.166
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":87,"skipped":1825,"failed":0}
------------------------------
• [SLOW TEST] [36.767 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:18:45.41
    Nov 12 12:18:45.410: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 12:18:45.411
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:18:45.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:18:45.431
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 11/12/22 12:18:45.434
    STEP: waiting for pod running 11/12/22 12:18:45.447
    Nov 12 12:18:45.447: INFO: Waiting up to 2m0s for pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" in namespace "var-expansion-5275" to be "running"
    Nov 12 12:18:45.455: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131": Phase="Pending", Reason="", readiness=false. Elapsed: 7.587725ms
    Nov 12 12:18:47.460: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131": Phase="Running", Reason="", readiness=true. Elapsed: 2.01291942s
    Nov 12 12:18:47.460: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" satisfied condition "running"
    STEP: creating a file in subpath 11/12/22 12:18:47.461
    Nov 12 12:18:47.465: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5275 PodName:var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:18:47.465: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:18:47.466: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:18:47.466: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5275/pods/var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 11/12/22 12:18:47.54
    Nov 12 12:18:47.544: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5275 PodName:var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:18:47.544: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:18:47.545: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:18:47.545: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5275/pods/var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 11/12/22 12:18:47.616
    Nov 12 12:18:48.134: INFO: Successfully updated pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131"
    STEP: waiting for annotated pod running 11/12/22 12:18:48.134
    Nov 12 12:18:48.134: INFO: Waiting up to 2m0s for pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" in namespace "var-expansion-5275" to be "running"
    Nov 12 12:18:48.138: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131": Phase="Running", Reason="", readiness=true. Elapsed: 3.875857ms
    Nov 12 12:18:48.138: INFO: Pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" satisfied condition "running"
    STEP: deleting the pod gracefully 11/12/22 12:18:48.138
    Nov 12 12:18:48.138: INFO: Deleting pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" in namespace "var-expansion-5275"
    Nov 12 12:18:48.149: INFO: Wait up to 5m0s for pod "var-expansion-634ff23f-ac33-4e0a-9197-bbd57d0ae131" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 12:19:22.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5275" for this suite. 11/12/22 12:19:22.166
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:19:22.177
Nov 12 12:19:22.178: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-watch 11/12/22 12:19:22.178
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:19:22.204
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:19:22.208
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Nov 12 12:19:22.212: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Creating first CR  11/12/22 12:19:24.776
Nov 12 12:19:24.782: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:24Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:24Z]] name:name1 resourceVersion:10987 uid:f7ea5e78-e0a3-4743-a9cb-4f61eb85db0e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 11/12/22 12:19:34.785
Nov 12 12:19:34.795: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:34Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:34Z]] name:name2 resourceVersion:11017 uid:e528d959-32b9-4c1e-9fde-6b9698dc1872] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 11/12/22 12:19:44.799
Nov 12 12:19:44.808: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:44Z]] name:name1 resourceVersion:11036 uid:f7ea5e78-e0a3-4743-a9cb-4f61eb85db0e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 11/12/22 12:19:54.811
Nov 12 12:19:54.819: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:54Z]] name:name2 resourceVersion:11056 uid:e528d959-32b9-4c1e-9fde-6b9698dc1872] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 11/12/22 12:20:04.823
Nov 12 12:20:04.839: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:44Z]] name:name1 resourceVersion:11075 uid:f7ea5e78-e0a3-4743-a9cb-4f61eb85db0e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 11/12/22 12:20:14.839
Nov 12 12:20:14.851: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:54Z]] name:name2 resourceVersion:11094 uid:e528d959-32b9-4c1e-9fde-6b9698dc1872] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:20:25.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4648" for this suite. 11/12/22 12:20:25.384
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":88,"skipped":1838,"failed":0}
------------------------------
• [SLOW TEST] [63.217 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:19:22.177
    Nov 12 12:19:22.178: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-watch 11/12/22 12:19:22.178
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:19:22.204
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:19:22.208
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Nov 12 12:19:22.212: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Creating first CR  11/12/22 12:19:24.776
    Nov 12 12:19:24.782: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:24Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:24Z]] name:name1 resourceVersion:10987 uid:f7ea5e78-e0a3-4743-a9cb-4f61eb85db0e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 11/12/22 12:19:34.785
    Nov 12 12:19:34.795: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:34Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:34Z]] name:name2 resourceVersion:11017 uid:e528d959-32b9-4c1e-9fde-6b9698dc1872] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 11/12/22 12:19:44.799
    Nov 12 12:19:44.808: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:44Z]] name:name1 resourceVersion:11036 uid:f7ea5e78-e0a3-4743-a9cb-4f61eb85db0e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 11/12/22 12:19:54.811
    Nov 12 12:19:54.819: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:54Z]] name:name2 resourceVersion:11056 uid:e528d959-32b9-4c1e-9fde-6b9698dc1872] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 11/12/22 12:20:04.823
    Nov 12 12:20:04.839: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:24Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:44Z]] name:name1 resourceVersion:11075 uid:f7ea5e78-e0a3-4743-a9cb-4f61eb85db0e] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 11/12/22 12:20:14.839
    Nov 12 12:20:14.851: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-12T12:19:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-12T12:19:54Z]] name:name2 resourceVersion:11094 uid:e528d959-32b9-4c1e-9fde-6b9698dc1872] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:20:25.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-4648" for this suite. 11/12/22 12:20:25.384
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:20:25.395
Nov 12 12:20:25.395: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:20:25.396
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:25.421
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:25.432
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:20:25.441
Nov 12 12:20:25.451: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4313" to be "running and ready"
Nov 12 12:20:25.465: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.592368ms
Nov 12 12:20:25.465: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:20:27.471: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.019836008s
Nov 12 12:20:27.471: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 12 12:20:27.471: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 11/12/22 12:20:27.477
Nov 12 12:20:27.489: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4313" to be "running and ready"
Nov 12 12:20:27.499: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 10.569639ms
Nov 12 12:20:27.499: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:20:29.504: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015518383s
Nov 12 12:20:29.504: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Nov 12 12:20:29.504: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/12/22 12:20:29.51
STEP: delete the pod with lifecycle hook 11/12/22 12:20:29.531
Nov 12 12:20:29.543: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 12 12:20:29.548: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 12 12:20:31.549: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 12 12:20:31.555: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 12 12:20:33.548: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 12 12:20:33.554: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 12 12:20:33.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4313" for this suite. 11/12/22 12:20:33.56
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":89,"skipped":1842,"failed":0}
------------------------------
• [SLOW TEST] [8.175 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:20:25.395
    Nov 12 12:20:25.395: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:20:25.396
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:25.421
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:25.432
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:20:25.441
    Nov 12 12:20:25.451: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4313" to be "running and ready"
    Nov 12 12:20:25.465: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 13.592368ms
    Nov 12 12:20:25.465: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:20:27.471: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.019836008s
    Nov 12 12:20:27.471: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 12 12:20:27.471: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 11/12/22 12:20:27.477
    Nov 12 12:20:27.489: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4313" to be "running and ready"
    Nov 12 12:20:27.499: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 10.569639ms
    Nov 12 12:20:27.499: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:20:29.504: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.015518383s
    Nov 12 12:20:29.504: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Nov 12 12:20:29.504: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/12/22 12:20:29.51
    STEP: delete the pod with lifecycle hook 11/12/22 12:20:29.531
    Nov 12 12:20:29.543: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 12 12:20:29.548: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov 12 12:20:31.549: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 12 12:20:31.555: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov 12 12:20:33.548: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 12 12:20:33.554: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 12 12:20:33.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4313" for this suite. 11/12/22 12:20:33.56
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:20:33.573
Nov 12 12:20:33.573: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replication-controller 11/12/22 12:20:33.573
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:33.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:33.6
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9 11/12/22 12:20:33.603
Nov 12 12:20:33.618: INFO: Pod name my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9: Found 0 pods out of 1
Nov 12 12:20:38.625: INFO: Pod name my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9: Found 1 pods out of 1
Nov 12 12:20:38.626: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9" are running
Nov 12 12:20:38.626: INFO: Waiting up to 5m0s for pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c" in namespace "replication-controller-2566" to be "running"
Nov 12 12:20:38.632: INFO: Pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c": Phase="Running", Reason="", readiness=true. Elapsed: 5.943286ms
Nov 12 12:20:38.632: INFO: Pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c" satisfied condition "running"
Nov 12 12:20:38.632: INFO: Pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:33 +0000 UTC Reason: Message:}])
Nov 12 12:20:38.632: INFO: Trying to dial the pod
Nov 12 12:20:43.647: INFO: Controller my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9: Got expected result from replica 1 [my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c]: "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 12:20:43.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2566" for this suite. 11/12/22 12:20:43.652
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":90,"skipped":1862,"failed":0}
------------------------------
• [SLOW TEST] [10.089 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:20:33.573
    Nov 12 12:20:33.573: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replication-controller 11/12/22 12:20:33.573
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:33.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:33.6
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9 11/12/22 12:20:33.603
    Nov 12 12:20:33.618: INFO: Pod name my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9: Found 0 pods out of 1
    Nov 12 12:20:38.625: INFO: Pod name my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9: Found 1 pods out of 1
    Nov 12 12:20:38.626: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9" are running
    Nov 12 12:20:38.626: INFO: Waiting up to 5m0s for pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c" in namespace "replication-controller-2566" to be "running"
    Nov 12 12:20:38.632: INFO: Pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c": Phase="Running", Reason="", readiness=true. Elapsed: 5.943286ms
    Nov 12 12:20:38.632: INFO: Pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c" satisfied condition "running"
    Nov 12 12:20:38.632: INFO: Pod "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-12 12:20:33 +0000 UTC Reason: Message:}])
    Nov 12 12:20:38.632: INFO: Trying to dial the pod
    Nov 12 12:20:43.647: INFO: Controller my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9: Got expected result from replica 1 [my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c]: "my-hostname-basic-65bc3127-e265-47eb-a3e8-521275a61ae9-rv97c", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 12:20:43.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2566" for this suite. 11/12/22 12:20:43.652
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:20:43.666
Nov 12 12:20:43.666: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 12:20:43.667
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:43.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:43.688
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 11/12/22 12:20:43.693
Nov 12 12:20:43.709: INFO: Waiting up to 5m0s for pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6" in namespace "var-expansion-1257" to be "Succeeded or Failed"
Nov 12 12:20:43.714: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.400539ms
Nov 12 12:20:45.721: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012255729s
Nov 12 12:20:47.721: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012564649s
STEP: Saw pod success 11/12/22 12:20:47.721
Nov 12 12:20:47.721: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6" satisfied condition "Succeeded or Failed"
Nov 12 12:20:47.725: INFO: Trying to get logs from node ip-172-31-89-190 pod var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6 container dapi-container: <nil>
STEP: delete the pod 11/12/22 12:20:47.745
Nov 12 12:20:47.768: INFO: Waiting for pod var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6 to disappear
Nov 12 12:20:47.771: INFO: Pod var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 12:20:47.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1257" for this suite. 11/12/22 12:20:47.775
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":91,"skipped":1922,"failed":0}
------------------------------
• [4.117 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:20:43.666
    Nov 12 12:20:43.666: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 12:20:43.667
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:43.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:43.688
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 11/12/22 12:20:43.693
    Nov 12 12:20:43.709: INFO: Waiting up to 5m0s for pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6" in namespace "var-expansion-1257" to be "Succeeded or Failed"
    Nov 12 12:20:43.714: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.400539ms
    Nov 12 12:20:45.721: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012255729s
    Nov 12 12:20:47.721: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012564649s
    STEP: Saw pod success 11/12/22 12:20:47.721
    Nov 12 12:20:47.721: INFO: Pod "var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6" satisfied condition "Succeeded or Failed"
    Nov 12 12:20:47.725: INFO: Trying to get logs from node ip-172-31-89-190 pod var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 12:20:47.745
    Nov 12 12:20:47.768: INFO: Waiting for pod var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6 to disappear
    Nov 12 12:20:47.771: INFO: Pod var-expansion-40bfd0e6-ada0-4987-bde9-1567f68793f6 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 12:20:47.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1257" for this suite. 11/12/22 12:20:47.775
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:20:47.783
Nov 12 12:20:47.784: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:20:47.784
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:47.806
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:47.811
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:20:47.839
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:20:48.364
STEP: Deploying the webhook pod 11/12/22 12:20:48.375
STEP: Wait for the deployment to be ready 11/12/22 12:20:48.39
Nov 12 12:20:48.402: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:20:50.417
STEP: Verifying the service has paired with the endpoint 11/12/22 12:20:50.431
Nov 12 12:20:51.431: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 11/12/22 12:20:51.437
STEP: create a pod that should be denied by the webhook 11/12/22 12:20:51.461
STEP: create a pod that causes the webhook to hang 11/12/22 12:20:51.472
STEP: create a configmap that should be denied by the webhook 11/12/22 12:21:01.488
STEP: create a configmap that should be admitted by the webhook 11/12/22 12:21:01.496
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/12/22 12:21:01.507
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/12/22 12:21:01.517
STEP: create a namespace that bypass the webhook 11/12/22 12:21:01.524
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/12/22 12:21:01.535
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:21:01.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5275" for this suite. 11/12/22 12:21:01.572
STEP: Destroying namespace "webhook-5275-markers" for this suite. 11/12/22 12:21:01.581
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":92,"skipped":1924,"failed":0}
------------------------------
• [SLOW TEST] [13.897 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:20:47.783
    Nov 12 12:20:47.784: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:20:47.784
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:20:47.806
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:20:47.811
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:20:47.839
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:20:48.364
    STEP: Deploying the webhook pod 11/12/22 12:20:48.375
    STEP: Wait for the deployment to be ready 11/12/22 12:20:48.39
    Nov 12 12:20:48.402: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:20:50.417
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:20:50.431
    Nov 12 12:20:51.431: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 11/12/22 12:20:51.437
    STEP: create a pod that should be denied by the webhook 11/12/22 12:20:51.461
    STEP: create a pod that causes the webhook to hang 11/12/22 12:20:51.472
    STEP: create a configmap that should be denied by the webhook 11/12/22 12:21:01.488
    STEP: create a configmap that should be admitted by the webhook 11/12/22 12:21:01.496
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/12/22 12:21:01.507
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/12/22 12:21:01.517
    STEP: create a namespace that bypass the webhook 11/12/22 12:21:01.524
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/12/22 12:21:01.535
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:21:01.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5275" for this suite. 11/12/22 12:21:01.572
    STEP: Destroying namespace "webhook-5275-markers" for this suite. 11/12/22 12:21:01.581
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:21:01.681
Nov 12 12:21:01.681: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename gc 11/12/22 12:21:01.682
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:21:01.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:21:01.718
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 11/12/22 12:21:01.727
STEP: delete the rc 11/12/22 12:21:06.738
STEP: wait for the rc to be deleted 11/12/22 12:21:06.762
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/12/22 12:21:11.791
STEP: Gathering metrics 11/12/22 12:21:41.807
W1112 12:21:41.812640      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 12:21:41.812: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 12 12:21:41.812: INFO: Deleting pod "simpletest.rc-2hpdl" in namespace "gc-9089"
Nov 12 12:21:41.833: INFO: Deleting pod "simpletest.rc-4s6j6" in namespace "gc-9089"
Nov 12 12:21:41.849: INFO: Deleting pod "simpletest.rc-5ctmv" in namespace "gc-9089"
Nov 12 12:21:41.865: INFO: Deleting pod "simpletest.rc-65vft" in namespace "gc-9089"
Nov 12 12:21:41.886: INFO: Deleting pod "simpletest.rc-6826x" in namespace "gc-9089"
Nov 12 12:21:41.906: INFO: Deleting pod "simpletest.rc-6qmdb" in namespace "gc-9089"
Nov 12 12:21:41.924: INFO: Deleting pod "simpletest.rc-6vbzm" in namespace "gc-9089"
Nov 12 12:21:41.945: INFO: Deleting pod "simpletest.rc-74gng" in namespace "gc-9089"
Nov 12 12:21:41.960: INFO: Deleting pod "simpletest.rc-7644n" in namespace "gc-9089"
Nov 12 12:21:42.069: INFO: Deleting pod "simpletest.rc-77grx" in namespace "gc-9089"
Nov 12 12:21:42.091: INFO: Deleting pod "simpletest.rc-867j4" in namespace "gc-9089"
Nov 12 12:21:42.118: INFO: Deleting pod "simpletest.rc-868sp" in namespace "gc-9089"
Nov 12 12:21:42.143: INFO: Deleting pod "simpletest.rc-8b2w4" in namespace "gc-9089"
Nov 12 12:21:42.166: INFO: Deleting pod "simpletest.rc-8fbm9" in namespace "gc-9089"
Nov 12 12:21:42.185: INFO: Deleting pod "simpletest.rc-8ls52" in namespace "gc-9089"
Nov 12 12:21:42.201: INFO: Deleting pod "simpletest.rc-8mlfg" in namespace "gc-9089"
Nov 12 12:21:42.218: INFO: Deleting pod "simpletest.rc-8qcch" in namespace "gc-9089"
Nov 12 12:21:42.246: INFO: Deleting pod "simpletest.rc-b2hmd" in namespace "gc-9089"
Nov 12 12:21:42.266: INFO: Deleting pod "simpletest.rc-bhgzb" in namespace "gc-9089"
Nov 12 12:21:42.287: INFO: Deleting pod "simpletest.rc-cbthl" in namespace "gc-9089"
Nov 12 12:21:42.309: INFO: Deleting pod "simpletest.rc-clwj5" in namespace "gc-9089"
Nov 12 12:21:42.336: INFO: Deleting pod "simpletest.rc-cvzhc" in namespace "gc-9089"
Nov 12 12:21:42.357: INFO: Deleting pod "simpletest.rc-d4sr4" in namespace "gc-9089"
Nov 12 12:21:42.384: INFO: Deleting pod "simpletest.rc-dccc9" in namespace "gc-9089"
Nov 12 12:21:42.404: INFO: Deleting pod "simpletest.rc-dg6ck" in namespace "gc-9089"
Nov 12 12:21:42.433: INFO: Deleting pod "simpletest.rc-dqb7c" in namespace "gc-9089"
Nov 12 12:21:42.453: INFO: Deleting pod "simpletest.rc-f9kd8" in namespace "gc-9089"
Nov 12 12:21:42.469: INFO: Deleting pod "simpletest.rc-fgkgj" in namespace "gc-9089"
Nov 12 12:21:42.485: INFO: Deleting pod "simpletest.rc-fn9dk" in namespace "gc-9089"
Nov 12 12:21:42.500: INFO: Deleting pod "simpletest.rc-fpw9s" in namespace "gc-9089"
Nov 12 12:21:42.518: INFO: Deleting pod "simpletest.rc-g42mw" in namespace "gc-9089"
Nov 12 12:21:42.551: INFO: Deleting pod "simpletest.rc-g44jr" in namespace "gc-9089"
Nov 12 12:21:42.571: INFO: Deleting pod "simpletest.rc-gsflg" in namespace "gc-9089"
Nov 12 12:21:42.591: INFO: Deleting pod "simpletest.rc-hjj4x" in namespace "gc-9089"
Nov 12 12:21:42.611: INFO: Deleting pod "simpletest.rc-hkplt" in namespace "gc-9089"
Nov 12 12:21:42.634: INFO: Deleting pod "simpletest.rc-hwghf" in namespace "gc-9089"
Nov 12 12:21:42.648: INFO: Deleting pod "simpletest.rc-j58hw" in namespace "gc-9089"
Nov 12 12:21:42.668: INFO: Deleting pod "simpletest.rc-jjvhp" in namespace "gc-9089"
Nov 12 12:21:42.686: INFO: Deleting pod "simpletest.rc-jkjrh" in namespace "gc-9089"
Nov 12 12:21:42.709: INFO: Deleting pod "simpletest.rc-jn4kf" in namespace "gc-9089"
Nov 12 12:21:42.730: INFO: Deleting pod "simpletest.rc-jnkzp" in namespace "gc-9089"
Nov 12 12:21:42.747: INFO: Deleting pod "simpletest.rc-kg62s" in namespace "gc-9089"
Nov 12 12:21:42.764: INFO: Deleting pod "simpletest.rc-kn9x4" in namespace "gc-9089"
Nov 12 12:21:42.789: INFO: Deleting pod "simpletest.rc-ksp6m" in namespace "gc-9089"
Nov 12 12:21:42.806: INFO: Deleting pod "simpletest.rc-kw675" in namespace "gc-9089"
Nov 12 12:21:42.823: INFO: Deleting pod "simpletest.rc-lfpks" in namespace "gc-9089"
Nov 12 12:21:42.840: INFO: Deleting pod "simpletest.rc-lnwq9" in namespace "gc-9089"
Nov 12 12:21:42.862: INFO: Deleting pod "simpletest.rc-lpk7b" in namespace "gc-9089"
Nov 12 12:21:42.880: INFO: Deleting pod "simpletest.rc-lqwbp" in namespace "gc-9089"
Nov 12 12:21:42.909: INFO: Deleting pod "simpletest.rc-lrkfs" in namespace "gc-9089"
Nov 12 12:21:42.923: INFO: Deleting pod "simpletest.rc-m4gtr" in namespace "gc-9089"
Nov 12 12:21:42.937: INFO: Deleting pod "simpletest.rc-mmmhb" in namespace "gc-9089"
Nov 12 12:21:42.953: INFO: Deleting pod "simpletest.rc-mqz5n" in namespace "gc-9089"
Nov 12 12:21:42.968: INFO: Deleting pod "simpletest.rc-n4c5l" in namespace "gc-9089"
Nov 12 12:21:42.985: INFO: Deleting pod "simpletest.rc-n5wcw" in namespace "gc-9089"
Nov 12 12:21:43.002: INFO: Deleting pod "simpletest.rc-ndtvg" in namespace "gc-9089"
Nov 12 12:21:43.021: INFO: Deleting pod "simpletest.rc-ng78j" in namespace "gc-9089"
Nov 12 12:21:43.039: INFO: Deleting pod "simpletest.rc-nlbf5" in namespace "gc-9089"
Nov 12 12:21:43.061: INFO: Deleting pod "simpletest.rc-nn6b8" in namespace "gc-9089"
Nov 12 12:21:43.075: INFO: Deleting pod "simpletest.rc-nr8kf" in namespace "gc-9089"
Nov 12 12:21:43.090: INFO: Deleting pod "simpletest.rc-ns84x" in namespace "gc-9089"
Nov 12 12:21:43.111: INFO: Deleting pod "simpletest.rc-nwh2v" in namespace "gc-9089"
Nov 12 12:21:43.132: INFO: Deleting pod "simpletest.rc-nzm8v" in namespace "gc-9089"
Nov 12 12:21:43.148: INFO: Deleting pod "simpletest.rc-p6b48" in namespace "gc-9089"
Nov 12 12:21:43.163: INFO: Deleting pod "simpletest.rc-pjwpm" in namespace "gc-9089"
Nov 12 12:21:43.177: INFO: Deleting pod "simpletest.rc-pr55h" in namespace "gc-9089"
Nov 12 12:21:43.191: INFO: Deleting pod "simpletest.rc-q2fg8" in namespace "gc-9089"
Nov 12 12:21:43.206: INFO: Deleting pod "simpletest.rc-q427c" in namespace "gc-9089"
Nov 12 12:21:43.222: INFO: Deleting pod "simpletest.rc-q6csx" in namespace "gc-9089"
Nov 12 12:21:43.241: INFO: Deleting pod "simpletest.rc-qfg2r" in namespace "gc-9089"
Nov 12 12:21:43.257: INFO: Deleting pod "simpletest.rc-qj62b" in namespace "gc-9089"
Nov 12 12:21:43.274: INFO: Deleting pod "simpletest.rc-qpmnv" in namespace "gc-9089"
Nov 12 12:21:43.288: INFO: Deleting pod "simpletest.rc-r8cc6" in namespace "gc-9089"
Nov 12 12:21:43.302: INFO: Deleting pod "simpletest.rc-rtvnz" in namespace "gc-9089"
Nov 12 12:21:43.318: INFO: Deleting pod "simpletest.rc-s88mh" in namespace "gc-9089"
Nov 12 12:21:43.333: INFO: Deleting pod "simpletest.rc-s8phv" in namespace "gc-9089"
Nov 12 12:21:43.347: INFO: Deleting pod "simpletest.rc-sqgz5" in namespace "gc-9089"
Nov 12 12:21:43.360: INFO: Deleting pod "simpletest.rc-sqxwf" in namespace "gc-9089"
Nov 12 12:21:43.375: INFO: Deleting pod "simpletest.rc-t4tbz" in namespace "gc-9089"
Nov 12 12:21:43.390: INFO: Deleting pod "simpletest.rc-ttvc7" in namespace "gc-9089"
Nov 12 12:21:43.406: INFO: Deleting pod "simpletest.rc-v2h8x" in namespace "gc-9089"
Nov 12 12:21:43.457: INFO: Deleting pod "simpletest.rc-vcfgt" in namespace "gc-9089"
Nov 12 12:21:43.511: INFO: Deleting pod "simpletest.rc-vwpfq" in namespace "gc-9089"
Nov 12 12:21:43.558: INFO: Deleting pod "simpletest.rc-w77sv" in namespace "gc-9089"
Nov 12 12:21:43.608: INFO: Deleting pod "simpletest.rc-wgh6h" in namespace "gc-9089"
Nov 12 12:21:43.661: INFO: Deleting pod "simpletest.rc-wnhcg" in namespace "gc-9089"
Nov 12 12:21:43.707: INFO: Deleting pod "simpletest.rc-wnjrs" in namespace "gc-9089"
Nov 12 12:21:43.757: INFO: Deleting pod "simpletest.rc-wt894" in namespace "gc-9089"
Nov 12 12:21:43.810: INFO: Deleting pod "simpletest.rc-wtc2w" in namespace "gc-9089"
Nov 12 12:21:43.857: INFO: Deleting pod "simpletest.rc-x69zd" in namespace "gc-9089"
Nov 12 12:21:43.906: INFO: Deleting pod "simpletest.rc-x7kth" in namespace "gc-9089"
Nov 12 12:21:43.958: INFO: Deleting pod "simpletest.rc-xbmn6" in namespace "gc-9089"
Nov 12 12:21:44.006: INFO: Deleting pod "simpletest.rc-xxqrd" in namespace "gc-9089"
Nov 12 12:21:44.063: INFO: Deleting pod "simpletest.rc-zcmkl" in namespace "gc-9089"
Nov 12 12:21:44.115: INFO: Deleting pod "simpletest.rc-zdfcg" in namespace "gc-9089"
Nov 12 12:21:44.158: INFO: Deleting pod "simpletest.rc-zj992" in namespace "gc-9089"
Nov 12 12:21:44.210: INFO: Deleting pod "simpletest.rc-znfrj" in namespace "gc-9089"
Nov 12 12:21:44.262: INFO: Deleting pod "simpletest.rc-znxht" in namespace "gc-9089"
Nov 12 12:21:44.311: INFO: Deleting pod "simpletest.rc-zttb7" in namespace "gc-9089"
Nov 12 12:21:44.363: INFO: Deleting pod "simpletest.rc-zxsj8" in namespace "gc-9089"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 12:21:44.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9089" for this suite. 11/12/22 12:21:44.449
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":93,"skipped":1933,"failed":0}
------------------------------
• [SLOW TEST] [42.823 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:21:01.681
    Nov 12 12:21:01.681: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename gc 11/12/22 12:21:01.682
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:21:01.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:21:01.718
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 11/12/22 12:21:01.727
    STEP: delete the rc 11/12/22 12:21:06.738
    STEP: wait for the rc to be deleted 11/12/22 12:21:06.762
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/12/22 12:21:11.791
    STEP: Gathering metrics 11/12/22 12:21:41.807
    W1112 12:21:41.812640      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 12:21:41.812: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 12 12:21:41.812: INFO: Deleting pod "simpletest.rc-2hpdl" in namespace "gc-9089"
    Nov 12 12:21:41.833: INFO: Deleting pod "simpletest.rc-4s6j6" in namespace "gc-9089"
    Nov 12 12:21:41.849: INFO: Deleting pod "simpletest.rc-5ctmv" in namespace "gc-9089"
    Nov 12 12:21:41.865: INFO: Deleting pod "simpletest.rc-65vft" in namespace "gc-9089"
    Nov 12 12:21:41.886: INFO: Deleting pod "simpletest.rc-6826x" in namespace "gc-9089"
    Nov 12 12:21:41.906: INFO: Deleting pod "simpletest.rc-6qmdb" in namespace "gc-9089"
    Nov 12 12:21:41.924: INFO: Deleting pod "simpletest.rc-6vbzm" in namespace "gc-9089"
    Nov 12 12:21:41.945: INFO: Deleting pod "simpletest.rc-74gng" in namespace "gc-9089"
    Nov 12 12:21:41.960: INFO: Deleting pod "simpletest.rc-7644n" in namespace "gc-9089"
    Nov 12 12:21:42.069: INFO: Deleting pod "simpletest.rc-77grx" in namespace "gc-9089"
    Nov 12 12:21:42.091: INFO: Deleting pod "simpletest.rc-867j4" in namespace "gc-9089"
    Nov 12 12:21:42.118: INFO: Deleting pod "simpletest.rc-868sp" in namespace "gc-9089"
    Nov 12 12:21:42.143: INFO: Deleting pod "simpletest.rc-8b2w4" in namespace "gc-9089"
    Nov 12 12:21:42.166: INFO: Deleting pod "simpletest.rc-8fbm9" in namespace "gc-9089"
    Nov 12 12:21:42.185: INFO: Deleting pod "simpletest.rc-8ls52" in namespace "gc-9089"
    Nov 12 12:21:42.201: INFO: Deleting pod "simpletest.rc-8mlfg" in namespace "gc-9089"
    Nov 12 12:21:42.218: INFO: Deleting pod "simpletest.rc-8qcch" in namespace "gc-9089"
    Nov 12 12:21:42.246: INFO: Deleting pod "simpletest.rc-b2hmd" in namespace "gc-9089"
    Nov 12 12:21:42.266: INFO: Deleting pod "simpletest.rc-bhgzb" in namespace "gc-9089"
    Nov 12 12:21:42.287: INFO: Deleting pod "simpletest.rc-cbthl" in namespace "gc-9089"
    Nov 12 12:21:42.309: INFO: Deleting pod "simpletest.rc-clwj5" in namespace "gc-9089"
    Nov 12 12:21:42.336: INFO: Deleting pod "simpletest.rc-cvzhc" in namespace "gc-9089"
    Nov 12 12:21:42.357: INFO: Deleting pod "simpletest.rc-d4sr4" in namespace "gc-9089"
    Nov 12 12:21:42.384: INFO: Deleting pod "simpletest.rc-dccc9" in namespace "gc-9089"
    Nov 12 12:21:42.404: INFO: Deleting pod "simpletest.rc-dg6ck" in namespace "gc-9089"
    Nov 12 12:21:42.433: INFO: Deleting pod "simpletest.rc-dqb7c" in namespace "gc-9089"
    Nov 12 12:21:42.453: INFO: Deleting pod "simpletest.rc-f9kd8" in namespace "gc-9089"
    Nov 12 12:21:42.469: INFO: Deleting pod "simpletest.rc-fgkgj" in namespace "gc-9089"
    Nov 12 12:21:42.485: INFO: Deleting pod "simpletest.rc-fn9dk" in namespace "gc-9089"
    Nov 12 12:21:42.500: INFO: Deleting pod "simpletest.rc-fpw9s" in namespace "gc-9089"
    Nov 12 12:21:42.518: INFO: Deleting pod "simpletest.rc-g42mw" in namespace "gc-9089"
    Nov 12 12:21:42.551: INFO: Deleting pod "simpletest.rc-g44jr" in namespace "gc-9089"
    Nov 12 12:21:42.571: INFO: Deleting pod "simpletest.rc-gsflg" in namespace "gc-9089"
    Nov 12 12:21:42.591: INFO: Deleting pod "simpletest.rc-hjj4x" in namespace "gc-9089"
    Nov 12 12:21:42.611: INFO: Deleting pod "simpletest.rc-hkplt" in namespace "gc-9089"
    Nov 12 12:21:42.634: INFO: Deleting pod "simpletest.rc-hwghf" in namespace "gc-9089"
    Nov 12 12:21:42.648: INFO: Deleting pod "simpletest.rc-j58hw" in namespace "gc-9089"
    Nov 12 12:21:42.668: INFO: Deleting pod "simpletest.rc-jjvhp" in namespace "gc-9089"
    Nov 12 12:21:42.686: INFO: Deleting pod "simpletest.rc-jkjrh" in namespace "gc-9089"
    Nov 12 12:21:42.709: INFO: Deleting pod "simpletest.rc-jn4kf" in namespace "gc-9089"
    Nov 12 12:21:42.730: INFO: Deleting pod "simpletest.rc-jnkzp" in namespace "gc-9089"
    Nov 12 12:21:42.747: INFO: Deleting pod "simpletest.rc-kg62s" in namespace "gc-9089"
    Nov 12 12:21:42.764: INFO: Deleting pod "simpletest.rc-kn9x4" in namespace "gc-9089"
    Nov 12 12:21:42.789: INFO: Deleting pod "simpletest.rc-ksp6m" in namespace "gc-9089"
    Nov 12 12:21:42.806: INFO: Deleting pod "simpletest.rc-kw675" in namespace "gc-9089"
    Nov 12 12:21:42.823: INFO: Deleting pod "simpletest.rc-lfpks" in namespace "gc-9089"
    Nov 12 12:21:42.840: INFO: Deleting pod "simpletest.rc-lnwq9" in namespace "gc-9089"
    Nov 12 12:21:42.862: INFO: Deleting pod "simpletest.rc-lpk7b" in namespace "gc-9089"
    Nov 12 12:21:42.880: INFO: Deleting pod "simpletest.rc-lqwbp" in namespace "gc-9089"
    Nov 12 12:21:42.909: INFO: Deleting pod "simpletest.rc-lrkfs" in namespace "gc-9089"
    Nov 12 12:21:42.923: INFO: Deleting pod "simpletest.rc-m4gtr" in namespace "gc-9089"
    Nov 12 12:21:42.937: INFO: Deleting pod "simpletest.rc-mmmhb" in namespace "gc-9089"
    Nov 12 12:21:42.953: INFO: Deleting pod "simpletest.rc-mqz5n" in namespace "gc-9089"
    Nov 12 12:21:42.968: INFO: Deleting pod "simpletest.rc-n4c5l" in namespace "gc-9089"
    Nov 12 12:21:42.985: INFO: Deleting pod "simpletest.rc-n5wcw" in namespace "gc-9089"
    Nov 12 12:21:43.002: INFO: Deleting pod "simpletest.rc-ndtvg" in namespace "gc-9089"
    Nov 12 12:21:43.021: INFO: Deleting pod "simpletest.rc-ng78j" in namespace "gc-9089"
    Nov 12 12:21:43.039: INFO: Deleting pod "simpletest.rc-nlbf5" in namespace "gc-9089"
    Nov 12 12:21:43.061: INFO: Deleting pod "simpletest.rc-nn6b8" in namespace "gc-9089"
    Nov 12 12:21:43.075: INFO: Deleting pod "simpletest.rc-nr8kf" in namespace "gc-9089"
    Nov 12 12:21:43.090: INFO: Deleting pod "simpletest.rc-ns84x" in namespace "gc-9089"
    Nov 12 12:21:43.111: INFO: Deleting pod "simpletest.rc-nwh2v" in namespace "gc-9089"
    Nov 12 12:21:43.132: INFO: Deleting pod "simpletest.rc-nzm8v" in namespace "gc-9089"
    Nov 12 12:21:43.148: INFO: Deleting pod "simpletest.rc-p6b48" in namespace "gc-9089"
    Nov 12 12:21:43.163: INFO: Deleting pod "simpletest.rc-pjwpm" in namespace "gc-9089"
    Nov 12 12:21:43.177: INFO: Deleting pod "simpletest.rc-pr55h" in namespace "gc-9089"
    Nov 12 12:21:43.191: INFO: Deleting pod "simpletest.rc-q2fg8" in namespace "gc-9089"
    Nov 12 12:21:43.206: INFO: Deleting pod "simpletest.rc-q427c" in namespace "gc-9089"
    Nov 12 12:21:43.222: INFO: Deleting pod "simpletest.rc-q6csx" in namespace "gc-9089"
    Nov 12 12:21:43.241: INFO: Deleting pod "simpletest.rc-qfg2r" in namespace "gc-9089"
    Nov 12 12:21:43.257: INFO: Deleting pod "simpletest.rc-qj62b" in namespace "gc-9089"
    Nov 12 12:21:43.274: INFO: Deleting pod "simpletest.rc-qpmnv" in namespace "gc-9089"
    Nov 12 12:21:43.288: INFO: Deleting pod "simpletest.rc-r8cc6" in namespace "gc-9089"
    Nov 12 12:21:43.302: INFO: Deleting pod "simpletest.rc-rtvnz" in namespace "gc-9089"
    Nov 12 12:21:43.318: INFO: Deleting pod "simpletest.rc-s88mh" in namespace "gc-9089"
    Nov 12 12:21:43.333: INFO: Deleting pod "simpletest.rc-s8phv" in namespace "gc-9089"
    Nov 12 12:21:43.347: INFO: Deleting pod "simpletest.rc-sqgz5" in namespace "gc-9089"
    Nov 12 12:21:43.360: INFO: Deleting pod "simpletest.rc-sqxwf" in namespace "gc-9089"
    Nov 12 12:21:43.375: INFO: Deleting pod "simpletest.rc-t4tbz" in namespace "gc-9089"
    Nov 12 12:21:43.390: INFO: Deleting pod "simpletest.rc-ttvc7" in namespace "gc-9089"
    Nov 12 12:21:43.406: INFO: Deleting pod "simpletest.rc-v2h8x" in namespace "gc-9089"
    Nov 12 12:21:43.457: INFO: Deleting pod "simpletest.rc-vcfgt" in namespace "gc-9089"
    Nov 12 12:21:43.511: INFO: Deleting pod "simpletest.rc-vwpfq" in namespace "gc-9089"
    Nov 12 12:21:43.558: INFO: Deleting pod "simpletest.rc-w77sv" in namespace "gc-9089"
    Nov 12 12:21:43.608: INFO: Deleting pod "simpletest.rc-wgh6h" in namespace "gc-9089"
    Nov 12 12:21:43.661: INFO: Deleting pod "simpletest.rc-wnhcg" in namespace "gc-9089"
    Nov 12 12:21:43.707: INFO: Deleting pod "simpletest.rc-wnjrs" in namespace "gc-9089"
    Nov 12 12:21:43.757: INFO: Deleting pod "simpletest.rc-wt894" in namespace "gc-9089"
    Nov 12 12:21:43.810: INFO: Deleting pod "simpletest.rc-wtc2w" in namespace "gc-9089"
    Nov 12 12:21:43.857: INFO: Deleting pod "simpletest.rc-x69zd" in namespace "gc-9089"
    Nov 12 12:21:43.906: INFO: Deleting pod "simpletest.rc-x7kth" in namespace "gc-9089"
    Nov 12 12:21:43.958: INFO: Deleting pod "simpletest.rc-xbmn6" in namespace "gc-9089"
    Nov 12 12:21:44.006: INFO: Deleting pod "simpletest.rc-xxqrd" in namespace "gc-9089"
    Nov 12 12:21:44.063: INFO: Deleting pod "simpletest.rc-zcmkl" in namespace "gc-9089"
    Nov 12 12:21:44.115: INFO: Deleting pod "simpletest.rc-zdfcg" in namespace "gc-9089"
    Nov 12 12:21:44.158: INFO: Deleting pod "simpletest.rc-zj992" in namespace "gc-9089"
    Nov 12 12:21:44.210: INFO: Deleting pod "simpletest.rc-znfrj" in namespace "gc-9089"
    Nov 12 12:21:44.262: INFO: Deleting pod "simpletest.rc-znxht" in namespace "gc-9089"
    Nov 12 12:21:44.311: INFO: Deleting pod "simpletest.rc-zttb7" in namespace "gc-9089"
    Nov 12 12:21:44.363: INFO: Deleting pod "simpletest.rc-zxsj8" in namespace "gc-9089"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 12:21:44.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-9089" for this suite. 11/12/22 12:21:44.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:21:44.504
Nov 12 12:21:44.504: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:21:44.505
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:21:44.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:21:44.533
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 12:21:44.536
Nov 12 12:21:44.551: INFO: Waiting up to 5m0s for pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec" in namespace "emptydir-7791" to be "Succeeded or Failed"
Nov 12 12:21:44.557: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195384ms
Nov 12 12:21:46.564: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013265768s
Nov 12 12:21:48.564: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013311085s
Nov 12 12:21:50.563: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012475946s
Nov 12 12:21:52.562: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011513442s
Nov 12 12:21:54.562: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011038708s
Nov 12 12:21:56.561: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010506759s
Nov 12 12:21:58.567: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.016064577s
STEP: Saw pod success 11/12/22 12:21:58.567
Nov 12 12:21:58.567: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec" satisfied condition "Succeeded or Failed"
Nov 12 12:21:58.574: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-56bda55b-493d-41ae-96d5-f36920ed5eec container test-container: <nil>
STEP: delete the pod 11/12/22 12:21:58.584
Nov 12 12:21:58.602: INFO: Waiting for pod pod-56bda55b-493d-41ae-96d5-f36920ed5eec to disappear
Nov 12 12:21:58.612: INFO: Pod pod-56bda55b-493d-41ae-96d5-f36920ed5eec no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:21:58.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7791" for this suite. 11/12/22 12:21:58.625
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":94,"skipped":1950,"failed":0}
------------------------------
• [SLOW TEST] [14.135 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:21:44.504
    Nov 12 12:21:44.504: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:21:44.505
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:21:44.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:21:44.533
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 12:21:44.536
    Nov 12 12:21:44.551: INFO: Waiting up to 5m0s for pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec" in namespace "emptydir-7791" to be "Succeeded or Failed"
    Nov 12 12:21:44.557: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195384ms
    Nov 12 12:21:46.564: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013265768s
    Nov 12 12:21:48.564: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013311085s
    Nov 12 12:21:50.563: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012475946s
    Nov 12 12:21:52.562: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011513442s
    Nov 12 12:21:54.562: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011038708s
    Nov 12 12:21:56.561: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010506759s
    Nov 12 12:21:58.567: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.016064577s
    STEP: Saw pod success 11/12/22 12:21:58.567
    Nov 12 12:21:58.567: INFO: Pod "pod-56bda55b-493d-41ae-96d5-f36920ed5eec" satisfied condition "Succeeded or Failed"
    Nov 12 12:21:58.574: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-56bda55b-493d-41ae-96d5-f36920ed5eec container test-container: <nil>
    STEP: delete the pod 11/12/22 12:21:58.584
    Nov 12 12:21:58.602: INFO: Waiting for pod pod-56bda55b-493d-41ae-96d5-f36920ed5eec to disappear
    Nov 12 12:21:58.612: INFO: Pod pod-56bda55b-493d-41ae-96d5-f36920ed5eec no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:21:58.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7791" for this suite. 11/12/22 12:21:58.625
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:21:58.647
Nov 12 12:21:58.659: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:21:58.66
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:21:58.691
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:21:58.696
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:21:58.727
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:21:59.304
STEP: Deploying the webhook pod 11/12/22 12:21:59.316
STEP: Wait for the deployment to be ready 11/12/22 12:21:59.334
Nov 12 12:21:59.352: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:22:01.368
STEP: Verifying the service has paired with the endpoint 11/12/22 12:22:01.403
Nov 12 12:22:02.404: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Nov 12 12:22:02.410: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6325-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 12:22:02.929
STEP: Creating a custom resource while v1 is storage version 11/12/22 12:22:02.949
STEP: Patching Custom Resource Definition to set v2 as storage 11/12/22 12:22:05.022
STEP: Patching the custom resource while v2 is storage version 11/12/22 12:22:05.053
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:22:05.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1336" for this suite. 11/12/22 12:22:05.671
STEP: Destroying namespace "webhook-1336-markers" for this suite. 11/12/22 12:22:05.681
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":95,"skipped":2001,"failed":0}
------------------------------
• [SLOW TEST] [7.143 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:21:58.647
    Nov 12 12:21:58.659: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:21:58.66
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:21:58.691
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:21:58.696
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:21:58.727
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:21:59.304
    STEP: Deploying the webhook pod 11/12/22 12:21:59.316
    STEP: Wait for the deployment to be ready 11/12/22 12:21:59.334
    Nov 12 12:21:59.352: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:22:01.368
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:22:01.403
    Nov 12 12:22:02.404: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Nov 12 12:22:02.410: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6325-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 12:22:02.929
    STEP: Creating a custom resource while v1 is storage version 11/12/22 12:22:02.949
    STEP: Patching Custom Resource Definition to set v2 as storage 11/12/22 12:22:05.022
    STEP: Patching the custom resource while v2 is storage version 11/12/22 12:22:05.053
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:22:05.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1336" for this suite. 11/12/22 12:22:05.671
    STEP: Destroying namespace "webhook-1336-markers" for this suite. 11/12/22 12:22:05.681
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:05.793
Nov 12 12:22:05.793: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:22:05.795
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:05.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:05.841
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 12:22:05.845
Nov 12 12:22:05.858: INFO: Waiting up to 5m0s for pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb" in namespace "emptydir-3789" to be "Succeeded or Failed"
Nov 12 12:22:05.869: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.313712ms
Nov 12 12:22:07.875: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016940307s
Nov 12 12:22:09.875: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016597237s
STEP: Saw pod success 11/12/22 12:22:09.875
Nov 12 12:22:09.875: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb" satisfied condition "Succeeded or Failed"
Nov 12 12:22:09.883: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb container test-container: <nil>
STEP: delete the pod 11/12/22 12:22:09.891
Nov 12 12:22:09.908: INFO: Waiting for pod pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb to disappear
Nov 12 12:22:09.912: INFO: Pod pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:22:09.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3789" for this suite. 11/12/22 12:22:09.917
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":96,"skipped":2013,"failed":0}
------------------------------
• [4.132 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:05.793
    Nov 12 12:22:05.793: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:22:05.795
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:05.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:05.841
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/12/22 12:22:05.845
    Nov 12 12:22:05.858: INFO: Waiting up to 5m0s for pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb" in namespace "emptydir-3789" to be "Succeeded or Failed"
    Nov 12 12:22:05.869: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.313712ms
    Nov 12 12:22:07.875: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016940307s
    Nov 12 12:22:09.875: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016597237s
    STEP: Saw pod success 11/12/22 12:22:09.875
    Nov 12 12:22:09.875: INFO: Pod "pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb" satisfied condition "Succeeded or Failed"
    Nov 12 12:22:09.883: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb container test-container: <nil>
    STEP: delete the pod 11/12/22 12:22:09.891
    Nov 12 12:22:09.908: INFO: Waiting for pod pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb to disappear
    Nov 12 12:22:09.912: INFO: Pod pod-8abd50c1-9fbc-43dd-9f0c-2aa3c44e36bb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:22:09.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3789" for this suite. 11/12/22 12:22:09.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:09.928
Nov 12 12:22:09.928: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 12:22:09.929
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:09.958
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:09.961
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 11/12/22 12:22:09.964
Nov 12 12:22:09.976: INFO: Waiting up to 5m0s for pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9" in namespace "downward-api-2287" to be "running and ready"
Nov 12 12:22:09.985: INFO: Pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.985004ms
Nov 12 12:22:09.985: INFO: The phase of Pod annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:22:11.990: INFO: Pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013850084s
Nov 12 12:22:11.990: INFO: The phase of Pod annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9 is Running (Ready = true)
Nov 12 12:22:11.990: INFO: Pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9" satisfied condition "running and ready"
Nov 12 12:22:12.525: INFO: Successfully updated pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 12:22:16.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2287" for this suite. 11/12/22 12:22:16.579
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":97,"skipped":2035,"failed":0}
------------------------------
• [SLOW TEST] [6.661 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:09.928
    Nov 12 12:22:09.928: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 12:22:09.929
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:09.958
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:09.961
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 11/12/22 12:22:09.964
    Nov 12 12:22:09.976: INFO: Waiting up to 5m0s for pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9" in namespace "downward-api-2287" to be "running and ready"
    Nov 12 12:22:09.985: INFO: Pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.985004ms
    Nov 12 12:22:09.985: INFO: The phase of Pod annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:22:11.990: INFO: Pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013850084s
    Nov 12 12:22:11.990: INFO: The phase of Pod annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9 is Running (Ready = true)
    Nov 12 12:22:11.990: INFO: Pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9" satisfied condition "running and ready"
    Nov 12 12:22:12.525: INFO: Successfully updated pod "annotationupdate2ec33779-a6ad-487a-83be-16384c4c6cd9"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 12:22:16.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2287" for this suite. 11/12/22 12:22:16.579
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:16.59
Nov 12 12:22:16.590: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 12:22:16.591
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:16.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:16.613
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 11/12/22 12:22:16.615
STEP: Ensuring ResourceQuota status is calculated 11/12/22 12:22:16.623
STEP: Creating a ResourceQuota with not best effort scope 11/12/22 12:22:18.628
STEP: Ensuring ResourceQuota status is calculated 11/12/22 12:22:18.635
STEP: Creating a best-effort pod 11/12/22 12:22:20.64
STEP: Ensuring resource quota with best effort scope captures the pod usage 11/12/22 12:22:20.661
STEP: Ensuring resource quota with not best effort ignored the pod usage 11/12/22 12:22:22.667
STEP: Deleting the pod 11/12/22 12:22:24.677
STEP: Ensuring resource quota status released the pod usage 11/12/22 12:22:24.702
STEP: Creating a not best-effort pod 11/12/22 12:22:26.708
STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/12/22 12:22:26.724
STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/12/22 12:22:28.732
STEP: Deleting the pod 11/12/22 12:22:30.737
STEP: Ensuring resource quota status released the pod usage 11/12/22 12:22:30.753
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 12:22:32.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6328" for this suite. 11/12/22 12:22:32.764
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":98,"skipped":2045,"failed":0}
------------------------------
• [SLOW TEST] [16.183 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:16.59
    Nov 12 12:22:16.590: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 12:22:16.591
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:16.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:16.613
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 11/12/22 12:22:16.615
    STEP: Ensuring ResourceQuota status is calculated 11/12/22 12:22:16.623
    STEP: Creating a ResourceQuota with not best effort scope 11/12/22 12:22:18.628
    STEP: Ensuring ResourceQuota status is calculated 11/12/22 12:22:18.635
    STEP: Creating a best-effort pod 11/12/22 12:22:20.64
    STEP: Ensuring resource quota with best effort scope captures the pod usage 11/12/22 12:22:20.661
    STEP: Ensuring resource quota with not best effort ignored the pod usage 11/12/22 12:22:22.667
    STEP: Deleting the pod 11/12/22 12:22:24.677
    STEP: Ensuring resource quota status released the pod usage 11/12/22 12:22:24.702
    STEP: Creating a not best-effort pod 11/12/22 12:22:26.708
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/12/22 12:22:26.724
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/12/22 12:22:28.732
    STEP: Deleting the pod 11/12/22 12:22:30.737
    STEP: Ensuring resource quota status released the pod usage 11/12/22 12:22:30.753
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 12:22:32.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6328" for this suite. 11/12/22 12:22:32.764
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:32.778
Nov 12 12:22:32.778: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:22:32.781
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:32.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:32.809
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 12:22:36.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3470" for this suite. 11/12/22 12:22:36.846
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":99,"skipped":2099,"failed":0}
------------------------------
• [4.078 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:32.778
    Nov 12 12:22:32.778: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:22:32.781
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:32.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:32.809
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 12:22:36.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3470" for this suite. 11/12/22 12:22:36.846
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:36.858
Nov 12 12:22:36.858: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 12:22:36.859
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:36.886
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:36.898
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-7e309640-7119-42da-8628-d0d72c529392 11/12/22 12:22:36.911
STEP: Creating a pod to test consume secrets 11/12/22 12:22:36.923
Nov 12 12:22:36.939: INFO: Waiting up to 5m0s for pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede" in namespace "secrets-1646" to be "Succeeded or Failed"
Nov 12 12:22:36.951: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede": Phase="Pending", Reason="", readiness=false. Elapsed: 11.751535ms
Nov 12 12:22:38.957: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017448551s
Nov 12 12:22:40.957: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017943161s
STEP: Saw pod success 11/12/22 12:22:40.957
Nov 12 12:22:40.958: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede" satisfied condition "Succeeded or Failed"
Nov 12 12:22:40.963: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 12:22:40.972
Nov 12 12:22:40.990: INFO: Waiting for pod pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede to disappear
Nov 12 12:22:40.994: INFO: Pod pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 12:22:40.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1646" for this suite. 11/12/22 12:22:40.999
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":100,"skipped":2123,"failed":0}
------------------------------
• [4.150 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:36.858
    Nov 12 12:22:36.858: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 12:22:36.859
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:36.886
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:36.898
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-7e309640-7119-42da-8628-d0d72c529392 11/12/22 12:22:36.911
    STEP: Creating a pod to test consume secrets 11/12/22 12:22:36.923
    Nov 12 12:22:36.939: INFO: Waiting up to 5m0s for pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede" in namespace "secrets-1646" to be "Succeeded or Failed"
    Nov 12 12:22:36.951: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede": Phase="Pending", Reason="", readiness=false. Elapsed: 11.751535ms
    Nov 12 12:22:38.957: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017448551s
    Nov 12 12:22:40.957: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017943161s
    STEP: Saw pod success 11/12/22 12:22:40.957
    Nov 12 12:22:40.958: INFO: Pod "pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede" satisfied condition "Succeeded or Failed"
    Nov 12 12:22:40.963: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:22:40.972
    Nov 12 12:22:40.990: INFO: Waiting for pod pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede to disappear
    Nov 12 12:22:40.994: INFO: Pod pod-secrets-d8c2e745-6aa0-4acb-9e95-0b02bf4feede no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 12:22:40.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1646" for this suite. 11/12/22 12:22:40.999
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:41.01
Nov 12 12:22:41.010: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:22:41.011
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:41.029
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:41.032
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 11/12/22 12:22:41.034
Nov 12 12:22:41.059: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3" in namespace "projected-8130" to be "Succeeded or Failed"
Nov 12 12:22:41.068: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.896873ms
Nov 12 12:22:43.074: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014756673s
Nov 12 12:22:45.074: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01440204s
STEP: Saw pod success 11/12/22 12:22:45.074
Nov 12 12:22:45.074: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3" satisfied condition "Succeeded or Failed"
Nov 12 12:22:45.079: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3 container client-container: <nil>
STEP: delete the pod 11/12/22 12:22:45.09
Nov 12 12:22:45.108: INFO: Waiting for pod downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3 to disappear
Nov 12 12:22:45.113: INFO: Pod downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 12:22:45.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8130" for this suite. 11/12/22 12:22:45.119
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":101,"skipped":2136,"failed":0}
------------------------------
• [4.123 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:41.01
    Nov 12 12:22:41.010: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:22:41.011
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:41.029
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:41.032
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 11/12/22 12:22:41.034
    Nov 12 12:22:41.059: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3" in namespace "projected-8130" to be "Succeeded or Failed"
    Nov 12 12:22:41.068: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.896873ms
    Nov 12 12:22:43.074: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014756673s
    Nov 12 12:22:45.074: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01440204s
    STEP: Saw pod success 11/12/22 12:22:45.074
    Nov 12 12:22:45.074: INFO: Pod "downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3" satisfied condition "Succeeded or Failed"
    Nov 12 12:22:45.079: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3 container client-container: <nil>
    STEP: delete the pod 11/12/22 12:22:45.09
    Nov 12 12:22:45.108: INFO: Waiting for pod downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3 to disappear
    Nov 12 12:22:45.113: INFO: Pod downwardapi-volume-9c4eec24-c963-4fb8-8de0-d461d10b4de3 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 12:22:45.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8130" for this suite. 11/12/22 12:22:45.119
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:45.135
Nov 12 12:22:45.135: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:22:45.136
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:45.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:45.165
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 11/12/22 12:22:45.168
Nov 12 12:22:45.168: INFO: namespace kubectl-2930
Nov 12 12:22:45.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 create -f -'
Nov 12 12:22:46.249: INFO: stderr: ""
Nov 12 12:22:46.249: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/12/22 12:22:46.249
Nov 12 12:22:47.255: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 12:22:47.255: INFO: Found 0 / 1
Nov 12 12:22:48.255: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 12:22:48.255: INFO: Found 1 / 1
Nov 12 12:22:48.255: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 12 12:22:48.259: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 12:22:48.259: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 12 12:22:48.259: INFO: wait on agnhost-primary startup in kubectl-2930 
Nov 12 12:22:48.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 logs agnhost-primary-zjnpp agnhost-primary'
Nov 12 12:22:48.354: INFO: stderr: ""
Nov 12 12:22:48.354: INFO: stdout: "Paused\n"
STEP: exposing RC 11/12/22 12:22:48.354
Nov 12 12:22:48.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Nov 12 12:22:48.436: INFO: stderr: ""
Nov 12 12:22:48.436: INFO: stdout: "service/rm2 exposed\n"
Nov 12 12:22:48.453: INFO: Service rm2 in namespace kubectl-2930 found.
STEP: exposing service 11/12/22 12:22:50.462
Nov 12 12:22:50.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Nov 12 12:22:50.565: INFO: stderr: ""
Nov 12 12:22:50.565: INFO: stdout: "service/rm3 exposed\n"
Nov 12 12:22:50.573: INFO: Service rm3 in namespace kubectl-2930 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:22:52.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2930" for this suite. 11/12/22 12:22:52.594
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":102,"skipped":2143,"failed":0}
------------------------------
• [SLOW TEST] [7.468 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:45.135
    Nov 12 12:22:45.135: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:22:45.136
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:45.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:45.165
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 11/12/22 12:22:45.168
    Nov 12 12:22:45.168: INFO: namespace kubectl-2930
    Nov 12 12:22:45.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 create -f -'
    Nov 12 12:22:46.249: INFO: stderr: ""
    Nov 12 12:22:46.249: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/12/22 12:22:46.249
    Nov 12 12:22:47.255: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 12:22:47.255: INFO: Found 0 / 1
    Nov 12 12:22:48.255: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 12:22:48.255: INFO: Found 1 / 1
    Nov 12 12:22:48.255: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 12 12:22:48.259: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 12:22:48.259: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 12 12:22:48.259: INFO: wait on agnhost-primary startup in kubectl-2930 
    Nov 12 12:22:48.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 logs agnhost-primary-zjnpp agnhost-primary'
    Nov 12 12:22:48.354: INFO: stderr: ""
    Nov 12 12:22:48.354: INFO: stdout: "Paused\n"
    STEP: exposing RC 11/12/22 12:22:48.354
    Nov 12 12:22:48.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Nov 12 12:22:48.436: INFO: stderr: ""
    Nov 12 12:22:48.436: INFO: stdout: "service/rm2 exposed\n"
    Nov 12 12:22:48.453: INFO: Service rm2 in namespace kubectl-2930 found.
    STEP: exposing service 11/12/22 12:22:50.462
    Nov 12 12:22:50.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2930 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Nov 12 12:22:50.565: INFO: stderr: ""
    Nov 12 12:22:50.565: INFO: stdout: "service/rm3 exposed\n"
    Nov 12 12:22:50.573: INFO: Service rm3 in namespace kubectl-2930 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:22:52.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2930" for this suite. 11/12/22 12:22:52.594
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:22:52.604
Nov 12 12:22:52.604: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename daemonsets 11/12/22 12:22:52.605
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:52.632
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:52.641
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Nov 12 12:22:52.688: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 11/12/22 12:22:52.696
Nov 12 12:22:52.704: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:22:52.704: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 11/12/22 12:22:52.704
Nov 12 12:22:52.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:22:52.741: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:22:53.747: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:22:53.747: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:22:54.746: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 12 12:22:54.746: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 11/12/22 12:22:54.751
Nov 12 12:22:54.779: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 12 12:22:54.779: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Nov 12 12:22:55.786: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:22:55.786: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/12/22 12:22:55.786
Nov 12 12:22:55.807: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:22:55.807: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:22:56.812: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:22:56.812: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:22:57.814: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:22:57.815: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:22:58.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 12 12:22:58.813: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:22:58.823
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3854, will wait for the garbage collector to delete the pods 11/12/22 12:22:58.823
Nov 12 12:22:58.893: INFO: Deleting DaemonSet.extensions daemon-set took: 11.867687ms
Nov 12 12:22:58.994: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.708072ms
Nov 12 12:23:00.999: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:23:01.000: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 12 12:23:01.003: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14562"},"items":null}

Nov 12 12:23:01.008: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14562"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:23:01.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3854" for this suite. 11/12/22 12:23:01.052
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":103,"skipped":2160,"failed":0}
------------------------------
• [SLOW TEST] [8.461 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:22:52.604
    Nov 12 12:22:52.604: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename daemonsets 11/12/22 12:22:52.605
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:22:52.632
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:22:52.641
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Nov 12 12:22:52.688: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 11/12/22 12:22:52.696
    Nov 12 12:22:52.704: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:22:52.704: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 11/12/22 12:22:52.704
    Nov 12 12:22:52.741: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:22:52.741: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:22:53.747: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:22:53.747: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:22:54.746: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 12 12:22:54.746: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 11/12/22 12:22:54.751
    Nov 12 12:22:54.779: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 12 12:22:54.779: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Nov 12 12:22:55.786: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:22:55.786: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/12/22 12:22:55.786
    Nov 12 12:22:55.807: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:22:55.807: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:22:56.812: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:22:56.812: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:22:57.814: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:22:57.815: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:22:58.813: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 12 12:22:58.813: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:22:58.823
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3854, will wait for the garbage collector to delete the pods 11/12/22 12:22:58.823
    Nov 12 12:22:58.893: INFO: Deleting DaemonSet.extensions daemon-set took: 11.867687ms
    Nov 12 12:22:58.994: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.708072ms
    Nov 12 12:23:00.999: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:23:01.000: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 12 12:23:01.003: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"14562"},"items":null}

    Nov 12 12:23:01.008: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"14562"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:23:01.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3854" for this suite. 11/12/22 12:23:01.052
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:01.066
Nov 12 12:23:01.066: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename gc 11/12/22 12:23:01.067
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:01.101
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:01.105
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 11/12/22 12:23:01.116
STEP: Wait for the Deployment to create new ReplicaSet 11/12/22 12:23:01.127
STEP: delete the deployment 11/12/22 12:23:01.259
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/12/22 12:23:01.268
STEP: Gathering metrics 11/12/22 12:23:01.814
W1112 12:23:01.819971      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 12:23:01.820: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 12:23:01.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5236" for this suite. 11/12/22 12:23:01.825
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":104,"skipped":2160,"failed":0}
------------------------------
• [0.776 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:01.066
    Nov 12 12:23:01.066: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename gc 11/12/22 12:23:01.067
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:01.101
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:01.105
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 11/12/22 12:23:01.116
    STEP: Wait for the Deployment to create new ReplicaSet 11/12/22 12:23:01.127
    STEP: delete the deployment 11/12/22 12:23:01.259
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/12/22 12:23:01.268
    STEP: Gathering metrics 11/12/22 12:23:01.814
    W1112 12:23:01.819971      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 12:23:01.820: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 12:23:01.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5236" for this suite. 11/12/22 12:23:01.825
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:01.842
Nov 12 12:23:01.842: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename security-context 11/12/22 12:23:01.843
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:01.873
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:01.879
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/12/22 12:23:01.887
Nov 12 12:23:01.909: INFO: Waiting up to 5m0s for pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970" in namespace "security-context-3550" to be "Succeeded or Failed"
Nov 12 12:23:01.915: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970": Phase="Pending", Reason="", readiness=false. Elapsed: 6.437768ms
Nov 12 12:23:03.921: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012592374s
Nov 12 12:23:05.922: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013071843s
STEP: Saw pod success 11/12/22 12:23:05.922
Nov 12 12:23:05.922: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970" satisfied condition "Succeeded or Failed"
Nov 12 12:23:05.926: INFO: Trying to get logs from node ip-172-31-14-110 pod security-context-78dad16a-7709-4f77-a593-3254ce8d9970 container test-container: <nil>
STEP: delete the pod 11/12/22 12:23:05.936
Nov 12 12:23:05.960: INFO: Waiting for pod security-context-78dad16a-7709-4f77-a593-3254ce8d9970 to disappear
Nov 12 12:23:05.964: INFO: Pod security-context-78dad16a-7709-4f77-a593-3254ce8d9970 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 12:23:05.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-3550" for this suite. 11/12/22 12:23:05.971
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":105,"skipped":2162,"failed":0}
------------------------------
• [4.149 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:01.842
    Nov 12 12:23:01.842: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename security-context 11/12/22 12:23:01.843
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:01.873
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:01.879
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/12/22 12:23:01.887
    Nov 12 12:23:01.909: INFO: Waiting up to 5m0s for pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970" in namespace "security-context-3550" to be "Succeeded or Failed"
    Nov 12 12:23:01.915: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970": Phase="Pending", Reason="", readiness=false. Elapsed: 6.437768ms
    Nov 12 12:23:03.921: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012592374s
    Nov 12 12:23:05.922: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013071843s
    STEP: Saw pod success 11/12/22 12:23:05.922
    Nov 12 12:23:05.922: INFO: Pod "security-context-78dad16a-7709-4f77-a593-3254ce8d9970" satisfied condition "Succeeded or Failed"
    Nov 12 12:23:05.926: INFO: Trying to get logs from node ip-172-31-14-110 pod security-context-78dad16a-7709-4f77-a593-3254ce8d9970 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:23:05.936
    Nov 12 12:23:05.960: INFO: Waiting for pod security-context-78dad16a-7709-4f77-a593-3254ce8d9970 to disappear
    Nov 12 12:23:05.964: INFO: Pod security-context-78dad16a-7709-4f77-a593-3254ce8d9970 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 12:23:05.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-3550" for this suite. 11/12/22 12:23:05.971
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:05.992
Nov 12 12:23:05.992: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename init-container 11/12/22 12:23:05.993
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:06.011
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:06.027
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 11/12/22 12:23:06.032
Nov 12 12:23:06.032: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 12:23:11.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5517" for this suite. 11/12/22 12:23:11.457
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":106,"skipped":2163,"failed":0}
------------------------------
• [SLOW TEST] [5.475 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:05.992
    Nov 12 12:23:05.992: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename init-container 11/12/22 12:23:05.993
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:06.011
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:06.027
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 11/12/22 12:23:06.032
    Nov 12 12:23:06.032: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 12:23:11.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-5517" for this suite. 11/12/22 12:23:11.457
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:11.469
Nov 12 12:23:11.469: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 12:23:11.476
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:11.496
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:11.499
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 11/12/22 12:23:11.502
Nov 12 12:23:11.514: INFO: Waiting up to 5m0s for pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58" in namespace "downward-api-8893" to be "Succeeded or Failed"
Nov 12 12:23:11.525: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58": Phase="Pending", Reason="", readiness=false. Elapsed: 10.270325ms
Nov 12 12:23:13.530: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015869142s
Nov 12 12:23:15.530: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01556408s
STEP: Saw pod success 11/12/22 12:23:15.53
Nov 12 12:23:15.530: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58" satisfied condition "Succeeded or Failed"
Nov 12 12:23:15.540: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58 container dapi-container: <nil>
STEP: delete the pod 11/12/22 12:23:15.548
Nov 12 12:23:15.566: INFO: Waiting for pod downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58 to disappear
Nov 12 12:23:15.570: INFO: Pod downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 12 12:23:15.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8893" for this suite. 11/12/22 12:23:15.575
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":107,"skipped":2184,"failed":0}
------------------------------
• [4.117 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:11.469
    Nov 12 12:23:11.469: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 12:23:11.476
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:11.496
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:11.499
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 11/12/22 12:23:11.502
    Nov 12 12:23:11.514: INFO: Waiting up to 5m0s for pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58" in namespace "downward-api-8893" to be "Succeeded or Failed"
    Nov 12 12:23:11.525: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58": Phase="Pending", Reason="", readiness=false. Elapsed: 10.270325ms
    Nov 12 12:23:13.530: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015869142s
    Nov 12 12:23:15.530: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01556408s
    STEP: Saw pod success 11/12/22 12:23:15.53
    Nov 12 12:23:15.530: INFO: Pod "downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58" satisfied condition "Succeeded or Failed"
    Nov 12 12:23:15.540: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 12:23:15.548
    Nov 12 12:23:15.566: INFO: Waiting for pod downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58 to disappear
    Nov 12 12:23:15.570: INFO: Pod downward-api-e89403a5-637b-4adf-91a0-89685d4c5f58 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 12 12:23:15.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8893" for this suite. 11/12/22 12:23:15.575
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:15.587
Nov 12 12:23:15.587: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename subpath 11/12/22 12:23:15.59
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:15.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:15.643
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 12:23:15.651
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-9z2z 11/12/22 12:23:15.677
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:23:15.677
Nov 12 12:23:15.689: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-9z2z" in namespace "subpath-8820" to be "Succeeded or Failed"
Nov 12 12:23:15.696: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.947979ms
Nov 12 12:23:17.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 2.013355411s
Nov 12 12:23:19.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 4.013830615s
Nov 12 12:23:21.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 6.013835402s
Nov 12 12:23:23.704: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 8.014475167s
Nov 12 12:23:25.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 10.01275467s
Nov 12 12:23:27.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 12.012484935s
Nov 12 12:23:29.704: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 14.014841684s
Nov 12 12:23:31.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 16.012032222s
Nov 12 12:23:33.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 18.012288562s
Nov 12 12:23:35.701: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 20.011916079s
Nov 12 12:23:37.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=false. Elapsed: 22.013569872s
Nov 12 12:23:39.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013333249s
STEP: Saw pod success 11/12/22 12:23:39.703
Nov 12 12:23:39.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z" satisfied condition "Succeeded or Failed"
Nov 12 12:23:39.708: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-downwardapi-9z2z container test-container-subpath-downwardapi-9z2z: <nil>
STEP: delete the pod 11/12/22 12:23:39.716
Nov 12 12:23:39.731: INFO: Waiting for pod pod-subpath-test-downwardapi-9z2z to disappear
Nov 12 12:23:39.739: INFO: Pod pod-subpath-test-downwardapi-9z2z no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-9z2z 11/12/22 12:23:39.739
Nov 12 12:23:39.740: INFO: Deleting pod "pod-subpath-test-downwardapi-9z2z" in namespace "subpath-8820"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 12:23:39.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8820" for this suite. 11/12/22 12:23:39.749
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":108,"skipped":2185,"failed":0}
------------------------------
• [SLOW TEST] [24.172 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:15.587
    Nov 12 12:23:15.587: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename subpath 11/12/22 12:23:15.59
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:15.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:15.643
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 12:23:15.651
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-9z2z 11/12/22 12:23:15.677
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:23:15.677
    Nov 12 12:23:15.689: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-9z2z" in namespace "subpath-8820" to be "Succeeded or Failed"
    Nov 12 12:23:15.696: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.947979ms
    Nov 12 12:23:17.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 2.013355411s
    Nov 12 12:23:19.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 4.013830615s
    Nov 12 12:23:21.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 6.013835402s
    Nov 12 12:23:23.704: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 8.014475167s
    Nov 12 12:23:25.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 10.01275467s
    Nov 12 12:23:27.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 12.012484935s
    Nov 12 12:23:29.704: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 14.014841684s
    Nov 12 12:23:31.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 16.012032222s
    Nov 12 12:23:33.702: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 18.012288562s
    Nov 12 12:23:35.701: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=true. Elapsed: 20.011916079s
    Nov 12 12:23:37.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Running", Reason="", readiness=false. Elapsed: 22.013569872s
    Nov 12 12:23:39.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013333249s
    STEP: Saw pod success 11/12/22 12:23:39.703
    Nov 12 12:23:39.703: INFO: Pod "pod-subpath-test-downwardapi-9z2z" satisfied condition "Succeeded or Failed"
    Nov 12 12:23:39.708: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-downwardapi-9z2z container test-container-subpath-downwardapi-9z2z: <nil>
    STEP: delete the pod 11/12/22 12:23:39.716
    Nov 12 12:23:39.731: INFO: Waiting for pod pod-subpath-test-downwardapi-9z2z to disappear
    Nov 12 12:23:39.739: INFO: Pod pod-subpath-test-downwardapi-9z2z no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-9z2z 11/12/22 12:23:39.739
    Nov 12 12:23:39.740: INFO: Deleting pod "pod-subpath-test-downwardapi-9z2z" in namespace "subpath-8820"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 12:23:39.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-8820" for this suite. 11/12/22 12:23:39.749
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:39.76
Nov 12 12:23:39.760: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename disruption 11/12/22 12:23:39.761
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:39.794
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:39.797
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 11/12/22 12:23:39.802
STEP: Waiting for the pdb to be processed 11/12/22 12:23:39.81
STEP: updating the pdb 11/12/22 12:23:39.816
STEP: Waiting for the pdb to be processed 11/12/22 12:23:39.829
STEP: patching the pdb 11/12/22 12:23:39.834
STEP: Waiting for the pdb to be processed 11/12/22 12:23:39.859
STEP: Waiting for the pdb to be deleted 11/12/22 12:23:39.876
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 12:23:39.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-248" for this suite. 11/12/22 12:23:39.887
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":109,"skipped":2188,"failed":0}
------------------------------
• [0.135 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:39.76
    Nov 12 12:23:39.760: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename disruption 11/12/22 12:23:39.761
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:39.794
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:39.797
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 11/12/22 12:23:39.802
    STEP: Waiting for the pdb to be processed 11/12/22 12:23:39.81
    STEP: updating the pdb 11/12/22 12:23:39.816
    STEP: Waiting for the pdb to be processed 11/12/22 12:23:39.829
    STEP: patching the pdb 11/12/22 12:23:39.834
    STEP: Waiting for the pdb to be processed 11/12/22 12:23:39.859
    STEP: Waiting for the pdb to be deleted 11/12/22 12:23:39.876
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 12:23:39.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-248" for this suite. 11/12/22 12:23:39.887
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:39.896
Nov 12 12:23:39.897: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename security-context 11/12/22 12:23:39.897
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:39.916
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:39.923
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/12/22 12:23:39.926
Nov 12 12:23:39.936: INFO: Waiting up to 5m0s for pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996" in namespace "security-context-4049" to be "Succeeded or Failed"
Nov 12 12:23:39.947: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996": Phase="Pending", Reason="", readiness=false. Elapsed: 10.998674ms
Nov 12 12:23:41.954: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017694638s
Nov 12 12:23:43.953: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017051585s
STEP: Saw pod success 11/12/22 12:23:43.953
Nov 12 12:23:43.953: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996" satisfied condition "Succeeded or Failed"
Nov 12 12:23:43.961: INFO: Trying to get logs from node ip-172-31-14-110 pod security-context-9863be28-a3c6-4ab1-a686-e8e691343996 container test-container: <nil>
STEP: delete the pod 11/12/22 12:23:43.97
Nov 12 12:23:43.985: INFO: Waiting for pod security-context-9863be28-a3c6-4ab1-a686-e8e691343996 to disappear
Nov 12 12:23:43.990: INFO: Pod security-context-9863be28-a3c6-4ab1-a686-e8e691343996 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 12:23:43.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4049" for this suite. 11/12/22 12:23:43.998
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":110,"skipped":2192,"failed":0}
------------------------------
• [4.112 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:39.896
    Nov 12 12:23:39.897: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename security-context 11/12/22 12:23:39.897
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:39.916
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:39.923
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/12/22 12:23:39.926
    Nov 12 12:23:39.936: INFO: Waiting up to 5m0s for pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996" in namespace "security-context-4049" to be "Succeeded or Failed"
    Nov 12 12:23:39.947: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996": Phase="Pending", Reason="", readiness=false. Elapsed: 10.998674ms
    Nov 12 12:23:41.954: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017694638s
    Nov 12 12:23:43.953: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017051585s
    STEP: Saw pod success 11/12/22 12:23:43.953
    Nov 12 12:23:43.953: INFO: Pod "security-context-9863be28-a3c6-4ab1-a686-e8e691343996" satisfied condition "Succeeded or Failed"
    Nov 12 12:23:43.961: INFO: Trying to get logs from node ip-172-31-14-110 pod security-context-9863be28-a3c6-4ab1-a686-e8e691343996 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:23:43.97
    Nov 12 12:23:43.985: INFO: Waiting for pod security-context-9863be28-a3c6-4ab1-a686-e8e691343996 to disappear
    Nov 12 12:23:43.990: INFO: Pod security-context-9863be28-a3c6-4ab1-a686-e8e691343996 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 12:23:43.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-4049" for this suite. 11/12/22 12:23:43.998
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:23:44.012
Nov 12 12:23:44.012: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename subpath 11/12/22 12:23:44.013
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:44.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:44.043
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 12:23:44.047
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-qjw6 11/12/22 12:23:44.061
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:23:44.061
Nov 12 12:23:44.074: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-qjw6" in namespace "subpath-6021" to be "Succeeded or Failed"
Nov 12 12:23:44.087: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.405359ms
Nov 12 12:23:46.092: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 2.017476033s
Nov 12 12:23:48.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 4.019258371s
Nov 12 12:23:50.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 6.019426133s
Nov 12 12:23:52.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 8.02028777s
Nov 12 12:23:54.095: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 10.020581517s
Nov 12 12:23:56.092: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 12.017765814s
Nov 12 12:23:58.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 14.019688645s
Nov 12 12:24:00.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 16.019018844s
Nov 12 12:24:02.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 18.019028043s
Nov 12 12:24:04.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 20.019917693s
Nov 12 12:24:06.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=false. Elapsed: 22.018666614s
Nov 12 12:24:08.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.018605925s
STEP: Saw pod success 11/12/22 12:24:08.093
Nov 12 12:24:08.093: INFO: Pod "pod-subpath-test-secret-qjw6" satisfied condition "Succeeded or Failed"
Nov 12 12:24:08.098: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-secret-qjw6 container test-container-subpath-secret-qjw6: <nil>
STEP: delete the pod 11/12/22 12:24:08.107
Nov 12 12:24:08.123: INFO: Waiting for pod pod-subpath-test-secret-qjw6 to disappear
Nov 12 12:24:08.127: INFO: Pod pod-subpath-test-secret-qjw6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-qjw6 11/12/22 12:24:08.127
Nov 12 12:24:08.127: INFO: Deleting pod "pod-subpath-test-secret-qjw6" in namespace "subpath-6021"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 12:24:08.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6021" for this suite. 11/12/22 12:24:08.137
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":111,"skipped":2201,"failed":0}
------------------------------
• [SLOW TEST] [24.133 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:23:44.012
    Nov 12 12:23:44.012: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename subpath 11/12/22 12:23:44.013
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:23:44.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:23:44.043
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 12:23:44.047
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-qjw6 11/12/22 12:23:44.061
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:23:44.061
    Nov 12 12:23:44.074: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-qjw6" in namespace "subpath-6021" to be "Succeeded or Failed"
    Nov 12 12:23:44.087: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.405359ms
    Nov 12 12:23:46.092: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 2.017476033s
    Nov 12 12:23:48.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 4.019258371s
    Nov 12 12:23:50.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 6.019426133s
    Nov 12 12:23:52.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 8.02028777s
    Nov 12 12:23:54.095: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 10.020581517s
    Nov 12 12:23:56.092: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 12.017765814s
    Nov 12 12:23:58.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 14.019688645s
    Nov 12 12:24:00.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 16.019018844s
    Nov 12 12:24:02.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 18.019028043s
    Nov 12 12:24:04.094: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=true. Elapsed: 20.019917693s
    Nov 12 12:24:06.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Running", Reason="", readiness=false. Elapsed: 22.018666614s
    Nov 12 12:24:08.093: INFO: Pod "pod-subpath-test-secret-qjw6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.018605925s
    STEP: Saw pod success 11/12/22 12:24:08.093
    Nov 12 12:24:08.093: INFO: Pod "pod-subpath-test-secret-qjw6" satisfied condition "Succeeded or Failed"
    Nov 12 12:24:08.098: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-secret-qjw6 container test-container-subpath-secret-qjw6: <nil>
    STEP: delete the pod 11/12/22 12:24:08.107
    Nov 12 12:24:08.123: INFO: Waiting for pod pod-subpath-test-secret-qjw6 to disappear
    Nov 12 12:24:08.127: INFO: Pod pod-subpath-test-secret-qjw6 no longer exists
    STEP: Deleting pod pod-subpath-test-secret-qjw6 11/12/22 12:24:08.127
    Nov 12 12:24:08.127: INFO: Deleting pod "pod-subpath-test-secret-qjw6" in namespace "subpath-6021"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 12:24:08.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6021" for this suite. 11/12/22 12:24:08.137
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:24:08.146
Nov 12 12:24:08.147: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename runtimeclass 11/12/22 12:24:08.149
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:08.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:08.185
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 11/12/22 12:24:08.188
STEP: getting /apis/node.k8s.io 11/12/22 12:24:08.19
STEP: getting /apis/node.k8s.io/v1 11/12/22 12:24:08.191
STEP: creating 11/12/22 12:24:08.193
STEP: watching 11/12/22 12:24:08.213
Nov 12 12:24:08.213: INFO: starting watch
STEP: getting 11/12/22 12:24:08.221
STEP: listing 11/12/22 12:24:08.233
STEP: patching 11/12/22 12:24:08.238
STEP: updating 11/12/22 12:24:08.247
Nov 12 12:24:08.253: INFO: waiting for watch events with expected annotations
STEP: deleting 11/12/22 12:24:08.253
STEP: deleting a collection 11/12/22 12:24:08.271
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 12:24:08.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4209" for this suite. 11/12/22 12:24:08.304
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":112,"skipped":2212,"failed":0}
------------------------------
• [0.166 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:24:08.146
    Nov 12 12:24:08.147: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 12:24:08.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:08.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:08.185
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 11/12/22 12:24:08.188
    STEP: getting /apis/node.k8s.io 11/12/22 12:24:08.19
    STEP: getting /apis/node.k8s.io/v1 11/12/22 12:24:08.191
    STEP: creating 11/12/22 12:24:08.193
    STEP: watching 11/12/22 12:24:08.213
    Nov 12 12:24:08.213: INFO: starting watch
    STEP: getting 11/12/22 12:24:08.221
    STEP: listing 11/12/22 12:24:08.233
    STEP: patching 11/12/22 12:24:08.238
    STEP: updating 11/12/22 12:24:08.247
    Nov 12 12:24:08.253: INFO: waiting for watch events with expected annotations
    STEP: deleting 11/12/22 12:24:08.253
    STEP: deleting a collection 11/12/22 12:24:08.271
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 12:24:08.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4209" for this suite. 11/12/22 12:24:08.304
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:24:08.316
Nov 12 12:24:08.316: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:24:08.319
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:08.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:08.344
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-4696 11/12/22 12:24:08.352
STEP: creating a selector 11/12/22 12:24:08.352
STEP: Creating the service pods in kubernetes 11/12/22 12:24:08.352
Nov 12 12:24:08.352: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 12 12:24:08.409: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4696" to be "running and ready"
Nov 12 12:24:08.414: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.432946ms
Nov 12 12:24:08.414: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:24:10.419: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.010365359s
Nov 12 12:24:10.419: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:12.422: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013468744s
Nov 12 12:24:12.422: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:14.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011230305s
Nov 12 12:24:14.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:16.421: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.012501362s
Nov 12 12:24:16.421: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:18.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.010719925s
Nov 12 12:24:18.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:20.424: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.015234892s
Nov 12 12:24:20.424: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:22.423: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.013637549s
Nov 12 12:24:22.423: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:24.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.011461125s
Nov 12 12:24:24.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:26.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.011315018s
Nov 12 12:24:26.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:28.422: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013086068s
Nov 12 12:24:28.422: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:24:30.419: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.010548252s
Nov 12 12:24:30.420: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 12 12:24:30.420: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 12 12:24:30.424: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4696" to be "running and ready"
Nov 12 12:24:30.429: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.698016ms
Nov 12 12:24:30.429: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 12 12:24:30.429: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 12 12:24:30.433: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4696" to be "running and ready"
Nov 12 12:24:30.437: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.982031ms
Nov 12 12:24:30.437: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 12 12:24:30.437: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/12/22 12:24:30.443
Nov 12 12:24:30.453: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4696" to be "running"
Nov 12 12:24:30.458: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.282353ms
Nov 12 12:24:32.464: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010168098s
Nov 12 12:24:32.464: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 12 12:24:32.468: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 12 12:24:32.468: INFO: Breadth first check of 192.168.249.4 on host 172.31.14.110...
Nov 12 12:24:32.472: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.6:9080/dial?request=hostname&protocol=http&host=192.168.249.4&port=8083&tries=1'] Namespace:pod-network-test-4696 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:24:32.472: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:24:32.473: INFO: ExecWithOptions: Clientset creation
Nov 12 12:24:32.473: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4696/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.6%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.249.4%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 12:24:32.555: INFO: Waiting for responses: map[]
Nov 12 12:24:32.555: INFO: reached 192.168.249.4 after 0/1 tries
Nov 12 12:24:32.556: INFO: Breadth first check of 192.168.27.115 on host 172.31.47.219...
Nov 12 12:24:32.560: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.6:9080/dial?request=hostname&protocol=http&host=192.168.27.115&port=8083&tries=1'] Namespace:pod-network-test-4696 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:24:32.560: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:24:32.561: INFO: ExecWithOptions: Clientset creation
Nov 12 12:24:32.561: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4696/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.6%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.27.115%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 12:24:32.642: INFO: Waiting for responses: map[]
Nov 12 12:24:32.643: INFO: reached 192.168.27.115 after 0/1 tries
Nov 12 12:24:32.643: INFO: Breadth first check of 192.168.128.253 on host 172.31.89.190...
Nov 12 12:24:32.654: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.6:9080/dial?request=hostname&protocol=http&host=192.168.128.253&port=8083&tries=1'] Namespace:pod-network-test-4696 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:24:32.654: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:24:32.655: INFO: ExecWithOptions: Clientset creation
Nov 12 12:24:32.655: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4696/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.6%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.128.253%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 12:24:32.750: INFO: Waiting for responses: map[]
Nov 12 12:24:32.751: INFO: reached 192.168.128.253 after 0/1 tries
Nov 12 12:24:32.751: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 12 12:24:32.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4696" for this suite. 11/12/22 12:24:32.757
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":113,"skipped":2231,"failed":0}
------------------------------
• [SLOW TEST] [24.450 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:24:08.316
    Nov 12 12:24:08.316: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:24:08.319
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:08.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:08.344
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-4696 11/12/22 12:24:08.352
    STEP: creating a selector 11/12/22 12:24:08.352
    STEP: Creating the service pods in kubernetes 11/12/22 12:24:08.352
    Nov 12 12:24:08.352: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 12 12:24:08.409: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4696" to be "running and ready"
    Nov 12 12:24:08.414: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.432946ms
    Nov 12 12:24:08.414: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:24:10.419: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.010365359s
    Nov 12 12:24:10.419: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:12.422: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013468744s
    Nov 12 12:24:12.422: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:14.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011230305s
    Nov 12 12:24:14.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:16.421: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.012501362s
    Nov 12 12:24:16.421: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:18.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.010719925s
    Nov 12 12:24:18.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:20.424: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.015234892s
    Nov 12 12:24:20.424: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:22.423: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.013637549s
    Nov 12 12:24:22.423: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:24.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.011461125s
    Nov 12 12:24:24.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:26.420: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.011315018s
    Nov 12 12:24:26.420: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:28.422: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013086068s
    Nov 12 12:24:28.422: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:24:30.419: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.010548252s
    Nov 12 12:24:30.420: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 12 12:24:30.420: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 12 12:24:30.424: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4696" to be "running and ready"
    Nov 12 12:24:30.429: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.698016ms
    Nov 12 12:24:30.429: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 12 12:24:30.429: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 12 12:24:30.433: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4696" to be "running and ready"
    Nov 12 12:24:30.437: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.982031ms
    Nov 12 12:24:30.437: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 12 12:24:30.437: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/12/22 12:24:30.443
    Nov 12 12:24:30.453: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4696" to be "running"
    Nov 12 12:24:30.458: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.282353ms
    Nov 12 12:24:32.464: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010168098s
    Nov 12 12:24:32.464: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 12 12:24:32.468: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 12 12:24:32.468: INFO: Breadth first check of 192.168.249.4 on host 172.31.14.110...
    Nov 12 12:24:32.472: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.6:9080/dial?request=hostname&protocol=http&host=192.168.249.4&port=8083&tries=1'] Namespace:pod-network-test-4696 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:24:32.472: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:24:32.473: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:24:32.473: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4696/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.6%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.249.4%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 12:24:32.555: INFO: Waiting for responses: map[]
    Nov 12 12:24:32.555: INFO: reached 192.168.249.4 after 0/1 tries
    Nov 12 12:24:32.556: INFO: Breadth first check of 192.168.27.115 on host 172.31.47.219...
    Nov 12 12:24:32.560: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.6:9080/dial?request=hostname&protocol=http&host=192.168.27.115&port=8083&tries=1'] Namespace:pod-network-test-4696 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:24:32.560: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:24:32.561: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:24:32.561: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4696/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.6%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.27.115%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 12:24:32.642: INFO: Waiting for responses: map[]
    Nov 12 12:24:32.643: INFO: reached 192.168.27.115 after 0/1 tries
    Nov 12 12:24:32.643: INFO: Breadth first check of 192.168.128.253 on host 172.31.89.190...
    Nov 12 12:24:32.654: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.6:9080/dial?request=hostname&protocol=http&host=192.168.128.253&port=8083&tries=1'] Namespace:pod-network-test-4696 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:24:32.654: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:24:32.655: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:24:32.655: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4696/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.6%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.128.253%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 12:24:32.750: INFO: Waiting for responses: map[]
    Nov 12 12:24:32.751: INFO: reached 192.168.128.253 after 0/1 tries
    Nov 12 12:24:32.751: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 12 12:24:32.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4696" for this suite. 11/12/22 12:24:32.757
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:24:32.77
Nov 12 12:24:32.770: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:24:32.771
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:32.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:32.794
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Nov 12 12:24:32.834: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130" in namespace "kubelet-test-598" to be "running and ready"
Nov 12 12:24:32.841: INFO: Pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130": Phase="Pending", Reason="", readiness=false. Elapsed: 7.227202ms
Nov 12 12:24:32.841: INFO: The phase of Pod busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:24:34.846: INFO: Pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130": Phase="Running", Reason="", readiness=true. Elapsed: 2.011659264s
Nov 12 12:24:34.846: INFO: The phase of Pod busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130 is Running (Ready = true)
Nov 12 12:24:34.846: INFO: Pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 12:24:34.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-598" for this suite. 11/12/22 12:24:34.873
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":114,"skipped":2266,"failed":0}
------------------------------
• [2.115 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:24:32.77
    Nov 12 12:24:32.770: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:24:32.771
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:32.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:32.794
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Nov 12 12:24:32.834: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130" in namespace "kubelet-test-598" to be "running and ready"
    Nov 12 12:24:32.841: INFO: Pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130": Phase="Pending", Reason="", readiness=false. Elapsed: 7.227202ms
    Nov 12 12:24:32.841: INFO: The phase of Pod busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:24:34.846: INFO: Pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130": Phase="Running", Reason="", readiness=true. Elapsed: 2.011659264s
    Nov 12 12:24:34.846: INFO: The phase of Pod busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130 is Running (Ready = true)
    Nov 12 12:24:34.846: INFO: Pod "busybox-readonly-fs130af3d3-acdf-4dde-a563-349747010130" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 12:24:34.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-598" for this suite. 11/12/22 12:24:34.873
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:24:34.886
Nov 12 12:24:34.886: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-webhook 11/12/22 12:24:34.887
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:34.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:34.919
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/12/22 12:24:34.923
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 12:24:35.195
STEP: Deploying the custom resource conversion webhook pod 11/12/22 12:24:35.205
STEP: Wait for the deployment to be ready 11/12/22 12:24:35.222
Nov 12 12:24:35.240: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:24:37.257
STEP: Verifying the service has paired with the endpoint 11/12/22 12:24:37.273
Nov 12 12:24:38.274: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Nov 12 12:24:38.279: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Creating a v1 custom resource 11/12/22 12:24:40.883
STEP: Create a v2 custom resource 11/12/22 12:24:40.912
STEP: List CRs in v1 11/12/22 12:24:40.926
STEP: List CRs in v2 11/12/22 12:24:40.981
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:24:41.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9687" for this suite. 11/12/22 12:24:41.515
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":115,"skipped":2269,"failed":0}
------------------------------
• [SLOW TEST] [6.712 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:24:34.886
    Nov 12 12:24:34.886: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-webhook 11/12/22 12:24:34.887
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:34.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:34.919
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/12/22 12:24:34.923
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/12/22 12:24:35.195
    STEP: Deploying the custom resource conversion webhook pod 11/12/22 12:24:35.205
    STEP: Wait for the deployment to be ready 11/12/22 12:24:35.222
    Nov 12 12:24:35.240: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:24:37.257
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:24:37.273
    Nov 12 12:24:38.274: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Nov 12 12:24:38.279: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Creating a v1 custom resource 11/12/22 12:24:40.883
    STEP: Create a v2 custom resource 11/12/22 12:24:40.912
    STEP: List CRs in v1 11/12/22 12:24:40.926
    STEP: List CRs in v2 11/12/22 12:24:40.981
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:24:41.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-9687" for this suite. 11/12/22 12:24:41.515
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:24:41.598
Nov 12 12:24:41.598: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 12:24:41.599
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:41.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:41.635
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Nov 12 12:24:41.660: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 12 12:24:46.667: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 12:24:46.667
Nov 12 12:24:46.667: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/12/22 12:24:46.682
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 12:24:46.700: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8432  ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce 15330 1 2022-11-12 12:24:46 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002731978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Nov 12 12:24:46.708: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-8432  fdc113d9-b015-45ad-b00d-7b5722f2bf1b 15332 1 2022-11-12 12:24:46 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce 0xc00287dec7 0xc00287dec8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00287df58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:24:46.708: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov 12 12:24:46.708: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-8432  0557ed4f-551e-46b1-b7ad-e1f1ecb2920c 15331 1 2022-11-12 12:24:41 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce 0xc00287dd97 0xc00287dd98}] [] [{e2e.test Update apps/v1 2022-11-12 12:24:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:24:43 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00287de58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:24:46.720: INFO: Pod "test-cleanup-controller-fzvvp" is available:
&Pod{ObjectMeta:{test-cleanup-controller-fzvvp test-cleanup-controller- deployment-8432  49dbd775-f258-4845-9625-8d87a1c26751 15316 0 2022-11-12 12:24:41 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 0557ed4f-551e-46b1-b7ad-e1f1ecb2920c 0xc002e28857 0xc002e28858}] [] [{kube-controller-manager Update v1 2022-11-12 12:24:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0557ed4f-551e-46b1-b7ad-e1f1ecb2920c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:24:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qqzlh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qqzlh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.7,StartTime:2022-11-12 12:24:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:24:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8b1aea8a6dd12ab0867c4e5d14c4126c53aa5908f16ccb77fdb21e44490e9371,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 12:24:46.720: INFO: Pod "test-cleanup-deployment-69cb9c5497-dwtxd" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-dwtxd test-cleanup-deployment-69cb9c5497- deployment-8432  63e79a1a-f7ad-4a22-82f3-2b6a48745481 15334 0 2022-11-12 12:24:46 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 fdc113d9-b015-45ad-b00d-7b5722f2bf1b 0xc002e28a57 0xc002e28a58}] [] [{kube-controller-manager Update v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fdc113d9-b015-45ad-b00d-7b5722f2bf1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s8mkz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s8mkz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 12:24:46.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8432" for this suite. 11/12/22 12:24:46.738
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":116,"skipped":2269,"failed":0}
------------------------------
• [SLOW TEST] [5.158 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:24:41.598
    Nov 12 12:24:41.598: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 12:24:41.599
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:41.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:41.635
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Nov 12 12:24:41.660: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Nov 12 12:24:46.667: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 12:24:46.667
    Nov 12 12:24:46.667: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/12/22 12:24:46.682
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 12:24:46.700: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8432  ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce 15330 1 2022-11-12 12:24:46 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002731978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Nov 12 12:24:46.708: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-8432  fdc113d9-b015-45ad-b00d-7b5722f2bf1b 15332 1 2022-11-12 12:24:46 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce 0xc00287dec7 0xc00287dec8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00287df58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:24:46.708: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Nov 12 12:24:46.708: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-8432  0557ed4f-551e-46b1-b7ad-e1f1ecb2920c 15331 1 2022-11-12 12:24:41 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce 0xc00287dd97 0xc00287dd98}] [] [{e2e.test Update apps/v1 2022-11-12 12:24:41 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:24:43 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8346f3-5a5d-4a69-b9a3-060d5fc0a5ce\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00287de58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:24:46.720: INFO: Pod "test-cleanup-controller-fzvvp" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-fzvvp test-cleanup-controller- deployment-8432  49dbd775-f258-4845-9625-8d87a1c26751 15316 0 2022-11-12 12:24:41 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 0557ed4f-551e-46b1-b7ad-e1f1ecb2920c 0xc002e28857 0xc002e28858}] [] [{kube-controller-manager Update v1 2022-11-12 12:24:41 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0557ed4f-551e-46b1-b7ad-e1f1ecb2920c\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:24:43 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qqzlh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qqzlh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:24:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.7,StartTime:2022-11-12 12:24:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:24:42 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8b1aea8a6dd12ab0867c4e5d14c4126c53aa5908f16ccb77fdb21e44490e9371,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 12:24:46.720: INFO: Pod "test-cleanup-deployment-69cb9c5497-dwtxd" is not available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-dwtxd test-cleanup-deployment-69cb9c5497- deployment-8432  63e79a1a-f7ad-4a22-82f3-2b6a48745481 15334 0 2022-11-12 12:24:46 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 fdc113d9-b015-45ad-b00d-7b5722f2bf1b 0xc002e28a57 0xc002e28a58}] [] [{kube-controller-manager Update v1 2022-11-12 12:24:46 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fdc113d9-b015-45ad-b00d-7b5722f2bf1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s8mkz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s8mkz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 12:24:46.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8432" for this suite. 11/12/22 12:24:46.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:24:46.756
Nov 12 12:24:46.757: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 12:24:46.758
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:46.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:46.79
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Nov 12 12:24:46.793: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 12:24:49.43
Nov 12 12:24:49.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 create -f -'
Nov 12 12:24:50.223: INFO: stderr: ""
Nov 12 12:24:50.224: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 12 12:24:50.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 delete e2e-test-crd-publish-openapi-3215-crds test-cr'
Nov 12 12:24:50.307: INFO: stderr: ""
Nov 12 12:24:50.307: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov 12 12:24:50.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 apply -f -'
Nov 12 12:24:50.603: INFO: stderr: ""
Nov 12 12:24:50.603: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 12 12:24:50.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 delete e2e-test-crd-publish-openapi-3215-crds test-cr'
Nov 12 12:24:50.689: INFO: stderr: ""
Nov 12 12:24:50.689: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/12/22 12:24:50.689
Nov 12 12:24:50.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 explain e2e-test-crd-publish-openapi-3215-crds'
Nov 12 12:24:51.251: INFO: stderr: ""
Nov 12 12:24:51.251: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3215-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:24:53.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4001" for this suite. 11/12/22 12:24:53.589
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":117,"skipped":2274,"failed":0}
------------------------------
• [SLOW TEST] [6.843 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:24:46.756
    Nov 12 12:24:46.757: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 12:24:46.758
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:46.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:46.79
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Nov 12 12:24:46.793: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 12:24:49.43
    Nov 12 12:24:49.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 create -f -'
    Nov 12 12:24:50.223: INFO: stderr: ""
    Nov 12 12:24:50.224: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 12 12:24:50.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 delete e2e-test-crd-publish-openapi-3215-crds test-cr'
    Nov 12 12:24:50.307: INFO: stderr: ""
    Nov 12 12:24:50.307: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Nov 12 12:24:50.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 apply -f -'
    Nov 12 12:24:50.603: INFO: stderr: ""
    Nov 12 12:24:50.603: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 12 12:24:50.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 --namespace=crd-publish-openapi-4001 delete e2e-test-crd-publish-openapi-3215-crds test-cr'
    Nov 12 12:24:50.689: INFO: stderr: ""
    Nov 12 12:24:50.689: INFO: stdout: "e2e-test-crd-publish-openapi-3215-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/12/22 12:24:50.689
    Nov 12 12:24:50.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-4001 explain e2e-test-crd-publish-openapi-3215-crds'
    Nov 12 12:24:51.251: INFO: stderr: ""
    Nov 12 12:24:51.251: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3215-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:24:53.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4001" for this suite. 11/12/22 12:24:53.589
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:24:53.601
Nov 12 12:24:53.601: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename watch 11/12/22 12:24:53.602
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:53.621
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:53.624
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 11/12/22 12:24:53.627
STEP: creating a watch on configmaps with label B 11/12/22 12:24:53.628
STEP: creating a watch on configmaps with label A or B 11/12/22 12:24:53.629
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/12/22 12:24:53.631
Nov 12 12:24:53.637: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15413 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:24:53.638: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15413 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/12/22 12:24:53.638
Nov 12 12:24:53.650: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15414 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:24:53.650: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15414 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/12/22 12:24:53.65
Nov 12 12:24:53.662: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15415 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:24:53.662: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15415 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/12/22 12:24:53.662
Nov 12 12:24:53.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15416 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:24:53.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15416 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/12/22 12:24:53.671
Nov 12 12:24:53.677: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15417 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:24:53.677: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15417 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/12/22 12:25:03.678
Nov 12 12:25:03.689: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15443 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:25:03.689: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15443 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 12:25:13.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4903" for this suite. 11/12/22 12:25:13.695
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":118,"skipped":2292,"failed":0}
------------------------------
• [SLOW TEST] [20.103 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:24:53.601
    Nov 12 12:24:53.601: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename watch 11/12/22 12:24:53.602
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:24:53.621
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:24:53.624
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 11/12/22 12:24:53.627
    STEP: creating a watch on configmaps with label B 11/12/22 12:24:53.628
    STEP: creating a watch on configmaps with label A or B 11/12/22 12:24:53.629
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/12/22 12:24:53.631
    Nov 12 12:24:53.637: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15413 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:24:53.638: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15413 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/12/22 12:24:53.638
    Nov 12 12:24:53.650: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15414 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:24:53.650: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15414 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/12/22 12:24:53.65
    Nov 12 12:24:53.662: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15415 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:24:53.662: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15415 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/12/22 12:24:53.662
    Nov 12 12:24:53.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15416 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:24:53.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4903  acf2b799-469e-4834-ad4b-f15b2daffbd3 15416 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/12/22 12:24:53.671
    Nov 12 12:24:53.677: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15417 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:24:53.677: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15417 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/12/22 12:25:03.678
    Nov 12 12:25:03.689: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15443 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:25:03.689: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4903  a748b7a4-17b4-48c7-8ebc-3603a392605e 15443 0 2022-11-12 12:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-12 12:24:53 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 12:25:13.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4903" for this suite. 11/12/22 12:25:13.695
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:25:13.707
Nov 12 12:25:13.708: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename security-context-test 11/12/22 12:25:13.71
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:25:13.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:25:13.739
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Nov 12 12:25:13.758: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db" in namespace "security-context-test-6323" to be "Succeeded or Failed"
Nov 12 12:25:13.766: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db": Phase="Pending", Reason="", readiness=false. Elapsed: 8.243023ms
Nov 12 12:25:15.774: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01661566s
Nov 12 12:25:17.771: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013600624s
Nov 12 12:25:17.771: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 12:25:17.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6323" for this suite. 11/12/22 12:25:17.785
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":119,"skipped":2311,"failed":0}
------------------------------
• [4.090 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:25:13.707
    Nov 12 12:25:13.708: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename security-context-test 11/12/22 12:25:13.71
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:25:13.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:25:13.739
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Nov 12 12:25:13.758: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db" in namespace "security-context-test-6323" to be "Succeeded or Failed"
    Nov 12 12:25:13.766: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db": Phase="Pending", Reason="", readiness=false. Elapsed: 8.243023ms
    Nov 12 12:25:15.774: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01661566s
    Nov 12 12:25:17.771: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013600624s
    Nov 12 12:25:17.771: INFO: Pod "alpine-nnp-false-c25353fb-a466-4fca-8dff-8070fd1ac4db" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 12:25:17.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6323" for this suite. 11/12/22 12:25:17.785
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:25:17.798
Nov 12 12:25:17.798: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-preemption 11/12/22 12:25:17.799
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:25:17.821
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:25:17.824
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 12 12:25:17.847: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 12:26:17.871: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:17.876
Nov 12 12:26:17.877: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-preemption-path 11/12/22 12:26:17.877
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:17.898
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:17.904
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Nov 12 12:26:17.927: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Nov 12 12:26:17.932: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Nov 12 12:26:17.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7850" for this suite. 11/12/22 12:26:17.962
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:26:18.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6718" for this suite. 11/12/22 12:26:18.02
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":120,"skipped":2317,"failed":0}
------------------------------
• [SLOW TEST] [60.295 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:25:17.798
    Nov 12 12:25:17.798: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-preemption 11/12/22 12:25:17.799
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:25:17.821
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:25:17.824
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 12 12:25:17.847: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 12:26:17.871: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:17.876
    Nov 12 12:26:17.877: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-preemption-path 11/12/22 12:26:17.877
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:17.898
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:17.904
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Nov 12 12:26:17.927: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Nov 12 12:26:17.932: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Nov 12 12:26:17.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-7850" for this suite. 11/12/22 12:26:17.962
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:26:18.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-6718" for this suite. 11/12/22 12:26:18.02
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:18.093
Nov 12 12:26:18.094: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:26:18.095
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:18.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:18.121
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:26:18.127
Nov 12 12:26:18.142: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1150" to be "running and ready"
Nov 12 12:26:18.154: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.778213ms
Nov 12 12:26:18.154: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:26:20.158: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016639834s
Nov 12 12:26:20.159: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 12 12:26:20.159: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 11/12/22 12:26:20.164
Nov 12 12:26:20.173: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-1150" to be "running and ready"
Nov 12 12:26:20.177: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.30269ms
Nov 12 12:26:20.177: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:26:22.183: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.010637516s
Nov 12 12:26:22.183: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Nov 12 12:26:22.183: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/12/22 12:26:22.189
Nov 12 12:26:22.204: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 12 12:26:22.212: INFO: Pod pod-with-prestop-http-hook still exists
Nov 12 12:26:24.213: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 12 12:26:24.219: INFO: Pod pod-with-prestop-http-hook still exists
Nov 12 12:26:26.213: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 12 12:26:26.218: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 11/12/22 12:26:26.218
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 12 12:26:26.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1150" for this suite. 11/12/22 12:26:26.246
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":121,"skipped":2319,"failed":0}
------------------------------
• [SLOW TEST] [8.168 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:18.093
    Nov 12 12:26:18.094: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:26:18.095
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:18.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:18.121
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:26:18.127
    Nov 12 12:26:18.142: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1150" to be "running and ready"
    Nov 12 12:26:18.154: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 11.778213ms
    Nov 12 12:26:18.154: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:26:20.158: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.016639834s
    Nov 12 12:26:20.159: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 12 12:26:20.159: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 11/12/22 12:26:20.164
    Nov 12 12:26:20.173: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-1150" to be "running and ready"
    Nov 12 12:26:20.177: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.30269ms
    Nov 12 12:26:20.177: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:26:22.183: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.010637516s
    Nov 12 12:26:22.183: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Nov 12 12:26:22.183: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/12/22 12:26:22.189
    Nov 12 12:26:22.204: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 12 12:26:22.212: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 12 12:26:24.213: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 12 12:26:24.219: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 12 12:26:26.213: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 12 12:26:26.218: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 11/12/22 12:26:26.218
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 12 12:26:26.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-1150" for this suite. 11/12/22 12:26:26.246
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:26.262
Nov 12 12:26:26.263: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:26:26.263
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:26.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:26.289
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 11/12/22 12:26:26.291
STEP: watching for the ServiceAccount to be added 11/12/22 12:26:26.303
STEP: patching the ServiceAccount 11/12/22 12:26:26.304
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/12/22 12:26:26.312
STEP: deleting the ServiceAccount 11/12/22 12:26:26.318
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 12 12:26:26.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4820" for this suite. 11/12/22 12:26:26.354
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":122,"skipped":2328,"failed":0}
------------------------------
• [0.105 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:26.262
    Nov 12 12:26:26.263: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:26:26.263
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:26.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:26.289
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 11/12/22 12:26:26.291
    STEP: watching for the ServiceAccount to be added 11/12/22 12:26:26.303
    STEP: patching the ServiceAccount 11/12/22 12:26:26.304
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/12/22 12:26:26.312
    STEP: deleting the ServiceAccount 11/12/22 12:26:26.318
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 12 12:26:26.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4820" for this suite. 11/12/22 12:26:26.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:26.37
Nov 12 12:26:26.370: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 12:26:26.37
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:26.394
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:26.4
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 11/12/22 12:26:26.402
Nov 12 12:26:26.416: INFO: Waiting up to 5m0s for pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3" in namespace "var-expansion-92" to be "Succeeded or Failed"
Nov 12 12:26:26.422: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.364131ms
Nov 12 12:26:28.429: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012563596s
Nov 12 12:26:30.429: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012789904s
STEP: Saw pod success 11/12/22 12:26:30.429
Nov 12 12:26:30.429: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3" satisfied condition "Succeeded or Failed"
Nov 12 12:26:30.435: INFO: Trying to get logs from node ip-172-31-14-110 pod var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3 container dapi-container: <nil>
STEP: delete the pod 11/12/22 12:26:30.45
Nov 12 12:26:30.466: INFO: Waiting for pod var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3 to disappear
Nov 12 12:26:30.473: INFO: Pod var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 12:26:30.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-92" for this suite. 11/12/22 12:26:30.478
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":123,"skipped":2333,"failed":0}
------------------------------
• [4.119 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:26.37
    Nov 12 12:26:26.370: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 12:26:26.37
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:26.394
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:26.4
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 11/12/22 12:26:26.402
    Nov 12 12:26:26.416: INFO: Waiting up to 5m0s for pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3" in namespace "var-expansion-92" to be "Succeeded or Failed"
    Nov 12 12:26:26.422: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.364131ms
    Nov 12 12:26:28.429: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012563596s
    Nov 12 12:26:30.429: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012789904s
    STEP: Saw pod success 11/12/22 12:26:30.429
    Nov 12 12:26:30.429: INFO: Pod "var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3" satisfied condition "Succeeded or Failed"
    Nov 12 12:26:30.435: INFO: Trying to get logs from node ip-172-31-14-110 pod var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 12:26:30.45
    Nov 12 12:26:30.466: INFO: Waiting for pod var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3 to disappear
    Nov 12 12:26:30.473: INFO: Pod var-expansion-af037435-4aa7-4a08-801a-4e486cc14fe3 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 12:26:30.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-92" for this suite. 11/12/22 12:26:30.478
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:30.5
Nov 12 12:26:30.501: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:26:30.501
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:30.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:30.526
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 11/12/22 12:26:30.53
Nov 12 12:26:30.547: INFO: Waiting up to 5m0s for pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3" in namespace "projected-8677" to be "running and ready"
Nov 12 12:26:30.553: INFO: Pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.221962ms
Nov 12 12:26:30.553: INFO: The phase of Pod labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:26:32.560: INFO: Pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3": Phase="Running", Reason="", readiness=true. Elapsed: 2.012347602s
Nov 12 12:26:32.560: INFO: The phase of Pod labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3 is Running (Ready = true)
Nov 12 12:26:32.560: INFO: Pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3" satisfied condition "running and ready"
Nov 12 12:26:33.116: INFO: Successfully updated pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 12:26:37.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8677" for this suite. 11/12/22 12:26:37.16
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":124,"skipped":2359,"failed":0}
------------------------------
• [SLOW TEST] [6.671 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:30.5
    Nov 12 12:26:30.501: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:26:30.501
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:30.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:30.526
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 11/12/22 12:26:30.53
    Nov 12 12:26:30.547: INFO: Waiting up to 5m0s for pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3" in namespace "projected-8677" to be "running and ready"
    Nov 12 12:26:30.553: INFO: Pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.221962ms
    Nov 12 12:26:30.553: INFO: The phase of Pod labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:26:32.560: INFO: Pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3": Phase="Running", Reason="", readiness=true. Elapsed: 2.012347602s
    Nov 12 12:26:32.560: INFO: The phase of Pod labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3 is Running (Ready = true)
    Nov 12 12:26:32.560: INFO: Pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3" satisfied condition "running and ready"
    Nov 12 12:26:33.116: INFO: Successfully updated pod "labelsupdate89230ae5-adfe-4016-924a-a5fd3fb2fba3"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 12:26:37.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8677" for this suite. 11/12/22 12:26:37.16
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:37.172
Nov 12 12:26:37.172: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:26:37.172
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:37.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:37.212
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Nov 12 12:26:37.217: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:26:40.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3285" for this suite. 11/12/22 12:26:40.608
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":125,"skipped":2360,"failed":0}
------------------------------
• [3.447 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:37.172
    Nov 12 12:26:37.172: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:26:37.172
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:37.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:37.212
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Nov 12 12:26:37.217: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:26:40.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3285" for this suite. 11/12/22 12:26:40.608
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:40.639
Nov 12 12:26:40.640: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename job 11/12/22 12:26:40.641
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:40.66
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:40.664
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 11/12/22 12:26:40.67
STEP: Patching the Job 11/12/22 12:26:40.681
STEP: Watching for Job to be patched 11/12/22 12:26:40.708
Nov 12 12:26:40.710: INFO: Event ADDED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov 12 12:26:40.710: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov 12 12:26:40.710: INFO: Event MODIFIED found for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 11/12/22 12:26:40.71
STEP: Watching for Job to be updated 11/12/22 12:26:40.722
Nov 12 12:26:40.724: INFO: Event MODIFIED found for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 12:26:40.724: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 11/12/22 12:26:40.724
Nov 12 12:26:40.728: INFO: Job: e2e-bxvts as labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts]
STEP: Waiting for job to complete 11/12/22 12:26:40.728
STEP: Delete a job collection with a labelselector 11/12/22 12:26:50.738
STEP: Watching for Job to be deleted 11/12/22 12:26:50.752
Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 12 12:26:50.766: INFO: Event DELETED found for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 11/12/22 12:26:50.766
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 12 12:26:50.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1019" for this suite. 11/12/22 12:26:50.788
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":126,"skipped":2411,"failed":0}
------------------------------
• [SLOW TEST] [10.170 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:40.639
    Nov 12 12:26:40.640: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename job 11/12/22 12:26:40.641
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:40.66
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:40.664
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 11/12/22 12:26:40.67
    STEP: Patching the Job 11/12/22 12:26:40.681
    STEP: Watching for Job to be patched 11/12/22 12:26:40.708
    Nov 12 12:26:40.710: INFO: Event ADDED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov 12 12:26:40.710: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov 12 12:26:40.710: INFO: Event MODIFIED found for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 11/12/22 12:26:40.71
    STEP: Watching for Job to be updated 11/12/22 12:26:40.722
    Nov 12 12:26:40.724: INFO: Event MODIFIED found for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 12:26:40.724: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 11/12/22 12:26:40.724
    Nov 12 12:26:40.728: INFO: Job: e2e-bxvts as labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts]
    STEP: Waiting for job to complete 11/12/22 12:26:40.728
    STEP: Delete a job collection with a labelselector 11/12/22 12:26:50.738
    STEP: Watching for Job to be deleted 11/12/22 12:26:50.752
    Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 12:26:50.766: INFO: Event MODIFIED observed for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 12 12:26:50.766: INFO: Event DELETED found for Job e2e-bxvts in namespace job-1019 with labels: map[e2e-bxvts:patched e2e-job-label:e2e-bxvts] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 11/12/22 12:26:50.766
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 12 12:26:50.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1019" for this suite. 11/12/22 12:26:50.788
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:50.814
Nov 12 12:26:50.814: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 12:26:50.814
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:50.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:50.846
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3397.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3397.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 11/12/22 12:26:50.852
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3397.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3397.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 11/12/22 12:26:50.852
STEP: creating a pod to probe /etc/hosts 11/12/22 12:26:50.853
STEP: submitting the pod to kubernetes 11/12/22 12:26:50.853
Nov 12 12:26:50.869: INFO: Waiting up to 15m0s for pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d" in namespace "dns-3397" to be "running"
Nov 12 12:26:50.880: INFO: Pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.684663ms
Nov 12 12:26:52.886: INFO: Pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d": Phase="Running", Reason="", readiness=true. Elapsed: 2.016805819s
Nov 12 12:26:52.886: INFO: Pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d" satisfied condition "running"
STEP: retrieving the pod 11/12/22 12:26:52.886
STEP: looking for the results for each expected name from probers 11/12/22 12:26:52.923
Nov 12 12:26:52.952: INFO: DNS probes using dns-3397/dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d succeeded

STEP: deleting the pod 11/12/22 12:26:52.952
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 12:26:52.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3397" for this suite. 11/12/22 12:26:52.986
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":127,"skipped":2443,"failed":0}
------------------------------
• [2.186 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:50.814
    Nov 12 12:26:50.814: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 12:26:50.814
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:50.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:50.846
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3397.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3397.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     11/12/22 12:26:50.852
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3397.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3397.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     11/12/22 12:26:50.852
    STEP: creating a pod to probe /etc/hosts 11/12/22 12:26:50.853
    STEP: submitting the pod to kubernetes 11/12/22 12:26:50.853
    Nov 12 12:26:50.869: INFO: Waiting up to 15m0s for pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d" in namespace "dns-3397" to be "running"
    Nov 12 12:26:50.880: INFO: Pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.684663ms
    Nov 12 12:26:52.886: INFO: Pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d": Phase="Running", Reason="", readiness=true. Elapsed: 2.016805819s
    Nov 12 12:26:52.886: INFO: Pod "dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 12:26:52.886
    STEP: looking for the results for each expected name from probers 11/12/22 12:26:52.923
    Nov 12 12:26:52.952: INFO: DNS probes using dns-3397/dns-test-ac407d1c-f291-42c1-b30c-6ffc569bc60d succeeded

    STEP: deleting the pod 11/12/22 12:26:52.952
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 12:26:52.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-3397" for this suite. 11/12/22 12:26:52.986
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:26:53.001
Nov 12 12:26:53.001: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:26:53.002
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:53.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:53.029
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-796 11/12/22 12:26:53.032
STEP: changing the ExternalName service to type=ClusterIP 11/12/22 12:26:53.04
STEP: creating replication controller externalname-service in namespace services-796 11/12/22 12:26:53.093
I1112 12:26:53.107155      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-796, replica count: 2
I1112 12:26:56.158328      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 12:26:56.158: INFO: Creating new exec pod
Nov 12 12:26:56.170: INFO: Waiting up to 5m0s for pod "execpod2pvdm" in namespace "services-796" to be "running"
Nov 12 12:26:56.174: INFO: Pod "execpod2pvdm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.604958ms
Nov 12 12:26:58.181: INFO: Pod "execpod2pvdm": Phase="Running", Reason="", readiness=true. Elapsed: 2.011200724s
Nov 12 12:26:58.181: INFO: Pod "execpod2pvdm" satisfied condition "running"
Nov 12 12:26:59.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-796 exec execpod2pvdm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 12 12:26:59.371: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 12 12:26:59.371: INFO: stdout: ""
Nov 12 12:27:00.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-796 exec execpod2pvdm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 12 12:27:00.528: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 12 12:27:00.528: INFO: stdout: "externalname-service-bjfxq"
Nov 12 12:27:00.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-796 exec execpod2pvdm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.231 80'
Nov 12 12:27:00.689: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.231 80\nConnection to 10.152.183.231 80 port [tcp/http] succeeded!\n"
Nov 12 12:27:00.689: INFO: stdout: "externalname-service-bjfxq"
Nov 12 12:27:00.689: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:27:00.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-796" for this suite. 11/12/22 12:27:00.728
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":128,"skipped":2446,"failed":0}
------------------------------
• [SLOW TEST] [7.736 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:26:53.001
    Nov 12 12:26:53.001: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:26:53.002
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:26:53.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:26:53.029
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-796 11/12/22 12:26:53.032
    STEP: changing the ExternalName service to type=ClusterIP 11/12/22 12:26:53.04
    STEP: creating replication controller externalname-service in namespace services-796 11/12/22 12:26:53.093
    I1112 12:26:53.107155      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-796, replica count: 2
    I1112 12:26:56.158328      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 12:26:56.158: INFO: Creating new exec pod
    Nov 12 12:26:56.170: INFO: Waiting up to 5m0s for pod "execpod2pvdm" in namespace "services-796" to be "running"
    Nov 12 12:26:56.174: INFO: Pod "execpod2pvdm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.604958ms
    Nov 12 12:26:58.181: INFO: Pod "execpod2pvdm": Phase="Running", Reason="", readiness=true. Elapsed: 2.011200724s
    Nov 12 12:26:58.181: INFO: Pod "execpod2pvdm" satisfied condition "running"
    Nov 12 12:26:59.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-796 exec execpod2pvdm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 12 12:26:59.371: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 12 12:26:59.371: INFO: stdout: ""
    Nov 12 12:27:00.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-796 exec execpod2pvdm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 12 12:27:00.528: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 12 12:27:00.528: INFO: stdout: "externalname-service-bjfxq"
    Nov 12 12:27:00.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-796 exec execpod2pvdm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.231 80'
    Nov 12 12:27:00.689: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.231 80\nConnection to 10.152.183.231 80 port [tcp/http] succeeded!\n"
    Nov 12 12:27:00.689: INFO: stdout: "externalname-service-bjfxq"
    Nov 12 12:27:00.689: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:27:00.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-796" for this suite. 11/12/22 12:27:00.728
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:00.737
Nov 12 12:27:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replicaset 11/12/22 12:27:00.738
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:00.762
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:00.764
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Nov 12 12:27:00.791: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 12 12:27:05.796: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 12:27:05.796
STEP: Scaling up "test-rs" replicaset  11/12/22 12:27:05.796
Nov 12 12:27:05.816: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 11/12/22 12:27:05.816
W1112 12:27:05.829729      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 12 12:27:05.831: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
Nov 12 12:27:05.863: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
Nov 12 12:27:05.885: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
Nov 12 12:27:05.911: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
Nov 12 12:27:06.934: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 2, AvailableReplicas 2
Nov 12 12:27:07.420: INFO: observed Replicaset test-rs in namespace replicaset-7892 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 12:27:07.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7892" for this suite. 11/12/22 12:27:07.427
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":129,"skipped":2447,"failed":0}
------------------------------
• [SLOW TEST] [6.699 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:00.737
    Nov 12 12:27:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replicaset 11/12/22 12:27:00.738
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:00.762
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:00.764
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Nov 12 12:27:00.791: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 12 12:27:05.796: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 12:27:05.796
    STEP: Scaling up "test-rs" replicaset  11/12/22 12:27:05.796
    Nov 12 12:27:05.816: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 11/12/22 12:27:05.816
    W1112 12:27:05.829729      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 12 12:27:05.831: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
    Nov 12 12:27:05.863: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
    Nov 12 12:27:05.885: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
    Nov 12 12:27:05.911: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 1, AvailableReplicas 1
    Nov 12 12:27:06.934: INFO: observed ReplicaSet test-rs in namespace replicaset-7892 with ReadyReplicas 2, AvailableReplicas 2
    Nov 12 12:27:07.420: INFO: observed Replicaset test-rs in namespace replicaset-7892 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 12:27:07.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7892" for this suite. 11/12/22 12:27:07.427
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:07.437
Nov 12 12:27:07.437: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:27:07.438
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:07.507
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:07.511
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:27:07.534
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:27:07.771
STEP: Deploying the webhook pod 11/12/22 12:27:07.782
STEP: Wait for the deployment to be ready 11/12/22 12:27:07.796
Nov 12 12:27:07.811: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:27:09.827
STEP: Verifying the service has paired with the endpoint 11/12/22 12:27:09.844
Nov 12 12:27:10.844: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 11/12/22 12:27:10.849
STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/12/22 12:27:10.872
STEP: Creating a configMap that should not be mutated 11/12/22 12:27:10.881
STEP: Patching a mutating webhook configuration's rules to include the create operation 11/12/22 12:27:10.897
STEP: Creating a configMap that should be mutated 11/12/22 12:27:10.907
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:27:10.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7344" for this suite. 11/12/22 12:27:10.944
STEP: Destroying namespace "webhook-7344-markers" for this suite. 11/12/22 12:27:10.955
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":130,"skipped":2450,"failed":0}
------------------------------
• [3.603 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:07.437
    Nov 12 12:27:07.437: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:27:07.438
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:07.507
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:07.511
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:27:07.534
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:27:07.771
    STEP: Deploying the webhook pod 11/12/22 12:27:07.782
    STEP: Wait for the deployment to be ready 11/12/22 12:27:07.796
    Nov 12 12:27:07.811: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:27:09.827
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:27:09.844
    Nov 12 12:27:10.844: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 11/12/22 12:27:10.849
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/12/22 12:27:10.872
    STEP: Creating a configMap that should not be mutated 11/12/22 12:27:10.881
    STEP: Patching a mutating webhook configuration's rules to include the create operation 11/12/22 12:27:10.897
    STEP: Creating a configMap that should be mutated 11/12/22 12:27:10.907
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:27:10.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7344" for this suite. 11/12/22 12:27:10.944
    STEP: Destroying namespace "webhook-7344-markers" for this suite. 11/12/22 12:27:10.955
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:11.04
Nov 12 12:27:11.040: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:27:11.041
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:11.115
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:11.118
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-cd72b2b4-a40c-4e15-a704-89cdcb3573d0 11/12/22 12:27:11.12
STEP: Creating a pod to test consume configMaps 11/12/22 12:27:11.129
Nov 12 12:27:11.144: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22" in namespace "projected-3219" to be "Succeeded or Failed"
Nov 12 12:27:11.152: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22": Phase="Pending", Reason="", readiness=false. Elapsed: 7.719046ms
Nov 12 12:27:13.161: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016438078s
Nov 12 12:27:15.159: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014811831s
STEP: Saw pod success 11/12/22 12:27:15.159
Nov 12 12:27:15.159: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22" satisfied condition "Succeeded or Failed"
Nov 12 12:27:15.164: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 12:27:15.172
Nov 12 12:27:15.201: INFO: Waiting for pod pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22 to disappear
Nov 12 12:27:15.205: INFO: Pod pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 12:27:15.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3219" for this suite. 11/12/22 12:27:15.211
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":131,"skipped":2453,"failed":0}
------------------------------
• [4.180 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:11.04
    Nov 12 12:27:11.040: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:27:11.041
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:11.115
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:11.118
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-cd72b2b4-a40c-4e15-a704-89cdcb3573d0 11/12/22 12:27:11.12
    STEP: Creating a pod to test consume configMaps 11/12/22 12:27:11.129
    Nov 12 12:27:11.144: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22" in namespace "projected-3219" to be "Succeeded or Failed"
    Nov 12 12:27:11.152: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22": Phase="Pending", Reason="", readiness=false. Elapsed: 7.719046ms
    Nov 12 12:27:13.161: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016438078s
    Nov 12 12:27:15.159: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014811831s
    STEP: Saw pod success 11/12/22 12:27:15.159
    Nov 12 12:27:15.159: INFO: Pod "pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22" satisfied condition "Succeeded or Failed"
    Nov 12 12:27:15.164: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 12:27:15.172
    Nov 12 12:27:15.201: INFO: Waiting for pod pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22 to disappear
    Nov 12 12:27:15.205: INFO: Pod pod-projected-configmaps-8b15d9b2-f1ba-4b0f-bb17-869bb3a20d22 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 12:27:15.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3219" for this suite. 11/12/22 12:27:15.211
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:15.222
Nov 12 12:27:15.222: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename disruption 11/12/22 12:27:15.224
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:15.246
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:15.252
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 11/12/22 12:27:15.263
STEP: Waiting for all pods to be running 11/12/22 12:27:17.323
Nov 12 12:27:17.332: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 12:27:19.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1171" for this suite. 11/12/22 12:27:19.346
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":132,"skipped":2469,"failed":0}
------------------------------
• [4.132 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:15.222
    Nov 12 12:27:15.222: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename disruption 11/12/22 12:27:15.224
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:15.246
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:15.252
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 11/12/22 12:27:15.263
    STEP: Waiting for all pods to be running 11/12/22 12:27:17.323
    Nov 12 12:27:17.332: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 12:27:19.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1171" for this suite. 11/12/22 12:27:19.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:19.355
Nov 12 12:27:19.355: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename namespaces 11/12/22 12:27:19.356
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:19.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:19.38
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 11/12/22 12:27:19.382
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:19.404
STEP: Creating a pod in the namespace 11/12/22 12:27:19.408
STEP: Waiting for the pod to have running status 11/12/22 12:27:19.42
Nov 12 12:27:19.420: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-979" to be "running"
Nov 12 12:27:19.427: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.12277ms
Nov 12 12:27:21.432: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012143127s
Nov 12 12:27:21.432: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 11/12/22 12:27:21.432
STEP: Waiting for the namespace to be removed. 11/12/22 12:27:21.442
STEP: Recreating the namespace 11/12/22 12:27:32.447
STEP: Verifying there are no pods in the namespace 11/12/22 12:27:32.465
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:27:32.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5154" for this suite. 11/12/22 12:27:32.483
STEP: Destroying namespace "nsdeletetest-979" for this suite. 11/12/22 12:27:32.493
Nov 12 12:27:32.497: INFO: Namespace nsdeletetest-979 was already deleted
STEP: Destroying namespace "nsdeletetest-4561" for this suite. 11/12/22 12:27:32.497
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":133,"skipped":2489,"failed":0}
------------------------------
• [SLOW TEST] [13.151 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:19.355
    Nov 12 12:27:19.355: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename namespaces 11/12/22 12:27:19.356
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:19.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:19.38
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 11/12/22 12:27:19.382
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:19.404
    STEP: Creating a pod in the namespace 11/12/22 12:27:19.408
    STEP: Waiting for the pod to have running status 11/12/22 12:27:19.42
    Nov 12 12:27:19.420: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-979" to be "running"
    Nov 12 12:27:19.427: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.12277ms
    Nov 12 12:27:21.432: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012143127s
    Nov 12 12:27:21.432: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 11/12/22 12:27:21.432
    STEP: Waiting for the namespace to be removed. 11/12/22 12:27:21.442
    STEP: Recreating the namespace 11/12/22 12:27:32.447
    STEP: Verifying there are no pods in the namespace 11/12/22 12:27:32.465
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:27:32.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-5154" for this suite. 11/12/22 12:27:32.483
    STEP: Destroying namespace "nsdeletetest-979" for this suite. 11/12/22 12:27:32.493
    Nov 12 12:27:32.497: INFO: Namespace nsdeletetest-979 was already deleted
    STEP: Destroying namespace "nsdeletetest-4561" for this suite. 11/12/22 12:27:32.497
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:32.516
Nov 12 12:27:32.516: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:27:32.517
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:32.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:32.544
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:27:32.573
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:27:32.927
STEP: Deploying the webhook pod 11/12/22 12:27:32.933
STEP: Wait for the deployment to be ready 11/12/22 12:27:32.951
Nov 12 12:27:32.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:27:34.981
STEP: Verifying the service has paired with the endpoint 11/12/22 12:27:34.998
Nov 12 12:27:35.999: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/12/22 12:27:36.004
STEP: create a pod that should be updated by the webhook 11/12/22 12:27:36.019
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:27:36.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2044" for this suite. 11/12/22 12:27:36.063
STEP: Destroying namespace "webhook-2044-markers" for this suite. 11/12/22 12:27:36.079
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":134,"skipped":2511,"failed":0}
------------------------------
• [3.654 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:32.516
    Nov 12 12:27:32.516: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:27:32.517
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:32.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:32.544
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:27:32.573
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:27:32.927
    STEP: Deploying the webhook pod 11/12/22 12:27:32.933
    STEP: Wait for the deployment to be ready 11/12/22 12:27:32.951
    Nov 12 12:27:32.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:27:34.981
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:27:34.998
    Nov 12 12:27:35.999: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/12/22 12:27:36.004
    STEP: create a pod that should be updated by the webhook 11/12/22 12:27:36.019
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:27:36.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2044" for this suite. 11/12/22 12:27:36.063
    STEP: Destroying namespace "webhook-2044-markers" for this suite. 11/12/22 12:27:36.079
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:36.171
Nov 12 12:27:36.171: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replicaset 11/12/22 12:27:36.172
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:36.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:36.192
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 11/12/22 12:27:36.195
STEP: Verify that the required pods have come up 11/12/22 12:27:36.201
Nov 12 12:27:36.205: INFO: Pod name sample-pod: Found 0 pods out of 3
Nov 12 12:27:41.217: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 11/12/22 12:27:41.217
Nov 12 12:27:41.222: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 11/12/22 12:27:41.222
STEP: DeleteCollection of the ReplicaSets 11/12/22 12:27:41.23
STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/12/22 12:27:41.247
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 12:27:41.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4847" for this suite. 11/12/22 12:27:41.26
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":135,"skipped":2512,"failed":0}
------------------------------
• [SLOW TEST] [5.107 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:36.171
    Nov 12 12:27:36.171: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replicaset 11/12/22 12:27:36.172
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:36.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:36.192
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 11/12/22 12:27:36.195
    STEP: Verify that the required pods have come up 11/12/22 12:27:36.201
    Nov 12 12:27:36.205: INFO: Pod name sample-pod: Found 0 pods out of 3
    Nov 12 12:27:41.217: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 11/12/22 12:27:41.217
    Nov 12 12:27:41.222: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 11/12/22 12:27:41.222
    STEP: DeleteCollection of the ReplicaSets 11/12/22 12:27:41.23
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/12/22 12:27:41.247
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 12:27:41.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4847" for this suite. 11/12/22 12:27:41.26
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:41.283
Nov 12 12:27:41.283: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:27:41.285
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:41.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:41.314
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 11/12/22 12:27:41.322
Nov 12 12:27:41.346: INFO: Waiting up to 5m0s for pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1" in namespace "projected-8598" to be "running and ready"
Nov 12 12:27:41.356: INFO: Pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.3043ms
Nov 12 12:27:41.357: INFO: The phase of Pod annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:27:43.363: INFO: Pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015515349s
Nov 12 12:27:43.363: INFO: The phase of Pod annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1 is Running (Ready = true)
Nov 12 12:27:43.363: INFO: Pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1" satisfied condition "running and ready"
Nov 12 12:27:43.895: INFO: Successfully updated pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 12:27:45.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8598" for this suite. 11/12/22 12:27:45.92
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":136,"skipped":2538,"failed":0}
------------------------------
• [4.646 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:41.283
    Nov 12 12:27:41.283: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:27:41.285
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:41.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:41.314
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 11/12/22 12:27:41.322
    Nov 12 12:27:41.346: INFO: Waiting up to 5m0s for pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1" in namespace "projected-8598" to be "running and ready"
    Nov 12 12:27:41.356: INFO: Pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.3043ms
    Nov 12 12:27:41.357: INFO: The phase of Pod annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:27:43.363: INFO: Pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015515349s
    Nov 12 12:27:43.363: INFO: The phase of Pod annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1 is Running (Ready = true)
    Nov 12 12:27:43.363: INFO: Pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1" satisfied condition "running and ready"
    Nov 12 12:27:43.895: INFO: Successfully updated pod "annotationupdate760dcc47-8255-4d9e-8723-588aaa5a05b1"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 12:27:45.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8598" for this suite. 11/12/22 12:27:45.92
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:45.933
Nov 12 12:27:45.933: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-runtime 11/12/22 12:27:45.934
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:45.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:45.958
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 11/12/22 12:27:45.963
STEP: wait for the container to reach Failed 11/12/22 12:27:45.976
STEP: get the container status 11/12/22 12:27:50.005
STEP: the container should be terminated 11/12/22 12:27:50.009
STEP: the termination message should be set 11/12/22 12:27:50.009
Nov 12 12:27:50.009: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/12/22 12:27:50.009
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 12:27:50.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3332" for this suite. 11/12/22 12:27:50.04
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":137,"skipped":2559,"failed":0}
------------------------------
• [4.118 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:45.933
    Nov 12 12:27:45.933: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-runtime 11/12/22 12:27:45.934
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:45.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:45.958
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 11/12/22 12:27:45.963
    STEP: wait for the container to reach Failed 11/12/22 12:27:45.976
    STEP: get the container status 11/12/22 12:27:50.005
    STEP: the container should be terminated 11/12/22 12:27:50.009
    STEP: the termination message should be set 11/12/22 12:27:50.009
    Nov 12 12:27:50.009: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/12/22 12:27:50.009
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 12:27:50.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-3332" for this suite. 11/12/22 12:27:50.04
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:50.051
Nov 12 12:27:50.051: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:27:50.052
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:50.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:50.078
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 11/12/22 12:27:50.087
Nov 12 12:27:50.101: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e" in namespace "projected-1456" to be "Succeeded or Failed"
Nov 12 12:27:50.107: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.180954ms
Nov 12 12:27:52.114: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012459209s
Nov 12 12:27:54.115: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013940596s
STEP: Saw pod success 11/12/22 12:27:54.115
Nov 12 12:27:54.115: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e" satisfied condition "Succeeded or Failed"
Nov 12 12:27:54.120: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e container client-container: <nil>
STEP: delete the pod 11/12/22 12:27:54.129
Nov 12 12:27:54.148: INFO: Waiting for pod downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e to disappear
Nov 12 12:27:54.152: INFO: Pod downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 12:27:54.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1456" for this suite. 11/12/22 12:27:54.158
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":138,"skipped":2569,"failed":0}
------------------------------
• [4.117 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:50.051
    Nov 12 12:27:50.051: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:27:50.052
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:50.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:50.078
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 11/12/22 12:27:50.087
    Nov 12 12:27:50.101: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e" in namespace "projected-1456" to be "Succeeded or Failed"
    Nov 12 12:27:50.107: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.180954ms
    Nov 12 12:27:52.114: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012459209s
    Nov 12 12:27:54.115: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013940596s
    STEP: Saw pod success 11/12/22 12:27:54.115
    Nov 12 12:27:54.115: INFO: Pod "downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e" satisfied condition "Succeeded or Failed"
    Nov 12 12:27:54.120: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e container client-container: <nil>
    STEP: delete the pod 11/12/22 12:27:54.129
    Nov 12 12:27:54.148: INFO: Waiting for pod downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e to disappear
    Nov 12 12:27:54.152: INFO: Pod downwardapi-volume-77cce6a1-c43e-4efe-911f-ce56a3bd153e no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 12:27:54.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1456" for this suite. 11/12/22 12:27:54.158
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:54.168
Nov 12 12:27:54.168: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:27:54.169
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:54.188
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:54.191
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-2cef01fc-40ec-4567-8deb-3dcd81653986 11/12/22 12:27:54.194
STEP: Creating secret with name secret-projected-all-test-volume-cfafcc98-b9f1-4740-ac7f-8c4f0317b37d 11/12/22 12:27:54.204
STEP: Creating a pod to test Check all projections for projected volume plugin 11/12/22 12:27:54.211
Nov 12 12:27:54.226: INFO: Waiting up to 5m0s for pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf" in namespace "projected-8990" to be "Succeeded or Failed"
Nov 12 12:27:54.230: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.315623ms
Nov 12 12:27:56.237: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010882587s
Nov 12 12:27:58.236: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010091087s
STEP: Saw pod success 11/12/22 12:27:58.236
Nov 12 12:27:58.236: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf" satisfied condition "Succeeded or Failed"
Nov 12 12:27:58.242: INFO: Trying to get logs from node ip-172-31-14-110 pod projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf container projected-all-volume-test: <nil>
STEP: delete the pod 11/12/22 12:27:58.25
Nov 12 12:27:58.265: INFO: Waiting for pod projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf to disappear
Nov 12 12:27:58.270: INFO: Pod projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Nov 12 12:27:58.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8990" for this suite. 11/12/22 12:27:58.28
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":139,"skipped":2573,"failed":0}
------------------------------
• [4.124 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:54.168
    Nov 12 12:27:54.168: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:27:54.169
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:54.188
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:54.191
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-2cef01fc-40ec-4567-8deb-3dcd81653986 11/12/22 12:27:54.194
    STEP: Creating secret with name secret-projected-all-test-volume-cfafcc98-b9f1-4740-ac7f-8c4f0317b37d 11/12/22 12:27:54.204
    STEP: Creating a pod to test Check all projections for projected volume plugin 11/12/22 12:27:54.211
    Nov 12 12:27:54.226: INFO: Waiting up to 5m0s for pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf" in namespace "projected-8990" to be "Succeeded or Failed"
    Nov 12 12:27:54.230: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.315623ms
    Nov 12 12:27:56.237: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010882587s
    Nov 12 12:27:58.236: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010091087s
    STEP: Saw pod success 11/12/22 12:27:58.236
    Nov 12 12:27:58.236: INFO: Pod "projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf" satisfied condition "Succeeded or Failed"
    Nov 12 12:27:58.242: INFO: Trying to get logs from node ip-172-31-14-110 pod projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf container projected-all-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:27:58.25
    Nov 12 12:27:58.265: INFO: Waiting for pod projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf to disappear
    Nov 12 12:27:58.270: INFO: Pod projected-volume-ddee39c7-b10b-4ba0-8e8c-c7f150d16bcf no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Nov 12 12:27:58.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8990" for this suite. 11/12/22 12:27:58.28
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:27:58.293
Nov 12 12:27:58.293: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:27:58.294
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:58.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:58.321
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-7323 11/12/22 12:27:58.324
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[] 11/12/22 12:27:58.346
Nov 12 12:27:58.353: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Nov 12 12:27:59.368: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-7323 11/12/22 12:27:59.369
Nov 12 12:27:59.382: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7323" to be "running and ready"
Nov 12 12:27:59.394: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.929393ms
Nov 12 12:27:59.394: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:28:01.401: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019197916s
Nov 12 12:28:01.401: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 12 12:28:01.401: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[pod1:[100]] 11/12/22 12:28:01.406
Nov 12 12:28:01.423: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-7323 11/12/22 12:28:01.423
Nov 12 12:28:01.434: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7323" to be "running and ready"
Nov 12 12:28:01.445: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.703279ms
Nov 12 12:28:01.445: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:28:03.451: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.01707009s
Nov 12 12:28:03.451: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 12 12:28:03.451: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[pod1:[100] pod2:[101]] 11/12/22 12:28:03.457
Nov 12 12:28:03.476: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 11/12/22 12:28:03.476
Nov 12 12:28:03.477: INFO: Creating new exec pod
Nov 12 12:28:03.483: INFO: Waiting up to 5m0s for pod "execpodd9bmn" in namespace "services-7323" to be "running"
Nov 12 12:28:03.488: INFO: Pod "execpodd9bmn": Phase="Pending", Reason="", readiness=false. Elapsed: 5.229446ms
Nov 12 12:28:05.494: INFO: Pod "execpodd9bmn": Phase="Running", Reason="", readiness=true. Elapsed: 2.010389885s
Nov 12 12:28:05.494: INFO: Pod "execpodd9bmn" satisfied condition "running"
Nov 12 12:28:06.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Nov 12 12:28:06.652: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Nov 12 12:28:06.653: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:28:06.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.53 80'
Nov 12 12:28:06.835: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 10.152.183.53 80\nConnection to 10.152.183.53 80 port [tcp/http] succeeded!\n"
Nov 12 12:28:06.835: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:28:06.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Nov 12 12:28:06.992: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Nov 12 12:28:06.992: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:28:06.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.53 81'
Nov 12 12:28:07.151: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 10.152.183.53 81\nConnection to 10.152.183.53 81 port [tcp/*] succeeded!\n"
Nov 12 12:28:07.151: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-7323 11/12/22 12:28:07.151
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[pod2:[101]] 11/12/22 12:28:07.179
Nov 12 12:28:07.201: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-7323 11/12/22 12:28:07.201
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[] 11/12/22 12:28:07.219
Nov 12 12:28:07.238: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:28:07.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7323" for this suite. 11/12/22 12:28:07.321
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":140,"skipped":2583,"failed":0}
------------------------------
• [SLOW TEST] [9.038 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:27:58.293
    Nov 12 12:27:58.293: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:27:58.294
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:27:58.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:27:58.321
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-7323 11/12/22 12:27:58.324
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[] 11/12/22 12:27:58.346
    Nov 12 12:27:58.353: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Nov 12 12:27:59.368: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-7323 11/12/22 12:27:59.369
    Nov 12 12:27:59.382: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7323" to be "running and ready"
    Nov 12 12:27:59.394: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 11.929393ms
    Nov 12 12:27:59.394: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:28:01.401: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019197916s
    Nov 12 12:28:01.401: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 12 12:28:01.401: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[pod1:[100]] 11/12/22 12:28:01.406
    Nov 12 12:28:01.423: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-7323 11/12/22 12:28:01.423
    Nov 12 12:28:01.434: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7323" to be "running and ready"
    Nov 12 12:28:01.445: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.703279ms
    Nov 12 12:28:01.445: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:28:03.451: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.01707009s
    Nov 12 12:28:03.451: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 12 12:28:03.451: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[pod1:[100] pod2:[101]] 11/12/22 12:28:03.457
    Nov 12 12:28:03.476: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 11/12/22 12:28:03.476
    Nov 12 12:28:03.477: INFO: Creating new exec pod
    Nov 12 12:28:03.483: INFO: Waiting up to 5m0s for pod "execpodd9bmn" in namespace "services-7323" to be "running"
    Nov 12 12:28:03.488: INFO: Pod "execpodd9bmn": Phase="Pending", Reason="", readiness=false. Elapsed: 5.229446ms
    Nov 12 12:28:05.494: INFO: Pod "execpodd9bmn": Phase="Running", Reason="", readiness=true. Elapsed: 2.010389885s
    Nov 12 12:28:05.494: INFO: Pod "execpodd9bmn" satisfied condition "running"
    Nov 12 12:28:06.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Nov 12 12:28:06.652: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Nov 12 12:28:06.653: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:28:06.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.53 80'
    Nov 12 12:28:06.835: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 10.152.183.53 80\nConnection to 10.152.183.53 80 port [tcp/http] succeeded!\n"
    Nov 12 12:28:06.835: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:28:06.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Nov 12 12:28:06.992: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Nov 12 12:28:06.992: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:28:06.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7323 exec execpodd9bmn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.53 81'
    Nov 12 12:28:07.151: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 10.152.183.53 81\nConnection to 10.152.183.53 81 port [tcp/*] succeeded!\n"
    Nov 12 12:28:07.151: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-7323 11/12/22 12:28:07.151
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[pod2:[101]] 11/12/22 12:28:07.179
    Nov 12 12:28:07.201: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-7323 11/12/22 12:28:07.201
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7323 to expose endpoints map[] 11/12/22 12:28:07.219
    Nov 12 12:28:07.238: INFO: successfully validated that service multi-endpoint-test in namespace services-7323 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:28:07.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7323" for this suite. 11/12/22 12:28:07.321
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:28:07.332
Nov 12 12:28:07.332: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 12:28:07.332
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:28:07.355
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:28:07.364
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced in namespace container-probe-6732 11/12/22 12:28:07.368
Nov 12 12:28:07.391: INFO: Waiting up to 5m0s for pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced" in namespace "container-probe-6732" to be "not pending"
Nov 12 12:28:07.404: INFO: Pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced": Phase="Pending", Reason="", readiness=false. Elapsed: 13.079128ms
Nov 12 12:28:09.409: INFO: Pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced": Phase="Running", Reason="", readiness=true. Elapsed: 2.018366127s
Nov 12 12:28:09.409: INFO: Pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced" satisfied condition "not pending"
Nov 12 12:28:09.409: INFO: Started pod busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced in namespace container-probe-6732
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:28:09.409
Nov 12 12:28:09.420: INFO: Initial restart count of pod busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced is 0
Nov 12 12:28:59.631: INFO: Restart count of pod container-probe-6732/busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced is now 1 (50.21066711s elapsed)
STEP: deleting the pod 11/12/22 12:28:59.631
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 12:28:59.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6732" for this suite. 11/12/22 12:28:59.654
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":141,"skipped":2585,"failed":0}
------------------------------
• [SLOW TEST] [52.331 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:28:07.332
    Nov 12 12:28:07.332: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 12:28:07.332
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:28:07.355
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:28:07.364
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced in namespace container-probe-6732 11/12/22 12:28:07.368
    Nov 12 12:28:07.391: INFO: Waiting up to 5m0s for pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced" in namespace "container-probe-6732" to be "not pending"
    Nov 12 12:28:07.404: INFO: Pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced": Phase="Pending", Reason="", readiness=false. Elapsed: 13.079128ms
    Nov 12 12:28:09.409: INFO: Pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced": Phase="Running", Reason="", readiness=true. Elapsed: 2.018366127s
    Nov 12 12:28:09.409: INFO: Pod "busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced" satisfied condition "not pending"
    Nov 12 12:28:09.409: INFO: Started pod busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced in namespace container-probe-6732
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:28:09.409
    Nov 12 12:28:09.420: INFO: Initial restart count of pod busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced is 0
    Nov 12 12:28:59.631: INFO: Restart count of pod container-probe-6732/busybox-7066f80b-2d34-4d49-a8bc-5f08a6525ced is now 1 (50.21066711s elapsed)
    STEP: deleting the pod 11/12/22 12:28:59.631
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 12:28:59.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6732" for this suite. 11/12/22 12:28:59.654
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:28:59.663
Nov 12 12:28:59.664: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 12:28:59.667
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:28:59.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:28:59.694
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Nov 12 12:28:59.699: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: creating the pod 11/12/22 12:28:59.7
STEP: submitting the pod to kubernetes 11/12/22 12:28:59.7
Nov 12 12:28:59.731: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520" in namespace "pods-5547" to be "running and ready"
Nov 12 12:28:59.741: INFO: Pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520": Phase="Pending", Reason="", readiness=false. Elapsed: 10.562772ms
Nov 12 12:28:59.741: INFO: The phase of Pod pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:29:01.748: INFO: Pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520": Phase="Running", Reason="", readiness=true. Elapsed: 2.017112868s
Nov 12 12:29:01.748: INFO: The phase of Pod pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520 is Running (Ready = true)
Nov 12 12:29:01.748: INFO: Pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 12:29:01.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5547" for this suite. 11/12/22 12:29:01.781
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":142,"skipped":2585,"failed":0}
------------------------------
• [2.129 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:28:59.663
    Nov 12 12:28:59.664: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 12:28:59.667
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:28:59.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:28:59.694
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Nov 12 12:28:59.699: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: creating the pod 11/12/22 12:28:59.7
    STEP: submitting the pod to kubernetes 11/12/22 12:28:59.7
    Nov 12 12:28:59.731: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520" in namespace "pods-5547" to be "running and ready"
    Nov 12 12:28:59.741: INFO: Pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520": Phase="Pending", Reason="", readiness=false. Elapsed: 10.562772ms
    Nov 12 12:28:59.741: INFO: The phase of Pod pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:29:01.748: INFO: Pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520": Phase="Running", Reason="", readiness=true. Elapsed: 2.017112868s
    Nov 12 12:29:01.748: INFO: The phase of Pod pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520 is Running (Ready = true)
    Nov 12 12:29:01.748: INFO: Pod "pod-logs-websocket-5fd4517b-e1e1-4d25-8c87-d6899a76d520" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 12:29:01.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5547" for this suite. 11/12/22 12:29:01.781
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:29:01.793
Nov 12 12:29:01.793: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:29:01.794
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:01.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:01.817
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 12:29:01.821
Nov 12 12:29:01.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5898 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 12 12:29:01.924: INFO: stderr: ""
Nov 12 12:29:01.924: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 11/12/22 12:29:01.924
Nov 12 12:29:01.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5898 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Nov 12 12:29:02.862: INFO: stderr: ""
Nov 12 12:29:02.862: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 12:29:02.862
Nov 12 12:29:02.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5898 delete pods e2e-test-httpd-pod'
Nov 12 12:29:04.249: INFO: stderr: ""
Nov 12 12:29:04.249: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:29:04.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5898" for this suite. 11/12/22 12:29:04.255
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":143,"skipped":2597,"failed":0}
------------------------------
• [2.472 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:29:01.793
    Nov 12 12:29:01.793: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:29:01.794
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:01.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:01.817
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 12:29:01.821
    Nov 12 12:29:01.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5898 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 12 12:29:01.924: INFO: stderr: ""
    Nov 12 12:29:01.924: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 11/12/22 12:29:01.924
    Nov 12 12:29:01.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5898 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Nov 12 12:29:02.862: INFO: stderr: ""
    Nov 12 12:29:02.862: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 12:29:02.862
    Nov 12 12:29:02.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5898 delete pods e2e-test-httpd-pod'
    Nov 12 12:29:04.249: INFO: stderr: ""
    Nov 12 12:29:04.249: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:29:04.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5898" for this suite. 11/12/22 12:29:04.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:29:04.266
Nov 12 12:29:04.266: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:29:04.267
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:04.289
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:04.293
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:29:04.335
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:29:04.632
STEP: Deploying the webhook pod 11/12/22 12:29:04.644
STEP: Wait for the deployment to be ready 11/12/22 12:29:04.665
Nov 12 12:29:04.699: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:29:06.716
STEP: Verifying the service has paired with the endpoint 11/12/22 12:29:06.73
Nov 12 12:29:07.730: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 11/12/22 12:29:07.736
STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 12:29:07.751
STEP: Updating a validating webhook configuration's rules to not include the create operation 11/12/22 12:29:07.759
STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 12:29:07.773
STEP: Patching a validating webhook configuration's rules to include the create operation 11/12/22 12:29:07.787
STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 12:29:07.795
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:29:07.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2794" for this suite. 11/12/22 12:29:07.812
STEP: Destroying namespace "webhook-2794-markers" for this suite. 11/12/22 12:29:07.821
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":144,"skipped":2603,"failed":0}
------------------------------
• [3.648 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:29:04.266
    Nov 12 12:29:04.266: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:29:04.267
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:04.289
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:04.293
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:29:04.335
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:29:04.632
    STEP: Deploying the webhook pod 11/12/22 12:29:04.644
    STEP: Wait for the deployment to be ready 11/12/22 12:29:04.665
    Nov 12 12:29:04.699: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:29:06.716
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:29:06.73
    Nov 12 12:29:07.730: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 11/12/22 12:29:07.736
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 12:29:07.751
    STEP: Updating a validating webhook configuration's rules to not include the create operation 11/12/22 12:29:07.759
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 12:29:07.773
    STEP: Patching a validating webhook configuration's rules to include the create operation 11/12/22 12:29:07.787
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 12:29:07.795
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:29:07.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2794" for this suite. 11/12/22 12:29:07.812
    STEP: Destroying namespace "webhook-2794-markers" for this suite. 11/12/22 12:29:07.821
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:29:07.914
Nov 12 12:29:07.914: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename podtemplate 11/12/22 12:29:07.915
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:07.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:07.992
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 11/12/22 12:29:07.995
Nov 12 12:29:08.001: INFO: created test-podtemplate-1
Nov 12 12:29:08.007: INFO: created test-podtemplate-2
Nov 12 12:29:08.014: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 11/12/22 12:29:08.014
STEP: delete collection of pod templates 11/12/22 12:29:08.019
Nov 12 12:29:08.019: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 11/12/22 12:29:08.045
Nov 12 12:29:08.046: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 12 12:29:08.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-649" for this suite. 11/12/22 12:29:08.063
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":145,"skipped":2610,"failed":0}
------------------------------
• [0.161 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:29:07.914
    Nov 12 12:29:07.914: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename podtemplate 11/12/22 12:29:07.915
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:07.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:07.992
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 11/12/22 12:29:07.995
    Nov 12 12:29:08.001: INFO: created test-podtemplate-1
    Nov 12 12:29:08.007: INFO: created test-podtemplate-2
    Nov 12 12:29:08.014: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 11/12/22 12:29:08.014
    STEP: delete collection of pod templates 11/12/22 12:29:08.019
    Nov 12 12:29:08.019: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 11/12/22 12:29:08.045
    Nov 12 12:29:08.046: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 12 12:29:08.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-649" for this suite. 11/12/22 12:29:08.063
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:29:08.076
Nov 12 12:29:08.076: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename job 11/12/22 12:29:08.077
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:08.097
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:08.103
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 11/12/22 12:29:08.106
STEP: Ensure pods equal to paralellism count is attached to the job 11/12/22 12:29:08.116
STEP: patching /status 11/12/22 12:29:12.123
STEP: updating /status 11/12/22 12:29:12.129
STEP: get /status 11/12/22 12:29:12.141
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 12 12:29:12.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1514" for this suite. 11/12/22 12:29:12.15
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":146,"skipped":2624,"failed":0}
------------------------------
• [4.082 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:29:08.076
    Nov 12 12:29:08.076: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename job 11/12/22 12:29:08.077
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:08.097
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:08.103
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 11/12/22 12:29:08.106
    STEP: Ensure pods equal to paralellism count is attached to the job 11/12/22 12:29:08.116
    STEP: patching /status 11/12/22 12:29:12.123
    STEP: updating /status 11/12/22 12:29:12.129
    STEP: get /status 11/12/22 12:29:12.141
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 12 12:29:12.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1514" for this suite. 11/12/22 12:29:12.15
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:29:12.161
Nov 12 12:29:12.161: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-preemption 11/12/22 12:29:12.162
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:12.178
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:12.182
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 12 12:29:12.205: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 12:30:12.228: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 11/12/22 12:30:12.232
Nov 12 12:30:12.260: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 12 12:30:12.266: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 12 12:30:12.289: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 12 12:30:12.303: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 12 12:30:12.325: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 12 12:30:12.338: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/12/22 12:30:12.338
Nov 12 12:30:12.338: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7463" to be "running"
Nov 12 12:30:12.346: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.078146ms
Nov 12 12:30:14.351: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012781203s
Nov 12 12:30:16.354: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016116923s
Nov 12 12:30:18.354: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.01606404s
Nov 12 12:30:18.354: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 12 12:30:18.354: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
Nov 12 12:30:18.360: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.759408ms
Nov 12 12:30:18.360: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 12:30:18.360: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
Nov 12 12:30:18.364: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884427ms
Nov 12 12:30:20.371: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.010591913s
Nov 12 12:30:20.371: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 12:30:20.371: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
Nov 12 12:30:20.375: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.453194ms
Nov 12 12:30:22.381: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.010273147s
Nov 12 12:30:22.381: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 12:30:22.381: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
Nov 12 12:30:22.386: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.172261ms
Nov 12 12:30:22.386: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 12:30:22.386: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
Nov 12 12:30:22.390: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.055132ms
Nov 12 12:30:22.390: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/12/22 12:30:22.39
Nov 12 12:30:22.400: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7463" to be "running"
Nov 12 12:30:22.405: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.448841ms
Nov 12 12:30:24.410: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009949017s
Nov 12 12:30:26.410: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009416728s
Nov 12 12:30:26.410: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:30:26.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-7463" for this suite. 11/12/22 12:30:26.447
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":147,"skipped":2664,"failed":0}
------------------------------
• [SLOW TEST] [74.349 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:29:12.161
    Nov 12 12:29:12.161: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-preemption 11/12/22 12:29:12.162
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:29:12.178
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:29:12.182
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 12 12:29:12.205: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 12:30:12.228: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 11/12/22 12:30:12.232
    Nov 12 12:30:12.260: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 12 12:30:12.266: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 12 12:30:12.289: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 12 12:30:12.303: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 12 12:30:12.325: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 12 12:30:12.338: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/12/22 12:30:12.338
    Nov 12 12:30:12.338: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-7463" to be "running"
    Nov 12 12:30:12.346: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.078146ms
    Nov 12 12:30:14.351: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012781203s
    Nov 12 12:30:16.354: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016116923s
    Nov 12 12:30:18.354: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.01606404s
    Nov 12 12:30:18.354: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 12 12:30:18.354: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
    Nov 12 12:30:18.360: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.759408ms
    Nov 12 12:30:18.360: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 12:30:18.360: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
    Nov 12 12:30:18.364: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 3.884427ms
    Nov 12 12:30:20.371: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.010591913s
    Nov 12 12:30:20.371: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 12:30:20.371: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
    Nov 12 12:30:20.375: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.453194ms
    Nov 12 12:30:22.381: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.010273147s
    Nov 12 12:30:22.381: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 12:30:22.381: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
    Nov 12 12:30:22.386: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.172261ms
    Nov 12 12:30:22.386: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 12:30:22.386: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-7463" to be "running"
    Nov 12 12:30:22.390: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.055132ms
    Nov 12 12:30:22.390: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/12/22 12:30:22.39
    Nov 12 12:30:22.400: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-7463" to be "running"
    Nov 12 12:30:22.405: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.448841ms
    Nov 12 12:30:24.410: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009949017s
    Nov 12 12:30:26.410: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.009416728s
    Nov 12 12:30:26.410: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:30:26.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-7463" for this suite. 11/12/22 12:30:26.447
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:30:26.511
Nov 12 12:30:26.511: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:30:26.512
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:30:26.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:30:26.539
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 11/12/22 12:30:26.542
Nov 12 12:30:26.557: INFO: Waiting up to 5m0s for pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967" in namespace "emptydir-3026" to be "Succeeded or Failed"
Nov 12 12:30:26.564: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967": Phase="Pending", Reason="", readiness=false. Elapsed: 6.764904ms
Nov 12 12:30:28.569: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011901872s
Nov 12 12:30:30.570: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012633226s
STEP: Saw pod success 11/12/22 12:30:30.57
Nov 12 12:30:30.570: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967" satisfied condition "Succeeded or Failed"
Nov 12 12:30:30.576: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-2fb01854-5eb8-481f-907f-cdd844e5e967 container test-container: <nil>
STEP: delete the pod 11/12/22 12:30:30.593
Nov 12 12:30:30.610: INFO: Waiting for pod pod-2fb01854-5eb8-481f-907f-cdd844e5e967 to disappear
Nov 12 12:30:30.613: INFO: Pod pod-2fb01854-5eb8-481f-907f-cdd844e5e967 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:30:30.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3026" for this suite. 11/12/22 12:30:30.619
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":148,"skipped":2668,"failed":0}
------------------------------
• [4.117 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:30:26.511
    Nov 12 12:30:26.511: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:30:26.512
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:30:26.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:30:26.539
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/12/22 12:30:26.542
    Nov 12 12:30:26.557: INFO: Waiting up to 5m0s for pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967" in namespace "emptydir-3026" to be "Succeeded or Failed"
    Nov 12 12:30:26.564: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967": Phase="Pending", Reason="", readiness=false. Elapsed: 6.764904ms
    Nov 12 12:30:28.569: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011901872s
    Nov 12 12:30:30.570: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012633226s
    STEP: Saw pod success 11/12/22 12:30:30.57
    Nov 12 12:30:30.570: INFO: Pod "pod-2fb01854-5eb8-481f-907f-cdd844e5e967" satisfied condition "Succeeded or Failed"
    Nov 12 12:30:30.576: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-2fb01854-5eb8-481f-907f-cdd844e5e967 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:30:30.593
    Nov 12 12:30:30.610: INFO: Waiting for pod pod-2fb01854-5eb8-481f-907f-cdd844e5e967 to disappear
    Nov 12 12:30:30.613: INFO: Pod pod-2fb01854-5eb8-481f-907f-cdd844e5e967 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:30:30.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3026" for this suite. 11/12/22 12:30:30.619
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:30:30.643
Nov 12 12:30:30.643: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename controllerrevisions 11/12/22 12:30:30.645
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:30:30.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:30:30.676
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-btdcw-daemon-set" 11/12/22 12:30:30.703
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:30:30.71
Nov 12 12:30:30.716: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:30:30.716: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:30:30.721: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 0
Nov 12 12:30:30.721: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:30:31.727: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:30:31.727: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:30:31.731: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 0
Nov 12 12:30:31.732: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:30:32.731: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:30:32.731: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:30:32.738: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 3
Nov 12 12:30:32.738: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-btdcw-daemon-set
STEP: Confirm DaemonSet "e2e-btdcw-daemon-set" successfully created with "daemonset-name=e2e-btdcw-daemon-set" label 11/12/22 12:30:32.742
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-btdcw-daemon-set" 11/12/22 12:30:32.757
Nov 12 12:30:32.763: INFO: Located ControllerRevision: "e2e-btdcw-daemon-set-558d44f4cf"
STEP: Patching ControllerRevision "e2e-btdcw-daemon-set-558d44f4cf" 11/12/22 12:30:32.769
Nov 12 12:30:32.777: INFO: e2e-btdcw-daemon-set-558d44f4cf has been patched
STEP: Create a new ControllerRevision 11/12/22 12:30:32.777
Nov 12 12:30:32.786: INFO: Created ControllerRevision: e2e-btdcw-daemon-set-6889b69cc9
STEP: Confirm that there are two ControllerRevisions 11/12/22 12:30:32.786
Nov 12 12:30:32.786: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 12:30:32.792: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-btdcw-daemon-set-558d44f4cf" 11/12/22 12:30:32.792
STEP: Confirm that there is only one ControllerRevision 11/12/22 12:30:32.803
Nov 12 12:30:32.803: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 12:30:32.808: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-btdcw-daemon-set-6889b69cc9" 11/12/22 12:30:32.812
Nov 12 12:30:32.823: INFO: e2e-btdcw-daemon-set-6889b69cc9 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 11/12/22 12:30:32.823
W1112 12:30:32.837364      19 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 11/12/22 12:30:32.837
Nov 12 12:30:32.837: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 12:30:33.844: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 12:30:33.849: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-btdcw-daemon-set-6889b69cc9=updated" 11/12/22 12:30:33.85
STEP: Confirm that there is only one ControllerRevision 11/12/22 12:30:33.861
Nov 12 12:30:33.861: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 12 12:30:33.864: INFO: Found 1 ControllerRevisions
Nov 12 12:30:33.868: INFO: ControllerRevision "e2e-btdcw-daemon-set-9b988f4c4" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-btdcw-daemon-set" 11/12/22 12:30:33.872
STEP: deleting DaemonSet.extensions e2e-btdcw-daemon-set in namespace controllerrevisions-9015, will wait for the garbage collector to delete the pods 11/12/22 12:30:33.872
Nov 12 12:30:33.936: INFO: Deleting DaemonSet.extensions e2e-btdcw-daemon-set took: 10.032272ms
Nov 12 12:30:34.037: INFO: Terminating DaemonSet.extensions e2e-btdcw-daemon-set pods took: 100.490695ms
Nov 12 12:30:35.549: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 0
Nov 12 12:30:35.549: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-btdcw-daemon-set
Nov 12 12:30:35.554: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17949"},"items":null}

Nov 12 12:30:35.560: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17949"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:30:35.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-9015" for this suite. 11/12/22 12:30:35.591
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":149,"skipped":2669,"failed":0}
------------------------------
• [4.958 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:30:30.643
    Nov 12 12:30:30.643: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename controllerrevisions 11/12/22 12:30:30.645
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:30:30.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:30:30.676
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-btdcw-daemon-set" 11/12/22 12:30:30.703
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:30:30.71
    Nov 12 12:30:30.716: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:30:30.716: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:30:30.721: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 0
    Nov 12 12:30:30.721: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:30:31.727: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:30:31.727: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:30:31.731: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 0
    Nov 12 12:30:31.732: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:30:32.731: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:30:32.731: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:30:32.738: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 3
    Nov 12 12:30:32.738: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-btdcw-daemon-set
    STEP: Confirm DaemonSet "e2e-btdcw-daemon-set" successfully created with "daemonset-name=e2e-btdcw-daemon-set" label 11/12/22 12:30:32.742
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-btdcw-daemon-set" 11/12/22 12:30:32.757
    Nov 12 12:30:32.763: INFO: Located ControllerRevision: "e2e-btdcw-daemon-set-558d44f4cf"
    STEP: Patching ControllerRevision "e2e-btdcw-daemon-set-558d44f4cf" 11/12/22 12:30:32.769
    Nov 12 12:30:32.777: INFO: e2e-btdcw-daemon-set-558d44f4cf has been patched
    STEP: Create a new ControllerRevision 11/12/22 12:30:32.777
    Nov 12 12:30:32.786: INFO: Created ControllerRevision: e2e-btdcw-daemon-set-6889b69cc9
    STEP: Confirm that there are two ControllerRevisions 11/12/22 12:30:32.786
    Nov 12 12:30:32.786: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 12:30:32.792: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-btdcw-daemon-set-558d44f4cf" 11/12/22 12:30:32.792
    STEP: Confirm that there is only one ControllerRevision 11/12/22 12:30:32.803
    Nov 12 12:30:32.803: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 12:30:32.808: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-btdcw-daemon-set-6889b69cc9" 11/12/22 12:30:32.812
    Nov 12 12:30:32.823: INFO: e2e-btdcw-daemon-set-6889b69cc9 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 11/12/22 12:30:32.823
    W1112 12:30:32.837364      19 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 11/12/22 12:30:32.837
    Nov 12 12:30:32.837: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 12:30:33.844: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 12:30:33.849: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-btdcw-daemon-set-6889b69cc9=updated" 11/12/22 12:30:33.85
    STEP: Confirm that there is only one ControllerRevision 11/12/22 12:30:33.861
    Nov 12 12:30:33.861: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 12 12:30:33.864: INFO: Found 1 ControllerRevisions
    Nov 12 12:30:33.868: INFO: ControllerRevision "e2e-btdcw-daemon-set-9b988f4c4" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-btdcw-daemon-set" 11/12/22 12:30:33.872
    STEP: deleting DaemonSet.extensions e2e-btdcw-daemon-set in namespace controllerrevisions-9015, will wait for the garbage collector to delete the pods 11/12/22 12:30:33.872
    Nov 12 12:30:33.936: INFO: Deleting DaemonSet.extensions e2e-btdcw-daemon-set took: 10.032272ms
    Nov 12 12:30:34.037: INFO: Terminating DaemonSet.extensions e2e-btdcw-daemon-set pods took: 100.490695ms
    Nov 12 12:30:35.549: INFO: Number of nodes with available pods controlled by daemonset e2e-btdcw-daemon-set: 0
    Nov 12 12:30:35.549: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-btdcw-daemon-set
    Nov 12 12:30:35.554: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17949"},"items":null}

    Nov 12 12:30:35.560: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17949"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:30:35.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-9015" for this suite. 11/12/22 12:30:35.591
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:30:35.602
Nov 12 12:30:35.602: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 12:30:35.603
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:30:35.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:30:35.63
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed in namespace container-probe-3609 11/12/22 12:30:35.632
Nov 12 12:30:35.655: INFO: Waiting up to 5m0s for pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed" in namespace "container-probe-3609" to be "not pending"
Nov 12 12:30:35.661: INFO: Pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed": Phase="Pending", Reason="", readiness=false. Elapsed: 5.966164ms
Nov 12 12:30:37.666: INFO: Pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed": Phase="Running", Reason="", readiness=true. Elapsed: 2.010867559s
Nov 12 12:30:37.666: INFO: Pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed" satisfied condition "not pending"
Nov 12 12:30:37.666: INFO: Started pod liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed in namespace container-probe-3609
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:30:37.666
Nov 12 12:30:37.671: INFO: Initial restart count of pod liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is 0
Nov 12 12:30:57.738: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 1 (20.066440756s elapsed)
Nov 12 12:31:17.795: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 2 (40.12375309s elapsed)
Nov 12 12:31:37.856: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 3 (1m0.184324004s elapsed)
Nov 12 12:31:57.915: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 4 (1m20.243318641s elapsed)
Nov 12 12:33:02.117: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 5 (2m24.445616367s elapsed)
STEP: deleting the pod 11/12/22 12:33:02.117
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 12:33:02.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3609" for this suite. 11/12/22 12:33:02.141
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":150,"skipped":2673,"failed":0}
------------------------------
• [SLOW TEST] [146.549 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:30:35.602
    Nov 12 12:30:35.602: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 12:30:35.603
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:30:35.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:30:35.63
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed in namespace container-probe-3609 11/12/22 12:30:35.632
    Nov 12 12:30:35.655: INFO: Waiting up to 5m0s for pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed" in namespace "container-probe-3609" to be "not pending"
    Nov 12 12:30:35.661: INFO: Pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed": Phase="Pending", Reason="", readiness=false. Elapsed: 5.966164ms
    Nov 12 12:30:37.666: INFO: Pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed": Phase="Running", Reason="", readiness=true. Elapsed: 2.010867559s
    Nov 12 12:30:37.666: INFO: Pod "liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed" satisfied condition "not pending"
    Nov 12 12:30:37.666: INFO: Started pod liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed in namespace container-probe-3609
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:30:37.666
    Nov 12 12:30:37.671: INFO: Initial restart count of pod liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is 0
    Nov 12 12:30:57.738: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 1 (20.066440756s elapsed)
    Nov 12 12:31:17.795: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 2 (40.12375309s elapsed)
    Nov 12 12:31:37.856: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 3 (1m0.184324004s elapsed)
    Nov 12 12:31:57.915: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 4 (1m20.243318641s elapsed)
    Nov 12 12:33:02.117: INFO: Restart count of pod container-probe-3609/liveness-0c4c2fe1-bd44-42ed-9ba9-f3d851af3fed is now 5 (2m24.445616367s elapsed)
    STEP: deleting the pod 11/12/22 12:33:02.117
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 12:33:02.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3609" for this suite. 11/12/22 12:33:02.141
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:33:02.151
Nov 12 12:33:02.151: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename runtimeclass 11/12/22 12:33:02.152
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:02.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:02.183
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-5028-delete-me 11/12/22 12:33:02.194
STEP: Waiting for the RuntimeClass to disappear 11/12/22 12:33:02.203
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 12:33:02.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-5028" for this suite. 11/12/22 12:33:02.228
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":151,"skipped":2674,"failed":0}
------------------------------
• [0.089 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:33:02.151
    Nov 12 12:33:02.151: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 12:33:02.152
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:02.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:02.183
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-5028-delete-me 11/12/22 12:33:02.194
    STEP: Waiting for the RuntimeClass to disappear 11/12/22 12:33:02.203
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 12:33:02.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-5028" for this suite. 11/12/22 12:33:02.228
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:33:02.242
Nov 12 12:33:02.242: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:33:02.243
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:02.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:02.274
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:33:02.313
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:33:02.925
STEP: Deploying the webhook pod 11/12/22 12:33:02.94
STEP: Wait for the deployment to be ready 11/12/22 12:33:02.963
Nov 12 12:33:02.976: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:33:04.992
STEP: Verifying the service has paired with the endpoint 11/12/22 12:33:05.009
Nov 12 12:33:06.010: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/12/22 12:33:06.015
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:06.015
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/12/22 12:33:06.033
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/12/22 12:33:07.051
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:07.051
STEP: Having no error when timeout is longer than webhook latency 11/12/22 12:33:08.088
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:08.088
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/12/22 12:33:13.131
STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:13.131
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:33:18.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-905" for this suite. 11/12/22 12:33:18.183
STEP: Destroying namespace "webhook-905-markers" for this suite. 11/12/22 12:33:18.199
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":152,"skipped":2676,"failed":0}
------------------------------
• [SLOW TEST] [16.065 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:33:02.242
    Nov 12 12:33:02.242: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:33:02.243
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:02.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:02.274
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:33:02.313
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:33:02.925
    STEP: Deploying the webhook pod 11/12/22 12:33:02.94
    STEP: Wait for the deployment to be ready 11/12/22 12:33:02.963
    Nov 12 12:33:02.976: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:33:04.992
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:33:05.009
    Nov 12 12:33:06.010: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/12/22 12:33:06.015
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:06.015
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/12/22 12:33:06.033
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/12/22 12:33:07.051
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:07.051
    STEP: Having no error when timeout is longer than webhook latency 11/12/22 12:33:08.088
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:08.088
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/12/22 12:33:13.131
    STEP: Registering slow webhook via the AdmissionRegistration API 11/12/22 12:33:13.131
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:33:18.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-905" for this suite. 11/12/22 12:33:18.183
    STEP: Destroying namespace "webhook-905-markers" for this suite. 11/12/22 12:33:18.199
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:33:18.312
Nov 12 12:33:18.312: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:33:18.315
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:18.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:18.351
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:33:18.365
Nov 12 12:33:18.383: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8360" to be "running and ready"
Nov 12 12:33:18.396: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.363901ms
Nov 12 12:33:18.397: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:33:20.403: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.019836467s
Nov 12 12:33:20.403: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 12 12:33:20.403: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 11/12/22 12:33:20.408
Nov 12 12:33:20.418: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8360" to be "running and ready"
Nov 12 12:33:20.425: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.360619ms
Nov 12 12:33:20.425: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:33:22.431: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013071683s
Nov 12 12:33:22.431: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Nov 12 12:33:22.431: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/12/22 12:33:22.436
Nov 12 12:33:22.448: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 12 12:33:22.454: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 12 12:33:24.454: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 12 12:33:24.460: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 12 12:33:26.454: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 12 12:33:26.462: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 11/12/22 12:33:26.462
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 12 12:33:26.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8360" for this suite. 11/12/22 12:33:26.485
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":153,"skipped":2712,"failed":0}
------------------------------
• [SLOW TEST] [8.184 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:33:18.312
    Nov 12 12:33:18.312: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:33:18.315
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:18.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:18.351
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:33:18.365
    Nov 12 12:33:18.383: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8360" to be "running and ready"
    Nov 12 12:33:18.396: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 12.363901ms
    Nov 12 12:33:18.397: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:33:20.403: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.019836467s
    Nov 12 12:33:20.403: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 12 12:33:20.403: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 11/12/22 12:33:20.408
    Nov 12 12:33:20.418: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8360" to be "running and ready"
    Nov 12 12:33:20.425: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.360619ms
    Nov 12 12:33:20.425: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:33:22.431: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013071683s
    Nov 12 12:33:22.431: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Nov 12 12:33:22.431: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/12/22 12:33:22.436
    Nov 12 12:33:22.448: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 12 12:33:22.454: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 12 12:33:24.454: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 12 12:33:24.460: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 12 12:33:26.454: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 12 12:33:26.462: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 11/12/22 12:33:26.462
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 12 12:33:26.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8360" for this suite. 11/12/22 12:33:26.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:33:26.5
Nov 12 12:33:26.500: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 12:33:26.501
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:26.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:26.547
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1124 11/12/22 12:33:26.554
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 11/12/22 12:33:26.575
Nov 12 12:33:26.598: INFO: Found 0 stateful pods, waiting for 3
Nov 12 12:33:36.603: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:33:36.603: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:33:36.603: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/12/22 12:33:36.618
Nov 12 12:33:36.644: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/12/22 12:33:36.644
STEP: Not applying an update when the partition is greater than the number of replicas 11/12/22 12:33:46.665
STEP: Performing a canary update 11/12/22 12:33:46.665
Nov 12 12:33:46.690: INFO: Updating stateful set ss2
Nov 12 12:33:46.704: INFO: Waiting for Pod statefulset-1124/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 11/12/22 12:33:56.714
Nov 12 12:33:56.762: INFO: Found 1 stateful pods, waiting for 3
Nov 12 12:34:06.769: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:34:06.769: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:34:06.769: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 11/12/22 12:34:06.777
Nov 12 12:34:06.804: INFO: Updating stateful set ss2
Nov 12 12:34:06.818: INFO: Waiting for Pod statefulset-1124/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov 12 12:34:16.851: INFO: Updating stateful set ss2
Nov 12 12:34:16.864: INFO: Waiting for StatefulSet statefulset-1124/ss2 to complete update
Nov 12 12:34:16.864: INFO: Waiting for Pod statefulset-1124/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 12:34:26.876: INFO: Deleting all statefulset in ns statefulset-1124
Nov 12 12:34:26.881: INFO: Scaling statefulset ss2 to 0
Nov 12 12:34:36.907: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:34:36.911: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 12:34:36.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1124" for this suite. 11/12/22 12:34:36.948
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":154,"skipped":2781,"failed":0}
------------------------------
• [SLOW TEST] [70.463 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:33:26.5
    Nov 12 12:33:26.500: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 12:33:26.501
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:33:26.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:33:26.547
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1124 11/12/22 12:33:26.554
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 11/12/22 12:33:26.575
    Nov 12 12:33:26.598: INFO: Found 0 stateful pods, waiting for 3
    Nov 12 12:33:36.603: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:33:36.603: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:33:36.603: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/12/22 12:33:36.618
    Nov 12 12:33:36.644: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/12/22 12:33:36.644
    STEP: Not applying an update when the partition is greater than the number of replicas 11/12/22 12:33:46.665
    STEP: Performing a canary update 11/12/22 12:33:46.665
    Nov 12 12:33:46.690: INFO: Updating stateful set ss2
    Nov 12 12:33:46.704: INFO: Waiting for Pod statefulset-1124/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 11/12/22 12:33:56.714
    Nov 12 12:33:56.762: INFO: Found 1 stateful pods, waiting for 3
    Nov 12 12:34:06.769: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:34:06.769: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:34:06.769: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 11/12/22 12:34:06.777
    Nov 12 12:34:06.804: INFO: Updating stateful set ss2
    Nov 12 12:34:06.818: INFO: Waiting for Pod statefulset-1124/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov 12 12:34:16.851: INFO: Updating stateful set ss2
    Nov 12 12:34:16.864: INFO: Waiting for StatefulSet statefulset-1124/ss2 to complete update
    Nov 12 12:34:16.864: INFO: Waiting for Pod statefulset-1124/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 12:34:26.876: INFO: Deleting all statefulset in ns statefulset-1124
    Nov 12 12:34:26.881: INFO: Scaling statefulset ss2 to 0
    Nov 12 12:34:36.907: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:34:36.911: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 12:34:36.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1124" for this suite. 11/12/22 12:34:36.948
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:34:36.965
Nov 12 12:34:36.965: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:34:36.966
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:34:36.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:34:36.99
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-646f4224-a177-400a-a025-3b898ba3cb8f 11/12/22 12:34:36.999
STEP: Creating secret with name s-test-opt-upd-ab461d94-574b-42c3-8abd-fef5acb45680 11/12/22 12:34:37.006
STEP: Creating the pod 11/12/22 12:34:37.014
Nov 12 12:34:37.027: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0" in namespace "projected-8342" to be "running and ready"
Nov 12 12:34:37.035: INFO: Pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.142151ms
Nov 12 12:34:37.035: INFO: The phase of Pod pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:34:39.041: INFO: Pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0": Phase="Running", Reason="", readiness=true. Elapsed: 2.013800305s
Nov 12 12:34:39.041: INFO: The phase of Pod pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0 is Running (Ready = true)
Nov 12 12:34:39.041: INFO: Pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-646f4224-a177-400a-a025-3b898ba3cb8f 11/12/22 12:34:39.08
STEP: Updating secret s-test-opt-upd-ab461d94-574b-42c3-8abd-fef5acb45680 11/12/22 12:34:39.089
STEP: Creating secret with name s-test-opt-create-fe8515b1-461e-42e8-881b-e1c32c91e1fd 11/12/22 12:34:39.096
STEP: waiting to observe update in volume 11/12/22 12:34:39.103
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 12:34:43.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8342" for this suite. 11/12/22 12:34:43.161
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":155,"skipped":2801,"failed":0}
------------------------------
• [SLOW TEST] [6.215 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:34:36.965
    Nov 12 12:34:36.965: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:34:36.966
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:34:36.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:34:36.99
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-646f4224-a177-400a-a025-3b898ba3cb8f 11/12/22 12:34:36.999
    STEP: Creating secret with name s-test-opt-upd-ab461d94-574b-42c3-8abd-fef5acb45680 11/12/22 12:34:37.006
    STEP: Creating the pod 11/12/22 12:34:37.014
    Nov 12 12:34:37.027: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0" in namespace "projected-8342" to be "running and ready"
    Nov 12 12:34:37.035: INFO: Pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.142151ms
    Nov 12 12:34:37.035: INFO: The phase of Pod pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:34:39.041: INFO: Pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0": Phase="Running", Reason="", readiness=true. Elapsed: 2.013800305s
    Nov 12 12:34:39.041: INFO: The phase of Pod pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0 is Running (Ready = true)
    Nov 12 12:34:39.041: INFO: Pod "pod-projected-secrets-68db756b-be49-4dd5-8ab3-2fb02971e0e0" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-646f4224-a177-400a-a025-3b898ba3cb8f 11/12/22 12:34:39.08
    STEP: Updating secret s-test-opt-upd-ab461d94-574b-42c3-8abd-fef5acb45680 11/12/22 12:34:39.089
    STEP: Creating secret with name s-test-opt-create-fe8515b1-461e-42e8-881b-e1c32c91e1fd 11/12/22 12:34:39.096
    STEP: waiting to observe update in volume 11/12/22 12:34:39.103
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 12:34:43.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8342" for this suite. 11/12/22 12:34:43.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:34:43.18
Nov 12 12:34:43.180: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 12:34:43.181
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:34:43.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:34:43.218
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Nov 12 12:34:43.236: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 12 12:34:48.245: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 12:34:48.245
Nov 12 12:34:48.245: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 12 12:34:50.254: INFO: Creating deployment "test-rollover-deployment"
Nov 12 12:34:50.268: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 12 12:34:52.279: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 12 12:34:52.288: INFO: Ensure that both replica sets have 1 created replica
Nov 12 12:34:52.297: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 12 12:34:52.308: INFO: Updating deployment test-rollover-deployment
Nov 12 12:34:52.309: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 12 12:34:54.318: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 12 12:34:54.327: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 12 12:34:54.337: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 12:34:54.337: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:34:56.346: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 12:34:56.346: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:34:58.347: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 12:34:58.347: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:35:00.347: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 12:35:00.347: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:35:02.349: INFO: all replica sets need to contain the pod-template-hash label
Nov 12 12:35:02.349: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:35:04.348: INFO: 
Nov 12 12:35:04.348: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 12:35:04.362: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1796  84f339a2-08a5-404d-9285-87230702f189 19198 2 2022-11-12 12:34:50 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b60918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 12:34:50 +0000 UTC,LastTransitionTime:2022-11-12 12:34:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-12 12:35:03 +0000 UTC,LastTransitionTime:2022-11-12 12:34:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 12:35:04.368: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-1796  471575f8-70b3-43f5-aecb-3e19dc859c08 19188 2 2022-11-12 12:34:52 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 84f339a2-08a5-404d-9285-87230702f189 0xc004381e17 0xc004381e18}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84f339a2-08a5-404d-9285-87230702f189\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004381ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:35:04.368: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 12 12:35:04.368: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1796  89dd15c8-73ea-429a-8725-005c10f421a4 19197 2 2022-11-12 12:34:43 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 84f339a2-08a5-404d-9285-87230702f189 0xc004381bc7 0xc004381bc8}] [] [{e2e.test Update apps/v1 2022-11-12 12:34:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84f339a2-08a5-404d-9285-87230702f189\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004381c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:35:04.368: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-1796  9bdc9494-4010-458a-a94a-fa3bb9e8ed83 19143 2 2022-11-12 12:34:50 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 84f339a2-08a5-404d-9285-87230702f189 0xc004381cf7 0xc004381cf8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84f339a2-08a5-404d-9285-87230702f189\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004381da8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:35:04.374: INFO: Pod "test-rollover-deployment-6d45fd857b-k92mq" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-k92mq test-rollover-deployment-6d45fd857b- deployment-1796  765b5d2d-419c-43a6-a986-133e149ce768 19163 0 2022-11-12 12:34:52 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 471575f8-70b3-43f5-aecb-3e19dc859c08 0xc002c321b7 0xc002c321b8}] [] [{kube-controller-manager Update v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471575f8-70b3-43f5-aecb-3e19dc859c08\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:34:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x95f5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x95f5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.23,StartTime:2022-11-12 12:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:34:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://301736fbb6aa32b1967489bbbce6f99102799eff24b12db2732f995c01541a0d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 12:35:04.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1796" for this suite. 11/12/22 12:35:04.379
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":156,"skipped":2809,"failed":0}
------------------------------
• [SLOW TEST] [21.213 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:34:43.18
    Nov 12 12:34:43.180: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 12:34:43.181
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:34:43.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:34:43.218
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Nov 12 12:34:43.236: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Nov 12 12:34:48.245: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 12:34:48.245
    Nov 12 12:34:48.245: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Nov 12 12:34:50.254: INFO: Creating deployment "test-rollover-deployment"
    Nov 12 12:34:50.268: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Nov 12 12:34:52.279: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Nov 12 12:34:52.288: INFO: Ensure that both replica sets have 1 created replica
    Nov 12 12:34:52.297: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Nov 12 12:34:52.308: INFO: Updating deployment test-rollover-deployment
    Nov 12 12:34:52.309: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Nov 12 12:34:54.318: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Nov 12 12:34:54.327: INFO: Make sure deployment "test-rollover-deployment" is complete
    Nov 12 12:34:54.337: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 12:34:54.337: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:34:56.346: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 12:34:56.346: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:34:58.347: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 12:34:58.347: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:35:00.347: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 12:35:00.347: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:35:02.349: INFO: all replica sets need to contain the pod-template-hash label
    Nov 12 12:35:02.349: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 34, 53, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 34, 50, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:35:04.348: INFO: 
    Nov 12 12:35:04.348: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 12:35:04.362: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-1796  84f339a2-08a5-404d-9285-87230702f189 19198 2 2022-11-12 12:34:50 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b60918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 12:34:50 +0000 UTC,LastTransitionTime:2022-11-12 12:34:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-12 12:35:03 +0000 UTC,LastTransitionTime:2022-11-12 12:34:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 12:35:04.368: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-1796  471575f8-70b3-43f5-aecb-3e19dc859c08 19188 2 2022-11-12 12:34:52 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 84f339a2-08a5-404d-9285-87230702f189 0xc004381e17 0xc004381e18}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84f339a2-08a5-404d-9285-87230702f189\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004381ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:35:04.368: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Nov 12 12:35:04.368: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1796  89dd15c8-73ea-429a-8725-005c10f421a4 19197 2 2022-11-12 12:34:43 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 84f339a2-08a5-404d-9285-87230702f189 0xc004381bc7 0xc004381bc8}] [] [{e2e.test Update apps/v1 2022-11-12 12:34:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84f339a2-08a5-404d-9285-87230702f189\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:35:03 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004381c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:35:04.368: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-1796  9bdc9494-4010-458a-a94a-fa3bb9e8ed83 19143 2 2022-11-12 12:34:50 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 84f339a2-08a5-404d-9285-87230702f189 0xc004381cf7 0xc004381cf8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"84f339a2-08a5-404d-9285-87230702f189\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004381da8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:35:04.374: INFO: Pod "test-rollover-deployment-6d45fd857b-k92mq" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-k92mq test-rollover-deployment-6d45fd857b- deployment-1796  765b5d2d-419c-43a6-a986-133e149ce768 19163 0 2022-11-12 12:34:52 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 471575f8-70b3-43f5-aecb-3e19dc859c08 0xc002c321b7 0xc002c321b8}] [] [{kube-controller-manager Update v1 2022-11-12 12:34:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"471575f8-70b3-43f5-aecb-3e19dc859c08\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:34:53 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x95f5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x95f5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:34:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.23,StartTime:2022-11-12 12:34:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:34:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://301736fbb6aa32b1967489bbbce6f99102799eff24b12db2732f995c01541a0d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 12:35:04.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1796" for this suite. 11/12/22 12:35:04.379
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:35:04.396
Nov 12 12:35:04.396: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 12:35:04.397
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:04.435
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:04.44
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 11/12/22 12:35:04.443
Nov 12 12:35:04.461: INFO: Waiting up to 5m0s for pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807" in namespace "downward-api-1914" to be "Succeeded or Failed"
Nov 12 12:35:04.471: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807": Phase="Pending", Reason="", readiness=false. Elapsed: 9.683636ms
Nov 12 12:35:06.476: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01458721s
Nov 12 12:35:08.479: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017282009s
STEP: Saw pod success 11/12/22 12:35:08.479
Nov 12 12:35:08.479: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807" satisfied condition "Succeeded or Failed"
Nov 12 12:35:08.484: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-302e4c9f-becc-467b-8516-464458078807 container client-container: <nil>
STEP: delete the pod 11/12/22 12:35:08.508
Nov 12 12:35:08.535: INFO: Waiting for pod downwardapi-volume-302e4c9f-becc-467b-8516-464458078807 to disappear
Nov 12 12:35:08.540: INFO: Pod downwardapi-volume-302e4c9f-becc-467b-8516-464458078807 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 12:35:08.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1914" for this suite. 11/12/22 12:35:08.545
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":157,"skipped":2868,"failed":0}
------------------------------
• [4.166 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:35:04.396
    Nov 12 12:35:04.396: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 12:35:04.397
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:04.435
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:04.44
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 11/12/22 12:35:04.443
    Nov 12 12:35:04.461: INFO: Waiting up to 5m0s for pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807" in namespace "downward-api-1914" to be "Succeeded or Failed"
    Nov 12 12:35:04.471: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807": Phase="Pending", Reason="", readiness=false. Elapsed: 9.683636ms
    Nov 12 12:35:06.476: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01458721s
    Nov 12 12:35:08.479: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017282009s
    STEP: Saw pod success 11/12/22 12:35:08.479
    Nov 12 12:35:08.479: INFO: Pod "downwardapi-volume-302e4c9f-becc-467b-8516-464458078807" satisfied condition "Succeeded or Failed"
    Nov 12 12:35:08.484: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-302e4c9f-becc-467b-8516-464458078807 container client-container: <nil>
    STEP: delete the pod 11/12/22 12:35:08.508
    Nov 12 12:35:08.535: INFO: Waiting for pod downwardapi-volume-302e4c9f-becc-467b-8516-464458078807 to disappear
    Nov 12 12:35:08.540: INFO: Pod downwardapi-volume-302e4c9f-becc-467b-8516-464458078807 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 12:35:08.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1914" for this suite. 11/12/22 12:35:08.545
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:35:08.566
Nov 12 12:35:08.566: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:35:08.567
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:08.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:08.59
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 12:35:08.592
Nov 12 12:35:08.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4362 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Nov 12 12:35:08.711: INFO: stderr: ""
Nov 12 12:35:08.712: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 12:35:08.712
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Nov 12 12:35:08.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4362 delete pods e2e-test-httpd-pod'
Nov 12 12:35:11.020: INFO: stderr: ""
Nov 12 12:35:11.020: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:35:11.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4362" for this suite. 11/12/22 12:35:11.024
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":158,"skipped":2923,"failed":0}
------------------------------
• [2.466 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:35:08.566
    Nov 12 12:35:08.566: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:35:08.567
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:08.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:08.59
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 12:35:08.592
    Nov 12 12:35:08.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4362 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Nov 12 12:35:08.711: INFO: stderr: ""
    Nov 12 12:35:08.712: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 12:35:08.712
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Nov 12 12:35:08.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4362 delete pods e2e-test-httpd-pod'
    Nov 12 12:35:11.020: INFO: stderr: ""
    Nov 12 12:35:11.020: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:35:11.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4362" for this suite. 11/12/22 12:35:11.024
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:35:11.033
Nov 12 12:35:11.033: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 12:35:11.034
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:11.052
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:11.055
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Nov 12 12:35:11.073: INFO: Waiting up to 2m0s for pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" in namespace "var-expansion-4993" to be "container 0 failed with reason CreateContainerConfigError"
Nov 12 12:35:11.080: INFO: Pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188": Phase="Pending", Reason="", readiness=false. Elapsed: 6.844208ms
Nov 12 12:35:13.088: INFO: Pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014924432s
Nov 12 12:35:13.088: INFO: Pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 12 12:35:13.089: INFO: Deleting pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" in namespace "var-expansion-4993"
Nov 12 12:35:13.112: INFO: Wait up to 5m0s for pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 12:35:15.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4993" for this suite. 11/12/22 12:35:15.134
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":159,"skipped":2932,"failed":0}
------------------------------
• [4.109 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:35:11.033
    Nov 12 12:35:11.033: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 12:35:11.034
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:11.052
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:11.055
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Nov 12 12:35:11.073: INFO: Waiting up to 2m0s for pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" in namespace "var-expansion-4993" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 12 12:35:11.080: INFO: Pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188": Phase="Pending", Reason="", readiness=false. Elapsed: 6.844208ms
    Nov 12 12:35:13.088: INFO: Pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014924432s
    Nov 12 12:35:13.088: INFO: Pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 12 12:35:13.089: INFO: Deleting pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" in namespace "var-expansion-4993"
    Nov 12 12:35:13.112: INFO: Wait up to 5m0s for pod "var-expansion-c7e163e9-fe4a-4689-a97d-27ec7fb6e188" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 12:35:15.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4993" for this suite. 11/12/22 12:35:15.134
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:35:15.149
Nov 12 12:35:15.150: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 12:35:15.151
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:15.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:15.175
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 11/12/22 12:35:15.18
STEP: Creating a ResourceQuota 11/12/22 12:35:20.191
STEP: Ensuring resource quota status is calculated 11/12/22 12:35:20.197
STEP: Creating a Pod that fits quota 11/12/22 12:35:22.203
STEP: Ensuring ResourceQuota status captures the pod usage 11/12/22 12:35:22.224
STEP: Not allowing a pod to be created that exceeds remaining quota 11/12/22 12:35:24.233
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/12/22 12:35:24.236
STEP: Ensuring a pod cannot update its resource requirements 11/12/22 12:35:24.24
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/12/22 12:35:24.247
STEP: Deleting the pod 11/12/22 12:35:26.253
STEP: Ensuring resource quota status released the pod usage 11/12/22 12:35:26.273
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 12:35:28.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-256" for this suite. 11/12/22 12:35:28.283
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":160,"skipped":2948,"failed":0}
------------------------------
• [SLOW TEST] [13.143 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:35:15.149
    Nov 12 12:35:15.150: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 12:35:15.151
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:15.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:15.175
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 11/12/22 12:35:15.18
    STEP: Creating a ResourceQuota 11/12/22 12:35:20.191
    STEP: Ensuring resource quota status is calculated 11/12/22 12:35:20.197
    STEP: Creating a Pod that fits quota 11/12/22 12:35:22.203
    STEP: Ensuring ResourceQuota status captures the pod usage 11/12/22 12:35:22.224
    STEP: Not allowing a pod to be created that exceeds remaining quota 11/12/22 12:35:24.233
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/12/22 12:35:24.236
    STEP: Ensuring a pod cannot update its resource requirements 11/12/22 12:35:24.24
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/12/22 12:35:24.247
    STEP: Deleting the pod 11/12/22 12:35:26.253
    STEP: Ensuring resource quota status released the pod usage 11/12/22 12:35:26.273
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 12:35:28.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-256" for this suite. 11/12/22 12:35:28.283
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:35:28.293
Nov 12 12:35:28.293: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:35:28.294
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:28.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:28.32
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-4549 11/12/22 12:35:28.323
STEP: creating service affinity-nodeport-transition in namespace services-4549 11/12/22 12:35:28.323
STEP: creating replication controller affinity-nodeport-transition in namespace services-4549 11/12/22 12:35:28.35
I1112 12:35:28.366404      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4549, replica count: 3
I1112 12:35:31.417889      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1112 12:35:34.419658      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 12:35:34.433: INFO: Creating new exec pod
Nov 12 12:35:34.441: INFO: Waiting up to 5m0s for pod "execpod-affinityv4fj9" in namespace "services-4549" to be "running"
Nov 12 12:35:34.448: INFO: Pod "execpod-affinityv4fj9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.282855ms
Nov 12 12:35:36.454: INFO: Pod "execpod-affinityv4fj9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013602377s
Nov 12 12:35:36.454: INFO: Pod "execpod-affinityv4fj9" satisfied condition "running"
Nov 12 12:35:37.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Nov 12 12:35:37.620: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Nov 12 12:35:37.620: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:35:37.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.156 80'
Nov 12 12:35:37.780: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.156 80\nConnection to 10.152.183.156 80 port [tcp/http] succeeded!\n"
Nov 12 12:35:37.780: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:35:37.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 30224'
Nov 12 12:35:37.929: INFO: stderr: "+ nc -v -t -w 2 172.31.89.190 30224\n+ echo hostName\nConnection to 172.31.89.190 30224 port [tcp/*] succeeded!\n"
Nov 12 12:35:37.929: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:35:37.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.14.110 30224'
Nov 12 12:35:38.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.14.110 30224\nConnection to 172.31.14.110 30224 port [tcp/*] succeeded!\n"
Nov 12 12:35:38.096: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:35:38.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:30224/ ; done'
Nov 12 12:35:38.367: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n"
Nov 12 12:35:38.367: INFO: stdout: "\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-nxt69\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-nxt69\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-nxt69\naffinity-nodeport-transition-nxt69"
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
Nov 12 12:35:38.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:30224/ ; done'
Nov 12 12:35:38.600: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n"
Nov 12 12:35:38.600: INFO: stdout: "\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c"
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
Nov 12 12:35:38.600: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4549, will wait for the garbage collector to delete the pods 11/12/22 12:35:38.615
Nov 12 12:35:38.680: INFO: Deleting ReplicationController affinity-nodeport-transition took: 9.579818ms
Nov 12 12:35:38.780: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.23922ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:35:41.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4549" for this suite. 11/12/22 12:35:41.22
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":161,"skipped":2952,"failed":0}
------------------------------
• [SLOW TEST] [12.938 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:35:28.293
    Nov 12 12:35:28.293: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:35:28.294
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:28.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:28.32
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-4549 11/12/22 12:35:28.323
    STEP: creating service affinity-nodeport-transition in namespace services-4549 11/12/22 12:35:28.323
    STEP: creating replication controller affinity-nodeport-transition in namespace services-4549 11/12/22 12:35:28.35
    I1112 12:35:28.366404      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4549, replica count: 3
    I1112 12:35:31.417889      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1112 12:35:34.419658      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 12:35:34.433: INFO: Creating new exec pod
    Nov 12 12:35:34.441: INFO: Waiting up to 5m0s for pod "execpod-affinityv4fj9" in namespace "services-4549" to be "running"
    Nov 12 12:35:34.448: INFO: Pod "execpod-affinityv4fj9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.282855ms
    Nov 12 12:35:36.454: INFO: Pod "execpod-affinityv4fj9": Phase="Running", Reason="", readiness=true. Elapsed: 2.013602377s
    Nov 12 12:35:36.454: INFO: Pod "execpod-affinityv4fj9" satisfied condition "running"
    Nov 12 12:35:37.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Nov 12 12:35:37.620: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Nov 12 12:35:37.620: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:35:37.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.156 80'
    Nov 12 12:35:37.780: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.156 80\nConnection to 10.152.183.156 80 port [tcp/http] succeeded!\n"
    Nov 12 12:35:37.780: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:35:37.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 30224'
    Nov 12 12:35:37.929: INFO: stderr: "+ nc -v -t -w 2 172.31.89.190 30224\n+ echo hostName\nConnection to 172.31.89.190 30224 port [tcp/*] succeeded!\n"
    Nov 12 12:35:37.929: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:35:37.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.14.110 30224'
    Nov 12 12:35:38.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.14.110 30224\nConnection to 172.31.14.110 30224 port [tcp/*] succeeded!\n"
    Nov 12 12:35:38.096: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:35:38.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:30224/ ; done'
    Nov 12 12:35:38.367: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n"
    Nov 12 12:35:38.367: INFO: stdout: "\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-nxt69\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-nxt69\naffinity-nodeport-transition-zlzc8\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-nxt69\naffinity-nodeport-transition-nxt69"
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-zlzc8
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
    Nov 12 12:35:38.367: INFO: Received response from host: affinity-nodeport-transition-nxt69
    Nov 12 12:35:38.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4549 exec execpod-affinityv4fj9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:30224/ ; done'
    Nov 12 12:35:38.600: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30224/\n"
    Nov 12 12:35:38.600: INFO: stdout: "\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c\naffinity-nodeport-transition-6lz6c"
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Received response from host: affinity-nodeport-transition-6lz6c
    Nov 12 12:35:38.600: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4549, will wait for the garbage collector to delete the pods 11/12/22 12:35:38.615
    Nov 12 12:35:38.680: INFO: Deleting ReplicationController affinity-nodeport-transition took: 9.579818ms
    Nov 12 12:35:38.780: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.23922ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:35:41.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4549" for this suite. 11/12/22 12:35:41.22
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:35:41.231
Nov 12 12:35:41.231: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename endpointslicemirroring 11/12/22 12:35:41.232
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:41.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:41.259
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 11/12/22 12:35:41.276
Nov 12 12:35:41.287: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 11/12/22 12:35:43.292
STEP: mirroring deletion of a custom Endpoint 11/12/22 12:35:43.306
Nov 12 12:35:43.323: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Nov 12 12:35:45.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-8213" for this suite. 11/12/22 12:35:45.337
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":162,"skipped":2952,"failed":0}
------------------------------
• [4.115 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:35:41.231
    Nov 12 12:35:41.231: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename endpointslicemirroring 11/12/22 12:35:41.232
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:41.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:41.259
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 11/12/22 12:35:41.276
    Nov 12 12:35:41.287: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 11/12/22 12:35:43.292
    STEP: mirroring deletion of a custom Endpoint 11/12/22 12:35:43.306
    Nov 12 12:35:43.323: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Nov 12 12:35:45.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-8213" for this suite. 11/12/22 12:35:45.337
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:35:45.351
Nov 12 12:35:45.351: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 12:35:45.352
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:45.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:45.378
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 11/12/22 12:36:02.386
STEP: Creating a ResourceQuota 11/12/22 12:36:07.391
STEP: Ensuring resource quota status is calculated 11/12/22 12:36:07.399
STEP: Creating a ConfigMap 11/12/22 12:36:09.405
STEP: Ensuring resource quota status captures configMap creation 11/12/22 12:36:09.429
STEP: Deleting a ConfigMap 11/12/22 12:36:11.434
STEP: Ensuring resource quota status released usage 11/12/22 12:36:11.444
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 12:36:13.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8152" for this suite. 11/12/22 12:36:13.456
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":163,"skipped":3016,"failed":0}
------------------------------
• [SLOW TEST] [28.123 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:35:45.351
    Nov 12 12:35:45.351: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 12:35:45.352
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:35:45.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:35:45.378
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 11/12/22 12:36:02.386
    STEP: Creating a ResourceQuota 11/12/22 12:36:07.391
    STEP: Ensuring resource quota status is calculated 11/12/22 12:36:07.399
    STEP: Creating a ConfigMap 11/12/22 12:36:09.405
    STEP: Ensuring resource quota status captures configMap creation 11/12/22 12:36:09.429
    STEP: Deleting a ConfigMap 11/12/22 12:36:11.434
    STEP: Ensuring resource quota status released usage 11/12/22 12:36:11.444
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 12:36:13.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8152" for this suite. 11/12/22 12:36:13.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:13.477
Nov 12 12:36:13.477: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 12:36:13.478
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:13.519
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:13.522
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-8825/configmap-test-606b8119-e99b-42e6-99aa-07a29577ac8e 11/12/22 12:36:13.524
STEP: Creating a pod to test consume configMaps 11/12/22 12:36:13.532
Nov 12 12:36:13.544: INFO: Waiting up to 5m0s for pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656" in namespace "configmap-8825" to be "Succeeded or Failed"
Nov 12 12:36:13.551: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656": Phase="Pending", Reason="", readiness=false. Elapsed: 6.593511ms
Nov 12 12:36:15.557: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012725886s
Nov 12 12:36:17.556: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011574459s
STEP: Saw pod success 11/12/22 12:36:17.556
Nov 12 12:36:17.556: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656" satisfied condition "Succeeded or Failed"
Nov 12 12:36:17.561: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656 container env-test: <nil>
STEP: delete the pod 11/12/22 12:36:17.576
Nov 12 12:36:17.590: INFO: Waiting for pod pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656 to disappear
Nov 12 12:36:17.595: INFO: Pod pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 12:36:17.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8825" for this suite. 11/12/22 12:36:17.6
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":164,"skipped":3048,"failed":0}
------------------------------
• [4.132 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:13.477
    Nov 12 12:36:13.477: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 12:36:13.478
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:13.519
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:13.522
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-8825/configmap-test-606b8119-e99b-42e6-99aa-07a29577ac8e 11/12/22 12:36:13.524
    STEP: Creating a pod to test consume configMaps 11/12/22 12:36:13.532
    Nov 12 12:36:13.544: INFO: Waiting up to 5m0s for pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656" in namespace "configmap-8825" to be "Succeeded or Failed"
    Nov 12 12:36:13.551: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656": Phase="Pending", Reason="", readiness=false. Elapsed: 6.593511ms
    Nov 12 12:36:15.557: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012725886s
    Nov 12 12:36:17.556: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011574459s
    STEP: Saw pod success 11/12/22 12:36:17.556
    Nov 12 12:36:17.556: INFO: Pod "pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656" satisfied condition "Succeeded or Failed"
    Nov 12 12:36:17.561: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656 container env-test: <nil>
    STEP: delete the pod 11/12/22 12:36:17.576
    Nov 12 12:36:17.590: INFO: Waiting for pod pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656 to disappear
    Nov 12 12:36:17.595: INFO: Pod pod-configmaps-12a4bf08-580a-4c54-86e4-751dc52ac656 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 12:36:17.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8825" for this suite. 11/12/22 12:36:17.6
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:17.612
Nov 12 12:36:17.612: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:17.613
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:17.631
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:17.634
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Nov 12 12:36:17.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4356 version'
Nov 12 12:36:17.705: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Nov 12 12:36:17.705: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-11T02:14:16Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:36:17.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4356" for this suite. 11/12/22 12:36:17.71
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":165,"skipped":3084,"failed":0}
------------------------------
• [0.107 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:17.612
    Nov 12 12:36:17.612: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:17.613
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:17.631
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:17.634
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Nov 12 12:36:17.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4356 version'
    Nov 12 12:36:17.705: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Nov 12 12:36:17.705: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-11T02:14:16Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:36:17.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4356" for this suite. 11/12/22 12:36:17.71
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:17.72
Nov 12 12:36:17.720: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename certificates 11/12/22 12:36:17.721
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:17.739
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:17.75
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 11/12/22 12:36:18.631
STEP: getting /apis/certificates.k8s.io 11/12/22 12:36:18.634
STEP: getting /apis/certificates.k8s.io/v1 11/12/22 12:36:18.635
STEP: creating 11/12/22 12:36:18.639
STEP: getting 11/12/22 12:36:18.663
STEP: listing 11/12/22 12:36:18.68
STEP: watching 11/12/22 12:36:18.688
Nov 12 12:36:18.688: INFO: starting watch
STEP: patching 11/12/22 12:36:18.689
STEP: updating 11/12/22 12:36:18.698
Nov 12 12:36:18.705: INFO: waiting for watch events with expected annotations
Nov 12 12:36:18.705: INFO: saw patched and updated annotations
STEP: getting /approval 11/12/22 12:36:18.705
STEP: patching /approval 11/12/22 12:36:18.71
STEP: updating /approval 11/12/22 12:36:18.72
STEP: getting /status 11/12/22 12:36:18.728
STEP: patching /status 11/12/22 12:36:18.732
STEP: updating /status 11/12/22 12:36:18.766
STEP: deleting 11/12/22 12:36:18.776
STEP: deleting a collection 11/12/22 12:36:18.794
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:36:18.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-7075" for this suite. 11/12/22 12:36:18.827
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":166,"skipped":3091,"failed":0}
------------------------------
• [1.117 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:17.72
    Nov 12 12:36:17.720: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename certificates 11/12/22 12:36:17.721
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:17.739
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:17.75
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 11/12/22 12:36:18.631
    STEP: getting /apis/certificates.k8s.io 11/12/22 12:36:18.634
    STEP: getting /apis/certificates.k8s.io/v1 11/12/22 12:36:18.635
    STEP: creating 11/12/22 12:36:18.639
    STEP: getting 11/12/22 12:36:18.663
    STEP: listing 11/12/22 12:36:18.68
    STEP: watching 11/12/22 12:36:18.688
    Nov 12 12:36:18.688: INFO: starting watch
    STEP: patching 11/12/22 12:36:18.689
    STEP: updating 11/12/22 12:36:18.698
    Nov 12 12:36:18.705: INFO: waiting for watch events with expected annotations
    Nov 12 12:36:18.705: INFO: saw patched and updated annotations
    STEP: getting /approval 11/12/22 12:36:18.705
    STEP: patching /approval 11/12/22 12:36:18.71
    STEP: updating /approval 11/12/22 12:36:18.72
    STEP: getting /status 11/12/22 12:36:18.728
    STEP: patching /status 11/12/22 12:36:18.732
    STEP: updating /status 11/12/22 12:36:18.766
    STEP: deleting 11/12/22 12:36:18.776
    STEP: deleting a collection 11/12/22 12:36:18.794
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:36:18.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-7075" for this suite. 11/12/22 12:36:18.827
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:18.838
Nov 12 12:36:18.838: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:18.839
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:18.863
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:18.866
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 11/12/22 12:36:18.869
Nov 12 12:36:18.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1198 create -f -'
Nov 12 12:36:19.047: INFO: stderr: ""
Nov 12 12:36:19.047: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 11/12/22 12:36:19.047
Nov 12 12:36:19.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1198 diff -f -'
Nov 12 12:36:19.251: INFO: rc: 1
Nov 12 12:36:19.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1198 delete -f -'
Nov 12 12:36:19.318: INFO: stderr: ""
Nov 12 12:36:19.318: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:36:19.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1198" for this suite. 11/12/22 12:36:19.33
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":167,"skipped":3096,"failed":0}
------------------------------
• [0.499 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:18.838
    Nov 12 12:36:18.838: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:18.839
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:18.863
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:18.866
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 11/12/22 12:36:18.869
    Nov 12 12:36:18.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1198 create -f -'
    Nov 12 12:36:19.047: INFO: stderr: ""
    Nov 12 12:36:19.047: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 11/12/22 12:36:19.047
    Nov 12 12:36:19.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1198 diff -f -'
    Nov 12 12:36:19.251: INFO: rc: 1
    Nov 12 12:36:19.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1198 delete -f -'
    Nov 12 12:36:19.318: INFO: stderr: ""
    Nov 12 12:36:19.318: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:36:19.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1198" for this suite. 11/12/22 12:36:19.33
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:19.343
Nov 12 12:36:19.344: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:36:19.344
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:19.363
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:19.366
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Nov 12 12:36:19.372: INFO: Got root ca configmap in namespace "svcaccounts-2399"
Nov 12 12:36:19.380: INFO: Deleted root ca configmap in namespace "svcaccounts-2399"
STEP: waiting for a new root ca configmap created 11/12/22 12:36:19.88
Nov 12 12:36:19.885: INFO: Recreated root ca configmap in namespace "svcaccounts-2399"
Nov 12 12:36:19.895: INFO: Updated root ca configmap in namespace "svcaccounts-2399"
STEP: waiting for the root ca configmap reconciled 11/12/22 12:36:20.396
Nov 12 12:36:20.401: INFO: Reconciled root ca configmap in namespace "svcaccounts-2399"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 12 12:36:20.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2399" for this suite. 11/12/22 12:36:20.407
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":168,"skipped":3188,"failed":0}
------------------------------
• [1.076 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:19.343
    Nov 12 12:36:19.344: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:36:19.344
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:19.363
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:19.366
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Nov 12 12:36:19.372: INFO: Got root ca configmap in namespace "svcaccounts-2399"
    Nov 12 12:36:19.380: INFO: Deleted root ca configmap in namespace "svcaccounts-2399"
    STEP: waiting for a new root ca configmap created 11/12/22 12:36:19.88
    Nov 12 12:36:19.885: INFO: Recreated root ca configmap in namespace "svcaccounts-2399"
    Nov 12 12:36:19.895: INFO: Updated root ca configmap in namespace "svcaccounts-2399"
    STEP: waiting for the root ca configmap reconciled 11/12/22 12:36:20.396
    Nov 12 12:36:20.401: INFO: Reconciled root ca configmap in namespace "svcaccounts-2399"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 12 12:36:20.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2399" for this suite. 11/12/22 12:36:20.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:20.423
Nov 12 12:36:20.423: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:36:20.425
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:20.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:20.449
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:36:20.471
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:36:21.01
STEP: Deploying the webhook pod 11/12/22 12:36:21.021
STEP: Wait for the deployment to be ready 11/12/22 12:36:21.038
Nov 12 12:36:21.049: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:36:23.066
STEP: Verifying the service has paired with the endpoint 11/12/22 12:36:23.084
Nov 12 12:36:24.084: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Nov 12 12:36:24.093: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/12/22 12:36:24.607
STEP: Creating a custom resource that should be denied by the webhook 11/12/22 12:36:24.63
STEP: Creating a custom resource whose deletion would be denied by the webhook 11/12/22 12:36:26.638
STEP: Updating the custom resource with disallowed data should be denied 11/12/22 12:36:26.653
STEP: Deleting the custom resource should be denied 11/12/22 12:36:26.665
STEP: Remove the offending key and value from the custom resource data 11/12/22 12:36:26.674
STEP: Deleting the updated custom resource should be successful 11/12/22 12:36:26.689
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:36:27.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5539" for this suite. 11/12/22 12:36:27.225
STEP: Destroying namespace "webhook-5539-markers" for this suite. 11/12/22 12:36:27.234
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":169,"skipped":3197,"failed":0}
------------------------------
• [SLOW TEST] [6.891 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:20.423
    Nov 12 12:36:20.423: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:36:20.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:20.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:20.449
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:36:20.471
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:36:21.01
    STEP: Deploying the webhook pod 11/12/22 12:36:21.021
    STEP: Wait for the deployment to be ready 11/12/22 12:36:21.038
    Nov 12 12:36:21.049: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:36:23.066
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:36:23.084
    Nov 12 12:36:24.084: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Nov 12 12:36:24.093: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/12/22 12:36:24.607
    STEP: Creating a custom resource that should be denied by the webhook 11/12/22 12:36:24.63
    STEP: Creating a custom resource whose deletion would be denied by the webhook 11/12/22 12:36:26.638
    STEP: Updating the custom resource with disallowed data should be denied 11/12/22 12:36:26.653
    STEP: Deleting the custom resource should be denied 11/12/22 12:36:26.665
    STEP: Remove the offending key and value from the custom resource data 11/12/22 12:36:26.674
    STEP: Deleting the updated custom resource should be successful 11/12/22 12:36:26.689
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:36:27.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5539" for this suite. 11/12/22 12:36:27.225
    STEP: Destroying namespace "webhook-5539-markers" for this suite. 11/12/22 12:36:27.234
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:27.314
Nov 12 12:36:27.314: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:36:27.315
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:27.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:27.363
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 11/12/22 12:36:27.369
Nov 12 12:36:27.385: INFO: Waiting up to 5m0s for pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e" in namespace "emptydir-9714" to be "Succeeded or Failed"
Nov 12 12:36:27.394: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.402232ms
Nov 12 12:36:29.400: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015382449s
Nov 12 12:36:31.400: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014821314s
STEP: Saw pod success 11/12/22 12:36:31.4
Nov 12 12:36:31.400: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e" satisfied condition "Succeeded or Failed"
Nov 12 12:36:31.405: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e container test-container: <nil>
STEP: delete the pod 11/12/22 12:36:31.416
Nov 12 12:36:31.431: INFO: Waiting for pod pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e to disappear
Nov 12 12:36:31.438: INFO: Pod pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:36:31.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9714" for this suite. 11/12/22 12:36:31.443
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":170,"skipped":3199,"failed":0}
------------------------------
• [4.139 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:27.314
    Nov 12 12:36:27.314: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:36:27.315
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:27.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:27.363
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/12/22 12:36:27.369
    Nov 12 12:36:27.385: INFO: Waiting up to 5m0s for pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e" in namespace "emptydir-9714" to be "Succeeded or Failed"
    Nov 12 12:36:27.394: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.402232ms
    Nov 12 12:36:29.400: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015382449s
    Nov 12 12:36:31.400: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014821314s
    STEP: Saw pod success 11/12/22 12:36:31.4
    Nov 12 12:36:31.400: INFO: Pod "pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e" satisfied condition "Succeeded or Failed"
    Nov 12 12:36:31.405: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e container test-container: <nil>
    STEP: delete the pod 11/12/22 12:36:31.416
    Nov 12 12:36:31.431: INFO: Waiting for pod pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e to disappear
    Nov 12 12:36:31.438: INFO: Pod pod-fb7a12db-e081-4f46-a64a-8ca8d2160d9e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:36:31.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9714" for this suite. 11/12/22 12:36:31.443
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:31.455
Nov 12 12:36:31.455: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:36:31.456
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:31.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:31.483
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Nov 12 12:36:31.485: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:36:32.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8703" for this suite. 11/12/22 12:36:32.067
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":171,"skipped":3208,"failed":0}
------------------------------
• [0.631 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:31.455
    Nov 12 12:36:31.455: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename custom-resource-definition 11/12/22 12:36:31.456
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:31.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:31.483
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Nov 12 12:36:31.485: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:36:32.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8703" for this suite. 11/12/22 12:36:32.067
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:32.088
Nov 12 12:36:32.088: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 12:36:32.089
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:32.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:32.113
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 11/12/22 12:36:32.116
Nov 12 12:36:32.142: INFO: Waiting up to 5m0s for pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a" in namespace "downward-api-3663" to be "Succeeded or Failed"
Nov 12 12:36:32.150: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.340125ms
Nov 12 12:36:34.157: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014764879s
Nov 12 12:36:36.156: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014169528s
STEP: Saw pod success 11/12/22 12:36:36.156
Nov 12 12:36:36.156: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a" satisfied condition "Succeeded or Failed"
Nov 12 12:36:36.161: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-fd44e925-e64e-4874-b0ed-175142acd49a container dapi-container: <nil>
STEP: delete the pod 11/12/22 12:36:36.171
Nov 12 12:36:36.188: INFO: Waiting for pod downward-api-fd44e925-e64e-4874-b0ed-175142acd49a to disappear
Nov 12 12:36:36.192: INFO: Pod downward-api-fd44e925-e64e-4874-b0ed-175142acd49a no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 12 12:36:36.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3663" for this suite. 11/12/22 12:36:36.199
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":172,"skipped":3229,"failed":0}
------------------------------
• [4.120 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:32.088
    Nov 12 12:36:32.088: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 12:36:32.089
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:32.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:32.113
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 11/12/22 12:36:32.116
    Nov 12 12:36:32.142: INFO: Waiting up to 5m0s for pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a" in namespace "downward-api-3663" to be "Succeeded or Failed"
    Nov 12 12:36:32.150: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.340125ms
    Nov 12 12:36:34.157: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014764879s
    Nov 12 12:36:36.156: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014169528s
    STEP: Saw pod success 11/12/22 12:36:36.156
    Nov 12 12:36:36.156: INFO: Pod "downward-api-fd44e925-e64e-4874-b0ed-175142acd49a" satisfied condition "Succeeded or Failed"
    Nov 12 12:36:36.161: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-fd44e925-e64e-4874-b0ed-175142acd49a container dapi-container: <nil>
    STEP: delete the pod 11/12/22 12:36:36.171
    Nov 12 12:36:36.188: INFO: Waiting for pod downward-api-fd44e925-e64e-4874-b0ed-175142acd49a to disappear
    Nov 12 12:36:36.192: INFO: Pod downward-api-fd44e925-e64e-4874-b0ed-175142acd49a no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 12 12:36:36.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3663" for this suite. 11/12/22 12:36:36.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:36.21
Nov 12 12:36:36.210: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 12:36:36.211
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:36.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:36.239
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 11/12/22 12:36:36.249
STEP: waiting for Deployment to be created 11/12/22 12:36:36.257
STEP: waiting for all Replicas to be Ready 11/12/22 12:36:36.259
Nov 12 12:36:36.263: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:36.264: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:36.282: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:36.283: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:36.308: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:36.308: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:36.333: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:36.334: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 12 12:36:37.211: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 12 12:36:37.211: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 12 12:36:37.982: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 11/12/22 12:36:37.982
W1112 12:36:37.996558      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 12 12:36:37.998: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 11/12/22 12:36:37.998
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.016: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.016: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.046: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.046: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:38.057: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:38.057: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:38.074: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:38.074: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:39.215: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:39.215: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:39.270: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
STEP: listing Deployments 11/12/22 12:36:39.27
Nov 12 12:36:39.283: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 11/12/22 12:36:39.283
Nov 12 12:36:39.299: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 11/12/22 12:36:39.299
Nov 12 12:36:39.309: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:39.319: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:39.369: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:39.386: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:41.041: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:41.220: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:41.298: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:41.310: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 12 12:36:43.009: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 11/12/22 12:36:43.045
STEP: fetching the DeploymentStatus 11/12/22 12:36:43.057
Nov 12 12:36:43.069: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3
STEP: deleting the Deployment 11/12/22 12:36:43.07
Nov 12 12:36:43.090: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
Nov 12 12:36:43.091: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 12:36:43.096: INFO: Log out all the ReplicaSets if there is no deployment created
Nov 12 12:36:43.101: INFO: ReplicaSet "test-deployment-54cc775c4b":
&ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-743  b5d4adc3-8531-4b43-8907-40e14bfeeb6d 20222 4 2022-11-12 12:36:37 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment e7b45e6e-218f-4d49-ad32-16e925a40760 0xc004e8e1f7 0xc004e8e1f8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:36:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e7b45e6e-218f-4d49-ad32-16e925a40760\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:36:42 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e8e280 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Nov 12 12:36:43.108: INFO: pod: "test-deployment-54cc775c4b-c2w9t":
&Pod{ObjectMeta:{test-deployment-54cc775c4b-c2w9t test-deployment-54cc775c4b- deployment-743  c44ed9f2-b195-4f5b-98ae-9a3296cce604 20217 0 2022-11-12 12:36:39 +0000 UTC 2022-11-12 12:36:43 +0000 UTC 0xc004e8e538 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b b5d4adc3-8531-4b43-8907-40e14bfeeb6d 0xc004e8e567 0xc004e8e568}] [] [{kube-controller-manager Update v1 2022-11-12 12:36:39 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b5d4adc3-8531-4b43-8907-40e14bfeeb6d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:36:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.215\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-45pc5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-45pc5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.215,StartTime:2022-11-12 12:36:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:36:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://010465eb0d57cae9663e6bbddc162c47689f3f73bd30e84c86496a6359af9530,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.215,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 12:36:43.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-743" for this suite. 11/12/22 12:36:43.116
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":173,"skipped":3244,"failed":0}
------------------------------
• [SLOW TEST] [6.916 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:36.21
    Nov 12 12:36:36.210: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 12:36:36.211
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:36.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:36.239
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 11/12/22 12:36:36.249
    STEP: waiting for Deployment to be created 11/12/22 12:36:36.257
    STEP: waiting for all Replicas to be Ready 11/12/22 12:36:36.259
    Nov 12 12:36:36.263: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:36.264: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:36.282: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:36.283: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:36.308: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:36.308: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:36.333: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:36.334: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 12 12:36:37.211: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 12 12:36:37.211: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 12 12:36:37.982: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 11/12/22 12:36:37.982
    W1112 12:36:37.996558      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 12 12:36:37.998: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 11/12/22 12:36:37.998
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 0
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:38.000: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.001: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.016: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.016: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.046: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.046: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:38.057: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:38.057: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:38.074: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:38.074: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:39.215: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:39.215: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:39.270: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    STEP: listing Deployments 11/12/22 12:36:39.27
    Nov 12 12:36:39.283: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 11/12/22 12:36:39.283
    Nov 12 12:36:39.299: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 11/12/22 12:36:39.299
    Nov 12 12:36:39.309: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:39.319: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:39.369: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:39.386: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:41.041: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:41.220: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:41.298: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:41.310: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 12 12:36:43.009: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 11/12/22 12:36:43.045
    STEP: fetching the DeploymentStatus 11/12/22 12:36:43.057
    Nov 12 12:36:43.069: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 1
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 2
    Nov 12 12:36:43.070: INFO: observed Deployment test-deployment in namespace deployment-743 with ReadyReplicas 3
    STEP: deleting the Deployment 11/12/22 12:36:43.07
    Nov 12 12:36:43.090: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    Nov 12 12:36:43.091: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 12:36:43.096: INFO: Log out all the ReplicaSets if there is no deployment created
    Nov 12 12:36:43.101: INFO: ReplicaSet "test-deployment-54cc775c4b":
    &ReplicaSet{ObjectMeta:{test-deployment-54cc775c4b  deployment-743  b5d4adc3-8531-4b43-8907-40e14bfeeb6d 20222 4 2022-11-12 12:36:37 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment e7b45e6e-218f-4d49-ad32-16e925a40760 0xc004e8e1f7 0xc004e8e1f8}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:36:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e7b45e6e-218f-4d49-ad32-16e925a40760\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:36:42 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 54cc775c4b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/pause:3.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e8e280 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    Nov 12 12:36:43.108: INFO: pod: "test-deployment-54cc775c4b-c2w9t":
    &Pod{ObjectMeta:{test-deployment-54cc775c4b-c2w9t test-deployment-54cc775c4b- deployment-743  c44ed9f2-b195-4f5b-98ae-9a3296cce604 20217 0 2022-11-12 12:36:39 +0000 UTC 2022-11-12 12:36:43 +0000 UTC 0xc004e8e538 map[pod-template-hash:54cc775c4b test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-54cc775c4b b5d4adc3-8531-4b43-8907-40e14bfeeb6d 0xc004e8e567 0xc004e8e568}] [] [{kube-controller-manager Update v1 2022-11-12 12:36:39 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b5d4adc3-8531-4b43-8907-40e14bfeeb6d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:36:40 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.215\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-45pc5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/pause:3.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-45pc5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:36:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.215,StartTime:2022-11-12 12:36:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:36:40 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/pause:3.8,ImageID:registry.k8s.io/pause@sha256:9001185023633d17a2f98ff69b6ff2615b8ea02a825adffa40422f51dfdcde9d,ContainerID:containerd://010465eb0d57cae9663e6bbddc162c47689f3f73bd30e84c86496a6359af9530,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.215,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 12:36:43.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-743" for this suite. 11/12/22 12:36:43.116
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:43.128
Nov 12 12:36:43.128: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:43.129
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:43.145
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:43.149
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 11/12/22 12:36:43.152
Nov 12 12:36:43.153: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8049 proxy --unix-socket=/tmp/kubectl-proxy-unix1366096498/test'
STEP: retrieving proxy /api/ output 11/12/22 12:36:43.23
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:36:43.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8049" for this suite. 11/12/22 12:36:43.238
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":174,"skipped":3271,"failed":0}
------------------------------
• [0.119 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:43.128
    Nov 12 12:36:43.128: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:43.129
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:43.145
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:43.149
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 11/12/22 12:36:43.152
    Nov 12 12:36:43.153: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-8049 proxy --unix-socket=/tmp/kubectl-proxy-unix1366096498/test'
    STEP: retrieving proxy /api/ output 11/12/22 12:36:43.23
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:36:43.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8049" for this suite. 11/12/22 12:36:43.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:43.248
Nov 12 12:36:43.248: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:43.249
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:43.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:43.273
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 11/12/22 12:36:43.277
Nov 12 12:36:43.277: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4565 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 11/12/22 12:36:43.363
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:36:43.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4565" for this suite. 11/12/22 12:36:43.378
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":175,"skipped":3290,"failed":0}
------------------------------
• [0.141 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:43.248
    Nov 12 12:36:43.248: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:36:43.249
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:43.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:43.273
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 11/12/22 12:36:43.277
    Nov 12 12:36:43.277: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4565 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 11/12/22 12:36:43.363
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:36:43.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4565" for this suite. 11/12/22 12:36:43.378
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:43.389
Nov 12 12:36:43.389: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replicaset 11/12/22 12:36:43.39
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:43.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:43.413
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/12/22 12:36:43.416
Nov 12 12:36:43.432: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8075" to be "running and ready"
Nov 12 12:36:43.441: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 9.109005ms
Nov 12 12:36:43.441: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:36:45.452: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.019840434s
Nov 12 12:36:45.452: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Nov 12 12:36:45.452: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 11/12/22 12:36:45.46
STEP: Then the orphan pod is adopted 11/12/22 12:36:45.467
STEP: When the matched label of one of its pods change 11/12/22 12:36:46.48
Nov 12 12:36:46.484: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 11/12/22 12:36:46.498
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 12:36:47.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8075" for this suite. 11/12/22 12:36:47.517
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":176,"skipped":3314,"failed":0}
------------------------------
• [4.139 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:43.389
    Nov 12 12:36:43.389: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replicaset 11/12/22 12:36:43.39
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:43.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:43.413
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/12/22 12:36:43.416
    Nov 12 12:36:43.432: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8075" to be "running and ready"
    Nov 12 12:36:43.441: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 9.109005ms
    Nov 12 12:36:43.441: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:36:45.452: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.019840434s
    Nov 12 12:36:45.452: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Nov 12 12:36:45.452: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 11/12/22 12:36:45.46
    STEP: Then the orphan pod is adopted 11/12/22 12:36:45.467
    STEP: When the matched label of one of its pods change 11/12/22 12:36:46.48
    Nov 12 12:36:46.484: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/12/22 12:36:46.498
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 12:36:47.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8075" for this suite. 11/12/22 12:36:47.517
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:47.529
Nov 12 12:36:47.529: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename gc 11/12/22 12:36:47.53
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:47.549
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:47.553
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 11/12/22 12:36:47.557
STEP: Wait for the Deployment to create new ReplicaSet 11/12/22 12:36:47.566
STEP: delete the deployment 11/12/22 12:36:48.078
STEP: wait for all rs to be garbage collected 11/12/22 12:36:48.089
STEP: expected 0 rs, got 1 rs 11/12/22 12:36:48.098
STEP: expected 0 pods, got 2 pods 11/12/22 12:36:48.105
STEP: Gathering metrics 11/12/22 12:36:48.626
W1112 12:36:48.635409      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 12:36:48.635: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 12:36:48.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8693" for this suite. 11/12/22 12:36:48.64
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":177,"skipped":3320,"failed":0}
------------------------------
• [1.124 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:47.529
    Nov 12 12:36:47.529: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename gc 11/12/22 12:36:47.53
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:47.549
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:47.553
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 11/12/22 12:36:47.557
    STEP: Wait for the Deployment to create new ReplicaSet 11/12/22 12:36:47.566
    STEP: delete the deployment 11/12/22 12:36:48.078
    STEP: wait for all rs to be garbage collected 11/12/22 12:36:48.089
    STEP: expected 0 rs, got 1 rs 11/12/22 12:36:48.098
    STEP: expected 0 pods, got 2 pods 11/12/22 12:36:48.105
    STEP: Gathering metrics 11/12/22 12:36:48.626
    W1112 12:36:48.635409      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 12:36:48.635: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 12:36:48.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8693" for this suite. 11/12/22 12:36:48.64
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:48.654
Nov 12 12:36:48.655: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 12:36:48.655
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:48.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:48.679
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 11/12/22 12:36:48.682
Nov 12 12:36:48.696: INFO: Waiting up to 5m0s for pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8" in namespace "var-expansion-8476" to be "Succeeded or Failed"
Nov 12 12:36:48.706: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.850562ms
Nov 12 12:36:50.712: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015772933s
Nov 12 12:36:52.712: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015614318s
STEP: Saw pod success 11/12/22 12:36:52.712
Nov 12 12:36:52.712: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8" satisfied condition "Succeeded or Failed"
Nov 12 12:36:52.717: INFO: Trying to get logs from node ip-172-31-89-190 pod var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8 container dapi-container: <nil>
STEP: delete the pod 11/12/22 12:36:52.731
Nov 12 12:36:52.747: INFO: Waiting for pod var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8 to disappear
Nov 12 12:36:52.752: INFO: Pod var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 12:36:52.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8476" for this suite. 11/12/22 12:36:52.756
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":178,"skipped":3334,"failed":0}
------------------------------
• [4.112 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:48.654
    Nov 12 12:36:48.655: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 12:36:48.655
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:48.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:48.679
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 11/12/22 12:36:48.682
    Nov 12 12:36:48.696: INFO: Waiting up to 5m0s for pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8" in namespace "var-expansion-8476" to be "Succeeded or Failed"
    Nov 12 12:36:48.706: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.850562ms
    Nov 12 12:36:50.712: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015772933s
    Nov 12 12:36:52.712: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015614318s
    STEP: Saw pod success 11/12/22 12:36:52.712
    Nov 12 12:36:52.712: INFO: Pod "var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8" satisfied condition "Succeeded or Failed"
    Nov 12 12:36:52.717: INFO: Trying to get logs from node ip-172-31-89-190 pod var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 12:36:52.731
    Nov 12 12:36:52.747: INFO: Waiting for pod var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8 to disappear
    Nov 12 12:36:52.752: INFO: Pod var-expansion-b0abb79f-8203-4429-8fa1-f983bd6079a8 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 12:36:52.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8476" for this suite. 11/12/22 12:36:52.756
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:36:52.769
Nov 12 12:36:52.769: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 12:36:52.77
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:52.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:52.793
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6782 11/12/22 12:36:52.796
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 11/12/22 12:36:52.802
STEP: Creating stateful set ss in namespace statefulset-6782 11/12/22 12:36:52.809
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6782 11/12/22 12:36:52.821
Nov 12 12:36:52.828: INFO: Found 0 stateful pods, waiting for 1
Nov 12 12:37:02.834: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/12/22 12:37:02.834
Nov 12 12:37:02.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:37:03.009: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:37:03.009: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:37:03.009: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:37:03.014: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 12 12:37:13.022: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:37:13.022: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:37:13.054: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999687s
Nov 12 12:37:14.060: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995565212s
Nov 12 12:37:15.067: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989047258s
Nov 12 12:37:16.072: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982419793s
Nov 12 12:37:17.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.976598757s
Nov 12 12:37:18.084: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.970250773s
Nov 12 12:37:19.091: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.965236117s
Nov 12 12:37:20.100: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.957155146s
Nov 12 12:37:21.105: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.94888486s
Nov 12 12:37:22.110: INFO: Verifying statefulset ss doesn't scale past 1 for another 944.306918ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6782 11/12/22 12:37:23.111
Nov 12 12:37:23.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:37:23.328: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 12 12:37:23.328: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:37:23.328: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 12:37:23.334: INFO: Found 1 stateful pods, waiting for 3
Nov 12 12:37:33.341: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:37:33.341: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:37:33.341: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 11/12/22 12:37:33.341
STEP: Scale down will halt with unhealthy stateful pod 11/12/22 12:37:33.341
Nov 12 12:37:33.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:37:33.500: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:37:33.500: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:37:33.500: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:37:33.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:37:33.658: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:37:33.658: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:37:33.658: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:37:33.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:37:33.824: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:37:33.824: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:37:33.824: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:37:33.824: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:37:33.828: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 12 12:37:43.841: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:37:43.841: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:37:43.841: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:37:43.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999672s
Nov 12 12:37:44.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995204597s
Nov 12 12:37:45.874: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98643999s
Nov 12 12:37:46.881: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981491612s
Nov 12 12:37:47.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974808368s
Nov 12 12:37:48.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.968608458s
Nov 12 12:37:49.898: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963141037s
Nov 12 12:37:50.904: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.956883747s
Nov 12 12:37:51.910: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.9503476s
Nov 12 12:37:52.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 944.436253ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6782 11/12/22 12:37:53.917
Nov 12 12:37:53.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:37:54.169: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 12 12:37:54.169: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:37:54.169: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 12:37:54.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:37:54.377: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 12 12:37:54.377: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:37:54.377: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 12:37:54.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:37:54.559: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 12 12:37:54.559: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:37:54.559: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 12:37:54.559: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 11/12/22 12:38:04.584
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 12:38:04.584: INFO: Deleting all statefulset in ns statefulset-6782
Nov 12 12:38:04.589: INFO: Scaling statefulset ss to 0
Nov 12 12:38:04.603: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:38:04.607: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 12:38:04.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6782" for this suite. 11/12/22 12:38:04.643
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":179,"skipped":3356,"failed":0}
------------------------------
• [SLOW TEST] [71.888 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:36:52.769
    Nov 12 12:36:52.769: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 12:36:52.77
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:36:52.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:36:52.793
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6782 11/12/22 12:36:52.796
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 11/12/22 12:36:52.802
    STEP: Creating stateful set ss in namespace statefulset-6782 11/12/22 12:36:52.809
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6782 11/12/22 12:36:52.821
    Nov 12 12:36:52.828: INFO: Found 0 stateful pods, waiting for 1
    Nov 12 12:37:02.834: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/12/22 12:37:02.834
    Nov 12 12:37:02.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:37:03.009: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:37:03.009: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:37:03.009: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:37:03.014: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 12 12:37:13.022: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:37:13.022: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:37:13.054: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999687s
    Nov 12 12:37:14.060: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995565212s
    Nov 12 12:37:15.067: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989047258s
    Nov 12 12:37:16.072: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.982419793s
    Nov 12 12:37:17.079: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.976598757s
    Nov 12 12:37:18.084: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.970250773s
    Nov 12 12:37:19.091: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.965236117s
    Nov 12 12:37:20.100: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.957155146s
    Nov 12 12:37:21.105: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.94888486s
    Nov 12 12:37:22.110: INFO: Verifying statefulset ss doesn't scale past 1 for another 944.306918ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6782 11/12/22 12:37:23.111
    Nov 12 12:37:23.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:37:23.328: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 12 12:37:23.328: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:37:23.328: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 12:37:23.334: INFO: Found 1 stateful pods, waiting for 3
    Nov 12 12:37:33.341: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:37:33.341: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:37:33.341: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 11/12/22 12:37:33.341
    STEP: Scale down will halt with unhealthy stateful pod 11/12/22 12:37:33.341
    Nov 12 12:37:33.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:37:33.500: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:37:33.500: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:37:33.500: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:37:33.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:37:33.658: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:37:33.658: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:37:33.658: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:37:33.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:37:33.824: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:37:33.824: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:37:33.824: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:37:33.824: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:37:33.828: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Nov 12 12:37:43.841: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:37:43.841: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:37:43.841: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:37:43.859: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999672s
    Nov 12 12:37:44.868: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995204597s
    Nov 12 12:37:45.874: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98643999s
    Nov 12 12:37:46.881: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981491612s
    Nov 12 12:37:47.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974808368s
    Nov 12 12:37:48.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.968608458s
    Nov 12 12:37:49.898: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963141037s
    Nov 12 12:37:50.904: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.956883747s
    Nov 12 12:37:51.910: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.9503476s
    Nov 12 12:37:52.917: INFO: Verifying statefulset ss doesn't scale past 3 for another 944.436253ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6782 11/12/22 12:37:53.917
    Nov 12 12:37:53.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:37:54.169: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 12 12:37:54.169: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:37:54.169: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 12:37:54.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:37:54.377: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 12 12:37:54.377: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:37:54.377: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 12:37:54.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-6782 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:37:54.559: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 12 12:37:54.559: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:37:54.559: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 12:37:54.559: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 11/12/22 12:38:04.584
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 12:38:04.584: INFO: Deleting all statefulset in ns statefulset-6782
    Nov 12 12:38:04.589: INFO: Scaling statefulset ss to 0
    Nov 12 12:38:04.603: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:38:04.607: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 12:38:04.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6782" for this suite. 11/12/22 12:38:04.643
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:38:04.659
Nov 12 12:38:04.659: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename daemonsets 11/12/22 12:38:04.66
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:04.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:04.695
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 11/12/22 12:38:04.726
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:38:04.735
Nov 12 12:38:04.747: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:04.747: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:04.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:38:04.751: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:38:05.757: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:05.757: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:05.764: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:38:05.764: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:38:06.757: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:06.757: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:06.762: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 12 12:38:06.762: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:38:07.757: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:07.758: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:07.763: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 12:38:07.763: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/12/22 12:38:07.768
Nov 12 12:38:07.798: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:07.798: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:07.805: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:38:07.805: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:38:08.816: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:08.816: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:08.823: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:38:08.823: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:38:09.813: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:09.813: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:38:09.818: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 12:38:09.818: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 11/12/22 12:38:09.818
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:38:09.826
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7061, will wait for the garbage collector to delete the pods 11/12/22 12:38:09.826
Nov 12 12:38:09.911: INFO: Deleting DaemonSet.extensions daemon-set took: 30.844039ms
Nov 12 12:38:10.012: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.785016ms
Nov 12 12:38:12.519: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:38:12.519: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 12 12:38:12.524: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20997"},"items":null}

Nov 12 12:38:12.528: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20997"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:38:12.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7061" for this suite. 11/12/22 12:38:12.563
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":180,"skipped":3383,"failed":0}
------------------------------
• [SLOW TEST] [7.914 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:38:04.659
    Nov 12 12:38:04.659: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename daemonsets 11/12/22 12:38:04.66
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:04.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:04.695
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 11/12/22 12:38:04.726
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:38:04.735
    Nov 12 12:38:04.747: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:04.747: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:04.751: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:38:04.751: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:38:05.757: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:05.757: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:05.764: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:38:05.764: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:38:06.757: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:06.757: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:06.762: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 12 12:38:06.762: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:38:07.757: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:07.758: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:07.763: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 12:38:07.763: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/12/22 12:38:07.768
    Nov 12 12:38:07.798: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:07.798: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:07.805: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:38:07.805: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:38:08.816: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:08.816: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:08.823: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:38:08.823: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:38:09.813: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:09.813: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:38:09.818: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 12:38:09.818: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 11/12/22 12:38:09.818
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/12/22 12:38:09.826
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7061, will wait for the garbage collector to delete the pods 11/12/22 12:38:09.826
    Nov 12 12:38:09.911: INFO: Deleting DaemonSet.extensions daemon-set took: 30.844039ms
    Nov 12 12:38:10.012: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.785016ms
    Nov 12 12:38:12.519: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:38:12.519: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 12 12:38:12.524: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"20997"},"items":null}

    Nov 12 12:38:12.528: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"20997"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:38:12.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7061" for this suite. 11/12/22 12:38:12.563
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:38:12.576
Nov 12 12:38:12.576: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 12:38:12.577
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:12.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:12.606
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 11/12/22 12:38:12.613
Nov 12 12:38:12.626: INFO: Waiting up to 5m0s for pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966" in namespace "pods-1613" to be "running and ready"
Nov 12 12:38:12.644: INFO: Pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966": Phase="Pending", Reason="", readiness=false. Elapsed: 17.308584ms
Nov 12 12:38:12.644: INFO: The phase of Pod pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:38:14.650: INFO: Pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966": Phase="Running", Reason="", readiness=true. Elapsed: 2.023223942s
Nov 12 12:38:14.650: INFO: The phase of Pod pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966 is Running (Ready = true)
Nov 12 12:38:14.650: INFO: Pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966" satisfied condition "running and ready"
Nov 12 12:38:14.658: INFO: Pod pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966 has hostIP: 172.31.14.110
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 12:38:14.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1613" for this suite. 11/12/22 12:38:14.663
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":181,"skipped":3391,"failed":0}
------------------------------
• [2.095 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:38:12.576
    Nov 12 12:38:12.576: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 12:38:12.577
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:12.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:12.606
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 11/12/22 12:38:12.613
    Nov 12 12:38:12.626: INFO: Waiting up to 5m0s for pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966" in namespace "pods-1613" to be "running and ready"
    Nov 12 12:38:12.644: INFO: Pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966": Phase="Pending", Reason="", readiness=false. Elapsed: 17.308584ms
    Nov 12 12:38:12.644: INFO: The phase of Pod pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:38:14.650: INFO: Pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966": Phase="Running", Reason="", readiness=true. Elapsed: 2.023223942s
    Nov 12 12:38:14.650: INFO: The phase of Pod pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966 is Running (Ready = true)
    Nov 12 12:38:14.650: INFO: Pod "pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966" satisfied condition "running and ready"
    Nov 12 12:38:14.658: INFO: Pod pod-hostip-0a5c0893-e535-4f14-8fe6-a90aa74b4966 has hostIP: 172.31.14.110
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 12:38:14.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1613" for this suite. 11/12/22 12:38:14.663
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:38:14.673
Nov 12 12:38:14.673: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename gc 11/12/22 12:38:14.674
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:14.697
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:14.703
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 11/12/22 12:38:14.711
STEP: delete the rc 11/12/22 12:38:19.727
STEP: wait for the rc to be deleted 11/12/22 12:38:19.743
Nov 12 12:38:20.768: INFO: 80 pods remaining
Nov 12 12:38:20.769: INFO: 80 pods has nil DeletionTimestamp
Nov 12 12:38:20.769: INFO: 
Nov 12 12:38:21.770: INFO: 75 pods remaining
Nov 12 12:38:21.771: INFO: 72 pods has nil DeletionTimestamp
Nov 12 12:38:21.771: INFO: 
Nov 12 12:38:22.762: INFO: 59 pods remaining
Nov 12 12:38:22.762: INFO: 59 pods has nil DeletionTimestamp
Nov 12 12:38:22.762: INFO: 
Nov 12 12:38:23.765: INFO: 40 pods remaining
Nov 12 12:38:23.765: INFO: 40 pods has nil DeletionTimestamp
Nov 12 12:38:23.765: INFO: 
Nov 12 12:38:24.755: INFO: 33 pods remaining
Nov 12 12:38:24.755: INFO: 33 pods has nil DeletionTimestamp
Nov 12 12:38:24.755: INFO: 
Nov 12 12:38:25.760: INFO: 19 pods remaining
Nov 12 12:38:25.760: INFO: 19 pods has nil DeletionTimestamp
Nov 12 12:38:25.760: INFO: 
STEP: Gathering metrics 11/12/22 12:38:26.757
W1112 12:38:26.762977      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 12:38:26.763: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 12:38:26.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8814" for this suite. 11/12/22 12:38:26.767
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":182,"skipped":3404,"failed":0}
------------------------------
• [SLOW TEST] [12.102 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:38:14.673
    Nov 12 12:38:14.673: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename gc 11/12/22 12:38:14.674
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:14.697
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:14.703
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 11/12/22 12:38:14.711
    STEP: delete the rc 11/12/22 12:38:19.727
    STEP: wait for the rc to be deleted 11/12/22 12:38:19.743
    Nov 12 12:38:20.768: INFO: 80 pods remaining
    Nov 12 12:38:20.769: INFO: 80 pods has nil DeletionTimestamp
    Nov 12 12:38:20.769: INFO: 
    Nov 12 12:38:21.770: INFO: 75 pods remaining
    Nov 12 12:38:21.771: INFO: 72 pods has nil DeletionTimestamp
    Nov 12 12:38:21.771: INFO: 
    Nov 12 12:38:22.762: INFO: 59 pods remaining
    Nov 12 12:38:22.762: INFO: 59 pods has nil DeletionTimestamp
    Nov 12 12:38:22.762: INFO: 
    Nov 12 12:38:23.765: INFO: 40 pods remaining
    Nov 12 12:38:23.765: INFO: 40 pods has nil DeletionTimestamp
    Nov 12 12:38:23.765: INFO: 
    Nov 12 12:38:24.755: INFO: 33 pods remaining
    Nov 12 12:38:24.755: INFO: 33 pods has nil DeletionTimestamp
    Nov 12 12:38:24.755: INFO: 
    Nov 12 12:38:25.760: INFO: 19 pods remaining
    Nov 12 12:38:25.760: INFO: 19 pods has nil DeletionTimestamp
    Nov 12 12:38:25.760: INFO: 
    STEP: Gathering metrics 11/12/22 12:38:26.757
    W1112 12:38:26.762977      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 12:38:26.763: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 12:38:26.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8814" for this suite. 11/12/22 12:38:26.767
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:38:26.778
Nov 12 12:38:26.778: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 12:38:26.779
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:26.799
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:26.806
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 11/12/22 12:38:26.808
STEP: listing secrets in all namespaces to ensure that there are more than zero 11/12/22 12:38:26.815
STEP: patching the secret 11/12/22 12:38:26.819
STEP: deleting the secret using a LabelSelector 11/12/22 12:38:26.833
STEP: listing secrets in all namespaces, searching for label name and value in patch 11/12/22 12:38:26.844
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 12 12:38:26.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8524" for this suite. 11/12/22 12:38:26.854
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":183,"skipped":3422,"failed":0}
------------------------------
• [0.085 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:38:26.778
    Nov 12 12:38:26.778: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 12:38:26.779
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:26.799
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:26.806
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 11/12/22 12:38:26.808
    STEP: listing secrets in all namespaces to ensure that there are more than zero 11/12/22 12:38:26.815
    STEP: patching the secret 11/12/22 12:38:26.819
    STEP: deleting the secret using a LabelSelector 11/12/22 12:38:26.833
    STEP: listing secrets in all namespaces, searching for label name and value in patch 11/12/22 12:38:26.844
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 12:38:26.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8524" for this suite. 11/12/22 12:38:26.854
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:38:26.863
Nov 12 12:38:26.863: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:38:26.864
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:26.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:26.883
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:38:26.904
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:38:27.645
STEP: Deploying the webhook pod 11/12/22 12:38:27.66
STEP: Wait for the deployment to be ready 11/12/22 12:38:27.681
Nov 12 12:38:27.696: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 12 12:38:29.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:38:31.747: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 12:38:33.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/12/22 12:38:35.718
STEP: Verifying the service has paired with the endpoint 11/12/22 12:38:35.732
Nov 12 12:38:36.733: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/12/22 12:38:36.738
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/12/22 12:38:36.755
STEP: Creating a dummy validating-webhook-configuration object 11/12/22 12:38:36.777
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/12/22 12:38:36.795
STEP: Creating a dummy mutating-webhook-configuration object 11/12/22 12:38:36.803
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/12/22 12:38:36.814
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:38:36.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2000" for this suite. 11/12/22 12:38:36.859
STEP: Destroying namespace "webhook-2000-markers" for this suite. 11/12/22 12:38:36.868
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":184,"skipped":3423,"failed":0}
------------------------------
• [SLOW TEST] [10.083 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:38:26.863
    Nov 12 12:38:26.863: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:38:26.864
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:26.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:26.883
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:38:26.904
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:38:27.645
    STEP: Deploying the webhook pod 11/12/22 12:38:27.66
    STEP: Wait for the deployment to be ready 11/12/22 12:38:27.681
    Nov 12 12:38:27.696: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 12 12:38:29.711: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:38:31.747: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 12:38:33.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 38, 27, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/12/22 12:38:35.718
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:38:35.732
    Nov 12 12:38:36.733: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/12/22 12:38:36.738
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/12/22 12:38:36.755
    STEP: Creating a dummy validating-webhook-configuration object 11/12/22 12:38:36.777
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/12/22 12:38:36.795
    STEP: Creating a dummy mutating-webhook-configuration object 11/12/22 12:38:36.803
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/12/22 12:38:36.814
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:38:36.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2000" for this suite. 11/12/22 12:38:36.859
    STEP: Destroying namespace "webhook-2000-markers" for this suite. 11/12/22 12:38:36.868
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:38:36.946
Nov 12 12:38:36.946: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 12:38:36.947
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:36.975
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:36.978
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-c0480eb0-975f-4cb9-a994-0f5a5201b52e 11/12/22 12:38:36.989
STEP: Creating a pod to test consume secrets 11/12/22 12:38:36.997
Nov 12 12:38:37.007: INFO: Waiting up to 5m0s for pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431" in namespace "secrets-198" to be "Succeeded or Failed"
Nov 12 12:38:37.017: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Pending", Reason="", readiness=false. Elapsed: 9.497677ms
Nov 12 12:38:39.022: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014919589s
Nov 12 12:38:41.022: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014138412s
Nov 12 12:38:43.025: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017671601s
STEP: Saw pod success 11/12/22 12:38:43.025
Nov 12 12:38:43.025: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431" satisfied condition "Succeeded or Failed"
Nov 12 12:38:43.030: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 12:38:43.046
Nov 12 12:38:43.062: INFO: Waiting for pod pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431 to disappear
Nov 12 12:38:43.067: INFO: Pod pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 12:38:43.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-198" for this suite. 11/12/22 12:38:43.072
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":185,"skipped":3423,"failed":0}
------------------------------
• [SLOW TEST] [6.135 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:38:36.946
    Nov 12 12:38:36.946: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 12:38:36.947
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:36.975
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:36.978
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-c0480eb0-975f-4cb9-a994-0f5a5201b52e 11/12/22 12:38:36.989
    STEP: Creating a pod to test consume secrets 11/12/22 12:38:36.997
    Nov 12 12:38:37.007: INFO: Waiting up to 5m0s for pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431" in namespace "secrets-198" to be "Succeeded or Failed"
    Nov 12 12:38:37.017: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Pending", Reason="", readiness=false. Elapsed: 9.497677ms
    Nov 12 12:38:39.022: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014919589s
    Nov 12 12:38:41.022: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014138412s
    Nov 12 12:38:43.025: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.017671601s
    STEP: Saw pod success 11/12/22 12:38:43.025
    Nov 12 12:38:43.025: INFO: Pod "pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431" satisfied condition "Succeeded or Failed"
    Nov 12 12:38:43.030: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:38:43.046
    Nov 12 12:38:43.062: INFO: Waiting for pod pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431 to disappear
    Nov 12 12:38:43.067: INFO: Pod pod-secrets-95163cc5-14ab-4201-a784-2746aaddb431 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 12:38:43.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-198" for this suite. 11/12/22 12:38:43.072
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:38:43.083
Nov 12 12:38:43.083: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 12:38:43.085
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:43.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:43.106
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-160 11/12/22 12:38:43.11
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Nov 12 12:38:43.138: INFO: Found 0 stateful pods, waiting for 1
Nov 12 12:38:53.146: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 11/12/22 12:38:53.153
W1112 12:38:53.166143      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 12 12:38:53.181: INFO: Found 1 stateful pods, waiting for 2
Nov 12 12:39:03.190: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:39:03.190: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 11/12/22 12:39:03.199
STEP: Delete all of the StatefulSets 11/12/22 12:39:03.21
STEP: Verify that StatefulSets have been deleted 11/12/22 12:39:03.224
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 12:39:03.232: INFO: Deleting all statefulset in ns statefulset-160
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 12:39:03.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-160" for this suite. 11/12/22 12:39:03.289
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":186,"skipped":3439,"failed":0}
------------------------------
• [SLOW TEST] [20.225 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:38:43.083
    Nov 12 12:38:43.083: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 12:38:43.085
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:38:43.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:38:43.106
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-160 11/12/22 12:38:43.11
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Nov 12 12:38:43.138: INFO: Found 0 stateful pods, waiting for 1
    Nov 12 12:38:53.146: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 11/12/22 12:38:53.153
    W1112 12:38:53.166143      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 12 12:38:53.181: INFO: Found 1 stateful pods, waiting for 2
    Nov 12 12:39:03.190: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:39:03.190: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 11/12/22 12:39:03.199
    STEP: Delete all of the StatefulSets 11/12/22 12:39:03.21
    STEP: Verify that StatefulSets have been deleted 11/12/22 12:39:03.224
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 12:39:03.232: INFO: Deleting all statefulset in ns statefulset-160
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 12:39:03.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-160" for this suite. 11/12/22 12:39:03.289
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:03.31
Nov 12 12:39:03.310: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename csistoragecapacity 11/12/22 12:39:03.313
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:03.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:03.361
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 11/12/22 12:39:03.373
STEP: getting /apis/storage.k8s.io 11/12/22 12:39:03.388
STEP: getting /apis/storage.k8s.io/v1 11/12/22 12:39:03.395
STEP: creating 11/12/22 12:39:03.4
STEP: watching 11/12/22 12:39:03.462
Nov 12 12:39:03.462: INFO: starting watch
STEP: getting 11/12/22 12:39:03.473
STEP: listing in namespace 11/12/22 12:39:03.48
STEP: listing across namespaces 11/12/22 12:39:03.485
STEP: patching 11/12/22 12:39:03.491
STEP: updating 11/12/22 12:39:03.5
Nov 12 12:39:03.509: INFO: waiting for watch events with expected annotations in namespace
Nov 12 12:39:03.509: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 11/12/22 12:39:03.509
STEP: deleting a collection 11/12/22 12:39:03.526
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Nov 12 12:39:03.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-7582" for this suite. 11/12/22 12:39:03.561
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":187,"skipped":3444,"failed":0}
------------------------------
• [0.269 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:03.31
    Nov 12 12:39:03.310: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename csistoragecapacity 11/12/22 12:39:03.313
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:03.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:03.361
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 11/12/22 12:39:03.373
    STEP: getting /apis/storage.k8s.io 11/12/22 12:39:03.388
    STEP: getting /apis/storage.k8s.io/v1 11/12/22 12:39:03.395
    STEP: creating 11/12/22 12:39:03.4
    STEP: watching 11/12/22 12:39:03.462
    Nov 12 12:39:03.462: INFO: starting watch
    STEP: getting 11/12/22 12:39:03.473
    STEP: listing in namespace 11/12/22 12:39:03.48
    STEP: listing across namespaces 11/12/22 12:39:03.485
    STEP: patching 11/12/22 12:39:03.491
    STEP: updating 11/12/22 12:39:03.5
    Nov 12 12:39:03.509: INFO: waiting for watch events with expected annotations in namespace
    Nov 12 12:39:03.509: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 11/12/22 12:39:03.509
    STEP: deleting a collection 11/12/22 12:39:03.526
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Nov 12 12:39:03.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-7582" for this suite. 11/12/22 12:39:03.561
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:03.582
Nov 12 12:39:03.582: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:39:03.583
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:03.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:03.615
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-6942 11/12/22 12:39:03.618
STEP: creating a selector 11/12/22 12:39:03.618
STEP: Creating the service pods in kubernetes 11/12/22 12:39:03.618
Nov 12 12:39:03.618: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 12 12:39:03.668: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6942" to be "running and ready"
Nov 12 12:39:03.680: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.197428ms
Nov 12 12:39:03.680: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:39:05.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018004277s
Nov 12 12:39:05.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:07.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017605805s
Nov 12 12:39:07.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:09.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017033662s
Nov 12 12:39:09.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:11.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.016584717s
Nov 12 12:39:11.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:13.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.01630909s
Nov 12 12:39:13.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:15.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.016572909s
Nov 12 12:39:15.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:17.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.016470341s
Nov 12 12:39:17.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:19.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.01661323s
Nov 12 12:39:19.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:21.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.016193968s
Nov 12 12:39:21.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:23.684: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.015957896s
Nov 12 12:39:23.684: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:39:25.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.017387011s
Nov 12 12:39:25.686: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 12 12:39:25.686: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 12 12:39:25.691: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6942" to be "running and ready"
Nov 12 12:39:25.695: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.85958ms
Nov 12 12:39:25.696: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 12 12:39:25.696: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 12 12:39:25.700: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6942" to be "running and ready"
Nov 12 12:39:25.704: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.528211ms
Nov 12 12:39:25.704: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 12 12:39:25.704: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/12/22 12:39:25.708
Nov 12 12:39:25.721: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6942" to be "running"
Nov 12 12:39:25.727: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.847057ms
Nov 12 12:39:27.733: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011705427s
Nov 12 12:39:27.733: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 12 12:39:27.737: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6942" to be "running"
Nov 12 12:39:27.742: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.76578ms
Nov 12 12:39:27.742: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 12 12:39:27.746: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 12 12:39:27.746: INFO: Going to poll 192.168.249.21 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 12 12:39:27.750: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.249.21 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6942 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:39:27.750: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:39:27.751: INFO: ExecWithOptions: Clientset creation
Nov 12 12:39:27.751: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6942/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.249.21+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 12:39:28.837: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 12 12:39:28.837: INFO: Going to poll 192.168.27.89 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 12 12:39:28.843: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.27.89 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6942 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:39:28.843: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:39:28.843: INFO: ExecWithOptions: Clientset creation
Nov 12 12:39:28.843: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6942/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.27.89+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 12:39:29.924: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 12 12:39:29.925: INFO: Going to poll 192.168.128.247 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 12 12:39:29.930: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.128.247 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6942 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:39:29.930: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:39:29.931: INFO: ExecWithOptions: Clientset creation
Nov 12 12:39:29.931: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6942/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.128.247+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 12 12:39:31.014: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 12 12:39:31.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6942" for this suite. 11/12/22 12:39:31.021
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":188,"skipped":3470,"failed":0}
------------------------------
• [SLOW TEST] [27.449 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:03.582
    Nov 12 12:39:03.582: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:39:03.583
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:03.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:03.615
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-6942 11/12/22 12:39:03.618
    STEP: creating a selector 11/12/22 12:39:03.618
    STEP: Creating the service pods in kubernetes 11/12/22 12:39:03.618
    Nov 12 12:39:03.618: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 12 12:39:03.668: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6942" to be "running and ready"
    Nov 12 12:39:03.680: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.197428ms
    Nov 12 12:39:03.680: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:39:05.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018004277s
    Nov 12 12:39:05.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:07.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017605805s
    Nov 12 12:39:07.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:09.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017033662s
    Nov 12 12:39:09.686: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:11.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.016584717s
    Nov 12 12:39:11.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:13.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.01630909s
    Nov 12 12:39:13.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:15.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.016572909s
    Nov 12 12:39:15.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:17.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.016470341s
    Nov 12 12:39:17.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:19.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.01661323s
    Nov 12 12:39:19.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:21.685: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.016193968s
    Nov 12 12:39:21.685: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:23.684: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.015957896s
    Nov 12 12:39:23.684: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:39:25.686: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.017387011s
    Nov 12 12:39:25.686: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 12 12:39:25.686: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 12 12:39:25.691: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6942" to be "running and ready"
    Nov 12 12:39:25.695: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.85958ms
    Nov 12 12:39:25.696: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 12 12:39:25.696: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 12 12:39:25.700: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6942" to be "running and ready"
    Nov 12 12:39:25.704: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.528211ms
    Nov 12 12:39:25.704: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 12 12:39:25.704: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/12/22 12:39:25.708
    Nov 12 12:39:25.721: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6942" to be "running"
    Nov 12 12:39:25.727: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.847057ms
    Nov 12 12:39:27.733: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011705427s
    Nov 12 12:39:27.733: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 12 12:39:27.737: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-6942" to be "running"
    Nov 12 12:39:27.742: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.76578ms
    Nov 12 12:39:27.742: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 12 12:39:27.746: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 12 12:39:27.746: INFO: Going to poll 192.168.249.21 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 12:39:27.750: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.249.21 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6942 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:39:27.750: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:39:27.751: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:39:27.751: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6942/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.249.21+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 12:39:28.837: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 12 12:39:28.837: INFO: Going to poll 192.168.27.89 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 12:39:28.843: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.27.89 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6942 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:39:28.843: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:39:28.843: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:39:28.843: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6942/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.27.89+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 12:39:29.924: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 12 12:39:29.925: INFO: Going to poll 192.168.128.247 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 12 12:39:29.930: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.128.247 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6942 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:39:29.930: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:39:29.931: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:39:29.931: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6942/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.128.247+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 12 12:39:31.014: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 12 12:39:31.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6942" for this suite. 11/12/22 12:39:31.021
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:31.031
Nov 12 12:39:31.031: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename hostport 11/12/22 12:39:31.032
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:31.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:31.055
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/12/22 12:39:31.065
Nov 12 12:39:31.080: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-2342" to be "running and ready"
Nov 12 12:39:31.086: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.678841ms
Nov 12 12:39:31.086: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:39:33.093: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012398436s
Nov 12 12:39:33.093: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 12 12:39:33.093: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.47.219 on the node which pod1 resides and expect scheduled 11/12/22 12:39:33.093
Nov 12 12:39:33.103: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-2342" to be "running and ready"
Nov 12 12:39:33.108: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.647931ms
Nov 12 12:39:33.109: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:39:35.115: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.011569026s
Nov 12 12:39:35.115: INFO: The phase of Pod pod2 is Running (Ready = false)
Nov 12 12:39:37.118: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.014690241s
Nov 12 12:39:37.118: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 12 12:39:37.118: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.47.219 but use UDP protocol on the node which pod2 resides 11/12/22 12:39:37.118
Nov 12 12:39:37.125: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-2342" to be "running and ready"
Nov 12 12:39:37.131: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.297791ms
Nov 12 12:39:37.131: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:39:39.137: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.01157118s
Nov 12 12:39:39.137: INFO: The phase of Pod pod3 is Running (Ready = true)
Nov 12 12:39:39.137: INFO: Pod "pod3" satisfied condition "running and ready"
Nov 12 12:39:39.144: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-2342" to be "running and ready"
Nov 12 12:39:39.148: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.193723ms
Nov 12 12:39:39.148: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:39:41.153: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.009041642s
Nov 12 12:39:41.153: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Nov 12 12:39:41.153: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/12/22 12:39:41.157
Nov 12 12:39:41.158: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.47.219 http://127.0.0.1:54323/hostname] Namespace:hostport-2342 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:39:41.158: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:39:41.158: INFO: ExecWithOptions: Clientset creation
Nov 12 12:39:41.158: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2342/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.47.219+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.47.219, port: 54323 11/12/22 12:39:41.243
Nov 12 12:39:41.243: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.47.219:54323/hostname] Namespace:hostport-2342 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:39:41.243: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:39:41.244: INFO: ExecWithOptions: Clientset creation
Nov 12 12:39:41.244: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2342/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.47.219%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.47.219, port: 54323 UDP 11/12/22 12:39:41.327
Nov 12 12:39:41.327: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.47.219 54323] Namespace:hostport-2342 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:39:41.327: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:39:41.328: INFO: ExecWithOptions: Clientset creation
Nov 12 12:39:41.328: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2342/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.47.219+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Nov 12 12:39:46.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-2342" for this suite. 11/12/22 12:39:46.43
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":189,"skipped":3481,"failed":0}
------------------------------
• [SLOW TEST] [15.408 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:31.031
    Nov 12 12:39:31.031: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename hostport 11/12/22 12:39:31.032
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:31.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:31.055
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/12/22 12:39:31.065
    Nov 12 12:39:31.080: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-2342" to be "running and ready"
    Nov 12 12:39:31.086: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.678841ms
    Nov 12 12:39:31.086: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:39:33.093: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012398436s
    Nov 12 12:39:33.093: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 12 12:39:33.093: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.47.219 on the node which pod1 resides and expect scheduled 11/12/22 12:39:33.093
    Nov 12 12:39:33.103: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-2342" to be "running and ready"
    Nov 12 12:39:33.108: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.647931ms
    Nov 12 12:39:33.109: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:39:35.115: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.011569026s
    Nov 12 12:39:35.115: INFO: The phase of Pod pod2 is Running (Ready = false)
    Nov 12 12:39:37.118: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.014690241s
    Nov 12 12:39:37.118: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 12 12:39:37.118: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.47.219 but use UDP protocol on the node which pod2 resides 11/12/22 12:39:37.118
    Nov 12 12:39:37.125: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-2342" to be "running and ready"
    Nov 12 12:39:37.131: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.297791ms
    Nov 12 12:39:37.131: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:39:39.137: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.01157118s
    Nov 12 12:39:39.137: INFO: The phase of Pod pod3 is Running (Ready = true)
    Nov 12 12:39:39.137: INFO: Pod "pod3" satisfied condition "running and ready"
    Nov 12 12:39:39.144: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-2342" to be "running and ready"
    Nov 12 12:39:39.148: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.193723ms
    Nov 12 12:39:39.148: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:39:41.153: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.009041642s
    Nov 12 12:39:41.153: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Nov 12 12:39:41.153: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/12/22 12:39:41.157
    Nov 12 12:39:41.158: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.47.219 http://127.0.0.1:54323/hostname] Namespace:hostport-2342 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:39:41.158: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:39:41.158: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:39:41.158: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2342/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.47.219+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.47.219, port: 54323 11/12/22 12:39:41.243
    Nov 12 12:39:41.243: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.47.219:54323/hostname] Namespace:hostport-2342 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:39:41.243: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:39:41.244: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:39:41.244: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2342/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.47.219%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.47.219, port: 54323 UDP 11/12/22 12:39:41.327
    Nov 12 12:39:41.327: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.47.219 54323] Namespace:hostport-2342 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:39:41.327: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:39:41.328: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:39:41.328: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2342/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.47.219+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Nov 12 12:39:46.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-2342" for this suite. 11/12/22 12:39:46.43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:46.441
Nov 12 12:39:46.441: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename watch 11/12/22 12:39:46.442
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:46.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:46.476
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 11/12/22 12:39:46.479
STEP: modifying the configmap once 11/12/22 12:39:46.575
STEP: modifying the configmap a second time 11/12/22 12:39:46.586
STEP: deleting the configmap 11/12/22 12:39:46.6
STEP: creating a watch on configmaps from the resource version returned by the first update 11/12/22 12:39:46.609
STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/12/22 12:39:46.612
Nov 12 12:39:46.612: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4210  4b0cce2c-66cc-4b70-8150-5fbe74a02697 23328 0 2022-11-12 12:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 12:39:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 12 12:39:46.612: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4210  4b0cce2c-66cc-4b70-8150-5fbe74a02697 23329 0 2022-11-12 12:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 12:39:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 12 12:39:46.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4210" for this suite. 11/12/22 12:39:46.617
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":190,"skipped":3491,"failed":0}
------------------------------
• [0.186 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:46.441
    Nov 12 12:39:46.441: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename watch 11/12/22 12:39:46.442
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:46.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:46.476
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 11/12/22 12:39:46.479
    STEP: modifying the configmap once 11/12/22 12:39:46.575
    STEP: modifying the configmap a second time 11/12/22 12:39:46.586
    STEP: deleting the configmap 11/12/22 12:39:46.6
    STEP: creating a watch on configmaps from the resource version returned by the first update 11/12/22 12:39:46.609
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/12/22 12:39:46.612
    Nov 12 12:39:46.612: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4210  4b0cce2c-66cc-4b70-8150-5fbe74a02697 23328 0 2022-11-12 12:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 12:39:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 12 12:39:46.612: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4210  4b0cce2c-66cc-4b70-8150-5fbe74a02697 23329 0 2022-11-12 12:39:46 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-12 12:39:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 12 12:39:46.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4210" for this suite. 11/12/22 12:39:46.617
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:46.628
Nov 12 12:39:46.628: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 12:39:46.629
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:46.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:46.656
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 11/12/22 12:39:46.658
Nov 12 12:39:46.673: INFO: Waiting up to 5m0s for pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441" in namespace "downward-api-3966" to be "Succeeded or Failed"
Nov 12 12:39:46.678: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441": Phase="Pending", Reason="", readiness=false. Elapsed: 5.626953ms
Nov 12 12:39:48.685: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012232994s
Nov 12 12:39:50.693: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020593125s
STEP: Saw pod success 11/12/22 12:39:50.693
Nov 12 12:39:50.693: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441" satisfied condition "Succeeded or Failed"
Nov 12 12:39:50.697: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-e1ae5492-e854-460a-8328-29e5919d6441 container dapi-container: <nil>
STEP: delete the pod 11/12/22 12:39:50.708
Nov 12 12:39:50.728: INFO: Waiting for pod downward-api-e1ae5492-e854-460a-8328-29e5919d6441 to disappear
Nov 12 12:39:50.731: INFO: Pod downward-api-e1ae5492-e854-460a-8328-29e5919d6441 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 12 12:39:50.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3966" for this suite. 11/12/22 12:39:50.737
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":191,"skipped":3501,"failed":0}
------------------------------
• [4.119 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:46.628
    Nov 12 12:39:46.628: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 12:39:46.629
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:46.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:46.656
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 11/12/22 12:39:46.658
    Nov 12 12:39:46.673: INFO: Waiting up to 5m0s for pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441" in namespace "downward-api-3966" to be "Succeeded or Failed"
    Nov 12 12:39:46.678: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441": Phase="Pending", Reason="", readiness=false. Elapsed: 5.626953ms
    Nov 12 12:39:48.685: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012232994s
    Nov 12 12:39:50.693: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020593125s
    STEP: Saw pod success 11/12/22 12:39:50.693
    Nov 12 12:39:50.693: INFO: Pod "downward-api-e1ae5492-e854-460a-8328-29e5919d6441" satisfied condition "Succeeded or Failed"
    Nov 12 12:39:50.697: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-e1ae5492-e854-460a-8328-29e5919d6441 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 12:39:50.708
    Nov 12 12:39:50.728: INFO: Waiting for pod downward-api-e1ae5492-e854-460a-8328-29e5919d6441 to disappear
    Nov 12 12:39:50.731: INFO: Pod downward-api-e1ae5492-e854-460a-8328-29e5919d6441 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 12 12:39:50.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3966" for this suite. 11/12/22 12:39:50.737
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:50.749
Nov 12 12:39:50.750: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 12:39:50.751
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:50.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:50.774
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-a9b6afb1-e25f-4498-a95c-f5cf6b85d1f7 11/12/22 12:39:50.777
STEP: Creating a pod to test consume configMaps 11/12/22 12:39:50.784
Nov 12 12:39:50.795: INFO: Waiting up to 5m0s for pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200" in namespace "configmap-8170" to be "Succeeded or Failed"
Nov 12 12:39:50.802: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200": Phase="Pending", Reason="", readiness=false. Elapsed: 7.54617ms
Nov 12 12:39:52.808: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013388906s
Nov 12 12:39:54.810: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014868803s
STEP: Saw pod success 11/12/22 12:39:54.81
Nov 12 12:39:54.810: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200" satisfied condition "Succeeded or Failed"
Nov 12 12:39:54.814: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 12:39:54.827
Nov 12 12:39:54.847: INFO: Waiting for pod pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200 to disappear
Nov 12 12:39:54.851: INFO: Pod pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 12:39:54.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8170" for this suite. 11/12/22 12:39:54.858
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":192,"skipped":3509,"failed":0}
------------------------------
• [4.119 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:50.749
    Nov 12 12:39:50.750: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 12:39:50.751
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:50.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:50.774
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-a9b6afb1-e25f-4498-a95c-f5cf6b85d1f7 11/12/22 12:39:50.777
    STEP: Creating a pod to test consume configMaps 11/12/22 12:39:50.784
    Nov 12 12:39:50.795: INFO: Waiting up to 5m0s for pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200" in namespace "configmap-8170" to be "Succeeded or Failed"
    Nov 12 12:39:50.802: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200": Phase="Pending", Reason="", readiness=false. Elapsed: 7.54617ms
    Nov 12 12:39:52.808: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013388906s
    Nov 12 12:39:54.810: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014868803s
    STEP: Saw pod success 11/12/22 12:39:54.81
    Nov 12 12:39:54.810: INFO: Pod "pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200" satisfied condition "Succeeded or Failed"
    Nov 12 12:39:54.814: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 12:39:54.827
    Nov 12 12:39:54.847: INFO: Waiting for pod pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200 to disappear
    Nov 12 12:39:54.851: INFO: Pod pod-configmaps-e123667c-73f8-48ca-b798-b7631ec08200 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 12:39:54.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8170" for this suite. 11/12/22 12:39:54.858
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:54.87
Nov 12 12:39:54.870: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename runtimeclass 11/12/22 12:39:54.87
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:54.889
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:54.893
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Nov 12 12:39:54.917: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8137 to be scheduled
Nov 12 12:39:54.931: INFO: 1 pods are not scheduled: [runtimeclass-8137/test-runtimeclass-runtimeclass-8137-preconfigured-handler-wsh9x(2994ca39-f5a2-43d9-ab8f-8c4abb76ceb2)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 12:39:56.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8137" for this suite. 11/12/22 12:39:56.951
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":193,"skipped":3522,"failed":0}
------------------------------
• [2.093 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:54.87
    Nov 12 12:39:54.870: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 12:39:54.87
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:54.889
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:54.893
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Nov 12 12:39:54.917: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-8137 to be scheduled
    Nov 12 12:39:54.931: INFO: 1 pods are not scheduled: [runtimeclass-8137/test-runtimeclass-runtimeclass-8137-preconfigured-handler-wsh9x(2994ca39-f5a2-43d9-ab8f-8c4abb76ceb2)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 12:39:56.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8137" for this suite. 11/12/22 12:39:56.951
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:39:56.965
Nov 12 12:39:56.966: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:39:56.966
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:56.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:56.986
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-9833 11/12/22 12:39:56.993
STEP: creating service affinity-clusterip in namespace services-9833 11/12/22 12:39:56.993
STEP: creating replication controller affinity-clusterip in namespace services-9833 11/12/22 12:39:57.013
I1112 12:39:57.034575      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-9833, replica count: 3
I1112 12:40:00.085849      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 12:40:00.096: INFO: Creating new exec pod
Nov 12 12:40:00.104: INFO: Waiting up to 5m0s for pod "execpod-affinity2qtqj" in namespace "services-9833" to be "running"
Nov 12 12:40:00.112: INFO: Pod "execpod-affinity2qtqj": Phase="Pending", Reason="", readiness=false. Elapsed: 7.935092ms
Nov 12 12:40:02.117: INFO: Pod "execpod-affinity2qtqj": Phase="Running", Reason="", readiness=true. Elapsed: 2.012670762s
Nov 12 12:40:02.117: INFO: Pod "execpod-affinity2qtqj" satisfied condition "running"
Nov 12 12:40:03.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9833 exec execpod-affinity2qtqj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 12 12:40:03.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Nov 12 12:40:03.312: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:40:03.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9833 exec execpod-affinity2qtqj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.251 80'
Nov 12 12:40:03.541: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.251 80\nConnection to 10.152.183.251 80 port [tcp/http] succeeded!\n"
Nov 12 12:40:03.541: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:40:03.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9833 exec execpod-affinity2qtqj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.251:80/ ; done'
Nov 12 12:40:03.873: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n"
Nov 12 12:40:03.873: INFO: stdout: "\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6"
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
Nov 12 12:40:03.873: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-9833, will wait for the garbage collector to delete the pods 11/12/22 12:40:03.895
Nov 12 12:40:03.967: INFO: Deleting ReplicationController affinity-clusterip took: 9.175773ms
Nov 12 12:40:04.068: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.00024ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:40:06.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9833" for this suite. 11/12/22 12:40:06.604
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":194,"skipped":3539,"failed":0}
------------------------------
• [SLOW TEST] [9.648 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:39:56.965
    Nov 12 12:39:56.966: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:39:56.966
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:39:56.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:39:56.986
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-9833 11/12/22 12:39:56.993
    STEP: creating service affinity-clusterip in namespace services-9833 11/12/22 12:39:56.993
    STEP: creating replication controller affinity-clusterip in namespace services-9833 11/12/22 12:39:57.013
    I1112 12:39:57.034575      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-9833, replica count: 3
    I1112 12:40:00.085849      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 12:40:00.096: INFO: Creating new exec pod
    Nov 12 12:40:00.104: INFO: Waiting up to 5m0s for pod "execpod-affinity2qtqj" in namespace "services-9833" to be "running"
    Nov 12 12:40:00.112: INFO: Pod "execpod-affinity2qtqj": Phase="Pending", Reason="", readiness=false. Elapsed: 7.935092ms
    Nov 12 12:40:02.117: INFO: Pod "execpod-affinity2qtqj": Phase="Running", Reason="", readiness=true. Elapsed: 2.012670762s
    Nov 12 12:40:02.117: INFO: Pod "execpod-affinity2qtqj" satisfied condition "running"
    Nov 12 12:40:03.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9833 exec execpod-affinity2qtqj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 12 12:40:03.312: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Nov 12 12:40:03.312: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:40:03.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9833 exec execpod-affinity2qtqj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.251 80'
    Nov 12 12:40:03.541: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.251 80\nConnection to 10.152.183.251 80 port [tcp/http] succeeded!\n"
    Nov 12 12:40:03.541: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:40:03.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9833 exec execpod-affinity2qtqj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.251:80/ ; done'
    Nov 12 12:40:03.873: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.251:80/\n"
    Nov 12 12:40:03.873: INFO: stdout: "\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6\naffinity-clusterip-r4xl6"
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Received response from host: affinity-clusterip-r4xl6
    Nov 12 12:40:03.873: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-9833, will wait for the garbage collector to delete the pods 11/12/22 12:40:03.895
    Nov 12 12:40:03.967: INFO: Deleting ReplicationController affinity-clusterip took: 9.175773ms
    Nov 12 12:40:04.068: INFO: Terminating ReplicationController affinity-clusterip pods took: 101.00024ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:40:06.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9833" for this suite. 11/12/22 12:40:06.604
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:40:06.617
Nov 12 12:40:06.617: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:40:06.618
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:40:06.635
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:40:06.638
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 12:40:06.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9686" for this suite. 11/12/22 12:40:06.734
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":195,"skipped":3574,"failed":0}
------------------------------
• [0.127 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:40:06.617
    Nov 12 12:40:06.617: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 12:40:06.618
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:40:06.635
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:40:06.638
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 12:40:06.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9686" for this suite. 11/12/22 12:40:06.734
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:40:06.744
Nov 12 12:40:06.744: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename job 11/12/22 12:40:06.745
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:40:06.764
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:40:06.766
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 11/12/22 12:40:06.769
STEP: Ensuring active pods == parallelism 11/12/22 12:40:06.778
STEP: delete a job 11/12/22 12:40:08.784
STEP: deleting Job.batch foo in namespace job-1917, will wait for the garbage collector to delete the pods 11/12/22 12:40:08.784
Nov 12 12:40:08.848: INFO: Deleting Job.batch foo took: 9.159201ms
Nov 12 12:40:08.949: INFO: Terminating Job.batch foo pods took: 101.32209ms
STEP: Ensuring job was deleted 11/12/22 12:40:41.65
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 12 12:40:41.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1917" for this suite. 11/12/22 12:40:41.66
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":196,"skipped":3575,"failed":0}
------------------------------
• [SLOW TEST] [34.925 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:40:06.744
    Nov 12 12:40:06.744: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename job 11/12/22 12:40:06.745
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:40:06.764
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:40:06.766
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 11/12/22 12:40:06.769
    STEP: Ensuring active pods == parallelism 11/12/22 12:40:06.778
    STEP: delete a job 11/12/22 12:40:08.784
    STEP: deleting Job.batch foo in namespace job-1917, will wait for the garbage collector to delete the pods 11/12/22 12:40:08.784
    Nov 12 12:40:08.848: INFO: Deleting Job.batch foo took: 9.159201ms
    Nov 12 12:40:08.949: INFO: Terminating Job.batch foo pods took: 101.32209ms
    STEP: Ensuring job was deleted 11/12/22 12:40:41.65
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 12 12:40:41.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1917" for this suite. 11/12/22 12:40:41.66
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:40:41.671
Nov 12 12:40:41.672: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:40:41.673
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:40:41.695
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:40:41.7
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Nov 12 12:40:41.721: INFO: created pod
Nov 12 12:40:41.721: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1699" to be "Succeeded or Failed"
Nov 12 12:40:41.729: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.857351ms
Nov 12 12:40:43.737: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016492643s
Nov 12 12:40:45.737: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016338949s
STEP: Saw pod success 11/12/22 12:40:45.737
Nov 12 12:40:45.737: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Nov 12 12:41:15.738: INFO: polling logs
Nov 12 12:41:15.748: INFO: Pod logs: 
I1112 12:40:42.781218       1 log.go:195] OK: Got token
I1112 12:40:42.781250       1 log.go:195] validating with in-cluster discovery
I1112 12:40:42.781553       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I1112 12:40:42.781586       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1699:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668257441, NotBefore:1668256841, IssuedAt:1668256841, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1699", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"1b029d1a-f016-46db-a41e-3fdfab34c990"}}}
I1112 12:40:42.793114       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I1112 12:40:42.798635       1 log.go:195] OK: Validated signature on JWT
I1112 12:40:42.798751       1 log.go:195] OK: Got valid claims from token!
I1112 12:40:42.798782       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1699:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668257441, NotBefore:1668256841, IssuedAt:1668256841, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1699", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"1b029d1a-f016-46db-a41e-3fdfab34c990"}}}

Nov 12 12:41:15.748: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 12 12:41:15.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1699" for this suite. 11/12/22 12:41:15.763
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":197,"skipped":3589,"failed":0}
------------------------------
• [SLOW TEST] [34.103 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:40:41.671
    Nov 12 12:40:41.672: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:40:41.673
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:40:41.695
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:40:41.7
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Nov 12 12:40:41.721: INFO: created pod
    Nov 12 12:40:41.721: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1699" to be "Succeeded or Failed"
    Nov 12 12:40:41.729: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.857351ms
    Nov 12 12:40:43.737: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016492643s
    Nov 12 12:40:45.737: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016338949s
    STEP: Saw pod success 11/12/22 12:40:45.737
    Nov 12 12:40:45.737: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Nov 12 12:41:15.738: INFO: polling logs
    Nov 12 12:41:15.748: INFO: Pod logs: 
    I1112 12:40:42.781218       1 log.go:195] OK: Got token
    I1112 12:40:42.781250       1 log.go:195] validating with in-cluster discovery
    I1112 12:40:42.781553       1 log.go:195] OK: got issuer https://kubernetes.default.svc
    I1112 12:40:42.781586       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1699:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668257441, NotBefore:1668256841, IssuedAt:1668256841, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1699", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"1b029d1a-f016-46db-a41e-3fdfab34c990"}}}
    I1112 12:40:42.793114       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I1112 12:40:42.798635       1 log.go:195] OK: Validated signature on JWT
    I1112 12:40:42.798751       1 log.go:195] OK: Got valid claims from token!
    I1112 12:40:42.798782       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1699:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1668257441, NotBefore:1668256841, IssuedAt:1668256841, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1699", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"1b029d1a-f016-46db-a41e-3fdfab34c990"}}}

    Nov 12 12:41:15.748: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 12 12:41:15.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1699" for this suite. 11/12/22 12:41:15.763
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:41:15.776
Nov 12 12:41:15.776: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/12/22 12:41:15.777
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:15.809
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:15.815
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 11/12/22 12:41:15.821
STEP: Creating hostNetwork=false pod 11/12/22 12:41:15.821
Nov 12 12:41:15.836: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-4501" to be "running and ready"
Nov 12 12:41:15.842: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.828415ms
Nov 12 12:41:15.842: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:41:17.849: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012315901s
Nov 12 12:41:17.849: INFO: The phase of Pod test-pod is Running (Ready = true)
Nov 12 12:41:17.849: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 11/12/22 12:41:17.854
Nov 12 12:41:17.863: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-4501" to be "running and ready"
Nov 12 12:41:17.869: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043558ms
Nov 12 12:41:17.869: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:41:19.876: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012596359s
Nov 12 12:41:19.876: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Nov 12 12:41:19.876: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 11/12/22 12:41:19.88
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/12/22 12:41:19.88
Nov 12 12:41:19.880: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:19.880: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:19.881: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:19.881: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 12:41:19.965: INFO: Exec stderr: ""
Nov 12 12:41:19.965: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:19.965: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:19.966: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:19.966: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 12:41:20.030: INFO: Exec stderr: ""
Nov 12 12:41:20.030: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.030: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.031: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.031: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 12:41:20.112: INFO: Exec stderr: ""
Nov 12 12:41:20.112: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.112: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.113: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.113: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 12:41:20.187: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/12/22 12:41:20.187
Nov 12 12:41:20.187: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.187: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.188: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.188: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 12 12:41:20.272: INFO: Exec stderr: ""
Nov 12 12:41:20.273: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.273: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.273: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.274: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 12 12:41:20.355: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/12/22 12:41:20.355
Nov 12 12:41:20.355: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.355: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.356: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.356: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 12:41:20.438: INFO: Exec stderr: ""
Nov 12 12:41:20.438: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.438: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.439: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.439: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 12 12:41:20.522: INFO: Exec stderr: ""
Nov 12 12:41:20.522: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.522: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.522: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.522: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 12:41:20.610: INFO: Exec stderr: ""
Nov 12 12:41:20.611: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:41:20.611: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:41:20.612: INFO: ExecWithOptions: Clientset creation
Nov 12 12:41:20.612: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 12 12:41:20.686: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Nov 12 12:41:20.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4501" for this suite. 11/12/22 12:41:20.691
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":198,"skipped":3591,"failed":0}
------------------------------
• [4.926 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:41:15.776
    Nov 12 12:41:15.776: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/12/22 12:41:15.777
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:15.809
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:15.815
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 11/12/22 12:41:15.821
    STEP: Creating hostNetwork=false pod 11/12/22 12:41:15.821
    Nov 12 12:41:15.836: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-4501" to be "running and ready"
    Nov 12 12:41:15.842: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.828415ms
    Nov 12 12:41:15.842: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:41:17.849: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012315901s
    Nov 12 12:41:17.849: INFO: The phase of Pod test-pod is Running (Ready = true)
    Nov 12 12:41:17.849: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 11/12/22 12:41:17.854
    Nov 12 12:41:17.863: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-4501" to be "running and ready"
    Nov 12 12:41:17.869: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043558ms
    Nov 12 12:41:17.869: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:41:19.876: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012596359s
    Nov 12 12:41:19.876: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Nov 12 12:41:19.876: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 11/12/22 12:41:19.88
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/12/22 12:41:19.88
    Nov 12 12:41:19.880: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:19.880: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:19.881: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:19.881: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 12:41:19.965: INFO: Exec stderr: ""
    Nov 12 12:41:19.965: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:19.965: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:19.966: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:19.966: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 12:41:20.030: INFO: Exec stderr: ""
    Nov 12 12:41:20.030: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.030: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.031: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.031: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 12:41:20.112: INFO: Exec stderr: ""
    Nov 12 12:41:20.112: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.112: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.113: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.113: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 12:41:20.187: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/12/22 12:41:20.187
    Nov 12 12:41:20.187: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.187: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.188: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.188: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 12 12:41:20.272: INFO: Exec stderr: ""
    Nov 12 12:41:20.273: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.273: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.273: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.274: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 12 12:41:20.355: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/12/22 12:41:20.355
    Nov 12 12:41:20.355: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.355: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.356: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.356: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 12:41:20.438: INFO: Exec stderr: ""
    Nov 12 12:41:20.438: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.438: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.439: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.439: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 12 12:41:20.522: INFO: Exec stderr: ""
    Nov 12 12:41:20.522: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.522: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.522: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.522: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 12:41:20.610: INFO: Exec stderr: ""
    Nov 12 12:41:20.611: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4501 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:41:20.611: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:41:20.612: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:41:20.612: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4501/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 12 12:41:20.686: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Nov 12 12:41:20.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-4501" for this suite. 11/12/22 12:41:20.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:41:20.702
Nov 12 12:41:20.703: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename endpointslice 11/12/22 12:41:20.704
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:20.72
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:20.728
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 12 12:41:22.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9918" for this suite. 11/12/22 12:41:22.872
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":199,"skipped":3596,"failed":0}
------------------------------
• [2.180 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:41:20.702
    Nov 12 12:41:20.703: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename endpointslice 11/12/22 12:41:20.704
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:20.72
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:20.728
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 12 12:41:22.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9918" for this suite. 11/12/22 12:41:22.872
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:41:22.883
Nov 12 12:41:22.883: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:41:22.884
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:22.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:22.91
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 12:41:22.915
Nov 12 12:41:22.937: INFO: Waiting up to 5m0s for pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7" in namespace "emptydir-2356" to be "Succeeded or Failed"
Nov 12 12:41:22.946: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.424909ms
Nov 12 12:41:24.952: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014852417s
Nov 12 12:41:26.951: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013864443s
STEP: Saw pod success 11/12/22 12:41:26.951
Nov 12 12:41:26.951: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7" satisfied condition "Succeeded or Failed"
Nov 12 12:41:26.955: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7 container test-container: <nil>
STEP: delete the pod 11/12/22 12:41:26.987
Nov 12 12:41:27.014: INFO: Waiting for pod pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7 to disappear
Nov 12 12:41:27.019: INFO: Pod pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:41:27.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2356" for this suite. 11/12/22 12:41:27.024
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":200,"skipped":3606,"failed":0}
------------------------------
• [4.177 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:41:22.883
    Nov 12 12:41:22.883: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:41:22.884
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:22.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:22.91
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 12:41:22.915
    Nov 12 12:41:22.937: INFO: Waiting up to 5m0s for pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7" in namespace "emptydir-2356" to be "Succeeded or Failed"
    Nov 12 12:41:22.946: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.424909ms
    Nov 12 12:41:24.952: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014852417s
    Nov 12 12:41:26.951: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013864443s
    STEP: Saw pod success 11/12/22 12:41:26.951
    Nov 12 12:41:26.951: INFO: Pod "pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7" satisfied condition "Succeeded or Failed"
    Nov 12 12:41:26.955: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:41:26.987
    Nov 12 12:41:27.014: INFO: Waiting for pod pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7 to disappear
    Nov 12 12:41:27.019: INFO: Pod pod-68578bd9-ca2d-44dc-b28b-b224cee1bff7 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:41:27.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2356" for this suite. 11/12/22 12:41:27.024
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:41:27.061
Nov 12 12:41:27.061: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 12:41:27.061
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:27.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:27.12
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 11/12/22 12:41:27.122
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_udp@PTR;check="$$(dig +tcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_tcp@PTR;sleep 1; done
 11/12/22 12:41:27.163
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_udp@PTR;check="$$(dig +tcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_tcp@PTR;sleep 1; done
 11/12/22 12:41:27.163
STEP: creating a pod to probe DNS 11/12/22 12:41:27.163
STEP: submitting the pod to kubernetes 11/12/22 12:41:27.163
Nov 12 12:41:27.199: INFO: Waiting up to 15m0s for pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847" in namespace "dns-137" to be "running"
Nov 12 12:41:27.233: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 33.753698ms
Nov 12 12:41:29.238: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039437234s
Nov 12 12:41:31.238: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039415773s
Nov 12 12:41:33.243: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043925941s
Nov 12 12:41:35.238: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 8.039256473s
Nov 12 12:41:37.239: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 10.039541112s
Nov 12 12:41:39.240: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Running", Reason="", readiness=true. Elapsed: 12.040894011s
Nov 12 12:41:39.240: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847" satisfied condition "running"
STEP: retrieving the pod 11/12/22 12:41:39.24
STEP: looking for the results for each expected name from probers 11/12/22 12:41:39.245
Nov 12 12:41:39.257: INFO: Unable to read wheezy_udp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.263: INFO: Unable to read wheezy_tcp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.268: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.273: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.298: INFO: Unable to read jessie_udp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.303: INFO: Unable to read jessie_tcp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.309: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.313: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
Nov 12 12:41:39.332: INFO: Lookups using dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847 failed for: [wheezy_udp@dns-test-service.dns-137.svc.cluster.local wheezy_tcp@dns-test-service.dns-137.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local jessie_udp@dns-test-service.dns-137.svc.cluster.local jessie_tcp@dns-test-service.dns-137.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local]

Nov 12 12:41:44.417: INFO: DNS probes using dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847 succeeded

STEP: deleting the pod 11/12/22 12:41:44.417
STEP: deleting the test service 11/12/22 12:41:44.437
STEP: deleting the test headless service 11/12/22 12:41:44.501
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 12:41:44.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-137" for this suite. 11/12/22 12:41:44.557
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":201,"skipped":3617,"failed":0}
------------------------------
• [SLOW TEST] [17.508 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:41:27.061
    Nov 12 12:41:27.061: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 12:41:27.061
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:27.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:27.12
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 11/12/22 12:41:27.122
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_udp@PTR;check="$$(dig +tcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_tcp@PTR;sleep 1; done
     11/12/22 12:41:27.163
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-137.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-137.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-137.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_udp@PTR;check="$$(dig +tcp +noall +answer +search 191.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.191_tcp@PTR;sleep 1; done
     11/12/22 12:41:27.163
    STEP: creating a pod to probe DNS 11/12/22 12:41:27.163
    STEP: submitting the pod to kubernetes 11/12/22 12:41:27.163
    Nov 12 12:41:27.199: INFO: Waiting up to 15m0s for pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847" in namespace "dns-137" to be "running"
    Nov 12 12:41:27.233: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 33.753698ms
    Nov 12 12:41:29.238: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039437234s
    Nov 12 12:41:31.238: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039415773s
    Nov 12 12:41:33.243: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043925941s
    Nov 12 12:41:35.238: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 8.039256473s
    Nov 12 12:41:37.239: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Pending", Reason="", readiness=false. Elapsed: 10.039541112s
    Nov 12 12:41:39.240: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847": Phase="Running", Reason="", readiness=true. Elapsed: 12.040894011s
    Nov 12 12:41:39.240: INFO: Pod "dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 12:41:39.24
    STEP: looking for the results for each expected name from probers 11/12/22 12:41:39.245
    Nov 12 12:41:39.257: INFO: Unable to read wheezy_udp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.263: INFO: Unable to read wheezy_tcp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.268: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.273: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.298: INFO: Unable to read jessie_udp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.303: INFO: Unable to read jessie_tcp@dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.309: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.313: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local from pod dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847: the server could not find the requested resource (get pods dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847)
    Nov 12 12:41:39.332: INFO: Lookups using dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847 failed for: [wheezy_udp@dns-test-service.dns-137.svc.cluster.local wheezy_tcp@dns-test-service.dns-137.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local jessie_udp@dns-test-service.dns-137.svc.cluster.local jessie_tcp@dns-test-service.dns-137.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-137.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-137.svc.cluster.local]

    Nov 12 12:41:44.417: INFO: DNS probes using dns-137/dns-test-cc02a997-59ad-4831-8b7b-b2a65cfb9847 succeeded

    STEP: deleting the pod 11/12/22 12:41:44.417
    STEP: deleting the test service 11/12/22 12:41:44.437
    STEP: deleting the test headless service 11/12/22 12:41:44.501
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 12:41:44.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-137" for this suite. 11/12/22 12:41:44.557
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:41:44.574
Nov 12 12:41:44.575: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir-wrapper 11/12/22 12:41:44.575
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:44.601
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:44.609
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 11/12/22 12:41:44.621
STEP: Creating RC which spawns configmap-volume pods 11/12/22 12:41:44.995
Nov 12 12:41:45.015: INFO: Pod name wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32: Found 0 pods out of 5
Nov 12 12:41:50.023: INFO: Pod name wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/12/22 12:41:50.023
Nov 12 12:41:50.023: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:41:50.031: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.140542ms
Nov 12 12:41:52.037: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013897116s
Nov 12 12:41:54.042: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018532943s
Nov 12 12:41:56.038: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014690721s
Nov 12 12:41:58.037: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013618642s
Nov 12 12:42:00.037: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Running", Reason="", readiness=true. Elapsed: 10.014226092s
Nov 12 12:42:00.038: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k" satisfied condition "running"
Nov 12 12:42:00.038: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-dxkb5" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:00.042: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-dxkb5": Phase="Running", Reason="", readiness=true. Elapsed: 4.786659ms
Nov 12 12:42:00.042: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-dxkb5" satisfied condition "running"
Nov 12 12:42:00.042: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-ljpmc" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:00.046: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-ljpmc": Phase="Running", Reason="", readiness=true. Elapsed: 3.820419ms
Nov 12 12:42:00.046: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-ljpmc" satisfied condition "running"
Nov 12 12:42:00.046: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-x7x68" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:00.052: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-x7x68": Phase="Running", Reason="", readiness=true. Elapsed: 5.737872ms
Nov 12 12:42:00.052: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-x7x68" satisfied condition "running"
Nov 12 12:42:00.052: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-zz77k" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:00.057: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-zz77k": Phase="Running", Reason="", readiness=true. Elapsed: 5.315555ms
Nov 12 12:42:00.057: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-zz77k" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32 in namespace emptydir-wrapper-606, will wait for the garbage collector to delete the pods 11/12/22 12:42:00.057
Nov 12 12:42:00.124: INFO: Deleting ReplicationController wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32 took: 10.629933ms
Nov 12 12:42:00.225: INFO: Terminating ReplicationController wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32 pods took: 100.237233ms
STEP: Creating RC which spawns configmap-volume pods 11/12/22 12:42:04.93
Nov 12 12:42:04.946: INFO: Pod name wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102: Found 0 pods out of 5
Nov 12 12:42:09.960: INFO: Pod name wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/12/22 12:42:09.96
Nov 12 12:42:09.960: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:09.965: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 5.020503ms
Nov 12 12:42:11.972: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011764545s
Nov 12 12:42:13.971: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010808484s
Nov 12 12:42:15.971: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010972626s
Nov 12 12:42:17.972: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011673076s
Nov 12 12:42:19.971: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011131003s
Nov 12 12:42:21.970: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Running", Reason="", readiness=true. Elapsed: 12.009963234s
Nov 12 12:42:21.970: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx" satisfied condition "running"
Nov 12 12:42:21.970: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-frksd" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:21.976: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-frksd": Phase="Running", Reason="", readiness=true. Elapsed: 6.103237ms
Nov 12 12:42:21.976: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-frksd" satisfied condition "running"
Nov 12 12:42:21.976: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-gwf5r" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:21.981: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-gwf5r": Phase="Running", Reason="", readiness=true. Elapsed: 4.527088ms
Nov 12 12:42:21.981: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-gwf5r" satisfied condition "running"
Nov 12 12:42:21.981: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-vq6wg" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:21.985: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-vq6wg": Phase="Running", Reason="", readiness=true. Elapsed: 4.532429ms
Nov 12 12:42:21.985: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-vq6wg" satisfied condition "running"
Nov 12 12:42:21.985: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-wc77t" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:21.990: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-wc77t": Phase="Running", Reason="", readiness=true. Elapsed: 4.705627ms
Nov 12 12:42:21.990: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-wc77t" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102 in namespace emptydir-wrapper-606, will wait for the garbage collector to delete the pods 11/12/22 12:42:21.99
Nov 12 12:42:22.058: INFO: Deleting ReplicationController wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102 took: 11.999569ms
Nov 12 12:42:22.259: INFO: Terminating ReplicationController wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102 pods took: 201.019196ms
STEP: Creating RC which spawns configmap-volume pods 11/12/22 12:42:26.365
Nov 12 12:42:26.388: INFO: Pod name wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe: Found 0 pods out of 5
Nov 12 12:42:31.397: INFO: Pod name wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/12/22 12:42:31.397
Nov 12 12:42:31.397: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:31.402: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.645579ms
Nov 12 12:42:33.409: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011563441s
Nov 12 12:42:35.408: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010832589s
Nov 12 12:42:37.409: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01153107s
Nov 12 12:42:39.419: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021625482s
Nov 12 12:42:41.407: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Running", Reason="", readiness=true. Elapsed: 10.009943682s
Nov 12 12:42:41.407: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm" satisfied condition "running"
Nov 12 12:42:41.407: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-6p482" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:41.412: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-6p482": Phase="Running", Reason="", readiness=true. Elapsed: 4.803509ms
Nov 12 12:42:41.412: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-6p482" satisfied condition "running"
Nov 12 12:42:41.412: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-f5dd2" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:41.418: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-f5dd2": Phase="Running", Reason="", readiness=true. Elapsed: 5.541584ms
Nov 12 12:42:41.418: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-f5dd2" satisfied condition "running"
Nov 12 12:42:41.418: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-v7dsm" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:41.422: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-v7dsm": Phase="Running", Reason="", readiness=true. Elapsed: 4.455907ms
Nov 12 12:42:41.422: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-v7dsm" satisfied condition "running"
Nov 12 12:42:41.422: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-xhbzd" in namespace "emptydir-wrapper-606" to be "running"
Nov 12 12:42:41.427: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-xhbzd": Phase="Running", Reason="", readiness=true. Elapsed: 4.970225ms
Nov 12 12:42:41.427: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-xhbzd" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe in namespace emptydir-wrapper-606, will wait for the garbage collector to delete the pods 11/12/22 12:42:41.427
Nov 12 12:42:41.498: INFO: Deleting ReplicationController wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe took: 14.284215ms
Nov 12 12:42:41.699: INFO: Terminating ReplicationController wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe pods took: 201.028719ms
STEP: Cleaning up the configMaps 11/12/22 12:42:45.3
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 12 12:42:45.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-606" for this suite. 11/12/22 12:42:45.807
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":202,"skipped":3674,"failed":0}
------------------------------
• [SLOW TEST] [61.243 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:41:44.574
    Nov 12 12:41:44.575: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir-wrapper 11/12/22 12:41:44.575
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:41:44.601
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:41:44.609
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 11/12/22 12:41:44.621
    STEP: Creating RC which spawns configmap-volume pods 11/12/22 12:41:44.995
    Nov 12 12:41:45.015: INFO: Pod name wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32: Found 0 pods out of 5
    Nov 12 12:41:50.023: INFO: Pod name wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/12/22 12:41:50.023
    Nov 12 12:41:50.023: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:41:50.031: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.140542ms
    Nov 12 12:41:52.037: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013897116s
    Nov 12 12:41:54.042: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018532943s
    Nov 12 12:41:56.038: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014690721s
    Nov 12 12:41:58.037: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013618642s
    Nov 12 12:42:00.037: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k": Phase="Running", Reason="", readiness=true. Elapsed: 10.014226092s
    Nov 12 12:42:00.038: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-4hc2k" satisfied condition "running"
    Nov 12 12:42:00.038: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-dxkb5" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:00.042: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-dxkb5": Phase="Running", Reason="", readiness=true. Elapsed: 4.786659ms
    Nov 12 12:42:00.042: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-dxkb5" satisfied condition "running"
    Nov 12 12:42:00.042: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-ljpmc" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:00.046: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-ljpmc": Phase="Running", Reason="", readiness=true. Elapsed: 3.820419ms
    Nov 12 12:42:00.046: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-ljpmc" satisfied condition "running"
    Nov 12 12:42:00.046: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-x7x68" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:00.052: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-x7x68": Phase="Running", Reason="", readiness=true. Elapsed: 5.737872ms
    Nov 12 12:42:00.052: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-x7x68" satisfied condition "running"
    Nov 12 12:42:00.052: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-zz77k" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:00.057: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-zz77k": Phase="Running", Reason="", readiness=true. Elapsed: 5.315555ms
    Nov 12 12:42:00.057: INFO: Pod "wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32-zz77k" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32 in namespace emptydir-wrapper-606, will wait for the garbage collector to delete the pods 11/12/22 12:42:00.057
    Nov 12 12:42:00.124: INFO: Deleting ReplicationController wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32 took: 10.629933ms
    Nov 12 12:42:00.225: INFO: Terminating ReplicationController wrapped-volume-race-c64a308c-c073-4a40-bd0b-87c454493b32 pods took: 100.237233ms
    STEP: Creating RC which spawns configmap-volume pods 11/12/22 12:42:04.93
    Nov 12 12:42:04.946: INFO: Pod name wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102: Found 0 pods out of 5
    Nov 12 12:42:09.960: INFO: Pod name wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/12/22 12:42:09.96
    Nov 12 12:42:09.960: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:09.965: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 5.020503ms
    Nov 12 12:42:11.972: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011764545s
    Nov 12 12:42:13.971: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010808484s
    Nov 12 12:42:15.971: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010972626s
    Nov 12 12:42:17.972: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011673076s
    Nov 12 12:42:19.971: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011131003s
    Nov 12 12:42:21.970: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx": Phase="Running", Reason="", readiness=true. Elapsed: 12.009963234s
    Nov 12 12:42:21.970: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-dmcmx" satisfied condition "running"
    Nov 12 12:42:21.970: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-frksd" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:21.976: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-frksd": Phase="Running", Reason="", readiness=true. Elapsed: 6.103237ms
    Nov 12 12:42:21.976: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-frksd" satisfied condition "running"
    Nov 12 12:42:21.976: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-gwf5r" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:21.981: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-gwf5r": Phase="Running", Reason="", readiness=true. Elapsed: 4.527088ms
    Nov 12 12:42:21.981: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-gwf5r" satisfied condition "running"
    Nov 12 12:42:21.981: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-vq6wg" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:21.985: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-vq6wg": Phase="Running", Reason="", readiness=true. Elapsed: 4.532429ms
    Nov 12 12:42:21.985: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-vq6wg" satisfied condition "running"
    Nov 12 12:42:21.985: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-wc77t" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:21.990: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-wc77t": Phase="Running", Reason="", readiness=true. Elapsed: 4.705627ms
    Nov 12 12:42:21.990: INFO: Pod "wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102-wc77t" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102 in namespace emptydir-wrapper-606, will wait for the garbage collector to delete the pods 11/12/22 12:42:21.99
    Nov 12 12:42:22.058: INFO: Deleting ReplicationController wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102 took: 11.999569ms
    Nov 12 12:42:22.259: INFO: Terminating ReplicationController wrapped-volume-race-8fb41a31-d59d-4bf4-bd3a-2d9eacc1b102 pods took: 201.019196ms
    STEP: Creating RC which spawns configmap-volume pods 11/12/22 12:42:26.365
    Nov 12 12:42:26.388: INFO: Pod name wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe: Found 0 pods out of 5
    Nov 12 12:42:31.397: INFO: Pod name wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/12/22 12:42:31.397
    Nov 12 12:42:31.397: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:31.402: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.645579ms
    Nov 12 12:42:33.409: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011563441s
    Nov 12 12:42:35.408: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010832589s
    Nov 12 12:42:37.409: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01153107s
    Nov 12 12:42:39.419: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021625482s
    Nov 12 12:42:41.407: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm": Phase="Running", Reason="", readiness=true. Elapsed: 10.009943682s
    Nov 12 12:42:41.407: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-47vwm" satisfied condition "running"
    Nov 12 12:42:41.407: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-6p482" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:41.412: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-6p482": Phase="Running", Reason="", readiness=true. Elapsed: 4.803509ms
    Nov 12 12:42:41.412: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-6p482" satisfied condition "running"
    Nov 12 12:42:41.412: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-f5dd2" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:41.418: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-f5dd2": Phase="Running", Reason="", readiness=true. Elapsed: 5.541584ms
    Nov 12 12:42:41.418: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-f5dd2" satisfied condition "running"
    Nov 12 12:42:41.418: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-v7dsm" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:41.422: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-v7dsm": Phase="Running", Reason="", readiness=true. Elapsed: 4.455907ms
    Nov 12 12:42:41.422: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-v7dsm" satisfied condition "running"
    Nov 12 12:42:41.422: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-xhbzd" in namespace "emptydir-wrapper-606" to be "running"
    Nov 12 12:42:41.427: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-xhbzd": Phase="Running", Reason="", readiness=true. Elapsed: 4.970225ms
    Nov 12 12:42:41.427: INFO: Pod "wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe-xhbzd" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe in namespace emptydir-wrapper-606, will wait for the garbage collector to delete the pods 11/12/22 12:42:41.427
    Nov 12 12:42:41.498: INFO: Deleting ReplicationController wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe took: 14.284215ms
    Nov 12 12:42:41.699: INFO: Terminating ReplicationController wrapped-volume-race-245ec5c4-4c82-49d9-9942-c0e2f234b8fe pods took: 201.028719ms
    STEP: Cleaning up the configMaps 11/12/22 12:42:45.3
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:42:45.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-606" for this suite. 11/12/22 12:42:45.807
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:42:45.818
Nov 12 12:42:45.818: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename tables 11/12/22 12:42:45.819
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:45.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:45.842
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Nov 12 12:42:45.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5182" for this suite. 11/12/22 12:42:45.859
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":203,"skipped":3680,"failed":0}
------------------------------
• [0.066 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:42:45.818
    Nov 12 12:42:45.818: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename tables 11/12/22 12:42:45.819
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:45.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:45.842
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Nov 12 12:42:45.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-5182" for this suite. 11/12/22 12:42:45.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:42:45.884
Nov 12 12:42:45.884: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:42:45.885
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:45.904
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:45.907
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Nov 12 12:42:45.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 create -f -'
Nov 12 12:42:46.337: INFO: stderr: ""
Nov 12 12:42:46.338: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Nov 12 12:42:46.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 create -f -'
Nov 12 12:42:46.659: INFO: stderr: ""
Nov 12 12:42:46.659: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/12/22 12:42:46.659
Nov 12 12:42:47.666: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 12:42:47.666: INFO: Found 0 / 1
Nov 12 12:42:48.664: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 12:42:48.665: INFO: Found 1 / 1
Nov 12 12:42:48.665: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 12 12:42:48.670: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 12:42:48.670: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 12 12:42:48.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe pod agnhost-primary-64tvq'
Nov 12 12:42:48.761: INFO: stderr: ""
Nov 12 12:42:48.761: INFO: stdout: "Name:             agnhost-primary-64tvq\nNamespace:        kubectl-5402\nPriority:         0\nService Account:  default\nNode:             ip-172-31-14-110/172.31.14.110\nStart Time:       Sat, 12 Nov 2022 12:42:46 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.249.17\nIPs:\n  IP:           192.168.249.17\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://0efbfea4634f27a7da1d714b9427e750eb9aae704360550e333f67416aea7cd3\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 12 Nov 2022 12:42:47 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mw4s9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-mw4s9:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5402/agnhost-primary-64tvq to ip-172-31-14-110\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Nov 12 12:42:48.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe rc agnhost-primary'
Nov 12 12:42:48.866: INFO: stderr: ""
Nov 12 12:42:48.866: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5402\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-64tvq\n"
Nov 12 12:42:48.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe service agnhost-primary'
Nov 12 12:42:48.959: INFO: stderr: ""
Nov 12 12:42:48.959: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5402\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.35\nIPs:               10.152.183.35\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.249.17:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 12 12:42:48.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe node ip-172-31-14-110'
Nov 12 12:42:49.106: INFO: stderr: ""
Nov 12 12:42:49.106: INFO: stdout: "Name:               ip-172-31-14-110\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-14-110\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 12 Nov 2022 11:49:55 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-14-110\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 12 Nov 2022 12:42:48 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:49:55 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:49:55 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:49:55 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:52:09 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.14.110\n  Hostname:    ip-172-31-14-110\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      16069568Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8036340Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    2\n  ephemeral-storage:      14809713845\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7933940Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                      ec2d983fd83ab297b03ec99f047274be\n  System UUID:                     ec2d983f-d83a-b297-b03e-c99f047274be\n  Boot ID:                         fb5a67d0-bbc5-4480-a6b9-8101ad934205\n  Kernel Version:                  5.15.0-1022-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.4\n  Kube-Proxy Version:              v1.25.4\nNon-terminated Pods:               (4 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-vpz52           0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\n  kubectl-5402                     agnhost-primary-64tvq                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                         sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests  Limits\n  --------               --------  ------\n  cpu                    0 (0%)    0 (0%)\n  memory                 0 (0%)    0 (0%)\n  ephemeral-storage      0 (0%)    0 (0%)\n  hugepages-1Gi          0 (0%)    0 (0%)\n  hugepages-2Mi          0 (0%)    0 (0%)\n  scheduling.k8s.io/foo  0         0\nEvents:\n  Type     Reason                   Age   From             Message\n  ----     ------                   ----  ----             -------\n  Normal   Starting                 52m   kube-proxy       \n  Normal   Starting                 51m   kube-proxy       \n  Normal   Starting                 50m   kube-proxy       \n  Normal   Starting                 52m   kube-proxy       \n  Normal   Starting                 52m   kube-proxy       \n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeAllocatableEnforced  52m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Warning  InvalidDiskCapacity      52m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 52m   kubelet          Starting kubelet.\n  Normal   RegisteredNode           52m   node-controller  Node ip-172-31-14-110 event: Registered Node ip-172-31-14-110 in Controller\n  Normal   Starting                 52m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      52m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  52m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  52m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      52m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 52m   kubelet          Starting kubelet.\n  Normal   NodeReady                52m   kubelet          Node ip-172-31-14-110 status is now: NodeReady\n  Normal   NodeNotReady             51m   kubelet          Node ip-172-31-14-110 status is now: NodeNotReady\n  Normal   Starting                 51m   kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    51m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     51m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      51m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  51m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  51m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeReady                51m   kubelet          Node ip-172-31-14-110 status is now: NodeReady\n  Normal   Starting                 50m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      50m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  50m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    50m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     50m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             50m   kubelet          Node ip-172-31-14-110 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  50m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                50m   kubelet          Node ip-172-31-14-110 status is now: NodeReady\n"
Nov 12 12:42:49.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe namespace kubectl-5402'
Nov 12 12:42:49.206: INFO: stderr: ""
Nov 12 12:42:49.206: INFO: stdout: "Name:         kubectl-5402\nLabels:       e2e-framework=kubectl\n              e2e-run=9f11ea07-55ae-48b5-a2d0-18d79ec42f84\n              kubernetes.io/metadata.name=kubectl-5402\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:42:49.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5402" for this suite. 11/12/22 12:42:49.212
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":204,"skipped":3686,"failed":0}
------------------------------
• [3.344 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:42:45.884
    Nov 12 12:42:45.884: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:42:45.885
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:45.904
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:45.907
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Nov 12 12:42:45.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 create -f -'
    Nov 12 12:42:46.337: INFO: stderr: ""
    Nov 12 12:42:46.338: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Nov 12 12:42:46.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 create -f -'
    Nov 12 12:42:46.659: INFO: stderr: ""
    Nov 12 12:42:46.659: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/12/22 12:42:46.659
    Nov 12 12:42:47.666: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 12:42:47.666: INFO: Found 0 / 1
    Nov 12 12:42:48.664: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 12:42:48.665: INFO: Found 1 / 1
    Nov 12 12:42:48.665: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 12 12:42:48.670: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 12:42:48.670: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 12 12:42:48.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe pod agnhost-primary-64tvq'
    Nov 12 12:42:48.761: INFO: stderr: ""
    Nov 12 12:42:48.761: INFO: stdout: "Name:             agnhost-primary-64tvq\nNamespace:        kubectl-5402\nPriority:         0\nService Account:  default\nNode:             ip-172-31-14-110/172.31.14.110\nStart Time:       Sat, 12 Nov 2022 12:42:46 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.249.17\nIPs:\n  IP:           192.168.249.17\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://0efbfea4634f27a7da1d714b9427e750eb9aae704360550e333f67416aea7cd3\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 12 Nov 2022 12:42:47 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mw4s9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-mw4s9:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-5402/agnhost-primary-64tvq to ip-172-31-14-110\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Nov 12 12:42:48.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe rc agnhost-primary'
    Nov 12 12:42:48.866: INFO: stderr: ""
    Nov 12 12:42:48.866: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5402\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-64tvq\n"
    Nov 12 12:42:48.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe service agnhost-primary'
    Nov 12 12:42:48.959: INFO: stderr: ""
    Nov 12 12:42:48.959: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5402\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.35\nIPs:               10.152.183.35\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.249.17:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Nov 12 12:42:48.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe node ip-172-31-14-110'
    Nov 12 12:42:49.106: INFO: stderr: ""
    Nov 12 12:42:49.106: INFO: stdout: "Name:               ip-172-31-14-110\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-14-110\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 12 Nov 2022 11:49:55 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-14-110\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 12 Nov 2022 12:42:48 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:49:55 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:49:55 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:49:55 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 12 Nov 2022 12:40:27 +0000   Sat, 12 Nov 2022 11:52:09 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.14.110\n  Hostname:    ip-172-31-14-110\nCapacity:\n  cpu:                    2\n  ephemeral-storage:      16069568Ki\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 8036340Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nAllocatable:\n  cpu:                    2\n  ephemeral-storage:      14809713845\n  hugepages-1Gi:          0\n  hugepages-2Mi:          0\n  memory:                 7933940Ki\n  pods:                   110\n  scheduling.k8s.io/foo:  5\nSystem Info:\n  Machine ID:                      ec2d983fd83ab297b03ec99f047274be\n  System UUID:                     ec2d983f-d83a-b297-b03e-c99f047274be\n  Boot ID:                         fb5a67d0-bbc5-4480-a6b9-8101ad934205\n  Kernel Version:                  5.15.0-1022-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.4\n  Kube-Proxy Version:              v1.25.4\nNon-terminated Pods:               (4 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-vpz52           0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\n  kubectl-5402                     agnhost-primary-64tvq                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                         sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm    0 (0%)        0 (0%)      0 (0%)           0 (0%)         44m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource               Requests  Limits\n  --------               --------  ------\n  cpu                    0 (0%)    0 (0%)\n  memory                 0 (0%)    0 (0%)\n  ephemeral-storage      0 (0%)    0 (0%)\n  hugepages-1Gi          0 (0%)    0 (0%)\n  hugepages-2Mi          0 (0%)    0 (0%)\n  scheduling.k8s.io/foo  0         0\nEvents:\n  Type     Reason                   Age   From             Message\n  ----     ------                   ----  ----             -------\n  Normal   Starting                 52m   kube-proxy       \n  Normal   Starting                 51m   kube-proxy       \n  Normal   Starting                 50m   kube-proxy       \n  Normal   Starting                 52m   kube-proxy       \n  Normal   Starting                 52m   kube-proxy       \n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeAllocatableEnforced  52m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Warning  InvalidDiskCapacity      52m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 52m   kubelet          Starting kubelet.\n  Normal   RegisteredNode           52m   node-controller  Node ip-172-31-14-110 event: Registered Node ip-172-31-14-110 in Controller\n  Normal   Starting                 52m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      52m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  52m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeHasNoDiskPressure    52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  52m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  52m   kubelet          Updated Node Allocatable limit across pods\n  Warning  InvalidDiskCapacity      52m   kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 52m   kubelet          Starting kubelet.\n  Normal   NodeReady                52m   kubelet          Node ip-172-31-14-110 status is now: NodeReady\n  Normal   NodeNotReady             51m   kubelet          Node ip-172-31-14-110 status is now: NodeNotReady\n  Normal   Starting                 51m   kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    51m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     51m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      51m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  51m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientMemory  51m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeReady                51m   kubelet          Node ip-172-31-14-110 status is now: NodeReady\n  Normal   Starting                 50m   kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      50m   kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  50m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    50m   kubelet          Node ip-172-31-14-110 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     50m   kubelet          Node ip-172-31-14-110 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             50m   kubelet          Node ip-172-31-14-110 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  50m   kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                50m   kubelet          Node ip-172-31-14-110 status is now: NodeReady\n"
    Nov 12 12:42:49.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-5402 describe namespace kubectl-5402'
    Nov 12 12:42:49.206: INFO: stderr: ""
    Nov 12 12:42:49.206: INFO: stdout: "Name:         kubectl-5402\nLabels:       e2e-framework=kubectl\n              e2e-run=9f11ea07-55ae-48b5-a2d0-18d79ec42f84\n              kubernetes.io/metadata.name=kubectl-5402\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:42:49.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5402" for this suite. 11/12/22 12:42:49.212
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:42:49.229
Nov 12 12:42:49.229: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 12:42:49.23
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:49.249
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:49.255
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 11/12/22 12:42:49.258
STEP: submitting the pod to kubernetes 11/12/22 12:42:49.258
Nov 12 12:42:49.272: INFO: Waiting up to 5m0s for pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" in namespace "pods-855" to be "running and ready"
Nov 12 12:42:49.282: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.990276ms
Nov 12 12:42:49.282: INFO: The phase of Pod pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:42:51.288: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.016072876s
Nov 12 12:42:51.288: INFO: The phase of Pod pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8 is Running (Ready = true)
Nov 12 12:42:51.288: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/12/22 12:42:51.292
STEP: updating the pod 11/12/22 12:42:51.3
Nov 12 12:42:51.814: INFO: Successfully updated pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8"
Nov 12 12:42:51.814: INFO: Waiting up to 5m0s for pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" in namespace "pods-855" to be "running"
Nov 12 12:42:51.820: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8": Phase="Running", Reason="", readiness=true. Elapsed: 5.218687ms
Nov 12 12:42:51.820: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 11/12/22 12:42:51.82
Nov 12 12:42:51.826: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 12:42:51.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-855" for this suite. 11/12/22 12:42:51.833
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":205,"skipped":3694,"failed":0}
------------------------------
• [2.616 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:42:49.229
    Nov 12 12:42:49.229: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 12:42:49.23
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:49.249
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:49.255
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 11/12/22 12:42:49.258
    STEP: submitting the pod to kubernetes 11/12/22 12:42:49.258
    Nov 12 12:42:49.272: INFO: Waiting up to 5m0s for pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" in namespace "pods-855" to be "running and ready"
    Nov 12 12:42:49.282: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.990276ms
    Nov 12 12:42:49.282: INFO: The phase of Pod pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:42:51.288: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.016072876s
    Nov 12 12:42:51.288: INFO: The phase of Pod pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8 is Running (Ready = true)
    Nov 12 12:42:51.288: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/12/22 12:42:51.292
    STEP: updating the pod 11/12/22 12:42:51.3
    Nov 12 12:42:51.814: INFO: Successfully updated pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8"
    Nov 12 12:42:51.814: INFO: Waiting up to 5m0s for pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" in namespace "pods-855" to be "running"
    Nov 12 12:42:51.820: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8": Phase="Running", Reason="", readiness=true. Elapsed: 5.218687ms
    Nov 12 12:42:51.820: INFO: Pod "pod-update-f02e8da4-e0d5-47c3-8cfe-450ca36621e8" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 11/12/22 12:42:51.82
    Nov 12 12:42:51.826: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 12:42:51.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-855" for this suite. 11/12/22 12:42:51.833
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:42:51.852
Nov 12 12:42:51.854: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename subpath 11/12/22 12:42:51.856
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:51.877
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:51.879
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 12:42:51.882
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-cjj6 11/12/22 12:42:51.896
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:42:51.896
Nov 12 12:42:51.907: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-cjj6" in namespace "subpath-1890" to be "Succeeded or Failed"
Nov 12 12:42:51.911: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.775927ms
Nov 12 12:42:53.919: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 2.012022317s
Nov 12 12:42:55.918: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 4.01099565s
Nov 12 12:42:57.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 6.009947371s
Nov 12 12:42:59.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 8.010310752s
Nov 12 12:43:01.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 10.010499059s
Nov 12 12:43:03.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 12.010307315s
Nov 12 12:43:05.918: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 14.011660332s
Nov 12 12:43:07.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 16.010768645s
Nov 12 12:43:09.921: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 18.014791415s
Nov 12 12:43:11.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 20.010553507s
Nov 12 12:43:13.916: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=false. Elapsed: 22.009559947s
Nov 12 12:43:15.916: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.009834814s
STEP: Saw pod success 11/12/22 12:43:15.916
Nov 12 12:43:15.917: INFO: Pod "pod-subpath-test-projected-cjj6" satisfied condition "Succeeded or Failed"
Nov 12 12:43:15.923: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-projected-cjj6 container test-container-subpath-projected-cjj6: <nil>
STEP: delete the pod 11/12/22 12:43:15.942
Nov 12 12:43:15.958: INFO: Waiting for pod pod-subpath-test-projected-cjj6 to disappear
Nov 12 12:43:15.964: INFO: Pod pod-subpath-test-projected-cjj6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-cjj6 11/12/22 12:43:15.964
Nov 12 12:43:15.964: INFO: Deleting pod "pod-subpath-test-projected-cjj6" in namespace "subpath-1890"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 12:43:15.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1890" for this suite. 11/12/22 12:43:15.973
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":206,"skipped":3698,"failed":0}
------------------------------
• [SLOW TEST] [24.130 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:42:51.852
    Nov 12 12:42:51.854: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename subpath 11/12/22 12:42:51.856
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:42:51.877
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:42:51.879
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 12:42:51.882
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-cjj6 11/12/22 12:42:51.896
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 12:42:51.896
    Nov 12 12:42:51.907: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-cjj6" in namespace "subpath-1890" to be "Succeeded or Failed"
    Nov 12 12:42:51.911: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.775927ms
    Nov 12 12:42:53.919: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 2.012022317s
    Nov 12 12:42:55.918: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 4.01099565s
    Nov 12 12:42:57.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 6.009947371s
    Nov 12 12:42:59.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 8.010310752s
    Nov 12 12:43:01.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 10.010499059s
    Nov 12 12:43:03.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 12.010307315s
    Nov 12 12:43:05.918: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 14.011660332s
    Nov 12 12:43:07.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 16.010768645s
    Nov 12 12:43:09.921: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 18.014791415s
    Nov 12 12:43:11.917: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=true. Elapsed: 20.010553507s
    Nov 12 12:43:13.916: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Running", Reason="", readiness=false. Elapsed: 22.009559947s
    Nov 12 12:43:15.916: INFO: Pod "pod-subpath-test-projected-cjj6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.009834814s
    STEP: Saw pod success 11/12/22 12:43:15.916
    Nov 12 12:43:15.917: INFO: Pod "pod-subpath-test-projected-cjj6" satisfied condition "Succeeded or Failed"
    Nov 12 12:43:15.923: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-projected-cjj6 container test-container-subpath-projected-cjj6: <nil>
    STEP: delete the pod 11/12/22 12:43:15.942
    Nov 12 12:43:15.958: INFO: Waiting for pod pod-subpath-test-projected-cjj6 to disappear
    Nov 12 12:43:15.964: INFO: Pod pod-subpath-test-projected-cjj6 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-cjj6 11/12/22 12:43:15.964
    Nov 12 12:43:15.964: INFO: Deleting pod "pod-subpath-test-projected-cjj6" in namespace "subpath-1890"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 12:43:15.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1890" for this suite. 11/12/22 12:43:15.973
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:43:15.984
Nov 12 12:43:15.985: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 12:43:15.986
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:43:16.004
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:43:16.008
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f in namespace container-probe-9755 11/12/22 12:43:16.011
Nov 12 12:43:16.028: INFO: Waiting up to 5m0s for pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f" in namespace "container-probe-9755" to be "not pending"
Nov 12 12:43:16.032: INFO: Pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.553942ms
Nov 12 12:43:18.038: INFO: Pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010232153s
Nov 12 12:43:18.038: INFO: Pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f" satisfied condition "not pending"
Nov 12 12:43:18.038: INFO: Started pod test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f in namespace container-probe-9755
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:43:18.038
Nov 12 12:43:18.044: INFO: Initial restart count of pod test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f is 0
STEP: deleting the pod 11/12/22 12:47:18.77
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 12:47:18.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9755" for this suite. 11/12/22 12:47:18.793
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":207,"skipped":3727,"failed":0}
------------------------------
• [SLOW TEST] [242.818 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:43:15.984
    Nov 12 12:43:15.985: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 12:43:15.986
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:43:16.004
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:43:16.008
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f in namespace container-probe-9755 11/12/22 12:43:16.011
    Nov 12 12:43:16.028: INFO: Waiting up to 5m0s for pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f" in namespace "container-probe-9755" to be "not pending"
    Nov 12 12:43:16.032: INFO: Pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.553942ms
    Nov 12 12:43:18.038: INFO: Pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010232153s
    Nov 12 12:43:18.038: INFO: Pod "test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f" satisfied condition "not pending"
    Nov 12 12:43:18.038: INFO: Started pod test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f in namespace container-probe-9755
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 12:43:18.038
    Nov 12 12:43:18.044: INFO: Initial restart count of pod test-webserver-53f193cd-4b63-42cf-ab99-f34c9712478f is 0
    STEP: deleting the pod 11/12/22 12:47:18.77
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 12:47:18.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-9755" for this suite. 11/12/22 12:47:18.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:47:18.806
Nov 12 12:47:18.806: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename daemonsets 11/12/22 12:47:18.807
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:18.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:18.833
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 11/12/22 12:47:18.865
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:47:18.876
Nov 12 12:47:18.882: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:18.883: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:18.887: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:47:18.887: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:47:19.894: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:19.894: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:19.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 12:47:19.899: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 12:47:20.895: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:20.895: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:20.900: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 12:47:20.900: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 12:47:21.894: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:21.894: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 12:47:21.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 12:47:21.899: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 11/12/22 12:47:21.903
STEP: DeleteCollection of the DaemonSets 11/12/22 12:47:21.908
STEP: Verify that ReplicaSets have been deleted 11/12/22 12:47:21.921
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Nov 12 12:47:21.940: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25924"},"items":null}

Nov 12 12:47:21.946: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25924"},"items":[{"metadata":{"name":"daemon-set-d8w4x","generateName":"daemon-set-","namespace":"daemonsets-7695","uid":"5781b50a-cdd8-483c-af6b-0d08e5f58007","resourceVersion":"25915","creationTimestamp":"2022-11-12T12:47:18Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8ee9125c-7988-4f9c-95f2-3d343d9a81cd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8ee9125c-7988-4f9c-95f2-3d343d9a81cd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-msthg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-msthg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-14-110","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-14-110"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"}],"hostIP":"172.31.14.110","podIP":"192.168.249.23","podIPs":[{"ip":"192.168.249.23"}],"startTime":"2022-11-12T12:47:18Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T12:47:19Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://0d826714ff4124f080f392d2ca34914e959c8c68798093f84bdac34ff04a360e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-nv55m","generateName":"daemon-set-","namespace":"daemonsets-7695","uid":"58d8c509-e37d-42ac-9005-c7b24c45e65d","resourceVersion":"25921","creationTimestamp":"2022-11-12T12:47:18Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8ee9125c-7988-4f9c-95f2-3d343d9a81cd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8ee9125c-7988-4f9c-95f2-3d343d9a81cd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-c2dt7","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-c2dt7","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-47-219","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-47-219"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"}],"hostIP":"172.31.47.219","podIP":"192.168.27.113","podIPs":[{"ip":"192.168.27.113"}],"startTime":"2022-11-12T12:47:18Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T12:47:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://36d8274dd784e43bbfdfddc9ef493707864a8513c0ee2040ab29483f80520326","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-szw8s","generateName":"daemon-set-","namespace":"daemonsets-7695","uid":"27a23299-249e-4e3c-8b67-d118546dcedf","resourceVersion":"25918","creationTimestamp":"2022-11-12T12:47:18Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8ee9125c-7988-4f9c-95f2-3d343d9a81cd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8ee9125c-7988-4f9c-95f2-3d343d9a81cd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-4qgx7","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-4qgx7","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-89-190","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-89-190"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"}],"hostIP":"172.31.89.190","podIP":"192.168.128.197","podIPs":[{"ip":"192.168.128.197"}],"startTime":"2022-11-12T12:47:18Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T12:47:19Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://4d64b5cbaa793e886aeb9f21e6b5c16f35d9f0df99c0fafbd6c628b77b855b96","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 12:47:21.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7695" for this suite. 11/12/22 12:47:21.973
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":208,"skipped":3751,"failed":0}
------------------------------
• [3.176 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:47:18.806
    Nov 12 12:47:18.806: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename daemonsets 11/12/22 12:47:18.807
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:18.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:18.833
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 11/12/22 12:47:18.865
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 12:47:18.876
    Nov 12 12:47:18.882: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:18.883: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:18.887: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:47:18.887: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:47:19.894: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:19.894: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:19.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 12:47:19.899: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 12:47:20.895: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:20.895: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:20.900: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 12:47:20.900: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 12:47:21.894: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:21.894: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 12:47:21.899: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 12:47:21.899: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 11/12/22 12:47:21.903
    STEP: DeleteCollection of the DaemonSets 11/12/22 12:47:21.908
    STEP: Verify that ReplicaSets have been deleted 11/12/22 12:47:21.921
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Nov 12 12:47:21.940: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"25924"},"items":null}

    Nov 12 12:47:21.946: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"25924"},"items":[{"metadata":{"name":"daemon-set-d8w4x","generateName":"daemon-set-","namespace":"daemonsets-7695","uid":"5781b50a-cdd8-483c-af6b-0d08e5f58007","resourceVersion":"25915","creationTimestamp":"2022-11-12T12:47:18Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8ee9125c-7988-4f9c-95f2-3d343d9a81cd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8ee9125c-7988-4f9c-95f2-3d343d9a81cd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-msthg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-msthg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-14-110","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-14-110"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"}],"hostIP":"172.31.14.110","podIP":"192.168.249.23","podIPs":[{"ip":"192.168.249.23"}],"startTime":"2022-11-12T12:47:18Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T12:47:19Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://0d826714ff4124f080f392d2ca34914e959c8c68798093f84bdac34ff04a360e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-nv55m","generateName":"daemon-set-","namespace":"daemonsets-7695","uid":"58d8c509-e37d-42ac-9005-c7b24c45e65d","resourceVersion":"25921","creationTimestamp":"2022-11-12T12:47:18Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8ee9125c-7988-4f9c-95f2-3d343d9a81cd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8ee9125c-7988-4f9c-95f2-3d343d9a81cd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:21Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.113\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-c2dt7","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-c2dt7","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-47-219","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-47-219"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"}],"hostIP":"172.31.47.219","podIP":"192.168.27.113","podIPs":[{"ip":"192.168.27.113"}],"startTime":"2022-11-12T12:47:18Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T12:47:20Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://36d8274dd784e43bbfdfddc9ef493707864a8513c0ee2040ab29483f80520326","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-szw8s","generateName":"daemon-set-","namespace":"daemonsets-7695","uid":"27a23299-249e-4e3c-8b67-d118546dcedf","resourceVersion":"25918","creationTimestamp":"2022-11-12T12:47:18Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"8ee9125c-7988-4f9c-95f2-3d343d9a81cd","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:18Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8ee9125c-7988-4f9c-95f2-3d343d9a81cd\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-12T12:47:20Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.197\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-4qgx7","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-4qgx7","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-89-190","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-89-190"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:20Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-12T12:47:18Z"}],"hostIP":"172.31.89.190","podIP":"192.168.128.197","podIPs":[{"ip":"192.168.128.197"}],"startTime":"2022-11-12T12:47:18Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-12T12:47:19Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://4d64b5cbaa793e886aeb9f21e6b5c16f35d9f0df99c0fafbd6c628b77b855b96","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 12:47:21.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7695" for this suite. 11/12/22 12:47:21.973
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:47:21.986
Nov 12 12:47:21.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:47:21.987
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:22.005
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:22.016
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-6806 11/12/22 12:47:22.022
STEP: creating a selector 11/12/22 12:47:22.023
STEP: Creating the service pods in kubernetes 11/12/22 12:47:22.023
Nov 12 12:47:22.023: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 12 12:47:22.064: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6806" to be "running and ready"
Nov 12 12:47:22.071: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.990969ms
Nov 12 12:47:22.071: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:47:24.077: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013039512s
Nov 12 12:47:24.077: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:47:26.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013454066s
Nov 12 12:47:26.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:28.076: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.012219494s
Nov 12 12:47:28.076: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:30.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.013569975s
Nov 12 12:47:30.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:32.081: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016335647s
Nov 12 12:47:32.081: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:34.079: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.015229755s
Nov 12 12:47:34.079: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:36.077: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.012662637s
Nov 12 12:47:36.077: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:38.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.013863404s
Nov 12 12:47:38.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:40.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014236901s
Nov 12 12:47:40.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:42.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013798074s
Nov 12 12:47:42.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 12 12:47:44.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014020964s
Nov 12 12:47:44.078: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 12 12:47:44.078: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 12 12:47:44.083: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6806" to be "running and ready"
Nov 12 12:47:44.089: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.121698ms
Nov 12 12:47:44.089: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 12 12:47:44.089: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 12 12:47:44.094: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6806" to be "running and ready"
Nov 12 12:47:44.098: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.380971ms
Nov 12 12:47:44.098: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 12 12:47:44.098: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/12/22 12:47:44.103
Nov 12 12:47:44.111: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6806" to be "running"
Nov 12 12:47:44.117: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.909017ms
Nov 12 12:47:46.122: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010648486s
Nov 12 12:47:46.122: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 12 12:47:46.127: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 12 12:47:46.127: INFO: Breadth first check of 192.168.249.19 on host 172.31.14.110...
Nov 12 12:47:46.132: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.48:9080/dial?request=hostname&protocol=udp&host=192.168.249.19&port=8081&tries=1'] Namespace:pod-network-test-6806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:47:46.132: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:47:46.133: INFO: ExecWithOptions: Clientset creation
Nov 12 12:47:46.133: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.48%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.249.19%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 12:47:46.226: INFO: Waiting for responses: map[]
Nov 12 12:47:46.226: INFO: reached 192.168.249.19 after 0/1 tries
Nov 12 12:47:46.226: INFO: Breadth first check of 192.168.27.114 on host 172.31.47.219...
Nov 12 12:47:46.231: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.48:9080/dial?request=hostname&protocol=udp&host=192.168.27.114&port=8081&tries=1'] Namespace:pod-network-test-6806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:47:46.231: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:47:46.231: INFO: ExecWithOptions: Clientset creation
Nov 12 12:47:46.231: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.48%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.27.114%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 12:47:46.327: INFO: Waiting for responses: map[]
Nov 12 12:47:46.327: INFO: reached 192.168.27.114 after 0/1 tries
Nov 12 12:47:46.327: INFO: Breadth first check of 192.168.128.198 on host 172.31.89.190...
Nov 12 12:47:46.332: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.48:9080/dial?request=hostname&protocol=udp&host=192.168.128.198&port=8081&tries=1'] Namespace:pod-network-test-6806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:47:46.332: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:47:46.333: INFO: ExecWithOptions: Clientset creation
Nov 12 12:47:46.333: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.48%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.128.198%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 12 12:47:46.416: INFO: Waiting for responses: map[]
Nov 12 12:47:46.416: INFO: reached 192.168.128.198 after 0/1 tries
Nov 12 12:47:46.416: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 12 12:47:46.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6806" for this suite. 11/12/22 12:47:46.422
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":209,"skipped":3781,"failed":0}
------------------------------
• [SLOW TEST] [24.445 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:47:21.986
    Nov 12 12:47:21.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pod-network-test 11/12/22 12:47:21.987
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:22.005
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:22.016
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-6806 11/12/22 12:47:22.022
    STEP: creating a selector 11/12/22 12:47:22.023
    STEP: Creating the service pods in kubernetes 11/12/22 12:47:22.023
    Nov 12 12:47:22.023: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 12 12:47:22.064: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-6806" to be "running and ready"
    Nov 12 12:47:22.071: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.990969ms
    Nov 12 12:47:22.071: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:47:24.077: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013039512s
    Nov 12 12:47:24.077: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:47:26.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013454066s
    Nov 12 12:47:26.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:28.076: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.012219494s
    Nov 12 12:47:28.076: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:30.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.013569975s
    Nov 12 12:47:30.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:32.081: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016335647s
    Nov 12 12:47:32.081: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:34.079: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.015229755s
    Nov 12 12:47:34.079: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:36.077: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.012662637s
    Nov 12 12:47:36.077: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:38.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.013863404s
    Nov 12 12:47:38.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:40.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.014236901s
    Nov 12 12:47:40.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:42.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013798074s
    Nov 12 12:47:42.078: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 12 12:47:44.078: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014020964s
    Nov 12 12:47:44.078: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 12 12:47:44.078: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 12 12:47:44.083: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-6806" to be "running and ready"
    Nov 12 12:47:44.089: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.121698ms
    Nov 12 12:47:44.089: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 12 12:47:44.089: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 12 12:47:44.094: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-6806" to be "running and ready"
    Nov 12 12:47:44.098: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.380971ms
    Nov 12 12:47:44.098: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 12 12:47:44.098: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/12/22 12:47:44.103
    Nov 12 12:47:44.111: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-6806" to be "running"
    Nov 12 12:47:44.117: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.909017ms
    Nov 12 12:47:46.122: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.010648486s
    Nov 12 12:47:46.122: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 12 12:47:46.127: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 12 12:47:46.127: INFO: Breadth first check of 192.168.249.19 on host 172.31.14.110...
    Nov 12 12:47:46.132: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.48:9080/dial?request=hostname&protocol=udp&host=192.168.249.19&port=8081&tries=1'] Namespace:pod-network-test-6806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:47:46.132: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:47:46.133: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:47:46.133: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.48%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.249.19%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 12:47:46.226: INFO: Waiting for responses: map[]
    Nov 12 12:47:46.226: INFO: reached 192.168.249.19 after 0/1 tries
    Nov 12 12:47:46.226: INFO: Breadth first check of 192.168.27.114 on host 172.31.47.219...
    Nov 12 12:47:46.231: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.48:9080/dial?request=hostname&protocol=udp&host=192.168.27.114&port=8081&tries=1'] Namespace:pod-network-test-6806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:47:46.231: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:47:46.231: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:47:46.231: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.48%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.27.114%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 12:47:46.327: INFO: Waiting for responses: map[]
    Nov 12 12:47:46.327: INFO: reached 192.168.27.114 after 0/1 tries
    Nov 12 12:47:46.327: INFO: Breadth first check of 192.168.128.198 on host 172.31.89.190...
    Nov 12 12:47:46.332: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.249.48:9080/dial?request=hostname&protocol=udp&host=192.168.128.198&port=8081&tries=1'] Namespace:pod-network-test-6806 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:47:46.332: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:47:46.333: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:47:46.333: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-6806/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.249.48%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.128.198%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 12 12:47:46.416: INFO: Waiting for responses: map[]
    Nov 12 12:47:46.416: INFO: reached 192.168.128.198 after 0/1 tries
    Nov 12 12:47:46.416: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 12 12:47:46.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-6806" for this suite. 11/12/22 12:47:46.422
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:47:46.436
Nov 12 12:47:46.436: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 12:47:46.436
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:46.457
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:46.464
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 11/12/22 12:47:46.467
Nov 12 12:47:46.467: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Nov 12 12:47:46.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
Nov 12 12:47:47.594: INFO: stderr: ""
Nov 12 12:47:47.594: INFO: stdout: "service/agnhost-replica created\n"
Nov 12 12:47:47.594: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Nov 12 12:47:47.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
Nov 12 12:47:47.861: INFO: stderr: ""
Nov 12 12:47:47.861: INFO: stdout: "service/agnhost-primary created\n"
Nov 12 12:47:47.861: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 12 12:47:47.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
Nov 12 12:47:48.144: INFO: stderr: ""
Nov 12 12:47:48.144: INFO: stdout: "service/frontend created\n"
Nov 12 12:47:48.144: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov 12 12:47:48.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
Nov 12 12:47:48.431: INFO: stderr: ""
Nov 12 12:47:48.431: INFO: stdout: "deployment.apps/frontend created\n"
Nov 12 12:47:48.431: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 12 12:47:48.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
Nov 12 12:47:48.683: INFO: stderr: ""
Nov 12 12:47:48.683: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Nov 12 12:47:48.683: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 12 12:47:48.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
Nov 12 12:47:49.056: INFO: stderr: ""
Nov 12 12:47:49.056: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 11/12/22 12:47:49.056
Nov 12 12:47:49.056: INFO: Waiting for all frontend pods to be Running.
Nov 12 12:47:54.109: INFO: Waiting for frontend to serve content.
Nov 12 12:47:54.123: INFO: Trying to add a new entry to the guestbook.
Nov 12 12:47:54.138: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 11/12/22 12:47:54.157
Nov 12 12:47:54.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
Nov 12 12:47:54.285: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 12:47:54.285: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 11/12/22 12:47:54.285
Nov 12 12:47:54.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
Nov 12 12:47:54.462: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 12:47:54.462: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/12/22 12:47:54.462
Nov 12 12:47:54.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
Nov 12 12:47:54.577: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 12:47:54.577: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/12/22 12:47:54.577
Nov 12 12:47:54.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
Nov 12 12:47:54.727: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 12:47:54.727: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/12/22 12:47:54.727
Nov 12 12:47:54.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
Nov 12 12:47:54.834: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 12:47:54.834: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/12/22 12:47:54.834
Nov 12 12:47:54.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
Nov 12 12:47:54.983: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 12:47:54.983: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 12:47:54.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4411" for this suite. 11/12/22 12:47:54.994
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":210,"skipped":3826,"failed":0}
------------------------------
• [SLOW TEST] [8.594 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:47:46.436
    Nov 12 12:47:46.436: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 12:47:46.436
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:46.457
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:46.464
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 11/12/22 12:47:46.467
    Nov 12 12:47:46.467: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Nov 12 12:47:46.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
    Nov 12 12:47:47.594: INFO: stderr: ""
    Nov 12 12:47:47.594: INFO: stdout: "service/agnhost-replica created\n"
    Nov 12 12:47:47.594: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Nov 12 12:47:47.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
    Nov 12 12:47:47.861: INFO: stderr: ""
    Nov 12 12:47:47.861: INFO: stdout: "service/agnhost-primary created\n"
    Nov 12 12:47:47.861: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Nov 12 12:47:47.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
    Nov 12 12:47:48.144: INFO: stderr: ""
    Nov 12 12:47:48.144: INFO: stdout: "service/frontend created\n"
    Nov 12 12:47:48.144: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Nov 12 12:47:48.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
    Nov 12 12:47:48.431: INFO: stderr: ""
    Nov 12 12:47:48.431: INFO: stdout: "deployment.apps/frontend created\n"
    Nov 12 12:47:48.431: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 12 12:47:48.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
    Nov 12 12:47:48.683: INFO: stderr: ""
    Nov 12 12:47:48.683: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Nov 12 12:47:48.683: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 12 12:47:48.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 create -f -'
    Nov 12 12:47:49.056: INFO: stderr: ""
    Nov 12 12:47:49.056: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 11/12/22 12:47:49.056
    Nov 12 12:47:49.056: INFO: Waiting for all frontend pods to be Running.
    Nov 12 12:47:54.109: INFO: Waiting for frontend to serve content.
    Nov 12 12:47:54.123: INFO: Trying to add a new entry to the guestbook.
    Nov 12 12:47:54.138: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 11/12/22 12:47:54.157
    Nov 12 12:47:54.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
    Nov 12 12:47:54.285: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 12:47:54.285: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 11/12/22 12:47:54.285
    Nov 12 12:47:54.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
    Nov 12 12:47:54.462: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 12:47:54.462: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/12/22 12:47:54.462
    Nov 12 12:47:54.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
    Nov 12 12:47:54.577: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 12:47:54.577: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/12/22 12:47:54.577
    Nov 12 12:47:54.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
    Nov 12 12:47:54.727: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 12:47:54.727: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/12/22 12:47:54.727
    Nov 12 12:47:54.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
    Nov 12 12:47:54.834: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 12:47:54.834: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/12/22 12:47:54.834
    Nov 12 12:47:54.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4411 delete --grace-period=0 --force -f -'
    Nov 12 12:47:54.983: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 12:47:54.983: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 12:47:54.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4411" for this suite. 11/12/22 12:47:54.994
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:47:55.03
Nov 12 12:47:55.030: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:47:55.035
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:55.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:55.06
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Nov 12 12:47:55.109: INFO: created pod pod-service-account-defaultsa
Nov 12 12:47:55.109: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 12 12:47:55.118: INFO: created pod pod-service-account-mountsa
Nov 12 12:47:55.118: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 12 12:47:55.128: INFO: created pod pod-service-account-nomountsa
Nov 12 12:47:55.128: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 12 12:47:55.142: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 12 12:47:55.142: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 12 12:47:55.154: INFO: created pod pod-service-account-mountsa-mountspec
Nov 12 12:47:55.154: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 12 12:47:55.165: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 12 12:47:55.165: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 12 12:47:55.173: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 12 12:47:55.173: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 12 12:47:55.210: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 12 12:47:55.210: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 12 12:47:55.215: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 12 12:47:55.215: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 12 12:47:55.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-855" for this suite. 11/12/22 12:47:55.223
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":211,"skipped":3835,"failed":0}
------------------------------
• [0.217 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:47:55.03
    Nov 12 12:47:55.030: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename svcaccounts 11/12/22 12:47:55.035
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:55.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:55.06
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Nov 12 12:47:55.109: INFO: created pod pod-service-account-defaultsa
    Nov 12 12:47:55.109: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Nov 12 12:47:55.118: INFO: created pod pod-service-account-mountsa
    Nov 12 12:47:55.118: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Nov 12 12:47:55.128: INFO: created pod pod-service-account-nomountsa
    Nov 12 12:47:55.128: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Nov 12 12:47:55.142: INFO: created pod pod-service-account-defaultsa-mountspec
    Nov 12 12:47:55.142: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Nov 12 12:47:55.154: INFO: created pod pod-service-account-mountsa-mountspec
    Nov 12 12:47:55.154: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Nov 12 12:47:55.165: INFO: created pod pod-service-account-nomountsa-mountspec
    Nov 12 12:47:55.165: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Nov 12 12:47:55.173: INFO: created pod pod-service-account-defaultsa-nomountspec
    Nov 12 12:47:55.173: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Nov 12 12:47:55.210: INFO: created pod pod-service-account-mountsa-nomountspec
    Nov 12 12:47:55.210: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Nov 12 12:47:55.215: INFO: created pod pod-service-account-nomountsa-nomountspec
    Nov 12 12:47:55.215: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 12 12:47:55.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-855" for this suite. 11/12/22 12:47:55.223
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:47:55.259
Nov 12 12:47:55.259: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename gc 11/12/22 12:47:55.26
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:55.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:55.284
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 11/12/22 12:47:55.295
STEP: create the rc2 11/12/22 12:47:55.301
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/12/22 12:48:00.315
STEP: delete the rc simpletest-rc-to-be-deleted 11/12/22 12:48:01.004
STEP: wait for the rc to be deleted 11/12/22 12:48:01.026
Nov 12 12:48:06.052: INFO: 70 pods remaining
Nov 12 12:48:06.052: INFO: 70 pods has nil DeletionTimestamp
Nov 12 12:48:06.052: INFO: 
STEP: Gathering metrics 11/12/22 12:48:11.041
W1112 12:48:11.049668      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 12:48:11.049: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 12 12:48:11.049: INFO: Deleting pod "simpletest-rc-to-be-deleted-2b8rx" in namespace "gc-3744"
Nov 12 12:48:11.068: INFO: Deleting pod "simpletest-rc-to-be-deleted-2f422" in namespace "gc-3744"
Nov 12 12:48:11.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lpw8" in namespace "gc-3744"
Nov 12 12:48:11.100: INFO: Deleting pod "simpletest-rc-to-be-deleted-2sdlv" in namespace "gc-3744"
Nov 12 12:48:11.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-2txmt" in namespace "gc-3744"
Nov 12 12:48:11.139: INFO: Deleting pod "simpletest-rc-to-be-deleted-48p5d" in namespace "gc-3744"
Nov 12 12:48:11.176: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jjv4" in namespace "gc-3744"
Nov 12 12:48:11.199: INFO: Deleting pod "simpletest-rc-to-be-deleted-5m2dm" in namespace "gc-3744"
Nov 12 12:48:11.242: INFO: Deleting pod "simpletest-rc-to-be-deleted-649ch" in namespace "gc-3744"
Nov 12 12:48:11.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fkds" in namespace "gc-3744"
Nov 12 12:48:11.280: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fss4" in namespace "gc-3744"
Nov 12 12:48:11.295: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k5t2" in namespace "gc-3744"
Nov 12 12:48:11.316: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mhlz" in namespace "gc-3744"
Nov 12 12:48:11.343: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rq87" in namespace "gc-3744"
Nov 12 12:48:11.363: INFO: Deleting pod "simpletest-rc-to-be-deleted-72fn8" in namespace "gc-3744"
Nov 12 12:48:11.385: INFO: Deleting pod "simpletest-rc-to-be-deleted-7855g" in namespace "gc-3744"
Nov 12 12:48:11.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cwdw" in namespace "gc-3744"
Nov 12 12:48:11.423: INFO: Deleting pod "simpletest-rc-to-be-deleted-7dlz8" in namespace "gc-3744"
Nov 12 12:48:11.439: INFO: Deleting pod "simpletest-rc-to-be-deleted-7tkln" in namespace "gc-3744"
Nov 12 12:48:11.455: INFO: Deleting pod "simpletest-rc-to-be-deleted-87krd" in namespace "gc-3744"
Nov 12 12:48:11.471: INFO: Deleting pod "simpletest-rc-to-be-deleted-8h5wg" in namespace "gc-3744"
Nov 12 12:48:11.486: INFO: Deleting pod "simpletest-rc-to-be-deleted-8k886" in namespace "gc-3744"
Nov 12 12:48:11.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-988sf" in namespace "gc-3744"
Nov 12 12:48:11.521: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fg79" in namespace "gc-3744"
Nov 12 12:48:11.537: INFO: Deleting pod "simpletest-rc-to-be-deleted-9j28r" in namespace "gc-3744"
Nov 12 12:48:11.553: INFO: Deleting pod "simpletest-rc-to-be-deleted-9ldlt" in namespace "gc-3744"
Nov 12 12:48:11.573: INFO: Deleting pod "simpletest-rc-to-be-deleted-9vqgr" in namespace "gc-3744"
Nov 12 12:48:11.592: INFO: Deleting pod "simpletest-rc-to-be-deleted-b2tkp" in namespace "gc-3744"
Nov 12 12:48:11.607: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6v69" in namespace "gc-3744"
Nov 12 12:48:11.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbqgf" in namespace "gc-3744"
Nov 12 12:48:11.637: INFO: Deleting pod "simpletest-rc-to-be-deleted-blj4w" in namespace "gc-3744"
Nov 12 12:48:11.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-cn5sf" in namespace "gc-3744"
Nov 12 12:48:11.670: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7zdc" in namespace "gc-3744"
Nov 12 12:48:11.685: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkghh" in namespace "gc-3744"
Nov 12 12:48:11.702: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzk8n" in namespace "gc-3744"
Nov 12 12:48:11.723: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjj2z" in namespace "gc-3744"
Nov 12 12:48:11.738: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjrdv" in namespace "gc-3744"
Nov 12 12:48:11.752: INFO: Deleting pod "simpletest-rc-to-be-deleted-frwzl" in namespace "gc-3744"
Nov 12 12:48:11.767: INFO: Deleting pod "simpletest-rc-to-be-deleted-fvpv4" in namespace "gc-3744"
Nov 12 12:48:11.801: INFO: Deleting pod "simpletest-rc-to-be-deleted-fx4mm" in namespace "gc-3744"
Nov 12 12:48:11.815: INFO: Deleting pod "simpletest-rc-to-be-deleted-gl8sr" in namespace "gc-3744"
Nov 12 12:48:11.841: INFO: Deleting pod "simpletest-rc-to-be-deleted-grzmr" in namespace "gc-3744"
Nov 12 12:48:11.860: INFO: Deleting pod "simpletest-rc-to-be-deleted-h2w28" in namespace "gc-3744"
Nov 12 12:48:11.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-hhc69" in namespace "gc-3744"
Nov 12 12:48:11.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp6xz" in namespace "gc-3744"
Nov 12 12:48:11.915: INFO: Deleting pod "simpletest-rc-to-be-deleted-hqqn2" in namespace "gc-3744"
Nov 12 12:48:11.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrcb2" in namespace "gc-3744"
Nov 12 12:48:11.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-jns6z" in namespace "gc-3744"
Nov 12 12:48:11.962: INFO: Deleting pod "simpletest-rc-to-be-deleted-jp68v" in namespace "gc-3744"
Nov 12 12:48:11.977: INFO: Deleting pod "simpletest-rc-to-be-deleted-jvftq" in namespace "gc-3744"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 12:48:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3744" for this suite. 11/12/22 12:48:11.999
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":212,"skipped":3927,"failed":0}
------------------------------
• [SLOW TEST] [16.752 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:47:55.259
    Nov 12 12:47:55.259: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename gc 11/12/22 12:47:55.26
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:47:55.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:47:55.284
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 11/12/22 12:47:55.295
    STEP: create the rc2 11/12/22 12:47:55.301
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/12/22 12:48:00.315
    STEP: delete the rc simpletest-rc-to-be-deleted 11/12/22 12:48:01.004
    STEP: wait for the rc to be deleted 11/12/22 12:48:01.026
    Nov 12 12:48:06.052: INFO: 70 pods remaining
    Nov 12 12:48:06.052: INFO: 70 pods has nil DeletionTimestamp
    Nov 12 12:48:06.052: INFO: 
    STEP: Gathering metrics 11/12/22 12:48:11.041
    W1112 12:48:11.049668      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 12:48:11.049: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 12 12:48:11.049: INFO: Deleting pod "simpletest-rc-to-be-deleted-2b8rx" in namespace "gc-3744"
    Nov 12 12:48:11.068: INFO: Deleting pod "simpletest-rc-to-be-deleted-2f422" in namespace "gc-3744"
    Nov 12 12:48:11.085: INFO: Deleting pod "simpletest-rc-to-be-deleted-2lpw8" in namespace "gc-3744"
    Nov 12 12:48:11.100: INFO: Deleting pod "simpletest-rc-to-be-deleted-2sdlv" in namespace "gc-3744"
    Nov 12 12:48:11.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-2txmt" in namespace "gc-3744"
    Nov 12 12:48:11.139: INFO: Deleting pod "simpletest-rc-to-be-deleted-48p5d" in namespace "gc-3744"
    Nov 12 12:48:11.176: INFO: Deleting pod "simpletest-rc-to-be-deleted-5jjv4" in namespace "gc-3744"
    Nov 12 12:48:11.199: INFO: Deleting pod "simpletest-rc-to-be-deleted-5m2dm" in namespace "gc-3744"
    Nov 12 12:48:11.242: INFO: Deleting pod "simpletest-rc-to-be-deleted-649ch" in namespace "gc-3744"
    Nov 12 12:48:11.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fkds" in namespace "gc-3744"
    Nov 12 12:48:11.280: INFO: Deleting pod "simpletest-rc-to-be-deleted-6fss4" in namespace "gc-3744"
    Nov 12 12:48:11.295: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k5t2" in namespace "gc-3744"
    Nov 12 12:48:11.316: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mhlz" in namespace "gc-3744"
    Nov 12 12:48:11.343: INFO: Deleting pod "simpletest-rc-to-be-deleted-6rq87" in namespace "gc-3744"
    Nov 12 12:48:11.363: INFO: Deleting pod "simpletest-rc-to-be-deleted-72fn8" in namespace "gc-3744"
    Nov 12 12:48:11.385: INFO: Deleting pod "simpletest-rc-to-be-deleted-7855g" in namespace "gc-3744"
    Nov 12 12:48:11.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-7cwdw" in namespace "gc-3744"
    Nov 12 12:48:11.423: INFO: Deleting pod "simpletest-rc-to-be-deleted-7dlz8" in namespace "gc-3744"
    Nov 12 12:48:11.439: INFO: Deleting pod "simpletest-rc-to-be-deleted-7tkln" in namespace "gc-3744"
    Nov 12 12:48:11.455: INFO: Deleting pod "simpletest-rc-to-be-deleted-87krd" in namespace "gc-3744"
    Nov 12 12:48:11.471: INFO: Deleting pod "simpletest-rc-to-be-deleted-8h5wg" in namespace "gc-3744"
    Nov 12 12:48:11.486: INFO: Deleting pod "simpletest-rc-to-be-deleted-8k886" in namespace "gc-3744"
    Nov 12 12:48:11.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-988sf" in namespace "gc-3744"
    Nov 12 12:48:11.521: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fg79" in namespace "gc-3744"
    Nov 12 12:48:11.537: INFO: Deleting pod "simpletest-rc-to-be-deleted-9j28r" in namespace "gc-3744"
    Nov 12 12:48:11.553: INFO: Deleting pod "simpletest-rc-to-be-deleted-9ldlt" in namespace "gc-3744"
    Nov 12 12:48:11.573: INFO: Deleting pod "simpletest-rc-to-be-deleted-9vqgr" in namespace "gc-3744"
    Nov 12 12:48:11.592: INFO: Deleting pod "simpletest-rc-to-be-deleted-b2tkp" in namespace "gc-3744"
    Nov 12 12:48:11.607: INFO: Deleting pod "simpletest-rc-to-be-deleted-b6v69" in namespace "gc-3744"
    Nov 12 12:48:11.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-bbqgf" in namespace "gc-3744"
    Nov 12 12:48:11.637: INFO: Deleting pod "simpletest-rc-to-be-deleted-blj4w" in namespace "gc-3744"
    Nov 12 12:48:11.656: INFO: Deleting pod "simpletest-rc-to-be-deleted-cn5sf" in namespace "gc-3744"
    Nov 12 12:48:11.670: INFO: Deleting pod "simpletest-rc-to-be-deleted-d7zdc" in namespace "gc-3744"
    Nov 12 12:48:11.685: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkghh" in namespace "gc-3744"
    Nov 12 12:48:11.702: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzk8n" in namespace "gc-3744"
    Nov 12 12:48:11.723: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjj2z" in namespace "gc-3744"
    Nov 12 12:48:11.738: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjrdv" in namespace "gc-3744"
    Nov 12 12:48:11.752: INFO: Deleting pod "simpletest-rc-to-be-deleted-frwzl" in namespace "gc-3744"
    Nov 12 12:48:11.767: INFO: Deleting pod "simpletest-rc-to-be-deleted-fvpv4" in namespace "gc-3744"
    Nov 12 12:48:11.801: INFO: Deleting pod "simpletest-rc-to-be-deleted-fx4mm" in namespace "gc-3744"
    Nov 12 12:48:11.815: INFO: Deleting pod "simpletest-rc-to-be-deleted-gl8sr" in namespace "gc-3744"
    Nov 12 12:48:11.841: INFO: Deleting pod "simpletest-rc-to-be-deleted-grzmr" in namespace "gc-3744"
    Nov 12 12:48:11.860: INFO: Deleting pod "simpletest-rc-to-be-deleted-h2w28" in namespace "gc-3744"
    Nov 12 12:48:11.877: INFO: Deleting pod "simpletest-rc-to-be-deleted-hhc69" in namespace "gc-3744"
    Nov 12 12:48:11.895: INFO: Deleting pod "simpletest-rc-to-be-deleted-hp6xz" in namespace "gc-3744"
    Nov 12 12:48:11.915: INFO: Deleting pod "simpletest-rc-to-be-deleted-hqqn2" in namespace "gc-3744"
    Nov 12 12:48:11.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-hrcb2" in namespace "gc-3744"
    Nov 12 12:48:11.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-jns6z" in namespace "gc-3744"
    Nov 12 12:48:11.962: INFO: Deleting pod "simpletest-rc-to-be-deleted-jp68v" in namespace "gc-3744"
    Nov 12 12:48:11.977: INFO: Deleting pod "simpletest-rc-to-be-deleted-jvftq" in namespace "gc-3744"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 12:48:11.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3744" for this suite. 11/12/22 12:48:11.999
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:12.016
Nov 12 12:48:12.016: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replicaset 11/12/22 12:48:12.017
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:12.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:12.042
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 11/12/22 12:48:12.051
STEP: Verify that the required pods have come up. 11/12/22 12:48:12.062
Nov 12 12:48:12.071: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 12 12:48:17.078: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 12:48:17.078
Nov 12 12:48:17.079: INFO: Waiting up to 5m0s for pod "test-rs-qlqw2" in namespace "replicaset-1732" to be "running"
Nov 12 12:48:17.082: INFO: Pod "test-rs-qlqw2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.817161ms
Nov 12 12:48:19.087: INFO: Pod "test-rs-qlqw2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008144902s
Nov 12 12:48:21.089: INFO: Pod "test-rs-qlqw2": Phase="Running", Reason="", readiness=true. Elapsed: 4.010031804s
Nov 12 12:48:21.089: INFO: Pod "test-rs-qlqw2" satisfied condition "running"
STEP: Getting /status 11/12/22 12:48:21.089
Nov 12 12:48:21.093: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 11/12/22 12:48:21.093
Nov 12 12:48:21.106: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 11/12/22 12:48:21.106
Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: ADDED
Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: MODIFIED
Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: MODIFIED
Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: MODIFIED
Nov 12 12:48:21.108: INFO: Found replicaset test-rs in namespace replicaset-1732 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 12 12:48:21.108: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 11/12/22 12:48:21.108
Nov 12 12:48:21.109: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 12 12:48:21.115: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 11/12/22 12:48:21.116
Nov 12 12:48:21.117: INFO: Observed &ReplicaSet event: ADDED
Nov 12 12:48:21.117: INFO: Observed &ReplicaSet event: MODIFIED
Nov 12 12:48:21.118: INFO: Observed &ReplicaSet event: MODIFIED
Nov 12 12:48:21.121: INFO: Observed &ReplicaSet event: MODIFIED
Nov 12 12:48:21.121: INFO: Observed replicaset test-rs in namespace replicaset-1732 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 12:48:21.121: INFO: Observed &ReplicaSet event: MODIFIED
Nov 12 12:48:21.121: INFO: Found replicaset test-rs in namespace replicaset-1732 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Nov 12 12:48:21.121: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 12:48:21.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1732" for this suite. 11/12/22 12:48:21.126
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":213,"skipped":3979,"failed":0}
------------------------------
• [SLOW TEST] [9.119 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:12.016
    Nov 12 12:48:12.016: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replicaset 11/12/22 12:48:12.017
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:12.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:12.042
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 11/12/22 12:48:12.051
    STEP: Verify that the required pods have come up. 11/12/22 12:48:12.062
    Nov 12 12:48:12.071: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 12 12:48:17.078: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 12:48:17.078
    Nov 12 12:48:17.079: INFO: Waiting up to 5m0s for pod "test-rs-qlqw2" in namespace "replicaset-1732" to be "running"
    Nov 12 12:48:17.082: INFO: Pod "test-rs-qlqw2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.817161ms
    Nov 12 12:48:19.087: INFO: Pod "test-rs-qlqw2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008144902s
    Nov 12 12:48:21.089: INFO: Pod "test-rs-qlqw2": Phase="Running", Reason="", readiness=true. Elapsed: 4.010031804s
    Nov 12 12:48:21.089: INFO: Pod "test-rs-qlqw2" satisfied condition "running"
    STEP: Getting /status 11/12/22 12:48:21.089
    Nov 12 12:48:21.093: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 11/12/22 12:48:21.093
    Nov 12 12:48:21.106: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 11/12/22 12:48:21.106
    Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: ADDED
    Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 12 12:48:21.108: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 12 12:48:21.108: INFO: Found replicaset test-rs in namespace replicaset-1732 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 12 12:48:21.108: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 11/12/22 12:48:21.108
    Nov 12 12:48:21.109: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 12 12:48:21.115: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 11/12/22 12:48:21.116
    Nov 12 12:48:21.117: INFO: Observed &ReplicaSet event: ADDED
    Nov 12 12:48:21.117: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 12 12:48:21.118: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 12 12:48:21.121: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 12 12:48:21.121: INFO: Observed replicaset test-rs in namespace replicaset-1732 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 12:48:21.121: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 12 12:48:21.121: INFO: Found replicaset test-rs in namespace replicaset-1732 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Nov 12 12:48:21.121: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 12:48:21.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1732" for this suite. 11/12/22 12:48:21.126
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:21.142
Nov 12 12:48:21.142: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:48:21.143
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:21.16
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:21.168
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 11/12/22 12:48:21.179
Nov 12 12:48:21.190: INFO: Waiting up to 5m0s for pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592" in namespace "emptydir-6607" to be "Succeeded or Failed"
Nov 12 12:48:21.197: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592": Phase="Pending", Reason="", readiness=false. Elapsed: 6.954912ms
Nov 12 12:48:23.203: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013244777s
Nov 12 12:48:25.203: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012560241s
STEP: Saw pod success 11/12/22 12:48:25.203
Nov 12 12:48:25.203: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592" satisfied condition "Succeeded or Failed"
Nov 12 12:48:25.208: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-29c0d2a4-175e-44cc-92a5-e7539142d592 container test-container: <nil>
STEP: delete the pod 11/12/22 12:48:25.235
Nov 12 12:48:25.257: INFO: Waiting for pod pod-29c0d2a4-175e-44cc-92a5-e7539142d592 to disappear
Nov 12 12:48:25.263: INFO: Pod pod-29c0d2a4-175e-44cc-92a5-e7539142d592 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:48:25.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6607" for this suite. 11/12/22 12:48:25.268
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":214,"skipped":4051,"failed":0}
------------------------------
• [4.137 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:21.142
    Nov 12 12:48:21.142: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:48:21.143
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:21.16
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:21.168
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/12/22 12:48:21.179
    Nov 12 12:48:21.190: INFO: Waiting up to 5m0s for pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592" in namespace "emptydir-6607" to be "Succeeded or Failed"
    Nov 12 12:48:21.197: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592": Phase="Pending", Reason="", readiness=false. Elapsed: 6.954912ms
    Nov 12 12:48:23.203: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013244777s
    Nov 12 12:48:25.203: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012560241s
    STEP: Saw pod success 11/12/22 12:48:25.203
    Nov 12 12:48:25.203: INFO: Pod "pod-29c0d2a4-175e-44cc-92a5-e7539142d592" satisfied condition "Succeeded or Failed"
    Nov 12 12:48:25.208: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-29c0d2a4-175e-44cc-92a5-e7539142d592 container test-container: <nil>
    STEP: delete the pod 11/12/22 12:48:25.235
    Nov 12 12:48:25.257: INFO: Waiting for pod pod-29c0d2a4-175e-44cc-92a5-e7539142d592 to disappear
    Nov 12 12:48:25.263: INFO: Pod pod-29c0d2a4-175e-44cc-92a5-e7539142d592 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:48:25.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6607" for this suite. 11/12/22 12:48:25.268
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:25.279
Nov 12 12:48:25.279: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 12:48:25.28
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:25.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:25.307
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Nov 12 12:48:25.330: INFO: Waiting up to 5m0s for pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173" in namespace "pods-2691" to be "running and ready"
Nov 12 12:48:25.339: INFO: Pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173": Phase="Pending", Reason="", readiness=false. Elapsed: 7.933558ms
Nov 12 12:48:25.339: INFO: The phase of Pod server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:48:27.344: INFO: Pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173": Phase="Running", Reason="", readiness=true. Elapsed: 2.013775558s
Nov 12 12:48:27.344: INFO: The phase of Pod server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173 is Running (Ready = true)
Nov 12 12:48:27.344: INFO: Pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173" satisfied condition "running and ready"
Nov 12 12:48:27.370: INFO: Waiting up to 5m0s for pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e" in namespace "pods-2691" to be "Succeeded or Failed"
Nov 12 12:48:27.384: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.465253ms
Nov 12 12:48:29.392: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021211901s
Nov 12 12:48:31.390: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019720675s
STEP: Saw pod success 11/12/22 12:48:31.39
Nov 12 12:48:31.390: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e" satisfied condition "Succeeded or Failed"
Nov 12 12:48:31.394: INFO: Trying to get logs from node ip-172-31-89-190 pod client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e container env3cont: <nil>
STEP: delete the pod 11/12/22 12:48:31.412
Nov 12 12:48:31.428: INFO: Waiting for pod client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e to disappear
Nov 12 12:48:31.432: INFO: Pod client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 12:48:31.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2691" for this suite. 11/12/22 12:48:31.437
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":215,"skipped":4051,"failed":0}
------------------------------
• [SLOW TEST] [6.174 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:25.279
    Nov 12 12:48:25.279: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 12:48:25.28
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:25.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:25.307
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Nov 12 12:48:25.330: INFO: Waiting up to 5m0s for pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173" in namespace "pods-2691" to be "running and ready"
    Nov 12 12:48:25.339: INFO: Pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173": Phase="Pending", Reason="", readiness=false. Elapsed: 7.933558ms
    Nov 12 12:48:25.339: INFO: The phase of Pod server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:48:27.344: INFO: Pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173": Phase="Running", Reason="", readiness=true. Elapsed: 2.013775558s
    Nov 12 12:48:27.344: INFO: The phase of Pod server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173 is Running (Ready = true)
    Nov 12 12:48:27.344: INFO: Pod "server-envvars-23ffd511-9bfd-42de-88e6-ad0ebbd27173" satisfied condition "running and ready"
    Nov 12 12:48:27.370: INFO: Waiting up to 5m0s for pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e" in namespace "pods-2691" to be "Succeeded or Failed"
    Nov 12 12:48:27.384: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.465253ms
    Nov 12 12:48:29.392: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021211901s
    Nov 12 12:48:31.390: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019720675s
    STEP: Saw pod success 11/12/22 12:48:31.39
    Nov 12 12:48:31.390: INFO: Pod "client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e" satisfied condition "Succeeded or Failed"
    Nov 12 12:48:31.394: INFO: Trying to get logs from node ip-172-31-89-190 pod client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e container env3cont: <nil>
    STEP: delete the pod 11/12/22 12:48:31.412
    Nov 12 12:48:31.428: INFO: Waiting for pod client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e to disappear
    Nov 12 12:48:31.432: INFO: Pod client-envvars-9276f312-7bff-4268-a793-019bdeea2f5e no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 12:48:31.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2691" for this suite. 11/12/22 12:48:31.437
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:31.453
Nov 12 12:48:31.453: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename prestop 11/12/22 12:48:31.454
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:31.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:31.481
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-124 11/12/22 12:48:31.483
STEP: Waiting for pods to come up. 11/12/22 12:48:31.492
Nov 12 12:48:31.493: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-124" to be "running"
Nov 12 12:48:31.499: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 6.532222ms
Nov 12 12:48:33.509: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.015926773s
Nov 12 12:48:33.509: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-124 11/12/22 12:48:33.514
Nov 12 12:48:33.522: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-124" to be "running"
Nov 12 12:48:33.530: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 7.258989ms
Nov 12 12:48:35.536: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.01362002s
Nov 12 12:48:35.536: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 11/12/22 12:48:35.536
Nov 12 12:48:40.554: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 11/12/22 12:48:40.554
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Nov 12 12:48:40.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-124" for this suite. 11/12/22 12:48:40.577
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":216,"skipped":4051,"failed":0}
------------------------------
• [SLOW TEST] [9.132 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:31.453
    Nov 12 12:48:31.453: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename prestop 11/12/22 12:48:31.454
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:31.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:31.481
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-124 11/12/22 12:48:31.483
    STEP: Waiting for pods to come up. 11/12/22 12:48:31.492
    Nov 12 12:48:31.493: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-124" to be "running"
    Nov 12 12:48:31.499: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 6.532222ms
    Nov 12 12:48:33.509: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.015926773s
    Nov 12 12:48:33.509: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-124 11/12/22 12:48:33.514
    Nov 12 12:48:33.522: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-124" to be "running"
    Nov 12 12:48:33.530: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 7.258989ms
    Nov 12 12:48:35.536: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.01362002s
    Nov 12 12:48:35.536: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 11/12/22 12:48:35.536
    Nov 12 12:48:40.554: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 11/12/22 12:48:40.554
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Nov 12 12:48:40.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-124" for this suite. 11/12/22 12:48:40.577
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:40.587
Nov 12 12:48:40.587: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:48:40.587
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:40.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:40.613
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:48:40.622
Nov 12 12:48:40.633: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3729" to be "running and ready"
Nov 12 12:48:40.641: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.607129ms
Nov 12 12:48:40.641: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:48:42.646: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012855053s
Nov 12 12:48:42.646: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 12 12:48:42.646: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 11/12/22 12:48:42.651
Nov 12 12:48:42.656: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-3729" to be "running and ready"
Nov 12 12:48:42.663: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.413273ms
Nov 12 12:48:42.663: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:48:44.668: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011809202s
Nov 12 12:48:44.668: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Nov 12 12:48:44.668: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/12/22 12:48:44.672
STEP: delete the pod with lifecycle hook 11/12/22 12:48:44.698
Nov 12 12:48:44.709: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 12 12:48:44.714: INFO: Pod pod-with-poststart-http-hook still exists
Nov 12 12:48:46.715: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 12 12:48:46.721: INFO: Pod pod-with-poststart-http-hook still exists
Nov 12 12:48:48.715: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 12 12:48:48.721: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 12 12:48:48.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3729" for this suite. 11/12/22 12:48:48.727
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":217,"skipped":4055,"failed":0}
------------------------------
• [SLOW TEST] [8.153 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:40.587
    Nov 12 12:48:40.587: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/12/22 12:48:40.587
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:40.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:40.613
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/12/22 12:48:40.622
    Nov 12 12:48:40.633: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-3729" to be "running and ready"
    Nov 12 12:48:40.641: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.607129ms
    Nov 12 12:48:40.641: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:48:42.646: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012855053s
    Nov 12 12:48:42.646: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 12 12:48:42.646: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 11/12/22 12:48:42.651
    Nov 12 12:48:42.656: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-3729" to be "running and ready"
    Nov 12 12:48:42.663: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.413273ms
    Nov 12 12:48:42.663: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:48:44.668: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011809202s
    Nov 12 12:48:44.668: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Nov 12 12:48:44.668: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/12/22 12:48:44.672
    STEP: delete the pod with lifecycle hook 11/12/22 12:48:44.698
    Nov 12 12:48:44.709: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 12 12:48:44.714: INFO: Pod pod-with-poststart-http-hook still exists
    Nov 12 12:48:46.715: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 12 12:48:46.721: INFO: Pod pod-with-poststart-http-hook still exists
    Nov 12 12:48:48.715: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 12 12:48:48.721: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 12 12:48:48.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-3729" for this suite. 11/12/22 12:48:48.727
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:48.74
Nov 12 12:48:48.740: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 12:48:48.741
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:48.763
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:48.766
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Nov 12 12:48:48.769: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 12:48:51.062
Nov 12 12:48:51.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 create -f -'
Nov 12 12:48:52.053: INFO: stderr: ""
Nov 12 12:48:52.053: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 12 12:48:52.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 delete e2e-test-crd-publish-openapi-8483-crds test-cr'
Nov 12 12:48:52.129: INFO: stderr: ""
Nov 12 12:48:52.129: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov 12 12:48:52.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 apply -f -'
Nov 12 12:48:52.800: INFO: stderr: ""
Nov 12 12:48:52.800: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 12 12:48:52.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 delete e2e-test-crd-publish-openapi-8483-crds test-cr'
Nov 12 12:48:52.899: INFO: stderr: ""
Nov 12 12:48:52.899: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/12/22 12:48:52.899
Nov 12 12:48:52.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 explain e2e-test-crd-publish-openapi-8483-crds'
Nov 12 12:48:53.110: INFO: stderr: ""
Nov 12 12:48:53.110: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8483-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:48:55.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9788" for this suite. 11/12/22 12:48:55.534
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":218,"skipped":4078,"failed":0}
------------------------------
• [SLOW TEST] [6.811 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:48.74
    Nov 12 12:48:48.740: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 12:48:48.741
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:48.763
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:48.766
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Nov 12 12:48:48.769: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 12:48:51.062
    Nov 12 12:48:51.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 create -f -'
    Nov 12 12:48:52.053: INFO: stderr: ""
    Nov 12 12:48:52.053: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 12 12:48:52.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 delete e2e-test-crd-publish-openapi-8483-crds test-cr'
    Nov 12 12:48:52.129: INFO: stderr: ""
    Nov 12 12:48:52.129: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Nov 12 12:48:52.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 apply -f -'
    Nov 12 12:48:52.800: INFO: stderr: ""
    Nov 12 12:48:52.800: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 12 12:48:52.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 --namespace=crd-publish-openapi-9788 delete e2e-test-crd-publish-openapi-8483-crds test-cr'
    Nov 12 12:48:52.899: INFO: stderr: ""
    Nov 12 12:48:52.899: INFO: stdout: "e2e-test-crd-publish-openapi-8483-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/12/22 12:48:52.899
    Nov 12 12:48:52.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-9788 explain e2e-test-crd-publish-openapi-8483-crds'
    Nov 12 12:48:53.110: INFO: stderr: ""
    Nov 12 12:48:53.110: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8483-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:48:55.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9788" for this suite. 11/12/22 12:48:55.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:55.553
Nov 12 12:48:55.553: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:48:55.554
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:55.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:55.583
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:48:55.611
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:48:56.311
STEP: Deploying the webhook pod 11/12/22 12:48:56.323
STEP: Wait for the deployment to be ready 11/12/22 12:48:56.337
Nov 12 12:48:56.352: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:48:58.379
STEP: Verifying the service has paired with the endpoint 11/12/22 12:48:58.398
Nov 12 12:48:59.398: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 11/12/22 12:48:59.404
STEP: Creating a custom resource definition that should be denied by the webhook 11/12/22 12:48:59.423
Nov 12 12:48:59.423: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:48:59.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4154" for this suite. 11/12/22 12:48:59.448
STEP: Destroying namespace "webhook-4154-markers" for this suite. 11/12/22 12:48:59.456
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":219,"skipped":4087,"failed":0}
------------------------------
• [3.989 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:55.553
    Nov 12 12:48:55.553: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:48:55.554
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:55.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:55.583
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:48:55.611
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:48:56.311
    STEP: Deploying the webhook pod 11/12/22 12:48:56.323
    STEP: Wait for the deployment to be ready 11/12/22 12:48:56.337
    Nov 12 12:48:56.352: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:48:58.379
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:48:58.398
    Nov 12 12:48:59.398: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 11/12/22 12:48:59.404
    STEP: Creating a custom resource definition that should be denied by the webhook 11/12/22 12:48:59.423
    Nov 12 12:48:59.423: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:48:59.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4154" for this suite. 11/12/22 12:48:59.448
    STEP: Destroying namespace "webhook-4154-markers" for this suite. 11/12/22 12:48:59.456
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:48:59.547
Nov 12 12:48:59.548: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:48:59.548
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:59.571
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:59.574
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-2174 11/12/22 12:48:59.576
Nov 12 12:48:59.585: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2174" to be "running and ready"
Nov 12 12:48:59.592: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.570309ms
Nov 12 12:48:59.592: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 12 12:49:01.597: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.011573433s
Nov 12 12:49:01.597: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 12 12:49:01.597: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 12 12:49:01.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 12 12:49:01.825: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 12 12:49:01.825: INFO: stdout: "iptables"
Nov 12 12:49:01.825: INFO: proxyMode: iptables
Nov 12 12:49:01.840: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 12 12:49:01.851: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-2174 11/12/22 12:49:01.851
STEP: creating replication controller affinity-nodeport-timeout in namespace services-2174 11/12/22 12:49:01.874
I1112 12:49:01.886812      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-2174, replica count: 3
I1112 12:49:04.937665      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1112 12:49:07.939653      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 12:49:07.958: INFO: Creating new exec pod
Nov 12 12:49:07.965: INFO: Waiting up to 5m0s for pod "execpod-affinity252h6" in namespace "services-2174" to be "running"
Nov 12 12:49:07.973: INFO: Pod "execpod-affinity252h6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.265244ms
Nov 12 12:49:09.980: INFO: Pod "execpod-affinity252h6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014428171s
Nov 12 12:49:09.980: INFO: Pod "execpod-affinity252h6" satisfied condition "running"
Nov 12 12:49:10.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 12 12:49:11.174: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Nov 12 12:49:11.174: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:49:11.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
Nov 12 12:49:11.348: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.135 80\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n"
Nov 12 12:49:11.348: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:49:11.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 30285'
Nov 12 12:49:11.566: INFO: stderr: "+ nc -v -t -w 2 172.31.89.190 30285\n+ echo hostName\nConnection to 172.31.89.190 30285 port [tcp/*] succeeded!\n"
Nov 12 12:49:11.566: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:49:11.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.47.219 30285'
Nov 12 12:49:11.733: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.47.219 30285\nConnection to 172.31.47.219 30285 port [tcp/*] succeeded!\n"
Nov 12 12:49:11.733: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 12:49:11.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:30285/ ; done'
Nov 12 12:49:12.034: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n"
Nov 12 12:49:12.034: INFO: stdout: "\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv"
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
Nov 12 12:49:12.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.14.110:30285/'
Nov 12 12:49:12.182: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n"
Nov 12 12:49:12.182: INFO: stdout: "affinity-nodeport-timeout-jttrv"
Nov 12 12:49:32.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.14.110:30285/'
Nov 12 12:49:32.379: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n"
Nov 12 12:49:32.379: INFO: stdout: "affinity-nodeport-timeout-vdq5d"
Nov 12 12:49:32.379: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-2174, will wait for the garbage collector to delete the pods 11/12/22 12:49:32.394
Nov 12 12:49:32.467: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 14.72209ms
Nov 12 12:49:32.567: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.310036ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:49:34.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2174" for this suite. 11/12/22 12:49:34.407
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":220,"skipped":4102,"failed":0}
------------------------------
• [SLOW TEST] [34.870 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:48:59.547
    Nov 12 12:48:59.548: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:48:59.548
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:48:59.571
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:48:59.574
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-2174 11/12/22 12:48:59.576
    Nov 12 12:48:59.585: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2174" to be "running and ready"
    Nov 12 12:48:59.592: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.570309ms
    Nov 12 12:48:59.592: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 12:49:01.597: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.011573433s
    Nov 12 12:49:01.597: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 12 12:49:01.597: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 12 12:49:01.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 12 12:49:01.825: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 12 12:49:01.825: INFO: stdout: "iptables"
    Nov 12 12:49:01.825: INFO: proxyMode: iptables
    Nov 12 12:49:01.840: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 12 12:49:01.851: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-2174 11/12/22 12:49:01.851
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-2174 11/12/22 12:49:01.874
    I1112 12:49:01.886812      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-2174, replica count: 3
    I1112 12:49:04.937665      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1112 12:49:07.939653      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 12:49:07.958: INFO: Creating new exec pod
    Nov 12 12:49:07.965: INFO: Waiting up to 5m0s for pod "execpod-affinity252h6" in namespace "services-2174" to be "running"
    Nov 12 12:49:07.973: INFO: Pod "execpod-affinity252h6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.265244ms
    Nov 12 12:49:09.980: INFO: Pod "execpod-affinity252h6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014428171s
    Nov 12 12:49:09.980: INFO: Pod "execpod-affinity252h6" satisfied condition "running"
    Nov 12 12:49:10.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 12 12:49:11.174: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Nov 12 12:49:11.174: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:49:11.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
    Nov 12 12:49:11.348: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.135 80\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n"
    Nov 12 12:49:11.348: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:49:11.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 30285'
    Nov 12 12:49:11.566: INFO: stderr: "+ nc -v -t -w 2 172.31.89.190 30285\n+ echo hostName\nConnection to 172.31.89.190 30285 port [tcp/*] succeeded!\n"
    Nov 12 12:49:11.566: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:49:11.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.47.219 30285'
    Nov 12 12:49:11.733: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.47.219 30285\nConnection to 172.31.47.219 30285 port [tcp/*] succeeded!\n"
    Nov 12 12:49:11.733: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 12:49:11.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.14.110:30285/ ; done'
    Nov 12 12:49:12.034: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n"
    Nov 12 12:49:12.034: INFO: stdout: "\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv\naffinity-nodeport-timeout-jttrv"
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Received response from host: affinity-nodeport-timeout-jttrv
    Nov 12 12:49:12.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.14.110:30285/'
    Nov 12 12:49:12.182: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n"
    Nov 12 12:49:12.182: INFO: stdout: "affinity-nodeport-timeout-jttrv"
    Nov 12 12:49:32.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-2174 exec execpod-affinity252h6 -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.14.110:30285/'
    Nov 12 12:49:32.379: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.14.110:30285/\n"
    Nov 12 12:49:32.379: INFO: stdout: "affinity-nodeport-timeout-vdq5d"
    Nov 12 12:49:32.379: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-2174, will wait for the garbage collector to delete the pods 11/12/22 12:49:32.394
    Nov 12 12:49:32.467: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 14.72209ms
    Nov 12 12:49:32.567: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.310036ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:49:34.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2174" for this suite. 11/12/22 12:49:34.407
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:49:34.421
Nov 12 12:49:34.421: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 12:49:34.422
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:34.445
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:34.449
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 11/12/22 12:49:34.46
STEP: watching for the Service to be added 11/12/22 12:49:34.478
Nov 12 12:49:34.480: INFO: Found Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Nov 12 12:49:34.480: INFO: Service test-service-km2t7 created
STEP: Getting /status 11/12/22 12:49:34.48
Nov 12 12:49:34.489: INFO: Service test-service-km2t7 has LoadBalancer: {[]}
STEP: patching the ServiceStatus 11/12/22 12:49:34.489
STEP: watching for the Service to be patched 11/12/22 12:49:34.497
Nov 12 12:49:34.499: INFO: observed Service test-service-km2t7 in namespace services-6757 with annotations: map[] & LoadBalancer: {[]}
Nov 12 12:49:34.499: INFO: Found Service test-service-km2t7 in namespace services-6757 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Nov 12 12:49:34.499: INFO: Service test-service-km2t7 has service status patched
STEP: updating the ServiceStatus 11/12/22 12:49:34.499
Nov 12 12:49:34.521: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 11/12/22 12:49:34.521
Nov 12 12:49:34.523: INFO: Observed Service test-service-km2t7 in namespace services-6757 with annotations: map[] & Conditions: {[]}
Nov 12 12:49:34.523: INFO: Observed event: &Service{ObjectMeta:{test-service-km2t7  services-6757  975e3a67-9192-48ce-8c25-1453b294d02d 29058 0 2022-11-12 12:49:34 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-12 12:49:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-12 12:49:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.248,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.248],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Nov 12 12:49:34.524: INFO: Found Service test-service-km2t7 in namespace services-6757 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 12 12:49:34.524: INFO: Service test-service-km2t7 has service status updated
STEP: patching the service 11/12/22 12:49:34.524
STEP: watching for the Service to be patched 11/12/22 12:49:34.544
Nov 12 12:49:34.546: INFO: observed Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true]
Nov 12 12:49:34.546: INFO: observed Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true]
Nov 12 12:49:34.546: INFO: observed Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true]
Nov 12 12:49:34.546: INFO: Found Service test-service-km2t7 in namespace services-6757 with labels: map[test-service:patched test-service-static:true]
Nov 12 12:49:34.546: INFO: Service test-service-km2t7 patched
STEP: deleting the service 11/12/22 12:49:34.546
STEP: watching for the Service to be deleted 11/12/22 12:49:34.574
Nov 12 12:49:34.576: INFO: Observed event: ADDED
Nov 12 12:49:34.576: INFO: Observed event: MODIFIED
Nov 12 12:49:34.576: INFO: Observed event: MODIFIED
Nov 12 12:49:34.576: INFO: Observed event: MODIFIED
Nov 12 12:49:34.576: INFO: Found Service test-service-km2t7 in namespace services-6757 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Nov 12 12:49:34.576: INFO: Service test-service-km2t7 deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 12:49:34.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6757" for this suite. 11/12/22 12:49:34.583
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":221,"skipped":4134,"failed":0}
------------------------------
• [0.173 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:49:34.421
    Nov 12 12:49:34.421: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 12:49:34.422
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:34.445
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:34.449
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 11/12/22 12:49:34.46
    STEP: watching for the Service to be added 11/12/22 12:49:34.478
    Nov 12 12:49:34.480: INFO: Found Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Nov 12 12:49:34.480: INFO: Service test-service-km2t7 created
    STEP: Getting /status 11/12/22 12:49:34.48
    Nov 12 12:49:34.489: INFO: Service test-service-km2t7 has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 11/12/22 12:49:34.489
    STEP: watching for the Service to be patched 11/12/22 12:49:34.497
    Nov 12 12:49:34.499: INFO: observed Service test-service-km2t7 in namespace services-6757 with annotations: map[] & LoadBalancer: {[]}
    Nov 12 12:49:34.499: INFO: Found Service test-service-km2t7 in namespace services-6757 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Nov 12 12:49:34.499: INFO: Service test-service-km2t7 has service status patched
    STEP: updating the ServiceStatus 11/12/22 12:49:34.499
    Nov 12 12:49:34.521: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 11/12/22 12:49:34.521
    Nov 12 12:49:34.523: INFO: Observed Service test-service-km2t7 in namespace services-6757 with annotations: map[] & Conditions: {[]}
    Nov 12 12:49:34.523: INFO: Observed event: &Service{ObjectMeta:{test-service-km2t7  services-6757  975e3a67-9192-48ce-8c25-1453b294d02d 29058 0 2022-11-12 12:49:34 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-12 12:49:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-12 12:49:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.248,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.248],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Nov 12 12:49:34.524: INFO: Found Service test-service-km2t7 in namespace services-6757 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 12 12:49:34.524: INFO: Service test-service-km2t7 has service status updated
    STEP: patching the service 11/12/22 12:49:34.524
    STEP: watching for the Service to be patched 11/12/22 12:49:34.544
    Nov 12 12:49:34.546: INFO: observed Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true]
    Nov 12 12:49:34.546: INFO: observed Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true]
    Nov 12 12:49:34.546: INFO: observed Service test-service-km2t7 in namespace services-6757 with labels: map[test-service-static:true]
    Nov 12 12:49:34.546: INFO: Found Service test-service-km2t7 in namespace services-6757 with labels: map[test-service:patched test-service-static:true]
    Nov 12 12:49:34.546: INFO: Service test-service-km2t7 patched
    STEP: deleting the service 11/12/22 12:49:34.546
    STEP: watching for the Service to be deleted 11/12/22 12:49:34.574
    Nov 12 12:49:34.576: INFO: Observed event: ADDED
    Nov 12 12:49:34.576: INFO: Observed event: MODIFIED
    Nov 12 12:49:34.576: INFO: Observed event: MODIFIED
    Nov 12 12:49:34.576: INFO: Observed event: MODIFIED
    Nov 12 12:49:34.576: INFO: Found Service test-service-km2t7 in namespace services-6757 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Nov 12 12:49:34.576: INFO: Service test-service-km2t7 deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 12:49:34.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6757" for this suite. 11/12/22 12:49:34.583
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:49:34.596
Nov 12 12:49:34.596: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:49:34.597
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:34.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:34.627
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:49:34.653
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:49:34.891
STEP: Deploying the webhook pod 11/12/22 12:49:34.905
STEP: Wait for the deployment to be ready 11/12/22 12:49:34.924
Nov 12 12:49:34.934: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 12:49:36.95
STEP: Verifying the service has paired with the endpoint 11/12/22 12:49:36.966
Nov 12 12:49:37.966: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Nov 12 12:49:37.973: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4684-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 12:49:38.492
STEP: Creating a custom resource that should be mutated by the webhook 11/12/22 12:49:38.519
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:49:41.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7975" for this suite. 11/12/22 12:49:41.13
STEP: Destroying namespace "webhook-7975-markers" for this suite. 11/12/22 12:49:41.141
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":222,"skipped":4164,"failed":0}
------------------------------
• [SLOW TEST] [6.636 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:49:34.596
    Nov 12 12:49:34.596: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:49:34.597
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:34.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:34.627
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:49:34.653
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:49:34.891
    STEP: Deploying the webhook pod 11/12/22 12:49:34.905
    STEP: Wait for the deployment to be ready 11/12/22 12:49:34.924
    Nov 12 12:49:34.934: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 12:49:36.95
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:49:36.966
    Nov 12 12:49:37.966: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Nov 12 12:49:37.973: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4684-crds.webhook.example.com via the AdmissionRegistration API 11/12/22 12:49:38.492
    STEP: Creating a custom resource that should be mutated by the webhook 11/12/22 12:49:38.519
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:49:41.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7975" for this suite. 11/12/22 12:49:41.13
    STEP: Destroying namespace "webhook-7975-markers" for this suite. 11/12/22 12:49:41.141
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:49:41.236
Nov 12 12:49:41.236: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 12:49:41.238
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:41.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:41.288
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 12:49:41.327
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:49:41.584
STEP: Deploying the webhook pod 11/12/22 12:49:41.592
STEP: Wait for the deployment to be ready 11/12/22 12:49:41.607
Nov 12 12:49:41.615: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/12/22 12:49:43.631
STEP: Verifying the service has paired with the endpoint 11/12/22 12:49:43.646
Nov 12 12:49:44.646: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 11/12/22 12:49:44.742
STEP: Creating a configMap that should be mutated 11/12/22 12:49:44.757
STEP: Deleting the collection of validation webhooks 11/12/22 12:49:44.793
STEP: Creating a configMap that should not be mutated 11/12/22 12:49:44.887
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 12:49:44.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7906" for this suite. 11/12/22 12:49:44.926
STEP: Destroying namespace "webhook-7906-markers" for this suite. 11/12/22 12:49:44.938
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":223,"skipped":4178,"failed":0}
------------------------------
• [3.785 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:49:41.236
    Nov 12 12:49:41.236: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 12:49:41.238
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:41.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:41.288
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 12:49:41.327
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 12:49:41.584
    STEP: Deploying the webhook pod 11/12/22 12:49:41.592
    STEP: Wait for the deployment to be ready 11/12/22 12:49:41.607
    Nov 12 12:49:41.615: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/12/22 12:49:43.631
    STEP: Verifying the service has paired with the endpoint 11/12/22 12:49:43.646
    Nov 12 12:49:44.646: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 11/12/22 12:49:44.742
    STEP: Creating a configMap that should be mutated 11/12/22 12:49:44.757
    STEP: Deleting the collection of validation webhooks 11/12/22 12:49:44.793
    STEP: Creating a configMap that should not be mutated 11/12/22 12:49:44.887
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 12:49:44.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7906" for this suite. 11/12/22 12:49:44.926
    STEP: Destroying namespace "webhook-7906-markers" for this suite. 11/12/22 12:49:44.938
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:49:45.022
Nov 12 12:49:45.022: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 12:49:45.023
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:45.052
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:45.059
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-119/secret-test-f01a194b-3512-4c12-ae92-c438f52613ed 11/12/22 12:49:45.065
STEP: Creating a pod to test consume secrets 11/12/22 12:49:45.072
Nov 12 12:49:45.086: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5" in namespace "secrets-119" to be "Succeeded or Failed"
Nov 12 12:49:45.093: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.715045ms
Nov 12 12:49:47.099: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013454519s
Nov 12 12:49:49.098: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011996664s
Nov 12 12:49:51.098: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012378027s
STEP: Saw pod success 11/12/22 12:49:51.098
Nov 12 12:49:51.099: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5" satisfied condition "Succeeded or Failed"
Nov 12 12:49:51.105: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5 container env-test: <nil>
STEP: delete the pod 11/12/22 12:49:51.124
Nov 12 12:49:51.145: INFO: Waiting for pod pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5 to disappear
Nov 12 12:49:51.151: INFO: Pod pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 12 12:49:51.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-119" for this suite. 11/12/22 12:49:51.157
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":224,"skipped":4181,"failed":0}
------------------------------
• [SLOW TEST] [6.161 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:49:45.022
    Nov 12 12:49:45.022: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 12:49:45.023
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:45.052
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:45.059
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-119/secret-test-f01a194b-3512-4c12-ae92-c438f52613ed 11/12/22 12:49:45.065
    STEP: Creating a pod to test consume secrets 11/12/22 12:49:45.072
    Nov 12 12:49:45.086: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5" in namespace "secrets-119" to be "Succeeded or Failed"
    Nov 12 12:49:45.093: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.715045ms
    Nov 12 12:49:47.099: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013454519s
    Nov 12 12:49:49.098: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011996664s
    Nov 12 12:49:51.098: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012378027s
    STEP: Saw pod success 11/12/22 12:49:51.098
    Nov 12 12:49:51.099: INFO: Pod "pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5" satisfied condition "Succeeded or Failed"
    Nov 12 12:49:51.105: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5 container env-test: <nil>
    STEP: delete the pod 11/12/22 12:49:51.124
    Nov 12 12:49:51.145: INFO: Waiting for pod pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5 to disappear
    Nov 12 12:49:51.151: INFO: Pod pod-configmaps-2ee00470-38e4-4e51-b319-d0a91aefd0d5 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 12:49:51.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-119" for this suite. 11/12/22 12:49:51.157
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:49:51.184
Nov 12 12:49:51.184: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename disruption 11/12/22 12:49:51.185
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:51.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:51.215
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:49:51.218
Nov 12 12:49:51.218: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename disruption-2 11/12/22 12:49:51.219
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:51.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:51.255
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 11/12/22 12:49:51.272
STEP: Waiting for the pdb to be processed 11/12/22 12:49:53.299
STEP: Waiting for the pdb to be processed 11/12/22 12:49:53.321
STEP: listing a collection of PDBs across all namespaces 11/12/22 12:49:55.336
STEP: listing a collection of PDBs in namespace disruption-7036 11/12/22 12:49:55.341
STEP: deleting a collection of PDBs 11/12/22 12:49:55.345
STEP: Waiting for the PDB collection to be deleted 11/12/22 12:49:55.373
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Nov 12 12:49:55.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-6405" for this suite. 11/12/22 12:49:55.391
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 12:49:55.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7036" for this suite. 11/12/22 12:49:55.414
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":225,"skipped":4205,"failed":0}
------------------------------
• [4.239 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:49:51.184
    Nov 12 12:49:51.184: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename disruption 11/12/22 12:49:51.185
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:51.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:51.215
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:49:51.218
    Nov 12 12:49:51.218: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename disruption-2 11/12/22 12:49:51.219
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:51.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:51.255
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 11/12/22 12:49:51.272
    STEP: Waiting for the pdb to be processed 11/12/22 12:49:53.299
    STEP: Waiting for the pdb to be processed 11/12/22 12:49:53.321
    STEP: listing a collection of PDBs across all namespaces 11/12/22 12:49:55.336
    STEP: listing a collection of PDBs in namespace disruption-7036 11/12/22 12:49:55.341
    STEP: deleting a collection of PDBs 11/12/22 12:49:55.345
    STEP: Waiting for the PDB collection to be deleted 11/12/22 12:49:55.373
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Nov 12 12:49:55.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-6405" for this suite. 11/12/22 12:49:55.391
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 12:49:55.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-7036" for this suite. 11/12/22 12:49:55.414
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:49:55.424
Nov 12 12:49:55.424: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename cronjob 11/12/22 12:49:55.425
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:55.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:55.454
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 11/12/22 12:49:55.459
STEP: Ensuring a job is scheduled 11/12/22 12:49:55.471
STEP: Ensuring exactly one is scheduled 11/12/22 12:50:01.477
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/12/22 12:50:01.483
STEP: Ensuring no more jobs are scheduled 11/12/22 12:50:01.491
STEP: Removing cronjob 11/12/22 12:55:01.511
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 12 12:55:01.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6400" for this suite. 11/12/22 12:55:01.529
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":226,"skipped":4209,"failed":0}
------------------------------
• [SLOW TEST] [306.119 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:49:55.424
    Nov 12 12:49:55.424: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename cronjob 11/12/22 12:49:55.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:49:55.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:49:55.454
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 11/12/22 12:49:55.459
    STEP: Ensuring a job is scheduled 11/12/22 12:49:55.471
    STEP: Ensuring exactly one is scheduled 11/12/22 12:50:01.477
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/12/22 12:50:01.483
    STEP: Ensuring no more jobs are scheduled 11/12/22 12:50:01.491
    STEP: Removing cronjob 11/12/22 12:55:01.511
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 12 12:55:01.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6400" for this suite. 11/12/22 12:55:01.529
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:55:01.544
Nov 12 12:55:01.544: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 12:55:01.545
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:01.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:01.585
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-27cc82ee-c73b-4323-977e-18b3ef92d411 11/12/22 12:55:01.592
STEP: Creating a pod to test consume secrets 11/12/22 12:55:01.6
Nov 12 12:55:01.622: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96" in namespace "projected-1894" to be "Succeeded or Failed"
Nov 12 12:55:01.631: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96": Phase="Pending", Reason="", readiness=false. Elapsed: 8.928504ms
Nov 12 12:55:03.638: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015252119s
Nov 12 12:55:05.637: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014755151s
STEP: Saw pod success 11/12/22 12:55:05.637
Nov 12 12:55:05.637: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96" satisfied condition "Succeeded or Failed"
Nov 12 12:55:05.642: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/12/22 12:55:05.662
Nov 12 12:55:05.681: INFO: Waiting for pod pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96 to disappear
Nov 12 12:55:05.685: INFO: Pod pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 12:55:05.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1894" for this suite. 11/12/22 12:55:05.69
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":227,"skipped":4224,"failed":0}
------------------------------
• [4.156 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:55:01.544
    Nov 12 12:55:01.544: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 12:55:01.545
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:01.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:01.585
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-27cc82ee-c73b-4323-977e-18b3ef92d411 11/12/22 12:55:01.592
    STEP: Creating a pod to test consume secrets 11/12/22 12:55:01.6
    Nov 12 12:55:01.622: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96" in namespace "projected-1894" to be "Succeeded or Failed"
    Nov 12 12:55:01.631: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96": Phase="Pending", Reason="", readiness=false. Elapsed: 8.928504ms
    Nov 12 12:55:03.638: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015252119s
    Nov 12 12:55:05.637: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014755151s
    STEP: Saw pod success 11/12/22 12:55:05.637
    Nov 12 12:55:05.637: INFO: Pod "pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96" satisfied condition "Succeeded or Failed"
    Nov 12 12:55:05.642: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 12:55:05.662
    Nov 12 12:55:05.681: INFO: Waiting for pod pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96 to disappear
    Nov 12 12:55:05.685: INFO: Pod pod-projected-secrets-856b977f-aef5-4e38-bb20-67fbb8002d96 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 12:55:05.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1894" for this suite. 11/12/22 12:55:05.69
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:55:05.701
Nov 12 12:55:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 12:55:05.702
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:05.779
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:05.782
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/12/22 12:55:05.785
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/12/22 12:55:05.785
STEP: creating a pod to probe DNS 11/12/22 12:55:05.785
STEP: submitting the pod to kubernetes 11/12/22 12:55:05.785
Nov 12 12:55:05.797: INFO: Waiting up to 15m0s for pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073" in namespace "dns-401" to be "running"
Nov 12 12:55:05.807: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073": Phase="Pending", Reason="", readiness=false. Elapsed: 10.141023ms
Nov 12 12:55:07.815: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018270655s
Nov 12 12:55:09.813: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073": Phase="Running", Reason="", readiness=true. Elapsed: 4.015993418s
Nov 12 12:55:09.813: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073" satisfied condition "running"
STEP: retrieving the pod 11/12/22 12:55:09.813
STEP: looking for the results for each expected name from probers 11/12/22 12:55:09.822
Nov 12 12:55:09.848: INFO: DNS probes using dns-401/dns-test-914a512d-05ef-4906-932a-8ce5c58c0073 succeeded

STEP: deleting the pod 11/12/22 12:55:09.848
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 12:55:09.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-401" for this suite. 11/12/22 12:55:09.879
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":228,"skipped":4225,"failed":0}
------------------------------
• [4.187 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:55:05.701
    Nov 12 12:55:05.702: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 12:55:05.702
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:05.779
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:05.782
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/12/22 12:55:05.785
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/12/22 12:55:05.785
    STEP: creating a pod to probe DNS 11/12/22 12:55:05.785
    STEP: submitting the pod to kubernetes 11/12/22 12:55:05.785
    Nov 12 12:55:05.797: INFO: Waiting up to 15m0s for pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073" in namespace "dns-401" to be "running"
    Nov 12 12:55:05.807: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073": Phase="Pending", Reason="", readiness=false. Elapsed: 10.141023ms
    Nov 12 12:55:07.815: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018270655s
    Nov 12 12:55:09.813: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073": Phase="Running", Reason="", readiness=true. Elapsed: 4.015993418s
    Nov 12 12:55:09.813: INFO: Pod "dns-test-914a512d-05ef-4906-932a-8ce5c58c0073" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 12:55:09.813
    STEP: looking for the results for each expected name from probers 11/12/22 12:55:09.822
    Nov 12 12:55:09.848: INFO: DNS probes using dns-401/dns-test-914a512d-05ef-4906-932a-8ce5c58c0073 succeeded

    STEP: deleting the pod 11/12/22 12:55:09.848
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 12:55:09.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-401" for this suite. 11/12/22 12:55:09.879
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:55:09.889
Nov 12 12:55:09.889: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 12:55:09.89
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:09.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:09.939
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 11/12/22 12:55:09.95
Nov 12 12:55:09.950: INFO: Creating simple deployment test-deployment-s2nwm
Nov 12 12:55:09.965: INFO: new replicaset for deployment "test-deployment-s2nwm" is yet to be created
STEP: Getting /status 11/12/22 12:55:11.987
Nov 12 12:55:11.993: INFO: Deployment test-deployment-s2nwm has Conditions: [{Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 11/12/22 12:55:11.993
Nov 12 12:55:12.005: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 55, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 55, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 55, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 55, 9, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-s2nwm-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 11/12/22 12:55:12.005
Nov 12 12:55:12.008: INFO: Observed &Deployment event: ADDED
Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
Nov 12 12:55:12.008: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 12:55:12.008: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-s2nwm-777898ffcc" is progressing.}
Nov 12 12:55:12.009: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
Nov 12 12:55:12.009: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
Nov 12 12:55:12.009: INFO: Found Deployment test-deployment-s2nwm in namespace deployment-1583 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 12:55:12.009: INFO: Deployment test-deployment-s2nwm has an updated status
STEP: patching the Statefulset Status 11/12/22 12:55:12.009
Nov 12 12:55:12.009: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 12 12:55:12.020: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 11/12/22 12:55:12.02
Nov 12 12:55:12.023: INFO: Observed &Deployment event: ADDED
Nov 12 12:55:12.023: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-s2nwm-777898ffcc" is progressing.}
Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 12:55:12.025: INFO: Observed &Deployment event: MODIFIED
Nov 12 12:55:12.025: INFO: Found deployment test-deployment-s2nwm in namespace deployment-1583 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Nov 12 12:55:12.025: INFO: Deployment test-deployment-s2nwm has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 12:55:12.033: INFO: Deployment "test-deployment-s2nwm":
&Deployment{ObjectMeta:{test-deployment-s2nwm  deployment-1583  ef07ed25-3e2a-42fb-9a3c-2bdab7bfe99d 30163 1 2022-11-12 12:55:09 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-12 12:55:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-12 12:55:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-12 12:55:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001c0ae58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-s2nwm-777898ffcc",LastUpdateTime:2022-11-12 12:55:11 +0000 UTC,LastTransitionTime:2022-11-12 12:55:11 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 12:55:12.039: INFO: New ReplicaSet "test-deployment-s2nwm-777898ffcc" of Deployment "test-deployment-s2nwm":
&ReplicaSet{ObjectMeta:{test-deployment-s2nwm-777898ffcc  deployment-1583  f103eba5-6050-4acb-8042-5570434f3eb3 30150 1 2022-11-12 12:55:09 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-s2nwm ef07ed25-3e2a-42fb-9a3c-2bdab7bfe99d 0xc000b50fe0 0xc000b50fe1}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:55:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ef07ed25-3e2a-42fb-9a3c-2bdab7bfe99d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:55:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000b51088 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 12:55:12.044: INFO: Pod "test-deployment-s2nwm-777898ffcc-prpsn" is available:
&Pod{ObjectMeta:{test-deployment-s2nwm-777898ffcc-prpsn test-deployment-s2nwm-777898ffcc- deployment-1583  00eddf21-4418-46f9-9ff2-7c50fcf1e1d5 30149 0 2022-11-12 12:55:09 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-s2nwm-777898ffcc f103eba5-6050-4acb-8042-5570434f3eb3 0xc000b514e0 0xc000b514e1}] [] [{kube-controller-manager Update v1 2022-11-12 12:55:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f103eba5-6050-4acb-8042-5570434f3eb3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:55:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.47\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gmcvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gmcvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.47,StartTime:2022-11-12 12:55:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:55:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://87c7c352fe050297bf28d115e5e353d9caa5f643c6725160af7bf930a68d6cfc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 12:55:12.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1583" for this suite. 11/12/22 12:55:12.05
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":229,"skipped":4226,"failed":0}
------------------------------
• [2.172 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:55:09.889
    Nov 12 12:55:09.889: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 12:55:09.89
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:09.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:09.939
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 11/12/22 12:55:09.95
    Nov 12 12:55:09.950: INFO: Creating simple deployment test-deployment-s2nwm
    Nov 12 12:55:09.965: INFO: new replicaset for deployment "test-deployment-s2nwm" is yet to be created
    STEP: Getting /status 11/12/22 12:55:11.987
    Nov 12 12:55:11.993: INFO: Deployment test-deployment-s2nwm has Conditions: [{Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 11/12/22 12:55:11.993
    Nov 12 12:55:12.005: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 55, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 55, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 12, 55, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 12, 55, 9, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-s2nwm-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 11/12/22 12:55:12.005
    Nov 12 12:55:12.008: INFO: Observed &Deployment event: ADDED
    Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
    Nov 12 12:55:12.008: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
    Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 12:55:12.008: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.008: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-s2nwm-777898ffcc" is progressing.}
    Nov 12 12:55:12.009: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
    Nov 12 12:55:12.009: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 12:55:12.009: INFO: Observed Deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
    Nov 12 12:55:12.009: INFO: Found Deployment test-deployment-s2nwm in namespace deployment-1583 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 12:55:12.009: INFO: Deployment test-deployment-s2nwm has an updated status
    STEP: patching the Statefulset Status 11/12/22 12:55:12.009
    Nov 12 12:55:12.009: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 12 12:55:12.020: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 11/12/22 12:55:12.02
    Nov 12 12:55:12.023: INFO: Observed &Deployment event: ADDED
    Nov 12 12:55:12.023: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
    Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-s2nwm-777898ffcc"}
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-12 12:55:09 +0000 UTC 2022-11-12 12:55:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-s2nwm-777898ffcc" is progressing.}
    Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
    Nov 12 12:55:12.024: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:10 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-12 12:55:10 +0000 UTC 2022-11-12 12:55:09 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-s2nwm-777898ffcc" has successfully progressed.}
    Nov 12 12:55:12.024: INFO: Observed deployment test-deployment-s2nwm in namespace deployment-1583 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 12:55:12.025: INFO: Observed &Deployment event: MODIFIED
    Nov 12 12:55:12.025: INFO: Found deployment test-deployment-s2nwm in namespace deployment-1583 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Nov 12 12:55:12.025: INFO: Deployment test-deployment-s2nwm has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 12:55:12.033: INFO: Deployment "test-deployment-s2nwm":
    &Deployment{ObjectMeta:{test-deployment-s2nwm  deployment-1583  ef07ed25-3e2a-42fb-9a3c-2bdab7bfe99d 30163 1 2022-11-12 12:55:09 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-12 12:55:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-12 12:55:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-12 12:55:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001c0ae58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-s2nwm-777898ffcc",LastUpdateTime:2022-11-12 12:55:11 +0000 UTC,LastTransitionTime:2022-11-12 12:55:11 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 12:55:12.039: INFO: New ReplicaSet "test-deployment-s2nwm-777898ffcc" of Deployment "test-deployment-s2nwm":
    &ReplicaSet{ObjectMeta:{test-deployment-s2nwm-777898ffcc  deployment-1583  f103eba5-6050-4acb-8042-5570434f3eb3 30150 1 2022-11-12 12:55:09 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-s2nwm ef07ed25-3e2a-42fb-9a3c-2bdab7bfe99d 0xc000b50fe0 0xc000b50fe1}] [] [{kube-controller-manager Update apps/v1 2022-11-12 12:55:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ef07ed25-3e2a-42fb-9a3c-2bdab7bfe99d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 12:55:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000b51088 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 12:55:12.044: INFO: Pod "test-deployment-s2nwm-777898ffcc-prpsn" is available:
    &Pod{ObjectMeta:{test-deployment-s2nwm-777898ffcc-prpsn test-deployment-s2nwm-777898ffcc- deployment-1583  00eddf21-4418-46f9-9ff2-7c50fcf1e1d5 30149 0 2022-11-12 12:55:09 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-s2nwm-777898ffcc f103eba5-6050-4acb-8042-5570434f3eb3 0xc000b514e0 0xc000b514e1}] [] [{kube-controller-manager Update v1 2022-11-12 12:55:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f103eba5-6050-4acb-8042-5570434f3eb3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 12:55:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.47\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gmcvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gmcvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 12:55:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.47,StartTime:2022-11-12 12:55:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 12:55:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://87c7c352fe050297bf28d115e5e353d9caa5f643c6725160af7bf930a68d6cfc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 12:55:12.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-1583" for this suite. 11/12/22 12:55:12.05
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:55:12.067
Nov 12 12:55:12.068: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 12:55:12.07
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:12.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:12.114
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 11/12/22 12:55:12.117
STEP: fetching the ConfigMap 11/12/22 12:55:12.126
STEP: patching the ConfigMap 11/12/22 12:55:12.133
STEP: listing all ConfigMaps in all namespaces with a label selector 11/12/22 12:55:12.142
STEP: deleting the ConfigMap by collection with a label selector 11/12/22 12:55:12.149
STEP: listing all ConfigMaps in test namespace 11/12/22 12:55:12.162
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 12:55:12.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8019" for this suite. 11/12/22 12:55:12.175
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":230,"skipped":4261,"failed":0}
------------------------------
• [0.118 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:55:12.067
    Nov 12 12:55:12.068: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 12:55:12.07
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:12.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:12.114
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 11/12/22 12:55:12.117
    STEP: fetching the ConfigMap 11/12/22 12:55:12.126
    STEP: patching the ConfigMap 11/12/22 12:55:12.133
    STEP: listing all ConfigMaps in all namespaces with a label selector 11/12/22 12:55:12.142
    STEP: deleting the ConfigMap by collection with a label selector 11/12/22 12:55:12.149
    STEP: listing all ConfigMaps in test namespace 11/12/22 12:55:12.162
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 12:55:12.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8019" for this suite. 11/12/22 12:55:12.175
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:55:12.191
Nov 12 12:55:12.191: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 12:55:12.194
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:12.217
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:12.222
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 11/12/22 12:55:12.225
Nov 12 12:55:12.240: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5" in namespace "emptydir-744" to be "running"
Nov 12 12:55:12.248: INFO: Pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.75683ms
Nov 12 12:55:14.254: INFO: Pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5": Phase="Running", Reason="", readiness=false. Elapsed: 2.014410146s
Nov 12 12:55:14.254: INFO: Pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5" satisfied condition "running"
STEP: Reading file content from the nginx-container 11/12/22 12:55:14.254
Nov 12 12:55:14.254: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-744 PodName:pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 12:55:14.254: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 12:55:14.255: INFO: ExecWithOptions: Clientset creation
Nov 12 12:55:14.255: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-744/pods/pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Nov 12 12:55:14.334: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 12:55:14.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-744" for this suite. 11/12/22 12:55:14.342
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":231,"skipped":4283,"failed":0}
------------------------------
• [2.161 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:55:12.191
    Nov 12 12:55:12.191: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 12:55:12.194
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:12.217
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:12.222
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 11/12/22 12:55:12.225
    Nov 12 12:55:12.240: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5" in namespace "emptydir-744" to be "running"
    Nov 12 12:55:12.248: INFO: Pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.75683ms
    Nov 12 12:55:14.254: INFO: Pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5": Phase="Running", Reason="", readiness=false. Elapsed: 2.014410146s
    Nov 12 12:55:14.254: INFO: Pod "pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5" satisfied condition "running"
    STEP: Reading file content from the nginx-container 11/12/22 12:55:14.254
    Nov 12 12:55:14.254: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-744 PodName:pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 12:55:14.254: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 12:55:14.255: INFO: ExecWithOptions: Clientset creation
    Nov 12 12:55:14.255: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-744/pods/pod-sharedvolume-02e88cbb-d6ab-489c-bf9b-149723018fd5/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Nov 12 12:55:14.334: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 12:55:14.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-744" for this suite. 11/12/22 12:55:14.342
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:55:14.356
Nov 12 12:55:14.356: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 12:55:14.356
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:14.382
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:14.385
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-680 11/12/22 12:55:14.388
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-680 11/12/22 12:55:14.4
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-680 11/12/22 12:55:14.409
Nov 12 12:55:14.414: INFO: Found 0 stateful pods, waiting for 1
Nov 12 12:55:24.424: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/12/22 12:55:24.424
Nov 12 12:55:24.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:55:24.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:55:24.610: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:55:24.610: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:55:24.616: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 12 12:55:34.624: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:55:34.624: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:55:34.651: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Nov 12 12:55:34.651: INFO: ss-0  ip-172-31-14-110  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  }]
Nov 12 12:55:34.651: INFO: ss-1                    Pending         []
Nov 12 12:55:34.651: INFO: 
Nov 12 12:55:34.651: INFO: StatefulSet ss has not reached scale 3, at 2
Nov 12 12:55:35.658: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990941621s
Nov 12 12:55:36.665: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984188825s
Nov 12 12:55:37.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977451927s
Nov 12 12:55:38.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969953588s
Nov 12 12:55:39.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962691193s
Nov 12 12:55:40.692: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955898622s
Nov 12 12:55:41.698: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9505635s
Nov 12 12:55:42.706: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943765233s
Nov 12 12:55:43.712: INFO: Verifying statefulset ss doesn't scale past 3 for another 936.857639ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-680 11/12/22 12:55:44.712
Nov 12 12:55:44.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:55:44.896: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 12 12:55:44.896: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:55:44.896: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 12:55:44.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:55:45.050: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 12 12:55:45.050: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:55:45.050: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 12:55:45.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 12 12:55:45.219: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 12 12:55:45.219: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 12 12:55:45.219: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 12 12:55:45.233: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Nov 12 12:55:55.246: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:55:55.246: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 12 12:55:55.246: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 11/12/22 12:55:55.246
Nov 12 12:55:55.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:55:55.402: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:55:55.402: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:55:55.402: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:55:55.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:55:55.588: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:55:55.588: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:55:55.588: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:55:55.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 12 12:55:55.759: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 12 12:55:55.759: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 12 12:55:55.759: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 12 12:55:55.759: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:55:55.767: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 12 12:56:05.778: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:56:05.778: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:56:05.778: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 12 12:56:05.795: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Nov 12 12:56:05.795: INFO: ss-0  ip-172-31-14-110  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  }]
Nov 12 12:56:05.795: INFO: ss-1  ip-172-31-89-190  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  }]
Nov 12 12:56:05.795: INFO: ss-2  ip-172-31-47-219  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  }]
Nov 12 12:56:05.795: INFO: 
Nov 12 12:56:05.795: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 12 12:56:06.801: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Nov 12 12:56:06.801: INFO: ss-0  ip-172-31-14-110  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  }]
Nov 12 12:56:06.801: INFO: ss-1  ip-172-31-89-190  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  }]
Nov 12 12:56:06.801: INFO: 
Nov 12 12:56:06.801: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 12 12:56:07.806: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.988817516s
Nov 12 12:56:08.812: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.983703009s
Nov 12 12:56:09.818: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.978174647s
Nov 12 12:56:10.825: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.971445674s
Nov 12 12:56:11.830: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.965466393s
Nov 12 12:56:12.835: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.960084147s
Nov 12 12:56:13.842: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.954449826s
Nov 12 12:56:14.849: INFO: Verifying statefulset ss doesn't scale past 0 for another 947.901831ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-680 11/12/22 12:56:15.849
Nov 12 12:56:15.856: INFO: Scaling statefulset ss to 0
Nov 12 12:56:15.877: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 12:56:15.883: INFO: Deleting all statefulset in ns statefulset-680
Nov 12 12:56:15.888: INFO: Scaling statefulset ss to 0
Nov 12 12:56:15.902: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 12:56:15.907: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 12:56:15.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-680" for this suite. 11/12/22 12:56:15.936
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":232,"skipped":4315,"failed":0}
------------------------------
• [SLOW TEST] [61.593 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:55:14.356
    Nov 12 12:55:14.356: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 12:55:14.356
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:55:14.382
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:55:14.385
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-680 11/12/22 12:55:14.388
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-680 11/12/22 12:55:14.4
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-680 11/12/22 12:55:14.409
    Nov 12 12:55:14.414: INFO: Found 0 stateful pods, waiting for 1
    Nov 12 12:55:24.424: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/12/22 12:55:24.424
    Nov 12 12:55:24.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:55:24.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:55:24.610: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:55:24.610: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:55:24.616: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 12 12:55:34.624: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:55:34.624: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:55:34.651: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Nov 12 12:55:34.651: INFO: ss-0  ip-172-31-14-110  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  }]
    Nov 12 12:55:34.651: INFO: ss-1                    Pending         []
    Nov 12 12:55:34.651: INFO: 
    Nov 12 12:55:34.651: INFO: StatefulSet ss has not reached scale 3, at 2
    Nov 12 12:55:35.658: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990941621s
    Nov 12 12:55:36.665: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984188825s
    Nov 12 12:55:37.671: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.977451927s
    Nov 12 12:55:38.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969953588s
    Nov 12 12:55:39.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962691193s
    Nov 12 12:55:40.692: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955898622s
    Nov 12 12:55:41.698: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9505635s
    Nov 12 12:55:42.706: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943765233s
    Nov 12 12:55:43.712: INFO: Verifying statefulset ss doesn't scale past 3 for another 936.857639ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-680 11/12/22 12:55:44.712
    Nov 12 12:55:44.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:55:44.896: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 12 12:55:44.896: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:55:44.896: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 12:55:44.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:55:45.050: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 12 12:55:45.050: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:55:45.050: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 12:55:45.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 12 12:55:45.219: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 12 12:55:45.219: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 12 12:55:45.219: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 12 12:55:45.233: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Nov 12 12:55:55.246: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:55:55.246: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 12 12:55:55.246: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 11/12/22 12:55:55.246
    Nov 12 12:55:55.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:55:55.402: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:55:55.402: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:55:55.402: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:55:55.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:55:55.588: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:55:55.588: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:55:55.588: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:55:55.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=statefulset-680 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 12 12:55:55.759: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 12 12:55:55.759: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 12 12:55:55.759: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 12 12:55:55.759: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:55:55.767: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Nov 12 12:56:05.778: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:56:05.778: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:56:05.778: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 12 12:56:05.795: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Nov 12 12:56:05.795: INFO: ss-0  ip-172-31-14-110  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  }]
    Nov 12 12:56:05.795: INFO: ss-1  ip-172-31-89-190  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  }]
    Nov 12 12:56:05.795: INFO: ss-2  ip-172-31-47-219  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  }]
    Nov 12 12:56:05.795: INFO: 
    Nov 12 12:56:05.795: INFO: StatefulSet ss has not reached scale 0, at 3
    Nov 12 12:56:06.801: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Nov 12 12:56:06.801: INFO: ss-0  ip-172-31-14-110  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:14 +0000 UTC  }]
    Nov 12 12:56:06.801: INFO: ss-1  ip-172-31-89-190  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 12:55:34 +0000 UTC  }]
    Nov 12 12:56:06.801: INFO: 
    Nov 12 12:56:06.801: INFO: StatefulSet ss has not reached scale 0, at 2
    Nov 12 12:56:07.806: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.988817516s
    Nov 12 12:56:08.812: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.983703009s
    Nov 12 12:56:09.818: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.978174647s
    Nov 12 12:56:10.825: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.971445674s
    Nov 12 12:56:11.830: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.965466393s
    Nov 12 12:56:12.835: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.960084147s
    Nov 12 12:56:13.842: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.954449826s
    Nov 12 12:56:14.849: INFO: Verifying statefulset ss doesn't scale past 0 for another 947.901831ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-680 11/12/22 12:56:15.849
    Nov 12 12:56:15.856: INFO: Scaling statefulset ss to 0
    Nov 12 12:56:15.877: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 12:56:15.883: INFO: Deleting all statefulset in ns statefulset-680
    Nov 12 12:56:15.888: INFO: Scaling statefulset ss to 0
    Nov 12 12:56:15.902: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 12:56:15.907: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 12:56:15.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-680" for this suite. 11/12/22 12:56:15.936
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 12:56:15.951
Nov 12 12:56:15.951: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename cronjob 11/12/22 12:56:15.951
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:56:15.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:56:15.98
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 11/12/22 12:56:15.985
STEP: Ensuring no jobs are scheduled 11/12/22 12:56:16
STEP: Ensuring no job exists by listing jobs explicitly 11/12/22 13:01:16.01
STEP: Removing cronjob 11/12/22 13:01:16.02
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 12 13:01:16.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9569" for this suite. 11/12/22 13:01:16.035
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":233,"skipped":4317,"failed":0}
------------------------------
• [SLOW TEST] [300.095 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 12:56:15.951
    Nov 12 12:56:15.951: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename cronjob 11/12/22 12:56:15.951
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 12:56:15.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 12:56:15.98
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 11/12/22 12:56:15.985
    STEP: Ensuring no jobs are scheduled 11/12/22 12:56:16
    STEP: Ensuring no job exists by listing jobs explicitly 11/12/22 13:01:16.01
    STEP: Removing cronjob 11/12/22 13:01:16.02
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 12 13:01:16.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9569" for this suite. 11/12/22 13:01:16.035
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:01:16.046
Nov 12 13:01:16.046: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:01:16.047
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:16.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:16.138
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-3476 11/12/22 13:01:16.142
STEP: creating replication controller nodeport-test in namespace services-3476 11/12/22 13:01:16.169
I1112 13:01:16.186871      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-3476, replica count: 2
I1112 13:01:19.240128      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 13:01:19.240: INFO: Creating new exec pod
Nov 12 13:01:19.251: INFO: Waiting up to 5m0s for pod "execpodpxr2s" in namespace "services-3476" to be "running"
Nov 12 13:01:19.258: INFO: Pod "execpodpxr2s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.857539ms
Nov 12 13:01:21.264: INFO: Pod "execpodpxr2s": Phase="Running", Reason="", readiness=true. Elapsed: 2.012474394s
Nov 12 13:01:21.264: INFO: Pod "execpodpxr2s" satisfied condition "running"
Nov 12 13:01:22.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 12 13:01:22.461: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 12 13:01:22.461: INFO: stdout: "nodeport-test-h7plb"
Nov 12 13:01:22.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.89 80'
Nov 12 13:01:22.666: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.89 80\nConnection to 10.152.183.89 80 port [tcp/http] succeeded!\n"
Nov 12 13:01:22.666: INFO: stdout: ""
Nov 12 13:01:23.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.89 80'
Nov 12 13:01:23.805: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.89 80\nConnection to 10.152.183.89 80 port [tcp/http] succeeded!\n"
Nov 12 13:01:23.805: INFO: stdout: "nodeport-test-h7plb"
Nov 12 13:01:23.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 32521'
Nov 12 13:01:23.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.89.190 32521\nConnection to 172.31.89.190 32521 port [tcp/*] succeeded!\n"
Nov 12 13:01:23.935: INFO: stdout: "nodeport-test-sgl8n"
Nov 12 13:01:23.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.47.219 32521'
Nov 12 13:01:24.081: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.47.219 32521\nConnection to 172.31.47.219 32521 port [tcp/*] succeeded!\n"
Nov 12 13:01:24.081: INFO: stdout: "nodeport-test-h7plb"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:01:24.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3476" for this suite. 11/12/22 13:01:24.086
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":234,"skipped":4317,"failed":0}
------------------------------
• [SLOW TEST] [8.055 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:01:16.046
    Nov 12 13:01:16.046: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:01:16.047
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:16.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:16.138
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-3476 11/12/22 13:01:16.142
    STEP: creating replication controller nodeport-test in namespace services-3476 11/12/22 13:01:16.169
    I1112 13:01:16.186871      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-3476, replica count: 2
    I1112 13:01:19.240128      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 13:01:19.240: INFO: Creating new exec pod
    Nov 12 13:01:19.251: INFO: Waiting up to 5m0s for pod "execpodpxr2s" in namespace "services-3476" to be "running"
    Nov 12 13:01:19.258: INFO: Pod "execpodpxr2s": Phase="Pending", Reason="", readiness=false. Elapsed: 6.857539ms
    Nov 12 13:01:21.264: INFO: Pod "execpodpxr2s": Phase="Running", Reason="", readiness=true. Elapsed: 2.012474394s
    Nov 12 13:01:21.264: INFO: Pod "execpodpxr2s" satisfied condition "running"
    Nov 12 13:01:22.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 12 13:01:22.461: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 12 13:01:22.461: INFO: stdout: "nodeport-test-h7plb"
    Nov 12 13:01:22.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.89 80'
    Nov 12 13:01:22.666: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.89 80\nConnection to 10.152.183.89 80 port [tcp/http] succeeded!\n"
    Nov 12 13:01:22.666: INFO: stdout: ""
    Nov 12 13:01:23.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.89 80'
    Nov 12 13:01:23.805: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.89 80\nConnection to 10.152.183.89 80 port [tcp/http] succeeded!\n"
    Nov 12 13:01:23.805: INFO: stdout: "nodeport-test-h7plb"
    Nov 12 13:01:23.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.190 32521'
    Nov 12 13:01:23.935: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.89.190 32521\nConnection to 172.31.89.190 32521 port [tcp/*] succeeded!\n"
    Nov 12 13:01:23.935: INFO: stdout: "nodeport-test-sgl8n"
    Nov 12 13:01:23.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-3476 exec execpodpxr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.47.219 32521'
    Nov 12 13:01:24.081: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.47.219 32521\nConnection to 172.31.47.219 32521 port [tcp/*] succeeded!\n"
    Nov 12 13:01:24.081: INFO: stdout: "nodeport-test-h7plb"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:01:24.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3476" for this suite. 11/12/22 13:01:24.086
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:01:24.102
Nov 12 13:01:24.102: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:01:24.103
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:24.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:24.134
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:01:24.139
Nov 12 13:01:24.156: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94" in namespace "downward-api-4942" to be "Succeeded or Failed"
Nov 12 13:01:24.163: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94": Phase="Pending", Reason="", readiness=false. Elapsed: 7.357586ms
Nov 12 13:01:26.170: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01388094s
Nov 12 13:01:28.173: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017467984s
STEP: Saw pod success 11/12/22 13:01:28.173
Nov 12 13:01:28.173: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94" satisfied condition "Succeeded or Failed"
Nov 12 13:01:28.178: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94 container client-container: <nil>
STEP: delete the pod 11/12/22 13:01:28.198
Nov 12 13:01:28.312: INFO: Waiting for pod downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94 to disappear
Nov 12 13:01:28.317: INFO: Pod downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:01:28.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4942" for this suite. 11/12/22 13:01:28.328
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":235,"skipped":4320,"failed":0}
------------------------------
• [4.238 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:01:24.102
    Nov 12 13:01:24.102: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:01:24.103
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:24.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:24.134
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:01:24.139
    Nov 12 13:01:24.156: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94" in namespace "downward-api-4942" to be "Succeeded or Failed"
    Nov 12 13:01:24.163: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94": Phase="Pending", Reason="", readiness=false. Elapsed: 7.357586ms
    Nov 12 13:01:26.170: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01388094s
    Nov 12 13:01:28.173: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017467984s
    STEP: Saw pod success 11/12/22 13:01:28.173
    Nov 12 13:01:28.173: INFO: Pod "downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94" satisfied condition "Succeeded or Failed"
    Nov 12 13:01:28.178: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94 container client-container: <nil>
    STEP: delete the pod 11/12/22 13:01:28.198
    Nov 12 13:01:28.312: INFO: Waiting for pod downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94 to disappear
    Nov 12 13:01:28.317: INFO: Pod downwardapi-volume-72a4847e-116a-4dd5-b220-c4bc00a33b94 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:01:28.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4942" for this suite. 11/12/22 13:01:28.328
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:01:28.339
Nov 12 13:01:28.340: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename security-context-test 11/12/22 13:01:28.341
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:28.367
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:28.37
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Nov 12 13:01:28.386: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053" in namespace "security-context-test-460" to be "Succeeded or Failed"
Nov 12 13:01:28.400: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Pending", Reason="", readiness=false. Elapsed: 14.11191ms
Nov 12 13:01:30.410: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024192106s
Nov 12 13:01:32.408: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022085156s
Nov 12 13:01:34.407: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020624251s
Nov 12 13:01:34.407: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053" satisfied condition "Succeeded or Failed"
Nov 12 13:01:34.428: INFO: Got logs for pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 13:01:34.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-460" for this suite. 11/12/22 13:01:34.434
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":236,"skipped":4320,"failed":0}
------------------------------
• [SLOW TEST] [6.104 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:01:28.339
    Nov 12 13:01:28.340: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename security-context-test 11/12/22 13:01:28.341
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:28.367
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:28.37
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Nov 12 13:01:28.386: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053" in namespace "security-context-test-460" to be "Succeeded or Failed"
    Nov 12 13:01:28.400: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Pending", Reason="", readiness=false. Elapsed: 14.11191ms
    Nov 12 13:01:30.410: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024192106s
    Nov 12 13:01:32.408: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022085156s
    Nov 12 13:01:34.407: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020624251s
    Nov 12 13:01:34.407: INFO: Pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053" satisfied condition "Succeeded or Failed"
    Nov 12 13:01:34.428: INFO: Got logs for pod "busybox-privileged-false-8303f894-0f45-4cb6-8b4a-f86a07c57053": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 13:01:34.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-460" for this suite. 11/12/22 13:01:34.434
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:01:34.445
Nov 12 13:01:34.445: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 13:01:34.446
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:34.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:34.475
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 11/12/22 13:01:34.482
STEP: Counting existing ResourceQuota 11/12/22 13:01:39.503
STEP: Creating a ResourceQuota 11/12/22 13:01:44.509
STEP: Ensuring resource quota status is calculated 11/12/22 13:01:44.52
STEP: Creating a Secret 11/12/22 13:01:46.527
STEP: Ensuring resource quota status captures secret creation 11/12/22 13:01:46.552
STEP: Deleting a secret 11/12/22 13:01:48.558
STEP: Ensuring resource quota status released usage 11/12/22 13:01:48.574
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 13:01:50.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7808" for this suite. 11/12/22 13:01:50.585
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":237,"skipped":4331,"failed":0}
------------------------------
• [SLOW TEST] [16.149 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:01:34.445
    Nov 12 13:01:34.445: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 13:01:34.446
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:34.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:34.475
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 11/12/22 13:01:34.482
    STEP: Counting existing ResourceQuota 11/12/22 13:01:39.503
    STEP: Creating a ResourceQuota 11/12/22 13:01:44.509
    STEP: Ensuring resource quota status is calculated 11/12/22 13:01:44.52
    STEP: Creating a Secret 11/12/22 13:01:46.527
    STEP: Ensuring resource quota status captures secret creation 11/12/22 13:01:46.552
    STEP: Deleting a secret 11/12/22 13:01:48.558
    STEP: Ensuring resource quota status released usage 11/12/22 13:01:48.574
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 13:01:50.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7808" for this suite. 11/12/22 13:01:50.585
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:01:50.597
Nov 12 13:01:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 13:01:50.598
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:50.624
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:50.627
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-57924655-6096-42ad-ba95-772b352ab76e 11/12/22 13:01:50.633
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 12 13:01:50.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6830" for this suite. 11/12/22 13:01:50.647
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":238,"skipped":4378,"failed":0}
------------------------------
• [0.059 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:01:50.597
    Nov 12 13:01:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 13:01:50.598
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:50.624
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:50.627
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-57924655-6096-42ad-ba95-772b352ab76e 11/12/22 13:01:50.633
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 13:01:50.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6830" for this suite. 11/12/22 13:01:50.647
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:01:50.659
Nov 12 13:01:50.659: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-pred 11/12/22 13:01:50.66
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:50.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:50.692
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 12 13:01:50.697: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 12 13:01:50.710: INFO: Waiting for terminating namespaces to be deleted...
Nov 12 13:01:50.715: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
Nov 12 13:01:50.722: INFO: nginx-ingress-controller-kubernetes-worker-vpz52 from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:20 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.722: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:01:50.722: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.722: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 12 13:01:50.722: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:01:50.722: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:01:50.722: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 13:01:50.722: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
Nov 12 13:01:50.730: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 12 13:01:50.730: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:01:50.730: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 12 13:01:50.730: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container coredns ready: true, restart count 0
Nov 12 13:01:50.730: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 12 13:01:50.730: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container metrics-server ready: true, restart count 0
Nov 12 13:01:50.730: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 12 13:01:50.730: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 12 13:01:50.730: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 12 13:01:50.730: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:01:50.730: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:01:50.730: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 13:01:50.730: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
Nov 12 13:01:50.737: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
Nov 12 13:01:50.738: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:01:50.738: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:01:50.738: INFO: 	Container e2e ready: true, restart count 0
Nov 12 13:01:50.738: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:01:50.738: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:01:50.738: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:01:50.738: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node ip-172-31-14-110 11/12/22 13:01:50.757
STEP: verifying the node has the label node ip-172-31-47-219 11/12/22 13:01:50.773
STEP: verifying the node has the label node ip-172-31-89-190 11/12/22 13:01:50.793
Nov 12 13:01:50.807: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-jqjnt requesting resource cpu=10m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod nginx-ingress-controller-kubernetes-worker-6kkxq requesting resource cpu=0m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod nginx-ingress-controller-kubernetes-worker-fl6kj requesting resource cpu=0m on Node ip-172-31-89-190
Nov 12 13:01:50.807: INFO: Pod nginx-ingress-controller-kubernetes-worker-vpz52 requesting resource cpu=0m on Node ip-172-31-14-110
Nov 12 13:01:50.807: INFO: Pod calico-kube-controllers-757485cd6d-94hn6 requesting resource cpu=0m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod coredns-6bcf44f4cc-v97wf requesting resource cpu=100m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod kube-state-metrics-74f5d549cc-7fvhd requesting resource cpu=0m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-mjkbl requesting resource cpu=5m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod dashboard-metrics-scraper-85d45476c6-b8gmx requesting resource cpu=0m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod kubernetes-dashboard-7fb574cb-cmvn2 requesting resource cpu=0m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-14-110
Nov 12 13:01:50.807: INFO: Pod sonobuoy-e2e-job-df3011634d0e45b0 requesting resource cpu=0m on Node ip-172-31-89-190
Nov 12 13:01:50.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k requesting resource cpu=0m on Node ip-172-31-89-190
Nov 12 13:01:50.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx requesting resource cpu=0m on Node ip-172-31-47-219
Nov 12 13:01:50.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm requesting resource cpu=0m on Node ip-172-31-14-110
STEP: Starting Pods to consume most of the cluster CPU. 11/12/22 13:01:50.807
Nov 12 13:01:50.808: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-14-110
Nov 12 13:01:50.821: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-47-219
Nov 12 13:01:50.830: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-89-190
Nov 12 13:01:50.836: INFO: Waiting up to 5m0s for pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824" in namespace "sched-pred-9923" to be "running"
Nov 12 13:01:50.845: INFO: Pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824": Phase="Pending", Reason="", readiness=false. Elapsed: 9.008478ms
Nov 12 13:01:52.851: INFO: Pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824": Phase="Running", Reason="", readiness=true. Elapsed: 2.014574491s
Nov 12 13:01:52.851: INFO: Pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824" satisfied condition "running"
Nov 12 13:01:52.851: INFO: Waiting up to 5m0s for pod "filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9" in namespace "sched-pred-9923" to be "running"
Nov 12 13:01:52.857: INFO: Pod "filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9": Phase="Running", Reason="", readiness=true. Elapsed: 5.768966ms
Nov 12 13:01:52.857: INFO: Pod "filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9" satisfied condition "running"
Nov 12 13:01:52.857: INFO: Waiting up to 5m0s for pod "filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7" in namespace "sched-pred-9923" to be "running"
Nov 12 13:01:52.865: INFO: Pod "filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7": Phase="Running", Reason="", readiness=true. Elapsed: 8.383405ms
Nov 12 13:01:52.865: INFO: Pod "filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 11/12/22 13:01:52.865
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9b8f3d649], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9923/filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9 to ip-172-31-47-219] 11/12/22 13:01:52.871
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9e4b1e887], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/12/22 13:01:52.871
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9e71580e8], Reason = [Created], Message = [Created container filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9] 11/12/22 13:01:52.872
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9ec554ba8], Reason = [Started], Message = [Started container filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9] 11/12/22 13:01:52.872
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9b99a7ca6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9923/filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7 to ip-172-31-89-190] 11/12/22 13:01:52.872
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9e8793837], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/12/22 13:01:52.872
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9ead3740d], Reason = [Created], Message = [Created container filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7] 11/12/22 13:01:52.872
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9efd09a89], Reason = [Started], Message = [Started container filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7] 11/12/22 13:01:52.872
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9b86a7285], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9923/filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824 to ip-172-31-14-110] 11/12/22 13:01:52.873
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9e64b1546], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/12/22 13:01:52.873
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9e861cdda], Reason = [Created], Message = [Created container filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824] 11/12/22 13:01:52.873
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9ed566751], Reason = [Started], Message = [Started container filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824] 11/12/22 13:01:52.873
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1726d7ea327356a4], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 11/12/22 13:01:52.894
STEP: removing the label node off the node ip-172-31-14-110 11/12/22 13:01:53.89
STEP: verifying the node doesn't have the label node 11/12/22 13:01:53.906
STEP: removing the label node off the node ip-172-31-47-219 11/12/22 13:01:53.913
STEP: verifying the node doesn't have the label node 11/12/22 13:01:53.934
STEP: removing the label node off the node ip-172-31-89-190 11/12/22 13:01:53.94
STEP: verifying the node doesn't have the label node 11/12/22 13:01:53.956
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:01:53.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9923" for this suite. 11/12/22 13:01:53.971
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":239,"skipped":4401,"failed":0}
------------------------------
• [3.324 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:01:50.659
    Nov 12 13:01:50.659: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-pred 11/12/22 13:01:50.66
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:50.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:50.692
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 12 13:01:50.697: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 12 13:01:50.710: INFO: Waiting for terminating namespaces to be deleted...
    Nov 12 13:01:50.715: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
    Nov 12 13:01:50.722: INFO: nginx-ingress-controller-kubernetes-worker-vpz52 from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:20 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.722: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:01:50.722: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.722: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 12 13:01:50.722: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:01:50.722: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:01:50.722: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 13:01:50.722: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
    Nov 12 13:01:50.730: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container coredns ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:01:50.730: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 13:01:50.730: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
    Nov 12 13:01:50.737: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
    Nov 12 13:01:50.738: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:01:50.738: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:01:50.738: INFO: 	Container e2e ready: true, restart count 0
    Nov 12 13:01:50.738: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:01:50.738: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:01:50.738: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:01:50.738: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node ip-172-31-14-110 11/12/22 13:01:50.757
    STEP: verifying the node has the label node ip-172-31-47-219 11/12/22 13:01:50.773
    STEP: verifying the node has the label node ip-172-31-89-190 11/12/22 13:01:50.793
    Nov 12 13:01:50.807: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-jqjnt requesting resource cpu=10m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod nginx-ingress-controller-kubernetes-worker-6kkxq requesting resource cpu=0m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod nginx-ingress-controller-kubernetes-worker-fl6kj requesting resource cpu=0m on Node ip-172-31-89-190
    Nov 12 13:01:50.807: INFO: Pod nginx-ingress-controller-kubernetes-worker-vpz52 requesting resource cpu=0m on Node ip-172-31-14-110
    Nov 12 13:01:50.807: INFO: Pod calico-kube-controllers-757485cd6d-94hn6 requesting resource cpu=0m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod coredns-6bcf44f4cc-v97wf requesting resource cpu=100m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod kube-state-metrics-74f5d549cc-7fvhd requesting resource cpu=0m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-mjkbl requesting resource cpu=5m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod dashboard-metrics-scraper-85d45476c6-b8gmx requesting resource cpu=0m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod kubernetes-dashboard-7fb574cb-cmvn2 requesting resource cpu=0m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-14-110
    Nov 12 13:01:50.807: INFO: Pod sonobuoy-e2e-job-df3011634d0e45b0 requesting resource cpu=0m on Node ip-172-31-89-190
    Nov 12 13:01:50.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k requesting resource cpu=0m on Node ip-172-31-89-190
    Nov 12 13:01:50.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx requesting resource cpu=0m on Node ip-172-31-47-219
    Nov 12 13:01:50.807: INFO: Pod sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm requesting resource cpu=0m on Node ip-172-31-14-110
    STEP: Starting Pods to consume most of the cluster CPU. 11/12/22 13:01:50.807
    Nov 12 13:01:50.808: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-14-110
    Nov 12 13:01:50.821: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-47-219
    Nov 12 13:01:50.830: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-89-190
    Nov 12 13:01:50.836: INFO: Waiting up to 5m0s for pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824" in namespace "sched-pred-9923" to be "running"
    Nov 12 13:01:50.845: INFO: Pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824": Phase="Pending", Reason="", readiness=false. Elapsed: 9.008478ms
    Nov 12 13:01:52.851: INFO: Pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824": Phase="Running", Reason="", readiness=true. Elapsed: 2.014574491s
    Nov 12 13:01:52.851: INFO: Pod "filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824" satisfied condition "running"
    Nov 12 13:01:52.851: INFO: Waiting up to 5m0s for pod "filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9" in namespace "sched-pred-9923" to be "running"
    Nov 12 13:01:52.857: INFO: Pod "filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9": Phase="Running", Reason="", readiness=true. Elapsed: 5.768966ms
    Nov 12 13:01:52.857: INFO: Pod "filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9" satisfied condition "running"
    Nov 12 13:01:52.857: INFO: Waiting up to 5m0s for pod "filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7" in namespace "sched-pred-9923" to be "running"
    Nov 12 13:01:52.865: INFO: Pod "filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7": Phase="Running", Reason="", readiness=true. Elapsed: 8.383405ms
    Nov 12 13:01:52.865: INFO: Pod "filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 11/12/22 13:01:52.865
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9b8f3d649], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9923/filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9 to ip-172-31-47-219] 11/12/22 13:01:52.871
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9e4b1e887], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/12/22 13:01:52.871
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9e71580e8], Reason = [Created], Message = [Created container filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9] 11/12/22 13:01:52.872
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9.1726d7e9ec554ba8], Reason = [Started], Message = [Started container filler-pod-4adca7a9-d6d0-4666-8b0e-99ba36de4ad9] 11/12/22 13:01:52.872
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9b99a7ca6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9923/filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7 to ip-172-31-89-190] 11/12/22 13:01:52.872
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9e8793837], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/12/22 13:01:52.872
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9ead3740d], Reason = [Created], Message = [Created container filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7] 11/12/22 13:01:52.872
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7.1726d7e9efd09a89], Reason = [Started], Message = [Started container filler-pod-5d2a390a-061d-4bc7-a81e-855ce8482aa7] 11/12/22 13:01:52.872
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9b86a7285], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9923/filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824 to ip-172-31-14-110] 11/12/22 13:01:52.873
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9e64b1546], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/12/22 13:01:52.873
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9e861cdda], Reason = [Created], Message = [Created container filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824] 11/12/22 13:01:52.873
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824.1726d7e9ed566751], Reason = [Started], Message = [Started container filler-pod-fc989e3a-6a6d-4b67-ab35-99ea30a30824] 11/12/22 13:01:52.873
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.1726d7ea327356a4], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 11/12/22 13:01:52.894
    STEP: removing the label node off the node ip-172-31-14-110 11/12/22 13:01:53.89
    STEP: verifying the node doesn't have the label node 11/12/22 13:01:53.906
    STEP: removing the label node off the node ip-172-31-47-219 11/12/22 13:01:53.913
    STEP: verifying the node doesn't have the label node 11/12/22 13:01:53.934
    STEP: removing the label node off the node ip-172-31-89-190 11/12/22 13:01:53.94
    STEP: verifying the node doesn't have the label node 11/12/22 13:01:53.956
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:01:53.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9923" for this suite. 11/12/22 13:01:53.971
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:01:53.986
Nov 12 13:01:53.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:01:53.987
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:54.023
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:54.026
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Nov 12 13:01:54.030: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/12/22 13:01:56.387
Nov 12 13:01:56.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
Nov 12 13:01:57.124: INFO: stderr: ""
Nov 12 13:01:57.124: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 12 13:01:57.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 delete e2e-test-crd-publish-openapi-3339-crds test-foo'
Nov 12 13:01:57.203: INFO: stderr: ""
Nov 12 13:01:57.203: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov 12 13:01:57.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 apply -f -'
Nov 12 13:01:57.411: INFO: stderr: ""
Nov 12 13:01:57.411: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 12 13:01:57.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 delete e2e-test-crd-publish-openapi-3339-crds test-foo'
Nov 12 13:01:57.495: INFO: stderr: ""
Nov 12 13:01:57.495: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/12/22 13:01:57.495
Nov 12 13:01:57.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
Nov 12 13:01:58.114: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/12/22 13:01:58.114
Nov 12 13:01:58.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
Nov 12 13:01:58.301: INFO: rc: 1
Nov 12 13:01:58.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 apply -f -'
Nov 12 13:01:58.574: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/12/22 13:01:58.574
Nov 12 13:01:58.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
Nov 12 13:01:58.855: INFO: rc: 1
Nov 12 13:01:58.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 apply -f -'
Nov 12 13:01:59.166: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 11/12/22 13:01:59.166
Nov 12 13:01:59.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds'
Nov 12 13:01:59.441: INFO: stderr: ""
Nov 12 13:01:59.441: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 11/12/22 13:01:59.442
Nov 12 13:01:59.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.metadata'
Nov 12 13:01:59.715: INFO: stderr: ""
Nov 12 13:01:59.715: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov 12 13:01:59.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.spec'
Nov 12 13:01:59.999: INFO: stderr: ""
Nov 12 13:01:59.999: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov 12 13:02:00.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.spec.bars'
Nov 12 13:02:00.195: INFO: stderr: ""
Nov 12 13:02:00.195: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/12/22 13:02:00.195
Nov 12 13:02:00.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.spec.bars2'
Nov 12 13:02:00.373: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:02:02.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6392" for this suite. 11/12/22 13:02:02.746
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":240,"skipped":4434,"failed":0}
------------------------------
• [SLOW TEST] [8.769 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:01:53.986
    Nov 12 13:01:53.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:01:53.987
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:01:54.023
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:01:54.026
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Nov 12 13:01:54.030: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/12/22 13:01:56.387
    Nov 12 13:01:56.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
    Nov 12 13:01:57.124: INFO: stderr: ""
    Nov 12 13:01:57.124: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 12 13:01:57.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 delete e2e-test-crd-publish-openapi-3339-crds test-foo'
    Nov 12 13:01:57.203: INFO: stderr: ""
    Nov 12 13:01:57.203: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Nov 12 13:01:57.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 apply -f -'
    Nov 12 13:01:57.411: INFO: stderr: ""
    Nov 12 13:01:57.411: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 12 13:01:57.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 delete e2e-test-crd-publish-openapi-3339-crds test-foo'
    Nov 12 13:01:57.495: INFO: stderr: ""
    Nov 12 13:01:57.495: INFO: stdout: "e2e-test-crd-publish-openapi-3339-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/12/22 13:01:57.495
    Nov 12 13:01:57.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
    Nov 12 13:01:58.114: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/12/22 13:01:58.114
    Nov 12 13:01:58.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
    Nov 12 13:01:58.301: INFO: rc: 1
    Nov 12 13:01:58.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 apply -f -'
    Nov 12 13:01:58.574: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/12/22 13:01:58.574
    Nov 12 13:01:58.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 create -f -'
    Nov 12 13:01:58.855: INFO: rc: 1
    Nov 12 13:01:58.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 --namespace=crd-publish-openapi-6392 apply -f -'
    Nov 12 13:01:59.166: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 11/12/22 13:01:59.166
    Nov 12 13:01:59.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds'
    Nov 12 13:01:59.441: INFO: stderr: ""
    Nov 12 13:01:59.441: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 11/12/22 13:01:59.442
    Nov 12 13:01:59.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.metadata'
    Nov 12 13:01:59.715: INFO: stderr: ""
    Nov 12 13:01:59.715: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Nov 12 13:01:59.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.spec'
    Nov 12 13:01:59.999: INFO: stderr: ""
    Nov 12 13:01:59.999: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Nov 12 13:02:00.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.spec.bars'
    Nov 12 13:02:00.195: INFO: stderr: ""
    Nov 12 13:02:00.195: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3339-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/12/22 13:02:00.195
    Nov 12 13:02:00.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-6392 explain e2e-test-crd-publish-openapi-3339-crds.spec.bars2'
    Nov 12 13:02:00.373: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:02:02.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6392" for this suite. 11/12/22 13:02:02.746
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:02:02.757
Nov 12 13:02:02.757: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:02:02.758
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:02.784
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:02.788
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/12/22 13:02:02.796
Nov 12 13:02:02.797: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/12/22 13:02:13.498
Nov 12 13:02:13.499: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 13:02:15.910: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:02:27.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3362" for this suite. 11/12/22 13:02:27.975
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":241,"skipped":4443,"failed":0}
------------------------------
• [SLOW TEST] [25.228 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:02:02.757
    Nov 12 13:02:02.757: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:02:02.758
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:02.784
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:02.788
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/12/22 13:02:02.796
    Nov 12 13:02:02.797: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/12/22 13:02:13.498
    Nov 12 13:02:13.499: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 13:02:15.910: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:02:27.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3362" for this suite. 11/12/22 13:02:27.975
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:02:27.986
Nov 12 13:02:27.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 13:02:27.987
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:28.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:28.01
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-ce23aa4f-520e-4458-bc89-6f149d757dfb 11/12/22 13:02:28.012
STEP: Creating a pod to test consume secrets 11/12/22 13:02:28.018
Nov 12 13:02:28.029: INFO: Waiting up to 5m0s for pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46" in namespace "secrets-4783" to be "Succeeded or Failed"
Nov 12 13:02:28.038: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46": Phase="Pending", Reason="", readiness=false. Elapsed: 8.942085ms
Nov 12 13:02:30.045: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015699014s
Nov 12 13:02:32.044: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014719382s
STEP: Saw pod success 11/12/22 13:02:32.044
Nov 12 13:02:32.044: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46" satisfied condition "Succeeded or Failed"
Nov 12 13:02:32.048: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 13:02:32.063
Nov 12 13:02:32.079: INFO: Waiting for pod pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46 to disappear
Nov 12 13:02:32.084: INFO: Pod pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 13:02:32.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4783" for this suite. 11/12/22 13:02:32.09
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":242,"skipped":4450,"failed":0}
------------------------------
• [4.113 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:02:27.986
    Nov 12 13:02:27.986: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 13:02:27.987
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:28.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:28.01
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-ce23aa4f-520e-4458-bc89-6f149d757dfb 11/12/22 13:02:28.012
    STEP: Creating a pod to test consume secrets 11/12/22 13:02:28.018
    Nov 12 13:02:28.029: INFO: Waiting up to 5m0s for pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46" in namespace "secrets-4783" to be "Succeeded or Failed"
    Nov 12 13:02:28.038: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46": Phase="Pending", Reason="", readiness=false. Elapsed: 8.942085ms
    Nov 12 13:02:30.045: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015699014s
    Nov 12 13:02:32.044: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014719382s
    STEP: Saw pod success 11/12/22 13:02:32.044
    Nov 12 13:02:32.044: INFO: Pod "pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46" satisfied condition "Succeeded or Failed"
    Nov 12 13:02:32.048: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 13:02:32.063
    Nov 12 13:02:32.079: INFO: Waiting for pod pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46 to disappear
    Nov 12 13:02:32.084: INFO: Pod pod-secrets-20f24efe-68f2-4a79-9a22-123516eb4e46 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 13:02:32.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4783" for this suite. 11/12/22 13:02:32.09
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:02:32.1
Nov 12 13:02:32.100: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:02:32.1
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:32.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:32.145
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-7919 11/12/22 13:02:32.148
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[] 11/12/22 13:02:32.171
Nov 12 13:02:32.179: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Nov 12 13:02:33.191: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-7919 11/12/22 13:02:33.191
Nov 12 13:02:33.206: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7919" to be "running and ready"
Nov 12 13:02:33.224: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.107433ms
Nov 12 13:02:33.224: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:02:35.230: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024469207s
Nov 12 13:02:35.230: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 12 13:02:35.230: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[pod1:[80]] 11/12/22 13:02:35.235
Nov 12 13:02:35.251: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 11/12/22 13:02:35.251
Nov 12 13:02:35.251: INFO: Creating new exec pod
Nov 12 13:02:35.259: INFO: Waiting up to 5m0s for pod "execpodl8j4s" in namespace "services-7919" to be "running"
Nov 12 13:02:35.267: INFO: Pod "execpodl8j4s": Phase="Pending", Reason="", readiness=false. Elapsed: 8.225771ms
Nov 12 13:02:37.272: INFO: Pod "execpodl8j4s": Phase="Running", Reason="", readiness=true. Elapsed: 2.013325541s
Nov 12 13:02:37.272: INFO: Pod "execpodl8j4s" satisfied condition "running"
Nov 12 13:02:38.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 12 13:02:38.469: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 12 13:02:38.469: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 13:02:38.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
Nov 12 13:02:38.628: INFO: stderr: "+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Nov 12 13:02:38.628: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-7919 11/12/22 13:02:38.628
Nov 12 13:02:38.638: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7919" to be "running and ready"
Nov 12 13:02:38.645: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.985055ms
Nov 12 13:02:38.645: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:02:40.651: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012601917s
Nov 12 13:02:40.651: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 12 13:02:40.651: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[pod1:[80] pod2:[80]] 11/12/22 13:02:40.656
Nov 12 13:02:40.674: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 11/12/22 13:02:40.674
Nov 12 13:02:41.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 12 13:02:41.872: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 12 13:02:41.872: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 13:02:41.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
Nov 12 13:02:42.052: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
Nov 12 13:02:42.052: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-7919 11/12/22 13:02:42.052
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[pod2:[80]] 11/12/22 13:02:42.075
Nov 12 13:02:42.100: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 11/12/22 13:02:42.1
Nov 12 13:02:43.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 12 13:02:43.285: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 12 13:02:43.285: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 13:02:43.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
Nov 12 13:02:43.465: INFO: stderr: "+ + echonc hostName\n -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
Nov 12 13:02:43.465: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-7919 11/12/22 13:02:43.465
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[] 11/12/22 13:02:43.489
Nov 12 13:02:43.507: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:02:43.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7919" for this suite. 11/12/22 13:02:43.547
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":243,"skipped":4454,"failed":0}
------------------------------
• [SLOW TEST] [11.460 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:02:32.1
    Nov 12 13:02:32.100: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:02:32.1
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:32.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:32.145
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-7919 11/12/22 13:02:32.148
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[] 11/12/22 13:02:32.171
    Nov 12 13:02:32.179: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Nov 12 13:02:33.191: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-7919 11/12/22 13:02:33.191
    Nov 12 13:02:33.206: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7919" to be "running and ready"
    Nov 12 13:02:33.224: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.107433ms
    Nov 12 13:02:33.224: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:02:35.230: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.024469207s
    Nov 12 13:02:35.230: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 12 13:02:35.230: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[pod1:[80]] 11/12/22 13:02:35.235
    Nov 12 13:02:35.251: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 11/12/22 13:02:35.251
    Nov 12 13:02:35.251: INFO: Creating new exec pod
    Nov 12 13:02:35.259: INFO: Waiting up to 5m0s for pod "execpodl8j4s" in namespace "services-7919" to be "running"
    Nov 12 13:02:35.267: INFO: Pod "execpodl8j4s": Phase="Pending", Reason="", readiness=false. Elapsed: 8.225771ms
    Nov 12 13:02:37.272: INFO: Pod "execpodl8j4s": Phase="Running", Reason="", readiness=true. Elapsed: 2.013325541s
    Nov 12 13:02:37.272: INFO: Pod "execpodl8j4s" satisfied condition "running"
    Nov 12 13:02:38.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 12 13:02:38.469: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 12 13:02:38.469: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 13:02:38.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
    Nov 12 13:02:38.628: INFO: stderr: "+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Nov 12 13:02:38.628: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-7919 11/12/22 13:02:38.628
    Nov 12 13:02:38.638: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7919" to be "running and ready"
    Nov 12 13:02:38.645: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.985055ms
    Nov 12 13:02:38.645: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:02:40.651: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012601917s
    Nov 12 13:02:40.651: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 12 13:02:40.651: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[pod1:[80] pod2:[80]] 11/12/22 13:02:40.656
    Nov 12 13:02:40.674: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 11/12/22 13:02:40.674
    Nov 12 13:02:41.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 12 13:02:41.872: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 12 13:02:41.872: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 13:02:41.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
    Nov 12 13:02:42.052: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
    Nov 12 13:02:42.052: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-7919 11/12/22 13:02:42.052
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[pod2:[80]] 11/12/22 13:02:42.075
    Nov 12 13:02:42.100: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 11/12/22 13:02:42.1
    Nov 12 13:02:43.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 12 13:02:43.285: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 12 13:02:43.285: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 13:02:43.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-7919 exec execpodl8j4s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.45 80'
    Nov 12 13:02:43.465: INFO: stderr: "+ + echonc hostName\n -v -t -w 2 10.152.183.45 80\nConnection to 10.152.183.45 80 port [tcp/http] succeeded!\n"
    Nov 12 13:02:43.465: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-7919 11/12/22 13:02:43.465
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7919 to expose endpoints map[] 11/12/22 13:02:43.489
    Nov 12 13:02:43.507: INFO: successfully validated that service endpoint-test2 in namespace services-7919 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:02:43.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7919" for this suite. 11/12/22 13:02:43.547
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:02:43.561
Nov 12 13:02:43.561: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-pred 11/12/22 13:02:43.562
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:43.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:43.586
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 12 13:02:43.592: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 12 13:02:43.603: INFO: Waiting for terminating namespaces to be deleted...
Nov 12 13:02:43.609: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
Nov 12 13:02:43.616: INFO: nginx-ingress-controller-kubernetes-worker-vpz52 from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:20 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.616: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:02:43.616: INFO: execpodl8j4s from services-7919 started at 2022-11-12 13:02:35 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.616: INFO: 	Container agnhost-container ready: true, restart count 0
Nov 12 13:02:43.616: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.616: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 12 13:02:43.616: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:02:43.616: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:02:43.616: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 13:02:43.616: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
Nov 12 13:02:43.623: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 12 13:02:43.623: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:02:43.623: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 12 13:02:43.623: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container coredns ready: true, restart count 0
Nov 12 13:02:43.623: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 12 13:02:43.623: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container metrics-server ready: true, restart count 0
Nov 12 13:02:43.623: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 12 13:02:43.623: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 12 13:02:43.623: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 12 13:02:43.623: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:02:43.623: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:02:43.623: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 13:02:43.623: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
Nov 12 13:02:43.630: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
Nov 12 13:02:43.630: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:02:43.631: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:02:43.631: INFO: 	Container e2e ready: true, restart count 0
Nov 12 13:02:43.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:02:43.631: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:02:43.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:02:43.631: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 13:02:43.631
Nov 12 13:02:43.648: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5288" to be "running"
Nov 12 13:02:43.656: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.82705ms
Nov 12 13:02:45.662: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.013867942s
Nov 12 13:02:45.662: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 13:02:45.667
STEP: Trying to apply a random label on the found node. 11/12/22 13:02:45.687
STEP: verifying the node has the label kubernetes.io/e2e-8d26b460-2ff0-4590-b17c-4acc926f0ed3 42 11/12/22 13:02:45.699
STEP: Trying to relaunch the pod, now with labels. 11/12/22 13:02:45.704
Nov 12 13:02:45.718: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5288" to be "not pending"
Nov 12 13:02:45.724: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 6.343989ms
Nov 12 13:02:47.730: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.01205261s
Nov 12 13:02:47.730: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-8d26b460-2ff0-4590-b17c-4acc926f0ed3 off the node ip-172-31-14-110 11/12/22 13:02:47.734
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8d26b460-2ff0-4590-b17c-4acc926f0ed3 11/12/22 13:02:47.749
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:02:47.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5288" for this suite. 11/12/22 13:02:47.762
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":244,"skipped":4472,"failed":0}
------------------------------
• [4.214 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:02:43.561
    Nov 12 13:02:43.561: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-pred 11/12/22 13:02:43.562
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:43.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:43.586
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 12 13:02:43.592: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 12 13:02:43.603: INFO: Waiting for terminating namespaces to be deleted...
    Nov 12 13:02:43.609: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
    Nov 12 13:02:43.616: INFO: nginx-ingress-controller-kubernetes-worker-vpz52 from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:20 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.616: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:02:43.616: INFO: execpodl8j4s from services-7919 started at 2022-11-12 13:02:35 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.616: INFO: 	Container agnhost-container ready: true, restart count 0
    Nov 12 13:02:43.616: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.616: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 12 13:02:43.616: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:02:43.616: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:02:43.616: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 13:02:43.616: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
    Nov 12 13:02:43.623: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container coredns ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:02:43.623: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 13:02:43.623: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
    Nov 12 13:02:43.630: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
    Nov 12 13:02:43.630: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:02:43.631: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:02:43.631: INFO: 	Container e2e ready: true, restart count 0
    Nov 12 13:02:43.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:02:43.631: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:02:43.631: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:02:43.631: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 13:02:43.631
    Nov 12 13:02:43.648: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-5288" to be "running"
    Nov 12 13:02:43.656: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.82705ms
    Nov 12 13:02:45.662: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.013867942s
    Nov 12 13:02:45.662: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 13:02:45.667
    STEP: Trying to apply a random label on the found node. 11/12/22 13:02:45.687
    STEP: verifying the node has the label kubernetes.io/e2e-8d26b460-2ff0-4590-b17c-4acc926f0ed3 42 11/12/22 13:02:45.699
    STEP: Trying to relaunch the pod, now with labels. 11/12/22 13:02:45.704
    Nov 12 13:02:45.718: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-5288" to be "not pending"
    Nov 12 13:02:45.724: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 6.343989ms
    Nov 12 13:02:47.730: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.01205261s
    Nov 12 13:02:47.730: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-8d26b460-2ff0-4590-b17c-4acc926f0ed3 off the node ip-172-31-14-110 11/12/22 13:02:47.734
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-8d26b460-2ff0-4590-b17c-4acc926f0ed3 11/12/22 13:02:47.749
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:02:47.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5288" for this suite. 11/12/22 13:02:47.762
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:02:47.78
Nov 12 13:02:47.780: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename taint-multiple-pods 11/12/22 13:02:47.781
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:47.8
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:47.804
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Nov 12 13:02:47.806: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 13:03:47.827: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Nov 12 13:03:47.832: INFO: Starting informer...
STEP: Starting pods... 11/12/22 13:03:47.832
Nov 12 13:03:48.061: INFO: Pod1 is running on ip-172-31-14-110. Tainting Node
Nov 12 13:03:48.275: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4439" to be "running"
Nov 12 13:03:48.279: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038168ms
Nov 12 13:03:50.287: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011658069s
Nov 12 13:03:50.287: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Nov 12 13:03:50.287: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4439" to be "running"
Nov 12 13:03:50.291: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 3.936862ms
Nov 12 13:03:50.291: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Nov 12 13:03:50.291: INFO: Pod2 is running on ip-172-31-14-110. Tainting Node
STEP: Trying to apply a taint on the Node 11/12/22 13:03:50.291
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:03:50.309
STEP: Waiting for Pod1 and Pod2 to be deleted 11/12/22 13:03:50.315
Nov 12 13:03:56.162: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov 12 13:04:15.906: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:04:15.921
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:04:15.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4439" for this suite. 11/12/22 13:04:15.931
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":245,"skipped":4530,"failed":0}
------------------------------
• [SLOW TEST] [88.183 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:02:47.78
    Nov 12 13:02:47.780: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename taint-multiple-pods 11/12/22 13:02:47.781
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:02:47.8
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:02:47.804
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Nov 12 13:02:47.806: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 13:03:47.827: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Nov 12 13:03:47.832: INFO: Starting informer...
    STEP: Starting pods... 11/12/22 13:03:47.832
    Nov 12 13:03:48.061: INFO: Pod1 is running on ip-172-31-14-110. Tainting Node
    Nov 12 13:03:48.275: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4439" to be "running"
    Nov 12 13:03:48.279: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038168ms
    Nov 12 13:03:50.287: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011658069s
    Nov 12 13:03:50.287: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Nov 12 13:03:50.287: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4439" to be "running"
    Nov 12 13:03:50.291: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 3.936862ms
    Nov 12 13:03:50.291: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Nov 12 13:03:50.291: INFO: Pod2 is running on ip-172-31-14-110. Tainting Node
    STEP: Trying to apply a taint on the Node 11/12/22 13:03:50.291
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:03:50.309
    STEP: Waiting for Pod1 and Pod2 to be deleted 11/12/22 13:03:50.315
    Nov 12 13:03:56.162: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Nov 12 13:04:15.906: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:04:15.921
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:04:15.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-4439" for this suite. 11/12/22 13:04:15.931
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:15.965
Nov 12 13:04:15.965: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:04:15.966
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:16.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:16.014
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:04:16.017
Nov 12 13:04:16.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb" in namespace "projected-9827" to be "Succeeded or Failed"
Nov 12 13:04:16.046: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.403063ms
Nov 12 13:04:18.052: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb": Phase="Running", Reason="", readiness=false. Elapsed: 2.014639696s
Nov 12 13:04:20.052: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014998352s
STEP: Saw pod success 11/12/22 13:04:20.052
Nov 12 13:04:20.052: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb" satisfied condition "Succeeded or Failed"
Nov 12 13:04:20.056: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb container client-container: <nil>
STEP: delete the pod 11/12/22 13:04:20.072
Nov 12 13:04:20.088: INFO: Waiting for pod downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb to disappear
Nov 12 13:04:20.093: INFO: Pod downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 13:04:20.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9827" for this suite. 11/12/22 13:04:20.098
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":246,"skipped":4541,"failed":0}
------------------------------
• [4.143 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:15.965
    Nov 12 13:04:15.965: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:04:15.966
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:16.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:16.014
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:04:16.017
    Nov 12 13:04:16.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb" in namespace "projected-9827" to be "Succeeded or Failed"
    Nov 12 13:04:16.046: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.403063ms
    Nov 12 13:04:18.052: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb": Phase="Running", Reason="", readiness=false. Elapsed: 2.014639696s
    Nov 12 13:04:20.052: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014998352s
    STEP: Saw pod success 11/12/22 13:04:20.052
    Nov 12 13:04:20.052: INFO: Pod "downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb" satisfied condition "Succeeded or Failed"
    Nov 12 13:04:20.056: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb container client-container: <nil>
    STEP: delete the pod 11/12/22 13:04:20.072
    Nov 12 13:04:20.088: INFO: Waiting for pod downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb to disappear
    Nov 12 13:04:20.093: INFO: Pod downwardapi-volume-916a7806-7bef-40b9-80e6-31d3010a97cb no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 13:04:20.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9827" for this suite. 11/12/22 13:04:20.098
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:20.109
Nov 12 13:04:20.109: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:04:20.11
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:20.129
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:20.133
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:04:20.138
Nov 12 13:04:20.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2" in namespace "downward-api-8345" to be "Succeeded or Failed"
Nov 12 13:04:20.170: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.708943ms
Nov 12 13:04:22.176: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018954148s
Nov 12 13:04:24.176: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018858944s
STEP: Saw pod success 11/12/22 13:04:24.176
Nov 12 13:04:24.176: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2" satisfied condition "Succeeded or Failed"
Nov 12 13:04:24.182: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2 container client-container: <nil>
STEP: delete the pod 11/12/22 13:04:24.189
Nov 12 13:04:24.206: INFO: Waiting for pod downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2 to disappear
Nov 12 13:04:24.210: INFO: Pod downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:04:24.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8345" for this suite. 11/12/22 13:04:24.215
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":247,"skipped":4549,"failed":0}
------------------------------
• [4.115 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:20.109
    Nov 12 13:04:20.109: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:04:20.11
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:20.129
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:20.133
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:04:20.138
    Nov 12 13:04:20.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2" in namespace "downward-api-8345" to be "Succeeded or Failed"
    Nov 12 13:04:20.170: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.708943ms
    Nov 12 13:04:22.176: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018954148s
    Nov 12 13:04:24.176: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018858944s
    STEP: Saw pod success 11/12/22 13:04:24.176
    Nov 12 13:04:24.176: INFO: Pod "downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2" satisfied condition "Succeeded or Failed"
    Nov 12 13:04:24.182: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2 container client-container: <nil>
    STEP: delete the pod 11/12/22 13:04:24.189
    Nov 12 13:04:24.206: INFO: Waiting for pod downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2 to disappear
    Nov 12 13:04:24.210: INFO: Pod downwardapi-volume-0779364f-4876-49d0-9497-80fbe4172ee2 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:04:24.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8345" for this suite. 11/12/22 13:04:24.215
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:24.227
Nov 12 13:04:24.227: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 13:04:24.228
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:24.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:24.247
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-5d6a6823-bd71-439a-b596-a38bb75bccde 11/12/22 13:04:24.25
STEP: Creating a pod to test consume secrets 11/12/22 13:04:24.256
Nov 12 13:04:24.272: INFO: Waiting up to 5m0s for pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba" in namespace "secrets-9607" to be "Succeeded or Failed"
Nov 12 13:04:24.276: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba": Phase="Pending", Reason="", readiness=false. Elapsed: 3.862208ms
Nov 12 13:04:26.282: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010071053s
Nov 12 13:04:28.282: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009757574s
STEP: Saw pod success 11/12/22 13:04:28.282
Nov 12 13:04:28.282: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba" satisfied condition "Succeeded or Failed"
Nov 12 13:04:28.287: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 13:04:28.295
Nov 12 13:04:28.312: INFO: Waiting for pod pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba to disappear
Nov 12 13:04:28.318: INFO: Pod pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 13:04:28.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9607" for this suite. 11/12/22 13:04:28.323
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":248,"skipped":4576,"failed":0}
------------------------------
• [4.106 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:24.227
    Nov 12 13:04:24.227: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 13:04:24.228
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:24.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:24.247
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-5d6a6823-bd71-439a-b596-a38bb75bccde 11/12/22 13:04:24.25
    STEP: Creating a pod to test consume secrets 11/12/22 13:04:24.256
    Nov 12 13:04:24.272: INFO: Waiting up to 5m0s for pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba" in namespace "secrets-9607" to be "Succeeded or Failed"
    Nov 12 13:04:24.276: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba": Phase="Pending", Reason="", readiness=false. Elapsed: 3.862208ms
    Nov 12 13:04:26.282: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010071053s
    Nov 12 13:04:28.282: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009757574s
    STEP: Saw pod success 11/12/22 13:04:28.282
    Nov 12 13:04:28.282: INFO: Pod "pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba" satisfied condition "Succeeded or Failed"
    Nov 12 13:04:28.287: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 13:04:28.295
    Nov 12 13:04:28.312: INFO: Waiting for pod pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba to disappear
    Nov 12 13:04:28.318: INFO: Pod pod-secrets-85716e9e-207f-4f93-81ee-937df8dc8eba no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 13:04:28.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9607" for this suite. 11/12/22 13:04:28.323
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:28.335
Nov 12 13:04:28.335: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename containers 11/12/22 13:04:28.336
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:28.36
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:28.364
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 11/12/22 13:04:28.371
Nov 12 13:04:28.388: INFO: Waiting up to 5m0s for pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841" in namespace "containers-7256" to be "Succeeded or Failed"
Nov 12 13:04:28.399: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841": Phase="Pending", Reason="", readiness=false. Elapsed: 10.576474ms
Nov 12 13:04:30.406: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017562257s
Nov 12 13:04:32.405: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016768382s
STEP: Saw pod success 11/12/22 13:04:32.405
Nov 12 13:04:32.406: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841" satisfied condition "Succeeded or Failed"
Nov 12 13:04:32.410: INFO: Trying to get logs from node ip-172-31-14-110 pod client-containers-5e120225-54fa-4585-acaa-1d56a86ee841 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:04:32.42
Nov 12 13:04:32.435: INFO: Waiting for pod client-containers-5e120225-54fa-4585-acaa-1d56a86ee841 to disappear
Nov 12 13:04:32.439: INFO: Pod client-containers-5e120225-54fa-4585-acaa-1d56a86ee841 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 12 13:04:32.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7256" for this suite. 11/12/22 13:04:32.444
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":249,"skipped":4595,"failed":0}
------------------------------
• [4.116 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:28.335
    Nov 12 13:04:28.335: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename containers 11/12/22 13:04:28.336
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:28.36
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:28.364
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 11/12/22 13:04:28.371
    Nov 12 13:04:28.388: INFO: Waiting up to 5m0s for pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841" in namespace "containers-7256" to be "Succeeded or Failed"
    Nov 12 13:04:28.399: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841": Phase="Pending", Reason="", readiness=false. Elapsed: 10.576474ms
    Nov 12 13:04:30.406: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017562257s
    Nov 12 13:04:32.405: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016768382s
    STEP: Saw pod success 11/12/22 13:04:32.405
    Nov 12 13:04:32.406: INFO: Pod "client-containers-5e120225-54fa-4585-acaa-1d56a86ee841" satisfied condition "Succeeded or Failed"
    Nov 12 13:04:32.410: INFO: Trying to get logs from node ip-172-31-14-110 pod client-containers-5e120225-54fa-4585-acaa-1d56a86ee841 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:04:32.42
    Nov 12 13:04:32.435: INFO: Waiting for pod client-containers-5e120225-54fa-4585-acaa-1d56a86ee841 to disappear
    Nov 12 13:04:32.439: INFO: Pod client-containers-5e120225-54fa-4585-acaa-1d56a86ee841 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 12 13:04:32.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7256" for this suite. 11/12/22 13:04:32.444
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:32.457
Nov 12 13:04:32.457: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 13:04:32.458
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:32.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:32.481
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 11/12/22 13:04:32.488
STEP: Getting a ResourceQuota 11/12/22 13:04:32.497
STEP: Listing all ResourceQuotas with LabelSelector 11/12/22 13:04:32.5
STEP: Patching the ResourceQuota 11/12/22 13:04:32.507
STEP: Deleting a Collection of ResourceQuotas 11/12/22 13:04:32.518
STEP: Verifying the deleted ResourceQuota 11/12/22 13:04:32.53
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 13:04:32.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4617" for this suite. 11/12/22 13:04:32.54
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":250,"skipped":4642,"failed":0}
------------------------------
• [0.093 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:32.457
    Nov 12 13:04:32.457: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 13:04:32.458
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:32.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:32.481
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 11/12/22 13:04:32.488
    STEP: Getting a ResourceQuota 11/12/22 13:04:32.497
    STEP: Listing all ResourceQuotas with LabelSelector 11/12/22 13:04:32.5
    STEP: Patching the ResourceQuota 11/12/22 13:04:32.507
    STEP: Deleting a Collection of ResourceQuotas 11/12/22 13:04:32.518
    STEP: Verifying the deleted ResourceQuota 11/12/22 13:04:32.53
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 13:04:32.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4617" for this suite. 11/12/22 13:04:32.54
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:32.555
Nov 12 13:04:32.555: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 13:04:32.556
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:32.579
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:32.582
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 13:04:32.588
Nov 12 13:04:32.599: INFO: Waiting up to 5m0s for pod "pod-c391f05d-5a33-4680-864f-85f079546750" in namespace "emptydir-3673" to be "Succeeded or Failed"
Nov 12 13:04:32.606: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750": Phase="Pending", Reason="", readiness=false. Elapsed: 7.211873ms
Nov 12 13:04:34.612: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013388482s
Nov 12 13:04:36.613: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01433844s
STEP: Saw pod success 11/12/22 13:04:36.613
Nov 12 13:04:36.613: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750" satisfied condition "Succeeded or Failed"
Nov 12 13:04:36.617: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-c391f05d-5a33-4680-864f-85f079546750 container test-container: <nil>
STEP: delete the pod 11/12/22 13:04:36.626
Nov 12 13:04:36.652: INFO: Waiting for pod pod-c391f05d-5a33-4680-864f-85f079546750 to disappear
Nov 12 13:04:36.658: INFO: Pod pod-c391f05d-5a33-4680-864f-85f079546750 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 13:04:36.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3673" for this suite. 11/12/22 13:04:36.666
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":251,"skipped":4702,"failed":0}
------------------------------
• [4.120 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:32.555
    Nov 12 13:04:32.555: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 13:04:32.556
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:32.579
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:32.582
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/12/22 13:04:32.588
    Nov 12 13:04:32.599: INFO: Waiting up to 5m0s for pod "pod-c391f05d-5a33-4680-864f-85f079546750" in namespace "emptydir-3673" to be "Succeeded or Failed"
    Nov 12 13:04:32.606: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750": Phase="Pending", Reason="", readiness=false. Elapsed: 7.211873ms
    Nov 12 13:04:34.612: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013388482s
    Nov 12 13:04:36.613: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01433844s
    STEP: Saw pod success 11/12/22 13:04:36.613
    Nov 12 13:04:36.613: INFO: Pod "pod-c391f05d-5a33-4680-864f-85f079546750" satisfied condition "Succeeded or Failed"
    Nov 12 13:04:36.617: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-c391f05d-5a33-4680-864f-85f079546750 container test-container: <nil>
    STEP: delete the pod 11/12/22 13:04:36.626
    Nov 12 13:04:36.652: INFO: Waiting for pod pod-c391f05d-5a33-4680-864f-85f079546750 to disappear
    Nov 12 13:04:36.658: INFO: Pod pod-c391f05d-5a33-4680-864f-85f079546750 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 13:04:36.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3673" for this suite. 11/12/22 13:04:36.666
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:36.676
Nov 12 13:04:36.676: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename containers 11/12/22 13:04:36.677
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:36.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:36.706
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Nov 12 13:04:36.719: INFO: Waiting up to 5m0s for pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02" in namespace "containers-4703" to be "running"
Nov 12 13:04:36.726: INFO: Pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02": Phase="Pending", Reason="", readiness=false. Elapsed: 6.695697ms
Nov 12 13:04:38.732: INFO: Pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02": Phase="Running", Reason="", readiness=true. Elapsed: 2.012101077s
Nov 12 13:04:38.732: INFO: Pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 12 13:04:38.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4703" for this suite. 11/12/22 13:04:38.746
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":252,"skipped":4702,"failed":0}
------------------------------
• [2.081 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:36.676
    Nov 12 13:04:36.676: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename containers 11/12/22 13:04:36.677
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:36.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:36.706
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Nov 12 13:04:36.719: INFO: Waiting up to 5m0s for pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02" in namespace "containers-4703" to be "running"
    Nov 12 13:04:36.726: INFO: Pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02": Phase="Pending", Reason="", readiness=false. Elapsed: 6.695697ms
    Nov 12 13:04:38.732: INFO: Pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02": Phase="Running", Reason="", readiness=true. Elapsed: 2.012101077s
    Nov 12 13:04:38.732: INFO: Pod "client-containers-75059fed-da65-4887-ba08-0e813b4a5f02" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 12 13:04:38.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4703" for this suite. 11/12/22 13:04:38.746
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:38.759
Nov 12 13:04:38.759: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:04:38.76
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:38.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:38.783
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-fcbdb4cf-6ef8-4597-813b-919f9b57cb39 11/12/22 13:04:38.785
STEP: Creating a pod to test consume secrets 11/12/22 13:04:38.793
Nov 12 13:04:38.802: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082" in namespace "projected-1741" to be "Succeeded or Failed"
Nov 12 13:04:38.810: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082": Phase="Pending", Reason="", readiness=false. Elapsed: 8.603903ms
Nov 12 13:04:40.817: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014989365s
Nov 12 13:04:42.816: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014257184s
STEP: Saw pod success 11/12/22 13:04:42.816
Nov 12 13:04:42.816: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082" satisfied condition "Succeeded or Failed"
Nov 12 13:04:42.821: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/12/22 13:04:42.83
Nov 12 13:04:42.846: INFO: Waiting for pod pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082 to disappear
Nov 12 13:04:42.850: INFO: Pod pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 13:04:42.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1741" for this suite. 11/12/22 13:04:42.856
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":253,"skipped":4719,"failed":0}
------------------------------
• [4.105 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:38.759
    Nov 12 13:04:38.759: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:04:38.76
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:38.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:38.783
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-fcbdb4cf-6ef8-4597-813b-919f9b57cb39 11/12/22 13:04:38.785
    STEP: Creating a pod to test consume secrets 11/12/22 13:04:38.793
    Nov 12 13:04:38.802: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082" in namespace "projected-1741" to be "Succeeded or Failed"
    Nov 12 13:04:38.810: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082": Phase="Pending", Reason="", readiness=false. Elapsed: 8.603903ms
    Nov 12 13:04:40.817: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014989365s
    Nov 12 13:04:42.816: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014257184s
    STEP: Saw pod success 11/12/22 13:04:42.816
    Nov 12 13:04:42.816: INFO: Pod "pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082" satisfied condition "Succeeded or Failed"
    Nov 12 13:04:42.821: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 13:04:42.83
    Nov 12 13:04:42.846: INFO: Waiting for pod pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082 to disappear
    Nov 12 13:04:42.850: INFO: Pod pod-projected-secrets-16f91a5f-88c3-4811-8dbf-90be7eaac082 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 13:04:42.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1741" for this suite. 11/12/22 13:04:42.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:04:42.867
Nov 12 13:04:42.867: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 13:04:42.868
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:42.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:42.894
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 11/12/22 13:04:42.897
Nov 12 13:04:42.911: INFO: Waiting up to 2m0s for pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" in namespace "var-expansion-5134" to be "running"
Nov 12 13:04:42.916: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.518967ms
Nov 12 13:04:44.920: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008893729s
Nov 12 13:04:46.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010745247s
Nov 12 13:04:48.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010086579s
Nov 12 13:04:50.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012408298s
Nov 12 13:04:52.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01096371s
Nov 12 13:04:54.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009923105s
Nov 12 13:04:56.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.010829847s
Nov 12 13:04:58.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012113462s
Nov 12 13:05:00.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.010740468s
Nov 12 13:05:02.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.012300693s
Nov 12 13:05:04.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.010490371s
Nov 12 13:05:06.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.011438908s
Nov 12 13:05:08.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.011098393s
Nov 12 13:05:10.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 28.012031011s
Nov 12 13:05:12.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 30.011095249s
Nov 12 13:05:14.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 32.010370521s
Nov 12 13:05:16.926: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.01488721s
Nov 12 13:05:18.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 36.009909333s
Nov 12 13:05:20.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011348722s
Nov 12 13:05:22.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 40.012150936s
Nov 12 13:05:24.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011188593s
Nov 12 13:05:26.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 44.011216991s
Nov 12 13:05:28.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 46.012085698s
Nov 12 13:05:30.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 48.010250121s
Nov 12 13:05:32.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 50.011994844s
Nov 12 13:05:34.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 52.010602522s
Nov 12 13:05:36.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 54.010593816s
Nov 12 13:05:38.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 56.011153966s
Nov 12 13:05:40.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 58.009815562s
Nov 12 13:05:42.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.011379615s
Nov 12 13:05:44.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.011260673s
Nov 12 13:05:46.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.012173173s
Nov 12 13:05:48.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.009730022s
Nov 12 13:05:50.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.010847337s
Nov 12 13:05:52.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.013072297s
Nov 12 13:05:54.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009946291s
Nov 12 13:05:56.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.010586447s
Nov 12 13:05:58.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01009833s
Nov 12 13:06:00.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.01108694s
Nov 12 13:06:02.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.010650179s
Nov 12 13:06:04.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.011359346s
Nov 12 13:06:06.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.01107477s
Nov 12 13:06:08.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.013040532s
Nov 12 13:06:10.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010773829s
Nov 12 13:06:12.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.011995135s
Nov 12 13:06:14.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.011845532s
Nov 12 13:06:16.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.012913493s
Nov 12 13:06:18.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.010129717s
Nov 12 13:06:20.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010530051s
Nov 12 13:06:22.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.011826985s
Nov 12 13:06:24.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.011294416s
Nov 12 13:06:26.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.010607412s
Nov 12 13:06:28.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.012010541s
Nov 12 13:06:30.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.009519047s
Nov 12 13:06:32.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.010469384s
Nov 12 13:06:34.926: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.014657655s
Nov 12 13:06:36.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011827871s
Nov 12 13:06:38.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.011183642s
Nov 12 13:06:40.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.010686295s
Nov 12 13:06:42.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.011611972s
Nov 12 13:06:42.928: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.01639603s
STEP: updating the pod 11/12/22 13:06:42.928
Nov 12 13:06:43.446: INFO: Successfully updated pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1"
STEP: waiting for pod running 11/12/22 13:06:43.446
Nov 12 13:06:43.446: INFO: Waiting up to 2m0s for pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" in namespace "var-expansion-5134" to be "running"
Nov 12 13:06:43.555: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 108.709367ms
Nov 12 13:06:45.560: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Running", Reason="", readiness=true. Elapsed: 2.114316841s
Nov 12 13:06:45.560: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" satisfied condition "running"
STEP: deleting the pod gracefully 11/12/22 13:06:45.56
Nov 12 13:06:45.560: INFO: Deleting pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" in namespace "var-expansion-5134"
Nov 12 13:06:45.572: INFO: Wait up to 5m0s for pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 13:07:17.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5134" for this suite. 11/12/22 13:07:17.588
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":254,"skipped":4772,"failed":0}
------------------------------
• [SLOW TEST] [154.731 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:04:42.867
    Nov 12 13:04:42.867: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 13:04:42.868
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:04:42.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:04:42.894
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 11/12/22 13:04:42.897
    Nov 12 13:04:42.911: INFO: Waiting up to 2m0s for pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" in namespace "var-expansion-5134" to be "running"
    Nov 12 13:04:42.916: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.518967ms
    Nov 12 13:04:44.920: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008893729s
    Nov 12 13:04:46.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010745247s
    Nov 12 13:04:48.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010086579s
    Nov 12 13:04:50.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012408298s
    Nov 12 13:04:52.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01096371s
    Nov 12 13:04:54.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009923105s
    Nov 12 13:04:56.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.010829847s
    Nov 12 13:04:58.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012113462s
    Nov 12 13:05:00.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.010740468s
    Nov 12 13:05:02.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.012300693s
    Nov 12 13:05:04.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.010490371s
    Nov 12 13:05:06.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.011438908s
    Nov 12 13:05:08.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.011098393s
    Nov 12 13:05:10.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 28.012031011s
    Nov 12 13:05:12.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 30.011095249s
    Nov 12 13:05:14.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 32.010370521s
    Nov 12 13:05:16.926: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.01488721s
    Nov 12 13:05:18.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 36.009909333s
    Nov 12 13:05:20.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 38.011348722s
    Nov 12 13:05:22.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 40.012150936s
    Nov 12 13:05:24.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011188593s
    Nov 12 13:05:26.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 44.011216991s
    Nov 12 13:05:28.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 46.012085698s
    Nov 12 13:05:30.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 48.010250121s
    Nov 12 13:05:32.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 50.011994844s
    Nov 12 13:05:34.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 52.010602522s
    Nov 12 13:05:36.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 54.010593816s
    Nov 12 13:05:38.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 56.011153966s
    Nov 12 13:05:40.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 58.009815562s
    Nov 12 13:05:42.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.011379615s
    Nov 12 13:05:44.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.011260673s
    Nov 12 13:05:46.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.012173173s
    Nov 12 13:05:48.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.009730022s
    Nov 12 13:05:50.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.010847337s
    Nov 12 13:05:52.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.013072297s
    Nov 12 13:05:54.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.009946291s
    Nov 12 13:05:56.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.010586447s
    Nov 12 13:05:58.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.01009833s
    Nov 12 13:06:00.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.01108694s
    Nov 12 13:06:02.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.010650179s
    Nov 12 13:06:04.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.011359346s
    Nov 12 13:06:06.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.01107477s
    Nov 12 13:06:08.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.013040532s
    Nov 12 13:06:10.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010773829s
    Nov 12 13:06:12.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.011995135s
    Nov 12 13:06:14.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.011845532s
    Nov 12 13:06:16.924: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.012913493s
    Nov 12 13:06:18.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.010129717s
    Nov 12 13:06:20.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010530051s
    Nov 12 13:06:22.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.011826985s
    Nov 12 13:06:24.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.011294416s
    Nov 12 13:06:26.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.010607412s
    Nov 12 13:06:28.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.012010541s
    Nov 12 13:06:30.921: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.009519047s
    Nov 12 13:06:32.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.010469384s
    Nov 12 13:06:34.926: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.014657655s
    Nov 12 13:06:36.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011827871s
    Nov 12 13:06:38.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.011183642s
    Nov 12 13:06:40.922: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.010686295s
    Nov 12 13:06:42.923: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.011611972s
    Nov 12 13:06:42.928: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.01639603s
    STEP: updating the pod 11/12/22 13:06:42.928
    Nov 12 13:06:43.446: INFO: Successfully updated pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1"
    STEP: waiting for pod running 11/12/22 13:06:43.446
    Nov 12 13:06:43.446: INFO: Waiting up to 2m0s for pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" in namespace "var-expansion-5134" to be "running"
    Nov 12 13:06:43.555: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Pending", Reason="", readiness=false. Elapsed: 108.709367ms
    Nov 12 13:06:45.560: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1": Phase="Running", Reason="", readiness=true. Elapsed: 2.114316841s
    Nov 12 13:06:45.560: INFO: Pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" satisfied condition "running"
    STEP: deleting the pod gracefully 11/12/22 13:06:45.56
    Nov 12 13:06:45.560: INFO: Deleting pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" in namespace "var-expansion-5134"
    Nov 12 13:06:45.572: INFO: Wait up to 5m0s for pod "var-expansion-a847c19d-1936-4372-9bc8-111e84c27ff1" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 13:07:17.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-5134" for this suite. 11/12/22 13:07:17.588
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:17.599
Nov 12 13:07:17.599: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 13:07:17.6
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:17.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:17.627
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-e36b53e1-dc48-427e-9e84-ea2d72856172 11/12/22 13:07:17.638
STEP: Creating a pod to test consume configMaps 11/12/22 13:07:17.645
Nov 12 13:07:17.663: INFO: Waiting up to 5m0s for pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874" in namespace "configmap-6729" to be "Succeeded or Failed"
Nov 12 13:07:17.671: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874": Phase="Pending", Reason="", readiness=false. Elapsed: 7.855121ms
Nov 12 13:07:19.676: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013220197s
Nov 12 13:07:21.676: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013269436s
STEP: Saw pod success 11/12/22 13:07:21.676
Nov 12 13:07:21.676: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874" satisfied condition "Succeeded or Failed"
Nov 12 13:07:21.681: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:07:21.705
Nov 12 13:07:21.720: INFO: Waiting for pod pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874 to disappear
Nov 12 13:07:21.731: INFO: Pod pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 13:07:21.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6729" for this suite. 11/12/22 13:07:21.738
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":255,"skipped":4784,"failed":0}
------------------------------
• [4.148 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:17.599
    Nov 12 13:07:17.599: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 13:07:17.6
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:17.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:17.627
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-e36b53e1-dc48-427e-9e84-ea2d72856172 11/12/22 13:07:17.638
    STEP: Creating a pod to test consume configMaps 11/12/22 13:07:17.645
    Nov 12 13:07:17.663: INFO: Waiting up to 5m0s for pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874" in namespace "configmap-6729" to be "Succeeded or Failed"
    Nov 12 13:07:17.671: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874": Phase="Pending", Reason="", readiness=false. Elapsed: 7.855121ms
    Nov 12 13:07:19.676: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013220197s
    Nov 12 13:07:21.676: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013269436s
    STEP: Saw pod success 11/12/22 13:07:21.676
    Nov 12 13:07:21.676: INFO: Pod "pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874" satisfied condition "Succeeded or Failed"
    Nov 12 13:07:21.681: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:07:21.705
    Nov 12 13:07:21.720: INFO: Waiting for pod pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874 to disappear
    Nov 12 13:07:21.731: INFO: Pod pod-configmaps-4d55b91d-8310-42bf-90f9-068074b4c874 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 13:07:21.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6729" for this suite. 11/12/22 13:07:21.738
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:21.749
Nov 12 13:07:21.749: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename cronjob 11/12/22 13:07:21.75
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:21.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:21.772
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 11/12/22 13:07:21.774
STEP: creating 11/12/22 13:07:21.775
STEP: getting 11/12/22 13:07:21.785
STEP: listing 11/12/22 13:07:21.79
STEP: watching 11/12/22 13:07:21.796
Nov 12 13:07:21.796: INFO: starting watch
STEP: cluster-wide listing 11/12/22 13:07:21.797
STEP: cluster-wide watching 11/12/22 13:07:21.802
Nov 12 13:07:21.802: INFO: starting watch
STEP: patching 11/12/22 13:07:21.803
STEP: updating 11/12/22 13:07:21.811
Nov 12 13:07:21.824: INFO: waiting for watch events with expected annotations
Nov 12 13:07:21.824: INFO: saw patched and updated annotations
STEP: patching /status 11/12/22 13:07:21.824
STEP: updating /status 11/12/22 13:07:21.833
STEP: get /status 11/12/22 13:07:21.847
STEP: deleting 11/12/22 13:07:21.851
STEP: deleting a collection 11/12/22 13:07:21.872
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 12 13:07:21.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4449" for this suite. 11/12/22 13:07:21.896
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":256,"skipped":4807,"failed":0}
------------------------------
• [0.156 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:21.749
    Nov 12 13:07:21.749: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename cronjob 11/12/22 13:07:21.75
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:21.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:21.772
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 11/12/22 13:07:21.774
    STEP: creating 11/12/22 13:07:21.775
    STEP: getting 11/12/22 13:07:21.785
    STEP: listing 11/12/22 13:07:21.79
    STEP: watching 11/12/22 13:07:21.796
    Nov 12 13:07:21.796: INFO: starting watch
    STEP: cluster-wide listing 11/12/22 13:07:21.797
    STEP: cluster-wide watching 11/12/22 13:07:21.802
    Nov 12 13:07:21.802: INFO: starting watch
    STEP: patching 11/12/22 13:07:21.803
    STEP: updating 11/12/22 13:07:21.811
    Nov 12 13:07:21.824: INFO: waiting for watch events with expected annotations
    Nov 12 13:07:21.824: INFO: saw patched and updated annotations
    STEP: patching /status 11/12/22 13:07:21.824
    STEP: updating /status 11/12/22 13:07:21.833
    STEP: get /status 11/12/22 13:07:21.847
    STEP: deleting 11/12/22 13:07:21.851
    STEP: deleting a collection 11/12/22 13:07:21.872
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 12 13:07:21.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-4449" for this suite. 11/12/22 13:07:21.896
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:21.914
Nov 12 13:07:21.914: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir-wrapper 11/12/22 13:07:21.917
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:21.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:21.942
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Nov 12 13:07:21.979: INFO: Waiting up to 5m0s for pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11" in namespace "emptydir-wrapper-9249" to be "running and ready"
Nov 12 13:07:21.985: INFO: Pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010719ms
Nov 12 13:07:21.985: INFO: The phase of Pod pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:07:23.991: INFO: Pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11": Phase="Running", Reason="", readiness=true. Elapsed: 2.012369908s
Nov 12 13:07:23.991: INFO: The phase of Pod pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11 is Running (Ready = true)
Nov 12 13:07:23.991: INFO: Pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11" satisfied condition "running and ready"
STEP: Cleaning up the secret 11/12/22 13:07:24.001
STEP: Cleaning up the configmap 11/12/22 13:07:24.011
STEP: Cleaning up the pod 11/12/22 13:07:24.02
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 12 13:07:24.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9249" for this suite. 11/12/22 13:07:24.052
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":257,"skipped":4819,"failed":0}
------------------------------
• [2.148 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:21.914
    Nov 12 13:07:21.914: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir-wrapper 11/12/22 13:07:21.917
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:21.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:21.942
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Nov 12 13:07:21.979: INFO: Waiting up to 5m0s for pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11" in namespace "emptydir-wrapper-9249" to be "running and ready"
    Nov 12 13:07:21.985: INFO: Pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010719ms
    Nov 12 13:07:21.985: INFO: The phase of Pod pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:07:23.991: INFO: Pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11": Phase="Running", Reason="", readiness=true. Elapsed: 2.012369908s
    Nov 12 13:07:23.991: INFO: The phase of Pod pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11 is Running (Ready = true)
    Nov 12 13:07:23.991: INFO: Pod "pod-secrets-2c9b0a63-ff76-49ea-8583-4bf350829c11" satisfied condition "running and ready"
    STEP: Cleaning up the secret 11/12/22 13:07:24.001
    STEP: Cleaning up the configmap 11/12/22 13:07:24.011
    STEP: Cleaning up the pod 11/12/22 13:07:24.02
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 12 13:07:24.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-9249" for this suite. 11/12/22 13:07:24.052
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:24.063
Nov 12 13:07:24.063: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:07:24.064
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:24.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:24.115
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-e60e184f-4bef-4859-8ec5-1532a4759360 11/12/22 13:07:24.128
STEP: Creating a pod to test consume configMaps 11/12/22 13:07:24.138
Nov 12 13:07:24.158: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9" in namespace "projected-438" to be "Succeeded or Failed"
Nov 12 13:07:24.171: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.132358ms
Nov 12 13:07:26.177: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018236661s
Nov 12 13:07:28.178: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01905654s
STEP: Saw pod success 11/12/22 13:07:28.178
Nov 12 13:07:28.178: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9" satisfied condition "Succeeded or Failed"
Nov 12 13:07:28.182: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:07:28.192
Nov 12 13:07:28.213: INFO: Waiting for pod pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9 to disappear
Nov 12 13:07:28.218: INFO: Pod pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 13:07:28.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-438" for this suite. 11/12/22 13:07:28.225
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":258,"skipped":4821,"failed":0}
------------------------------
• [4.172 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:24.063
    Nov 12 13:07:24.063: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:07:24.064
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:24.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:24.115
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-e60e184f-4bef-4859-8ec5-1532a4759360 11/12/22 13:07:24.128
    STEP: Creating a pod to test consume configMaps 11/12/22 13:07:24.138
    Nov 12 13:07:24.158: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9" in namespace "projected-438" to be "Succeeded or Failed"
    Nov 12 13:07:24.171: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.132358ms
    Nov 12 13:07:26.177: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018236661s
    Nov 12 13:07:28.178: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01905654s
    STEP: Saw pod success 11/12/22 13:07:28.178
    Nov 12 13:07:28.178: INFO: Pod "pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9" satisfied condition "Succeeded or Failed"
    Nov 12 13:07:28.182: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:07:28.192
    Nov 12 13:07:28.213: INFO: Waiting for pod pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9 to disappear
    Nov 12 13:07:28.218: INFO: Pod pod-projected-configmaps-4da2dee4-876d-4142-b035-c105b8111be9 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 13:07:28.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-438" for this suite. 11/12/22 13:07:28.225
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:28.237
Nov 12 13:07:28.238: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sysctl 11/12/22 13:07:28.238
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:28.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:28.262
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/12/22 13:07:28.265
STEP: Watching for error events or started pod 11/12/22 13:07:28.277
STEP: Waiting for pod completion 11/12/22 13:07:30.284
Nov 12 13:07:30.284: INFO: Waiting up to 3m0s for pod "sysctl-76126599-9920-41dd-a1f8-18274f682506" in namespace "sysctl-9246" to be "completed"
Nov 12 13:07:30.289: INFO: Pod "sysctl-76126599-9920-41dd-a1f8-18274f682506": Phase="Pending", Reason="", readiness=false. Elapsed: 5.196384ms
Nov 12 13:07:32.296: INFO: Pod "sysctl-76126599-9920-41dd-a1f8-18274f682506": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011499273s
Nov 12 13:07:32.296: INFO: Pod "sysctl-76126599-9920-41dd-a1f8-18274f682506" satisfied condition "completed"
STEP: Checking that the pod succeeded 11/12/22 13:07:32.3
STEP: Getting logs from the pod 11/12/22 13:07:32.3
STEP: Checking that the sysctl is actually updated 11/12/22 13:07:32.31
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 13:07:32.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-9246" for this suite. 11/12/22 13:07:32.314
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":259,"skipped":4836,"failed":0}
------------------------------
• [4.086 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:28.237
    Nov 12 13:07:28.238: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sysctl 11/12/22 13:07:28.238
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:28.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:28.262
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/12/22 13:07:28.265
    STEP: Watching for error events or started pod 11/12/22 13:07:28.277
    STEP: Waiting for pod completion 11/12/22 13:07:30.284
    Nov 12 13:07:30.284: INFO: Waiting up to 3m0s for pod "sysctl-76126599-9920-41dd-a1f8-18274f682506" in namespace "sysctl-9246" to be "completed"
    Nov 12 13:07:30.289: INFO: Pod "sysctl-76126599-9920-41dd-a1f8-18274f682506": Phase="Pending", Reason="", readiness=false. Elapsed: 5.196384ms
    Nov 12 13:07:32.296: INFO: Pod "sysctl-76126599-9920-41dd-a1f8-18274f682506": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011499273s
    Nov 12 13:07:32.296: INFO: Pod "sysctl-76126599-9920-41dd-a1f8-18274f682506" satisfied condition "completed"
    STEP: Checking that the pod succeeded 11/12/22 13:07:32.3
    STEP: Getting logs from the pod 11/12/22 13:07:32.3
    STEP: Checking that the sysctl is actually updated 11/12/22 13:07:32.31
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 13:07:32.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-9246" for this suite. 11/12/22 13:07:32.314
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:32.33
Nov 12 13:07:32.331: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 13:07:32.332
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:32.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:32.36
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-b05d9094-4064-41bb-be51-353f87b72002 11/12/22 13:07:32.362
STEP: Creating a pod to test consume configMaps 11/12/22 13:07:32.375
Nov 12 13:07:32.388: INFO: Waiting up to 5m0s for pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870" in namespace "configmap-7001" to be "Succeeded or Failed"
Nov 12 13:07:32.405: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Pending", Reason="", readiness=false. Elapsed: 16.325202ms
Nov 12 13:07:34.411: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022814099s
Nov 12 13:07:36.411: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022339897s
Nov 12 13:07:38.413: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025035802s
STEP: Saw pod success 11/12/22 13:07:38.414
Nov 12 13:07:38.414: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870" satisfied condition "Succeeded or Failed"
Nov 12 13:07:38.418: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:07:38.435
Nov 12 13:07:38.454: INFO: Waiting for pod pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870 to disappear
Nov 12 13:07:38.459: INFO: Pod pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 13:07:38.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7001" for this suite. 11/12/22 13:07:38.464
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":260,"skipped":4874,"failed":0}
------------------------------
• [SLOW TEST] [6.143 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:32.33
    Nov 12 13:07:32.331: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 13:07:32.332
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:32.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:32.36
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-b05d9094-4064-41bb-be51-353f87b72002 11/12/22 13:07:32.362
    STEP: Creating a pod to test consume configMaps 11/12/22 13:07:32.375
    Nov 12 13:07:32.388: INFO: Waiting up to 5m0s for pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870" in namespace "configmap-7001" to be "Succeeded or Failed"
    Nov 12 13:07:32.405: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Pending", Reason="", readiness=false. Elapsed: 16.325202ms
    Nov 12 13:07:34.411: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022814099s
    Nov 12 13:07:36.411: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022339897s
    Nov 12 13:07:38.413: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.025035802s
    STEP: Saw pod success 11/12/22 13:07:38.414
    Nov 12 13:07:38.414: INFO: Pod "pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870" satisfied condition "Succeeded or Failed"
    Nov 12 13:07:38.418: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:07:38.435
    Nov 12 13:07:38.454: INFO: Waiting for pod pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870 to disappear
    Nov 12 13:07:38.459: INFO: Pod pod-configmaps-15307ae9-a02e-439d-bdaa-a44046820870 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 13:07:38.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7001" for this suite. 11/12/22 13:07:38.464
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:38.474
Nov 12 13:07:38.474: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename server-version 11/12/22 13:07:38.475
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:38.493
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:38.495
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 11/12/22 13:07:38.498
STEP: Confirm major version 11/12/22 13:07:38.499
Nov 12 13:07:38.499: INFO: Major version: 1
STEP: Confirm minor version 11/12/22 13:07:38.499
Nov 12 13:07:38.499: INFO: cleanMinorVersion: 25
Nov 12 13:07:38.499: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Nov 12 13:07:38.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-2609" for this suite. 11/12/22 13:07:38.503
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":261,"skipped":4882,"failed":0}
------------------------------
• [0.037 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:38.474
    Nov 12 13:07:38.474: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename server-version 11/12/22 13:07:38.475
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:38.493
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:38.495
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 11/12/22 13:07:38.498
    STEP: Confirm major version 11/12/22 13:07:38.499
    Nov 12 13:07:38.499: INFO: Major version: 1
    STEP: Confirm minor version 11/12/22 13:07:38.499
    Nov 12 13:07:38.499: INFO: cleanMinorVersion: 25
    Nov 12 13:07:38.499: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Nov 12 13:07:38.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-2609" for this suite. 11/12/22 13:07:38.503
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:38.513
Nov 12 13:07:38.513: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:07:38.514
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:38.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:38.536
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:07:38.543
Nov 12 13:07:38.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c" in namespace "projected-2355" to be "Succeeded or Failed"
Nov 12 13:07:38.562: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.325127ms
Nov 12 13:07:40.567: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011737031s
Nov 12 13:07:42.567: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011422842s
STEP: Saw pod success 11/12/22 13:07:42.567
Nov 12 13:07:42.567: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c" satisfied condition "Succeeded or Failed"
Nov 12 13:07:42.572: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c container client-container: <nil>
STEP: delete the pod 11/12/22 13:07:42.581
Nov 12 13:07:42.596: INFO: Waiting for pod downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c to disappear
Nov 12 13:07:42.603: INFO: Pod downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 13:07:42.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2355" for this suite. 11/12/22 13:07:42.615
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":262,"skipped":4902,"failed":0}
------------------------------
• [4.113 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:38.513
    Nov 12 13:07:38.513: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:07:38.514
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:38.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:38.536
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:07:38.543
    Nov 12 13:07:38.555: INFO: Waiting up to 5m0s for pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c" in namespace "projected-2355" to be "Succeeded or Failed"
    Nov 12 13:07:38.562: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.325127ms
    Nov 12 13:07:40.567: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011737031s
    Nov 12 13:07:42.567: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011422842s
    STEP: Saw pod success 11/12/22 13:07:42.567
    Nov 12 13:07:42.567: INFO: Pod "downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c" satisfied condition "Succeeded or Failed"
    Nov 12 13:07:42.572: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c container client-container: <nil>
    STEP: delete the pod 11/12/22 13:07:42.581
    Nov 12 13:07:42.596: INFO: Waiting for pod downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c to disappear
    Nov 12 13:07:42.603: INFO: Pod downwardapi-volume-abce8e40-54ec-412e-9734-3ef7d89a3e6c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 13:07:42.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2355" for this suite. 11/12/22 13:07:42.615
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:07:42.626
Nov 12 13:07:42.627: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename init-container 11/12/22 13:07:42.627
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:42.646
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:42.652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 11/12/22 13:07:42.659
Nov 12 13:07:42.659: INFO: PodSpec: initContainers in spec.initContainers
Nov 12 13:08:27.396: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d1596528-e74a-4e8b-80f9-c9604c577e45", GenerateName:"", Namespace:"init-container-1247", SelfLink:"", UID:"7a8deb06-4693-4cb5-8c12-8598ac5e5b50", ResourceVersion:"33180", Generation:0, CreationTimestamp:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"659759757"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00489a1f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 13, 8, 27, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00489a2e8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-hkngl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004892020), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-hkngl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-hkngl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-hkngl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003a140d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-14-110", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00361a000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a14160)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a14180)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003a14188), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003a1418c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000de4070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.14.110", PodIP:"192.168.249.3", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.249.3"}}, StartTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00361a0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00361a150)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://594422bb3de4def5a43bb2c9248e71e7c2847c59f49acb722fcbf96821d2d601", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0048920a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004892080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003a14204)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 13:08:27.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1247" for this suite. 11/12/22 13:08:27.405
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":263,"skipped":4902,"failed":0}
------------------------------
• [SLOW TEST] [44.790 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:07:42.626
    Nov 12 13:07:42.627: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename init-container 11/12/22 13:07:42.627
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:07:42.646
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:07:42.652
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 11/12/22 13:07:42.659
    Nov 12 13:07:42.659: INFO: PodSpec: initContainers in spec.initContainers
    Nov 12 13:08:27.396: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-d1596528-e74a-4e8b-80f9-c9604c577e45", GenerateName:"", Namespace:"init-container-1247", SelfLink:"", UID:"7a8deb06-4693-4cb5-8c12-8598ac5e5b50", ResourceVersion:"33180", Generation:0, CreationTimestamp:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"659759757"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00489a1f8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 12, 13, 8, 27, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00489a2e8), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-hkngl", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004892020), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-hkngl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-hkngl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-hkngl", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003a140d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-14-110", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00361a000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a14160)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a14180)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003a14188), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003a1418c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000de4070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.14.110", PodIP:"192.168.249.3", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.249.3"}}, StartTime:time.Date(2022, time.November, 12, 13, 7, 42, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00361a0e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00361a150)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://594422bb3de4def5a43bb2c9248e71e7c2847c59f49acb722fcbf96821d2d601", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0048920a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004892080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc003a14204)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 13:08:27.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1247" for this suite. 11/12/22 13:08:27.405
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:27.42
Nov 12 13:08:27.420: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 13:08:27.421
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:27.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:27.452
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 13:08:27.455
Nov 12 13:08:27.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 12 13:08:27.544: INFO: stderr: ""
Nov 12 13:08:27.544: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 11/12/22 13:08:27.544
STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 13:08:32.595
Nov 12 13:08:32.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 get pod e2e-test-httpd-pod -o json'
Nov 12 13:08:32.676: INFO: stderr: ""
Nov 12 13:08:32.676: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-11-12T13:08:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4760\",\n        \"resourceVersion\": \"33200\",\n        \"uid\": \"49db5a32-f2cc-4fe4-9dca-41f2daed00d1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-n4cbq\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-89-190\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-n4cbq\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://0acea914c67ea8daa285b1632310cc9e3d15afe51560ef252d5af55b3c662593\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-12T13:08:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.89.190\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.128.251\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.128.251\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-12T13:08:27Z\"\n    }\n}\n"
STEP: replace the image in the pod 11/12/22 13:08:32.676
Nov 12 13:08:32.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 replace -f -'
Nov 12 13:08:33.129: INFO: stderr: ""
Nov 12 13:08:33.129: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/12/22 13:08:33.129
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Nov 12 13:08:33.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 delete pods e2e-test-httpd-pod'
Nov 12 13:08:35.194: INFO: stderr: ""
Nov 12 13:08:35.194: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 13:08:35.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4760" for this suite. 11/12/22 13:08:35.198
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":264,"skipped":4926,"failed":0}
------------------------------
• [SLOW TEST] [7.788 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:27.42
    Nov 12 13:08:27.420: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 13:08:27.421
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:27.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:27.452
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/12/22 13:08:27.455
    Nov 12 13:08:27.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 12 13:08:27.544: INFO: stderr: ""
    Nov 12 13:08:27.544: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 11/12/22 13:08:27.544
    STEP: verifying the pod e2e-test-httpd-pod was created 11/12/22 13:08:32.595
    Nov 12 13:08:32.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 get pod e2e-test-httpd-pod -o json'
    Nov 12 13:08:32.676: INFO: stderr: ""
    Nov 12 13:08:32.676: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-11-12T13:08:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-4760\",\n        \"resourceVersion\": \"33200\",\n        \"uid\": \"49db5a32-f2cc-4fe4-9dca-41f2daed00d1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-n4cbq\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-89-190\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-n4cbq\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-12T13:08:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://0acea914c67ea8daa285b1632310cc9e3d15afe51560ef252d5af55b3c662593\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-12T13:08:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.89.190\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.128.251\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.128.251\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-12T13:08:27Z\"\n    }\n}\n"
    STEP: replace the image in the pod 11/12/22 13:08:32.676
    Nov 12 13:08:32.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 replace -f -'
    Nov 12 13:08:33.129: INFO: stderr: ""
    Nov 12 13:08:33.129: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/12/22 13:08:33.129
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Nov 12 13:08:33.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-4760 delete pods e2e-test-httpd-pod'
    Nov 12 13:08:35.194: INFO: stderr: ""
    Nov 12 13:08:35.194: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 13:08:35.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4760" for this suite. 11/12/22 13:08:35.198
  << End Captured GinkgoWriter Output
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:35.208
Nov 12 13:08:35.208: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename conformance-tests 11/12/22 13:08:35.209
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:35.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:35.232
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 11/12/22 13:08:35.234
Nov 12 13:08:35.234: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Nov 12 13:08:35.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1527" for this suite. 11/12/22 13:08:35.245
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":265,"skipped":4926,"failed":0}
------------------------------
• [0.048 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:35.208
    Nov 12 13:08:35.208: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename conformance-tests 11/12/22 13:08:35.209
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:35.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:35.232
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 11/12/22 13:08:35.234
    Nov 12 13:08:35.234: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Nov 12 13:08:35.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1527" for this suite. 11/12/22 13:08:35.245
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:35.258
Nov 12 13:08:35.259: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:08:35.259
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:35.279
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:35.281
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/12/22 13:08:35.284
Nov 12 13:08:35.285: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 13:08:37.816: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:08:48.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2824" for this suite. 11/12/22 13:08:48.13
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":266,"skipped":4964,"failed":0}
------------------------------
• [SLOW TEST] [12.885 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:35.258
    Nov 12 13:08:35.259: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:08:35.259
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:35.279
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:35.281
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/12/22 13:08:35.284
    Nov 12 13:08:35.285: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 13:08:37.816: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:08:48.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2824" for this suite. 11/12/22 13:08:48.13
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:48.144
Nov 12 13:08:48.144: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename lease-test 11/12/22 13:08:48.145
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:48.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:48.171
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Nov 12 13:08:48.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-2187" for this suite. 11/12/22 13:08:48.318
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":267,"skipped":4966,"failed":0}
------------------------------
• [0.183 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:48.144
    Nov 12 13:08:48.144: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename lease-test 11/12/22 13:08:48.145
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:48.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:48.171
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Nov 12 13:08:48.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-2187" for this suite. 11/12/22 13:08:48.318
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:48.338
Nov 12 13:08:48.338: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:08:48.339
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:48.358
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:48.361
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 11/12/22 13:08:48.364
Nov 12 13:08:48.379: INFO: Waiting up to 5m0s for pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7" in namespace "downward-api-1377" to be "Succeeded or Failed"
Nov 12 13:08:48.384: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.852333ms
Nov 12 13:08:50.389: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010733996s
Nov 12 13:08:52.390: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010853858s
STEP: Saw pod success 11/12/22 13:08:52.39
Nov 12 13:08:52.390: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7" satisfied condition "Succeeded or Failed"
Nov 12 13:08:52.394: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-65535e9e-6386-4591-8598-3888848e1ab7 container dapi-container: <nil>
STEP: delete the pod 11/12/22 13:08:52.403
Nov 12 13:08:52.423: INFO: Waiting for pod downward-api-65535e9e-6386-4591-8598-3888848e1ab7 to disappear
Nov 12 13:08:52.431: INFO: Pod downward-api-65535e9e-6386-4591-8598-3888848e1ab7 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 12 13:08:52.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1377" for this suite. 11/12/22 13:08:52.435
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":268,"skipped":5080,"failed":0}
------------------------------
• [4.107 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:48.338
    Nov 12 13:08:48.338: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:08:48.339
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:48.358
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:48.361
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 11/12/22 13:08:48.364
    Nov 12 13:08:48.379: INFO: Waiting up to 5m0s for pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7" in namespace "downward-api-1377" to be "Succeeded or Failed"
    Nov 12 13:08:48.384: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.852333ms
    Nov 12 13:08:50.389: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010733996s
    Nov 12 13:08:52.390: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010853858s
    STEP: Saw pod success 11/12/22 13:08:52.39
    Nov 12 13:08:52.390: INFO: Pod "downward-api-65535e9e-6386-4591-8598-3888848e1ab7" satisfied condition "Succeeded or Failed"
    Nov 12 13:08:52.394: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-65535e9e-6386-4591-8598-3888848e1ab7 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 13:08:52.403
    Nov 12 13:08:52.423: INFO: Waiting for pod downward-api-65535e9e-6386-4591-8598-3888848e1ab7 to disappear
    Nov 12 13:08:52.431: INFO: Pod downward-api-65535e9e-6386-4591-8598-3888848e1ab7 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 12 13:08:52.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1377" for this suite. 11/12/22 13:08:52.435
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:52.457
Nov 12 13:08:52.457: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:08:52.458
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:52.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:52.482
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-e97edd46-db12-4d8b-837f-fdc2ae2cf837 11/12/22 13:08:52.491
STEP: Creating configMap with name cm-test-opt-upd-2a8a1f3a-8076-4e60-9eaa-53cbbe26a958 11/12/22 13:08:52.5
STEP: Creating the pod 11/12/22 13:08:52.512
Nov 12 13:08:52.525: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf" in namespace "projected-2801" to be "running and ready"
Nov 12 13:08:52.536: INFO: Pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.286405ms
Nov 12 13:08:52.536: INFO: The phase of Pod pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:08:54.542: INFO: Pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf": Phase="Running", Reason="", readiness=true. Elapsed: 2.016246406s
Nov 12 13:08:54.542: INFO: The phase of Pod pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf is Running (Ready = true)
Nov 12 13:08:54.542: INFO: Pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-e97edd46-db12-4d8b-837f-fdc2ae2cf837 11/12/22 13:08:54.571
STEP: Updating configmap cm-test-opt-upd-2a8a1f3a-8076-4e60-9eaa-53cbbe26a958 11/12/22 13:08:54.579
STEP: Creating configMap with name cm-test-opt-create-8ec2692c-69aa-46a0-a52b-7c67cb49a94b 11/12/22 13:08:54.585
STEP: waiting to observe update in volume 11/12/22 13:08:54.592
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 13:08:58.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2801" for this suite. 11/12/22 13:08:58.65
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":269,"skipped":5159,"failed":0}
------------------------------
• [SLOW TEST] [6.202 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:52.457
    Nov 12 13:08:52.457: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:08:52.458
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:52.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:52.482
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-e97edd46-db12-4d8b-837f-fdc2ae2cf837 11/12/22 13:08:52.491
    STEP: Creating configMap with name cm-test-opt-upd-2a8a1f3a-8076-4e60-9eaa-53cbbe26a958 11/12/22 13:08:52.5
    STEP: Creating the pod 11/12/22 13:08:52.512
    Nov 12 13:08:52.525: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf" in namespace "projected-2801" to be "running and ready"
    Nov 12 13:08:52.536: INFO: Pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.286405ms
    Nov 12 13:08:52.536: INFO: The phase of Pod pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:08:54.542: INFO: Pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf": Phase="Running", Reason="", readiness=true. Elapsed: 2.016246406s
    Nov 12 13:08:54.542: INFO: The phase of Pod pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf is Running (Ready = true)
    Nov 12 13:08:54.542: INFO: Pod "pod-projected-configmaps-cb5712d6-9643-47b1-9dee-eefa3064ffdf" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-e97edd46-db12-4d8b-837f-fdc2ae2cf837 11/12/22 13:08:54.571
    STEP: Updating configmap cm-test-opt-upd-2a8a1f3a-8076-4e60-9eaa-53cbbe26a958 11/12/22 13:08:54.579
    STEP: Creating configMap with name cm-test-opt-create-8ec2692c-69aa-46a0-a52b-7c67cb49a94b 11/12/22 13:08:54.585
    STEP: waiting to observe update in volume 11/12/22 13:08:54.592
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 13:08:58.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2801" for this suite. 11/12/22 13:08:58.65
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:58.661
Nov 12 13:08:58.661: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 13:08:58.662
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:58.687
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:58.694
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 13:08:58.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7205" for this suite. 11/12/22 13:08:58.782
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":270,"skipped":5180,"failed":0}
------------------------------
• [0.138 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:58.661
    Nov 12 13:08:58.661: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 13:08:58.662
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:58.687
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:58.694
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 13:08:58.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7205" for this suite. 11/12/22 13:08:58.782
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:08:58.8
Nov 12 13:08:58.800: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:08:58.801
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:58.833
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:58.841
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1350 11/12/22 13:08:58.845
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 13:08:58.87
STEP: creating service externalsvc in namespace services-1350 11/12/22 13:08:58.87
STEP: creating replication controller externalsvc in namespace services-1350 11/12/22 13:08:58.906
I1112 13:08:58.928553      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1350, replica count: 2
I1112 13:09:01.979775      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 11/12/22 13:09:01.985
Nov 12 13:09:02.024: INFO: Creating new exec pod
Nov 12 13:09:02.041: INFO: Waiting up to 5m0s for pod "execpodk7bxz" in namespace "services-1350" to be "running"
Nov 12 13:09:02.046: INFO: Pod "execpodk7bxz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.174967ms
Nov 12 13:09:04.059: INFO: Pod "execpodk7bxz": Phase="Running", Reason="", readiness=true. Elapsed: 2.01767298s
Nov 12 13:09:04.059: INFO: Pod "execpodk7bxz" satisfied condition "running"
Nov 12 13:09:04.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-1350 exec execpodk7bxz -- /bin/sh -x -c nslookup nodeport-service.services-1350.svc.cluster.local'
Nov 12 13:09:04.262: INFO: stderr: "+ nslookup nodeport-service.services-1350.svc.cluster.local\n"
Nov 12 13:09:04.262: INFO: stdout: "Server:\t\t10.152.183.100\nAddress:\t10.152.183.100#53\n\nnodeport-service.services-1350.svc.cluster.local\tcanonical name = externalsvc.services-1350.svc.cluster.local.\nName:\texternalsvc.services-1350.svc.cluster.local\nAddress: 10.152.183.19\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1350, will wait for the garbage collector to delete the pods 11/12/22 13:09:04.262
Nov 12 13:09:04.335: INFO: Deleting ReplicationController externalsvc took: 13.396369ms
Nov 12 13:09:04.436: INFO: Terminating ReplicationController externalsvc pods took: 100.846461ms
Nov 12 13:09:06.664: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:09:06.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1350" for this suite. 11/12/22 13:09:06.701
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":271,"skipped":5180,"failed":0}
------------------------------
• [SLOW TEST] [7.912 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:08:58.8
    Nov 12 13:08:58.800: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:08:58.801
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:08:58.833
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:08:58.841
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-1350 11/12/22 13:08:58.845
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/12/22 13:08:58.87
    STEP: creating service externalsvc in namespace services-1350 11/12/22 13:08:58.87
    STEP: creating replication controller externalsvc in namespace services-1350 11/12/22 13:08:58.906
    I1112 13:08:58.928553      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1350, replica count: 2
    I1112 13:09:01.979775      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 11/12/22 13:09:01.985
    Nov 12 13:09:02.024: INFO: Creating new exec pod
    Nov 12 13:09:02.041: INFO: Waiting up to 5m0s for pod "execpodk7bxz" in namespace "services-1350" to be "running"
    Nov 12 13:09:02.046: INFO: Pod "execpodk7bxz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.174967ms
    Nov 12 13:09:04.059: INFO: Pod "execpodk7bxz": Phase="Running", Reason="", readiness=true. Elapsed: 2.01767298s
    Nov 12 13:09:04.059: INFO: Pod "execpodk7bxz" satisfied condition "running"
    Nov 12 13:09:04.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-1350 exec execpodk7bxz -- /bin/sh -x -c nslookup nodeport-service.services-1350.svc.cluster.local'
    Nov 12 13:09:04.262: INFO: stderr: "+ nslookup nodeport-service.services-1350.svc.cluster.local\n"
    Nov 12 13:09:04.262: INFO: stdout: "Server:\t\t10.152.183.100\nAddress:\t10.152.183.100#53\n\nnodeport-service.services-1350.svc.cluster.local\tcanonical name = externalsvc.services-1350.svc.cluster.local.\nName:\texternalsvc.services-1350.svc.cluster.local\nAddress: 10.152.183.19\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1350, will wait for the garbage collector to delete the pods 11/12/22 13:09:04.262
    Nov 12 13:09:04.335: INFO: Deleting ReplicationController externalsvc took: 13.396369ms
    Nov 12 13:09:04.436: INFO: Terminating ReplicationController externalsvc pods took: 100.846461ms
    Nov 12 13:09:06.664: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:09:06.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1350" for this suite. 11/12/22 13:09:06.701
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:09:06.712
Nov 12 13:09:06.712: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 13:09:06.713
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:06.781
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:06.785
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-ef1187a1-d417-4e89-a37c-cfb1bbf44c3e 11/12/22 13:09:06.792
STEP: Creating the pod 11/12/22 13:09:06.8
Nov 12 13:09:06.810: INFO: Waiting up to 5m0s for pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c" in namespace "configmap-8883" to be "running and ready"
Nov 12 13:09:06.818: INFO: Pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.990966ms
Nov 12 13:09:06.818: INFO: The phase of Pod pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:09:08.824: INFO: Pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c": Phase="Running", Reason="", readiness=true. Elapsed: 2.014154878s
Nov 12 13:09:08.824: INFO: The phase of Pod pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c is Running (Ready = true)
Nov 12 13:09:08.824: INFO: Pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-ef1187a1-d417-4e89-a37c-cfb1bbf44c3e 11/12/22 13:09:08.84
STEP: waiting to observe update in volume 11/12/22 13:09:08.854
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 13:09:10.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8883" for this suite. 11/12/22 13:09:10.891
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":272,"skipped":5181,"failed":0}
------------------------------
• [4.189 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:09:06.712
    Nov 12 13:09:06.712: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 13:09:06.713
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:06.781
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:06.785
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-ef1187a1-d417-4e89-a37c-cfb1bbf44c3e 11/12/22 13:09:06.792
    STEP: Creating the pod 11/12/22 13:09:06.8
    Nov 12 13:09:06.810: INFO: Waiting up to 5m0s for pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c" in namespace "configmap-8883" to be "running and ready"
    Nov 12 13:09:06.818: INFO: Pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.990966ms
    Nov 12 13:09:06.818: INFO: The phase of Pod pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:09:08.824: INFO: Pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c": Phase="Running", Reason="", readiness=true. Elapsed: 2.014154878s
    Nov 12 13:09:08.824: INFO: The phase of Pod pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c is Running (Ready = true)
    Nov 12 13:09:08.824: INFO: Pod "pod-configmaps-5b95b007-d061-4c3e-a8d4-9a80a994d35c" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-ef1187a1-d417-4e89-a37c-cfb1bbf44c3e 11/12/22 13:09:08.84
    STEP: waiting to observe update in volume 11/12/22 13:09:08.854
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 13:09:10.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8883" for this suite. 11/12/22 13:09:10.891
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:09:10.902
Nov 12 13:09:10.902: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 13:09:10.903
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:10.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:10.941
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4887 11/12/22 13:09:10.946
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-4887 11/12/22 13:09:10.963
Nov 12 13:09:10.985: INFO: Found 0 stateful pods, waiting for 1
Nov 12 13:09:20.992: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 11/12/22 13:09:21.001
STEP: updating a scale subresource 11/12/22 13:09:21.006
STEP: verifying the statefulset Spec.Replicas was modified 11/12/22 13:09:21.013
STEP: Patch a scale subresource 11/12/22 13:09:21.02
STEP: verifying the statefulset Spec.Replicas was modified 11/12/22 13:09:21.144
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 13:09:21.150: INFO: Deleting all statefulset in ns statefulset-4887
Nov 12 13:09:21.155: INFO: Scaling statefulset ss to 0
Nov 12 13:09:31.182: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 13:09:31.186: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 13:09:31.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4887" for this suite. 11/12/22 13:09:31.218
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":273,"skipped":5196,"failed":0}
------------------------------
• [SLOW TEST] [20.325 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:09:10.902
    Nov 12 13:09:10.902: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 13:09:10.903
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:10.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:10.941
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4887 11/12/22 13:09:10.946
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-4887 11/12/22 13:09:10.963
    Nov 12 13:09:10.985: INFO: Found 0 stateful pods, waiting for 1
    Nov 12 13:09:20.992: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 11/12/22 13:09:21.001
    STEP: updating a scale subresource 11/12/22 13:09:21.006
    STEP: verifying the statefulset Spec.Replicas was modified 11/12/22 13:09:21.013
    STEP: Patch a scale subresource 11/12/22 13:09:21.02
    STEP: verifying the statefulset Spec.Replicas was modified 11/12/22 13:09:21.144
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 13:09:21.150: INFO: Deleting all statefulset in ns statefulset-4887
    Nov 12 13:09:21.155: INFO: Scaling statefulset ss to 0
    Nov 12 13:09:31.182: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 13:09:31.186: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 13:09:31.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4887" for this suite. 11/12/22 13:09:31.218
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:09:31.229
Nov 12 13:09:31.230: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 13:09:31.23
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:31.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:31.254
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 11/12/22 13:09:31.256
STEP: Ensuring ResourceQuota status is calculated 11/12/22 13:09:31.265
STEP: Creating a ResourceQuota with not terminating scope 11/12/22 13:09:33.271
STEP: Ensuring ResourceQuota status is calculated 11/12/22 13:09:33.277
STEP: Creating a long running pod 11/12/22 13:09:35.283
STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/12/22 13:09:35.308
STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/12/22 13:09:37.314
STEP: Deleting the pod 11/12/22 13:09:39.321
STEP: Ensuring resource quota status released the pod usage 11/12/22 13:09:39.338
STEP: Creating a terminating pod 11/12/22 13:09:41.344
STEP: Ensuring resource quota with terminating scope captures the pod usage 11/12/22 13:09:41.358
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/12/22 13:09:43.364
STEP: Deleting the pod 11/12/22 13:09:45.37
STEP: Ensuring resource quota status released the pod usage 11/12/22 13:09:45.384
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 13:09:47.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8301" for this suite. 11/12/22 13:09:47.398
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":274,"skipped":5205,"failed":0}
------------------------------
• [SLOW TEST] [16.177 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:09:31.229
    Nov 12 13:09:31.230: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 13:09:31.23
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:31.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:31.254
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 11/12/22 13:09:31.256
    STEP: Ensuring ResourceQuota status is calculated 11/12/22 13:09:31.265
    STEP: Creating a ResourceQuota with not terminating scope 11/12/22 13:09:33.271
    STEP: Ensuring ResourceQuota status is calculated 11/12/22 13:09:33.277
    STEP: Creating a long running pod 11/12/22 13:09:35.283
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/12/22 13:09:35.308
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/12/22 13:09:37.314
    STEP: Deleting the pod 11/12/22 13:09:39.321
    STEP: Ensuring resource quota status released the pod usage 11/12/22 13:09:39.338
    STEP: Creating a terminating pod 11/12/22 13:09:41.344
    STEP: Ensuring resource quota with terminating scope captures the pod usage 11/12/22 13:09:41.358
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/12/22 13:09:43.364
    STEP: Deleting the pod 11/12/22 13:09:45.37
    STEP: Ensuring resource quota status released the pod usage 11/12/22 13:09:45.384
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 13:09:47.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8301" for this suite. 11/12/22 13:09:47.398
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:09:47.407
Nov 12 13:09:47.407: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename disruption 11/12/22 13:09:47.408
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:47.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:47.429
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 11/12/22 13:09:47.44
STEP: Updating PodDisruptionBudget status 11/12/22 13:09:49.455
STEP: Waiting for all pods to be running 11/12/22 13:09:49.467
Nov 12 13:09:49.475: INFO: running pods: 0 < 1
STEP: locating a running pod 11/12/22 13:09:51.48
STEP: Waiting for the pdb to be processed 11/12/22 13:09:51.494
STEP: Patching PodDisruptionBudget status 11/12/22 13:09:51.502
STEP: Waiting for the pdb to be processed 11/12/22 13:09:51.514
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 13:09:51.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6057" for this suite. 11/12/22 13:09:51.525
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":275,"skipped":5206,"failed":0}
------------------------------
• [4.126 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:09:47.407
    Nov 12 13:09:47.407: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename disruption 11/12/22 13:09:47.408
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:47.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:47.429
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 11/12/22 13:09:47.44
    STEP: Updating PodDisruptionBudget status 11/12/22 13:09:49.455
    STEP: Waiting for all pods to be running 11/12/22 13:09:49.467
    Nov 12 13:09:49.475: INFO: running pods: 0 < 1
    STEP: locating a running pod 11/12/22 13:09:51.48
    STEP: Waiting for the pdb to be processed 11/12/22 13:09:51.494
    STEP: Patching PodDisruptionBudget status 11/12/22 13:09:51.502
    STEP: Waiting for the pdb to be processed 11/12/22 13:09:51.514
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 13:09:51.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6057" for this suite. 11/12/22 13:09:51.525
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:09:51.535
Nov 12 13:09:51.535: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename discovery 11/12/22 13:09:51.536
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:51.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:51.557
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 11/12/22 13:09:51.561
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Nov 12 13:09:52.002: INFO: Checking APIGroup: apiregistration.k8s.io
Nov 12 13:09:52.003: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Nov 12 13:09:52.003: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Nov 12 13:09:52.003: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Nov 12 13:09:52.003: INFO: Checking APIGroup: apps
Nov 12 13:09:52.004: INFO: PreferredVersion.GroupVersion: apps/v1
Nov 12 13:09:52.004: INFO: Versions found [{apps/v1 v1}]
Nov 12 13:09:52.004: INFO: apps/v1 matches apps/v1
Nov 12 13:09:52.004: INFO: Checking APIGroup: events.k8s.io
Nov 12 13:09:52.004: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Nov 12 13:09:52.004: INFO: Versions found [{events.k8s.io/v1 v1}]
Nov 12 13:09:52.004: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Nov 12 13:09:52.004: INFO: Checking APIGroup: authentication.k8s.io
Nov 12 13:09:52.005: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Nov 12 13:09:52.005: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Nov 12 13:09:52.005: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Nov 12 13:09:52.005: INFO: Checking APIGroup: authorization.k8s.io
Nov 12 13:09:52.006: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Nov 12 13:09:52.006: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Nov 12 13:09:52.006: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Nov 12 13:09:52.006: INFO: Checking APIGroup: autoscaling
Nov 12 13:09:52.007: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Nov 12 13:09:52.007: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Nov 12 13:09:52.007: INFO: autoscaling/v2 matches autoscaling/v2
Nov 12 13:09:52.007: INFO: Checking APIGroup: batch
Nov 12 13:09:52.007: INFO: PreferredVersion.GroupVersion: batch/v1
Nov 12 13:09:52.007: INFO: Versions found [{batch/v1 v1}]
Nov 12 13:09:52.007: INFO: batch/v1 matches batch/v1
Nov 12 13:09:52.007: INFO: Checking APIGroup: certificates.k8s.io
Nov 12 13:09:52.008: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Nov 12 13:09:52.008: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Nov 12 13:09:52.008: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Nov 12 13:09:52.008: INFO: Checking APIGroup: networking.k8s.io
Nov 12 13:09:52.009: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Nov 12 13:09:52.009: INFO: Versions found [{networking.k8s.io/v1 v1}]
Nov 12 13:09:52.009: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Nov 12 13:09:52.009: INFO: Checking APIGroup: policy
Nov 12 13:09:52.010: INFO: PreferredVersion.GroupVersion: policy/v1
Nov 12 13:09:52.010: INFO: Versions found [{policy/v1 v1}]
Nov 12 13:09:52.010: INFO: policy/v1 matches policy/v1
Nov 12 13:09:52.010: INFO: Checking APIGroup: rbac.authorization.k8s.io
Nov 12 13:09:52.010: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Nov 12 13:09:52.010: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Nov 12 13:09:52.010: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Nov 12 13:09:52.010: INFO: Checking APIGroup: storage.k8s.io
Nov 12 13:09:52.011: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Nov 12 13:09:52.011: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Nov 12 13:09:52.011: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Nov 12 13:09:52.011: INFO: Checking APIGroup: admissionregistration.k8s.io
Nov 12 13:09:52.012: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Nov 12 13:09:52.012: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Nov 12 13:09:52.012: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Nov 12 13:09:52.012: INFO: Checking APIGroup: apiextensions.k8s.io
Nov 12 13:09:52.013: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Nov 12 13:09:52.013: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Nov 12 13:09:52.013: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Nov 12 13:09:52.013: INFO: Checking APIGroup: scheduling.k8s.io
Nov 12 13:09:52.014: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Nov 12 13:09:52.014: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Nov 12 13:09:52.014: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Nov 12 13:09:52.014: INFO: Checking APIGroup: coordination.k8s.io
Nov 12 13:09:52.015: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Nov 12 13:09:52.015: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Nov 12 13:09:52.015: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Nov 12 13:09:52.016: INFO: Checking APIGroup: node.k8s.io
Nov 12 13:09:52.017: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Nov 12 13:09:52.017: INFO: Versions found [{node.k8s.io/v1 v1}]
Nov 12 13:09:52.017: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Nov 12 13:09:52.017: INFO: Checking APIGroup: discovery.k8s.io
Nov 12 13:09:52.018: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Nov 12 13:09:52.018: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Nov 12 13:09:52.018: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Nov 12 13:09:52.018: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Nov 12 13:09:52.019: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Nov 12 13:09:52.019: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Nov 12 13:09:52.019: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Nov 12 13:09:52.019: INFO: Checking APIGroup: metrics.k8s.io
Nov 12 13:09:52.020: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Nov 12 13:09:52.020: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Nov 12 13:09:52.020: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Nov 12 13:09:52.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-8303" for this suite. 11/12/22 13:09:52.025
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":276,"skipped":5222,"failed":0}
------------------------------
• [0.501 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:09:51.535
    Nov 12 13:09:51.535: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename discovery 11/12/22 13:09:51.536
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:51.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:51.557
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 11/12/22 13:09:51.561
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Nov 12 13:09:52.002: INFO: Checking APIGroup: apiregistration.k8s.io
    Nov 12 13:09:52.003: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Nov 12 13:09:52.003: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Nov 12 13:09:52.003: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Nov 12 13:09:52.003: INFO: Checking APIGroup: apps
    Nov 12 13:09:52.004: INFO: PreferredVersion.GroupVersion: apps/v1
    Nov 12 13:09:52.004: INFO: Versions found [{apps/v1 v1}]
    Nov 12 13:09:52.004: INFO: apps/v1 matches apps/v1
    Nov 12 13:09:52.004: INFO: Checking APIGroup: events.k8s.io
    Nov 12 13:09:52.004: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Nov 12 13:09:52.004: INFO: Versions found [{events.k8s.io/v1 v1}]
    Nov 12 13:09:52.004: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Nov 12 13:09:52.004: INFO: Checking APIGroup: authentication.k8s.io
    Nov 12 13:09:52.005: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Nov 12 13:09:52.005: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Nov 12 13:09:52.005: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Nov 12 13:09:52.005: INFO: Checking APIGroup: authorization.k8s.io
    Nov 12 13:09:52.006: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Nov 12 13:09:52.006: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Nov 12 13:09:52.006: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Nov 12 13:09:52.006: INFO: Checking APIGroup: autoscaling
    Nov 12 13:09:52.007: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Nov 12 13:09:52.007: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Nov 12 13:09:52.007: INFO: autoscaling/v2 matches autoscaling/v2
    Nov 12 13:09:52.007: INFO: Checking APIGroup: batch
    Nov 12 13:09:52.007: INFO: PreferredVersion.GroupVersion: batch/v1
    Nov 12 13:09:52.007: INFO: Versions found [{batch/v1 v1}]
    Nov 12 13:09:52.007: INFO: batch/v1 matches batch/v1
    Nov 12 13:09:52.007: INFO: Checking APIGroup: certificates.k8s.io
    Nov 12 13:09:52.008: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Nov 12 13:09:52.008: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Nov 12 13:09:52.008: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Nov 12 13:09:52.008: INFO: Checking APIGroup: networking.k8s.io
    Nov 12 13:09:52.009: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Nov 12 13:09:52.009: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Nov 12 13:09:52.009: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Nov 12 13:09:52.009: INFO: Checking APIGroup: policy
    Nov 12 13:09:52.010: INFO: PreferredVersion.GroupVersion: policy/v1
    Nov 12 13:09:52.010: INFO: Versions found [{policy/v1 v1}]
    Nov 12 13:09:52.010: INFO: policy/v1 matches policy/v1
    Nov 12 13:09:52.010: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Nov 12 13:09:52.010: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Nov 12 13:09:52.010: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Nov 12 13:09:52.010: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Nov 12 13:09:52.010: INFO: Checking APIGroup: storage.k8s.io
    Nov 12 13:09:52.011: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Nov 12 13:09:52.011: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Nov 12 13:09:52.011: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Nov 12 13:09:52.011: INFO: Checking APIGroup: admissionregistration.k8s.io
    Nov 12 13:09:52.012: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Nov 12 13:09:52.012: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Nov 12 13:09:52.012: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Nov 12 13:09:52.012: INFO: Checking APIGroup: apiextensions.k8s.io
    Nov 12 13:09:52.013: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Nov 12 13:09:52.013: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Nov 12 13:09:52.013: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Nov 12 13:09:52.013: INFO: Checking APIGroup: scheduling.k8s.io
    Nov 12 13:09:52.014: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Nov 12 13:09:52.014: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Nov 12 13:09:52.014: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Nov 12 13:09:52.014: INFO: Checking APIGroup: coordination.k8s.io
    Nov 12 13:09:52.015: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Nov 12 13:09:52.015: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Nov 12 13:09:52.015: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Nov 12 13:09:52.016: INFO: Checking APIGroup: node.k8s.io
    Nov 12 13:09:52.017: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Nov 12 13:09:52.017: INFO: Versions found [{node.k8s.io/v1 v1}]
    Nov 12 13:09:52.017: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Nov 12 13:09:52.017: INFO: Checking APIGroup: discovery.k8s.io
    Nov 12 13:09:52.018: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Nov 12 13:09:52.018: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Nov 12 13:09:52.018: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Nov 12 13:09:52.018: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Nov 12 13:09:52.019: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Nov 12 13:09:52.019: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Nov 12 13:09:52.019: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Nov 12 13:09:52.019: INFO: Checking APIGroup: metrics.k8s.io
    Nov 12 13:09:52.020: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Nov 12 13:09:52.020: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Nov 12 13:09:52.020: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Nov 12 13:09:52.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-8303" for this suite. 11/12/22 13:09:52.025
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:09:52.036
Nov 12 13:09:52.037: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 13:09:52.038
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:52.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:52.061
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Nov 12 13:09:52.063: INFO: Creating deployment "webserver-deployment"
Nov 12 13:09:52.071: INFO: Waiting for observed generation 1
Nov 12 13:09:54.081: INFO: Waiting for all required pods to come up
Nov 12 13:09:54.086: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 11/12/22 13:09:54.086
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-z2t5f" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9bx95" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bnx99" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2s8z4" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ggf62" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6wgtf" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ljsc5" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-pf782" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.087: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8drkp" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.087: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-94l5v" in namespace "deployment-921" to be "running"
Nov 12 13:09:54.093: INFO: Pod "webserver-deployment-845c8977d9-ggf62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.78773ms
Nov 12 13:09:54.094: INFO: Pod "webserver-deployment-845c8977d9-6wgtf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.425979ms
Nov 12 13:09:54.094: INFO: Pod "webserver-deployment-845c8977d9-pf782": Phase="Pending", Reason="", readiness=false. Elapsed: 7.587992ms
Nov 12 13:09:54.094: INFO: Pod "webserver-deployment-845c8977d9-bnx99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.09648ms
Nov 12 13:09:54.095: INFO: Pod "webserver-deployment-845c8977d9-2s8z4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.427287ms
Nov 12 13:09:54.095: INFO: Pod "webserver-deployment-845c8977d9-94l5v": Phase="Pending", Reason="", readiness=false. Elapsed: 8.15798ms
Nov 12 13:09:54.099: INFO: Pod "webserver-deployment-845c8977d9-z2t5f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.123262ms
Nov 12 13:09:54.100: INFO: Pod "webserver-deployment-845c8977d9-8drkp": Phase="Pending", Reason="", readiness=false. Elapsed: 13.865879ms
Nov 12 13:09:54.102: INFO: Pod "webserver-deployment-845c8977d9-ljsc5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.905611ms
Nov 12 13:09:54.102: INFO: Pod "webserver-deployment-845c8977d9-9bx95": Phase="Pending", Reason="", readiness=false. Elapsed: 16.448248ms
Nov 12 13:09:56.099: INFO: Pod "webserver-deployment-845c8977d9-ggf62": Phase="Running", Reason="", readiness=true. Elapsed: 2.012907544s
Nov 12 13:09:56.099: INFO: Pod "webserver-deployment-845c8977d9-ggf62" satisfied condition "running"
Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-6wgtf": Phase="Running", Reason="", readiness=true. Elapsed: 2.013254597s
Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-6wgtf" satisfied condition "running"
Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-2s8z4": Phase="Running", Reason="", readiness=true. Elapsed: 2.014221689s
Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-2s8z4" satisfied condition "running"
Nov 12 13:09:56.101: INFO: Pod "webserver-deployment-845c8977d9-94l5v": Phase="Running", Reason="", readiness=true. Elapsed: 2.014271635s
Nov 12 13:09:56.101: INFO: Pod "webserver-deployment-845c8977d9-94l5v" satisfied condition "running"
Nov 12 13:09:56.103: INFO: Pod "webserver-deployment-845c8977d9-pf782": Phase="Running", Reason="", readiness=true. Elapsed: 2.01622208s
Nov 12 13:09:56.103: INFO: Pod "webserver-deployment-845c8977d9-pf782" satisfied condition "running"
Nov 12 13:09:56.104: INFO: Pod "webserver-deployment-845c8977d9-8drkp": Phase="Running", Reason="", readiness=true. Elapsed: 2.017816907s
Nov 12 13:09:56.104: INFO: Pod "webserver-deployment-845c8977d9-8drkp" satisfied condition "running"
Nov 12 13:09:56.105: INFO: Pod "webserver-deployment-845c8977d9-bnx99": Phase="Running", Reason="", readiness=true. Elapsed: 2.019192877s
Nov 12 13:09:56.105: INFO: Pod "webserver-deployment-845c8977d9-bnx99" satisfied condition "running"
Nov 12 13:09:56.105: INFO: Pod "webserver-deployment-845c8977d9-z2t5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.019594405s
Nov 12 13:09:56.106: INFO: Pod "webserver-deployment-845c8977d9-z2t5f" satisfied condition "running"
Nov 12 13:09:56.106: INFO: Pod "webserver-deployment-845c8977d9-9bx95": Phase="Running", Reason="", readiness=true. Elapsed: 2.020428184s
Nov 12 13:09:56.106: INFO: Pod "webserver-deployment-845c8977d9-9bx95" satisfied condition "running"
Nov 12 13:09:56.107: INFO: Pod "webserver-deployment-845c8977d9-ljsc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.020590709s
Nov 12 13:09:56.107: INFO: Pod "webserver-deployment-845c8977d9-ljsc5" satisfied condition "running"
Nov 12 13:09:56.107: INFO: Waiting for deployment "webserver-deployment" to complete
Nov 12 13:09:56.116: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov 12 13:09:56.128: INFO: Updating deployment webserver-deployment
Nov 12 13:09:56.128: INFO: Waiting for observed generation 2
Nov 12 13:09:58.140: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 12 13:09:58.144: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 12 13:09:58.149: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 12 13:09:58.160: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 12 13:09:58.160: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 12 13:09:58.163: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 12 13:09:58.171: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov 12 13:09:58.171: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov 12 13:09:58.182: INFO: Updating deployment webserver-deployment
Nov 12 13:09:58.182: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov 12 13:09:58.191: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 12 13:09:58.198: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 13:09:58.243: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-921  30252b76-387d-441e-b0f7-d141f902f552 34196 3 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e8e768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-12 13:09:56 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 13:09:58 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov 12 13:09:58.255: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-921  77b741cc-f03d-4bab-b1bb-26b062018369 34188 3 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 30252b76-387d-441e-b0f7-d141f902f552 0xc003f70e97 0xc003f70e98}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30252b76-387d-441e-b0f7-d141f902f552\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f70f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 13:09:58.255: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov 12 13:09:58.255: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-921  207e3298-5c39-4254-930c-654ba6362c3e 34186 3 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 30252b76-387d-441e-b0f7-d141f902f552 0xc003f70f97 0xc003f70f98}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30252b76-387d-441e-b0f7-d141f902f552\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f71688 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-5tdqr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5tdqr webserver-deployment-69b7448995- deployment-921  7ba35364-10f6-41e5-93fd-4ad1e42f14a0 34201 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14077 0xc003a14078}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ssbxl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ssbxl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-8ckc2" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-8ckc2 webserver-deployment-69b7448995- deployment-921  76540e52-39a0-470b-84ba-901d5dde7ed2 34108 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a141f0 0xc003a141f1}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbbsg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbbsg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-b9mzt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-b9mzt webserver-deployment-69b7448995- deployment-921  83369bd0-8e3b-4006-b983-cdfd3280aee6 34203 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a143e7 0xc003a143e8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6xqkf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6xqkf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-qfc7c" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qfc7c webserver-deployment-69b7448995- deployment-921  40820a3b-7d32-4e79-9738-03bebcae4572 34156 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14537 0xc003a14538}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.253\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xt6hh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xt6hh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.253,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.253,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-qn8bz" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qn8bz webserver-deployment-69b7448995- deployment-921  1d688d84-f10d-4ac3-8a0f-d13ada3d156a 34165 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14757 0xc003a14758}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.89\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h2zcp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h2zcp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.89,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-rmnsg" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-rmnsg webserver-deployment-69b7448995- deployment-921  3514d6ba-3e4e-4483-99c4-6b79901dfd0d 34177 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14987 0xc003a14988}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.25\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kk7l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kk7l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.25,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.25,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-rngc5" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-rngc5 webserver-deployment-69b7448995- deployment-921  1bc0deb5-b10b-427a-97b2-ada39e0857b6 34200 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14bc7 0xc003a14bc8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ndlw5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ndlw5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-zkbzx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-zkbzx webserver-deployment-69b7448995- deployment-921  e153d6a2-4431-4647-afb3-79d18bcdea43 34175 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14d17 0xc003a14d18}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4jbz5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4jbz5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.41,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-845c8977d9-2s8z4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2s8z4 webserver-deployment-845c8977d9- deployment-921  fbf67387-9275-4f16-9b4d-390a2c6eea5b 34037 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a14f37 0xc003a14f38}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.92\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6k578,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6k578,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.92,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://346c397fcbb3cf469d458653841849b6c8970417d962143f7f8ed771c966c20e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.92,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-8drkp" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8drkp webserver-deployment-845c8977d9- deployment-921  d30be1c4-569b-464e-b2b9-ed038959f20f 34043 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15127 0xc003a15128}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhm2x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhm2x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.88,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://718f78efc73533316310928e6c0ac2b2e36bd63a58a709a66d6ae4eb1ed0a909,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-9bx95" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9bx95 webserver-deployment-845c8977d9- deployment-921  eef3494a-7b62-4c64-8191-e0d114b0a150 34046 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15317 0xc003a15318}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.26\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9jztm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9jztm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.26,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://08a2e01293e4a27d2e413f5fe36278364783d3fec1191c3b7a6d12c56da46478,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-bnx99" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bnx99 webserver-deployment-845c8977d9- deployment-921  90d8c0a6-5e0d-4826-af3d-e40ac88cf073 34055 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15967 0xc003a15968}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6p55w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6p55w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.54,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c0a1eaae44b1402dabca8bec2c0dc8617453914b69a6cdf917527931740d4e18,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-fjpp2" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fjpp2 webserver-deployment-845c8977d9- deployment-921  fb5159f9-dcb3-40cb-9db4-8e1d41a9e5b1 34197 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15b67 0xc003a15b68}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r6cbw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r6cbw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-ggf62" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ggf62 webserver-deployment-845c8977d9- deployment-921  875c4509-148b-4ae0-bcc2-955aead9c57a 34030 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15cd0 0xc003a15cd1}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.252\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8sd9d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8sd9d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.252,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2cbf4ff222209b78124ccfb0835c2e5319961ffac76696a74697c77b5ae9d242,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.252,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-hkq6s" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hkq6s webserver-deployment-845c8977d9- deployment-921  4533e14a-098a-43a5-800d-61671075c5c4 34207 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15eb7 0xc003a15eb8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-54df4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-54df4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-ljsc5" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ljsc5 webserver-deployment-845c8977d9- deployment-921  0aa6f479-a4f0-4f70-97df-bca40d213ac8 34034 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15ff7 0xc003a15ff8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.242\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7gq8p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7gq8p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.242,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fd6e5d2bc157ea6eddf492000c8730e9c8f99ca2a1ddb748a79b8d86027f888c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.242,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-pf782" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-pf782 webserver-deployment-845c8977d9- deployment-921  c9480d03-f002-4eba-9cd3-d5bae3145552 34040 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e1f7 0xc00366e1f8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s425p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s425p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.93,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fef7fc52bf72e6d8f3a42e7c6de9af294205c44dc618c659bc9406462fb35dfe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.93,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-r85b9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-r85b9 webserver-deployment-845c8977d9- deployment-921  ce55ac52-01a8-42bc-a619-9d12722cf152 34209 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e3e7 0xc00366e3e8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mcclk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mcclk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-rnrn7" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rnrn7 webserver-deployment-845c8977d9- deployment-921  4a5bd042-b7ee-4e70-93b3-97c169a55164 34202 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e547 0xc00366e548}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qxh44,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qxh44,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-snjp2" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-snjp2 webserver-deployment-845c8977d9- deployment-921  99ac857a-750e-4bbc-b81f-f29b0c511848 34208 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e6c0 0xc00366e6c1}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7267q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7267q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:,StartTime:2022-11-12 13:09:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-xtzjs" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-xtzjs webserver-deployment-845c8977d9- deployment-921  24e9f595-8b2b-4063-913e-e9e3b36796f0 34206 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e887 0xc00366e888}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hjrl6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hjrl6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-z296w" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-z296w webserver-deployment-845c8977d9- deployment-921  54f09638-2656-402d-a43d-30fd53f94098 34210 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e9c7 0xc00366e9c8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27lk2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27lk2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:09:58.277: INFO: Pod "webserver-deployment-845c8977d9-z2t5f" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-z2t5f webserver-deployment-845c8977d9- deployment-921  cb7c9bda-9ec8-48a7-9523-15e8cf5fd7ea 34049 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366eb07 0xc00366eb08}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wkwmw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wkwmw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.10,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1f9b849876dfccaf457c5441c44b5b36fa9e3da012627a5a459dbcc4f1c89152,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.10,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 13:09:58.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-921" for this suite. 11/12/22 13:09:58.297
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":277,"skipped":5227,"failed":0}
------------------------------
• [SLOW TEST] [6.288 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:09:52.036
    Nov 12 13:09:52.037: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 13:09:52.038
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:52.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:52.061
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Nov 12 13:09:52.063: INFO: Creating deployment "webserver-deployment"
    Nov 12 13:09:52.071: INFO: Waiting for observed generation 1
    Nov 12 13:09:54.081: INFO: Waiting for all required pods to come up
    Nov 12 13:09:54.086: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 11/12/22 13:09:54.086
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-z2t5f" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-9bx95" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bnx99" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-2s8z4" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ggf62" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-6wgtf" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-ljsc5" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.086: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-pf782" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.087: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-8drkp" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.087: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-94l5v" in namespace "deployment-921" to be "running"
    Nov 12 13:09:54.093: INFO: Pod "webserver-deployment-845c8977d9-ggf62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.78773ms
    Nov 12 13:09:54.094: INFO: Pod "webserver-deployment-845c8977d9-6wgtf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.425979ms
    Nov 12 13:09:54.094: INFO: Pod "webserver-deployment-845c8977d9-pf782": Phase="Pending", Reason="", readiness=false. Elapsed: 7.587992ms
    Nov 12 13:09:54.094: INFO: Pod "webserver-deployment-845c8977d9-bnx99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.09648ms
    Nov 12 13:09:54.095: INFO: Pod "webserver-deployment-845c8977d9-2s8z4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.427287ms
    Nov 12 13:09:54.095: INFO: Pod "webserver-deployment-845c8977d9-94l5v": Phase="Pending", Reason="", readiness=false. Elapsed: 8.15798ms
    Nov 12 13:09:54.099: INFO: Pod "webserver-deployment-845c8977d9-z2t5f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.123262ms
    Nov 12 13:09:54.100: INFO: Pod "webserver-deployment-845c8977d9-8drkp": Phase="Pending", Reason="", readiness=false. Elapsed: 13.865879ms
    Nov 12 13:09:54.102: INFO: Pod "webserver-deployment-845c8977d9-ljsc5": Phase="Pending", Reason="", readiness=false. Elapsed: 15.905611ms
    Nov 12 13:09:54.102: INFO: Pod "webserver-deployment-845c8977d9-9bx95": Phase="Pending", Reason="", readiness=false. Elapsed: 16.448248ms
    Nov 12 13:09:56.099: INFO: Pod "webserver-deployment-845c8977d9-ggf62": Phase="Running", Reason="", readiness=true. Elapsed: 2.012907544s
    Nov 12 13:09:56.099: INFO: Pod "webserver-deployment-845c8977d9-ggf62" satisfied condition "running"
    Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-6wgtf": Phase="Running", Reason="", readiness=true. Elapsed: 2.013254597s
    Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-6wgtf" satisfied condition "running"
    Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-2s8z4": Phase="Running", Reason="", readiness=true. Elapsed: 2.014221689s
    Nov 12 13:09:56.100: INFO: Pod "webserver-deployment-845c8977d9-2s8z4" satisfied condition "running"
    Nov 12 13:09:56.101: INFO: Pod "webserver-deployment-845c8977d9-94l5v": Phase="Running", Reason="", readiness=true. Elapsed: 2.014271635s
    Nov 12 13:09:56.101: INFO: Pod "webserver-deployment-845c8977d9-94l5v" satisfied condition "running"
    Nov 12 13:09:56.103: INFO: Pod "webserver-deployment-845c8977d9-pf782": Phase="Running", Reason="", readiness=true. Elapsed: 2.01622208s
    Nov 12 13:09:56.103: INFO: Pod "webserver-deployment-845c8977d9-pf782" satisfied condition "running"
    Nov 12 13:09:56.104: INFO: Pod "webserver-deployment-845c8977d9-8drkp": Phase="Running", Reason="", readiness=true. Elapsed: 2.017816907s
    Nov 12 13:09:56.104: INFO: Pod "webserver-deployment-845c8977d9-8drkp" satisfied condition "running"
    Nov 12 13:09:56.105: INFO: Pod "webserver-deployment-845c8977d9-bnx99": Phase="Running", Reason="", readiness=true. Elapsed: 2.019192877s
    Nov 12 13:09:56.105: INFO: Pod "webserver-deployment-845c8977d9-bnx99" satisfied condition "running"
    Nov 12 13:09:56.105: INFO: Pod "webserver-deployment-845c8977d9-z2t5f": Phase="Running", Reason="", readiness=true. Elapsed: 2.019594405s
    Nov 12 13:09:56.106: INFO: Pod "webserver-deployment-845c8977d9-z2t5f" satisfied condition "running"
    Nov 12 13:09:56.106: INFO: Pod "webserver-deployment-845c8977d9-9bx95": Phase="Running", Reason="", readiness=true. Elapsed: 2.020428184s
    Nov 12 13:09:56.106: INFO: Pod "webserver-deployment-845c8977d9-9bx95" satisfied condition "running"
    Nov 12 13:09:56.107: INFO: Pod "webserver-deployment-845c8977d9-ljsc5": Phase="Running", Reason="", readiness=true. Elapsed: 2.020590709s
    Nov 12 13:09:56.107: INFO: Pod "webserver-deployment-845c8977d9-ljsc5" satisfied condition "running"
    Nov 12 13:09:56.107: INFO: Waiting for deployment "webserver-deployment" to complete
    Nov 12 13:09:56.116: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Nov 12 13:09:56.128: INFO: Updating deployment webserver-deployment
    Nov 12 13:09:56.128: INFO: Waiting for observed generation 2
    Nov 12 13:09:58.140: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Nov 12 13:09:58.144: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Nov 12 13:09:58.149: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 12 13:09:58.160: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Nov 12 13:09:58.160: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Nov 12 13:09:58.163: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 12 13:09:58.171: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Nov 12 13:09:58.171: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Nov 12 13:09:58.182: INFO: Updating deployment webserver-deployment
    Nov 12 13:09:58.182: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Nov 12 13:09:58.191: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Nov 12 13:09:58.198: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 13:09:58.243: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-921  30252b76-387d-441e-b0f7-d141f902f552 34196 3 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004e8e768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-12 13:09:56 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 13:09:58 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Nov 12 13:09:58.255: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-921  77b741cc-f03d-4bab-b1bb-26b062018369 34188 3 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 30252b76-387d-441e-b0f7-d141f902f552 0xc003f70e97 0xc003f70e98}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30252b76-387d-441e-b0f7-d141f902f552\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f70f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 13:09:58.255: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Nov 12 13:09:58.255: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-921  207e3298-5c39-4254-930c-654ba6362c3e 34186 3 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 30252b76-387d-441e-b0f7-d141f902f552 0xc003f70f97 0xc003f70f98}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30252b76-387d-441e-b0f7-d141f902f552\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f71688 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-5tdqr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5tdqr webserver-deployment-69b7448995- deployment-921  7ba35364-10f6-41e5-93fd-4ad1e42f14a0 34201 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14077 0xc003a14078}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ssbxl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ssbxl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-8ckc2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-8ckc2 webserver-deployment-69b7448995- deployment-921  76540e52-39a0-470b-84ba-901d5dde7ed2 34108 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a141f0 0xc003a141f1}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dbbsg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dbbsg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-b9mzt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-b9mzt webserver-deployment-69b7448995- deployment-921  83369bd0-8e3b-4006-b983-cdfd3280aee6 34203 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a143e7 0xc003a143e8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6xqkf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6xqkf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.273: INFO: Pod "webserver-deployment-69b7448995-qfc7c" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qfc7c webserver-deployment-69b7448995- deployment-921  40820a3b-7d32-4e79-9738-03bebcae4572 34156 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14537 0xc003a14538}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.253\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xt6hh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xt6hh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.253,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.253,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-qn8bz" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qn8bz webserver-deployment-69b7448995- deployment-921  1d688d84-f10d-4ac3-8a0f-d13ada3d156a 34165 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14757 0xc003a14758}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.89\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h2zcp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h2zcp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.89,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-rmnsg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-rmnsg webserver-deployment-69b7448995- deployment-921  3514d6ba-3e4e-4483-99c4-6b79901dfd0d 34177 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14987 0xc003a14988}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.25\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kk7l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kk7l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.25,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.25,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-rngc5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-rngc5 webserver-deployment-69b7448995- deployment-921  1bc0deb5-b10b-427a-97b2-ada39e0857b6 34200 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14bc7 0xc003a14bc8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ndlw5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ndlw5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-69b7448995-zkbzx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-zkbzx webserver-deployment-69b7448995- deployment-921  e153d6a2-4431-4647-afb3-79d18bcdea43 34175 0 2022-11-12 13:09:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 77b741cc-f03d-4bab-b1bb-26b062018369 0xc003a14d17 0xc003a14d18}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"77b741cc-f03d-4bab-b1bb-26b062018369\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:57 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.41\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4jbz5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4jbz5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.41,StartTime:2022-11-12 13:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.274: INFO: Pod "webserver-deployment-845c8977d9-2s8z4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2s8z4 webserver-deployment-845c8977d9- deployment-921  fbf67387-9275-4f16-9b4d-390a2c6eea5b 34037 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a14f37 0xc003a14f38}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.92\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6k578,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6k578,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.92,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://346c397fcbb3cf469d458653841849b6c8970417d962143f7f8ed771c966c20e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.92,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-8drkp" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8drkp webserver-deployment-845c8977d9- deployment-921  d30be1c4-569b-464e-b2b9-ed038959f20f 34043 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15127 0xc003a15128}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.88\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhm2x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhm2x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.88,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://718f78efc73533316310928e6c0ac2b2e36bd63a58a709a66d6ae4eb1ed0a909,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.88,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-9bx95" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9bx95 webserver-deployment-845c8977d9- deployment-921  eef3494a-7b62-4c64-8191-e0d114b0a150 34046 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15317 0xc003a15318}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.26\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9jztm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9jztm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.26,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://08a2e01293e4a27d2e413f5fe36278364783d3fec1191c3b7a6d12c56da46478,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-bnx99" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bnx99 webserver-deployment-845c8977d9- deployment-921  90d8c0a6-5e0d-4826-af3d-e40ac88cf073 34055 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15967 0xc003a15968}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.54\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6p55w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6p55w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.54,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c0a1eaae44b1402dabca8bec2c0dc8617453914b69a6cdf917527931740d4e18,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-fjpp2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fjpp2 webserver-deployment-845c8977d9- deployment-921  fb5159f9-dcb3-40cb-9db4-8e1d41a9e5b1 34197 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15b67 0xc003a15b68}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-r6cbw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-r6cbw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-ggf62" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ggf62 webserver-deployment-845c8977d9- deployment-921  875c4509-148b-4ae0-bcc2-955aead9c57a 34030 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15cd0 0xc003a15cd1}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.252\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8sd9d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8sd9d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.252,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2cbf4ff222209b78124ccfb0835c2e5319961ffac76696a74697c77b5ae9d242,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.252,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-hkq6s" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hkq6s webserver-deployment-845c8977d9- deployment-921  4533e14a-098a-43a5-800d-61671075c5c4 34207 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15eb7 0xc003a15eb8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-54df4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-54df4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.275: INFO: Pod "webserver-deployment-845c8977d9-ljsc5" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ljsc5 webserver-deployment-845c8977d9- deployment-921  0aa6f479-a4f0-4f70-97df-bca40d213ac8 34034 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc003a15ff7 0xc003a15ff8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.128.242\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7gq8p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7gq8p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:192.168.128.242,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fd6e5d2bc157ea6eddf492000c8730e9c8f99ca2a1ddb748a79b8d86027f888c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.128.242,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-pf782" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-pf782 webserver-deployment-845c8977d9- deployment-921  c9480d03-f002-4eba-9cd3-d5bae3145552 34040 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e1f7 0xc00366e1f8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.27.93\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s425p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s425p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-47-219,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.47.219,PodIP:192.168.27.93,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fef7fc52bf72e6d8f3a42e7c6de9af294205c44dc618c659bc9406462fb35dfe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.27.93,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-r85b9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-r85b9 webserver-deployment-845c8977d9- deployment-921  ce55ac52-01a8-42bc-a619-9d12722cf152 34209 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e3e7 0xc00366e3e8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mcclk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mcclk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-rnrn7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rnrn7 webserver-deployment-845c8977d9- deployment-921  4a5bd042-b7ee-4e70-93b3-97c169a55164 34202 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e547 0xc00366e548}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qxh44,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qxh44,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-snjp2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-snjp2 webserver-deployment-845c8977d9- deployment-921  99ac857a-750e-4bbc-b81f-f29b0c511848 34208 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e6c0 0xc00366e6c1}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7267q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7267q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:,StartTime:2022-11-12 13:09:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-xtzjs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-xtzjs webserver-deployment-845c8977d9- deployment-921  24e9f595-8b2b-4063-913e-e9e3b36796f0 34206 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e887 0xc00366e888}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hjrl6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hjrl6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.276: INFO: Pod "webserver-deployment-845c8977d9-z296w" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-z296w webserver-deployment-845c8977d9- deployment-921  54f09638-2656-402d-a43d-30fd53f94098 34210 0 2022-11-12 13:09:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366e9c7 0xc00366e9c8}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-27lk2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-27lk2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:09:58.277: INFO: Pod "webserver-deployment-845c8977d9-z2t5f" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-z2t5f webserver-deployment-845c8977d9- deployment-921  cb7c9bda-9ec8-48a7-9523-15e8cf5fd7ea 34049 0 2022-11-12 13:09:52 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 207e3298-5c39-4254-930c-654ba6362c3e 0xc00366eb07 0xc00366eb08}] [] [{kube-controller-manager Update v1 2022-11-12 13:09:52 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"207e3298-5c39-4254-930c-654ba6362c3e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:09:54 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wkwmw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wkwmw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:09:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.10,StartTime:2022-11-12 13:09:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:09:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1f9b849876dfccaf457c5441c44b5b36fa9e3da012627a5a459dbcc4f1c89152,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.10,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 13:09:58.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-921" for this suite. 11/12/22 13:09:58.297
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:09:58.326
Nov 12 13:09:58.326: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 13:09:58.327
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:58.393
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:58.401
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-82f458cd-064a-4653-ad1e-8dd2a98ddb98 11/12/22 13:09:58.409
STEP: Creating a pod to test consume secrets 11/12/22 13:09:58.416
Nov 12 13:09:58.429: INFO: Waiting up to 5m0s for pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2" in namespace "secrets-2955" to be "Succeeded or Failed"
Nov 12 13:09:58.453: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.04845ms
Nov 12 13:10:00.460: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030446542s
Nov 12 13:10:02.460: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030561514s
Nov 12 13:10:04.465: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036077509s
STEP: Saw pod success 11/12/22 13:10:04.465
Nov 12 13:10:04.466: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2" satisfied condition "Succeeded or Failed"
Nov 12 13:10:04.477: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 13:10:05.234
Nov 12 13:10:05.250: INFO: Waiting for pod pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2 to disappear
Nov 12 13:10:05.255: INFO: Pod pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 13:10:05.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2955" for this suite. 11/12/22 13:10:05.259
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":278,"skipped":5228,"failed":0}
------------------------------
• [SLOW TEST] [6.945 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:09:58.326
    Nov 12 13:09:58.326: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 13:09:58.327
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:09:58.393
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:09:58.401
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-82f458cd-064a-4653-ad1e-8dd2a98ddb98 11/12/22 13:09:58.409
    STEP: Creating a pod to test consume secrets 11/12/22 13:09:58.416
    Nov 12 13:09:58.429: INFO: Waiting up to 5m0s for pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2" in namespace "secrets-2955" to be "Succeeded or Failed"
    Nov 12 13:09:58.453: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 24.04845ms
    Nov 12 13:10:00.460: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030446542s
    Nov 12 13:10:02.460: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030561514s
    Nov 12 13:10:04.465: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.036077509s
    STEP: Saw pod success 11/12/22 13:10:04.465
    Nov 12 13:10:04.466: INFO: Pod "pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2" satisfied condition "Succeeded or Failed"
    Nov 12 13:10:04.477: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 13:10:05.234
    Nov 12 13:10:05.250: INFO: Waiting for pod pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2 to disappear
    Nov 12 13:10:05.255: INFO: Pod pod-secrets-f839e539-d031-4439-ac79-6b18a2618ad2 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 13:10:05.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2955" for this suite. 11/12/22 13:10:05.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:05.273
Nov 12 13:10:05.273: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename containers 11/12/22 13:10:05.274
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:05.295
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:05.299
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 11/12/22 13:10:05.301
Nov 12 13:10:05.312: INFO: Waiting up to 5m0s for pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4" in namespace "containers-4694" to be "Succeeded or Failed"
Nov 12 13:10:05.326: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.704392ms
Nov 12 13:10:07.331: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019015539s
Nov 12 13:10:09.333: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021261269s
STEP: Saw pod success 11/12/22 13:10:09.333
Nov 12 13:10:09.333: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4" satisfied condition "Succeeded or Failed"
Nov 12 13:10:09.338: INFO: Trying to get logs from node ip-172-31-14-110 pod client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:10:09.348
Nov 12 13:10:09.443: INFO: Waiting for pod client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4 to disappear
Nov 12 13:10:09.448: INFO: Pod client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 12 13:10:09.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4694" for this suite. 11/12/22 13:10:09.456
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":279,"skipped":5268,"failed":0}
------------------------------
• [4.201 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:05.273
    Nov 12 13:10:05.273: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename containers 11/12/22 13:10:05.274
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:05.295
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:05.299
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 11/12/22 13:10:05.301
    Nov 12 13:10:05.312: INFO: Waiting up to 5m0s for pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4" in namespace "containers-4694" to be "Succeeded or Failed"
    Nov 12 13:10:05.326: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4": Phase="Pending", Reason="", readiness=false. Elapsed: 13.704392ms
    Nov 12 13:10:07.331: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019015539s
    Nov 12 13:10:09.333: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021261269s
    STEP: Saw pod success 11/12/22 13:10:09.333
    Nov 12 13:10:09.333: INFO: Pod "client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4" satisfied condition "Succeeded or Failed"
    Nov 12 13:10:09.338: INFO: Trying to get logs from node ip-172-31-14-110 pod client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:10:09.348
    Nov 12 13:10:09.443: INFO: Waiting for pod client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4 to disappear
    Nov 12 13:10:09.448: INFO: Pod client-containers-c1942499-b6c8-4c86-b463-be84cb8ce6c4 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 12 13:10:09.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-4694" for this suite. 11/12/22 13:10:09.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:09.478
Nov 12 13:10:09.480: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 13:10:09.481
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:09.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:09.53
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-0167449a-6632-4694-9d50-a9f1e5e30bc3 11/12/22 13:10:09.547
STEP: Creating the pod 11/12/22 13:10:09.558
Nov 12 13:10:09.575: INFO: Waiting up to 5m0s for pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a" in namespace "configmap-9484" to be "running"
Nov 12 13:10:09.583: INFO: Pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.356021ms
Nov 12 13:10:11.588: INFO: Pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a": Phase="Running", Reason="", readiness=false. Elapsed: 2.012614928s
Nov 12 13:10:11.588: INFO: Pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a" satisfied condition "running"
STEP: Waiting for pod with text data 11/12/22 13:10:11.588
STEP: Waiting for pod with binary data 11/12/22 13:10:11.597
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 13:10:11.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9484" for this suite. 11/12/22 13:10:11.614
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":280,"skipped":5298,"failed":0}
------------------------------
• [2.153 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:09.478
    Nov 12 13:10:09.480: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 13:10:09.481
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:09.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:09.53
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-0167449a-6632-4694-9d50-a9f1e5e30bc3 11/12/22 13:10:09.547
    STEP: Creating the pod 11/12/22 13:10:09.558
    Nov 12 13:10:09.575: INFO: Waiting up to 5m0s for pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a" in namespace "configmap-9484" to be "running"
    Nov 12 13:10:09.583: INFO: Pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.356021ms
    Nov 12 13:10:11.588: INFO: Pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a": Phase="Running", Reason="", readiness=false. Elapsed: 2.012614928s
    Nov 12 13:10:11.588: INFO: Pod "pod-configmaps-ebeb7528-ed2d-4c2e-92e5-b5146be6561a" satisfied condition "running"
    STEP: Waiting for pod with text data 11/12/22 13:10:11.588
    STEP: Waiting for pod with binary data 11/12/22 13:10:11.597
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 13:10:11.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9484" for this suite. 11/12/22 13:10:11.614
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:11.631
Nov 12 13:10:11.631: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename ingressclass 11/12/22 13:10:11.632
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:11.708
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:11.711
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 11/12/22 13:10:11.714
STEP: getting /apis/networking.k8s.io 11/12/22 13:10:11.716
STEP: getting /apis/networking.k8s.iov1 11/12/22 13:10:11.717
STEP: creating 11/12/22 13:10:11.718
STEP: getting 11/12/22 13:10:11.739
STEP: listing 11/12/22 13:10:11.754
STEP: watching 11/12/22 13:10:11.762
Nov 12 13:10:11.762: INFO: starting watch
STEP: patching 11/12/22 13:10:11.764
STEP: updating 11/12/22 13:10:11.782
Nov 12 13:10:11.790: INFO: waiting for watch events with expected annotations
Nov 12 13:10:11.790: INFO: saw patched and updated annotations
STEP: deleting 11/12/22 13:10:11.791
STEP: deleting a collection 11/12/22 13:10:11.811
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Nov 12 13:10:11.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-7621" for this suite. 11/12/22 13:10:11.84
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":281,"skipped":5299,"failed":0}
------------------------------
• [0.220 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:11.631
    Nov 12 13:10:11.631: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename ingressclass 11/12/22 13:10:11.632
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:11.708
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:11.711
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 11/12/22 13:10:11.714
    STEP: getting /apis/networking.k8s.io 11/12/22 13:10:11.716
    STEP: getting /apis/networking.k8s.iov1 11/12/22 13:10:11.717
    STEP: creating 11/12/22 13:10:11.718
    STEP: getting 11/12/22 13:10:11.739
    STEP: listing 11/12/22 13:10:11.754
    STEP: watching 11/12/22 13:10:11.762
    Nov 12 13:10:11.762: INFO: starting watch
    STEP: patching 11/12/22 13:10:11.764
    STEP: updating 11/12/22 13:10:11.782
    Nov 12 13:10:11.790: INFO: waiting for watch events with expected annotations
    Nov 12 13:10:11.790: INFO: saw patched and updated annotations
    STEP: deleting 11/12/22 13:10:11.791
    STEP: deleting a collection 11/12/22 13:10:11.811
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Nov 12 13:10:11.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-7621" for this suite. 11/12/22 13:10:11.84
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:11.853
Nov 12 13:10:11.853: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 13:10:11.854
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:11.879
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:11.882
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Nov 12 13:10:11.888: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: creating the pod 11/12/22 13:10:11.889
STEP: submitting the pod to kubernetes 11/12/22 13:10:11.889
Nov 12 13:10:11.902: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76" in namespace "pods-5039" to be "running and ready"
Nov 12 13:10:11.913: INFO: Pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76": Phase="Pending", Reason="", readiness=false. Elapsed: 10.868511ms
Nov 12 13:10:11.913: INFO: The phase of Pod pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:10:13.919: INFO: Pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76": Phase="Running", Reason="", readiness=true. Elapsed: 2.016630196s
Nov 12 13:10:13.919: INFO: The phase of Pod pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76 is Running (Ready = true)
Nov 12 13:10:13.919: INFO: Pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 13:10:14.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5039" for this suite. 11/12/22 13:10:14.019
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":282,"skipped":5300,"failed":0}
------------------------------
• [2.174 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:11.853
    Nov 12 13:10:11.853: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 13:10:11.854
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:11.879
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:11.882
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Nov 12 13:10:11.888: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: creating the pod 11/12/22 13:10:11.889
    STEP: submitting the pod to kubernetes 11/12/22 13:10:11.889
    Nov 12 13:10:11.902: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76" in namespace "pods-5039" to be "running and ready"
    Nov 12 13:10:11.913: INFO: Pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76": Phase="Pending", Reason="", readiness=false. Elapsed: 10.868511ms
    Nov 12 13:10:11.913: INFO: The phase of Pod pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:10:13.919: INFO: Pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76": Phase="Running", Reason="", readiness=true. Elapsed: 2.016630196s
    Nov 12 13:10:13.919: INFO: The phase of Pod pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76 is Running (Ready = true)
    Nov 12 13:10:13.919: INFO: Pod "pod-exec-websocket-45680040-18f4-4dec-933f-d7f10bdf9a76" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 13:10:14.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5039" for this suite. 11/12/22 13:10:14.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:14.028
Nov 12 13:10:14.028: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 13:10:14.029
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:14.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:14.053
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/12/22 13:10:14.056
Nov 12 13:10:14.078: INFO: Waiting up to 5m0s for pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df" in namespace "emptydir-495" to be "Succeeded or Failed"
Nov 12 13:10:14.086: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df": Phase="Pending", Reason="", readiness=false. Elapsed: 7.536042ms
Nov 12 13:10:16.090: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01201728s
Nov 12 13:10:18.093: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014147614s
STEP: Saw pod success 11/12/22 13:10:18.093
Nov 12 13:10:18.093: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df" satisfied condition "Succeeded or Failed"
Nov 12 13:10:18.097: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df container test-container: <nil>
STEP: delete the pod 11/12/22 13:10:18.106
Nov 12 13:10:18.120: INFO: Waiting for pod pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df to disappear
Nov 12 13:10:18.124: INFO: Pod pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 13:10:18.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-495" for this suite. 11/12/22 13:10:18.129
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":283,"skipped":5305,"failed":0}
------------------------------
• [4.110 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:14.028
    Nov 12 13:10:14.028: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 13:10:14.029
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:14.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:14.053
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/12/22 13:10:14.056
    Nov 12 13:10:14.078: INFO: Waiting up to 5m0s for pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df" in namespace "emptydir-495" to be "Succeeded or Failed"
    Nov 12 13:10:14.086: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df": Phase="Pending", Reason="", readiness=false. Elapsed: 7.536042ms
    Nov 12 13:10:16.090: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01201728s
    Nov 12 13:10:18.093: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014147614s
    STEP: Saw pod success 11/12/22 13:10:18.093
    Nov 12 13:10:18.093: INFO: Pod "pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df" satisfied condition "Succeeded or Failed"
    Nov 12 13:10:18.097: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df container test-container: <nil>
    STEP: delete the pod 11/12/22 13:10:18.106
    Nov 12 13:10:18.120: INFO: Waiting for pod pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df to disappear
    Nov 12 13:10:18.124: INFO: Pod pod-cdc74ca4-cc55-4c25-b0aa-a3063be400df no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 13:10:18.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-495" for this suite. 11/12/22 13:10:18.129
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:18.144
Nov 12 13:10:18.144: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename subpath 11/12/22 13:10:18.144
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:18.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:18.166
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/12/22 13:10:18.211
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-tm8s 11/12/22 13:10:18.23
STEP: Creating a pod to test atomic-volume-subpath 11/12/22 13:10:18.23
Nov 12 13:10:18.241: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tm8s" in namespace "subpath-5958" to be "Succeeded or Failed"
Nov 12 13:10:18.249: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Pending", Reason="", readiness=false. Elapsed: 8.617729ms
Nov 12 13:10:20.254: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 2.012993065s
Nov 12 13:10:22.257: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 4.016508218s
Nov 12 13:10:24.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 6.015049308s
Nov 12 13:10:26.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 8.014839132s
Nov 12 13:10:28.254: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 10.012721534s
Nov 12 13:10:30.258: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 12.017048509s
Nov 12 13:10:32.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 14.014928874s
Nov 12 13:10:34.255: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 16.014648792s
Nov 12 13:10:36.255: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 18.014200965s
Nov 12 13:10:38.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 20.015130087s
Nov 12 13:10:40.254: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=false. Elapsed: 22.013445794s
Nov 12 13:10:42.255: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013964445s
STEP: Saw pod success 11/12/22 13:10:42.255
Nov 12 13:10:42.255: INFO: Pod "pod-subpath-test-configmap-tm8s" satisfied condition "Succeeded or Failed"
Nov 12 13:10:42.260: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-configmap-tm8s container test-container-subpath-configmap-tm8s: <nil>
STEP: delete the pod 11/12/22 13:10:42.268
Nov 12 13:10:42.283: INFO: Waiting for pod pod-subpath-test-configmap-tm8s to disappear
Nov 12 13:10:42.287: INFO: Pod pod-subpath-test-configmap-tm8s no longer exists
STEP: Deleting pod pod-subpath-test-configmap-tm8s 11/12/22 13:10:42.287
Nov 12 13:10:42.288: INFO: Deleting pod "pod-subpath-test-configmap-tm8s" in namespace "subpath-5958"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 12 13:10:42.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5958" for this suite. 11/12/22 13:10:42.297
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":284,"skipped":5340,"failed":0}
------------------------------
• [SLOW TEST] [24.163 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:18.144
    Nov 12 13:10:18.144: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename subpath 11/12/22 13:10:18.144
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:18.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:18.166
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/12/22 13:10:18.211
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-tm8s 11/12/22 13:10:18.23
    STEP: Creating a pod to test atomic-volume-subpath 11/12/22 13:10:18.23
    Nov 12 13:10:18.241: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-tm8s" in namespace "subpath-5958" to be "Succeeded or Failed"
    Nov 12 13:10:18.249: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Pending", Reason="", readiness=false. Elapsed: 8.617729ms
    Nov 12 13:10:20.254: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 2.012993065s
    Nov 12 13:10:22.257: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 4.016508218s
    Nov 12 13:10:24.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 6.015049308s
    Nov 12 13:10:26.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 8.014839132s
    Nov 12 13:10:28.254: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 10.012721534s
    Nov 12 13:10:30.258: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 12.017048509s
    Nov 12 13:10:32.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 14.014928874s
    Nov 12 13:10:34.255: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 16.014648792s
    Nov 12 13:10:36.255: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 18.014200965s
    Nov 12 13:10:38.256: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=true. Elapsed: 20.015130087s
    Nov 12 13:10:40.254: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Running", Reason="", readiness=false. Elapsed: 22.013445794s
    Nov 12 13:10:42.255: INFO: Pod "pod-subpath-test-configmap-tm8s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013964445s
    STEP: Saw pod success 11/12/22 13:10:42.255
    Nov 12 13:10:42.255: INFO: Pod "pod-subpath-test-configmap-tm8s" satisfied condition "Succeeded or Failed"
    Nov 12 13:10:42.260: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-subpath-test-configmap-tm8s container test-container-subpath-configmap-tm8s: <nil>
    STEP: delete the pod 11/12/22 13:10:42.268
    Nov 12 13:10:42.283: INFO: Waiting for pod pod-subpath-test-configmap-tm8s to disappear
    Nov 12 13:10:42.287: INFO: Pod pod-subpath-test-configmap-tm8s no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-tm8s 11/12/22 13:10:42.287
    Nov 12 13:10:42.288: INFO: Deleting pod "pod-subpath-test-configmap-tm8s" in namespace "subpath-5958"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 12 13:10:42.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5958" for this suite. 11/12/22 13:10:42.297
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:42.31
Nov 12 13:10:42.310: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename job 11/12/22 13:10:42.312
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:42.349
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:42.356
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 11/12/22 13:10:42.363
STEP: Ensuring job reaches completions 11/12/22 13:10:42.376
STEP: Ensuring pods with index for job exist 11/12/22 13:10:52.382
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 12 13:10:52.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8319" for this suite. 11/12/22 13:10:52.392
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":285,"skipped":5355,"failed":0}
------------------------------
• [SLOW TEST] [10.092 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:42.31
    Nov 12 13:10:42.310: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename job 11/12/22 13:10:42.312
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:42.349
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:42.356
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 11/12/22 13:10:42.363
    STEP: Ensuring job reaches completions 11/12/22 13:10:42.376
    STEP: Ensuring pods with index for job exist 11/12/22 13:10:52.382
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 12 13:10:52.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-8319" for this suite. 11/12/22 13:10:52.392
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:52.404
Nov 12 13:10:52.404: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:10:52.405
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:52.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:52.44
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:10:52.453
Nov 12 13:10:52.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3" in namespace "downward-api-1427" to be "Succeeded or Failed"
Nov 12 13:10:52.485: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.072457ms
Nov 12 13:10:54.496: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020243798s
Nov 12 13:10:56.492: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015812105s
STEP: Saw pod success 11/12/22 13:10:56.492
Nov 12 13:10:56.492: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3" satisfied condition "Succeeded or Failed"
Nov 12 13:10:56.498: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3 container client-container: <nil>
STEP: delete the pod 11/12/22 13:10:56.513
Nov 12 13:10:56.535: INFO: Waiting for pod downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3 to disappear
Nov 12 13:10:56.540: INFO: Pod downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:10:56.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1427" for this suite. 11/12/22 13:10:56.545
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":286,"skipped":5364,"failed":0}
------------------------------
• [4.154 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:52.404
    Nov 12 13:10:52.404: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:10:52.405
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:52.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:52.44
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:10:52.453
    Nov 12 13:10:52.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3" in namespace "downward-api-1427" to be "Succeeded or Failed"
    Nov 12 13:10:52.485: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.072457ms
    Nov 12 13:10:54.496: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020243798s
    Nov 12 13:10:56.492: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015812105s
    STEP: Saw pod success 11/12/22 13:10:56.492
    Nov 12 13:10:56.492: INFO: Pod "downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3" satisfied condition "Succeeded or Failed"
    Nov 12 13:10:56.498: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3 container client-container: <nil>
    STEP: delete the pod 11/12/22 13:10:56.513
    Nov 12 13:10:56.535: INFO: Waiting for pod downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3 to disappear
    Nov 12 13:10:56.540: INFO: Pod downwardapi-volume-d778ec2d-9f9f-427e-91b3-554361d3e6d3 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:10:56.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1427" for this suite. 11/12/22 13:10:56.545
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:10:56.558
Nov 12 13:10:56.559: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:10:56.56
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:56.581
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:56.585
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9818 11/12/22 13:10:56.587
STEP: changing the ExternalName service to type=NodePort 11/12/22 13:10:56.593
STEP: creating replication controller externalname-service in namespace services-9818 11/12/22 13:10:56.634
I1112 13:10:56.650870      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9818, replica count: 2
I1112 13:10:59.701919      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 13:10:59.702: INFO: Creating new exec pod
Nov 12 13:10:59.719: INFO: Waiting up to 5m0s for pod "execpod4jmqx" in namespace "services-9818" to be "running"
Nov 12 13:10:59.726: INFO: Pod "execpod4jmqx": Phase="Pending", Reason="", readiness=false. Elapsed: 7.599151ms
Nov 12 13:11:01.732: INFO: Pod "execpod4jmqx": Phase="Running", Reason="", readiness=true. Elapsed: 2.013218282s
Nov 12 13:11:01.732: INFO: Pod "execpod4jmqx" satisfied condition "running"
Nov 12 13:11:02.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 12 13:11:02.977: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 12 13:11:02.979: INFO: stdout: "externalname-service-jq6wl"
Nov 12 13:11:02.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
Nov 12 13:11:03.150: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
Nov 12 13:11:03.151: INFO: stdout: "externalname-service-jq6wl"
Nov 12 13:11:03.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.14.110 31125'
Nov 12 13:11:03.380: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.14.110 31125\nConnection to 172.31.14.110 31125 port [tcp/*] succeeded!\n"
Nov 12 13:11:03.380: INFO: stdout: "externalname-service-jq6wl"
Nov 12 13:11:03.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.47.219 31125'
Nov 12 13:11:03.557: INFO: stderr: "+ nc -v -t -w 2 172.31.47.219 31125\n+ echo hostName\nConnection to 172.31.47.219 31125 port [tcp/*] succeeded!\n"
Nov 12 13:11:03.557: INFO: stdout: "externalname-service-jq6wl"
Nov 12 13:11:03.557: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:11:03.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9818" for this suite. 11/12/22 13:11:03.623
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":287,"skipped":5365,"failed":0}
------------------------------
• [SLOW TEST] [7.086 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:10:56.558
    Nov 12 13:10:56.559: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:10:56.56
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:10:56.581
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:10:56.585
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-9818 11/12/22 13:10:56.587
    STEP: changing the ExternalName service to type=NodePort 11/12/22 13:10:56.593
    STEP: creating replication controller externalname-service in namespace services-9818 11/12/22 13:10:56.634
    I1112 13:10:56.650870      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9818, replica count: 2
    I1112 13:10:59.701919      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 13:10:59.702: INFO: Creating new exec pod
    Nov 12 13:10:59.719: INFO: Waiting up to 5m0s for pod "execpod4jmqx" in namespace "services-9818" to be "running"
    Nov 12 13:10:59.726: INFO: Pod "execpod4jmqx": Phase="Pending", Reason="", readiness=false. Elapsed: 7.599151ms
    Nov 12 13:11:01.732: INFO: Pod "execpod4jmqx": Phase="Running", Reason="", readiness=true. Elapsed: 2.013218282s
    Nov 12 13:11:01.732: INFO: Pod "execpod4jmqx" satisfied condition "running"
    Nov 12 13:11:02.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 12 13:11:02.977: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 12 13:11:02.979: INFO: stdout: "externalname-service-jq6wl"
    Nov 12 13:11:02.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
    Nov 12 13:11:03.150: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
    Nov 12 13:11:03.151: INFO: stdout: "externalname-service-jq6wl"
    Nov 12 13:11:03.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.14.110 31125'
    Nov 12 13:11:03.380: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.14.110 31125\nConnection to 172.31.14.110 31125 port [tcp/*] succeeded!\n"
    Nov 12 13:11:03.380: INFO: stdout: "externalname-service-jq6wl"
    Nov 12 13:11:03.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-9818 exec execpod4jmqx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.47.219 31125'
    Nov 12 13:11:03.557: INFO: stderr: "+ nc -v -t -w 2 172.31.47.219 31125\n+ echo hostName\nConnection to 172.31.47.219 31125 port [tcp/*] succeeded!\n"
    Nov 12 13:11:03.557: INFO: stdout: "externalname-service-jq6wl"
    Nov 12 13:11:03.557: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:11:03.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9818" for this suite. 11/12/22 13:11:03.623
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:03.645
Nov 12 13:11:03.645: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename runtimeclass 11/12/22 13:11:03.645
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:03.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:03.675
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Nov 12 13:11:03.703: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-6091 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 13:11:03.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6091" for this suite. 11/12/22 13:11:03.739
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":288,"skipped":5367,"failed":0}
------------------------------
• [0.103 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:03.645
    Nov 12 13:11:03.645: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 13:11:03.645
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:03.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:03.675
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Nov 12 13:11:03.703: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-6091 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 13:11:03.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6091" for this suite. 11/12/22 13:11:03.739
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:03.749
Nov 12 13:11:03.749: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:11:03.75
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:03.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:03.771
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-4fbe333a-19a8-40d9-a8f4-24d82ab019df 11/12/22 13:11:03.776
STEP: Creating a pod to test consume configMaps 11/12/22 13:11:03.783
Nov 12 13:11:03.799: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c" in namespace "projected-8000" to be "Succeeded or Failed"
Nov 12 13:11:03.803: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.409816ms
Nov 12 13:11:05.809: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Running", Reason="", readiness=true. Elapsed: 2.009900008s
Nov 12 13:11:07.810: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Running", Reason="", readiness=false. Elapsed: 4.010670972s
Nov 12 13:11:09.808: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009502926s
STEP: Saw pod success 11/12/22 13:11:09.808
Nov 12 13:11:09.809: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c" satisfied condition "Succeeded or Failed"
Nov 12 13:11:09.813: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:11:09.821
Nov 12 13:11:09.836: INFO: Waiting for pod pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c to disappear
Nov 12 13:11:09.840: INFO: Pod pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 13:11:09.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8000" for this suite. 11/12/22 13:11:09.845
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":289,"skipped":5376,"failed":0}
------------------------------
• [SLOW TEST] [6.105 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:03.749
    Nov 12 13:11:03.749: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:11:03.75
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:03.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:03.771
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-4fbe333a-19a8-40d9-a8f4-24d82ab019df 11/12/22 13:11:03.776
    STEP: Creating a pod to test consume configMaps 11/12/22 13:11:03.783
    Nov 12 13:11:03.799: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c" in namespace "projected-8000" to be "Succeeded or Failed"
    Nov 12 13:11:03.803: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.409816ms
    Nov 12 13:11:05.809: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Running", Reason="", readiness=true. Elapsed: 2.009900008s
    Nov 12 13:11:07.810: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Running", Reason="", readiness=false. Elapsed: 4.010670972s
    Nov 12 13:11:09.808: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009502926s
    STEP: Saw pod success 11/12/22 13:11:09.808
    Nov 12 13:11:09.809: INFO: Pod "pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c" satisfied condition "Succeeded or Failed"
    Nov 12 13:11:09.813: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:11:09.821
    Nov 12 13:11:09.836: INFO: Waiting for pod pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c to disappear
    Nov 12 13:11:09.840: INFO: Pod pod-projected-configmaps-ec3b934c-b7a4-4754-afe2-a8cc3c2f671c no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 13:11:09.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8000" for this suite. 11/12/22 13:11:09.845
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:09.855
Nov 12 13:11:09.856: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename proxy 11/12/22 13:11:09.856
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:09.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:09.881
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Nov 12 13:11:09.895: INFO: Creating pod...
Nov 12 13:11:09.907: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-8491" to be "running"
Nov 12 13:11:09.915: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 8.431238ms
Nov 12 13:11:11.922: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01469239s
Nov 12 13:11:13.921: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.014531943s
Nov 12 13:11:13.922: INFO: Pod "agnhost" satisfied condition "running"
Nov 12 13:11:13.922: INFO: Creating service...
Nov 12 13:11:13.938: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=DELETE
Nov 12 13:11:13.956: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 13:11:13.956: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=OPTIONS
Nov 12 13:11:13.961: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 13:11:13.961: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=PATCH
Nov 12 13:11:13.967: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 13:11:13.967: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=POST
Nov 12 13:11:13.974: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 13:11:13.974: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=PUT
Nov 12 13:11:13.979: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 12 13:11:13.979: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=DELETE
Nov 12 13:11:13.989: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 12 13:11:13.989: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=OPTIONS
Nov 12 13:11:14.001: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 12 13:11:14.001: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=PATCH
Nov 12 13:11:14.009: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 12 13:11:14.010: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=POST
Nov 12 13:11:14.019: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 12 13:11:14.019: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=PUT
Nov 12 13:11:14.028: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 12 13:11:14.028: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=GET
Nov 12 13:11:14.033: INFO: http.Client request:GET StatusCode:301
Nov 12 13:11:14.033: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=GET
Nov 12 13:11:14.045: INFO: http.Client request:GET StatusCode:301
Nov 12 13:11:14.046: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=HEAD
Nov 12 13:11:14.051: INFO: http.Client request:HEAD StatusCode:301
Nov 12 13:11:14.051: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=HEAD
Nov 12 13:11:14.059: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 12 13:11:14.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8491" for this suite. 11/12/22 13:11:14.065
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":290,"skipped":5398,"failed":0}
------------------------------
• [4.220 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:09.855
    Nov 12 13:11:09.856: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename proxy 11/12/22 13:11:09.856
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:09.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:09.881
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Nov 12 13:11:09.895: INFO: Creating pod...
    Nov 12 13:11:09.907: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-8491" to be "running"
    Nov 12 13:11:09.915: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 8.431238ms
    Nov 12 13:11:11.922: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01469239s
    Nov 12 13:11:13.921: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 4.014531943s
    Nov 12 13:11:13.922: INFO: Pod "agnhost" satisfied condition "running"
    Nov 12 13:11:13.922: INFO: Creating service...
    Nov 12 13:11:13.938: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=DELETE
    Nov 12 13:11:13.956: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 13:11:13.956: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=OPTIONS
    Nov 12 13:11:13.961: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 13:11:13.961: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=PATCH
    Nov 12 13:11:13.967: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 13:11:13.967: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=POST
    Nov 12 13:11:13.974: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 13:11:13.974: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=PUT
    Nov 12 13:11:13.979: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 12 13:11:13.979: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=DELETE
    Nov 12 13:11:13.989: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 12 13:11:13.989: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Nov 12 13:11:14.001: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 12 13:11:14.001: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=PATCH
    Nov 12 13:11:14.009: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 12 13:11:14.010: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=POST
    Nov 12 13:11:14.019: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 12 13:11:14.019: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=PUT
    Nov 12 13:11:14.028: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 12 13:11:14.028: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=GET
    Nov 12 13:11:14.033: INFO: http.Client request:GET StatusCode:301
    Nov 12 13:11:14.033: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=GET
    Nov 12 13:11:14.045: INFO: http.Client request:GET StatusCode:301
    Nov 12 13:11:14.046: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/pods/agnhost/proxy?method=HEAD
    Nov 12 13:11:14.051: INFO: http.Client request:HEAD StatusCode:301
    Nov 12 13:11:14.051: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8491/services/e2e-proxy-test-service/proxy?method=HEAD
    Nov 12 13:11:14.059: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 12 13:11:14.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-8491" for this suite. 11/12/22 13:11:14.065
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:14.078
Nov 12 13:11:14.078: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:11:14.08
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:14.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:14.107
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Nov 12 13:11:14.112: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 13:11:16.77
Nov 12 13:11:16.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 create -f -'
Nov 12 13:11:17.291: INFO: stderr: ""
Nov 12 13:11:17.291: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 12 13:11:17.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 delete e2e-test-crd-publish-openapi-9107-crds test-cr'
Nov 12 13:11:17.403: INFO: stderr: ""
Nov 12 13:11:17.403: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov 12 13:11:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 apply -f -'
Nov 12 13:11:17.601: INFO: stderr: ""
Nov 12 13:11:17.601: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 12 13:11:17.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 delete e2e-test-crd-publish-openapi-9107-crds test-cr'
Nov 12 13:11:17.678: INFO: stderr: ""
Nov 12 13:11:17.678: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 11/12/22 13:11:17.678
Nov 12 13:11:17.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 explain e2e-test-crd-publish-openapi-9107-crds'
Nov 12 13:11:17.859: INFO: stderr: ""
Nov 12 13:11:17.859: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9107-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:11:20.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8682" for this suite. 11/12/22 13:11:20.41
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":291,"skipped":5408,"failed":0}
------------------------------
• [SLOW TEST] [6.344 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:14.078
    Nov 12 13:11:14.078: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:11:14.08
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:14.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:14.107
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Nov 12 13:11:14.112: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/12/22 13:11:16.77
    Nov 12 13:11:16.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 create -f -'
    Nov 12 13:11:17.291: INFO: stderr: ""
    Nov 12 13:11:17.291: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 12 13:11:17.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 delete e2e-test-crd-publish-openapi-9107-crds test-cr'
    Nov 12 13:11:17.403: INFO: stderr: ""
    Nov 12 13:11:17.403: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Nov 12 13:11:17.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 apply -f -'
    Nov 12 13:11:17.601: INFO: stderr: ""
    Nov 12 13:11:17.601: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 12 13:11:17.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 --namespace=crd-publish-openapi-8682 delete e2e-test-crd-publish-openapi-9107-crds test-cr'
    Nov 12 13:11:17.678: INFO: stderr: ""
    Nov 12 13:11:17.678: INFO: stdout: "e2e-test-crd-publish-openapi-9107-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 11/12/22 13:11:17.678
    Nov 12 13:11:17.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=crd-publish-openapi-8682 explain e2e-test-crd-publish-openapi-9107-crds'
    Nov 12 13:11:17.859: INFO: stderr: ""
    Nov 12 13:11:17.859: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9107-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:11:20.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8682" for this suite. 11/12/22 13:11:20.41
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:20.424
Nov 12 13:11:20.424: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename emptydir 11/12/22 13:11:20.425
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:20.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:20.451
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 11/12/22 13:11:20.468
Nov 12 13:11:20.481: INFO: Waiting up to 5m0s for pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1" in namespace "emptydir-6809" to be "Succeeded or Failed"
Nov 12 13:11:20.486: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.851672ms
Nov 12 13:11:22.493: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011042251s
Nov 12 13:11:24.494: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012593539s
STEP: Saw pod success 11/12/22 13:11:24.494
Nov 12 13:11:24.494: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1" satisfied condition "Succeeded or Failed"
Nov 12 13:11:24.514: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-09ef972c-79d1-424c-83b9-0143a7cf19b1 container test-container: <nil>
STEP: delete the pod 11/12/22 13:11:24.538
Nov 12 13:11:24.556: INFO: Waiting for pod pod-09ef972c-79d1-424c-83b9-0143a7cf19b1 to disappear
Nov 12 13:11:24.561: INFO: Pod pod-09ef972c-79d1-424c-83b9-0143a7cf19b1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 12 13:11:24.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6809" for this suite. 11/12/22 13:11:24.568
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":292,"skipped":5417,"failed":0}
------------------------------
• [4.157 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:20.424
    Nov 12 13:11:20.424: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename emptydir 11/12/22 13:11:20.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:20.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:20.451
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/12/22 13:11:20.468
    Nov 12 13:11:20.481: INFO: Waiting up to 5m0s for pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1" in namespace "emptydir-6809" to be "Succeeded or Failed"
    Nov 12 13:11:20.486: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.851672ms
    Nov 12 13:11:22.493: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011042251s
    Nov 12 13:11:24.494: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012593539s
    STEP: Saw pod success 11/12/22 13:11:24.494
    Nov 12 13:11:24.494: INFO: Pod "pod-09ef972c-79d1-424c-83b9-0143a7cf19b1" satisfied condition "Succeeded or Failed"
    Nov 12 13:11:24.514: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-09ef972c-79d1-424c-83b9-0143a7cf19b1 container test-container: <nil>
    STEP: delete the pod 11/12/22 13:11:24.538
    Nov 12 13:11:24.556: INFO: Waiting for pod pod-09ef972c-79d1-424c-83b9-0143a7cf19b1 to disappear
    Nov 12 13:11:24.561: INFO: Pod pod-09ef972c-79d1-424c-83b9-0143a7cf19b1 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 12 13:11:24.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6809" for this suite. 11/12/22 13:11:24.568
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:24.583
Nov 12 13:11:24.583: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:11:24.587
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:24.635
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:24.64
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:11:24.645
Nov 12 13:11:24.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a" in namespace "downward-api-1999" to be "Succeeded or Failed"
Nov 12 13:11:24.666: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.204482ms
Nov 12 13:11:26.672: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012302368s
Nov 12 13:11:28.673: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013374371s
STEP: Saw pod success 11/12/22 13:11:28.673
Nov 12 13:11:28.673: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a" satisfied condition "Succeeded or Failed"
Nov 12 13:11:28.678: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a container client-container: <nil>
STEP: delete the pod 11/12/22 13:11:28.687
Nov 12 13:11:28.707: INFO: Waiting for pod downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a to disappear
Nov 12 13:11:28.712: INFO: Pod downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:11:28.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1999" for this suite. 11/12/22 13:11:28.718
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":293,"skipped":5428,"failed":0}
------------------------------
• [4.145 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:24.583
    Nov 12 13:11:24.583: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:11:24.587
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:24.635
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:24.64
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:11:24.645
    Nov 12 13:11:24.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a" in namespace "downward-api-1999" to be "Succeeded or Failed"
    Nov 12 13:11:24.666: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.204482ms
    Nov 12 13:11:26.672: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012302368s
    Nov 12 13:11:28.673: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013374371s
    STEP: Saw pod success 11/12/22 13:11:28.673
    Nov 12 13:11:28.673: INFO: Pod "downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a" satisfied condition "Succeeded or Failed"
    Nov 12 13:11:28.678: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a container client-container: <nil>
    STEP: delete the pod 11/12/22 13:11:28.687
    Nov 12 13:11:28.707: INFO: Waiting for pod downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a to disappear
    Nov 12 13:11:28.712: INFO: Pod downwardapi-volume-090f8993-3593-43de-b61f-7102d5e6aa2a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:11:28.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1999" for this suite. 11/12/22 13:11:28.718
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:28.731
Nov 12 13:11:28.732: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename security-context-test 11/12/22 13:11:28.733
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:28.768
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:28.774
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Nov 12 13:11:28.796: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3" in namespace "security-context-test-6644" to be "Succeeded or Failed"
Nov 12 13:11:28.807: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.177356ms
Nov 12 13:11:30.813: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016181866s
Nov 12 13:11:32.817: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020172672s
Nov 12 13:11:32.817: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 12 13:11:32.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6644" for this suite. 11/12/22 13:11:32.823
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":294,"skipped":5437,"failed":0}
------------------------------
• [4.102 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:28.731
    Nov 12 13:11:28.732: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename security-context-test 11/12/22 13:11:28.733
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:28.768
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:28.774
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Nov 12 13:11:28.796: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3" in namespace "security-context-test-6644" to be "Succeeded or Failed"
    Nov 12 13:11:28.807: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.177356ms
    Nov 12 13:11:30.813: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016181866s
    Nov 12 13:11:32.817: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020172672s
    Nov 12 13:11:32.817: INFO: Pod "busybox-readonly-false-74cc288b-5582-4fee-ba2c-a810102028d3" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 12 13:11:32.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6644" for this suite. 11/12/22 13:11:32.823
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:32.837
Nov 12 13:11:32.837: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename containers 11/12/22 13:11:32.839
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:32.866
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:32.871
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 11/12/22 13:11:32.874
Nov 12 13:11:32.887: INFO: Waiting up to 5m0s for pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c" in namespace "containers-8659" to be "Succeeded or Failed"
Nov 12 13:11:32.892: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801615ms
Nov 12 13:11:34.899: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012012037s
Nov 12 13:11:36.898: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011308909s
STEP: Saw pod success 11/12/22 13:11:36.898
Nov 12 13:11:36.898: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c" satisfied condition "Succeeded or Failed"
Nov 12 13:11:36.909: INFO: Trying to get logs from node ip-172-31-14-110 pod client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:11:36.918
Nov 12 13:11:36.937: INFO: Waiting for pod client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c to disappear
Nov 12 13:11:36.943: INFO: Pod client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 12 13:11:36.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8659" for this suite. 11/12/22 13:11:36.95
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":295,"skipped":5460,"failed":0}
------------------------------
• [4.222 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:32.837
    Nov 12 13:11:32.837: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename containers 11/12/22 13:11:32.839
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:32.866
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:32.871
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 11/12/22 13:11:32.874
    Nov 12 13:11:32.887: INFO: Waiting up to 5m0s for pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c" in namespace "containers-8659" to be "Succeeded or Failed"
    Nov 12 13:11:32.892: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.801615ms
    Nov 12 13:11:34.899: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012012037s
    Nov 12 13:11:36.898: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011308909s
    STEP: Saw pod success 11/12/22 13:11:36.898
    Nov 12 13:11:36.898: INFO: Pod "client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c" satisfied condition "Succeeded or Failed"
    Nov 12 13:11:36.909: INFO: Trying to get logs from node ip-172-31-14-110 pod client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:11:36.918
    Nov 12 13:11:36.937: INFO: Waiting for pod client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c to disappear
    Nov 12 13:11:36.943: INFO: Pod client-containers-d5684e49-1bf3-487f-9bc2-b697661eaf7c no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 12 13:11:36.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8659" for this suite. 11/12/22 13:11:36.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:37.062
Nov 12 13:11:37.062: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename gc 11/12/22 13:11:37.062
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:37.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:37.105
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Nov 12 13:11:37.166: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4dfbb13a-ac01-4aa5-be41-36354a5b2631", Controller:(*bool)(0xc0053ab5b6), BlockOwnerDeletion:(*bool)(0xc0053ab5b7)}}
Nov 12 13:11:37.175: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"29184f7c-7275-444d-ad58-a286dbc5c228", Controller:(*bool)(0xc0053ab8e6), BlockOwnerDeletion:(*bool)(0xc0053ab8e7)}}
Nov 12 13:11:37.192: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"aeba5c2b-a336-401f-be2c-28f8e46d12e5", Controller:(*bool)(0xc005339f0e), BlockOwnerDeletion:(*bool)(0xc005339f0f)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 13:11:42.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2936" for this suite. 11/12/22 13:11:42.214
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":296,"skipped":5495,"failed":0}
------------------------------
• [SLOW TEST] [5.162 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:37.062
    Nov 12 13:11:37.062: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename gc 11/12/22 13:11:37.062
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:37.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:37.105
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Nov 12 13:11:37.166: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4dfbb13a-ac01-4aa5-be41-36354a5b2631", Controller:(*bool)(0xc0053ab5b6), BlockOwnerDeletion:(*bool)(0xc0053ab5b7)}}
    Nov 12 13:11:37.175: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"29184f7c-7275-444d-ad58-a286dbc5c228", Controller:(*bool)(0xc0053ab8e6), BlockOwnerDeletion:(*bool)(0xc0053ab8e7)}}
    Nov 12 13:11:37.192: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"aeba5c2b-a336-401f-be2c-28f8e46d12e5", Controller:(*bool)(0xc005339f0e), BlockOwnerDeletion:(*bool)(0xc005339f0f)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 13:11:42.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2936" for this suite. 11/12/22 13:11:42.214
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:42.225
Nov 12 13:11:42.225: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 13:11:42.226
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:42.251
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:42.255
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 11/12/22 13:11:42.259
Nov 12 13:11:42.272: INFO: Waiting up to 5m0s for pod "pod-27nsw" in namespace "pods-7694" to be "running"
Nov 12 13:11:42.282: INFO: Pod "pod-27nsw": Phase="Pending", Reason="", readiness=false. Elapsed: 9.539697ms
Nov 12 13:11:44.287: INFO: Pod "pod-27nsw": Phase="Running", Reason="", readiness=true. Elapsed: 2.014800068s
Nov 12 13:11:44.287: INFO: Pod "pod-27nsw" satisfied condition "running"
STEP: patching /status 11/12/22 13:11:44.287
Nov 12 13:11:44.298: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 13:11:44.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7694" for this suite. 11/12/22 13:11:44.304
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":297,"skipped":5500,"failed":0}
------------------------------
• [2.090 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:42.225
    Nov 12 13:11:42.225: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 13:11:42.226
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:42.251
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:42.255
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 11/12/22 13:11:42.259
    Nov 12 13:11:42.272: INFO: Waiting up to 5m0s for pod "pod-27nsw" in namespace "pods-7694" to be "running"
    Nov 12 13:11:42.282: INFO: Pod "pod-27nsw": Phase="Pending", Reason="", readiness=false. Elapsed: 9.539697ms
    Nov 12 13:11:44.287: INFO: Pod "pod-27nsw": Phase="Running", Reason="", readiness=true. Elapsed: 2.014800068s
    Nov 12 13:11:44.287: INFO: Pod "pod-27nsw" satisfied condition "running"
    STEP: patching /status 11/12/22 13:11:44.287
    Nov 12 13:11:44.298: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 13:11:44.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7694" for this suite. 11/12/22 13:11:44.304
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:44.317
Nov 12 13:11:44.317: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 13:11:44.319
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:44.347
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:44.351
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2401 11/12/22 13:11:44.36
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 11/12/22 13:11:44.369
STEP: Creating pod with conflicting port in namespace statefulset-2401 11/12/22 13:11:44.382
STEP: Waiting until pod test-pod will start running in namespace statefulset-2401 11/12/22 13:11:44.4
Nov 12 13:11:44.401: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2401" to be "running"
Nov 12 13:11:44.407: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.573285ms
Nov 12 13:11:46.416: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014592473s
Nov 12 13:11:46.416: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-2401 11/12/22 13:11:46.416
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2401 11/12/22 13:11:46.424
Nov 12 13:11:46.454: INFO: Observed stateful pod in namespace: statefulset-2401, name: ss-0, uid: f90859a9-8623-4e4b-a112-5abeaa69d551, status phase: Pending. Waiting for statefulset controller to delete.
Nov 12 13:11:46.477: INFO: Observed stateful pod in namespace: statefulset-2401, name: ss-0, uid: f90859a9-8623-4e4b-a112-5abeaa69d551, status phase: Failed. Waiting for statefulset controller to delete.
Nov 12 13:11:46.486: INFO: Observed stateful pod in namespace: statefulset-2401, name: ss-0, uid: f90859a9-8623-4e4b-a112-5abeaa69d551, status phase: Failed. Waiting for statefulset controller to delete.
Nov 12 13:11:46.492: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2401
STEP: Removing pod with conflicting port in namespace statefulset-2401 11/12/22 13:11:46.492
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2401 and will be in running state 11/12/22 13:11:46.507
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 13:11:48.523: INFO: Deleting all statefulset in ns statefulset-2401
Nov 12 13:11:48.528: INFO: Scaling statefulset ss to 0
Nov 12 13:11:58.554: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 13:11:58.559: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 13:11:58.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2401" for this suite. 11/12/22 13:11:58.586
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":298,"skipped":5522,"failed":0}
------------------------------
• [SLOW TEST] [14.279 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:44.317
    Nov 12 13:11:44.317: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 13:11:44.319
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:44.347
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:44.351
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-2401 11/12/22 13:11:44.36
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 11/12/22 13:11:44.369
    STEP: Creating pod with conflicting port in namespace statefulset-2401 11/12/22 13:11:44.382
    STEP: Waiting until pod test-pod will start running in namespace statefulset-2401 11/12/22 13:11:44.4
    Nov 12 13:11:44.401: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-2401" to be "running"
    Nov 12 13:11:44.407: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.573285ms
    Nov 12 13:11:46.416: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014592473s
    Nov 12 13:11:46.416: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-2401 11/12/22 13:11:46.416
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2401 11/12/22 13:11:46.424
    Nov 12 13:11:46.454: INFO: Observed stateful pod in namespace: statefulset-2401, name: ss-0, uid: f90859a9-8623-4e4b-a112-5abeaa69d551, status phase: Pending. Waiting for statefulset controller to delete.
    Nov 12 13:11:46.477: INFO: Observed stateful pod in namespace: statefulset-2401, name: ss-0, uid: f90859a9-8623-4e4b-a112-5abeaa69d551, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 12 13:11:46.486: INFO: Observed stateful pod in namespace: statefulset-2401, name: ss-0, uid: f90859a9-8623-4e4b-a112-5abeaa69d551, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 12 13:11:46.492: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2401
    STEP: Removing pod with conflicting port in namespace statefulset-2401 11/12/22 13:11:46.492
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2401 and will be in running state 11/12/22 13:11:46.507
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 13:11:48.523: INFO: Deleting all statefulset in ns statefulset-2401
    Nov 12 13:11:48.528: INFO: Scaling statefulset ss to 0
    Nov 12 13:11:58.554: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 13:11:58.559: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 13:11:58.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-2401" for this suite. 11/12/22 13:11:58.586
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:11:58.597
Nov 12 13:11:58.598: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:11:58.599
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:58.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:58.679
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-6339b0df-a877-4ed6-b429-fca8bbf6bf90 11/12/22 13:11:58.681
STEP: Creating a pod to test consume secrets 11/12/22 13:11:58.688
Nov 12 13:11:58.705: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa" in namespace "projected-1420" to be "Succeeded or Failed"
Nov 12 13:11:58.713: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 7.739619ms
Nov 12 13:12:00.719: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013655731s
Nov 12 13:12:02.718: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013490984s
STEP: Saw pod success 11/12/22 13:12:02.718
Nov 12 13:12:02.719: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa" satisfied condition "Succeeded or Failed"
Nov 12 13:12:02.724: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa container projected-secret-volume-test: <nil>
STEP: delete the pod 11/12/22 13:12:02.733
Nov 12 13:12:02.756: INFO: Waiting for pod pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa to disappear
Nov 12 13:12:02.760: INFO: Pod pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 12 13:12:02.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1420" for this suite. 11/12/22 13:12:02.769
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":299,"skipped":5537,"failed":0}
------------------------------
• [4.181 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:11:58.597
    Nov 12 13:11:58.598: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:11:58.599
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:11:58.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:11:58.679
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-6339b0df-a877-4ed6-b429-fca8bbf6bf90 11/12/22 13:11:58.681
    STEP: Creating a pod to test consume secrets 11/12/22 13:11:58.688
    Nov 12 13:11:58.705: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa" in namespace "projected-1420" to be "Succeeded or Failed"
    Nov 12 13:11:58.713: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 7.739619ms
    Nov 12 13:12:00.719: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013655731s
    Nov 12 13:12:02.718: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013490984s
    STEP: Saw pod success 11/12/22 13:12:02.718
    Nov 12 13:12:02.719: INFO: Pod "pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa" satisfied condition "Succeeded or Failed"
    Nov 12 13:12:02.724: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 13:12:02.733
    Nov 12 13:12:02.756: INFO: Waiting for pod pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa to disappear
    Nov 12 13:12:02.760: INFO: Pod pod-projected-secrets-12cc3640-9f11-4d0e-9a2b-7cdf50f9f1aa no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 12 13:12:02.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1420" for this suite. 11/12/22 13:12:02.769
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:12:02.782
Nov 12 13:12:02.782: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:12:02.783
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:02.812
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:02.816
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-4086 11/12/22 13:12:02.82
Nov 12 13:12:02.834: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4086" to be "running and ready"
Nov 12 13:12:02.842: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.862211ms
Nov 12 13:12:02.842: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:12:04.848: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.013109623s
Nov 12 13:12:04.848: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 12 13:12:04.848: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 12 13:12:04.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 12 13:12:05.030: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 12 13:12:05.030: INFO: stdout: "iptables"
Nov 12 13:12:05.030: INFO: proxyMode: iptables
Nov 12 13:12:05.048: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 12 13:12:05.054: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-4086 11/12/22 13:12:05.054
STEP: creating replication controller affinity-clusterip-timeout in namespace services-4086 11/12/22 13:12:05.084
I1112 13:12:05.109451      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-4086, replica count: 3
I1112 13:12:08.160717      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 13:12:08.180: INFO: Creating new exec pod
Nov 12 13:12:08.193: INFO: Waiting up to 5m0s for pod "execpod-affinitytsbdq" in namespace "services-4086" to be "running"
Nov 12 13:12:08.200: INFO: Pod "execpod-affinitytsbdq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.536252ms
Nov 12 13:12:10.208: INFO: Pod "execpod-affinitytsbdq": Phase="Running", Reason="", readiness=true. Elapsed: 2.014528513s
Nov 12 13:12:10.208: INFO: Pod "execpod-affinitytsbdq" satisfied condition "running"
Nov 12 13:12:11.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Nov 12 13:12:11.388: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Nov 12 13:12:11.388: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 13:12:11.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.245 80'
Nov 12 13:12:11.588: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.245 80\nConnection to 10.152.183.245 80 port [tcp/http] succeeded!\n"
Nov 12 13:12:11.588: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 13:12:11.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.245:80/ ; done'
Nov 12 13:12:11.901: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n"
Nov 12 13:12:11.901: INFO: stdout: "\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p"
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
Nov 12 13:12:11.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.245:80/'
Nov 12 13:12:12.081: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n"
Nov 12 13:12:12.081: INFO: stdout: "affinity-clusterip-timeout-b2z7p"
Nov 12 13:12:32.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.245:80/'
Nov 12 13:12:32.284: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n"
Nov 12 13:12:32.284: INFO: stdout: "affinity-clusterip-timeout-bjpkg"
Nov 12 13:12:32.284: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-4086, will wait for the garbage collector to delete the pods 11/12/22 13:12:32.305
Nov 12 13:12:32.371: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 10.684911ms
Nov 12 13:12:32.472: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.759111ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:12:34.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4086" for this suite. 11/12/22 13:12:34.802
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":300,"skipped":5570,"failed":0}
------------------------------
• [SLOW TEST] [32.033 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:12:02.782
    Nov 12 13:12:02.782: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:12:02.783
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:02.812
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:02.816
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-4086 11/12/22 13:12:02.82
    Nov 12 13:12:02.834: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4086" to be "running and ready"
    Nov 12 13:12:02.842: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.862211ms
    Nov 12 13:12:02.842: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:12:04.848: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.013109623s
    Nov 12 13:12:04.848: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 12 13:12:04.848: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 12 13:12:04.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 12 13:12:05.030: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 12 13:12:05.030: INFO: stdout: "iptables"
    Nov 12 13:12:05.030: INFO: proxyMode: iptables
    Nov 12 13:12:05.048: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 12 13:12:05.054: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-4086 11/12/22 13:12:05.054
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-4086 11/12/22 13:12:05.084
    I1112 13:12:05.109451      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-4086, replica count: 3
    I1112 13:12:08.160717      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 13:12:08.180: INFO: Creating new exec pod
    Nov 12 13:12:08.193: INFO: Waiting up to 5m0s for pod "execpod-affinitytsbdq" in namespace "services-4086" to be "running"
    Nov 12 13:12:08.200: INFO: Pod "execpod-affinitytsbdq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.536252ms
    Nov 12 13:12:10.208: INFO: Pod "execpod-affinitytsbdq": Phase="Running", Reason="", readiness=true. Elapsed: 2.014528513s
    Nov 12 13:12:10.208: INFO: Pod "execpod-affinitytsbdq" satisfied condition "running"
    Nov 12 13:12:11.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Nov 12 13:12:11.388: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Nov 12 13:12:11.388: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 13:12:11.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.245 80'
    Nov 12 13:12:11.588: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.245 80\nConnection to 10.152.183.245 80 port [tcp/http] succeeded!\n"
    Nov 12 13:12:11.588: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 13:12:11.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.245:80/ ; done'
    Nov 12 13:12:11.901: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n"
    Nov 12 13:12:11.901: INFO: stdout: "\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p\naffinity-clusterip-timeout-b2z7p"
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Received response from host: affinity-clusterip-timeout-b2z7p
    Nov 12 13:12:11.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.245:80/'
    Nov 12 13:12:12.081: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n"
    Nov 12 13:12:12.081: INFO: stdout: "affinity-clusterip-timeout-b2z7p"
    Nov 12 13:12:32.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4086 exec execpod-affinitytsbdq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.245:80/'
    Nov 12 13:12:32.284: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.245:80/\n"
    Nov 12 13:12:32.284: INFO: stdout: "affinity-clusterip-timeout-bjpkg"
    Nov 12 13:12:32.284: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-4086, will wait for the garbage collector to delete the pods 11/12/22 13:12:32.305
    Nov 12 13:12:32.371: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 10.684911ms
    Nov 12 13:12:32.472: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.759111ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:12:34.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4086" for this suite. 11/12/22 13:12:34.802
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:12:34.816
Nov 12 13:12:34.816: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename statefulset 11/12/22 13:12:34.817
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:34.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:34.845
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5325 11/12/22 13:12:34.848
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-5325 11/12/22 13:12:34.86
Nov 12 13:12:34.873: INFO: Found 0 stateful pods, waiting for 1
Nov 12 13:12:44.890: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 11/12/22 13:12:44.9
STEP: Getting /status 11/12/22 13:12:44.92
Nov 12 13:12:44.929: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 11/12/22 13:12:44.929
Nov 12 13:12:44.956: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 11/12/22 13:12:44.956
Nov 12 13:12:44.960: INFO: Observed &StatefulSet event: ADDED
Nov 12 13:12:44.960: INFO: Found Statefulset ss in namespace statefulset-5325 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 12 13:12:44.960: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 11/12/22 13:12:44.961
Nov 12 13:12:44.961: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 12 13:12:44.973: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 11/12/22 13:12:44.973
Nov 12 13:12:44.976: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 12 13:12:44.976: INFO: Deleting all statefulset in ns statefulset-5325
Nov 12 13:12:44.985: INFO: Scaling statefulset ss to 0
Nov 12 13:12:55.012: INFO: Waiting for statefulset status.replicas updated to 0
Nov 12 13:12:55.017: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 12 13:12:55.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5325" for this suite. 11/12/22 13:12:55.05
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":301,"skipped":5573,"failed":0}
------------------------------
• [SLOW TEST] [20.257 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:12:34.816
    Nov 12 13:12:34.816: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename statefulset 11/12/22 13:12:34.817
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:34.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:34.845
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5325 11/12/22 13:12:34.848
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-5325 11/12/22 13:12:34.86
    Nov 12 13:12:34.873: INFO: Found 0 stateful pods, waiting for 1
    Nov 12 13:12:44.890: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 11/12/22 13:12:44.9
    STEP: Getting /status 11/12/22 13:12:44.92
    Nov 12 13:12:44.929: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 11/12/22 13:12:44.929
    Nov 12 13:12:44.956: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 11/12/22 13:12:44.956
    Nov 12 13:12:44.960: INFO: Observed &StatefulSet event: ADDED
    Nov 12 13:12:44.960: INFO: Found Statefulset ss in namespace statefulset-5325 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 12 13:12:44.960: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 11/12/22 13:12:44.961
    Nov 12 13:12:44.961: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 12 13:12:44.973: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 11/12/22 13:12:44.973
    Nov 12 13:12:44.976: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 12 13:12:44.976: INFO: Deleting all statefulset in ns statefulset-5325
    Nov 12 13:12:44.985: INFO: Scaling statefulset ss to 0
    Nov 12 13:12:55.012: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 12 13:12:55.017: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 12 13:12:55.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5325" for this suite. 11/12/22 13:12:55.05
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:12:55.073
Nov 12 13:12:55.073: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:12:55.075
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:55.116
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:55.121
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:12:55.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3463" for this suite. 11/12/22 13:12:55.141
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":302,"skipped":5580,"failed":0}
------------------------------
• [0.081 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:12:55.073
    Nov 12 13:12:55.073: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:12:55.075
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:55.116
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:55.121
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:12:55.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3463" for this suite. 11/12/22 13:12:55.141
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:12:55.156
Nov 12 13:12:55.156: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-runtime 11/12/22 13:12:55.157
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:55.185
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:55.192
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 11/12/22 13:12:55.203
STEP: wait for the container to reach Succeeded 11/12/22 13:12:55.276
STEP: get the container status 11/12/22 13:12:59.314
STEP: the container should be terminated 11/12/22 13:12:59.324
STEP: the termination message should be set 11/12/22 13:12:59.324
Nov 12 13:12:59.324: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 11/12/22 13:12:59.324
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 13:12:59.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9037" for this suite. 11/12/22 13:12:59.363
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":303,"skipped":5595,"failed":0}
------------------------------
• [4.219 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:12:55.156
    Nov 12 13:12:55.156: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-runtime 11/12/22 13:12:55.157
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:55.185
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:55.192
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 11/12/22 13:12:55.203
    STEP: wait for the container to reach Succeeded 11/12/22 13:12:55.276
    STEP: get the container status 11/12/22 13:12:59.314
    STEP: the container should be terminated 11/12/22 13:12:59.324
    STEP: the termination message should be set 11/12/22 13:12:59.324
    Nov 12 13:12:59.324: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 11/12/22 13:12:59.324
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 13:12:59.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-9037" for this suite. 11/12/22 13:12:59.363
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:12:59.375
Nov 12 13:12:59.375: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 13:12:59.376
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:59.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:59.408
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 11/12/22 13:12:59.415
Nov 12 13:12:59.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1819 cluster-info'
Nov 12 13:12:59.512: INFO: stderr: ""
Nov 12 13:12:59.512: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 13:12:59.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1819" for this suite. 11/12/22 13:12:59.523
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":304,"skipped":5596,"failed":0}
------------------------------
• [0.161 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:12:59.375
    Nov 12 13:12:59.375: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 13:12:59.376
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:59.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:59.408
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 11/12/22 13:12:59.415
    Nov 12 13:12:59.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-1819 cluster-info'
    Nov 12 13:12:59.512: INFO: stderr: ""
    Nov 12 13:12:59.512: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 13:12:59.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1819" for this suite. 11/12/22 13:12:59.523
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:12:59.537
Nov 12 13:12:59.537: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replication-controller 11/12/22 13:12:59.538
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:59.566
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:59.571
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 11/12/22 13:12:59.581
STEP: waiting for RC to be added 11/12/22 13:12:59.588
STEP: waiting for available Replicas 11/12/22 13:12:59.589
STEP: patching ReplicationController 11/12/22 13:13:01.132
STEP: waiting for RC to be modified 11/12/22 13:13:01.169
STEP: patching ReplicationController status 11/12/22 13:13:01.169
STEP: waiting for RC to be modified 11/12/22 13:13:01.201
STEP: waiting for available Replicas 11/12/22 13:13:01.201
STEP: fetching ReplicationController status 11/12/22 13:13:01.205
STEP: patching ReplicationController scale 11/12/22 13:13:01.211
STEP: waiting for RC to be modified 11/12/22 13:13:01.233
STEP: waiting for ReplicationController's scale to be the max amount 11/12/22 13:13:01.233
STEP: fetching ReplicationController; ensuring that it's patched 11/12/22 13:13:02.782
STEP: updating ReplicationController status 11/12/22 13:13:02.787
STEP: waiting for RC to be modified 11/12/22 13:13:02.797
STEP: listing all ReplicationControllers 11/12/22 13:13:02.797
STEP: checking that ReplicationController has expected values 11/12/22 13:13:02.802
STEP: deleting ReplicationControllers by collection 11/12/22 13:13:02.803
STEP: waiting for ReplicationController to have a DELETED watchEvent 11/12/22 13:13:02.819
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 12 13:13:02.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1833" for this suite. 11/12/22 13:13:02.903
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":305,"skipped":5612,"failed":0}
------------------------------
• [3.376 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:12:59.537
    Nov 12 13:12:59.537: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replication-controller 11/12/22 13:12:59.538
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:12:59.566
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:12:59.571
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 11/12/22 13:12:59.581
    STEP: waiting for RC to be added 11/12/22 13:12:59.588
    STEP: waiting for available Replicas 11/12/22 13:12:59.589
    STEP: patching ReplicationController 11/12/22 13:13:01.132
    STEP: waiting for RC to be modified 11/12/22 13:13:01.169
    STEP: patching ReplicationController status 11/12/22 13:13:01.169
    STEP: waiting for RC to be modified 11/12/22 13:13:01.201
    STEP: waiting for available Replicas 11/12/22 13:13:01.201
    STEP: fetching ReplicationController status 11/12/22 13:13:01.205
    STEP: patching ReplicationController scale 11/12/22 13:13:01.211
    STEP: waiting for RC to be modified 11/12/22 13:13:01.233
    STEP: waiting for ReplicationController's scale to be the max amount 11/12/22 13:13:01.233
    STEP: fetching ReplicationController; ensuring that it's patched 11/12/22 13:13:02.782
    STEP: updating ReplicationController status 11/12/22 13:13:02.787
    STEP: waiting for RC to be modified 11/12/22 13:13:02.797
    STEP: listing all ReplicationControllers 11/12/22 13:13:02.797
    STEP: checking that ReplicationController has expected values 11/12/22 13:13:02.802
    STEP: deleting ReplicationControllers by collection 11/12/22 13:13:02.803
    STEP: waiting for ReplicationController to have a DELETED watchEvent 11/12/22 13:13:02.819
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 12 13:13:02.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1833" for this suite. 11/12/22 13:13:02.903
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:13:02.913
Nov 12 13:13:02.913: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-runtime 11/12/22 13:13:02.914
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:02.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:02.945
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 11/12/22 13:13:02.948
STEP: wait for the container to reach Succeeded 11/12/22 13:13:02.971
STEP: get the container status 11/12/22 13:13:07.005
STEP: the container should be terminated 11/12/22 13:13:07.013
STEP: the termination message should be set 11/12/22 13:13:07.013
Nov 12 13:13:07.014: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/12/22 13:13:07.014
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 13:13:07.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-936" for this suite. 11/12/22 13:13:07.049
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":306,"skipped":5618,"failed":0}
------------------------------
• [4.151 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:13:02.913
    Nov 12 13:13:02.913: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-runtime 11/12/22 13:13:02.914
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:02.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:02.945
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 11/12/22 13:13:02.948
    STEP: wait for the container to reach Succeeded 11/12/22 13:13:02.971
    STEP: get the container status 11/12/22 13:13:07.005
    STEP: the container should be terminated 11/12/22 13:13:07.013
    STEP: the termination message should be set 11/12/22 13:13:07.013
    Nov 12 13:13:07.014: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/12/22 13:13:07.014
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 13:13:07.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-936" for this suite. 11/12/22 13:13:07.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:13:07.067
Nov 12 13:13:07.068: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 13:13:07.069
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:07.113
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:07.118
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 11/12/22 13:13:07.123
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
 11/12/22 13:13:07.136
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
 11/12/22 13:13:07.136
STEP: creating a pod to probe DNS 11/12/22 13:13:07.136
STEP: submitting the pod to kubernetes 11/12/22 13:13:07.136
Nov 12 13:13:07.153: INFO: Waiting up to 15m0s for pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5" in namespace "dns-2670" to be "running"
Nov 12 13:13:07.158: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.176378ms
Nov 12 13:13:09.164: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011309269s
Nov 12 13:13:11.164: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5": Phase="Running", Reason="", readiness=true. Elapsed: 4.010923115s
Nov 12 13:13:11.164: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5" satisfied condition "running"
STEP: retrieving the pod 11/12/22 13:13:11.164
STEP: looking for the results for each expected name from probers 11/12/22 13:13:11.17
Nov 12 13:13:11.184: INFO: DNS probes using dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5 succeeded

STEP: deleting the pod 11/12/22 13:13:11.184
STEP: changing the externalName to bar.example.com 11/12/22 13:13:11.205
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
 11/12/22 13:13:11.227
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
 11/12/22 13:13:11.228
STEP: creating a second pod to probe DNS 11/12/22 13:13:11.228
STEP: submitting the pod to kubernetes 11/12/22 13:13:11.228
Nov 12 13:13:11.235: INFO: Waiting up to 15m0s for pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24" in namespace "dns-2670" to be "running"
Nov 12 13:13:11.242: INFO: Pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24": Phase="Pending", Reason="", readiness=false. Elapsed: 7.273243ms
Nov 12 13:13:13.248: INFO: Pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24": Phase="Running", Reason="", readiness=true. Elapsed: 2.013531946s
Nov 12 13:13:13.249: INFO: Pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24" satisfied condition "running"
STEP: retrieving the pod 11/12/22 13:13:13.249
STEP: looking for the results for each expected name from probers 11/12/22 13:13:13.254
Nov 12 13:13:13.263: INFO: File wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local from pod  dns-2670/dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 12 13:13:13.270: INFO: File jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local from pod  dns-2670/dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 12 13:13:13.270: INFO: Lookups using dns-2670/dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 failed for: [wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local]

Nov 12 13:13:18.293: INFO: DNS probes using dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 succeeded

STEP: deleting the pod 11/12/22 13:13:18.293
STEP: changing the service to type=ClusterIP 11/12/22 13:13:18.315
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
 11/12/22 13:13:18.346
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
 11/12/22 13:13:18.346
STEP: creating a third pod to probe DNS 11/12/22 13:13:18.346
STEP: submitting the pod to kubernetes 11/12/22 13:13:18.359
Nov 12 13:13:18.379: INFO: Waiting up to 15m0s for pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d" in namespace "dns-2670" to be "running"
Nov 12 13:13:18.387: INFO: Pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.400676ms
Nov 12 13:13:20.394: INFO: Pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d": Phase="Running", Reason="", readiness=true. Elapsed: 2.015087249s
Nov 12 13:13:20.394: INFO: Pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d" satisfied condition "running"
STEP: retrieving the pod 11/12/22 13:13:20.394
STEP: looking for the results for each expected name from probers 11/12/22 13:13:20.399
Nov 12 13:13:20.414: INFO: DNS probes using dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d succeeded

STEP: deleting the pod 11/12/22 13:13:20.414
STEP: deleting the test externalName service 11/12/22 13:13:20.437
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 13:13:20.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2670" for this suite. 11/12/22 13:13:20.479
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":307,"skipped":5643,"failed":0}
------------------------------
• [SLOW TEST] [13.428 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:13:07.067
    Nov 12 13:13:07.068: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 13:13:07.069
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:07.113
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:07.118
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 11/12/22 13:13:07.123
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
     11/12/22 13:13:07.136
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
     11/12/22 13:13:07.136
    STEP: creating a pod to probe DNS 11/12/22 13:13:07.136
    STEP: submitting the pod to kubernetes 11/12/22 13:13:07.136
    Nov 12 13:13:07.153: INFO: Waiting up to 15m0s for pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5" in namespace "dns-2670" to be "running"
    Nov 12 13:13:07.158: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.176378ms
    Nov 12 13:13:09.164: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011309269s
    Nov 12 13:13:11.164: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5": Phase="Running", Reason="", readiness=true. Elapsed: 4.010923115s
    Nov 12 13:13:11.164: INFO: Pod "dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 13:13:11.164
    STEP: looking for the results for each expected name from probers 11/12/22 13:13:11.17
    Nov 12 13:13:11.184: INFO: DNS probes using dns-test-9c9d5005-8188-414f-9130-4fb80b3bfed5 succeeded

    STEP: deleting the pod 11/12/22 13:13:11.184
    STEP: changing the externalName to bar.example.com 11/12/22 13:13:11.205
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
     11/12/22 13:13:11.227
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
     11/12/22 13:13:11.228
    STEP: creating a second pod to probe DNS 11/12/22 13:13:11.228
    STEP: submitting the pod to kubernetes 11/12/22 13:13:11.228
    Nov 12 13:13:11.235: INFO: Waiting up to 15m0s for pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24" in namespace "dns-2670" to be "running"
    Nov 12 13:13:11.242: INFO: Pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24": Phase="Pending", Reason="", readiness=false. Elapsed: 7.273243ms
    Nov 12 13:13:13.248: INFO: Pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24": Phase="Running", Reason="", readiness=true. Elapsed: 2.013531946s
    Nov 12 13:13:13.249: INFO: Pod "dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 13:13:13.249
    STEP: looking for the results for each expected name from probers 11/12/22 13:13:13.254
    Nov 12 13:13:13.263: INFO: File wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local from pod  dns-2670/dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 12 13:13:13.270: INFO: File jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local from pod  dns-2670/dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 12 13:13:13.270: INFO: Lookups using dns-2670/dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 failed for: [wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local]

    Nov 12 13:13:18.293: INFO: DNS probes using dns-test-16c5e631-264b-4c10-9d77-c3f53260bf24 succeeded

    STEP: deleting the pod 11/12/22 13:13:18.293
    STEP: changing the service to type=ClusterIP 11/12/22 13:13:18.315
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
     11/12/22 13:13:18.346
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2670.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2670.svc.cluster.local; sleep 1; done
     11/12/22 13:13:18.346
    STEP: creating a third pod to probe DNS 11/12/22 13:13:18.346
    STEP: submitting the pod to kubernetes 11/12/22 13:13:18.359
    Nov 12 13:13:18.379: INFO: Waiting up to 15m0s for pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d" in namespace "dns-2670" to be "running"
    Nov 12 13:13:18.387: INFO: Pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.400676ms
    Nov 12 13:13:20.394: INFO: Pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d": Phase="Running", Reason="", readiness=true. Elapsed: 2.015087249s
    Nov 12 13:13:20.394: INFO: Pod "dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 13:13:20.394
    STEP: looking for the results for each expected name from probers 11/12/22 13:13:20.399
    Nov 12 13:13:20.414: INFO: DNS probes using dns-test-e046f44d-1e33-4130-82cb-cae38a113e6d succeeded

    STEP: deleting the pod 11/12/22 13:13:20.414
    STEP: deleting the test externalName service 11/12/22 13:13:20.437
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 13:13:20.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2670" for this suite. 11/12/22 13:13:20.479
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:13:20.497
Nov 12 13:13:20.497: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 13:13:20.497
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:20.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:20.54
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Nov 12 13:13:20.550: INFO: Creating deployment "test-recreate-deployment"
Nov 12 13:13:20.561: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 12 13:13:20.574: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 12 13:13:22.585: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 12 13:13:22.589: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 12 13:13:24.595: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 12 13:13:24.608: INFO: Updating deployment test-recreate-deployment
Nov 12 13:13:24.608: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 13:13:24.851: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9325  caba649b-0cbd-4cd2-934a-2db858f51d28 36375 2 2022-11-12 13:13:20 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001c0b708 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 13:13:24 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-12 13:13:24 +0000 UTC,LastTransitionTime:2022-11-12 13:13:20 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov 12 13:13:24.857: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-9325  ea7e6552-6fe7-4cb4-a61c-b788a7d09227 36374 1 2022-11-12 13:13:24 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment caba649b-0cbd-4cd2-934a-2db858f51d28 0xc00555bc50 0xc00555bc51}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"caba649b-0cbd-4cd2-934a-2db858f51d28\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00555bce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 13:13:24.857: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 12 13:13:24.857: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-9325  52392766-5869-4a18-8f27-ceb3820f27b5 36363 2 2022-11-12 13:13:20 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment caba649b-0cbd-4cd2-934a-2db858f51d28 0xc00555bb37 0xc00555bb38}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"caba649b-0cbd-4cd2-934a-2db858f51d28\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00555bbe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 12 13:13:24.864: INFO: Pod "test-recreate-deployment-9d58999df-5c7zv" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-5c7zv test-recreate-deployment-9d58999df- deployment-9325  588100ff-9802-4c10-aa2d-79fa47b9b8e0 36373 0 2022-11-12 13:13:24 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df ea7e6552-6fe7-4cb4-a61c-b788a7d09227 0xc001c0bb50 0xc001c0bb51}] [] [{kube-controller-manager Update v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea7e6552-6fe7-4cb4-a61c-b788a7d09227\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-snh2t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-snh2t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:,StartTime:2022-11-12 13:13:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 13:13:24.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9325" for this suite. 11/12/22 13:13:24.871
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":308,"skipped":5646,"failed":0}
------------------------------
• [4.388 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:13:20.497
    Nov 12 13:13:20.497: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 13:13:20.497
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:20.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:20.54
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Nov 12 13:13:20.550: INFO: Creating deployment "test-recreate-deployment"
    Nov 12 13:13:20.561: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Nov 12 13:13:20.574: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Nov 12 13:13:22.585: INFO: Waiting deployment "test-recreate-deployment" to complete
    Nov 12 13:13:22.589: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 12, 13, 13, 20, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 12 13:13:24.595: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Nov 12 13:13:24.608: INFO: Updating deployment test-recreate-deployment
    Nov 12 13:13:24.608: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 13:13:24.851: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-9325  caba649b-0cbd-4cd2-934a-2db858f51d28 36375 2 2022-11-12 13:13:20 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001c0b708 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-12 13:13:24 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-12 13:13:24 +0000 UTC,LastTransitionTime:2022-11-12 13:13:20 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Nov 12 13:13:24.857: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-9325  ea7e6552-6fe7-4cb4-a61c-b788a7d09227 36374 1 2022-11-12 13:13:24 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment caba649b-0cbd-4cd2-934a-2db858f51d28 0xc00555bc50 0xc00555bc51}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"caba649b-0cbd-4cd2-934a-2db858f51d28\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00555bce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 13:13:24.857: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Nov 12 13:13:24.857: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-9325  52392766-5869-4a18-8f27-ceb3820f27b5 36363 2 2022-11-12 13:13:20 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment caba649b-0cbd-4cd2-934a-2db858f51d28 0xc00555bb37 0xc00555bb38}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"caba649b-0cbd-4cd2-934a-2db858f51d28\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00555bbe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 13:13:24.864: INFO: Pod "test-recreate-deployment-9d58999df-5c7zv" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-5c7zv test-recreate-deployment-9d58999df- deployment-9325  588100ff-9802-4c10-aa2d-79fa47b9b8e0 36373 0 2022-11-12 13:13:24 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df ea7e6552-6fe7-4cb4-a61c-b788a7d09227 0xc001c0bb50 0xc001c0bb51}] [] [{kube-controller-manager Update v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea7e6552-6fe7-4cb4-a61c-b788a7d09227\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:13:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-snh2t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-snh2t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:13:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:,StartTime:2022-11-12 13:13:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 13:13:24.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9325" for this suite. 11/12/22 13:13:24.871
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:13:24.893
Nov 12 13:13:24.893: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-preemption 11/12/22 13:13:24.896
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:24.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:24.928
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 12 13:13:24.952: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 13:14:24.975: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:14:24.983
Nov 12 13:14:24.983: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-preemption-path 11/12/22 13:14:24.985
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:25.012
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:25.017
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 11/12/22 13:14:25.024
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 13:14:25.024
Nov 12 13:14:25.041: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7013" to be "running"
Nov 12 13:14:25.047: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 5.66351ms
Nov 12 13:14:27.053: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011664746s
Nov 12 13:14:27.053: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 13:14:27.057
Nov 12 13:14:27.077: INFO: found a healthy node: ip-172-31-14-110
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Nov 12 13:14:37.180: INFO: pods created so far: [1 1 1]
Nov 12 13:14:37.180: INFO: length of pods created so far: 3
Nov 12 13:14:39.195: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Nov 12 13:14:46.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-7013" for this suite. 11/12/22 13:14:46.202
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:14:46.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-417" for this suite. 11/12/22 13:14:46.261
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":309,"skipped":5685,"failed":0}
------------------------------
• [SLOW TEST] [81.450 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:13:24.893
    Nov 12 13:13:24.893: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-preemption 11/12/22 13:13:24.896
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:13:24.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:13:24.928
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 12 13:13:24.952: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 13:14:24.975: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:14:24.983
    Nov 12 13:14:24.983: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-preemption-path 11/12/22 13:14:24.985
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:25.012
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:25.017
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 11/12/22 13:14:25.024
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 13:14:25.024
    Nov 12 13:14:25.041: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-7013" to be "running"
    Nov 12 13:14:25.047: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 5.66351ms
    Nov 12 13:14:27.053: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011664746s
    Nov 12 13:14:27.053: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 13:14:27.057
    Nov 12 13:14:27.077: INFO: found a healthy node: ip-172-31-14-110
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Nov 12 13:14:37.180: INFO: pods created so far: [1 1 1]
    Nov 12 13:14:37.180: INFO: length of pods created so far: 3
    Nov 12 13:14:39.195: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Nov 12 13:14:46.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-7013" for this suite. 11/12/22 13:14:46.202
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:14:46.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-417" for this suite. 11/12/22 13:14:46.261
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:14:46.345
Nov 12 13:14:46.346: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename ephemeral-containers-test 11/12/22 13:14:46.349
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:46.371
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:46.375
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 11/12/22 13:14:46.384
Nov 12 13:14:46.396: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4784" to be "running and ready"
Nov 12 13:14:46.402: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.157445ms
Nov 12 13:14:46.402: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:14:48.407: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011195289s
Nov 12 13:14:48.407: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Nov 12 13:14:48.407: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 11/12/22 13:14:48.412
Nov 12 13:14:48.429: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4784" to be "container debugger running"
Nov 12 13:14:48.437: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.337854ms
Nov 12 13:14:50.444: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014674818s
Nov 12 13:14:52.445: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.016409055s
Nov 12 13:14:52.445: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 11/12/22 13:14:52.445
Nov 12 13:14:52.445: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4784 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 12 13:14:52.445: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
Nov 12 13:14:52.446: INFO: ExecWithOptions: Clientset creation
Nov 12 13:14:52.446: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-4784/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Nov 12 13:14:52.562: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 13:14:52.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-4784" for this suite. 11/12/22 13:14:52.591
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":310,"skipped":5716,"failed":0}
------------------------------
• [SLOW TEST] [6.260 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:14:46.345
    Nov 12 13:14:46.346: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename ephemeral-containers-test 11/12/22 13:14:46.349
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:46.371
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:46.375
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 11/12/22 13:14:46.384
    Nov 12 13:14:46.396: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4784" to be "running and ready"
    Nov 12 13:14:46.402: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.157445ms
    Nov 12 13:14:46.402: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:14:48.407: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.011195289s
    Nov 12 13:14:48.407: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Nov 12 13:14:48.407: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 11/12/22 13:14:48.412
    Nov 12 13:14:48.429: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-4784" to be "container debugger running"
    Nov 12 13:14:48.437: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 8.337854ms
    Nov 12 13:14:50.444: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014674818s
    Nov 12 13:14:52.445: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.016409055s
    Nov 12 13:14:52.445: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 11/12/22 13:14:52.445
    Nov 12 13:14:52.445: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-4784 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 12 13:14:52.445: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    Nov 12 13:14:52.446: INFO: ExecWithOptions: Clientset creation
    Nov 12 13:14:52.446: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-4784/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Nov 12 13:14:52.562: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 13:14:52.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-4784" for this suite. 11/12/22 13:14:52.591
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:14:52.607
Nov 12 13:14:52.607: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:14:52.608
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:52.633
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:52.64
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 11/12/22 13:14:52.664
Nov 12 13:14:52.680: INFO: Waiting up to 5m0s for pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3" in namespace "downward-api-9682" to be "Succeeded or Failed"
Nov 12 13:14:52.690: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.821033ms
Nov 12 13:14:54.697: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016837109s
Nov 12 13:14:56.696: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016555773s
STEP: Saw pod success 11/12/22 13:14:56.696
Nov 12 13:14:56.697: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3" satisfied condition "Succeeded or Failed"
Nov 12 13:14:56.702: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3 container dapi-container: <nil>
STEP: delete the pod 11/12/22 13:14:56.723
Nov 12 13:14:56.743: INFO: Waiting for pod downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3 to disappear
Nov 12 13:14:56.749: INFO: Pod downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 12 13:14:56.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9682" for this suite. 11/12/22 13:14:56.756
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":311,"skipped":5727,"failed":0}
------------------------------
• [4.160 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:14:52.607
    Nov 12 13:14:52.607: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:14:52.608
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:52.633
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:52.64
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 11/12/22 13:14:52.664
    Nov 12 13:14:52.680: INFO: Waiting up to 5m0s for pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3" in namespace "downward-api-9682" to be "Succeeded or Failed"
    Nov 12 13:14:52.690: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.821033ms
    Nov 12 13:14:54.697: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016837109s
    Nov 12 13:14:56.696: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016555773s
    STEP: Saw pod success 11/12/22 13:14:56.696
    Nov 12 13:14:56.697: INFO: Pod "downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3" satisfied condition "Succeeded or Failed"
    Nov 12 13:14:56.702: INFO: Trying to get logs from node ip-172-31-14-110 pod downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 13:14:56.723
    Nov 12 13:14:56.743: INFO: Waiting for pod downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3 to disappear
    Nov 12 13:14:56.749: INFO: Pod downward-api-5d4604d3-2dce-40df-92c0-5c978d479cf3 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 12 13:14:56.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9682" for this suite. 11/12/22 13:14:56.756
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:14:56.767
Nov 12 13:14:56.767: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename taint-single-pod 11/12/22 13:14:56.768
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:56.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:56.795
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Nov 12 13:14:56.800: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 13:15:56.815: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Nov 12 13:15:56.821: INFO: Starting informer...
STEP: Starting pod... 11/12/22 13:15:56.821
Nov 12 13:15:57.049: INFO: Pod is running on ip-172-31-14-110. Tainting Node
STEP: Trying to apply a taint on the Node 11/12/22 13:15:57.049
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:15:57.083
STEP: Waiting short time to make sure Pod is queued for deletion 11/12/22 13:15:57.088
Nov 12 13:15:57.088: INFO: Pod wasn't evicted. Proceeding
Nov 12 13:15:57.088: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:15:57.108
STEP: Waiting some time to make sure that toleration time passed. 11/12/22 13:15:57.113
Nov 12 13:17:12.114: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:17:12.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-242" for this suite. 11/12/22 13:17:12.12
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":312,"skipped":5730,"failed":0}
------------------------------
• [SLOW TEST] [135.363 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:14:56.767
    Nov 12 13:14:56.767: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename taint-single-pod 11/12/22 13:14:56.768
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:14:56.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:14:56.795
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Nov 12 13:14:56.800: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 13:15:56.815: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Nov 12 13:15:56.821: INFO: Starting informer...
    STEP: Starting pod... 11/12/22 13:15:56.821
    Nov 12 13:15:57.049: INFO: Pod is running on ip-172-31-14-110. Tainting Node
    STEP: Trying to apply a taint on the Node 11/12/22 13:15:57.049
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:15:57.083
    STEP: Waiting short time to make sure Pod is queued for deletion 11/12/22 13:15:57.088
    Nov 12 13:15:57.088: INFO: Pod wasn't evicted. Proceeding
    Nov 12 13:15:57.088: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/12/22 13:15:57.108
    STEP: Waiting some time to make sure that toleration time passed. 11/12/22 13:15:57.113
    Nov 12 13:17:12.114: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:17:12.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-242" for this suite. 11/12/22 13:17:12.12
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:17:12.132
Nov 12 13:17:12.132: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 13:17:12.133
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:17:12.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:17:12.159
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 11/12/22 13:17:12.162
STEP: Creating a ResourceQuota 11/12/22 13:17:17.168
STEP: Ensuring resource quota status is calculated 11/12/22 13:17:17.175
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 13:17:19.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9588" for this suite. 11/12/22 13:17:19.191
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":313,"skipped":5755,"failed":0}
------------------------------
• [SLOW TEST] [7.077 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:17:12.132
    Nov 12 13:17:12.132: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 13:17:12.133
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:17:12.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:17:12.159
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 11/12/22 13:17:12.162
    STEP: Creating a ResourceQuota 11/12/22 13:17:17.168
    STEP: Ensuring resource quota status is calculated 11/12/22 13:17:17.175
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 13:17:19.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9588" for this suite. 11/12/22 13:17:19.191
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:17:19.213
Nov 12 13:17:19.215: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-pred 11/12/22 13:17:19.217
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:17:19.243
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:17:19.247
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 12 13:17:19.250: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 12 13:17:19.264: INFO: Waiting for terminating namespaces to be deleted...
Nov 12 13:17:19.269: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
Nov 12 13:17:19.276: INFO: nginx-ingress-controller-kubernetes-worker-kktq7 from ingress-nginx-kubernetes-worker started at 2022-11-12 13:16:08 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.276: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:17:19.276: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.276: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 12 13:17:19.276: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:17:19.276: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:17:19.276: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 13:17:19.276: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
Nov 12 13:17:19.283: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.283: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 12 13:17:19.284: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:17:19.284: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 12 13:17:19.284: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container coredns ready: true, restart count 0
Nov 12 13:17:19.284: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 12 13:17:19.284: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container metrics-server ready: true, restart count 0
Nov 12 13:17:19.284: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 12 13:17:19.284: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 12 13:17:19.284: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 12 13:17:19.284: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:17:19.284: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:17:19.284: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 12 13:17:19.284: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
Nov 12 13:17:19.291: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
Nov 12 13:17:19.291: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 12 13:17:19.291: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:17:19.291: INFO: 	Container e2e ready: true, restart count 0
Nov 12 13:17:19.291: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:17:19.291: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
Nov 12 13:17:19.291: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 12 13:17:19.291: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 13:17:19.291
Nov 12 13:17:19.304: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1226" to be "running"
Nov 12 13:17:19.311: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 6.700728ms
Nov 12 13:17:21.316: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.012372886s
Nov 12 13:17:21.316: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 13:17:21.321
STEP: Trying to apply a random label on the found node. 11/12/22 13:17:21.349
STEP: verifying the node has the label kubernetes.io/e2e-5c1cc425-69ab-4b5f-a41b-f27fa9233b14 95 11/12/22 13:17:21.364
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/12/22 13:17:21.37
Nov 12 13:17:21.377: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-1226" to be "not pending"
Nov 12 13:17:21.385: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.063275ms
Nov 12 13:17:23.393: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.015427657s
Nov 12 13:17:23.393: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.14.110 on the node which pod4 resides and expect not scheduled 11/12/22 13:17:23.393
Nov 12 13:17:23.402: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-1226" to be "not pending"
Nov 12 13:17:23.410: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.618574ms
Nov 12 13:17:25.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014918615s
Nov 12 13:17:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013654445s
Nov 12 13:17:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014642339s
Nov 12 13:17:31.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014013299s
Nov 12 13:17:33.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01506072s
Nov 12 13:17:35.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014693863s
Nov 12 13:17:37.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016894082s
Nov 12 13:17:39.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012525122s
Nov 12 13:17:41.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.013412653s
Nov 12 13:17:43.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015566095s
Nov 12 13:17:45.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016652215s
Nov 12 13:17:47.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.01505756s
Nov 12 13:17:49.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014484759s
Nov 12 13:17:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013410035s
Nov 12 13:17:53.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014292456s
Nov 12 13:17:55.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.013969605s
Nov 12 13:17:57.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013921523s
Nov 12 13:17:59.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.014952927s
Nov 12 13:18:01.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.012972536s
Nov 12 13:18:03.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013084601s
Nov 12 13:18:05.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013745615s
Nov 12 13:18:07.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.014816819s
Nov 12 13:18:09.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014941188s
Nov 12 13:18:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.013696771s
Nov 12 13:18:13.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.014097952s
Nov 12 13:18:15.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.013791208s
Nov 12 13:18:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.015202637s
Nov 12 13:18:19.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013828113s
Nov 12 13:18:21.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.014202957s
Nov 12 13:18:23.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.014687869s
Nov 12 13:18:25.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.013489948s
Nov 12 13:18:27.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.014784484s
Nov 12 13:18:29.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.013925848s
Nov 12 13:18:31.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.013880561s
Nov 12 13:18:33.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.014186485s
Nov 12 13:18:35.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.01432612s
Nov 12 13:18:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.01462107s
Nov 12 13:18:39.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.013868558s
Nov 12 13:18:41.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.013015602s
Nov 12 13:18:43.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013878488s
Nov 12 13:18:45.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015387265s
Nov 12 13:18:47.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.016764505s
Nov 12 13:18:49.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.01389586s
Nov 12 13:18:51.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.013128234s
Nov 12 13:18:53.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013407033s
Nov 12 13:18:55.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013988663s
Nov 12 13:18:57.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013973539s
Nov 12 13:18:59.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.016559748s
Nov 12 13:19:01.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.012956631s
Nov 12 13:19:03.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015824473s
Nov 12 13:19:05.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.014077892s
Nov 12 13:19:07.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.01537624s
Nov 12 13:19:09.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.012885566s
Nov 12 13:19:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014173974s
Nov 12 13:19:13.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013794539s
Nov 12 13:19:15.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.01449709s
Nov 12 13:19:17.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.014137723s
Nov 12 13:19:19.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.016916877s
Nov 12 13:19:21.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.013337673s
Nov 12 13:19:23.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.014310343s
Nov 12 13:19:25.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.015762914s
Nov 12 13:19:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.013422054s
Nov 12 13:19:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014644022s
Nov 12 13:19:31.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.012801506s
Nov 12 13:19:33.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.014005958s
Nov 12 13:19:35.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.014249108s
Nov 12 13:19:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.014787467s
Nov 12 13:19:39.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.01448085s
Nov 12 13:19:41.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.013024496s
Nov 12 13:19:43.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.016732277s
Nov 12 13:19:45.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.013903643s
Nov 12 13:19:47.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.014471858s
Nov 12 13:19:49.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.015041462s
Nov 12 13:19:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.013547937s
Nov 12 13:19:53.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.014564294s
Nov 12 13:19:55.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.013574888s
Nov 12 13:19:57.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.014965346s
Nov 12 13:19:59.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.012725678s
Nov 12 13:20:01.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.01461978s
Nov 12 13:20:03.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.014404199s
Nov 12 13:20:05.423: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.020385927s
Nov 12 13:20:07.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.013937796s
Nov 12 13:20:09.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.015981128s
Nov 12 13:20:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.013331674s
Nov 12 13:20:13.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.014832945s
Nov 12 13:20:15.420: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.017323866s
Nov 12 13:20:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014391595s
Nov 12 13:20:19.421: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.01897225s
Nov 12 13:20:21.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.012881495s
Nov 12 13:20:23.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.013545699s
Nov 12 13:20:25.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.016724601s
Nov 12 13:20:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.01416237s
Nov 12 13:20:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.014807553s
Nov 12 13:20:31.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.015788607s
Nov 12 13:20:33.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01343552s
Nov 12 13:20:35.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.013864938s
Nov 12 13:20:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.014388865s
Nov 12 13:20:39.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.014739722s
Nov 12 13:20:41.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.014237621s
Nov 12 13:20:43.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.015124466s
Nov 12 13:20:45.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.013278414s
Nov 12 13:20:47.422: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.019372964s
Nov 12 13:20:49.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.013921511s
Nov 12 13:20:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013537134s
Nov 12 13:20:53.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.015603725s
Nov 12 13:20:55.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.015122353s
Nov 12 13:20:57.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.014678177s
Nov 12 13:20:59.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.014345873s
Nov 12 13:21:01.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.014091581s
Nov 12 13:21:03.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.01496601s
Nov 12 13:21:05.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.01384075s
Nov 12 13:21:07.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.013573011s
Nov 12 13:21:09.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.014630967s
Nov 12 13:21:11.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.014763786s
Nov 12 13:21:13.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.014541497s
Nov 12 13:21:15.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.013281058s
Nov 12 13:21:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.014708821s
Nov 12 13:21:19.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.014619858s
Nov 12 13:21:21.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.016503858s
Nov 12 13:21:23.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014246378s
Nov 12 13:21:25.420: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.018272146s
Nov 12 13:21:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.013832222s
Nov 12 13:21:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.014989811s
Nov 12 13:21:31.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.013428294s
Nov 12 13:21:33.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.014321512s
Nov 12 13:21:35.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.014484528s
Nov 12 13:21:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.014939015s
Nov 12 13:21:39.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.014269348s
Nov 12 13:21:41.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013408235s
Nov 12 13:21:43.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.014776487s
Nov 12 13:21:45.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.013239825s
Nov 12 13:21:47.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.013910353s
Nov 12 13:21:49.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.014627214s
Nov 12 13:21:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.014265302s
Nov 12 13:21:53.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.015056009s
Nov 12 13:21:55.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.014714263s
Nov 12 13:21:57.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.014791204s
Nov 12 13:21:59.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.015141993s
Nov 12 13:22:01.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.013798253s
Nov 12 13:22:03.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.014162653s
Nov 12 13:22:05.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.014862159s
Nov 12 13:22:07.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.0134402s
Nov 12 13:22:09.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.015571834s
Nov 12 13:22:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.013716591s
Nov 12 13:22:13.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.013287954s
Nov 12 13:22:15.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.013945634s
Nov 12 13:22:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.01438312s
Nov 12 13:22:19.421: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.018459898s
Nov 12 13:22:21.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.014046906s
Nov 12 13:22:23.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.014335645s
Nov 12 13:22:23.422: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.020231827s
STEP: removing the label kubernetes.io/e2e-5c1cc425-69ab-4b5f-a41b-f27fa9233b14 off the node ip-172-31-14-110 11/12/22 13:22:23.423
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c1cc425-69ab-4b5f-a41b-f27fa9233b14 11/12/22 13:22:23.441
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:22:23.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1226" for this suite. 11/12/22 13:22:23.452
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":314,"skipped":5774,"failed":0}
------------------------------
• [SLOW TEST] [304.250 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:17:19.213
    Nov 12 13:17:19.215: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-pred 11/12/22 13:17:19.217
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:17:19.243
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:17:19.247
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 12 13:17:19.250: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 12 13:17:19.264: INFO: Waiting for terminating namespaces to be deleted...
    Nov 12 13:17:19.269: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-14-110 before test
    Nov 12 13:17:19.276: INFO: nginx-ingress-controller-kubernetes-worker-kktq7 from ingress-nginx-kubernetes-worker started at 2022-11-12 13:16:08 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.276: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:17:19.276: INFO: sonobuoy from sonobuoy started at 2022-11-12 11:58:15 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.276: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 12 13:17:19.276: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-m4lvm from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:17:19.276: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:17:19.276: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 13:17:19.276: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-47-219 before test
    Nov 12 13:17:19.283: INFO: default-http-backend-kubernetes-worker-6546b9855c-jqjnt from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.283: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: nginx-ingress-controller-kubernetes-worker-6kkxq from ingress-nginx-kubernetes-worker started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: calico-kube-controllers-757485cd6d-94hn6 from kube-system started at 2022-11-12 11:50:16 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: coredns-6bcf44f4cc-v97wf from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container coredns ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: kube-state-metrics-74f5d549cc-7fvhd from kube-system started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: metrics-server-v0.5.2-6b48dc6f97-mjkbl from kube-system started at 2022-11-12 11:50:14 +0000 UTC (2 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: dashboard-metrics-scraper-85d45476c6-b8gmx from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: kubernetes-dashboard-7fb574cb-cmvn2 from kubernetes-dashboard started at 2022-11-12 11:50:14 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-54pdx from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:17:19.284: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 12 13:17:19.284: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-89-190 before test
    Nov 12 13:17:19.291: INFO: nginx-ingress-controller-kubernetes-worker-fl6kj from ingress-nginx-kubernetes-worker started at 2022-11-12 11:54:40 +0000 UTC (1 container statuses recorded)
    Nov 12 13:17:19.291: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 12 13:17:19.291: INFO: sonobuoy-e2e-job-df3011634d0e45b0 from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:17:19.291: INFO: 	Container e2e ready: true, restart count 0
    Nov 12 13:17:19.291: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:17:19.291: INFO: sonobuoy-systemd-logs-daemon-set-dfd71a1b6838417a-2465k from sonobuoy started at 2022-11-12 11:58:17 +0000 UTC (2 container statuses recorded)
    Nov 12 13:17:19.291: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 12 13:17:19.291: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/12/22 13:17:19.291
    Nov 12 13:17:19.304: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1226" to be "running"
    Nov 12 13:17:19.311: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 6.700728ms
    Nov 12 13:17:21.316: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.012372886s
    Nov 12 13:17:21.316: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/12/22 13:17:21.321
    STEP: Trying to apply a random label on the found node. 11/12/22 13:17:21.349
    STEP: verifying the node has the label kubernetes.io/e2e-5c1cc425-69ab-4b5f-a41b-f27fa9233b14 95 11/12/22 13:17:21.364
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/12/22 13:17:21.37
    Nov 12 13:17:21.377: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-1226" to be "not pending"
    Nov 12 13:17:21.385: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.063275ms
    Nov 12 13:17:23.393: INFO: Pod "pod4": Phase="Running", Reason="", readiness=true. Elapsed: 2.015427657s
    Nov 12 13:17:23.393: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.14.110 on the node which pod4 resides and expect not scheduled 11/12/22 13:17:23.393
    Nov 12 13:17:23.402: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-1226" to be "not pending"
    Nov 12 13:17:23.410: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.618574ms
    Nov 12 13:17:25.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014918615s
    Nov 12 13:17:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013654445s
    Nov 12 13:17:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014642339s
    Nov 12 13:17:31.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014013299s
    Nov 12 13:17:33.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01506072s
    Nov 12 13:17:35.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014693863s
    Nov 12 13:17:37.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016894082s
    Nov 12 13:17:39.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012525122s
    Nov 12 13:17:41.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.013412653s
    Nov 12 13:17:43.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015566095s
    Nov 12 13:17:45.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.016652215s
    Nov 12 13:17:47.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.01505756s
    Nov 12 13:17:49.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014484759s
    Nov 12 13:17:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.013410035s
    Nov 12 13:17:53.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014292456s
    Nov 12 13:17:55.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.013969605s
    Nov 12 13:17:57.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.013921523s
    Nov 12 13:17:59.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.014952927s
    Nov 12 13:18:01.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.012972536s
    Nov 12 13:18:03.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013084601s
    Nov 12 13:18:05.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.013745615s
    Nov 12 13:18:07.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.014816819s
    Nov 12 13:18:09.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.014941188s
    Nov 12 13:18:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.013696771s
    Nov 12 13:18:13.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.014097952s
    Nov 12 13:18:15.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.013791208s
    Nov 12 13:18:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.015202637s
    Nov 12 13:18:19.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013828113s
    Nov 12 13:18:21.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.014202957s
    Nov 12 13:18:23.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.014687869s
    Nov 12 13:18:25.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.013489948s
    Nov 12 13:18:27.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.014784484s
    Nov 12 13:18:29.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.013925848s
    Nov 12 13:18:31.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.013880561s
    Nov 12 13:18:33.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.014186485s
    Nov 12 13:18:35.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.01432612s
    Nov 12 13:18:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.01462107s
    Nov 12 13:18:39.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.013868558s
    Nov 12 13:18:41.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.013015602s
    Nov 12 13:18:43.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013878488s
    Nov 12 13:18:45.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015387265s
    Nov 12 13:18:47.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.016764505s
    Nov 12 13:18:49.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.01389586s
    Nov 12 13:18:51.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.013128234s
    Nov 12 13:18:53.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013407033s
    Nov 12 13:18:55.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013988663s
    Nov 12 13:18:57.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013973539s
    Nov 12 13:18:59.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.016559748s
    Nov 12 13:19:01.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.012956631s
    Nov 12 13:19:03.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015824473s
    Nov 12 13:19:05.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.014077892s
    Nov 12 13:19:07.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.01537624s
    Nov 12 13:19:09.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.012885566s
    Nov 12 13:19:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.014173974s
    Nov 12 13:19:13.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013794539s
    Nov 12 13:19:15.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.01449709s
    Nov 12 13:19:17.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.014137723s
    Nov 12 13:19:19.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.016916877s
    Nov 12 13:19:21.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.013337673s
    Nov 12 13:19:23.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.014310343s
    Nov 12 13:19:25.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.015762914s
    Nov 12 13:19:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.013422054s
    Nov 12 13:19:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014644022s
    Nov 12 13:19:31.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.012801506s
    Nov 12 13:19:33.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.014005958s
    Nov 12 13:19:35.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.014249108s
    Nov 12 13:19:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.014787467s
    Nov 12 13:19:39.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.01448085s
    Nov 12 13:19:41.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.013024496s
    Nov 12 13:19:43.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.016732277s
    Nov 12 13:19:45.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.013903643s
    Nov 12 13:19:47.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.014471858s
    Nov 12 13:19:49.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.015041462s
    Nov 12 13:19:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.013547937s
    Nov 12 13:19:53.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.014564294s
    Nov 12 13:19:55.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.013574888s
    Nov 12 13:19:57.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.014965346s
    Nov 12 13:19:59.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.012725678s
    Nov 12 13:20:01.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.01461978s
    Nov 12 13:20:03.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.014404199s
    Nov 12 13:20:05.423: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.020385927s
    Nov 12 13:20:07.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.013937796s
    Nov 12 13:20:09.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.015981128s
    Nov 12 13:20:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.013331674s
    Nov 12 13:20:13.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.014832945s
    Nov 12 13:20:15.420: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.017323866s
    Nov 12 13:20:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014391595s
    Nov 12 13:20:19.421: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.01897225s
    Nov 12 13:20:21.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.012881495s
    Nov 12 13:20:23.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.013545699s
    Nov 12 13:20:25.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.016724601s
    Nov 12 13:20:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.01416237s
    Nov 12 13:20:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.014807553s
    Nov 12 13:20:31.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.015788607s
    Nov 12 13:20:33.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01343552s
    Nov 12 13:20:35.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.013864938s
    Nov 12 13:20:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.014388865s
    Nov 12 13:20:39.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.014739722s
    Nov 12 13:20:41.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.014237621s
    Nov 12 13:20:43.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.015124466s
    Nov 12 13:20:45.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.013278414s
    Nov 12 13:20:47.422: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.019372964s
    Nov 12 13:20:49.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.013921511s
    Nov 12 13:20:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013537134s
    Nov 12 13:20:53.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.015603725s
    Nov 12 13:20:55.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.015122353s
    Nov 12 13:20:57.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.014678177s
    Nov 12 13:20:59.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.014345873s
    Nov 12 13:21:01.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.014091581s
    Nov 12 13:21:03.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.01496601s
    Nov 12 13:21:05.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.01384075s
    Nov 12 13:21:07.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.013573011s
    Nov 12 13:21:09.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.014630967s
    Nov 12 13:21:11.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.014763786s
    Nov 12 13:21:13.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.014541497s
    Nov 12 13:21:15.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.013281058s
    Nov 12 13:21:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.014708821s
    Nov 12 13:21:19.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.014619858s
    Nov 12 13:21:21.419: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.016503858s
    Nov 12 13:21:23.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014246378s
    Nov 12 13:21:25.420: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.018272146s
    Nov 12 13:21:27.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.013832222s
    Nov 12 13:21:29.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.014989811s
    Nov 12 13:21:31.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.013428294s
    Nov 12 13:21:33.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.014321512s
    Nov 12 13:21:35.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.014484528s
    Nov 12 13:21:37.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.014939015s
    Nov 12 13:21:39.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.014269348s
    Nov 12 13:21:41.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.013408235s
    Nov 12 13:21:43.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.014776487s
    Nov 12 13:21:45.415: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.013239825s
    Nov 12 13:21:47.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.013910353s
    Nov 12 13:21:49.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.014627214s
    Nov 12 13:21:51.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.014265302s
    Nov 12 13:21:53.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.015056009s
    Nov 12 13:21:55.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.014714263s
    Nov 12 13:21:57.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.014791204s
    Nov 12 13:21:59.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.015141993s
    Nov 12 13:22:01.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.013798253s
    Nov 12 13:22:03.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.014162653s
    Nov 12 13:22:05.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.014862159s
    Nov 12 13:22:07.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.0134402s
    Nov 12 13:22:09.418: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.015571834s
    Nov 12 13:22:11.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.013716591s
    Nov 12 13:22:13.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.013287954s
    Nov 12 13:22:15.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.013945634s
    Nov 12 13:22:17.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.01438312s
    Nov 12 13:22:19.421: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.018459898s
    Nov 12 13:22:21.416: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.014046906s
    Nov 12 13:22:23.417: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.014335645s
    Nov 12 13:22:23.422: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.020231827s
    STEP: removing the label kubernetes.io/e2e-5c1cc425-69ab-4b5f-a41b-f27fa9233b14 off the node ip-172-31-14-110 11/12/22 13:22:23.423
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-5c1cc425-69ab-4b5f-a41b-f27fa9233b14 11/12/22 13:22:23.441
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:22:23.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-1226" for this suite. 11/12/22 13:22:23.452
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:22:23.464
Nov 12 13:22:23.464: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 13:22:23.465
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:23.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:23.494
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 11/12/22 13:22:23.497
Nov 12 13:22:23.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 create -f -'
Nov 12 13:22:24.259: INFO: stderr: ""
Nov 12 13:22:24.259: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:22:24.259
Nov 12 13:22:24.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:22:24.369: INFO: stderr: ""
Nov 12 13:22:24.369: INFO: stdout: "update-demo-nautilus-dql9t update-demo-nautilus-phnk6 "
Nov 12 13:22:24.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:22:24.470: INFO: stderr: ""
Nov 12 13:22:24.470: INFO: stdout: ""
Nov 12 13:22:24.470: INFO: update-demo-nautilus-dql9t is created but not running
Nov 12 13:22:29.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:22:29.564: INFO: stderr: ""
Nov 12 13:22:29.564: INFO: stdout: "update-demo-nautilus-dql9t update-demo-nautilus-phnk6 "
Nov 12 13:22:29.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:22:29.685: INFO: stderr: ""
Nov 12 13:22:29.686: INFO: stdout: ""
Nov 12 13:22:29.686: INFO: update-demo-nautilus-dql9t is created but not running
Nov 12 13:22:34.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:22:34.767: INFO: stderr: ""
Nov 12 13:22:34.767: INFO: stdout: "update-demo-nautilus-dql9t update-demo-nautilus-phnk6 "
Nov 12 13:22:34.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:22:34.850: INFO: stderr: ""
Nov 12 13:22:34.850: INFO: stdout: "true"
Nov 12 13:22:34.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:22:34.947: INFO: stderr: ""
Nov 12 13:22:34.947: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:22:34.947: INFO: validating pod update-demo-nautilus-dql9t
Nov 12 13:22:34.955: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:22:34.955: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:22:34.955: INFO: update-demo-nautilus-dql9t is verified up and running
Nov 12 13:22:34.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-phnk6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:22:35.029: INFO: stderr: ""
Nov 12 13:22:35.029: INFO: stdout: "true"
Nov 12 13:22:35.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-phnk6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:22:35.113: INFO: stderr: ""
Nov 12 13:22:35.113: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:22:35.113: INFO: validating pod update-demo-nautilus-phnk6
Nov 12 13:22:35.131: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:22:35.131: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:22:35.131: INFO: update-demo-nautilus-phnk6 is verified up and running
STEP: using delete to clean up resources 11/12/22 13:22:35.131
Nov 12 13:22:35.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 delete --grace-period=0 --force -f -'
Nov 12 13:22:35.250: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 13:22:35.250: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 12 13:22:35.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get rc,svc -l name=update-demo --no-headers'
Nov 12 13:22:35.467: INFO: stderr: "No resources found in kubectl-715 namespace.\n"
Nov 12 13:22:35.467: INFO: stdout: ""
Nov 12 13:22:35.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 12 13:22:35.718: INFO: stderr: ""
Nov 12 13:22:35.718: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 13:22:35.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-715" for this suite. 11/12/22 13:22:35.727
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":315,"skipped":5790,"failed":0}
------------------------------
• [SLOW TEST] [12.275 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:22:23.464
    Nov 12 13:22:23.464: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 13:22:23.465
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:23.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:23.494
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 11/12/22 13:22:23.497
    Nov 12 13:22:23.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 create -f -'
    Nov 12 13:22:24.259: INFO: stderr: ""
    Nov 12 13:22:24.259: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:22:24.259
    Nov 12 13:22:24.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:22:24.369: INFO: stderr: ""
    Nov 12 13:22:24.369: INFO: stdout: "update-demo-nautilus-dql9t update-demo-nautilus-phnk6 "
    Nov 12 13:22:24.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:22:24.470: INFO: stderr: ""
    Nov 12 13:22:24.470: INFO: stdout: ""
    Nov 12 13:22:24.470: INFO: update-demo-nautilus-dql9t is created but not running
    Nov 12 13:22:29.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:22:29.564: INFO: stderr: ""
    Nov 12 13:22:29.564: INFO: stdout: "update-demo-nautilus-dql9t update-demo-nautilus-phnk6 "
    Nov 12 13:22:29.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:22:29.685: INFO: stderr: ""
    Nov 12 13:22:29.686: INFO: stdout: ""
    Nov 12 13:22:29.686: INFO: update-demo-nautilus-dql9t is created but not running
    Nov 12 13:22:34.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:22:34.767: INFO: stderr: ""
    Nov 12 13:22:34.767: INFO: stdout: "update-demo-nautilus-dql9t update-demo-nautilus-phnk6 "
    Nov 12 13:22:34.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:22:34.850: INFO: stderr: ""
    Nov 12 13:22:34.850: INFO: stdout: "true"
    Nov 12 13:22:34.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-dql9t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:22:34.947: INFO: stderr: ""
    Nov 12 13:22:34.947: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:22:34.947: INFO: validating pod update-demo-nautilus-dql9t
    Nov 12 13:22:34.955: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:22:34.955: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:22:34.955: INFO: update-demo-nautilus-dql9t is verified up and running
    Nov 12 13:22:34.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-phnk6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:22:35.029: INFO: stderr: ""
    Nov 12 13:22:35.029: INFO: stdout: "true"
    Nov 12 13:22:35.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods update-demo-nautilus-phnk6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:22:35.113: INFO: stderr: ""
    Nov 12 13:22:35.113: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:22:35.113: INFO: validating pod update-demo-nautilus-phnk6
    Nov 12 13:22:35.131: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:22:35.131: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:22:35.131: INFO: update-demo-nautilus-phnk6 is verified up and running
    STEP: using delete to clean up resources 11/12/22 13:22:35.131
    Nov 12 13:22:35.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 delete --grace-period=0 --force -f -'
    Nov 12 13:22:35.250: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 13:22:35.250: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 12 13:22:35.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get rc,svc -l name=update-demo --no-headers'
    Nov 12 13:22:35.467: INFO: stderr: "No resources found in kubectl-715 namespace.\n"
    Nov 12 13:22:35.467: INFO: stdout: ""
    Nov 12 13:22:35.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-715 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 12 13:22:35.718: INFO: stderr: ""
    Nov 12 13:22:35.718: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 13:22:35.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-715" for this suite. 11/12/22 13:22:35.727
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:22:35.739
Nov 12 13:22:35.739: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 13:22:35.74
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:35.787
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:35.791
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-f04ba19c-37d8-4499-ba2b-25fbed25eaf0 11/12/22 13:22:35.795
STEP: Creating a pod to test consume configMaps 11/12/22 13:22:35.803
Nov 12 13:22:35.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0" in namespace "configmap-8947" to be "Succeeded or Failed"
Nov 12 13:22:35.821: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.523624ms
Nov 12 13:22:37.827: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011678772s
Nov 12 13:22:39.828: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013347934s
STEP: Saw pod success 11/12/22 13:22:39.828
Nov 12 13:22:39.829: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0" satisfied condition "Succeeded or Failed"
Nov 12 13:22:39.835: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:22:39.86
Nov 12 13:22:39.888: INFO: Waiting for pod pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0 to disappear
Nov 12 13:22:39.893: INFO: Pod pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 13:22:39.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8947" for this suite. 11/12/22 13:22:39.899
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":316,"skipped":5797,"failed":0}
------------------------------
• [4.170 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:22:35.739
    Nov 12 13:22:35.739: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 13:22:35.74
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:35.787
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:35.791
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-f04ba19c-37d8-4499-ba2b-25fbed25eaf0 11/12/22 13:22:35.795
    STEP: Creating a pod to test consume configMaps 11/12/22 13:22:35.803
    Nov 12 13:22:35.815: INFO: Waiting up to 5m0s for pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0" in namespace "configmap-8947" to be "Succeeded or Failed"
    Nov 12 13:22:35.821: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.523624ms
    Nov 12 13:22:37.827: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011678772s
    Nov 12 13:22:39.828: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013347934s
    STEP: Saw pod success 11/12/22 13:22:39.828
    Nov 12 13:22:39.829: INFO: Pod "pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0" satisfied condition "Succeeded or Failed"
    Nov 12 13:22:39.835: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:22:39.86
    Nov 12 13:22:39.888: INFO: Waiting for pod pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0 to disappear
    Nov 12 13:22:39.893: INFO: Pod pod-configmaps-f68fb00a-dbf1-448d-bfa1-3652e8c8c1f0 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 13:22:39.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8947" for this suite. 11/12/22 13:22:39.899
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:22:39.911
Nov 12 13:22:39.911: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 13:22:39.911
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:39.935
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:39.94
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-a4345f97-5bbc-476e-b8b4-7486a7762293 11/12/22 13:22:39.944
STEP: Creating a pod to test consume configMaps 11/12/22 13:22:39.951
Nov 12 13:22:39.966: INFO: Waiting up to 5m0s for pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932" in namespace "configmap-2230" to be "Succeeded or Failed"
Nov 12 13:22:39.974: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932": Phase="Pending", Reason="", readiness=false. Elapsed: 8.091168ms
Nov 12 13:22:41.979: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013302975s
Nov 12 13:22:43.981: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014906941s
STEP: Saw pod success 11/12/22 13:22:43.981
Nov 12 13:22:43.981: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932" satisfied condition "Succeeded or Failed"
Nov 12 13:22:43.986: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932 container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:22:43.995
Nov 12 13:22:44.012: INFO: Waiting for pod pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932 to disappear
Nov 12 13:22:44.017: INFO: Pod pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 13:22:44.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2230" for this suite. 11/12/22 13:22:44.023
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":317,"skipped":5807,"failed":0}
------------------------------
• [4.121 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:22:39.911
    Nov 12 13:22:39.911: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 13:22:39.911
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:39.935
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:39.94
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-a4345f97-5bbc-476e-b8b4-7486a7762293 11/12/22 13:22:39.944
    STEP: Creating a pod to test consume configMaps 11/12/22 13:22:39.951
    Nov 12 13:22:39.966: INFO: Waiting up to 5m0s for pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932" in namespace "configmap-2230" to be "Succeeded or Failed"
    Nov 12 13:22:39.974: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932": Phase="Pending", Reason="", readiness=false. Elapsed: 8.091168ms
    Nov 12 13:22:41.979: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013302975s
    Nov 12 13:22:43.981: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014906941s
    STEP: Saw pod success 11/12/22 13:22:43.981
    Nov 12 13:22:43.981: INFO: Pod "pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932" satisfied condition "Succeeded or Failed"
    Nov 12 13:22:43.986: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932 container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:22:43.995
    Nov 12 13:22:44.012: INFO: Waiting for pod pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932 to disappear
    Nov 12 13:22:44.017: INFO: Pod pod-configmaps-210e42ce-d23f-42a1-8260-5b5717c7f932 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 13:22:44.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2230" for this suite. 11/12/22 13:22:44.023
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:22:44.033
Nov 12 13:22:44.033: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:22:44.034
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:44.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:44.061
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:22:44.065
Nov 12 13:22:44.080: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16" in namespace "downward-api-4200" to be "Succeeded or Failed"
Nov 12 13:22:44.085: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Pending", Reason="", readiness=false. Elapsed: 4.982411ms
Nov 12 13:22:46.090: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Running", Reason="", readiness=true. Elapsed: 2.010650805s
Nov 12 13:22:48.090: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Running", Reason="", readiness=false. Elapsed: 4.010362916s
Nov 12 13:22:50.094: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013928204s
STEP: Saw pod success 11/12/22 13:22:50.094
Nov 12 13:22:50.094: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16" satisfied condition "Succeeded or Failed"
Nov 12 13:22:50.099: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16 container client-container: <nil>
STEP: delete the pod 11/12/22 13:22:50.109
Nov 12 13:22:50.133: INFO: Waiting for pod downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16 to disappear
Nov 12 13:22:50.138: INFO: Pod downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:22:50.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4200" for this suite. 11/12/22 13:22:50.144
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":318,"skipped":5855,"failed":0}
------------------------------
• [SLOW TEST] [6.122 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:22:44.033
    Nov 12 13:22:44.033: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:22:44.034
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:44.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:44.061
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:22:44.065
    Nov 12 13:22:44.080: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16" in namespace "downward-api-4200" to be "Succeeded or Failed"
    Nov 12 13:22:44.085: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Pending", Reason="", readiness=false. Elapsed: 4.982411ms
    Nov 12 13:22:46.090: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Running", Reason="", readiness=true. Elapsed: 2.010650805s
    Nov 12 13:22:48.090: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Running", Reason="", readiness=false. Elapsed: 4.010362916s
    Nov 12 13:22:50.094: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013928204s
    STEP: Saw pod success 11/12/22 13:22:50.094
    Nov 12 13:22:50.094: INFO: Pod "downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16" satisfied condition "Succeeded or Failed"
    Nov 12 13:22:50.099: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16 container client-container: <nil>
    STEP: delete the pod 11/12/22 13:22:50.109
    Nov 12 13:22:50.133: INFO: Waiting for pod downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16 to disappear
    Nov 12 13:22:50.138: INFO: Pod downwardapi-volume-d34f7e4e-258a-4770-93e3-4b595ca18e16 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:22:50.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4200" for this suite. 11/12/22 13:22:50.144
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:22:50.156
Nov 12 13:22:50.156: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename events 11/12/22 13:22:50.157
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:50.19
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:50.198
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 11/12/22 13:22:50.202
STEP: listing all events in all namespaces 11/12/22 13:22:50.21
STEP: patching the test event 11/12/22 13:22:50.216
STEP: fetching the test event 11/12/22 13:22:50.233
STEP: updating the test event 11/12/22 13:22:50.239
STEP: getting the test event 11/12/22 13:22:50.257
STEP: deleting the test event 11/12/22 13:22:50.263
STEP: listing all events in all namespaces 11/12/22 13:22:50.286
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 12 13:22:50.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1334" for this suite. 11/12/22 13:22:50.299
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":319,"skipped":5861,"failed":0}
------------------------------
• [0.155 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:22:50.156
    Nov 12 13:22:50.156: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename events 11/12/22 13:22:50.157
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:50.19
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:50.198
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 11/12/22 13:22:50.202
    STEP: listing all events in all namespaces 11/12/22 13:22:50.21
    STEP: patching the test event 11/12/22 13:22:50.216
    STEP: fetching the test event 11/12/22 13:22:50.233
    STEP: updating the test event 11/12/22 13:22:50.239
    STEP: getting the test event 11/12/22 13:22:50.257
    STEP: deleting the test event 11/12/22 13:22:50.263
    STEP: listing all events in all namespaces 11/12/22 13:22:50.286
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 12 13:22:50.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1334" for this suite. 11/12/22 13:22:50.299
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:22:50.314
Nov 12 13:22:50.314: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename namespaces 11/12/22 13:22:50.318
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:50.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:50.351
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 11/12/22 13:22:50.357
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:50.383
STEP: Creating a service in the namespace 11/12/22 13:22:50.387
STEP: Deleting the namespace 11/12/22 13:22:50.469
STEP: Waiting for the namespace to be removed. 11/12/22 13:22:50.483
STEP: Recreating the namespace 11/12/22 13:22:56.489
STEP: Verifying there is no service in the namespace 11/12/22 13:22:56.52
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:22:56.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4926" for this suite. 11/12/22 13:22:56.532
STEP: Destroying namespace "nsdeletetest-2007" for this suite. 11/12/22 13:22:56.542
Nov 12 13:22:56.549: INFO: Namespace nsdeletetest-2007 was already deleted
STEP: Destroying namespace "nsdeletetest-663" for this suite. 11/12/22 13:22:56.549
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":320,"skipped":5877,"failed":0}
------------------------------
• [SLOW TEST] [6.248 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:22:50.314
    Nov 12 13:22:50.314: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename namespaces 11/12/22 13:22:50.318
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:50.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:50.351
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 11/12/22 13:22:50.357
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:50.383
    STEP: Creating a service in the namespace 11/12/22 13:22:50.387
    STEP: Deleting the namespace 11/12/22 13:22:50.469
    STEP: Waiting for the namespace to be removed. 11/12/22 13:22:50.483
    STEP: Recreating the namespace 11/12/22 13:22:56.489
    STEP: Verifying there is no service in the namespace 11/12/22 13:22:56.52
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:22:56.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4926" for this suite. 11/12/22 13:22:56.532
    STEP: Destroying namespace "nsdeletetest-2007" for this suite. 11/12/22 13:22:56.542
    Nov 12 13:22:56.549: INFO: Namespace nsdeletetest-2007 was already deleted
    STEP: Destroying namespace "nsdeletetest-663" for this suite. 11/12/22 13:22:56.549
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:22:56.569
Nov 12 13:22:56.569: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 13:22:56.574
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:56.595
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:56.6
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 11/12/22 13:22:56.61
Nov 12 13:22:56.623: INFO: created test-pod-1
Nov 12 13:22:56.634: INFO: created test-pod-2
Nov 12 13:22:56.644: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 11/12/22 13:22:56.644
Nov 12 13:22:56.645: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-1071' to be running and ready
Nov 12 13:22:56.679: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 13:22:56.679: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 13:22:56.679: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 12 13:22:56.679: INFO: 0 / 3 pods in namespace 'pods-1071' are running and ready (0 seconds elapsed)
Nov 12 13:22:56.679: INFO: expected 0 pod replicas in namespace 'pods-1071', 0 are Running and Ready.
Nov 12 13:22:56.679: INFO: POD         NODE              PHASE    GRACE  CONDITIONS
Nov 12 13:22:56.679: INFO: test-pod-1  ip-172-31-14-110  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  }]
Nov 12 13:22:56.679: INFO: test-pod-2  ip-172-31-89-190  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  }]
Nov 12 13:22:56.679: INFO: test-pod-3  ip-172-31-14-110  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  }]
Nov 12 13:22:56.679: INFO: 
Nov 12 13:22:58.693: INFO: 3 / 3 pods in namespace 'pods-1071' are running and ready (2 seconds elapsed)
Nov 12 13:22:58.693: INFO: expected 0 pod replicas in namespace 'pods-1071', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 11/12/22 13:22:58.731
Nov 12 13:22:58.738: INFO: Pod quantity 3 is different from expected quantity 0
Nov 12 13:22:59.744: INFO: Pod quantity 3 is different from expected quantity 0
Nov 12 13:23:00.744: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 12 13:23:01.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1071" for this suite. 11/12/22 13:23:01.757
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":321,"skipped":5893,"failed":0}
------------------------------
• [SLOW TEST] [5.200 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:22:56.569
    Nov 12 13:22:56.569: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 13:22:56.574
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:22:56.595
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:22:56.6
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 11/12/22 13:22:56.61
    Nov 12 13:22:56.623: INFO: created test-pod-1
    Nov 12 13:22:56.634: INFO: created test-pod-2
    Nov 12 13:22:56.644: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 11/12/22 13:22:56.644
    Nov 12 13:22:56.645: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-1071' to be running and ready
    Nov 12 13:22:56.679: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 13:22:56.679: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 13:22:56.679: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 12 13:22:56.679: INFO: 0 / 3 pods in namespace 'pods-1071' are running and ready (0 seconds elapsed)
    Nov 12 13:22:56.679: INFO: expected 0 pod replicas in namespace 'pods-1071', 0 are Running and Ready.
    Nov 12 13:22:56.679: INFO: POD         NODE              PHASE    GRACE  CONDITIONS
    Nov 12 13:22:56.679: INFO: test-pod-1  ip-172-31-14-110  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  }]
    Nov 12 13:22:56.679: INFO: test-pod-2  ip-172-31-89-190  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  }]
    Nov 12 13:22:56.679: INFO: test-pod-3  ip-172-31-14-110  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-12 13:22:56 +0000 UTC  }]
    Nov 12 13:22:56.679: INFO: 
    Nov 12 13:22:58.693: INFO: 3 / 3 pods in namespace 'pods-1071' are running and ready (2 seconds elapsed)
    Nov 12 13:22:58.693: INFO: expected 0 pod replicas in namespace 'pods-1071', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 11/12/22 13:22:58.731
    Nov 12 13:22:58.738: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 12 13:22:59.744: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 12 13:23:00.744: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 12 13:23:01.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1071" for this suite. 11/12/22 13:23:01.757
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:01.774
Nov 12 13:23:01.774: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename configmap 11/12/22 13:23:01.775
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:01.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:01.824
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 12 13:23:01.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3376" for this suite. 11/12/22 13:23:01.901
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":322,"skipped":5975,"failed":0}
------------------------------
• [0.136 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:01.774
    Nov 12 13:23:01.774: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename configmap 11/12/22 13:23:01.775
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:01.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:01.824
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 12 13:23:01.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3376" for this suite. 11/12/22 13:23:01.901
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:01.914
Nov 12 13:23:01.914: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename deployment 11/12/22 13:23:01.915
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:01.945
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:01.948
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Nov 12 13:23:01.953: INFO: Creating simple deployment test-new-deployment
Nov 12 13:23:01.978: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 11/12/22 13:23:03.999
STEP: updating a scale subresource 11/12/22 13:23:04.005
STEP: verifying the deployment Spec.Replicas was modified 11/12/22 13:23:04.013
STEP: Patch a scale subresource 11/12/22 13:23:04.021
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 12 13:23:04.047: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-3089  f2d9303b-0703-4417-b46e-910aecbacfd4 38297 3 2022-11-12 13:23:01 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-12 13:23:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:23:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032904e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 13:23:03 +0000 UTC,LastTransitionTime:2022-11-12 13:23:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-12 13:23:03 +0000 UTC,LastTransitionTime:2022-11-12 13:23:01 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 12 13:23:04.057: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-3089  f44d6fd9-c077-43db-851c-362cadf6e0e2 38301 2 2022-11-12 13:23:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment f2d9303b-0703-4417-b46e-910aecbacfd4 0xc003291467 0xc003291468}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:23:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f2d9303b-0703-4417-b46e-910aecbacfd4\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:23:04 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003291608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 12 13:23:04.063: INFO: Pod "test-new-deployment-845c8977d9-72gtr" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-72gtr test-new-deployment-845c8977d9- deployment-3089  e197c9b9-0823-4156-b5ea-dcdcf23bca9d 38289 0 2022-11-12 13:23:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 f44d6fd9-c077-43db-851c-362cadf6e0e2 0xc003856137 0xc003856138}] [] [{kube-controller-manager Update v1 2022-11-12 13:23:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f44d6fd9-c077-43db-851c-362cadf6e0e2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:23:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wxnzg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wxnzg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.53,StartTime:2022-11-12 13:23:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:23:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://22733963d8b20c29153fe5dfedfba433fb3fe0ede1e7f87bf20bf6e4c6eff25c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 12 13:23:04.068: INFO: Pod "test-new-deployment-845c8977d9-ncqjw" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-ncqjw test-new-deployment-845c8977d9- deployment-3089  83102743-f831-4b2c-8445-a71527b34533 38304 0 2022-11-12 13:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 f44d6fd9-c077-43db-851c-362cadf6e0e2 0xc003856337 0xc003856338}] [] [{kube-controller-manager Update v1 2022-11-12 13:23:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f44d6fd9-c077-43db-851c-362cadf6e0e2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:23:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f6zc9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f6zc9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:,StartTime:2022-11-12 13:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 12 13:23:04.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3089" for this suite. 11/12/22 13:23:04.073
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":323,"skipped":6007,"failed":0}
------------------------------
• [2.176 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:01.914
    Nov 12 13:23:01.914: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename deployment 11/12/22 13:23:01.915
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:01.945
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:01.948
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Nov 12 13:23:01.953: INFO: Creating simple deployment test-new-deployment
    Nov 12 13:23:01.978: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 11/12/22 13:23:03.999
    STEP: updating a scale subresource 11/12/22 13:23:04.005
    STEP: verifying the deployment Spec.Replicas was modified 11/12/22 13:23:04.013
    STEP: Patch a scale subresource 11/12/22 13:23:04.021
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 12 13:23:04.047: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-3089  f2d9303b-0703-4417-b46e-910aecbacfd4 38297 3 2022-11-12 13:23:01 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-12 13:23:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:23:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0032904e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-12 13:23:03 +0000 UTC,LastTransitionTime:2022-11-12 13:23:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-12 13:23:03 +0000 UTC,LastTransitionTime:2022-11-12 13:23:01 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 12 13:23:04.057: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-3089  f44d6fd9-c077-43db-851c-362cadf6e0e2 38301 2 2022-11-12 13:23:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment f2d9303b-0703-4417-b46e-910aecbacfd4 0xc003291467 0xc003291468}] [] [{kube-controller-manager Update apps/v1 2022-11-12 13:23:03 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f2d9303b-0703-4417-b46e-910aecbacfd4\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-12 13:23:04 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003291608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 12 13:23:04.063: INFO: Pod "test-new-deployment-845c8977d9-72gtr" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-72gtr test-new-deployment-845c8977d9- deployment-3089  e197c9b9-0823-4156-b5ea-dcdcf23bca9d 38289 0 2022-11-12 13:23:01 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 f44d6fd9-c077-43db-851c-362cadf6e0e2 0xc003856137 0xc003856138}] [] [{kube-controller-manager Update v1 2022-11-12 13:23:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f44d6fd9-c077-43db-851c-362cadf6e0e2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:23:03 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.249.53\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wxnzg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wxnzg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-14-110,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.14.110,PodIP:192.168.249.53,StartTime:2022-11-12 13:23:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-12 13:23:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://22733963d8b20c29153fe5dfedfba433fb3fe0ede1e7f87bf20bf6e4c6eff25c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.249.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 12 13:23:04.068: INFO: Pod "test-new-deployment-845c8977d9-ncqjw" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-ncqjw test-new-deployment-845c8977d9- deployment-3089  83102743-f831-4b2c-8445-a71527b34533 38304 0 2022-11-12 13:23:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 f44d6fd9-c077-43db-851c-362cadf6e0e2 0xc003856337 0xc003856338}] [] [{kube-controller-manager Update v1 2022-11-12 13:23:04 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f44d6fd9-c077-43db-851c-362cadf6e0e2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-12 13:23:04 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f6zc9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f6zc9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-89-190,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-12 13:23:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.89.190,PodIP:,StartTime:2022-11-12 13:23:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 12 13:23:04.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3089" for this suite. 11/12/22 13:23:04.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:04.093
Nov 12 13:23:04.093: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename resourcequota 11/12/22 13:23:04.094
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:04.124
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:04.135
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 11/12/22 13:23:04.15
STEP: Creating a ResourceQuota 11/12/22 13:23:09.158
STEP: Ensuring resource quota status is calculated 11/12/22 13:23:09.167
STEP: Creating a Service 11/12/22 13:23:11.174
STEP: Creating a NodePort Service 11/12/22 13:23:11.203
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/12/22 13:23:11.236
STEP: Ensuring resource quota status captures service creation 11/12/22 13:23:11.271
STEP: Deleting Services 11/12/22 13:23:13.278
STEP: Ensuring resource quota status released usage 11/12/22 13:23:13.352
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 12 13:23:15.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2116" for this suite. 11/12/22 13:23:15.364
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":324,"skipped":6029,"failed":0}
------------------------------
• [SLOW TEST] [11.280 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:04.093
    Nov 12 13:23:04.093: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename resourcequota 11/12/22 13:23:04.094
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:04.124
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:04.135
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 11/12/22 13:23:04.15
    STEP: Creating a ResourceQuota 11/12/22 13:23:09.158
    STEP: Ensuring resource quota status is calculated 11/12/22 13:23:09.167
    STEP: Creating a Service 11/12/22 13:23:11.174
    STEP: Creating a NodePort Service 11/12/22 13:23:11.203
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/12/22 13:23:11.236
    STEP: Ensuring resource quota status captures service creation 11/12/22 13:23:11.271
    STEP: Deleting Services 11/12/22 13:23:13.278
    STEP: Ensuring resource quota status released usage 11/12/22 13:23:13.352
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 12 13:23:15.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-2116" for this suite. 11/12/22 13:23:15.364
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:15.374
Nov 12 13:23:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:23:15.375
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:15.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:15.405
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-02a81ee1-b328-4480-bc06-a96665dd41fd 11/12/22 13:23:15.409
STEP: Creating a pod to test consume configMaps 11/12/22 13:23:15.416
Nov 12 13:23:15.430: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d" in namespace "projected-2060" to be "Succeeded or Failed"
Nov 12 13:23:15.437: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.104588ms
Nov 12 13:23:17.444: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014350276s
Nov 12 13:23:19.446: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015552582s
STEP: Saw pod success 11/12/22 13:23:19.446
Nov 12 13:23:19.446: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d" satisfied condition "Succeeded or Failed"
Nov 12 13:23:19.450: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d container agnhost-container: <nil>
STEP: delete the pod 11/12/22 13:23:19.46
Nov 12 13:23:19.482: INFO: Waiting for pod pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d to disappear
Nov 12 13:23:19.487: INFO: Pod pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 13:23:19.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2060" for this suite. 11/12/22 13:23:19.493
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":325,"skipped":6036,"failed":0}
------------------------------
• [4.133 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:15.374
    Nov 12 13:23:15.374: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:23:15.375
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:15.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:15.405
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-02a81ee1-b328-4480-bc06-a96665dd41fd 11/12/22 13:23:15.409
    STEP: Creating a pod to test consume configMaps 11/12/22 13:23:15.416
    Nov 12 13:23:15.430: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d" in namespace "projected-2060" to be "Succeeded or Failed"
    Nov 12 13:23:15.437: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.104588ms
    Nov 12 13:23:17.444: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014350276s
    Nov 12 13:23:19.446: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015552582s
    STEP: Saw pod success 11/12/22 13:23:19.446
    Nov 12 13:23:19.446: INFO: Pod "pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d" satisfied condition "Succeeded or Failed"
    Nov 12 13:23:19.450: INFO: Trying to get logs from node ip-172-31-14-110 pod pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d container agnhost-container: <nil>
    STEP: delete the pod 11/12/22 13:23:19.46
    Nov 12 13:23:19.482: INFO: Waiting for pod pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d to disappear
    Nov 12 13:23:19.487: INFO: Pod pod-projected-configmaps-243ea884-8f15-469a-a858-becff5109c4d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 13:23:19.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2060" for this suite. 11/12/22 13:23:19.493
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:19.51
Nov 12 13:23:19.510: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename runtimeclass 11/12/22 13:23:19.511
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:19.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:19.552
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 12 13:23:19.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-6158" for this suite. 11/12/22 13:23:19.58
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":326,"skipped":6086,"failed":0}
------------------------------
• [0.083 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:19.51
    Nov 12 13:23:19.510: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename runtimeclass 11/12/22 13:23:19.511
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:19.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:19.552
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 12 13:23:19.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-6158" for this suite. 11/12/22 13:23:19.58
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:19.595
Nov 12 13:23:19.595: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-runtime 11/12/22 13:23:19.596
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:19.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:19.64
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 11/12/22 13:23:19.647
STEP: wait for the container to reach Succeeded 11/12/22 13:23:19.675
STEP: get the container status 11/12/22 13:23:23.71
STEP: the container should be terminated 11/12/22 13:23:23.716
STEP: the termination message should be set 11/12/22 13:23:23.716
Nov 12 13:23:23.716: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 11/12/22 13:23:23.716
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 12 13:23:23.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5998" for this suite. 11/12/22 13:23:23.747
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":327,"skipped":6093,"failed":0}
------------------------------
• [4.162 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:19.595
    Nov 12 13:23:19.595: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-runtime 11/12/22 13:23:19.596
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:19.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:19.64
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 11/12/22 13:23:19.647
    STEP: wait for the container to reach Succeeded 11/12/22 13:23:19.675
    STEP: get the container status 11/12/22 13:23:23.71
    STEP: the container should be terminated 11/12/22 13:23:23.716
    STEP: the termination message should be set 11/12/22 13:23:23.716
    Nov 12 13:23:23.716: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 11/12/22 13:23:23.716
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 12 13:23:23.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5998" for this suite. 11/12/22 13:23:23.747
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:23.766
Nov 12 13:23:23.766: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename ingress 11/12/22 13:23:23.767
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:23.788
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:23.793
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 11/12/22 13:23:23.797
STEP: getting /apis/networking.k8s.io 11/12/22 13:23:23.802
STEP: getting /apis/networking.k8s.iov1 11/12/22 13:23:23.804
STEP: creating 11/12/22 13:23:23.805
STEP: getting 11/12/22 13:23:23.837
STEP: listing 11/12/22 13:23:23.845
STEP: watching 11/12/22 13:23:23.851
Nov 12 13:23:23.851: INFO: starting watch
STEP: cluster-wide listing 11/12/22 13:23:23.853
STEP: cluster-wide watching 11/12/22 13:23:23.86
Nov 12 13:23:23.860: INFO: starting watch
STEP: patching 11/12/22 13:23:23.862
STEP: updating 11/12/22 13:23:23.872
Nov 12 13:23:23.894: INFO: waiting for watch events with expected annotations
Nov 12 13:23:23.897: INFO: saw patched and updated annotations
STEP: patching /status 11/12/22 13:23:23.897
STEP: updating /status 11/12/22 13:23:24.004
STEP: get /status 11/12/22 13:23:24.028
STEP: deleting 11/12/22 13:23:24.035
STEP: deleting a collection 11/12/22 13:23:24.061
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Nov 12 13:23:24.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-5668" for this suite. 11/12/22 13:23:24.09
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":328,"skipped":6166,"failed":0}
------------------------------
• [0.333 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:23.766
    Nov 12 13:23:23.766: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename ingress 11/12/22 13:23:23.767
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:23.788
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:23.793
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 11/12/22 13:23:23.797
    STEP: getting /apis/networking.k8s.io 11/12/22 13:23:23.802
    STEP: getting /apis/networking.k8s.iov1 11/12/22 13:23:23.804
    STEP: creating 11/12/22 13:23:23.805
    STEP: getting 11/12/22 13:23:23.837
    STEP: listing 11/12/22 13:23:23.845
    STEP: watching 11/12/22 13:23:23.851
    Nov 12 13:23:23.851: INFO: starting watch
    STEP: cluster-wide listing 11/12/22 13:23:23.853
    STEP: cluster-wide watching 11/12/22 13:23:23.86
    Nov 12 13:23:23.860: INFO: starting watch
    STEP: patching 11/12/22 13:23:23.862
    STEP: updating 11/12/22 13:23:23.872
    Nov 12 13:23:23.894: INFO: waiting for watch events with expected annotations
    Nov 12 13:23:23.897: INFO: saw patched and updated annotations
    STEP: patching /status 11/12/22 13:23:23.897
    STEP: updating /status 11/12/22 13:23:24.004
    STEP: get /status 11/12/22 13:23:24.028
    STEP: deleting 11/12/22 13:23:24.035
    STEP: deleting a collection 11/12/22 13:23:24.061
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Nov 12 13:23:24.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-5668" for this suite. 11/12/22 13:23:24.09
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:24.099
Nov 12 13:23:24.099: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:23:24.1
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:24.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:24.134
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:23:24.138
Nov 12 13:23:24.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c" in namespace "projected-1425" to be "Succeeded or Failed"
Nov 12 13:23:24.160: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.11784ms
Nov 12 13:23:26.167: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014569908s
Nov 12 13:23:28.168: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01519658s
STEP: Saw pod success 11/12/22 13:23:28.168
Nov 12 13:23:28.168: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c" satisfied condition "Succeeded or Failed"
Nov 12 13:23:28.173: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c container client-container: <nil>
STEP: delete the pod 11/12/22 13:23:28.184
Nov 12 13:23:28.215: INFO: Waiting for pod downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c to disappear
Nov 12 13:23:28.222: INFO: Pod downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 13:23:28.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1425" for this suite. 11/12/22 13:23:28.228
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":329,"skipped":6185,"failed":0}
------------------------------
• [4.142 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:24.099
    Nov 12 13:23:24.099: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:23:24.1
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:24.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:24.134
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:23:24.138
    Nov 12 13:23:24.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c" in namespace "projected-1425" to be "Succeeded or Failed"
    Nov 12 13:23:24.160: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.11784ms
    Nov 12 13:23:26.167: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014569908s
    Nov 12 13:23:28.168: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01519658s
    STEP: Saw pod success 11/12/22 13:23:28.168
    Nov 12 13:23:28.168: INFO: Pod "downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c" satisfied condition "Succeeded or Failed"
    Nov 12 13:23:28.173: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c container client-container: <nil>
    STEP: delete the pod 11/12/22 13:23:28.184
    Nov 12 13:23:28.215: INFO: Waiting for pod downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c to disappear
    Nov 12 13:23:28.222: INFO: Pod downwardapi-volume-e58475ab-6e69-4a04-adac-cc991a436b1c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 13:23:28.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1425" for this suite. 11/12/22 13:23:28.228
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:28.242
Nov 12 13:23:28.242: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename endpointslice 11/12/22 13:23:28.243
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:28.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:28.272
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 11/12/22 13:23:33.391
STEP: referencing matching pods with named port 11/12/22 13:23:38.407
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/12/22 13:23:43.421
STEP: recreating EndpointSlices after they've been deleted 11/12/22 13:23:48.435
Nov 12 13:23:48.471: INFO: EndpointSlice for Service endpointslice-9060/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 12 13:23:58.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9060" for this suite. 11/12/22 13:23:58.494
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":330,"skipped":6185,"failed":0}
------------------------------
• [SLOW TEST] [30.262 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:28.242
    Nov 12 13:23:28.242: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename endpointslice 11/12/22 13:23:28.243
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:28.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:28.272
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 11/12/22 13:23:33.391
    STEP: referencing matching pods with named port 11/12/22 13:23:38.407
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/12/22 13:23:43.421
    STEP: recreating EndpointSlices after they've been deleted 11/12/22 13:23:48.435
    Nov 12 13:23:48.471: INFO: EndpointSlice for Service endpointslice-9060/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 12 13:23:58.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-9060" for this suite. 11/12/22 13:23:58.494
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:23:58.505
Nov 12 13:23:58.506: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename daemonsets 11/12/22 13:23:58.506
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:58.529
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:58.532
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Nov 12 13:23:58.579: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 13:23:58.588
Nov 12 13:23:58.594: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:23:58.594: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:23:58.599: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 13:23:58.599: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 13:23:59.606: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:23:59.606: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:23:59.612: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 13:23:59.612: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
Nov 12 13:24:00.607: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:00.607: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:00.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 13:24:00.613: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 11/12/22 13:24:00.636
STEP: Check that daemon pods images are updated. 11/12/22 13:24:00.672
Nov 12 13:24:00.679: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:00.679: INFO: Wrong image for pod: daemon-set-mhkgw. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:00.679: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:00.691: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:00.691: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:01.700: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:01.700: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:01.706: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:01.706: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:02.697: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:02.697: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:02.702: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:02.702: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:03.698: INFO: Pod daemon-set-7sf76 is not available
Nov 12 13:24:03.698: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:03.698: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:03.705: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:03.705: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:04.698: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:04.704: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:04.704: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:05.696: INFO: Pod daemon-set-6pf2x is not available
Nov 12 13:24:05.696: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:05.702: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:05.702: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:06.698: INFO: Pod daemon-set-6pf2x is not available
Nov 12 13:24:06.698: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 12 13:24:06.704: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:06.704: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:07.706: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:07.707: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:08.696: INFO: Pod daemon-set-wsd8m is not available
Nov 12 13:24:08.702: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:08.702: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 11/12/22 13:24:08.703
Nov 12 13:24:08.710: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:08.710: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:08.717: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 12 13:24:08.717: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
Nov 12 13:24:09.724: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:09.725: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 12 13:24:09.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 12 13:24:09.732: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/12/22 13:24:09.769
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4945, will wait for the garbage collector to delete the pods 11/12/22 13:24:09.77
Nov 12 13:24:09.837: INFO: Deleting DaemonSet.extensions daemon-set took: 9.887911ms
Nov 12 13:24:09.937: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.514059ms
Nov 12 13:24:12.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 12 13:24:12.343: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 12 13:24:12.348: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38933"},"items":null}

Nov 12 13:24:12.353: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38933"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:24:12.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4945" for this suite. 11/12/22 13:24:12.377
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":331,"skipped":6203,"failed":0}
------------------------------
• [SLOW TEST] [13.880 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:23:58.505
    Nov 12 13:23:58.506: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename daemonsets 11/12/22 13:23:58.506
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:23:58.529
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:23:58.532
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Nov 12 13:23:58.579: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 11/12/22 13:23:58.588
    Nov 12 13:23:58.594: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:23:58.594: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:23:58.599: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 13:23:58.599: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 13:23:59.606: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:23:59.606: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:23:59.612: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 13:23:59.612: INFO: Node ip-172-31-14-110 is running 0 daemon pod, expected 1
    Nov 12 13:24:00.607: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:00.607: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:00.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 13:24:00.613: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 11/12/22 13:24:00.636
    STEP: Check that daemon pods images are updated. 11/12/22 13:24:00.672
    Nov 12 13:24:00.679: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:00.679: INFO: Wrong image for pod: daemon-set-mhkgw. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:00.679: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:00.691: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:00.691: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:01.700: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:01.700: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:01.706: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:01.706: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:02.697: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:02.697: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:02.702: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:02.702: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:03.698: INFO: Pod daemon-set-7sf76 is not available
    Nov 12 13:24:03.698: INFO: Wrong image for pod: daemon-set-c9c65. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:03.698: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:03.705: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:03.705: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:04.698: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:04.704: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:04.704: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:05.696: INFO: Pod daemon-set-6pf2x is not available
    Nov 12 13:24:05.696: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:05.702: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:05.702: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:06.698: INFO: Pod daemon-set-6pf2x is not available
    Nov 12 13:24:06.698: INFO: Wrong image for pod: daemon-set-twjxj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 12 13:24:06.704: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:06.704: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:07.706: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:07.707: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:08.696: INFO: Pod daemon-set-wsd8m is not available
    Nov 12 13:24:08.702: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:08.702: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 11/12/22 13:24:08.703
    Nov 12 13:24:08.710: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:08.710: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:08.717: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 12 13:24:08.717: INFO: Node ip-172-31-47-219 is running 0 daemon pod, expected 1
    Nov 12 13:24:09.724: INFO: DaemonSet pods can't tolerate node ip-172-31-30-106 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:09.725: INFO: DaemonSet pods can't tolerate node ip-172-31-95-4 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 12 13:24:09.732: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 12 13:24:09.732: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/12/22 13:24:09.769
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4945, will wait for the garbage collector to delete the pods 11/12/22 13:24:09.77
    Nov 12 13:24:09.837: INFO: Deleting DaemonSet.extensions daemon-set took: 9.887911ms
    Nov 12 13:24:09.937: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.514059ms
    Nov 12 13:24:12.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 12 13:24:12.343: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 12 13:24:12.348: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38933"},"items":null}

    Nov 12 13:24:12.353: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38933"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:24:12.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4945" for this suite. 11/12/22 13:24:12.377
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:24:12.387
Nov 12 13:24:12.387: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 13:24:12.388
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:12.421
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:12.425
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 13:24:12.453
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 13:24:13.285
STEP: Deploying the webhook pod 11/12/22 13:24:13.298
STEP: Wait for the deployment to be ready 11/12/22 13:24:13.32
Nov 12 13:24:13.340: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 13:24:15.359
STEP: Verifying the service has paired with the endpoint 11/12/22 13:24:15.376
Nov 12 13:24:16.377: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 11/12/22 13:24:16.384
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/12/22 13:24:16.385
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 13:24:16.385
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/12/22 13:24:16.385
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/12/22 13:24:16.387
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 13:24:16.387
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 13:24:16.388
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:24:16.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4383" for this suite. 11/12/22 13:24:16.396
STEP: Destroying namespace "webhook-4383-markers" for this suite. 11/12/22 13:24:16.407
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":332,"skipped":6205,"failed":0}
------------------------------
• [4.103 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:24:12.387
    Nov 12 13:24:12.387: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 13:24:12.388
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:12.421
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:12.425
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 13:24:12.453
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 13:24:13.285
    STEP: Deploying the webhook pod 11/12/22 13:24:13.298
    STEP: Wait for the deployment to be ready 11/12/22 13:24:13.32
    Nov 12 13:24:13.340: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 13:24:15.359
    STEP: Verifying the service has paired with the endpoint 11/12/22 13:24:15.376
    Nov 12 13:24:16.377: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 11/12/22 13:24:16.384
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/12/22 13:24:16.385
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/12/22 13:24:16.385
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/12/22 13:24:16.385
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/12/22 13:24:16.387
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 13:24:16.387
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/12/22 13:24:16.388
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:24:16.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4383" for this suite. 11/12/22 13:24:16.396
    STEP: Destroying namespace "webhook-4383-markers" for this suite. 11/12/22 13:24:16.407
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:24:16.491
Nov 12 13:24:16.492: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename dns 11/12/22 13:24:16.492
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:16.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:16.54
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 11/12/22 13:24:16.544
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8590;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8590;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +notcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_tcp@PTR;sleep 1; done
 11/12/22 13:24:16.576
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8590;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8590;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +notcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_tcp@PTR;sleep 1; done
 11/12/22 13:24:16.576
STEP: creating a pod to probe DNS 11/12/22 13:24:16.576
STEP: submitting the pod to kubernetes 11/12/22 13:24:16.577
Nov 12 13:24:16.595: INFO: Waiting up to 15m0s for pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2" in namespace "dns-8590" to be "running"
Nov 12 13:24:16.606: INFO: Pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.709641ms
Nov 12 13:24:18.612: INFO: Pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2": Phase="Running", Reason="", readiness=true. Elapsed: 2.017482897s
Nov 12 13:24:18.612: INFO: Pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2" satisfied condition "running"
STEP: retrieving the pod 11/12/22 13:24:18.612
STEP: looking for the results for each expected name from probers 11/12/22 13:24:18.617
Nov 12 13:24:18.624: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.632: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.639: INFO: Unable to read wheezy_udp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.644: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.651: INFO: Unable to read wheezy_udp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.656: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.663: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.672: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.700: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.707: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.713: INFO: Unable to read jessie_udp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.718: INFO: Unable to read jessie_tcp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.724: INFO: Unable to read jessie_udp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.730: INFO: Unable to read jessie_tcp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.741: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.747: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
Nov 12 13:24:18.771: INFO: Lookups using dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8590 wheezy_tcp@dns-test-service.dns-8590 wheezy_udp@dns-test-service.dns-8590.svc wheezy_tcp@dns-test-service.dns-8590.svc wheezy_udp@_http._tcp.dns-test-service.dns-8590.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8590.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8590 jessie_tcp@dns-test-service.dns-8590 jessie_udp@dns-test-service.dns-8590.svc jessie_tcp@dns-test-service.dns-8590.svc jessie_udp@_http._tcp.dns-test-service.dns-8590.svc jessie_tcp@_http._tcp.dns-test-service.dns-8590.svc]

Nov 12 13:24:23.953: INFO: DNS probes using dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2 succeeded

STEP: deleting the pod 11/12/22 13:24:23.953
STEP: deleting the test service 11/12/22 13:24:23.974
STEP: deleting the test headless service 11/12/22 13:24:24.01
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 12 13:24:24.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8590" for this suite. 11/12/22 13:24:24.066
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":333,"skipped":6215,"failed":0}
------------------------------
• [SLOW TEST] [7.585 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:24:16.491
    Nov 12 13:24:16.492: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename dns 11/12/22 13:24:16.492
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:16.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:16.54
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 11/12/22 13:24:16.544
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8590;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8590;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +notcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_tcp@PTR;sleep 1; done
     11/12/22 13:24:16.576
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8590;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8590;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8590.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8590.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8590.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8590.svc;check="$$(dig +notcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_udp@PTR;check="$$(dig +tcp +noall +answer +search 208.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.208_tcp@PTR;sleep 1; done
     11/12/22 13:24:16.576
    STEP: creating a pod to probe DNS 11/12/22 13:24:16.576
    STEP: submitting the pod to kubernetes 11/12/22 13:24:16.577
    Nov 12 13:24:16.595: INFO: Waiting up to 15m0s for pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2" in namespace "dns-8590" to be "running"
    Nov 12 13:24:16.606: INFO: Pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.709641ms
    Nov 12 13:24:18.612: INFO: Pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2": Phase="Running", Reason="", readiness=true. Elapsed: 2.017482897s
    Nov 12 13:24:18.612: INFO: Pod "dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2" satisfied condition "running"
    STEP: retrieving the pod 11/12/22 13:24:18.612
    STEP: looking for the results for each expected name from probers 11/12/22 13:24:18.617
    Nov 12 13:24:18.624: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.632: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.639: INFO: Unable to read wheezy_udp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.644: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.651: INFO: Unable to read wheezy_udp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.656: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.663: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.672: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.700: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.707: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.713: INFO: Unable to read jessie_udp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.718: INFO: Unable to read jessie_tcp@dns-test-service.dns-8590 from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.724: INFO: Unable to read jessie_udp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.730: INFO: Unable to read jessie_tcp@dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.741: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.747: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8590.svc from pod dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2: the server could not find the requested resource (get pods dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2)
    Nov 12 13:24:18.771: INFO: Lookups using dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8590 wheezy_tcp@dns-test-service.dns-8590 wheezy_udp@dns-test-service.dns-8590.svc wheezy_tcp@dns-test-service.dns-8590.svc wheezy_udp@_http._tcp.dns-test-service.dns-8590.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8590.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8590 jessie_tcp@dns-test-service.dns-8590 jessie_udp@dns-test-service.dns-8590.svc jessie_tcp@dns-test-service.dns-8590.svc jessie_udp@_http._tcp.dns-test-service.dns-8590.svc jessie_tcp@_http._tcp.dns-test-service.dns-8590.svc]

    Nov 12 13:24:23.953: INFO: DNS probes using dns-8590/dns-test-d0423680-4b25-4d99-a8de-bd4aa5ad1ab2 succeeded

    STEP: deleting the pod 11/12/22 13:24:23.953
    STEP: deleting the test service 11/12/22 13:24:23.974
    STEP: deleting the test headless service 11/12/22 13:24:24.01
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 12 13:24:24.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8590" for this suite. 11/12/22 13:24:24.066
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:24:24.079
Nov 12 13:24:24.079: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename gc 11/12/22 13:24:24.081
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:24.109
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:24.114
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 11/12/22 13:24:24.118
STEP: delete the rc 11/12/22 13:24:29.138
STEP: wait for all pods to be garbage collected 11/12/22 13:24:29.152
STEP: Gathering metrics 11/12/22 13:24:34.163
W1112 13:24:34.172203      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 12 13:24:34.172: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 12 13:24:34.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5648" for this suite. 11/12/22 13:24:34.178
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":334,"skipped":6232,"failed":0}
------------------------------
• [SLOW TEST] [10.112 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:24:24.079
    Nov 12 13:24:24.079: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename gc 11/12/22 13:24:24.081
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:24.109
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:24.114
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 11/12/22 13:24:24.118
    STEP: delete the rc 11/12/22 13:24:29.138
    STEP: wait for all pods to be garbage collected 11/12/22 13:24:29.152
    STEP: Gathering metrics 11/12/22 13:24:34.163
    W1112 13:24:34.172203      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 12 13:24:34.172: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 12 13:24:34.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5648" for this suite. 11/12/22 13:24:34.178
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:24:34.193
Nov 12 13:24:34.193: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:24:34.194
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:34.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:34.232
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 11/12/22 13:24:34.237
Nov 12 13:24:34.238: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: rename a version 11/12/22 13:24:40.471
STEP: check the new version name is served 11/12/22 13:24:40.487
STEP: check the old version name is removed 11/12/22 13:24:43.368
STEP: check the other version is not changed 11/12/22 13:24:44.603
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:24:51.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-385" for this suite. 11/12/22 13:24:51.367
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":335,"skipped":6265,"failed":0}
------------------------------
• [SLOW TEST] [17.182 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:24:34.193
    Nov 12 13:24:34.193: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:24:34.194
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:34.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:34.232
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 11/12/22 13:24:34.237
    Nov 12 13:24:34.238: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: rename a version 11/12/22 13:24:40.471
    STEP: check the new version name is served 11/12/22 13:24:40.487
    STEP: check the old version name is removed 11/12/22 13:24:43.368
    STEP: check the other version is not changed 11/12/22 13:24:44.603
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:24:51.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-385" for this suite. 11/12/22 13:24:51.367
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:24:51.377
Nov 12 13:24:51.377: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename var-expansion 11/12/22 13:24:51.378
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:51.397
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:51.402
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 11/12/22 13:24:51.404
Nov 12 13:24:51.418: INFO: Waiting up to 5m0s for pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179" in namespace "var-expansion-1240" to be "Succeeded or Failed"
Nov 12 13:24:51.427: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179": Phase="Pending", Reason="", readiness=false. Elapsed: 8.778839ms
Nov 12 13:24:53.433: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014153963s
Nov 12 13:24:55.433: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014572945s
STEP: Saw pod success 11/12/22 13:24:55.433
Nov 12 13:24:55.433: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179" satisfied condition "Succeeded or Failed"
Nov 12 13:24:55.437: INFO: Trying to get logs from node ip-172-31-14-110 pod var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179 container dapi-container: <nil>
STEP: delete the pod 11/12/22 13:24:55.455
Nov 12 13:24:55.472: INFO: Waiting for pod var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179 to disappear
Nov 12 13:24:55.477: INFO: Pod var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 12 13:24:55.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1240" for this suite. 11/12/22 13:24:55.482
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":336,"skipped":6270,"failed":0}
------------------------------
• [4.115 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:24:51.377
    Nov 12 13:24:51.377: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename var-expansion 11/12/22 13:24:51.378
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:51.397
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:51.402
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 11/12/22 13:24:51.404
    Nov 12 13:24:51.418: INFO: Waiting up to 5m0s for pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179" in namespace "var-expansion-1240" to be "Succeeded or Failed"
    Nov 12 13:24:51.427: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179": Phase="Pending", Reason="", readiness=false. Elapsed: 8.778839ms
    Nov 12 13:24:53.433: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014153963s
    Nov 12 13:24:55.433: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014572945s
    STEP: Saw pod success 11/12/22 13:24:55.433
    Nov 12 13:24:55.433: INFO: Pod "var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179" satisfied condition "Succeeded or Failed"
    Nov 12 13:24:55.437: INFO: Trying to get logs from node ip-172-31-14-110 pod var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179 container dapi-container: <nil>
    STEP: delete the pod 11/12/22 13:24:55.455
    Nov 12 13:24:55.472: INFO: Waiting for pod var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179 to disappear
    Nov 12 13:24:55.477: INFO: Pod var-expansion-8fee36df-af1e-41d9-90ad-caa6581ad179 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 12 13:24:55.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1240" for this suite. 11/12/22 13:24:55.482
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:24:55.494
Nov 12 13:24:55.494: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename namespaces 11/12/22 13:24:55.495
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:55.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:55.519
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 11/12/22 13:24:55.522
STEP: patching the Namespace 11/12/22 13:24:55.546
STEP: get the Namespace and ensuring it has the label 11/12/22 13:24:55.56
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:24:55.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4243" for this suite. 11/12/22 13:24:55.573
STEP: Destroying namespace "nspatchtest-ef7757d5-91ab-4b22-af68-36b64229e18c-3602" for this suite. 11/12/22 13:24:55.582
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":337,"skipped":6282,"failed":0}
------------------------------
• [0.098 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:24:55.494
    Nov 12 13:24:55.494: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename namespaces 11/12/22 13:24:55.495
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:55.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:55.519
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 11/12/22 13:24:55.522
    STEP: patching the Namespace 11/12/22 13:24:55.546
    STEP: get the Namespace and ensuring it has the label 11/12/22 13:24:55.56
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:24:55.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4243" for this suite. 11/12/22 13:24:55.573
    STEP: Destroying namespace "nspatchtest-ef7757d5-91ab-4b22-af68-36b64229e18c-3602" for this suite. 11/12/22 13:24:55.582
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:24:55.594
Nov 12 13:24:55.594: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename container-probe 11/12/22 13:24:55.595
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:55.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:55.619
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-391f3205-399e-4de1-9702-122b86b84a50 in namespace container-probe-2520 11/12/22 13:24:55.621
Nov 12 13:24:55.635: INFO: Waiting up to 5m0s for pod "busybox-391f3205-399e-4de1-9702-122b86b84a50" in namespace "container-probe-2520" to be "not pending"
Nov 12 13:24:55.644: INFO: Pod "busybox-391f3205-399e-4de1-9702-122b86b84a50": Phase="Pending", Reason="", readiness=false. Elapsed: 9.51014ms
Nov 12 13:24:57.649: INFO: Pod "busybox-391f3205-399e-4de1-9702-122b86b84a50": Phase="Running", Reason="", readiness=true. Elapsed: 2.014165857s
Nov 12 13:24:57.649: INFO: Pod "busybox-391f3205-399e-4de1-9702-122b86b84a50" satisfied condition "not pending"
Nov 12 13:24:57.649: INFO: Started pod busybox-391f3205-399e-4de1-9702-122b86b84a50 in namespace container-probe-2520
STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 13:24:57.649
Nov 12 13:24:57.654: INFO: Initial restart count of pod busybox-391f3205-399e-4de1-9702-122b86b84a50 is 0
STEP: deleting the pod 11/12/22 13:28:58.375
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 12 13:28:58.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2520" for this suite. 11/12/22 13:28:58.397
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":338,"skipped":6310,"failed":0}
------------------------------
• [SLOW TEST] [242.814 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:24:55.594
    Nov 12 13:24:55.594: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename container-probe 11/12/22 13:24:55.595
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:24:55.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:24:55.619
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-391f3205-399e-4de1-9702-122b86b84a50 in namespace container-probe-2520 11/12/22 13:24:55.621
    Nov 12 13:24:55.635: INFO: Waiting up to 5m0s for pod "busybox-391f3205-399e-4de1-9702-122b86b84a50" in namespace "container-probe-2520" to be "not pending"
    Nov 12 13:24:55.644: INFO: Pod "busybox-391f3205-399e-4de1-9702-122b86b84a50": Phase="Pending", Reason="", readiness=false. Elapsed: 9.51014ms
    Nov 12 13:24:57.649: INFO: Pod "busybox-391f3205-399e-4de1-9702-122b86b84a50": Phase="Running", Reason="", readiness=true. Elapsed: 2.014165857s
    Nov 12 13:24:57.649: INFO: Pod "busybox-391f3205-399e-4de1-9702-122b86b84a50" satisfied condition "not pending"
    Nov 12 13:24:57.649: INFO: Started pod busybox-391f3205-399e-4de1-9702-122b86b84a50 in namespace container-probe-2520
    STEP: checking the pod's current state and verifying that restartCount is present 11/12/22 13:24:57.649
    Nov 12 13:24:57.654: INFO: Initial restart count of pod busybox-391f3205-399e-4de1-9702-122b86b84a50 is 0
    STEP: deleting the pod 11/12/22 13:28:58.375
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 12 13:28:58.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2520" for this suite. 11/12/22 13:28:58.397
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:28:58.41
Nov 12 13:28:58.410: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 13:28:58.411
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:28:58.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:28:58.436
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-8c5ba30f-815e-4005-a4b3-94a396a779a9 11/12/22 13:28:58.456
STEP: Creating secret with name s-test-opt-upd-e3a0ffba-018c-49b2-8edf-1107061da630 11/12/22 13:28:58.463
STEP: Creating the pod 11/12/22 13:28:58.471
Nov 12 13:28:58.485: INFO: Waiting up to 5m0s for pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5" in namespace "secrets-7428" to be "running and ready"
Nov 12 13:28:58.495: INFO: Pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.978171ms
Nov 12 13:28:58.495: INFO: The phase of Pod pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:29:00.502: INFO: Pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5": Phase="Running", Reason="", readiness=true. Elapsed: 2.016259229s
Nov 12 13:29:00.502: INFO: The phase of Pod pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5 is Running (Ready = true)
Nov 12 13:29:00.502: INFO: Pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-8c5ba30f-815e-4005-a4b3-94a396a779a9 11/12/22 13:29:00.542
STEP: Updating secret s-test-opt-upd-e3a0ffba-018c-49b2-8edf-1107061da630 11/12/22 13:29:00.551
STEP: Creating secret with name s-test-opt-create-645dfd24-34c4-42d6-8fbb-7b15727c8609 11/12/22 13:29:00.558
STEP: waiting to observe update in volume 11/12/22 13:29:00.564
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 13:29:02.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7428" for this suite. 11/12/22 13:29:02.608
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":339,"skipped":6344,"failed":0}
------------------------------
• [4.217 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:28:58.41
    Nov 12 13:28:58.410: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 13:28:58.411
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:28:58.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:28:58.436
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-8c5ba30f-815e-4005-a4b3-94a396a779a9 11/12/22 13:28:58.456
    STEP: Creating secret with name s-test-opt-upd-e3a0ffba-018c-49b2-8edf-1107061da630 11/12/22 13:28:58.463
    STEP: Creating the pod 11/12/22 13:28:58.471
    Nov 12 13:28:58.485: INFO: Waiting up to 5m0s for pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5" in namespace "secrets-7428" to be "running and ready"
    Nov 12 13:28:58.495: INFO: Pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.978171ms
    Nov 12 13:28:58.495: INFO: The phase of Pod pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:29:00.502: INFO: Pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5": Phase="Running", Reason="", readiness=true. Elapsed: 2.016259229s
    Nov 12 13:29:00.502: INFO: The phase of Pod pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5 is Running (Ready = true)
    Nov 12 13:29:00.502: INFO: Pod "pod-secrets-1a5aaf3d-e9b0-4837-8b79-5679fa431af5" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-8c5ba30f-815e-4005-a4b3-94a396a779a9 11/12/22 13:29:00.542
    STEP: Updating secret s-test-opt-upd-e3a0ffba-018c-49b2-8edf-1107061da630 11/12/22 13:29:00.551
    STEP: Creating secret with name s-test-opt-create-645dfd24-34c4-42d6-8fbb-7b15727c8609 11/12/22 13:29:00.558
    STEP: waiting to observe update in volume 11/12/22 13:29:00.564
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 13:29:02.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7428" for this suite. 11/12/22 13:29:02.608
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:29:02.628
Nov 12 13:29:02.628: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:29:02.629
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:29:02.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:29:02.658
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-aa53a226-7070-4882-9f34-e011683a6bab 11/12/22 13:29:02.663
STEP: Creating a pod to test consume configMaps 11/12/22 13:29:02.673
Nov 12 13:29:02.697: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c" in namespace "projected-9008" to be "Succeeded or Failed"
Nov 12 13:29:02.711: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.257906ms
Nov 12 13:29:04.716: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018867659s
Nov 12 13:29:06.717: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019851739s
STEP: Saw pod success 11/12/22 13:29:06.717
Nov 12 13:29:06.718: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c" satisfied condition "Succeeded or Failed"
Nov 12 13:29:06.722: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c container projected-configmap-volume-test: <nil>
STEP: delete the pod 11/12/22 13:29:06.746
Nov 12 13:29:06.762: INFO: Waiting for pod pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c to disappear
Nov 12 13:29:06.766: INFO: Pod pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 12 13:29:06.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9008" for this suite. 11/12/22 13:29:06.771
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":340,"skipped":6346,"failed":0}
------------------------------
• [4.152 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:29:02.628
    Nov 12 13:29:02.628: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:29:02.629
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:29:02.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:29:02.658
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-aa53a226-7070-4882-9f34-e011683a6bab 11/12/22 13:29:02.663
    STEP: Creating a pod to test consume configMaps 11/12/22 13:29:02.673
    Nov 12 13:29:02.697: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c" in namespace "projected-9008" to be "Succeeded or Failed"
    Nov 12 13:29:02.711: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.257906ms
    Nov 12 13:29:04.716: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018867659s
    Nov 12 13:29:06.717: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019851739s
    STEP: Saw pod success 11/12/22 13:29:06.717
    Nov 12 13:29:06.718: INFO: Pod "pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c" satisfied condition "Succeeded or Failed"
    Nov 12 13:29:06.722: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c container projected-configmap-volume-test: <nil>
    STEP: delete the pod 11/12/22 13:29:06.746
    Nov 12 13:29:06.762: INFO: Waiting for pod pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c to disappear
    Nov 12 13:29:06.766: INFO: Pod pod-projected-configmaps-8b17a102-8a9b-4834-acca-f5f85a860a5c no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 12 13:29:06.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9008" for this suite. 11/12/22 13:29:06.771
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:29:06.784
Nov 12 13:29:06.785: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename sched-preemption 11/12/22 13:29:06.785
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:29:06.805
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:29:06.809
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 12 13:29:06.833: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 12 13:30:06.860: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 11/12/22 13:30:06.865
Nov 12 13:30:06.909: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 12 13:30:06.951: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 12 13:30:06.980: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 12 13:30:06.992: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 12 13:30:07.028: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 12 13:30:07.051: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/12/22 13:30:07.051
Nov 12 13:30:07.051: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8799" to be "running"
Nov 12 13:30:07.063: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.636535ms
Nov 12 13:30:09.068: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016495902s
Nov 12 13:30:11.069: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017683855s
Nov 12 13:30:13.073: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021730183s
Nov 12 13:30:15.069: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.017803652s
Nov 12 13:30:15.069: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 12 13:30:15.069: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
Nov 12 13:30:15.076: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.056515ms
Nov 12 13:30:15.077: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 13:30:15.077: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
Nov 12 13:30:15.081: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.628599ms
Nov 12 13:30:15.082: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 13:30:15.082: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
Nov 12 13:30:15.086: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.565206ms
Nov 12 13:30:15.086: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 13:30:15.086: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
Nov 12 13:30:15.094: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 7.650512ms
Nov 12 13:30:17.101: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015018342s
Nov 12 13:30:19.100: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.014049274s
Nov 12 13:30:19.100: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 12 13:30:19.100: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
Nov 12 13:30:19.105: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.375269ms
Nov 12 13:30:19.105: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 11/12/22 13:30:19.105
Nov 12 13:30:19.120: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Nov 12 13:30:19.124: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.720056ms
Nov 12 13:30:21.129: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009416428s
Nov 12 13:30:23.131: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010822048s
Nov 12 13:30:23.131: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 12 13:30:23.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8799" for this suite. 11/12/22 13:30:23.194
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":341,"skipped":6411,"failed":0}
------------------------------
• [SLOW TEST] [76.486 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:29:06.784
    Nov 12 13:29:06.785: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename sched-preemption 11/12/22 13:29:06.785
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:29:06.805
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:29:06.809
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 12 13:29:06.833: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 12 13:30:06.860: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 11/12/22 13:30:06.865
    Nov 12 13:30:06.909: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 12 13:30:06.951: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 12 13:30:06.980: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 12 13:30:06.992: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 12 13:30:07.028: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 12 13:30:07.051: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/12/22 13:30:07.051
    Nov 12 13:30:07.051: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8799" to be "running"
    Nov 12 13:30:07.063: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 11.636535ms
    Nov 12 13:30:09.068: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016495902s
    Nov 12 13:30:11.069: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017683855s
    Nov 12 13:30:13.073: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021730183s
    Nov 12 13:30:15.069: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 8.017803652s
    Nov 12 13:30:15.069: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 12 13:30:15.069: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
    Nov 12 13:30:15.076: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.056515ms
    Nov 12 13:30:15.077: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 13:30:15.077: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
    Nov 12 13:30:15.081: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.628599ms
    Nov 12 13:30:15.082: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 13:30:15.082: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
    Nov 12 13:30:15.086: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.565206ms
    Nov 12 13:30:15.086: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 13:30:15.086: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
    Nov 12 13:30:15.094: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 7.650512ms
    Nov 12 13:30:17.101: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015018342s
    Nov 12 13:30:19.100: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.014049274s
    Nov 12 13:30:19.100: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 12 13:30:19.100: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8799" to be "running"
    Nov 12 13:30:19.105: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.375269ms
    Nov 12 13:30:19.105: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 11/12/22 13:30:19.105
    Nov 12 13:30:19.120: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Nov 12 13:30:19.124: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.720056ms
    Nov 12 13:30:21.129: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009416428s
    Nov 12 13:30:23.131: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010822048s
    Nov 12 13:30:23.131: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 12 13:30:23.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8799" for this suite. 11/12/22 13:30:23.194
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:23.273
Nov 12 13:30:23.273: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename events 11/12/22 13:30:23.274
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:23.294
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:23.3
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 11/12/22 13:30:23.303
STEP: listing events in all namespaces 11/12/22 13:30:23.32
STEP: listing events in test namespace 11/12/22 13:30:23.328
STEP: listing events with field selection filtering on source 11/12/22 13:30:23.338
STEP: listing events with field selection filtering on reportingController 11/12/22 13:30:23.346
STEP: getting the test event 11/12/22 13:30:23.354
STEP: patching the test event 11/12/22 13:30:23.361
STEP: getting the test event 11/12/22 13:30:23.381
STEP: updating the test event 11/12/22 13:30:23.392
STEP: getting the test event 11/12/22 13:30:23.402
STEP: deleting the test event 11/12/22 13:30:23.408
STEP: listing events in all namespaces 11/12/22 13:30:23.422
STEP: listing events in test namespace 11/12/22 13:30:23.429
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 12 13:30:23.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5133" for this suite. 11/12/22 13:30:23.439
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":342,"skipped":6433,"failed":0}
------------------------------
• [0.176 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:23.273
    Nov 12 13:30:23.273: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename events 11/12/22 13:30:23.274
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:23.294
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:23.3
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 11/12/22 13:30:23.303
    STEP: listing events in all namespaces 11/12/22 13:30:23.32
    STEP: listing events in test namespace 11/12/22 13:30:23.328
    STEP: listing events with field selection filtering on source 11/12/22 13:30:23.338
    STEP: listing events with field selection filtering on reportingController 11/12/22 13:30:23.346
    STEP: getting the test event 11/12/22 13:30:23.354
    STEP: patching the test event 11/12/22 13:30:23.361
    STEP: getting the test event 11/12/22 13:30:23.381
    STEP: updating the test event 11/12/22 13:30:23.392
    STEP: getting the test event 11/12/22 13:30:23.402
    STEP: deleting the test event 11/12/22 13:30:23.408
    STEP: listing events in all namespaces 11/12/22 13:30:23.422
    STEP: listing events in test namespace 11/12/22 13:30:23.429
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 12 13:30:23.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5133" for this suite. 11/12/22 13:30:23.439
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:23.449
Nov 12 13:30:23.449: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 13:30:23.45
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:23.472
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:23.476
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 13:30:23.504
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 13:30:23.776
STEP: Deploying the webhook pod 11/12/22 13:30:23.785
STEP: Wait for the deployment to be ready 11/12/22 13:30:23.801
Nov 12 13:30:23.816: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/12/22 13:30:25.834
STEP: Verifying the service has paired with the endpoint 11/12/22 13:30:25.846
Nov 12 13:30:26.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 11/12/22 13:30:26.928
STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 13:30:26.965
STEP: Deleting the collection of validation webhooks 11/12/22 13:30:26.999
STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 13:30:27.076
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:30:27.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5640" for this suite. 11/12/22 13:30:27.097
STEP: Destroying namespace "webhook-5640-markers" for this suite. 11/12/22 13:30:27.105
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":343,"skipped":6435,"failed":0}
------------------------------
• [3.748 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:23.449
    Nov 12 13:30:23.449: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 13:30:23.45
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:23.472
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:23.476
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 13:30:23.504
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 13:30:23.776
    STEP: Deploying the webhook pod 11/12/22 13:30:23.785
    STEP: Wait for the deployment to be ready 11/12/22 13:30:23.801
    Nov 12 13:30:23.816: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/12/22 13:30:25.834
    STEP: Verifying the service has paired with the endpoint 11/12/22 13:30:25.846
    Nov 12 13:30:26.846: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 11/12/22 13:30:26.928
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 13:30:26.965
    STEP: Deleting the collection of validation webhooks 11/12/22 13:30:26.999
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/12/22 13:30:27.076
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:30:27.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5640" for this suite. 11/12/22 13:30:27.097
    STEP: Destroying namespace "webhook-5640-markers" for this suite. 11/12/22 13:30:27.105
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:27.2
Nov 12 13:30:27.200: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:30:27.201
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:27.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:27.23
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:30:27.236
Nov 12 13:30:27.251: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b" in namespace "downward-api-1424" to be "Succeeded or Failed"
Nov 12 13:30:27.259: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.664012ms
Nov 12 13:30:29.263: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b": Phase="Running", Reason="", readiness=false. Elapsed: 2.011894629s
Nov 12 13:30:31.264: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012616086s
STEP: Saw pod success 11/12/22 13:30:31.264
Nov 12 13:30:31.264: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b" satisfied condition "Succeeded or Failed"
Nov 12 13:30:31.269: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b container client-container: <nil>
STEP: delete the pod 11/12/22 13:30:31.278
Nov 12 13:30:31.292: INFO: Waiting for pod downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b to disappear
Nov 12 13:30:31.297: INFO: Pod downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:30:31.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1424" for this suite. 11/12/22 13:30:31.308
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":344,"skipped":6453,"failed":0}
------------------------------
• [4.125 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:27.2
    Nov 12 13:30:27.200: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:30:27.201
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:27.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:27.23
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:30:27.236
    Nov 12 13:30:27.251: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b" in namespace "downward-api-1424" to be "Succeeded or Failed"
    Nov 12 13:30:27.259: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.664012ms
    Nov 12 13:30:29.263: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b": Phase="Running", Reason="", readiness=false. Elapsed: 2.011894629s
    Nov 12 13:30:31.264: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012616086s
    STEP: Saw pod success 11/12/22 13:30:31.264
    Nov 12 13:30:31.264: INFO: Pod "downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b" satisfied condition "Succeeded or Failed"
    Nov 12 13:30:31.269: INFO: Trying to get logs from node ip-172-31-14-110 pod downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b container client-container: <nil>
    STEP: delete the pod 11/12/22 13:30:31.278
    Nov 12 13:30:31.292: INFO: Waiting for pod downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b to disappear
    Nov 12 13:30:31.297: INFO: Pod downwardapi-volume-66554800-fc37-4cde-8525-620e2c2d834b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:30:31.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1424" for this suite. 11/12/22 13:30:31.308
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:31.326
Nov 12 13:30:31.326: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubelet-test 11/12/22 13:30:31.327
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:31.359
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:31.366
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Nov 12 13:30:31.396: INFO: Waiting up to 5m0s for pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469" in namespace "kubelet-test-5646" to be "running and ready"
Nov 12 13:30:31.402: INFO: Pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469": Phase="Pending", Reason="", readiness=false. Elapsed: 6.084733ms
Nov 12 13:30:31.402: INFO: The phase of Pod busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:30:33.408: INFO: Pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469": Phase="Running", Reason="", readiness=true. Elapsed: 2.011944279s
Nov 12 13:30:33.408: INFO: The phase of Pod busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469 is Running (Ready = true)
Nov 12 13:30:33.408: INFO: Pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 12 13:30:33.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5646" for this suite. 11/12/22 13:30:33.427
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":345,"skipped":6461,"failed":0}
------------------------------
• [2.109 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:31.326
    Nov 12 13:30:31.326: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubelet-test 11/12/22 13:30:31.327
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:31.359
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:31.366
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Nov 12 13:30:31.396: INFO: Waiting up to 5m0s for pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469" in namespace "kubelet-test-5646" to be "running and ready"
    Nov 12 13:30:31.402: INFO: Pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469": Phase="Pending", Reason="", readiness=false. Elapsed: 6.084733ms
    Nov 12 13:30:31.402: INFO: The phase of Pod busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:30:33.408: INFO: Pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469": Phase="Running", Reason="", readiness=true. Elapsed: 2.011944279s
    Nov 12 13:30:33.408: INFO: The phase of Pod busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469 is Running (Ready = true)
    Nov 12 13:30:33.408: INFO: Pod "busybox-scheduling-4ef45b25-b17d-4f3f-9211-bf12811d9469" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 12 13:30:33.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5646" for this suite. 11/12/22 13:30:33.427
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:33.435
Nov 12 13:30:33.435: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename disruption 11/12/22 13:30:33.436
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:33.455
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:33.458
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 11/12/22 13:30:33.46
STEP: Waiting for the pdb to be processed 11/12/22 13:30:33.467
STEP: First trying to evict a pod which shouldn't be evictable 11/12/22 13:30:35.486
STEP: Waiting for all pods to be running 11/12/22 13:30:35.486
Nov 12 13:30:35.492: INFO: pods: 0 < 3
Nov 12 13:30:37.497: INFO: running pods: 2 < 3
STEP: locating a running pod 11/12/22 13:30:39.499
STEP: Updating the pdb to allow a pod to be evicted 11/12/22 13:30:39.514
STEP: Waiting for the pdb to be processed 11/12/22 13:30:39.53
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 13:30:39.534
STEP: Waiting for all pods to be running 11/12/22 13:30:39.534
STEP: Waiting for the pdb to observed all healthy pods 11/12/22 13:30:39.541
STEP: Patching the pdb to disallow a pod to be evicted 11/12/22 13:30:39.58
STEP: Waiting for the pdb to be processed 11/12/22 13:30:39.611
STEP: Waiting for all pods to be running 11/12/22 13:30:39.616
Nov 12 13:30:39.621: INFO: running pods: 2 < 3
STEP: locating a running pod 11/12/22 13:30:41.626
STEP: Deleting the pdb to allow a pod to be evicted 11/12/22 13:30:41.64
STEP: Waiting for the pdb to be deleted 11/12/22 13:30:41.652
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 13:30:41.658
STEP: Waiting for all pods to be running 11/12/22 13:30:41.658
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 12 13:30:41.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-7182" for this suite. 11/12/22 13:30:41.687
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":346,"skipped":6463,"failed":0}
------------------------------
• [SLOW TEST] [8.269 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:33.435
    Nov 12 13:30:33.435: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename disruption 11/12/22 13:30:33.436
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:33.455
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:33.458
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 11/12/22 13:30:33.46
    STEP: Waiting for the pdb to be processed 11/12/22 13:30:33.467
    STEP: First trying to evict a pod which shouldn't be evictable 11/12/22 13:30:35.486
    STEP: Waiting for all pods to be running 11/12/22 13:30:35.486
    Nov 12 13:30:35.492: INFO: pods: 0 < 3
    Nov 12 13:30:37.497: INFO: running pods: 2 < 3
    STEP: locating a running pod 11/12/22 13:30:39.499
    STEP: Updating the pdb to allow a pod to be evicted 11/12/22 13:30:39.514
    STEP: Waiting for the pdb to be processed 11/12/22 13:30:39.53
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 13:30:39.534
    STEP: Waiting for all pods to be running 11/12/22 13:30:39.534
    STEP: Waiting for the pdb to observed all healthy pods 11/12/22 13:30:39.541
    STEP: Patching the pdb to disallow a pod to be evicted 11/12/22 13:30:39.58
    STEP: Waiting for the pdb to be processed 11/12/22 13:30:39.611
    STEP: Waiting for all pods to be running 11/12/22 13:30:39.616
    Nov 12 13:30:39.621: INFO: running pods: 2 < 3
    STEP: locating a running pod 11/12/22 13:30:41.626
    STEP: Deleting the pdb to allow a pod to be evicted 11/12/22 13:30:41.64
    STEP: Waiting for the pdb to be deleted 11/12/22 13:30:41.652
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/12/22 13:30:41.658
    STEP: Waiting for all pods to be running 11/12/22 13:30:41.658
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 12 13:30:41.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-7182" for this suite. 11/12/22 13:30:41.687
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:41.708
Nov 12 13:30:41.708: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:30:41.71
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:41.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:41.746
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 11/12/22 13:30:41.749
Nov 12 13:30:41.767: INFO: Waiting up to 5m0s for pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6" in namespace "downward-api-1457" to be "running and ready"
Nov 12 13:30:41.773: INFO: Pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.104233ms
Nov 12 13:30:41.773: INFO: The phase of Pod labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6 is Pending, waiting for it to be Running (with Ready = true)
Nov 12 13:30:43.778: INFO: Pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6": Phase="Running", Reason="", readiness=true. Elapsed: 2.011546619s
Nov 12 13:30:43.778: INFO: The phase of Pod labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6 is Running (Ready = true)
Nov 12 13:30:43.779: INFO: Pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6" satisfied condition "running and ready"
Nov 12 13:30:44.316: INFO: Successfully updated pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:30:48.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1457" for this suite. 11/12/22 13:30:48.346
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":347,"skipped":6469,"failed":0}
------------------------------
• [SLOW TEST] [6.647 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:41.708
    Nov 12 13:30:41.708: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:30:41.71
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:41.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:41.746
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 11/12/22 13:30:41.749
    Nov 12 13:30:41.767: INFO: Waiting up to 5m0s for pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6" in namespace "downward-api-1457" to be "running and ready"
    Nov 12 13:30:41.773: INFO: Pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.104233ms
    Nov 12 13:30:41.773: INFO: The phase of Pod labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6 is Pending, waiting for it to be Running (with Ready = true)
    Nov 12 13:30:43.778: INFO: Pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6": Phase="Running", Reason="", readiness=true. Elapsed: 2.011546619s
    Nov 12 13:30:43.778: INFO: The phase of Pod labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6 is Running (Ready = true)
    Nov 12 13:30:43.779: INFO: Pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6" satisfied condition "running and ready"
    Nov 12 13:30:44.316: INFO: Successfully updated pod "labelsupdate8bdf8cb7-de7f-44ca-ac5b-0af5836fccd6"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:30:48.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1457" for this suite. 11/12/22 13:30:48.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:48.357
Nov 12 13:30:48.357: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename init-container 11/12/22 13:30:48.358
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:48.376
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:48.381
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 11/12/22 13:30:48.385
Nov 12 13:30:48.385: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 12 13:30:52.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3910" for this suite. 11/12/22 13:30:52.675
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":348,"skipped":6482,"failed":0}
------------------------------
• [4.338 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:48.357
    Nov 12 13:30:48.357: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename init-container 11/12/22 13:30:48.358
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:48.376
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:48.381
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 11/12/22 13:30:48.385
    Nov 12 13:30:48.385: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 12 13:30:52.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-3910" for this suite. 11/12/22 13:30:52.675
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:52.696
Nov 12 13:30:52.696: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename secrets 11/12/22 13:30:52.697
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:52.716
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:52.724
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-ece416fd-ee53-43b6-89a0-b21d17229258 11/12/22 13:30:52.762
STEP: Creating a pod to test consume secrets 11/12/22 13:30:52.771
Nov 12 13:30:52.783: INFO: Waiting up to 5m0s for pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3" in namespace "secrets-6185" to be "Succeeded or Failed"
Nov 12 13:30:52.791: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.303761ms
Nov 12 13:30:54.798: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01406s
Nov 12 13:30:56.798: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014078947s
STEP: Saw pod success 11/12/22 13:30:56.798
Nov 12 13:30:56.798: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3" satisfied condition "Succeeded or Failed"
Nov 12 13:30:56.803: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3 container secret-volume-test: <nil>
STEP: delete the pod 11/12/22 13:30:56.81
Nov 12 13:30:56.825: INFO: Waiting for pod pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3 to disappear
Nov 12 13:30:56.830: INFO: Pod pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 12 13:30:56.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6185" for this suite. 11/12/22 13:30:56.834
STEP: Destroying namespace "secret-namespace-1672" for this suite. 11/12/22 13:30:56.845
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":349,"skipped":6484,"failed":0}
------------------------------
• [4.162 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:52.696
    Nov 12 13:30:52.696: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename secrets 11/12/22 13:30:52.697
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:52.716
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:52.724
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-ece416fd-ee53-43b6-89a0-b21d17229258 11/12/22 13:30:52.762
    STEP: Creating a pod to test consume secrets 11/12/22 13:30:52.771
    Nov 12 13:30:52.783: INFO: Waiting up to 5m0s for pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3" in namespace "secrets-6185" to be "Succeeded or Failed"
    Nov 12 13:30:52.791: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.303761ms
    Nov 12 13:30:54.798: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01406s
    Nov 12 13:30:56.798: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014078947s
    STEP: Saw pod success 11/12/22 13:30:56.798
    Nov 12 13:30:56.798: INFO: Pod "pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3" satisfied condition "Succeeded or Failed"
    Nov 12 13:30:56.803: INFO: Trying to get logs from node ip-172-31-89-190 pod pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3 container secret-volume-test: <nil>
    STEP: delete the pod 11/12/22 13:30:56.81
    Nov 12 13:30:56.825: INFO: Waiting for pod pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3 to disappear
    Nov 12 13:30:56.830: INFO: Pod pod-secrets-824a0d6d-50c2-4ade-b946-0e0a881f37c3 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 12 13:30:56.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6185" for this suite. 11/12/22 13:30:56.834
    STEP: Destroying namespace "secret-namespace-1672" for this suite. 11/12/22 13:30:56.845
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:30:56.859
Nov 12 13:30:56.860: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename projected 11/12/22 13:30:56.86
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:56.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:56.883
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:30:56.886
Nov 12 13:30:56.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248" in namespace "projected-1197" to be "Succeeded or Failed"
Nov 12 13:30:56.905: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248": Phase="Pending", Reason="", readiness=false. Elapsed: 5.790585ms
Nov 12 13:30:58.909: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010512456s
Nov 12 13:31:00.910: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010836573s
STEP: Saw pod success 11/12/22 13:31:00.91
Nov 12 13:31:00.910: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248" satisfied condition "Succeeded or Failed"
Nov 12 13:31:00.914: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248 container client-container: <nil>
STEP: delete the pod 11/12/22 13:31:00.922
Nov 12 13:31:00.938: INFO: Waiting for pod downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248 to disappear
Nov 12 13:31:00.943: INFO: Pod downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 12 13:31:00.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1197" for this suite. 11/12/22 13:31:00.949
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":350,"skipped":6509,"failed":0}
------------------------------
• [4.100 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:30:56.859
    Nov 12 13:30:56.860: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename projected 11/12/22 13:30:56.86
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:30:56.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:30:56.883
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:30:56.886
    Nov 12 13:30:56.899: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248" in namespace "projected-1197" to be "Succeeded or Failed"
    Nov 12 13:30:56.905: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248": Phase="Pending", Reason="", readiness=false. Elapsed: 5.790585ms
    Nov 12 13:30:58.909: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010512456s
    Nov 12 13:31:00.910: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010836573s
    STEP: Saw pod success 11/12/22 13:31:00.91
    Nov 12 13:31:00.910: INFO: Pod "downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248" satisfied condition "Succeeded or Failed"
    Nov 12 13:31:00.914: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248 container client-container: <nil>
    STEP: delete the pod 11/12/22 13:31:00.922
    Nov 12 13:31:00.938: INFO: Waiting for pod downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248 to disappear
    Nov 12 13:31:00.943: INFO: Pod downwardapi-volume-2693a68b-8fbb-4231-ba5d-52a3c15ed248 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 12 13:31:00.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1197" for this suite. 11/12/22 13:31:00.949
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:00.962
Nov 12 13:31:00.962: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 13:31:00.963
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:00.981
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:00.983
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 11/12/22 13:31:00.987
Nov 12 13:31:00.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-9052 api-versions'
Nov 12 13:31:01.049: INFO: stderr: ""
Nov 12 13:31:01.049: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 13:31:01.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9052" for this suite. 11/12/22 13:31:01.054
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":351,"skipped":6543,"failed":0}
------------------------------
• [0.102 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:00.962
    Nov 12 13:31:00.962: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 13:31:00.963
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:00.981
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:00.983
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 11/12/22 13:31:00.987
    Nov 12 13:31:00.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-9052 api-versions'
    Nov 12 13:31:01.049: INFO: stderr: ""
    Nov 12 13:31:01.049: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 13:31:01.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9052" for this suite. 11/12/22 13:31:01.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:01.065
Nov 12 13:31:01.065: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:31:01.066
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:01.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:01.087
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 11/12/22 13:31:01.09
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:31:01.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5840" for this suite. 11/12/22 13:31:01.1
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":352,"skipped":6549,"failed":0}
------------------------------
• [0.047 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:01.065
    Nov 12 13:31:01.065: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:31:01.066
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:01.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:01.087
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 11/12/22 13:31:01.09
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:31:01.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5840" for this suite. 11/12/22 13:31:01.1
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:01.114
Nov 12 13:31:01.114: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 13:31:01.114
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:01.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:01.137
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 11/12/22 13:31:01.139
Nov 12 13:31:01.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 create -f -'
Nov 12 13:31:01.373: INFO: stderr: ""
Nov 12 13:31:01.373: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:31:01.373
Nov 12 13:31:01.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:31:01.464: INFO: stderr: ""
Nov 12 13:31:01.464: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-vrr5w "
Nov 12 13:31:01.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:01.551: INFO: stderr: ""
Nov 12 13:31:01.551: INFO: stdout: ""
Nov 12 13:31:01.551: INFO: update-demo-nautilus-k2mc8 is created but not running
Nov 12 13:31:06.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:31:06.657: INFO: stderr: ""
Nov 12 13:31:06.657: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-vrr5w "
Nov 12 13:31:06.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:06.754: INFO: stderr: ""
Nov 12 13:31:06.754: INFO: stdout: "true"
Nov 12 13:31:06.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:31:06.858: INFO: stderr: ""
Nov 12 13:31:06.858: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:31:06.858: INFO: validating pod update-demo-nautilus-k2mc8
Nov 12 13:31:06.865: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:31:06.865: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:31:06.865: INFO: update-demo-nautilus-k2mc8 is verified up and running
Nov 12 13:31:06.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-vrr5w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:06.971: INFO: stderr: ""
Nov 12 13:31:06.971: INFO: stdout: "true"
Nov 12 13:31:06.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-vrr5w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:31:07.070: INFO: stderr: ""
Nov 12 13:31:07.070: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:31:07.070: INFO: validating pod update-demo-nautilus-vrr5w
Nov 12 13:31:07.077: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:31:07.077: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:31:07.077: INFO: update-demo-nautilus-vrr5w is verified up and running
STEP: scaling down the replication controller 11/12/22 13:31:07.077
Nov 12 13:31:07.078: INFO: scanned /root for discovery docs: <nil>
Nov 12 13:31:07.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Nov 12 13:31:08.205: INFO: stderr: ""
Nov 12 13:31:08.205: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:31:08.205
Nov 12 13:31:08.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:31:08.268: INFO: stderr: ""
Nov 12 13:31:08.268: INFO: stdout: "update-demo-nautilus-k2mc8 "
Nov 12 13:31:08.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:08.330: INFO: stderr: ""
Nov 12 13:31:08.331: INFO: stdout: "true"
Nov 12 13:31:08.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:31:08.404: INFO: stderr: ""
Nov 12 13:31:08.404: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:31:08.404: INFO: validating pod update-demo-nautilus-k2mc8
Nov 12 13:31:08.408: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:31:08.408: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:31:08.408: INFO: update-demo-nautilus-k2mc8 is verified up and running
STEP: scaling up the replication controller 11/12/22 13:31:08.408
Nov 12 13:31:08.410: INFO: scanned /root for discovery docs: <nil>
Nov 12 13:31:08.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Nov 12 13:31:09.515: INFO: stderr: ""
Nov 12 13:31:09.515: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:31:09.515
Nov 12 13:31:09.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:31:09.594: INFO: stderr: ""
Nov 12 13:31:09.594: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-x8pkw "
Nov 12 13:31:09.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:09.664: INFO: stderr: ""
Nov 12 13:31:09.665: INFO: stdout: "true"
Nov 12 13:31:09.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:31:09.761: INFO: stderr: ""
Nov 12 13:31:09.761: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:31:09.761: INFO: validating pod update-demo-nautilus-k2mc8
Nov 12 13:31:09.771: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:31:09.771: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:31:09.771: INFO: update-demo-nautilus-k2mc8 is verified up and running
Nov 12 13:31:09.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-x8pkw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:09.875: INFO: stderr: ""
Nov 12 13:31:09.875: INFO: stdout: ""
Nov 12 13:31:09.875: INFO: update-demo-nautilus-x8pkw is created but not running
Nov 12 13:31:14.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 12 13:31:14.989: INFO: stderr: ""
Nov 12 13:31:14.989: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-x8pkw "
Nov 12 13:31:14.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:15.078: INFO: stderr: ""
Nov 12 13:31:15.078: INFO: stdout: "true"
Nov 12 13:31:15.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:31:15.166: INFO: stderr: ""
Nov 12 13:31:15.166: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:31:15.166: INFO: validating pod update-demo-nautilus-k2mc8
Nov 12 13:31:15.171: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:31:15.171: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:31:15.171: INFO: update-demo-nautilus-k2mc8 is verified up and running
Nov 12 13:31:15.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-x8pkw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 12 13:31:15.256: INFO: stderr: ""
Nov 12 13:31:15.256: INFO: stdout: "true"
Nov 12 13:31:15.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-x8pkw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 12 13:31:15.342: INFO: stderr: ""
Nov 12 13:31:15.342: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 12 13:31:15.342: INFO: validating pod update-demo-nautilus-x8pkw
Nov 12 13:31:15.348: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 12 13:31:15.348: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 12 13:31:15.348: INFO: update-demo-nautilus-x8pkw is verified up and running
STEP: using delete to clean up resources 11/12/22 13:31:15.348
Nov 12 13:31:15.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 delete --grace-period=0 --force -f -'
Nov 12 13:31:15.428: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 12 13:31:15.428: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 12 13:31:15.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get rc,svc -l name=update-demo --no-headers'
Nov 12 13:31:15.520: INFO: stderr: "No resources found in kubectl-2016 namespace.\n"
Nov 12 13:31:15.520: INFO: stdout: ""
Nov 12 13:31:15.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 12 13:31:15.625: INFO: stderr: ""
Nov 12 13:31:15.625: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 13:31:15.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2016" for this suite. 11/12/22 13:31:15.63
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":353,"skipped":6574,"failed":0}
------------------------------
• [SLOW TEST] [14.528 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:01.114
    Nov 12 13:31:01.114: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 13:31:01.114
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:01.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:01.137
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 11/12/22 13:31:01.139
    Nov 12 13:31:01.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 create -f -'
    Nov 12 13:31:01.373: INFO: stderr: ""
    Nov 12 13:31:01.373: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:31:01.373
    Nov 12 13:31:01.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:31:01.464: INFO: stderr: ""
    Nov 12 13:31:01.464: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-vrr5w "
    Nov 12 13:31:01.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:01.551: INFO: stderr: ""
    Nov 12 13:31:01.551: INFO: stdout: ""
    Nov 12 13:31:01.551: INFO: update-demo-nautilus-k2mc8 is created but not running
    Nov 12 13:31:06.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:31:06.657: INFO: stderr: ""
    Nov 12 13:31:06.657: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-vrr5w "
    Nov 12 13:31:06.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:06.754: INFO: stderr: ""
    Nov 12 13:31:06.754: INFO: stdout: "true"
    Nov 12 13:31:06.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:31:06.858: INFO: stderr: ""
    Nov 12 13:31:06.858: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:31:06.858: INFO: validating pod update-demo-nautilus-k2mc8
    Nov 12 13:31:06.865: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:31:06.865: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:31:06.865: INFO: update-demo-nautilus-k2mc8 is verified up and running
    Nov 12 13:31:06.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-vrr5w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:06.971: INFO: stderr: ""
    Nov 12 13:31:06.971: INFO: stdout: "true"
    Nov 12 13:31:06.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-vrr5w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:31:07.070: INFO: stderr: ""
    Nov 12 13:31:07.070: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:31:07.070: INFO: validating pod update-demo-nautilus-vrr5w
    Nov 12 13:31:07.077: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:31:07.077: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:31:07.077: INFO: update-demo-nautilus-vrr5w is verified up and running
    STEP: scaling down the replication controller 11/12/22 13:31:07.077
    Nov 12 13:31:07.078: INFO: scanned /root for discovery docs: <nil>
    Nov 12 13:31:07.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Nov 12 13:31:08.205: INFO: stderr: ""
    Nov 12 13:31:08.205: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:31:08.205
    Nov 12 13:31:08.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:31:08.268: INFO: stderr: ""
    Nov 12 13:31:08.268: INFO: stdout: "update-demo-nautilus-k2mc8 "
    Nov 12 13:31:08.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:08.330: INFO: stderr: ""
    Nov 12 13:31:08.331: INFO: stdout: "true"
    Nov 12 13:31:08.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:31:08.404: INFO: stderr: ""
    Nov 12 13:31:08.404: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:31:08.404: INFO: validating pod update-demo-nautilus-k2mc8
    Nov 12 13:31:08.408: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:31:08.408: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:31:08.408: INFO: update-demo-nautilus-k2mc8 is verified up and running
    STEP: scaling up the replication controller 11/12/22 13:31:08.408
    Nov 12 13:31:08.410: INFO: scanned /root for discovery docs: <nil>
    Nov 12 13:31:08.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Nov 12 13:31:09.515: INFO: stderr: ""
    Nov 12 13:31:09.515: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/12/22 13:31:09.515
    Nov 12 13:31:09.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:31:09.594: INFO: stderr: ""
    Nov 12 13:31:09.594: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-x8pkw "
    Nov 12 13:31:09.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:09.664: INFO: stderr: ""
    Nov 12 13:31:09.665: INFO: stdout: "true"
    Nov 12 13:31:09.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:31:09.761: INFO: stderr: ""
    Nov 12 13:31:09.761: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:31:09.761: INFO: validating pod update-demo-nautilus-k2mc8
    Nov 12 13:31:09.771: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:31:09.771: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:31:09.771: INFO: update-demo-nautilus-k2mc8 is verified up and running
    Nov 12 13:31:09.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-x8pkw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:09.875: INFO: stderr: ""
    Nov 12 13:31:09.875: INFO: stdout: ""
    Nov 12 13:31:09.875: INFO: update-demo-nautilus-x8pkw is created but not running
    Nov 12 13:31:14.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 12 13:31:14.989: INFO: stderr: ""
    Nov 12 13:31:14.989: INFO: stdout: "update-demo-nautilus-k2mc8 update-demo-nautilus-x8pkw "
    Nov 12 13:31:14.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:15.078: INFO: stderr: ""
    Nov 12 13:31:15.078: INFO: stdout: "true"
    Nov 12 13:31:15.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-k2mc8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:31:15.166: INFO: stderr: ""
    Nov 12 13:31:15.166: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:31:15.166: INFO: validating pod update-demo-nautilus-k2mc8
    Nov 12 13:31:15.171: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:31:15.171: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:31:15.171: INFO: update-demo-nautilus-k2mc8 is verified up and running
    Nov 12 13:31:15.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-x8pkw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 12 13:31:15.256: INFO: stderr: ""
    Nov 12 13:31:15.256: INFO: stdout: "true"
    Nov 12 13:31:15.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods update-demo-nautilus-x8pkw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 12 13:31:15.342: INFO: stderr: ""
    Nov 12 13:31:15.342: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 12 13:31:15.342: INFO: validating pod update-demo-nautilus-x8pkw
    Nov 12 13:31:15.348: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 12 13:31:15.348: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 12 13:31:15.348: INFO: update-demo-nautilus-x8pkw is verified up and running
    STEP: using delete to clean up resources 11/12/22 13:31:15.348
    Nov 12 13:31:15.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 delete --grace-period=0 --force -f -'
    Nov 12 13:31:15.428: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 12 13:31:15.428: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 12 13:31:15.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get rc,svc -l name=update-demo --no-headers'
    Nov 12 13:31:15.520: INFO: stderr: "No resources found in kubectl-2016 namespace.\n"
    Nov 12 13:31:15.520: INFO: stdout: ""
    Nov 12 13:31:15.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-2016 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 12 13:31:15.625: INFO: stderr: ""
    Nov 12 13:31:15.625: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 13:31:15.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2016" for this suite. 11/12/22 13:31:15.63
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:15.643
Nov 12 13:31:15.643: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename kubectl 11/12/22 13:31:15.644
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:15.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:15.665
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 11/12/22 13:31:15.667
Nov 12 13:31:15.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-9683 create -f -'
Nov 12 13:31:15.992: INFO: stderr: ""
Nov 12 13:31:15.992: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/12/22 13:31:15.992
Nov 12 13:31:16.997: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 13:31:16.997: INFO: Found 0 / 1
Nov 12 13:31:17.998: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 13:31:17.998: INFO: Found 1 / 1
Nov 12 13:31:17.998: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 11/12/22 13:31:17.998
Nov 12 13:31:18.002: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 13:31:18.002: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 12 13:31:18.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-9683 patch pod agnhost-primary-cbctf -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 12 13:31:18.088: INFO: stderr: ""
Nov 12 13:31:18.088: INFO: stdout: "pod/agnhost-primary-cbctf patched\n"
STEP: checking annotations 11/12/22 13:31:18.088
Nov 12 13:31:18.093: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 12 13:31:18.093: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 12 13:31:18.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9683" for this suite. 11/12/22 13:31:18.097
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":354,"skipped":6607,"failed":0}
------------------------------
• [2.462 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:15.643
    Nov 12 13:31:15.643: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename kubectl 11/12/22 13:31:15.644
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:15.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:15.665
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 11/12/22 13:31:15.667
    Nov 12 13:31:15.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-9683 create -f -'
    Nov 12 13:31:15.992: INFO: stderr: ""
    Nov 12 13:31:15.992: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/12/22 13:31:15.992
    Nov 12 13:31:16.997: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 13:31:16.997: INFO: Found 0 / 1
    Nov 12 13:31:17.998: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 13:31:17.998: INFO: Found 1 / 1
    Nov 12 13:31:17.998: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 11/12/22 13:31:17.998
    Nov 12 13:31:18.002: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 13:31:18.002: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 12 13:31:18.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=kubectl-9683 patch pod agnhost-primary-cbctf -p {"metadata":{"annotations":{"x":"y"}}}'
    Nov 12 13:31:18.088: INFO: stderr: ""
    Nov 12 13:31:18.088: INFO: stdout: "pod/agnhost-primary-cbctf patched\n"
    STEP: checking annotations 11/12/22 13:31:18.088
    Nov 12 13:31:18.093: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 12 13:31:18.093: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 12 13:31:18.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9683" for this suite. 11/12/22 13:31:18.097
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:18.105
Nov 12 13:31:18.106: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename services 11/12/22 13:31:18.106
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:18.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:18.131
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-4724 11/12/22 13:31:18.136
STEP: creating service affinity-clusterip-transition in namespace services-4724 11/12/22 13:31:18.136
STEP: creating replication controller affinity-clusterip-transition in namespace services-4724 11/12/22 13:31:18.149
I1112 13:31:18.168773      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-4724, replica count: 3
I1112 13:31:21.220022      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 12 13:31:21.233: INFO: Creating new exec pod
Nov 12 13:31:21.244: INFO: Waiting up to 5m0s for pod "execpod-affinitylrt9s" in namespace "services-4724" to be "running"
Nov 12 13:31:21.252: INFO: Pod "execpod-affinitylrt9s": Phase="Pending", Reason="", readiness=false. Elapsed: 7.869497ms
Nov 12 13:31:23.257: INFO: Pod "execpod-affinitylrt9s": Phase="Running", Reason="", readiness=true. Elapsed: 2.012341515s
Nov 12 13:31:23.257: INFO: Pod "execpod-affinitylrt9s" satisfied condition "running"
Nov 12 13:31:24.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Nov 12 13:31:24.418: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Nov 12 13:31:24.418: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 13:31:24.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.85 80'
Nov 12 13:31:24.580: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.85 80\nConnection to 10.152.183.85 80 port [tcp/http] succeeded!\n"
Nov 12 13:31:24.580: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 12 13:31:24.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.85:80/ ; done'
Nov 12 13:31:24.919: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n"
Nov 12 13:31:24.919: INFO: stdout: "\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-xm4vd\naffinity-clusterip-transition-xm4vd\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-xm4vd"
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-xm4vd
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-xm4vd
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-xm4vd
Nov 12 13:31:24.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.85:80/ ; done'
Nov 12 13:31:25.170: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n"
Nov 12 13:31:25.170: INFO: stdout: "\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x"
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
Nov 12 13:31:25.170: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-4724, will wait for the garbage collector to delete the pods 11/12/22 13:31:25.186
Nov 12 13:31:25.255: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.89979ms
Nov 12 13:31:25.355: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.296784ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 12 13:31:27.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4724" for this suite. 11/12/22 13:31:27.394
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":355,"skipped":6615,"failed":0}
------------------------------
• [SLOW TEST] [9.299 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:18.105
    Nov 12 13:31:18.106: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename services 11/12/22 13:31:18.106
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:18.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:18.131
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-4724 11/12/22 13:31:18.136
    STEP: creating service affinity-clusterip-transition in namespace services-4724 11/12/22 13:31:18.136
    STEP: creating replication controller affinity-clusterip-transition in namespace services-4724 11/12/22 13:31:18.149
    I1112 13:31:18.168773      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-4724, replica count: 3
    I1112 13:31:21.220022      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 12 13:31:21.233: INFO: Creating new exec pod
    Nov 12 13:31:21.244: INFO: Waiting up to 5m0s for pod "execpod-affinitylrt9s" in namespace "services-4724" to be "running"
    Nov 12 13:31:21.252: INFO: Pod "execpod-affinitylrt9s": Phase="Pending", Reason="", readiness=false. Elapsed: 7.869497ms
    Nov 12 13:31:23.257: INFO: Pod "execpod-affinitylrt9s": Phase="Running", Reason="", readiness=true. Elapsed: 2.012341515s
    Nov 12 13:31:23.257: INFO: Pod "execpod-affinitylrt9s" satisfied condition "running"
    Nov 12 13:31:24.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Nov 12 13:31:24.418: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Nov 12 13:31:24.418: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 13:31:24.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.85 80'
    Nov 12 13:31:24.580: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.85 80\nConnection to 10.152.183.85 80 port [tcp/http] succeeded!\n"
    Nov 12 13:31:24.580: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 12 13:31:24.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.85:80/ ; done'
    Nov 12 13:31:24.919: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n"
    Nov 12 13:31:24.919: INFO: stdout: "\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-xm4vd\naffinity-clusterip-transition-xm4vd\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-sjdnv\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-xm4vd"
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-xm4vd
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-xm4vd
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-sjdnv
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:24.919: INFO: Received response from host: affinity-clusterip-transition-xm4vd
    Nov 12 13:31:24.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-225746869 --namespace=services-4724 exec execpod-affinitylrt9s -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.85:80/ ; done'
    Nov 12 13:31:25.170: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.85:80/\n"
    Nov 12 13:31:25.170: INFO: stdout: "\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x\naffinity-clusterip-transition-kv87x"
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Received response from host: affinity-clusterip-transition-kv87x
    Nov 12 13:31:25.170: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-4724, will wait for the garbage collector to delete the pods 11/12/22 13:31:25.186
    Nov 12 13:31:25.255: INFO: Deleting ReplicationController affinity-clusterip-transition took: 12.89979ms
    Nov 12 13:31:25.355: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.296784ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 12 13:31:27.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4724" for this suite. 11/12/22 13:31:27.394
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:27.404
Nov 12 13:31:27.404: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename pods 11/12/22 13:31:27.405
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:27.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:27.43
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 11/12/22 13:31:27.432
STEP: submitting the pod to kubernetes 11/12/22 13:31:27.432
STEP: verifying QOS class is set on the pod 11/12/22 13:31:27.446
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Nov 12 13:31:27.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2206" for this suite. 11/12/22 13:31:27.458
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":356,"skipped":6617,"failed":0}
------------------------------
• [0.066 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:27.404
    Nov 12 13:31:27.404: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename pods 11/12/22 13:31:27.405
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:27.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:27.43
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 11/12/22 13:31:27.432
    STEP: submitting the pod to kubernetes 11/12/22 13:31:27.432
    STEP: verifying QOS class is set on the pod 11/12/22 13:31:27.446
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Nov 12 13:31:27.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2206" for this suite. 11/12/22 13:31:27.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:27.471
Nov 12 13:31:27.471: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename replicaset 11/12/22 13:31:27.472
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:27.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:27.545
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/12/22 13:31:27.547
Nov 12 13:31:27.559: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 12 13:31:32.566: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/12/22 13:31:32.566
STEP: getting scale subresource 11/12/22 13:31:32.566
STEP: updating a scale subresource 11/12/22 13:31:32.57
STEP: verifying the replicaset Spec.Replicas was modified 11/12/22 13:31:32.584
STEP: Patch a scale subresource 11/12/22 13:31:32.594
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 12 13:31:32.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2412" for this suite. 11/12/22 13:31:32.643
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":357,"skipped":6623,"failed":0}
------------------------------
• [SLOW TEST] [5.195 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:27.471
    Nov 12 13:31:27.471: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename replicaset 11/12/22 13:31:27.472
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:27.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:27.545
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/12/22 13:31:27.547
    Nov 12 13:31:27.559: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 12 13:31:32.566: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/12/22 13:31:32.566
    STEP: getting scale subresource 11/12/22 13:31:32.566
    STEP: updating a scale subresource 11/12/22 13:31:32.57
    STEP: verifying the replicaset Spec.Replicas was modified 11/12/22 13:31:32.584
    STEP: Patch a scale subresource 11/12/22 13:31:32.594
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 12 13:31:32.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-2412" for this suite. 11/12/22 13:31:32.643
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:32.666
Nov 12 13:31:32.666: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename podtemplate 11/12/22 13:31:32.668
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:32.715
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:32.717
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 12 13:31:32.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-2806" for this suite. 11/12/22 13:31:32.797
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":358,"skipped":6628,"failed":0}
------------------------------
• [0.141 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:32.666
    Nov 12 13:31:32.666: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename podtemplate 11/12/22 13:31:32.668
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:32.715
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:32.717
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 12 13:31:32.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-2806" for this suite. 11/12/22 13:31:32.797
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:32.809
Nov 12 13:31:32.809: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:31:32.81
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:32.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:32.834
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 11/12/22 13:31:32.837
Nov 12 13:31:32.837: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: mark a version not serverd 11/12/22 13:31:40.478
STEP: check the unserved version gets removed 11/12/22 13:31:40.508
STEP: check the other version is not changed 11/12/22 13:31:43.393
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:31:48.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-507" for this suite. 11/12/22 13:31:48.289
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":359,"skipped":6645,"failed":0}
------------------------------
• [SLOW TEST] [15.489 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:32.809
    Nov 12 13:31:32.809: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename crd-publish-openapi 11/12/22 13:31:32.81
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:32.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:32.834
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 11/12/22 13:31:32.837
    Nov 12 13:31:32.837: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: mark a version not serverd 11/12/22 13:31:40.478
    STEP: check the unserved version gets removed 11/12/22 13:31:40.508
    STEP: check the other version is not changed 11/12/22 13:31:43.393
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:31:48.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-507" for this suite. 11/12/22 13:31:48.289
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:48.3
Nov 12 13:31:48.300: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename podtemplate 11/12/22 13:31:48.301
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:48.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:48.33
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 11/12/22 13:31:48.334
STEP: Replace a pod template 11/12/22 13:31:48.341
Nov 12 13:31:48.356: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 12 13:31:48.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8539" for this suite. 11/12/22 13:31:48.363
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":360,"skipped":6662,"failed":0}
------------------------------
• [0.072 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:48.3
    Nov 12 13:31:48.300: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename podtemplate 11/12/22 13:31:48.301
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:48.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:48.33
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 11/12/22 13:31:48.334
    STEP: Replace a pod template 11/12/22 13:31:48.341
    Nov 12 13:31:48.356: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 12 13:31:48.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-8539" for this suite. 11/12/22 13:31:48.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:48.373
Nov 12 13:31:48.373: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename downward-api 11/12/22 13:31:48.374
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:48.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:48.404
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 11/12/22 13:31:48.407
Nov 12 13:31:48.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68" in namespace "downward-api-9792" to be "Succeeded or Failed"
Nov 12 13:31:48.429: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68": Phase="Pending", Reason="", readiness=false. Elapsed: 9.184747ms
Nov 12 13:31:50.435: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015606292s
Nov 12 13:31:52.435: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015211743s
STEP: Saw pod success 11/12/22 13:31:52.435
Nov 12 13:31:52.435: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68" satisfied condition "Succeeded or Failed"
Nov 12 13:31:52.440: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68 container client-container: <nil>
STEP: delete the pod 11/12/22 13:31:52.448
Nov 12 13:31:52.463: INFO: Waiting for pod downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68 to disappear
Nov 12 13:31:52.468: INFO: Pod downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 12 13:31:52.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9792" for this suite. 11/12/22 13:31:52.473
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":361,"skipped":6669,"failed":0}
------------------------------
• [4.111 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:48.373
    Nov 12 13:31:48.373: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename downward-api 11/12/22 13:31:48.374
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:48.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:48.404
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 11/12/22 13:31:48.407
    Nov 12 13:31:48.419: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68" in namespace "downward-api-9792" to be "Succeeded or Failed"
    Nov 12 13:31:48.429: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68": Phase="Pending", Reason="", readiness=false. Elapsed: 9.184747ms
    Nov 12 13:31:50.435: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015606292s
    Nov 12 13:31:52.435: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015211743s
    STEP: Saw pod success 11/12/22 13:31:52.435
    Nov 12 13:31:52.435: INFO: Pod "downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68" satisfied condition "Succeeded or Failed"
    Nov 12 13:31:52.440: INFO: Trying to get logs from node ip-172-31-89-190 pod downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68 container client-container: <nil>
    STEP: delete the pod 11/12/22 13:31:52.448
    Nov 12 13:31:52.463: INFO: Waiting for pod downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68 to disappear
    Nov 12 13:31:52.468: INFO: Pod downwardapi-volume-0fd22394-48e9-4c8d-bed6-532a8e53ff68 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 12 13:31:52.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9792" for this suite. 11/12/22 13:31:52.473
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/12/22 13:31:52.485
Nov 12 13:31:52.485: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
STEP: Building a namespace api object, basename webhook 11/12/22 13:31:52.486
STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:52.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:52.517
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/12/22 13:31:52.54
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 13:31:53.19
STEP: Deploying the webhook pod 11/12/22 13:31:53.206
STEP: Wait for the deployment to be ready 11/12/22 13:31:53.293
Nov 12 13:31:53.325: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/12/22 13:31:55.344
STEP: Verifying the service has paired with the endpoint 11/12/22 13:31:55.383
Nov 12 13:31:56.384: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/12/22 13:31:56.393
STEP: create a configmap that should be updated by the webhook 11/12/22 13:31:56.411
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 12 13:31:56.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1609" for this suite. 11/12/22 13:31:56.439
STEP: Destroying namespace "webhook-1609-markers" for this suite. 11/12/22 13:31:56.448
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":362,"skipped":6702,"failed":0}
------------------------------
• [4.059 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/12/22 13:31:52.485
    Nov 12 13:31:52.485: INFO: >>> kubeConfig: /tmp/kubeconfig-225746869
    STEP: Building a namespace api object, basename webhook 11/12/22 13:31:52.486
    STEP: Waiting for a default service account to be provisioned in namespace 11/12/22 13:31:52.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/12/22 13:31:52.517
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/12/22 13:31:52.54
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/12/22 13:31:53.19
    STEP: Deploying the webhook pod 11/12/22 13:31:53.206
    STEP: Wait for the deployment to be ready 11/12/22 13:31:53.293
    Nov 12 13:31:53.325: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/12/22 13:31:55.344
    STEP: Verifying the service has paired with the endpoint 11/12/22 13:31:55.383
    Nov 12 13:31:56.384: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/12/22 13:31:56.393
    STEP: create a configmap that should be updated by the webhook 11/12/22 13:31:56.411
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 12 13:31:56.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1609" for this suite. 11/12/22 13:31:56.439
    STEP: Destroying namespace "webhook-1609-markers" for this suite. 11/12/22 13:31:56.448
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Nov 12 13:31:56.546: INFO: Running AfterSuite actions on all nodes
Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Nov 12 13:31:56.546: INFO: Running AfterSuite actions on node 1
Nov 12 13:31:56.546: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 12 13:31:56.546: INFO: Running AfterSuite actions on all nodes
    Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Nov 12 13:31:56.546: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 12 13:31:56.546: INFO: Running AfterSuite actions on node 1
    Nov 12 13:31:56.546: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.145 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5596.059 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h33m16.728774644s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

