  I1209 12:07:33.253235      18 e2e.go:117] Starting e2e run "52bbc029-43ee-4e5f-9bdb-3340e795d598" on Ginkgo node 1
  Dec  9 12:07:33.275: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1702123653 - will randomize all specs

Will run 380 of 7389 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:153
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Dec  9 12:07:33.421: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 12:07:33.422: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Dec  9 12:07:33.462: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Dec  9 12:07:33.467: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  Dec  9 12:07:33.467: INFO: e2e test version: v1.28.4
  Dec  9 12:07:33.469: INFO: kube-apiserver version: v1.28.4
  Dec  9 12:07:33.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 12:07:33.474: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.052 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:640
  STEP: Creating a kubernetes client @ 12/09/23 12:07:33.879
  Dec  9 12:07:33.879: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 12:07:33.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:07:33.901
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:07:33.905
  STEP: Creating service test in namespace statefulset-5706 @ 12/09/23 12:07:33.909
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 12/09/23 12:07:33.917
  STEP: Creating stateful set ss in namespace statefulset-5706 @ 12/09/23 12:07:33.922
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5706 @ 12/09/23 12:07:33.932
  Dec  9 12:07:33.935: INFO: Found 0 stateful pods, waiting for 1
  Dec  9 12:07:43.941: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 12/09/23 12:07:43.941
  Dec  9 12:07:43.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 12:07:44.065: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 12:07:44.065: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 12:07:44.065: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 12:07:44.070: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  Dec  9 12:07:54.076: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 12:07:54.076: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  9 12:07:54.091: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999859s
  Dec  9 12:07:55.095: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.99686284s
  Dec  9 12:07:56.099: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992895566s
  Dec  9 12:07:57.104: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988878823s
  Dec  9 12:07:58.107: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.984465752s
  Dec  9 12:07:59.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.979957562s
  Dec  9 12:08:00.115: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.976561538s
  Dec  9 12:08:01.119: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.972910788s
  Dec  9 12:08:02.123: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.968670345s
  Dec  9 12:08:03.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 964.878449ms
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5706 @ 12/09/23 12:08:04.127
  Dec  9 12:08:04.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 12:08:04.240: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  9 12:08:04.240: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 12:08:04.240: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  9 12:08:04.244: INFO: Found 1 stateful pods, waiting for 3
  Dec  9 12:08:14.248: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 12:08:14.248: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 12:08:14.248: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 12/09/23 12:08:14.248
  STEP: Scale down will halt with unhealthy stateful pod @ 12/09/23 12:08:14.248
  Dec  9 12:08:14.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 12:08:14.355: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 12:08:14.355: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 12:08:14.355: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 12:08:14.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 12:08:14.464: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 12:08:14.464: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 12:08:14.464: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 12:08:14.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 12:08:14.571: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 12:08:14.571: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 12:08:14.571: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 12:08:14.571: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  9 12:08:14.575: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  Dec  9 12:08:24.582: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 12:08:24.582: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 12:08:24.582: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 12:08:24.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999842s
  Dec  9 12:08:25.599: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995248896s
  Dec  9 12:08:26.604: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990760486s
  Dec  9 12:08:27.609: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985741327s
  Dec  9 12:08:28.614: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981027769s
  Dec  9 12:08:29.619: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975867455s
  Dec  9 12:08:30.623: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.97124976s
  Dec  9 12:08:31.627: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967249871s
  Dec  9 12:08:32.633: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962169733s
  Dec  9 12:08:33.636: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.416564ms
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5706 @ 12/09/23 12:08:34.637
  Dec  9 12:08:34.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 12:08:34.744: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  9 12:08:34.744: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 12:08:34.744: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  9 12:08:34.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 12:08:34.850: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  9 12:08:34.850: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 12:08:34.850: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  9 12:08:34.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-5706 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 12:08:34.959: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  9 12:08:34.959: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 12:08:34.959: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  9 12:08:34.959: INFO: Scaling statefulset ss to 0
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 12/09/23 12:08:44.974
  Dec  9 12:08:44.974: INFO: Deleting all statefulset in ns statefulset-5706
  Dec  9 12:08:44.979: INFO: Scaling statefulset ss to 0
  Dec  9 12:08:44.988: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 12:08:44.991: INFO: Deleting statefulset ss
  Dec  9 12:08:45.002: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5706" for this suite. @ 12/09/23 12:08:45.005
• [71.133 seconds]
------------------------------
SS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 12/09/23 12:08:45.012
  Dec  9 12:08:45.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 12:08:45.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:08:45.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:08:45.035
  STEP: Creating secret with name secret-test-map-887ac5c7-8d85-4a0f-a222-d0ab41803cde @ 12/09/23 12:08:45.036
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:08:45.041
  STEP: Saw pod success @ 12/09/23 12:08:51.066
  Dec  9 12:08:51.069: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-secrets-b9be2b18-32ef-42a2-ad0a-8c67d9e54df9 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:08:51.086
  Dec  9 12:08:51.102: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-126" for this suite. @ 12/09/23 12:08:51.105
• [6.099 seconds]
------------------------------
S
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 12/09/23 12:08:51.111
  Dec  9 12:08:51.111: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 12:08:51.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:08:51.127
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:08:51.129
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:08:51.131
  STEP: Saw pod success @ 12/09/23 12:08:55.157
  Dec  9 12:08:55.159: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-804a2de3-f8e9-45eb-91bb-a02fb5fa4e22 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:08:55.167
  Dec  9 12:08:55.184: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-766" for this suite. @ 12/09/23 12:08:55.187
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 12/09/23 12:08:55.195
  Dec  9 12:08:55.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename taint-single-pod @ 12/09/23 12:08:55.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:08:55.213
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:08:55.215
  Dec  9 12:08:55.217: INFO: Waiting up to 1m0s for all nodes to be ready
  Dec  9 12:09:55.231: INFO: Waiting for terminating namespaces to be deleted...
  Dec  9 12:09:55.235: INFO: Starting informer...
  STEP: Starting pod... @ 12/09/23 12:09:55.235
  Dec  9 12:09:55.450: INFO: Pod is running on ip-172-31-77-176. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/09/23 12:09:55.45
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/09/23 12:09:55.46
  STEP: Waiting short time to make sure Pod is queued for deletion @ 12/09/23 12:09:55.463
  Dec  9 12:09:55.463: INFO: Pod wasn't evicted. Proceeding
  Dec  9 12:09:55.463: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/09/23 12:09:55.471
  STEP: Waiting some time to make sure that toleration time passed. @ 12/09/23 12:09:55.474
  Dec  9 12:11:10.475: INFO: Pod wasn't evicted. Test successful
  Dec  9 12:11:10.475: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-9602" for this suite. @ 12/09/23 12:11:10.48
• [135.292 seconds]
------------------------------
SSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 12/09/23 12:11:10.487
  Dec  9 12:11:10.487: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename containers @ 12/09/23 12:11:10.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:10.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:10.509
  Dec  9 12:11:12.537: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-2840" for this suite. @ 12/09/23 12:11:12.541
• [2.062 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 12/09/23 12:11:12.55
  Dec  9 12:11:12.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-runtime @ 12/09/23 12:11:12.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:12.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:12.568
  STEP: create the container @ 12/09/23 12:11:12.57
  W1209 12:11:12.578151      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/09/23 12:11:12.578
  STEP: get the container status @ 12/09/23 12:11:15.594
  STEP: the container should be terminated @ 12/09/23 12:11:15.597
  STEP: the termination message should be set @ 12/09/23 12:11:15.597
  Dec  9 12:11:15.597: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/09/23 12:11:15.597
  Dec  9 12:11:15.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-9151" for this suite. @ 12/09/23 12:11:15.616
• [3.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 12/09/23 12:11:15.622
  Dec  9 12:11:15.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 12:11:15.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:15.643
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:15.645
  STEP: Create set of pods @ 12/09/23 12:11:15.646
  Dec  9 12:11:15.657: INFO: created test-pod-1
  Dec  9 12:11:15.663: INFO: created test-pod-2
  Dec  9 12:11:15.669: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 12/09/23 12:11:15.669
  STEP: waiting for all pods to be deleted @ 12/09/23 12:11:19.724
  Dec  9 12:11:19.728: INFO: Pod quantity 3 is different from expected quantity 0
  Dec  9 12:11:20.731: INFO: Pod quantity 2 is different from expected quantity 0
  Dec  9 12:11:21.732: INFO: Pod quantity 2 is different from expected quantity 0
  Dec  9 12:11:22.731: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9560" for this suite. @ 12/09/23 12:11:22.734
• [7.117 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 12/09/23 12:11:22.74
  Dec  9 12:11:22.740: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename hostport @ 12/09/23 12:11:22.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:22.76
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:22.762
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 12/09/23 12:11:22.767
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.80.205 on the node which pod1 resides and expect scheduled @ 12/09/23 12:11:26.785
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.80.205 but use UDP protocol on the node which pod2 resides @ 12/09/23 12:11:38.817
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 12/09/23 12:11:42.845
  Dec  9 12:11:42.845: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.80.205 http://127.0.0.1:54323/hostname] Namespace:hostport-2318 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 12:11:42.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 12:11:42.845: INFO: ExecWithOptions: Clientset creation
  Dec  9 12:11:42.845: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2318/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.80.205+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.80.205, port: 54323 @ 12/09/23 12:11:42.901
  Dec  9 12:11:42.901: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.80.205:54323/hostname] Namespace:hostport-2318 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 12:11:42.901: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 12:11:42.901: INFO: ExecWithOptions: Clientset creation
  Dec  9 12:11:42.902: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2318/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.80.205%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.80.205, port: 54323 UDP @ 12/09/23 12:11:42.956
  Dec  9 12:11:42.956: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.80.205 54323] Namespace:hostport-2318 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 12:11:42.956: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 12:11:42.957: INFO: ExecWithOptions: Clientset creation
  Dec  9 12:11:42.957: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-2318/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.80.205+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  Dec  9 12:11:48.001: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-2318" for this suite. @ 12/09/23 12:11:48.005
• [25.271 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1316
  STEP: Creating a kubernetes client @ 12/09/23 12:11:48.012
  Dec  9 12:11:48.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 12:11:48.012
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:48.028
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:48.03
  STEP: validating cluster-info @ 12/09/23 12:11:48.032
  Dec  9 12:11:48.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3194 cluster-info'
  Dec  9 12:11:48.080: INFO: stderr: ""
  Dec  9 12:11:48.080: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Dec  9 12:11:48.080: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3194" for this suite. @ 12/09/23 12:11:48.084
• [0.078 seconds]
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 12/09/23 12:11:48.09
  Dec  9 12:11:48.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename init-container @ 12/09/23 12:11:48.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:48.106
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:48.108
  STEP: creating the pod @ 12/09/23 12:11:48.11
  Dec  9 12:11:48.110: INFO: PodSpec: initContainers in spec.initContainers
  Dec  9 12:11:51.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-2281" for this suite. @ 12/09/23 12:11:51.582
• [3.498 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 12/09/23 12:11:51.589
  Dec  9 12:11:51.589: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename daemonsets @ 12/09/23 12:11:51.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:51.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:51.608
  STEP: Creating a simple DaemonSet "daemon-set" @ 12/09/23 12:11:51.625
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/09/23 12:11:51.631
  Dec  9 12:11:51.634: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:51.635: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:51.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:11:51.637: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  Dec  9 12:11:52.641: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:52.641: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:52.644: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 12:11:52.644: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 12/09/23 12:11:52.647
  Dec  9 12:11:52.662: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:52.662: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:52.666: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 12:11:52.666: INFO: Node ip-172-31-80-205 is running 0 daemon pod, expected 1
  Dec  9 12:11:53.671: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:53.671: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:53.674: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 12:11:53.674: INFO: Node ip-172-31-80-205 is running 0 daemon pod, expected 1
  Dec  9 12:11:54.669: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:54.670: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:11:54.672: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 12:11:54.672: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 12/09/23 12:11:54.672
  STEP: Deleting DaemonSet "daemon-set" @ 12/09/23 12:11:54.678
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7580, will wait for the garbage collector to delete the pods @ 12/09/23 12:11:54.678
  Dec  9 12:11:54.736: INFO: Deleting DaemonSet.extensions daemon-set took: 5.588033ms
  Dec  9 12:11:54.837: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.410282ms
  Dec  9 12:11:57.441: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:11:57.441: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  9 12:11:57.445: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"3785"},"items":null}

  Dec  9 12:11:57.448: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"3785"},"items":null}

  Dec  9 12:11:57.459: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7580" for this suite. @ 12/09/23 12:11:57.462
• [5.878 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 12/09/23 12:11:57.468
  Dec  9 12:11:57.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 12:11:57.469
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:11:57.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:11:57.487
  STEP: Creating configMap with name cm-test-opt-del-8a365d99-ada8-4fb0-b380-57ec34d327f2 @ 12/09/23 12:11:57.493
  STEP: Creating configMap with name cm-test-opt-upd-17db3bc2-0941-4efd-872c-f72352838a87 @ 12/09/23 12:11:57.496
  STEP: Creating the pod @ 12/09/23 12:11:57.5
  STEP: Deleting configmap cm-test-opt-del-8a365d99-ada8-4fb0-b380-57ec34d327f2 @ 12/09/23 12:11:59.539
  STEP: Updating configmap cm-test-opt-upd-17db3bc2-0941-4efd-872c-f72352838a87 @ 12/09/23 12:11:59.545
  STEP: Creating configMap with name cm-test-opt-create-96d2fafd-1e55-4e49-9265-cd02010dff92 @ 12/09/23 12:11:59.549
  STEP: waiting to observe update in volume @ 12/09/23 12:11:59.555
  Dec  9 12:13:19.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8658" for this suite. @ 12/09/23 12:13:19.941
• [82.480 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 12/09/23 12:13:19.95
  Dec  9 12:13:19.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:13:19.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:19.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:19.97
  STEP: Creating configMap with name configmap-projected-all-test-volume-d7121644-ecf1-4445-8ff1-6585f7e1a01c @ 12/09/23 12:13:19.974
  STEP: Creating secret with name secret-projected-all-test-volume-dc290c24-8403-48d5-8ab8-dfa6dd4bbbbb @ 12/09/23 12:13:19.978
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 12/09/23 12:13:19.983
  STEP: Saw pod success @ 12/09/23 12:13:24.008
  Dec  9 12:13:24.011: INFO: Trying to get logs from node ip-172-31-38-129 pod projected-volume-af486d26-c689-40b1-814c-aac15a9a58d0 container projected-all-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:13:24.032
  Dec  9 12:13:24.048: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-782" for this suite. @ 12/09/23 12:13:24.052
• [4.109 seconds]
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 12/09/23 12:13:24.059
  Dec  9 12:13:24.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:13:24.06
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:24.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:24.077
  STEP: Creating configMap with name projected-configmap-test-volume-0d6df879-e1f9-4a1e-b901-cab7f467af7e @ 12/09/23 12:13:24.078
  STEP: Creating a pod to test consume configMaps @ 12/09/23 12:13:24.083
  STEP: Saw pod success @ 12/09/23 12:13:28.104
  Dec  9 12:13:28.107: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-projected-configmaps-b13d859d-6c82-4a6f-8a3d-7312377a4b38 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 12:13:28.113
  Dec  9 12:13:28.126: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4250" for this suite. @ 12/09/23 12:13:28.13
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 12/09/23 12:13:28.139
  Dec  9 12:13:28.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:13:28.139
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:28.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:28.157
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:13:28.159
  STEP: Saw pod success @ 12/09/23 12:13:32.181
  Dec  9 12:13:32.185: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-131b087d-1afd-4705-9a71-d0cee104ce72 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:13:32.192
  Dec  9 12:13:32.206: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6703" for this suite. @ 12/09/23 12:13:32.209
• [4.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 12/09/23 12:13:32.216
  Dec  9 12:13:32.216: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename namespaces @ 12/09/23 12:13:32.217
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:32.236
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:32.238
  STEP: Creating a test namespace @ 12/09/23 12:13:32.24
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:32.254
  STEP: Creating a service in the namespace @ 12/09/23 12:13:32.256
  STEP: Deleting the namespace @ 12/09/23 12:13:32.267
  STEP: Waiting for the namespace to be removed. @ 12/09/23 12:13:32.276
  STEP: Recreating the namespace @ 12/09/23 12:13:38.281
  STEP: Verifying there is no service in the namespace @ 12/09/23 12:13:38.297
  Dec  9 12:13:38.300: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6195" for this suite. @ 12/09/23 12:13:38.303
  STEP: Destroying namespace "nsdeletetest-1552" for this suite. @ 12/09/23 12:13:38.31
  Dec  9 12:13:38.313: INFO: Namespace nsdeletetest-1552 was already deleted
  STEP: Destroying namespace "nsdeletetest-4169" for this suite. @ 12/09/23 12:13:38.313
• [6.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 12/09/23 12:13:38.321
  Dec  9 12:13:38.321: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename containers @ 12/09/23 12:13:38.322
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:38.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:38.341
  STEP: Creating a pod to test override arguments @ 12/09/23 12:13:38.343
  STEP: Saw pod success @ 12/09/23 12:13:42.363
  Dec  9 12:13:42.366: INFO: Trying to get logs from node ip-172-31-77-176 pod client-containers-aac151ed-f9b1-4ad1-92d6-d6605e5b5187 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 12:13:42.373
  Dec  9 12:13:42.390: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4710" for this suite. @ 12/09/23 12:13:42.393
• [4.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 12/09/23 12:13:42.401
  Dec  9 12:13:42.401: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename disruption @ 12/09/23 12:13:42.402
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:42.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:42.418
  STEP: creating the pdb @ 12/09/23 12:13:42.42
  STEP: Waiting for the pdb to be processed @ 12/09/23 12:13:42.425
  STEP: updating the pdb @ 12/09/23 12:13:44.434
  STEP: Waiting for the pdb to be processed @ 12/09/23 12:13:44.441
  STEP: patching the pdb @ 12/09/23 12:13:46.448
  STEP: Waiting for the pdb to be processed @ 12/09/23 12:13:46.459
  STEP: Waiting for the pdb to be deleted @ 12/09/23 12:13:46.468
  Dec  9 12:13:46.472: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2821" for this suite. @ 12/09/23 12:13:46.475
• [4.081 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 12/09/23 12:13:46.482
  Dec  9 12:13:46.483: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-webhook @ 12/09/23 12:13:46.483
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:46.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:46.5
  STEP: Setting up server cert @ 12/09/23 12:13:46.502
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/09/23 12:13:46.801
  STEP: Deploying the custom resource conversion webhook pod @ 12/09/23 12:13:46.809
  STEP: Wait for the deployment to be ready @ 12/09/23 12:13:46.821
  Dec  9 12:13:46.828: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 12:13:48.838
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 12:13:48.851
  Dec  9 12:13:49.852: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  9 12:13:49.859: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Creating a v1 custom resource @ 12/09/23 12:13:52.424
  STEP: Create a v2 custom resource @ 12/09/23 12:13:52.44
  STEP: List CRs in v1 @ 12/09/23 12:13:52.479
  STEP: List CRs in v2 @ 12/09/23 12:13:52.484
  Dec  9 12:13:52.488: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-324" for this suite. @ 12/09/23 12:13:53.041
• [6.573 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 12/09/23 12:13:53.057
  Dec  9 12:13:53.057: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename lease-test @ 12/09/23 12:13:53.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:53.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:53.077
  Dec  9 12:13:53.137: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-4764" for this suite. @ 12/09/23 12:13:53.141
• [0.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 12/09/23 12:13:53.149
  Dec  9 12:13:53.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename endpointslice @ 12/09/23 12:13:53.15
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:53.171
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:53.173
  STEP: getting /apis @ 12/09/23 12:13:53.176
  STEP: getting /apis/discovery.k8s.io @ 12/09/23 12:13:53.178
  STEP: getting /apis/discovery.k8s.iov1 @ 12/09/23 12:13:53.179
  STEP: creating @ 12/09/23 12:13:53.18
  STEP: getting @ 12/09/23 12:13:53.193
  STEP: listing @ 12/09/23 12:13:53.195
  STEP: watching @ 12/09/23 12:13:53.198
  Dec  9 12:13:53.198: INFO: starting watch
  STEP: cluster-wide listing @ 12/09/23 12:13:53.199
  STEP: cluster-wide watching @ 12/09/23 12:13:53.202
  Dec  9 12:13:53.202: INFO: starting watch
  STEP: patching @ 12/09/23 12:13:53.203
  STEP: updating @ 12/09/23 12:13:53.207
  Dec  9 12:13:53.215: INFO: waiting for watch events with expected annotations
  Dec  9 12:13:53.215: INFO: saw patched and updated annotations
  STEP: deleting @ 12/09/23 12:13:53.215
  STEP: deleting a collection @ 12/09/23 12:13:53.226
  Dec  9 12:13:53.240: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-6304" for this suite. @ 12/09/23 12:13:53.244
• [0.101 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 12/09/23 12:13:53.251
  Dec  9 12:13:53.251: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 12:13:53.251
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:53.269
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:53.271
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/09/23 12:13:53.273
  STEP: Saw pod success @ 12/09/23 12:13:57.294
  Dec  9 12:13:57.297: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-ddf29e87-5a06-46ec-b793-bff48b8c91e2 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 12:13:57.308
  Dec  9 12:13:57.326: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2465" for this suite. @ 12/09/23 12:13:57.331
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 12/09/23 12:13:57.341
  Dec  9 12:13:57.341: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 12:13:57.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:13:57.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:13:57.362
  STEP: set up a multi version CRD @ 12/09/23 12:13:57.364
  Dec  9 12:13:57.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: rename a version @ 12/09/23 12:14:00.658
  STEP: check the new version name is served @ 12/09/23 12:14:00.67
  STEP: check the old version name is removed @ 12/09/23 12:14:01.589
  STEP: check the other version is not changed @ 12/09/23 12:14:02.224
  Dec  9 12:14:04.811: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-2688" for this suite. @ 12/09/23 12:14:04.821
• [7.488 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 12/09/23 12:14:04.83
  Dec  9 12:14:04.830: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replication-controller @ 12/09/23 12:14:04.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:14:04.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:14:04.852
  STEP: Given a ReplicationController is created @ 12/09/23 12:14:04.856
  STEP: When the matched label of one of its pods change @ 12/09/23 12:14:04.862
  Dec  9 12:14:04.865: INFO: Pod name pod-release: Found 0 pods out of 1
  Dec  9 12:14:09.871: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/09/23 12:14:09.882
  Dec  9 12:14:10.893: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9092" for this suite. @ 12/09/23 12:14:10.897
• [6.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 12/09/23 12:14:10.911
  Dec  9 12:14:10.911: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-pred @ 12/09/23 12:14:10.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:14:10.933
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:14:10.939
  Dec  9 12:14:10.951: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  9 12:14:10.960: INFO: Waiting for terminating namespaces to be deleted...
  Dec  9 12:14:10.968: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-38-129 before test
  Dec  9 12:14:10.974: INFO: nginx-ingress-controller-kubernetes-worker-j9sl2 from ingress-nginx-kubernetes-worker started at 2023-12-09 12:04:10 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.974: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 12:14:10.974: INFO: calico-node-j8mjn from kube-system started at 2023-12-09 12:03:58 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.974: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 12:14:10.974: INFO: sonobuoy-e2e-job-f705b9d168e44085 from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:14:10.974: INFO: 	Container e2e ready: true, restart count 0
  Dec  9 12:14:10.974: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:14:10.974: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-k7blf from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:14:10.974: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:14:10.974: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 12:14:10.974: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-77-176 before test
  Dec  9 12:14:10.979: INFO: nginx-ingress-controller-kubernetes-worker-jdvw7 from ingress-nginx-kubernetes-worker started at 2023-12-09 12:10:06 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.979: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 12:14:10.979: INFO: calico-node-rzjq2 from kube-system started at 2023-12-09 11:58:38 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.979: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 12:14:10.979: INFO: pod-release-7z5sf from replication-controller-9092 started at 2023-12-09 12:14:04 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.979: INFO: 	Container pod-release ready: true, restart count 0
  Dec  9 12:14:10.979: INFO: pod-release-spwsc from replication-controller-9092 started at 2023-12-09 12:14:09 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.979: INFO: 	Container pod-release ready: true, restart count 0
  Dec  9 12:14:10.979: INFO: sonobuoy from sonobuoy started at 2023-12-09 12:07:20 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.979: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  9 12:14:10.979: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-29sdb from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:14:10.979: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:14:10.979: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 12:14:10.979: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-80-205 before test
  Dec  9 12:14:10.985: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-nm9vp from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: nginx-ingress-controller-kubernetes-worker-crj2p from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: calico-node-f2fvk from kube-system started at 2023-12-09 11:58:36 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: coredns-59cfb5bf46-t9rkp from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container coredns ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: kube-state-metrics-78c475f58b-km8l9 from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: metrics-server-v0.6.3-69d7fbfdf8-hlh9f from kube-system started at 2023-12-09 11:58:49 +0000 UTC (2 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: dashboard-metrics-scraper-5dd7cb5fc-jlz46 from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: kubernetes-dashboard-7b899cb9d9-68n2j from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-w5xwq from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:14:10.986: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:14:10.986: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 12/09/23 12:14:10.986
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.179f28ce5face0a2], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling..] @ 12/09/23 12:14:11.009
  Dec  9 12:14:12.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4461" for this suite. @ 12/09/23 12:14:12.011
• [1.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 12/09/23 12:14:12.021
  Dec  9 12:14:12.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:14:12.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:14:12.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:14:12.041
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:14:12.047
  STEP: Saw pod success @ 12/09/23 12:14:16.067
  Dec  9 12:14:16.071: INFO: Trying to get logs from node ip-172-31-38-129 pod downwardapi-volume-2c5cbab5-efd2-4dc2-9e7e-745dbc0756f8 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:14:16.097
  Dec  9 12:14:16.117: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3998" for this suite. @ 12/09/23 12:14:16.12
• [4.112 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 12/09/23 12:14:16.134
  Dec  9 12:14:16.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 12:14:16.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:14:16.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:14:16.161
  STEP: Creating pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774 @ 12/09/23 12:14:16.167
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 12:14:18.193
  Dec  9 12:14:18.196: INFO: Initial restart count of pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa is 0
  Dec  9 12:14:18.200: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:20.205: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:22.210: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:24.215: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:26.220: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:28.226: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:30.230: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:32.234: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:34.240: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:36.244: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:38.248: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:40.254: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:42.259: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:44.264: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:46.268: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:48.274: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:50.279: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:52.284: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:54.289: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:56.294: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:14:58.298: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:00.303: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:02.308: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:04.312: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:06.318: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:08.322: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:10.326: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:12.331: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:14.334: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:16.340: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:18.344: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:20.349: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:22.354: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:24.359: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:26.363: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:28.367: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:30.373: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:32.378: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:34.382: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:36.387: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:38.390: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:40.395: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:42.400: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:44.404: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:46.407: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:48.411: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:50.415: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:52.420: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:54.424: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:56.428: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:15:58.433: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:00.437: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:02.443: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:04.447: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:06.456: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:08.460: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:10.464: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:12.469: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:14.472: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:16.476: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:18.482: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:20.486: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:22.489: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:24.494: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:26.498: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:28.504: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:30.507: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:32.512: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:34.517: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:36.521: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:38.525: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:40.530: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:42.534: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:44.539: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:46.542: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:48.548: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:50.553: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:52.558: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:54.563: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:56.568: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:16:58.573: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:00.578: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:02.583: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:04.587: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:06.591: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:08.596: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:10.600: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:12.604: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:14.609: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:16.613: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:18.617: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:20.622: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:22.627: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:24.630: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:26.634: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:28.638: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:30.643: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:32.647: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:34.652: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:36.656: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:38.660: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:40.664: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:42.669: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:44.672: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:46.676: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:48.681: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:50.684: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:52.689: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:54.695: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:56.698: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:17:58.703: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:00.707: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:02.711: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:04.717: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:06.721: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:08.726: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:10.731: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:12.735: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:14.739: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:16.743: INFO: Get pod liveness-03fedf43-355c-4c6d-9606-01ccdbe141fa in namespace container-probe-774
  Dec  9 12:18:18.744: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 12:18:18.749
  STEP: Destroying namespace "container-probe-774" for this suite. @ 12/09/23 12:18:18.76
• [242.636 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 12/09/23 12:18:18.771
  Dec  9 12:18:18.771: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename job @ 12/09/23 12:18:18.772
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:18.787
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:18.791
  STEP: Creating a job @ 12/09/23 12:18:18.795
  STEP: Ensure pods equal to parallelism count is attached to the job @ 12/09/23 12:18:18.801
  STEP: patching /status @ 12/09/23 12:18:20.806
  STEP: updating /status @ 12/09/23 12:18:20.814
  STEP: get /status @ 12/09/23 12:18:20.822
  Dec  9 12:18:20.825: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3212" for this suite. @ 12/09/23 12:18:20.828
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 12/09/23 12:18:20.835
  Dec  9 12:18:20.835: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename podtemplate @ 12/09/23 12:18:20.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:20.853
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:20.857
  STEP: Create a pod template @ 12/09/23 12:18:20.86
  STEP: Replace a pod template @ 12/09/23 12:18:20.866
  Dec  9 12:18:20.875: INFO: Found updated podtemplate annotation: "true"

  Dec  9 12:18:20.875: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3699" for this suite. @ 12/09/23 12:18:20.879
• [0.050 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 12/09/23 12:18:20.885
  Dec  9 12:18:20.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 12:18:20.886
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:20.899
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:20.904
  STEP: Creating configMap with name configmap-test-volume-3b572891-5dde-4f66-b686-128b485bea7b @ 12/09/23 12:18:20.909
  STEP: Creating a pod to test consume configMaps @ 12/09/23 12:18:20.913
  STEP: Saw pod success @ 12/09/23 12:18:24.94
  Dec  9 12:18:24.942: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-configmaps-f690c70a-224c-40b2-83eb-955430ec3a80 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 12:18:24.955
  Dec  9 12:18:24.972: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1425" for this suite. @ 12/09/23 12:18:24.977
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 12/09/23 12:18:24.985
  Dec  9 12:18:24.985: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-runtime @ 12/09/23 12:18:24.985
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:24.998
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:25.003
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 12/09/23 12:18:25.014
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 12/09/23 12:18:41.093
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 12/09/23 12:18:41.096
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 12/09/23 12:18:41.104
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 12/09/23 12:18:41.104
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 12/09/23 12:18:41.129
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 12/09/23 12:18:44.144
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 12/09/23 12:18:45.153
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 12/09/23 12:18:45.159
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 12/09/23 12:18:45.159
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 12/09/23 12:18:45.182
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 12/09/23 12:18:46.189
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 12/09/23 12:18:48.2
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 12/09/23 12:18:48.207
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 12/09/23 12:18:48.207
  Dec  9 12:18:48.223: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-1593" for this suite. @ 12/09/23 12:18:48.236
• [23.256 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 12/09/23 12:18:48.242
  Dec  9 12:18:48.242: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename field-validation @ 12/09/23 12:18:48.242
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:48.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:48.262
  Dec  9 12:18:48.265: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  W1209 12:18:50.810307      18 warnings.go:70] unknown field "alpha"
  W1209 12:18:50.810325      18 warnings.go:70] unknown field "beta"
  W1209 12:18:50.810329      18 warnings.go:70] unknown field "delta"
  W1209 12:18:50.810333      18 warnings.go:70] unknown field "epsilon"
  W1209 12:18:50.810336      18 warnings.go:70] unknown field "gamma"
  Dec  9 12:18:51.344: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-5096" for this suite. @ 12/09/23 12:18:51.361
• [3.125 seconds]
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 12/09/23 12:18:51.367
  Dec  9 12:18:51.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 12:18:51.368
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:51.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:51.388
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/09/23 12:18:51.391
  STEP: Saw pod success @ 12/09/23 12:18:55.414
  Dec  9 12:18:55.417: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-8b8bb751-fc75-402c-b773-fdeeae880c29 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 12:18:55.423
  Dec  9 12:18:55.440: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3880" for this suite. @ 12/09/23 12:18:55.444
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 12/09/23 12:18:55.45
  Dec  9 12:18:55.451: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:18:55.451
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:55.466
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:55.47
  STEP: Creating secret with name projected-secret-test-5432c5fc-a4f5-463e-93fc-1e468955eeb1 @ 12/09/23 12:18:55.473
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:18:55.477
  STEP: Saw pod success @ 12/09/23 12:18:57.496
  Dec  9 12:18:57.500: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-secrets-f7d96a99-a2bc-4a2b-812f-0c6bca471ae8 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:18:57.51
  Dec  9 12:18:57.523: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3221" for this suite. @ 12/09/23 12:18:57.526
• [2.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 12/09/23 12:18:57.534
  Dec  9 12:18:57.534: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:18:57.535
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:57.549
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:57.552
  STEP: Creating projection with secret that has name projected-secret-test-map-656f86e8-4cf5-426d-8266-c7d8788c467e @ 12/09/23 12:18:57.555
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:18:57.56
  STEP: Saw pod success @ 12/09/23 12:18:59.576
  Dec  9 12:18:59.580: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-secrets-5e4abc4b-ea28-490f-ab50-631fb14e5675 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:18:59.586
  Dec  9 12:18:59.600: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3145" for this suite. @ 12/09/23 12:18:59.605
• [2.077 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 12/09/23 12:18:59.612
  Dec  9 12:18:59.612: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:18:59.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:18:59.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:18:59.63
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:18:59.633
  STEP: Saw pod success @ 12/09/23 12:19:01.655
  Dec  9 12:19:01.659: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-c4346bd4-47db-4cdf-a190-d05c80edd81c container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:19:01.671
  Dec  9 12:19:01.686: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1754" for this suite. @ 12/09/23 12:19:01.691
• [2.086 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 12/09/23 12:19:01.698
  Dec  9 12:19:01.698: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sysctl @ 12/09/23 12:19:01.698
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:19:01.712
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:19:01.716
  STEP: Creating a pod with one valid and two invalid sysctls @ 12/09/23 12:19:01.719
  Dec  9 12:19:01.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-2925" for this suite. @ 12/09/23 12:19:01.727
• [0.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:96
  STEP: Creating a kubernetes client @ 12/09/23 12:19:01.734
  Dec  9 12:19:01.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename aggregator @ 12/09/23 12:19:01.734
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:19:01.752
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:19:01.755
  Dec  9 12:19:01.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Registering the sample API server. @ 12/09/23 12:19:01.759
  Dec  9 12:19:02.105: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Dec  9 12:19:02.135: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  Dec  9 12:19:04.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:06.188: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:08.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:10.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:12.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:14.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:16.188: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:18.188: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:20.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:22.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 2, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  9 12:19:24.305: INFO: Waited 114.109715ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 12/09/23 12:19:24.34
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 12/09/23 12:19:24.343
  STEP: List APIServices @ 12/09/23 12:19:24.349
  Dec  9 12:19:24.355: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 12/09/23 12:19:24.355
  Dec  9 12:19:24.366: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 12/09/23 12:19:24.366
  Dec  9 12:19:24.375: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.December, 9, 12, 19, 24, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 12/09/23 12:19:24.375
  Dec  9 12:19:24.379: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-12-09 12:19:24 +0000 UTC Passed all checks passed}
  Dec  9 12:19:24.379: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  9 12:19:24.379: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 12/09/23 12:19:24.379
  Dec  9 12:19:24.389: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-1890793682" @ 12/09/23 12:19:24.389
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 12/09/23 12:19:24.401
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 12/09/23 12:19:24.406
  STEP: Patch APIService Status @ 12/09/23 12:19:24.41
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 12/09/23 12:19:24.419
  Dec  9 12:19:24.422: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-12-09 12:19:24 +0000 UTC Passed all checks passed}
  Dec  9 12:19:24.422: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  9 12:19:24.422: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Dec  9 12:19:24.422: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 12/09/23 12:19:24.422
  STEP: Confirm that the generated APIService has been deleted @ 12/09/23 12:19:24.427
  Dec  9 12:19:24.427: INFO: Requesting list of APIServices to confirm quantity
  Dec  9 12:19:24.432: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Dec  9 12:19:24.432: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Dec  9 12:19:24.508: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-5077" for this suite. @ 12/09/23 12:19:24.542
• [22.816 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 12/09/23 12:19:24.551
  Dec  9 12:19:24.551: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 12:19:24.551
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:19:24.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:19:24.57
  STEP: Creating a ResourceQuota @ 12/09/23 12:19:24.574
  STEP: Getting a ResourceQuota @ 12/09/23 12:19:24.578
  STEP: Updating a ResourceQuota @ 12/09/23 12:19:24.583
  STEP: Verifying a ResourceQuota was modified @ 12/09/23 12:19:24.587
  STEP: Deleting a ResourceQuota @ 12/09/23 12:19:24.592
  STEP: Verifying the deleted ResourceQuota @ 12/09/23 12:19:24.599
  Dec  9 12:19:24.603: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-5867" for this suite. @ 12/09/23 12:19:24.608
• [0.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 12/09/23 12:19:24.622
  Dec  9 12:19:24.622: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename watch @ 12/09/23 12:19:24.623
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:19:24.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:19:24.638
  STEP: creating a new configmap @ 12/09/23 12:19:24.642
  STEP: modifying the configmap once @ 12/09/23 12:19:24.647
  STEP: modifying the configmap a second time @ 12/09/23 12:19:24.655
  STEP: deleting the configmap @ 12/09/23 12:19:24.663
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 12/09/23 12:19:24.673
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 12/09/23 12:19:24.675
  Dec  9 12:19:24.675: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4728  59ec4b04-69be-482d-ab3e-85764585822b 5755 0 2023-12-09 12:19:24 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-09 12:19:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:19:24.675: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4728  59ec4b04-69be-482d-ab3e-85764585822b 5756 0 2023-12-09 12:19:24 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-09 12:19:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:19:24.675: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-4728" for this suite. @ 12/09/23 12:19:24.679
• [0.065 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 12/09/23 12:19:24.687
  Dec  9 12:19:24.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 12:19:24.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:19:24.703
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:19:24.707
  STEP: Creating resourceQuota "e2e-rq-status-5sbck" @ 12/09/23 12:19:24.716
  Dec  9 12:19:24.723: INFO: Resource quota "e2e-rq-status-5sbck" reports spec: hard cpu limit of 500m
  Dec  9 12:19:24.723: INFO: Resource quota "e2e-rq-status-5sbck" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-5sbck" /status @ 12/09/23 12:19:24.723
  STEP: Confirm /status for "e2e-rq-status-5sbck" resourceQuota via watch @ 12/09/23 12:19:24.73
  Dec  9 12:19:24.732: INFO: observed resourceQuota "e2e-rq-status-5sbck" in namespace "resourcequota-6629" with hard status: v1.ResourceList(nil)
  Dec  9 12:19:24.732: INFO: Found resourceQuota "e2e-rq-status-5sbck" in namespace "resourcequota-6629" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec  9 12:19:24.732: INFO: ResourceQuota "e2e-rq-status-5sbck" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 12/09/23 12:19:24.736
  Dec  9 12:19:24.741: INFO: Resource quota "e2e-rq-status-5sbck" reports spec: hard cpu limit of 1
  Dec  9 12:19:24.741: INFO: Resource quota "e2e-rq-status-5sbck" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-5sbck" /status @ 12/09/23 12:19:24.741
  STEP: Confirm /status for "e2e-rq-status-5sbck" resourceQuota via watch @ 12/09/23 12:19:24.748
  Dec  9 12:19:24.750: INFO: observed resourceQuota "e2e-rq-status-5sbck" in namespace "resourcequota-6629" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec  9 12:19:24.750: INFO: Found resourceQuota "e2e-rq-status-5sbck" in namespace "resourcequota-6629" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Dec  9 12:19:24.750: INFO: ResourceQuota "e2e-rq-status-5sbck" /status was patched
  STEP: Get "e2e-rq-status-5sbck" /status @ 12/09/23 12:19:24.75
  Dec  9 12:19:24.753: INFO: Resourcequota "e2e-rq-status-5sbck" reports status: hard cpu of 1
  Dec  9 12:19:24.753: INFO: Resourcequota "e2e-rq-status-5sbck" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-5sbck" /status before checking Spec is unchanged @ 12/09/23 12:19:24.756
  Dec  9 12:19:24.761: INFO: Resourcequota "e2e-rq-status-5sbck" reports status: hard cpu of 2
  Dec  9 12:19:24.761: INFO: Resourcequota "e2e-rq-status-5sbck" reports status: hard memory of 2Gi
  Dec  9 12:19:24.763: INFO: Found resourceQuota "e2e-rq-status-5sbck" in namespace "resourcequota-6629" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  Dec  9 12:22:04.771: INFO: ResourceQuota "e2e-rq-status-5sbck" Spec was unchanged and /status reset
  Dec  9 12:22:04.771: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6629" for this suite. @ 12/09/23 12:22:04.775
• [160.095 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 12/09/23 12:22:04.783
  Dec  9 12:22:04.783: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 12:22:04.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:04.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:04.805
  STEP: creating all guestbook components @ 12/09/23 12:22:04.808
  Dec  9 12:22:04.808: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Dec  9 12:22:04.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 create -f -'
  Dec  9 12:22:05.013: INFO: stderr: ""
  Dec  9 12:22:05.013: INFO: stdout: "service/agnhost-replica created\n"
  Dec  9 12:22:05.013: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Dec  9 12:22:05.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 create -f -'
  Dec  9 12:22:05.189: INFO: stderr: ""
  Dec  9 12:22:05.189: INFO: stdout: "service/agnhost-primary created\n"
  Dec  9 12:22:05.189: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Dec  9 12:22:05.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 create -f -'
  Dec  9 12:22:05.360: INFO: stderr: ""
  Dec  9 12:22:05.360: INFO: stdout: "service/frontend created\n"
  Dec  9 12:22:05.360: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Dec  9 12:22:05.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 create -f -'
  Dec  9 12:22:05.511: INFO: stderr: ""
  Dec  9 12:22:05.512: INFO: stdout: "deployment.apps/frontend created\n"
  Dec  9 12:22:05.512: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec  9 12:22:05.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 create -f -'
  Dec  9 12:22:05.655: INFO: stderr: ""
  Dec  9 12:22:05.655: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Dec  9 12:22:05.655: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec  9 12:22:05.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 create -f -'
  Dec  9 12:22:05.791: INFO: stderr: ""
  Dec  9 12:22:05.791: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 12/09/23 12:22:05.791
  Dec  9 12:22:05.791: INFO: Waiting for all frontend pods to be Running.
  Dec  9 12:22:10.842: INFO: Waiting for frontend to serve content.
  Dec  9 12:22:10.857: INFO: Trying to add a new entry to the guestbook.
  Dec  9 12:22:10.867: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 12/09/23 12:22:10.877
  Dec  9 12:22:10.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 delete --grace-period=0 --force -f -'
  Dec  9 12:22:10.963: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:22:10.963: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 12/09/23 12:22:10.963
  Dec  9 12:22:10.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 delete --grace-period=0 --force -f -'
  Dec  9 12:22:11.032: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:22:11.032: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/09/23 12:22:11.032
  Dec  9 12:22:11.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 delete --grace-period=0 --force -f -'
  Dec  9 12:22:11.092: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:22:11.092: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/09/23 12:22:11.092
  Dec  9 12:22:11.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 delete --grace-period=0 --force -f -'
  Dec  9 12:22:11.142: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:22:11.143: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/09/23 12:22:11.143
  Dec  9 12:22:11.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 delete --grace-period=0 --force -f -'
  Dec  9 12:22:11.211: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:22:11.212: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/09/23 12:22:11.212
  Dec  9 12:22:11.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3035 delete --grace-period=0 --force -f -'
  Dec  9 12:22:11.286: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:22:11.286: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Dec  9 12:22:11.286: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3035" for this suite. @ 12/09/23 12:22:11.295
• [6.523 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 12/09/23 12:22:11.307
  Dec  9 12:22:11.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename daemonsets @ 12/09/23 12:22:11.308
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:11.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:11.326
  STEP: Creating simple DaemonSet "daemon-set" @ 12/09/23 12:22:11.369
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/09/23 12:22:11.375
  Dec  9 12:22:11.379: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:22:11.379: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:22:11.384: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:22:11.384: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  Dec  9 12:22:12.388: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:22:12.388: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:22:12.392: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 12:22:12.392: INFO: Node ip-172-31-77-176 is running 0 daemon pod, expected 1
  Dec  9 12:22:13.388: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:22:13.389: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:22:13.392: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 12:22:13.392: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 12/09/23 12:22:13.396
  STEP: DeleteCollection of the DaemonSets @ 12/09/23 12:22:13.399
  STEP: Verify that ReplicaSets have been deleted @ 12/09/23 12:22:13.407
  Dec  9 12:22:13.425: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"6391"},"items":null}

  Dec  9 12:22:13.433: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"6395"},"items":[{"metadata":{"name":"daemon-set-4crbz","generateName":"daemon-set-","namespace":"daemonsets-4034","uid":"c28ae6a4-5b07-4d7e-9fdb-60f19bc395b1","resourceVersion":"6392","creationTimestamp":"2023-12-09T12:22:11Z","deletionTimestamp":"2023-12-09T12:22:43Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b00ef807-51a8-469a-998c-2fc3281a3e27","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-09T12:22:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00ef807-51a8-469a-998c-2fc3281a3e27\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-09T12:22:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.31\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-7ss7n","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-7ss7n","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-77-176","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-77-176"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:11Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:12Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:12Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:11Z"}],"hostIP":"172.31.77.176","podIP":"192.168.34.31","podIPs":[{"ip":"192.168.34.31"}],"startTime":"2023-12-09T12:22:11Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-09T12:22:11Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://f4f1e8ebe19c2c98c43906fd1d561fa8a5f3e7a8967bd709cf46057ae28462bb","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-xhrkw","generateName":"daemon-set-","namespace":"daemonsets-4034","uid":"b5d94747-bb74-4baf-bf3c-f52ed3c14db2","resourceVersion":"6391","creationTimestamp":"2023-12-09T12:22:11Z","deletionTimestamp":"2023-12-09T12:22:43Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b00ef807-51a8-469a-998c-2fc3281a3e27","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-09T12:22:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00ef807-51a8-469a-998c-2fc3281a3e27\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-09T12:22:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.250.78\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6mnkn","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6mnkn","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-80-205","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-80-205"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:11Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:12Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:12Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:11Z"}],"hostIP":"172.31.80.205","podIP":"192.168.250.78","podIPs":[{"ip":"192.168.250.78"}],"startTime":"2023-12-09T12:22:11Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-09T12:22:11Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://537b675891ee10c47a7511aabaa96761d897d7f25079823a95b1dc2fd502c9c6","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-zfk98","generateName":"daemon-set-","namespace":"daemonsets-4034","uid":"52fcc19f-02b9-4b5e-ace5-2ef6ada5231c","resourceVersion":"6390","creationTimestamp":"2023-12-09T12:22:11Z","deletionTimestamp":"2023-12-09T12:22:43Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"b00ef807-51a8-469a-998c-2fc3281a3e27","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-09T12:22:11Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b00ef807-51a8-469a-998c-2fc3281a3e27\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-09T12:22:12Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.201.205\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-q8djd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-q8djd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-38-129","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-38-129"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:11Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:12Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:12Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-09T12:22:11Z"}],"hostIP":"172.31.38.129","podIP":"192.168.201.205","podIPs":[{"ip":"192.168.201.205"}],"startTime":"2023-12-09T12:22:11Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-09T12:22:11Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://5f183e6426cd9f896efc22d2aa1c75d02c6be478632181d6acf7709a38349ac7","started":true}],"qosClass":"BestEffort"}}]}

  Dec  9 12:22:13.447: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4034" for this suite. @ 12/09/23 12:22:13.451
• [2.151 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 12/09/23 12:22:13.459
  Dec  9 12:22:13.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename containers @ 12/09/23 12:22:13.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:13.474
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:13.478
  STEP: Creating a pod to test override all @ 12/09/23 12:22:13.482
  STEP: Saw pod success @ 12/09/23 12:22:17.502
  Dec  9 12:22:17.505: INFO: Trying to get logs from node ip-172-31-77-176 pod client-containers-fd80f763-a757-4056-89e5-f857b271a4d5 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 12:22:17.518
  Dec  9 12:22:17.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-9138" for this suite. @ 12/09/23 12:22:17.541
• [4.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1342
  STEP: Creating a kubernetes client @ 12/09/23 12:22:17.551
  Dec  9 12:22:17.551: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 12:22:17.552
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:17.567
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:17.571
  Dec  9 12:22:17.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-5305 create -f -'
  Dec  9 12:22:17.733: INFO: stderr: ""
  Dec  9 12:22:17.733: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Dec  9 12:22:17.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-5305 create -f -'
  Dec  9 12:22:17.897: INFO: stderr: ""
  Dec  9 12:22:17.897: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/09/23 12:22:17.897
  Dec  9 12:22:18.903: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 12:22:18.903: INFO: Found 1 / 1
  Dec  9 12:22:18.903: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec  9 12:22:18.906: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 12:22:18.906: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  9 12:22:18.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-5305 describe pod agnhost-primary-w7mfj'
  Dec  9 12:22:18.963: INFO: stderr: ""
  Dec  9 12:22:18.963: INFO: stdout: "Name:             agnhost-primary-w7mfj\nNamespace:        kubectl-5305\nPriority:         0\nService Account:  default\nNode:             ip-172-31-77-176/172.31.77.176\nStart Time:       Sat, 09 Dec 2023 12:22:17 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.34.33\nIPs:\n  IP:           192.168.34.33\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://7887589eabe7e85d8c8df9c85d3233e5a6e193a0e294b3da5a9d135bcd4cd497\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.45\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 09 Dec 2023 12:22:18 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-s54c7 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-s54c7:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-5305/agnhost-primary-w7mfj to ip-172-31-77-176\n  Normal  Pulled     0s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.45\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
  Dec  9 12:22:18.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-5305 describe rc agnhost-primary'
  Dec  9 12:22:19.024: INFO: stderr: ""
  Dec  9 12:22:19.024: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5305\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.45\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-w7mfj\n"
  Dec  9 12:22:19.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-5305 describe service agnhost-primary'
  Dec  9 12:22:19.081: INFO: stderr: ""
  Dec  9 12:22:19.081: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5305\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.80\nIPs:               10.152.183.80\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.34.33:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Dec  9 12:22:19.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-5305 describe node ip-172-31-25-73'
  Dec  9 12:22:19.181: INFO: stderr: ""
  Dec  9 12:22:19.181: INFO: stdout: "Name:               ip-172-31-25-73\nRoles:              control-plane\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-control-plane\n                    juju-charm=kubernetes-control-plane\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-25-73\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/control-plane=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 09 Dec 2023 11:57:09 +0000\nTaints:             node-role.kubernetes.io/control-plane:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-25-73\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 09 Dec 2023 12:22:09 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 09 Dec 2023 11:57:49 +0000   Sat, 09 Dec 2023 11:57:49 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 09 Dec 2023 12:17:52 +0000   Sat, 09 Dec 2023 11:57:09 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 09 Dec 2023 12:17:52 +0000   Sat, 09 Dec 2023 11:57:09 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 09 Dec 2023 12:17:52 +0000   Sat, 09 Dec 2023 11:57:09 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 09 Dec 2023 12:17:52 +0000   Sat, 09 Dec 2023 11:57:32 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.25.73\n  Hostname:    ip-172-31-25-73\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7978660Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7876260Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec26ad93a13f4a4538d02fff4244fb8c\n  System UUID:                ec26ad93-a13f-4a45-38d0-2fff4244fb8c\n  Boot ID:                    cd6b1605-e42f-4b35-aa48-eccfc869b804\n  Kernel Version:             6.2.0-1017-aws\n  OS Image:                   Ubuntu 22.04.3 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.8\n  Kubelet Version:            v1.28.4\n  Kube-Proxy Version:         v1.28.4\nNon-terminated Pods:          (3 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-kube-controllers-75b657ddcc-w86gw                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         25m\n  kube-system                 calico-node-95gcf                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         25m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-cs5sb    0 (0%)        0 (0%)      0 (0%)           0 (0%)         14m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From             Message\n  ----     ------                   ----               ----             -------\n  Normal   Starting                 25m                kube-proxy       \n  Normal   RegisteredNode           25m                node-controller  Node ip-172-31-25-73 event: Registered Node ip-172-31-25-73 in Controller\n  Normal   Starting                 25m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      25m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  25m (x2 over 25m)  kubelet          Node ip-172-31-25-73 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    25m (x2 over 25m)  kubelet          Node ip-172-31-25-73 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     25m (x2 over 25m)  kubelet          Node ip-172-31-25-73 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  25m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                24m                kubelet          Node ip-172-31-25-73 status is now: NodeReady\n"
  Dec  9 12:22:19.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-5305 describe namespace kubectl-5305'
  Dec  9 12:22:19.239: INFO: stderr: ""
  Dec  9 12:22:19.239: INFO: stdout: "Name:         kubectl-5305\nLabels:       e2e-framework=kubectl\n              e2e-run=52bbc029-43ee-4e5f-9bdb-3340e795d598\n              kubernetes.io/metadata.name=kubectl-5305\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Dec  9 12:22:19.239: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5305" for this suite. @ 12/09/23 12:22:19.244
• [1.700 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 12/09/23 12:22:19.253
  Dec  9 12:22:19.253: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:22:19.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:19.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:19.274
  STEP: creating service in namespace services-4697 @ 12/09/23 12:22:19.277
  STEP: creating service affinity-clusterip in namespace services-4697 @ 12/09/23 12:22:19.277
  STEP: creating replication controller affinity-clusterip in namespace services-4697 @ 12/09/23 12:22:19.294
  I1209 12:22:19.302499      18 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-4697, replica count: 3
  I1209 12:22:22.353060      18 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 12:22:22.360: INFO: Creating new exec pod
  Dec  9 12:22:25.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4697 exec execpod-affinitydph2f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Dec  9 12:22:25.483: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Dec  9 12:22:25.483: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:22:25.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4697 exec execpod-affinitydph2f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.183 80'
  Dec  9 12:22:25.585: INFO: stderr: "+ nc -v -t -w 2 10.152.183.183 80\n+ echo hostName\nConnection to 10.152.183.183 80 port [tcp/http] succeeded!\n"
  Dec  9 12:22:25.585: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:22:25.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4697 exec execpod-affinitydph2f -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.183:80/ ; done'
  Dec  9 12:22:25.722: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.183:80/\n"
  Dec  9 12:22:25.722: INFO: stdout: "\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh\naffinity-clusterip-qwqqh"
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.722: INFO: Received response from host: affinity-clusterip-qwqqh
  Dec  9 12:22:25.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:22:25.726: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-4697, will wait for the garbage collector to delete the pods @ 12/09/23 12:22:25.741
  Dec  9 12:22:25.802: INFO: Deleting ReplicationController affinity-clusterip took: 6.754456ms
  Dec  9 12:22:25.903: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.696562ms
  STEP: Destroying namespace "services-4697" for this suite. @ 12/09/23 12:22:28.829
• [9.586 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 12/09/23 12:22:28.84
  Dec  9 12:22:28.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 12:22:28.84
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:28.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:28.858
  STEP: Counting existing ResourceQuota @ 12/09/23 12:22:28.862
  STEP: Creating a ResourceQuota @ 12/09/23 12:22:33.866
  STEP: Ensuring resource quota status is calculated @ 12/09/23 12:22:33.878
  STEP: Creating a ReplicaSet @ 12/09/23 12:22:35.881
  STEP: Ensuring resource quota status captures replicaset creation @ 12/09/23 12:22:35.893
  STEP: Deleting a ReplicaSet @ 12/09/23 12:22:37.898
  STEP: Ensuring resource quota status released usage @ 12/09/23 12:22:37.903
  Dec  9 12:22:39.908: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4754" for this suite. @ 12/09/23 12:22:39.911
• [11.079 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 12/09/23 12:22:39.919
  Dec  9 12:22:39.919: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename proxy @ 12/09/23 12:22:39.92
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:39.935
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:39.939
  STEP: starting an echo server on multiple ports @ 12/09/23 12:22:39.955
  STEP: creating replication controller proxy-service-r2hk4 in namespace proxy-7675 @ 12/09/23 12:22:39.955
  I1209 12:22:39.963235      18 runners.go:197] Created replication controller with name: proxy-service-r2hk4, namespace: proxy-7675, replica count: 1
  I1209 12:22:41.014143      18 runners.go:197] proxy-service-r2hk4 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
  I1209 12:22:42.014515      18 runners.go:197] proxy-service-r2hk4 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 12:22:42.017: INFO: setup took 2.075440767s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 12/09/23 12:22:42.017
  Dec  9 12:22:42.023: INFO: (0) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 5.826883ms)
  Dec  9 12:22:42.038: INFO: (0) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 20.117559ms)
  Dec  9 12:22:42.039: INFO: (0) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 20.873951ms)
  Dec  9 12:22:42.039: INFO: (0) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 20.851965ms)
  Dec  9 12:22:42.039: INFO: (0) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 21.572144ms)
  Dec  9 12:22:42.044: INFO: (0) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 25.734205ms)
  Dec  9 12:22:42.044: INFO: (0) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 26.042916ms)
  Dec  9 12:22:42.044: INFO: (0) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 26.194898ms)
  Dec  9 12:22:42.044: INFO: (0) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 26.69322ms)
  Dec  9 12:22:42.045: INFO: (0) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 27.292137ms)
  Dec  9 12:22:42.047: INFO: (0) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 28.554675ms)
  Dec  9 12:22:42.047: INFO: (0) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 29.253055ms)
  Dec  9 12:22:42.047: INFO: (0) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 29.04338ms)
  Dec  9 12:22:42.047: INFO: (0) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 28.657353ms)
  Dec  9 12:22:42.050: INFO: (0) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 32.385071ms)
  Dec  9 12:22:42.051: INFO: (0) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 33.002412ms)
  Dec  9 12:22:42.066: INFO: (1) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 15.185494ms)
  Dec  9 12:22:42.075: INFO: (1) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 23.455175ms)
  Dec  9 12:22:42.075: INFO: (1) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 23.332748ms)
  Dec  9 12:22:42.075: INFO: (1) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 23.536419ms)
  Dec  9 12:22:42.075: INFO: (1) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 23.530045ms)
  Dec  9 12:22:42.077: INFO: (1) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 25.83526ms)
  Dec  9 12:22:42.078: INFO: (1) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 26.586926ms)
  Dec  9 12:22:42.078: INFO: (1) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 26.932551ms)
  Dec  9 12:22:42.080: INFO: (1) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 29.433599ms)
  Dec  9 12:22:42.084: INFO: (1) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 33.035049ms)
  Dec  9 12:22:42.084: INFO: (1) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 33.123625ms)
  Dec  9 12:22:42.085: INFO: (1) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 34.60764ms)
  Dec  9 12:22:42.086: INFO: (1) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 34.531114ms)
  Dec  9 12:22:42.086: INFO: (1) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 34.668824ms)
  Dec  9 12:22:42.086: INFO: (1) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 35.257537ms)
  Dec  9 12:22:42.087: INFO: (1) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 35.955872ms)
  Dec  9 12:22:42.099: INFO: (2) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 11.515571ms)
  Dec  9 12:22:42.108: INFO: (2) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 20.420518ms)
  Dec  9 12:22:42.108: INFO: (2) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 20.155969ms)
  Dec  9 12:22:42.109: INFO: (2) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 21.779413ms)
  Dec  9 12:22:42.110: INFO: (2) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 22.875522ms)
  Dec  9 12:22:42.115: INFO: (2) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 27.669572ms)
  Dec  9 12:22:42.116: INFO: (2) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 28.629087ms)
  Dec  9 12:22:42.117: INFO: (2) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 29.681308ms)
  Dec  9 12:22:42.117: INFO: (2) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 30.063539ms)
  Dec  9 12:22:42.118: INFO: (2) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 30.03132ms)
  Dec  9 12:22:42.118: INFO: (2) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 30.486084ms)
  Dec  9 12:22:42.119: INFO: (2) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 31.604031ms)
  Dec  9 12:22:42.119: INFO: (2) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 31.929504ms)
  Dec  9 12:22:42.119: INFO: (2) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 31.67476ms)
  Dec  9 12:22:42.119: INFO: (2) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 31.919662ms)
  Dec  9 12:22:42.119: INFO: (2) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 31.869924ms)
  Dec  9 12:22:42.126: INFO: (3) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 6.034946ms)
  Dec  9 12:22:42.126: INFO: (3) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 6.197493ms)
  Dec  9 12:22:42.126: INFO: (3) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 6.680453ms)
  Dec  9 12:22:42.126: INFO: (3) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.113525ms)
  Dec  9 12:22:42.127: INFO: (3) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 7.430531ms)
  Dec  9 12:22:42.128: INFO: (3) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.079178ms)
  Dec  9 12:22:42.128: INFO: (3) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 8.209581ms)
  Dec  9 12:22:42.128: INFO: (3) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 8.435151ms)
  Dec  9 12:22:42.128: INFO: (3) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 8.734821ms)
  Dec  9 12:22:42.128: INFO: (3) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 8.952329ms)
  Dec  9 12:22:42.128: INFO: (3) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 8.799874ms)
  Dec  9 12:22:42.128: INFO: (3) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 8.760594ms)
  Dec  9 12:22:42.129: INFO: (3) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 8.823722ms)
  Dec  9 12:22:42.129: INFO: (3) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 9.342619ms)
  Dec  9 12:22:42.129: INFO: (3) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 9.056876ms)
  Dec  9 12:22:42.130: INFO: (3) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 9.992442ms)
  Dec  9 12:22:42.134: INFO: (4) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 3.807534ms)
  Dec  9 12:22:42.134: INFO: (4) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 4.072437ms)
  Dec  9 12:22:42.136: INFO: (4) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 5.590978ms)
  Dec  9 12:22:42.136: INFO: (4) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.806434ms)
  Dec  9 12:22:42.136: INFO: (4) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.831615ms)
  Dec  9 12:22:42.138: INFO: (4) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 7.902952ms)
  Dec  9 12:22:42.138: INFO: (4) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 7.89477ms)
  Dec  9 12:22:42.138: INFO: (4) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 8.208681ms)
  Dec  9 12:22:42.138: INFO: (4) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 8.314865ms)
  Dec  9 12:22:42.138: INFO: (4) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 8.613208ms)
  Dec  9 12:22:42.138: INFO: (4) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 8.543445ms)
  Dec  9 12:22:42.139: INFO: (4) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 8.604762ms)
  Dec  9 12:22:42.139: INFO: (4) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 8.851119ms)
  Dec  9 12:22:42.139: INFO: (4) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 9.027363ms)
  Dec  9 12:22:42.139: INFO: (4) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 8.892712ms)
  Dec  9 12:22:42.140: INFO: (4) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 9.517141ms)
  Dec  9 12:22:42.144: INFO: (5) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 3.865951ms)
  Dec  9 12:22:42.144: INFO: (5) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 3.989931ms)
  Dec  9 12:22:42.145: INFO: (5) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 4.735057ms)
  Dec  9 12:22:42.145: INFO: (5) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.397294ms)
  Dec  9 12:22:42.146: INFO: (5) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 5.885522ms)
  Dec  9 12:22:42.147: INFO: (5) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.790635ms)
  Dec  9 12:22:42.147: INFO: (5) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 7.070958ms)
  Dec  9 12:22:42.147: INFO: (5) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 6.878654ms)
  Dec  9 12:22:42.147: INFO: (5) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 7.419631ms)
  Dec  9 12:22:42.147: INFO: (5) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 7.228897ms)
  Dec  9 12:22:42.148: INFO: (5) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 7.593097ms)
  Dec  9 12:22:42.148: INFO: (5) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 8.046787ms)
  Dec  9 12:22:42.148: INFO: (5) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.274522ms)
  Dec  9 12:22:42.148: INFO: (5) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 8.361027ms)
  Dec  9 12:22:42.149: INFO: (5) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 8.796485ms)
  Dec  9 12:22:42.150: INFO: (5) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 10.013959ms)
  Dec  9 12:22:42.154: INFO: (6) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 3.646617ms)
  Dec  9 12:22:42.154: INFO: (6) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 4.204183ms)
  Dec  9 12:22:42.155: INFO: (6) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 4.554702ms)
  Dec  9 12:22:42.155: INFO: (6) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 5.237954ms)
  Dec  9 12:22:42.156: INFO: (6) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.579816ms)
  Dec  9 12:22:42.156: INFO: (6) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 5.819172ms)
  Dec  9 12:22:42.157: INFO: (6) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 6.397249ms)
  Dec  9 12:22:42.157: INFO: (6) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.140674ms)
  Dec  9 12:22:42.157: INFO: (6) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 7.19059ms)
  Dec  9 12:22:42.157: INFO: (6) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 7.216141ms)
  Dec  9 12:22:42.158: INFO: (6) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.175308ms)
  Dec  9 12:22:42.158: INFO: (6) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 7.568405ms)
  Dec  9 12:22:42.158: INFO: (6) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.027461ms)
  Dec  9 12:22:42.158: INFO: (6) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 8.211881ms)
  Dec  9 12:22:42.159: INFO: (6) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 8.593366ms)
  Dec  9 12:22:42.160: INFO: (6) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 9.391036ms)
  Dec  9 12:22:42.164: INFO: (7) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 3.940245ms)
  Dec  9 12:22:42.165: INFO: (7) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 4.790333ms)
  Dec  9 12:22:42.166: INFO: (7) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 5.727592ms)
  Dec  9 12:22:42.166: INFO: (7) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 6.007217ms)
  Dec  9 12:22:42.167: INFO: (7) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 6.759801ms)
  Dec  9 12:22:42.167: INFO: (7) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 7.056082ms)
  Dec  9 12:22:42.167: INFO: (7) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 7.494355ms)
  Dec  9 12:22:42.168: INFO: (7) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 7.612772ms)
  Dec  9 12:22:42.168: INFO: (7) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 7.782886ms)
  Dec  9 12:22:42.168: INFO: (7) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.686152ms)
  Dec  9 12:22:42.169: INFO: (7) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 8.724421ms)
  Dec  9 12:22:42.169: INFO: (7) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.875517ms)
  Dec  9 12:22:42.169: INFO: (7) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 8.905193ms)
  Dec  9 12:22:42.169: INFO: (7) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 9.116277ms)
  Dec  9 12:22:42.170: INFO: (7) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 10.03299ms)
  Dec  9 12:22:42.170: INFO: (7) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 10.066177ms)
  Dec  9 12:22:42.174: INFO: (8) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 3.986308ms)
  Dec  9 12:22:42.177: INFO: (8) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 6.65489ms)
  Dec  9 12:22:42.177: INFO: (8) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 6.63621ms)
  Dec  9 12:22:42.177: INFO: (8) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 7.003967ms)
  Dec  9 12:22:42.177: INFO: (8) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 6.819939ms)
  Dec  9 12:22:42.177: INFO: (8) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.753858ms)
  Dec  9 12:22:42.178: INFO: (8) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 7.370128ms)
  Dec  9 12:22:42.179: INFO: (8) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 7.968516ms)
  Dec  9 12:22:42.179: INFO: (8) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 8.307372ms)
  Dec  9 12:22:42.179: INFO: (8) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.381195ms)
  Dec  9 12:22:42.179: INFO: (8) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 8.255111ms)
  Dec  9 12:22:42.179: INFO: (8) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 8.570586ms)
  Dec  9 12:22:42.179: INFO: (8) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 8.863014ms)
  Dec  9 12:22:42.179: INFO: (8) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 9.362572ms)
  Dec  9 12:22:42.180: INFO: (8) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 9.383896ms)
  Dec  9 12:22:42.180: INFO: (8) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 9.747726ms)
  Dec  9 12:22:42.184: INFO: (9) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 3.874606ms)
  Dec  9 12:22:42.185: INFO: (9) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 3.89338ms)
  Dec  9 12:22:42.186: INFO: (9) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 5.46646ms)
  Dec  9 12:22:42.186: INFO: (9) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 5.435063ms)
  Dec  9 12:22:42.186: INFO: (9) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 5.315265ms)
  Dec  9 12:22:42.187: INFO: (9) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 6.401633ms)
  Dec  9 12:22:42.187: INFO: (9) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 6.43469ms)
  Dec  9 12:22:42.187: INFO: (9) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 6.710897ms)
  Dec  9 12:22:42.188: INFO: (9) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 6.954536ms)
  Dec  9 12:22:42.188: INFO: (9) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 7.603132ms)
  Dec  9 12:22:42.188: INFO: (9) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 7.663064ms)
  Dec  9 12:22:42.188: INFO: (9) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 7.759759ms)
  Dec  9 12:22:42.189: INFO: (9) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.96489ms)
  Dec  9 12:22:42.189: INFO: (9) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.355032ms)
  Dec  9 12:22:42.189: INFO: (9) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 8.537719ms)
  Dec  9 12:22:42.191: INFO: (9) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 10.085068ms)
  Dec  9 12:22:42.194: INFO: (10) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 3.585228ms)
  Dec  9 12:22:42.196: INFO: (10) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.406855ms)
  Dec  9 12:22:42.198: INFO: (10) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 6.663041ms)
  Dec  9 12:22:42.198: INFO: (10) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 6.662739ms)
  Dec  9 12:22:42.198: INFO: (10) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 7.245927ms)
  Dec  9 12:22:42.198: INFO: (10) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 7.442658ms)
  Dec  9 12:22:42.198: INFO: (10) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 7.330491ms)
  Dec  9 12:22:42.199: INFO: (10) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 7.681699ms)
  Dec  9 12:22:42.199: INFO: (10) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.725239ms)
  Dec  9 12:22:42.199: INFO: (10) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 7.906874ms)
  Dec  9 12:22:42.200: INFO: (10) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.424306ms)
  Dec  9 12:22:42.200: INFO: (10) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 8.841735ms)
  Dec  9 12:22:42.200: INFO: (10) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 8.665362ms)
  Dec  9 12:22:42.200: INFO: (10) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 8.665266ms)
  Dec  9 12:22:42.200: INFO: (10) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.656549ms)
  Dec  9 12:22:42.200: INFO: (10) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 8.800016ms)
  Dec  9 12:22:42.204: INFO: (11) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 3.923079ms)
  Dec  9 12:22:42.204: INFO: (11) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 4.364485ms)
  Dec  9 12:22:42.205: INFO: (11) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 4.965188ms)
  Dec  9 12:22:42.205: INFO: (11) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.484317ms)
  Dec  9 12:22:42.206: INFO: (11) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 5.553682ms)
  Dec  9 12:22:42.206: INFO: (11) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 5.630493ms)
  Dec  9 12:22:42.207: INFO: (11) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 6.604565ms)
  Dec  9 12:22:42.207: INFO: (11) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 6.864244ms)
  Dec  9 12:22:42.207: INFO: (11) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 7.231623ms)
  Dec  9 12:22:42.208: INFO: (11) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.607106ms)
  Dec  9 12:22:42.208: INFO: (11) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 8.114869ms)
  Dec  9 12:22:42.209: INFO: (11) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 8.918103ms)
  Dec  9 12:22:42.210: INFO: (11) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 9.498658ms)
  Dec  9 12:22:42.210: INFO: (11) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 9.367475ms)
  Dec  9 12:22:42.210: INFO: (11) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 10.28797ms)
  Dec  9 12:22:42.211: INFO: (11) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 11.1984ms)
  Dec  9 12:22:42.215: INFO: (12) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 3.828376ms)
  Dec  9 12:22:42.218: INFO: (12) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 6.321201ms)
  Dec  9 12:22:42.218: INFO: (12) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.308318ms)
  Dec  9 12:22:42.218: INFO: (12) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 6.87015ms)
  Dec  9 12:22:42.219: INFO: (12) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.006734ms)
  Dec  9 12:22:42.219: INFO: (12) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 7.189183ms)
  Dec  9 12:22:42.219: INFO: (12) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 6.997511ms)
  Dec  9 12:22:42.219: INFO: (12) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 7.852939ms)
  Dec  9 12:22:42.220: INFO: (12) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 8.325062ms)
  Dec  9 12:22:42.220: INFO: (12) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 8.042512ms)
  Dec  9 12:22:42.220: INFO: (12) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 8.14865ms)
  Dec  9 12:22:42.220: INFO: (12) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.288836ms)
  Dec  9 12:22:42.220: INFO: (12) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.427128ms)
  Dec  9 12:22:42.221: INFO: (12) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 8.977228ms)
  Dec  9 12:22:42.221: INFO: (12) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 9.364464ms)
  Dec  9 12:22:42.223: INFO: (12) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 11.418749ms)
  Dec  9 12:22:42.227: INFO: (13) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 4.09879ms)
  Dec  9 12:22:42.228: INFO: (13) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 4.464369ms)
  Dec  9 12:22:42.230: INFO: (13) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 6.254681ms)
  Dec  9 12:22:42.230: INFO: (13) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 6.788141ms)
  Dec  9 12:22:42.230: INFO: (13) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.618984ms)
  Dec  9 12:22:42.230: INFO: (13) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 6.881631ms)
  Dec  9 12:22:42.230: INFO: (13) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.937885ms)
  Dec  9 12:22:42.231: INFO: (13) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 7.721123ms)
  Dec  9 12:22:42.232: INFO: (13) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 8.389753ms)
  Dec  9 12:22:42.232: INFO: (13) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 8.284939ms)
  Dec  9 12:22:42.232: INFO: (13) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.651177ms)
  Dec  9 12:22:42.232: INFO: (13) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 8.731785ms)
  Dec  9 12:22:42.232: INFO: (13) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 8.606863ms)
  Dec  9 12:22:42.232: INFO: (13) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.799683ms)
  Dec  9 12:22:42.233: INFO: (13) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 9.262599ms)
  Dec  9 12:22:42.234: INFO: (13) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 10.218802ms)
  Dec  9 12:22:42.238: INFO: (14) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 4.561351ms)
  Dec  9 12:22:42.239: INFO: (14) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 5.161606ms)
  Dec  9 12:22:42.239: INFO: (14) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 5.340823ms)
  Dec  9 12:22:42.240: INFO: (14) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 6.141689ms)
  Dec  9 12:22:42.240: INFO: (14) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.111747ms)
  Dec  9 12:22:42.242: INFO: (14) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 7.642225ms)
  Dec  9 12:22:42.242: INFO: (14) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 7.974043ms)
  Dec  9 12:22:42.242: INFO: (14) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.366012ms)
  Dec  9 12:22:42.242: INFO: (14) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 8.384798ms)
  Dec  9 12:22:42.242: INFO: (14) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 8.237186ms)
  Dec  9 12:22:42.243: INFO: (14) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 8.628949ms)
  Dec  9 12:22:42.243: INFO: (14) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 8.477635ms)
  Dec  9 12:22:42.243: INFO: (14) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 8.851348ms)
  Dec  9 12:22:42.243: INFO: (14) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 9.103204ms)
  Dec  9 12:22:42.243: INFO: (14) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 9.236929ms)
  Dec  9 12:22:42.244: INFO: (14) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 9.405448ms)
  Dec  9 12:22:42.250: INFO: (15) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 5.946955ms)
  Dec  9 12:22:42.250: INFO: (15) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 6.243862ms)
  Dec  9 12:22:42.250: INFO: (15) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.10936ms)
  Dec  9 12:22:42.250: INFO: (15) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 6.488745ms)
  Dec  9 12:22:42.251: INFO: (15) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 7.062504ms)
  Dec  9 12:22:42.251: INFO: (15) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 7.600152ms)
  Dec  9 12:22:42.252: INFO: (15) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 7.623674ms)
  Dec  9 12:22:42.252: INFO: (15) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 7.828514ms)
  Dec  9 12:22:42.252: INFO: (15) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 8.421897ms)
  Dec  9 12:22:42.253: INFO: (15) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 9.446391ms)
  Dec  9 12:22:42.253: INFO: (15) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 9.510863ms)
  Dec  9 12:22:42.253: INFO: (15) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 9.809935ms)
  Dec  9 12:22:42.254: INFO: (15) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 9.736071ms)
  Dec  9 12:22:42.254: INFO: (15) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 9.665738ms)
  Dec  9 12:22:42.254: INFO: (15) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 9.677895ms)
  Dec  9 12:22:42.254: INFO: (15) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 9.850446ms)
  Dec  9 12:22:42.258: INFO: (16) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 4.118603ms)
  Dec  9 12:22:42.259: INFO: (16) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 4.643899ms)
  Dec  9 12:22:42.259: INFO: (16) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 5.31988ms)
  Dec  9 12:22:42.260: INFO: (16) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 5.555962ms)
  Dec  9 12:22:42.260: INFO: (16) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 6.024707ms)
  Dec  9 12:22:42.260: INFO: (16) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 6.297494ms)
  Dec  9 12:22:42.260: INFO: (16) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.102086ms)
  Dec  9 12:22:42.261: INFO: (16) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 6.2943ms)
  Dec  9 12:22:42.262: INFO: (16) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 7.495496ms)
  Dec  9 12:22:42.262: INFO: (16) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.602997ms)
  Dec  9 12:22:42.262: INFO: (16) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 7.434793ms)
  Dec  9 12:22:42.262: INFO: (16) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.140997ms)
  Dec  9 12:22:42.262: INFO: (16) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 8.136963ms)
  Dec  9 12:22:42.263: INFO: (16) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 8.545086ms)
  Dec  9 12:22:42.263: INFO: (16) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.893416ms)
  Dec  9 12:22:42.264: INFO: (16) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 9.433737ms)
  Dec  9 12:22:42.268: INFO: (17) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 4.330864ms)
  Dec  9 12:22:42.268: INFO: (17) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 4.476609ms)
  Dec  9 12:22:42.269: INFO: (17) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 4.803222ms)
  Dec  9 12:22:42.269: INFO: (17) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.083398ms)
  Dec  9 12:22:42.270: INFO: (17) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 5.737822ms)
  Dec  9 12:22:42.270: INFO: (17) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 5.724679ms)
  Dec  9 12:22:42.270: INFO: (17) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 6.029708ms)
  Dec  9 12:22:42.270: INFO: (17) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 6.475544ms)
  Dec  9 12:22:42.271: INFO: (17) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 6.505768ms)
  Dec  9 12:22:42.271: INFO: (17) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 7.095904ms)
  Dec  9 12:22:42.271: INFO: (17) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 7.096231ms)
  Dec  9 12:22:42.271: INFO: (17) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 7.515377ms)
  Dec  9 12:22:42.272: INFO: (17) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 8.184079ms)
  Dec  9 12:22:42.272: INFO: (17) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 8.147939ms)
  Dec  9 12:22:42.272: INFO: (17) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 8.250156ms)
  Dec  9 12:22:42.273: INFO: (17) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 9.198363ms)
  Dec  9 12:22:42.278: INFO: (18) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 4.33725ms)
  Dec  9 12:22:42.278: INFO: (18) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 4.823579ms)
  Dec  9 12:22:42.279: INFO: (18) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 5.151029ms)
  Dec  9 12:22:42.279: INFO: (18) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 5.518039ms)
  Dec  9 12:22:42.280: INFO: (18) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 6.059671ms)
  Dec  9 12:22:42.280: INFO: (18) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.288656ms)
  Dec  9 12:22:42.280: INFO: (18) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 6.75975ms)
  Dec  9 12:22:42.281: INFO: (18) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 7.2325ms)
  Dec  9 12:22:42.281: INFO: (18) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 7.459166ms)
  Dec  9 12:22:42.282: INFO: (18) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 7.946573ms)
  Dec  9 12:22:42.282: INFO: (18) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 8.291559ms)
  Dec  9 12:22:42.282: INFO: (18) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 8.455893ms)
  Dec  9 12:22:42.282: INFO: (18) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 8.493622ms)
  Dec  9 12:22:42.282: INFO: (18) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 8.730379ms)
  Dec  9 12:22:42.283: INFO: (18) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 9.382716ms)
  Dec  9 12:22:42.284: INFO: (18) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 10.171808ms)
  Dec  9 12:22:42.288: INFO: (19) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:462/proxy/: tls qux (200; 4.270026ms)
  Dec  9 12:22:42.289: INFO: (19) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn/proxy/rewriteme">test</a> (200; 4.826867ms)
  Dec  9 12:22:42.289: INFO: (19) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname2/proxy/: tls qux (200; 5.245094ms)
  Dec  9 12:22:42.289: INFO: (19) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 5.402228ms)
  Dec  9 12:22:42.290: INFO: (19) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:460/proxy/: tls baz (200; 5.642938ms)
  Dec  9 12:22:42.290: INFO: (19) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:162/proxy/: bar (200; 6.116327ms)
  Dec  9 12:22:42.290: INFO: (19) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 6.338792ms)
  Dec  9 12:22:42.291: INFO: (19) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:160/proxy/: foo (200; 6.988762ms)
  Dec  9 12:22:42.291: INFO: (19) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname2/proxy/: bar (200; 7.27772ms)
  Dec  9 12:22:42.292: INFO: (19) /api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">test<... (200; 7.631498ms)
  Dec  9 12:22:42.292: INFO: (19) /api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/https:proxy-service-r2hk4-htmqn:443/proxy/tlsrewritem... (200; 8.084629ms)
  Dec  9 12:22:42.292: INFO: (19) /api/v1/namespaces/proxy-7675/services/https:proxy-service-r2hk4:tlsportname1/proxy/: tls baz (200; 8.148646ms)
  Dec  9 12:22:42.292: INFO: (19) /api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/: <a href="/api/v1/namespaces/proxy-7675/pods/http:proxy-service-r2hk4-htmqn:1080/proxy/rewriteme">... (200; 8.108187ms)
  Dec  9 12:22:42.292: INFO: (19) /api/v1/namespaces/proxy-7675/services/http:proxy-service-r2hk4:portname1/proxy/: foo (200; 8.516927ms)
  Dec  9 12:22:42.293: INFO: (19) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname1/proxy/: foo (200; 9.094153ms)
  Dec  9 12:22:42.293: INFO: (19) /api/v1/namespaces/proxy-7675/services/proxy-service-r2hk4:portname2/proxy/: bar (200; 9.247767ms)
  Dec  9 12:22:42.293: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-r2hk4 in namespace proxy-7675, will wait for the garbage collector to delete the pods @ 12/09/23 12:22:42.296
  Dec  9 12:22:42.356: INFO: Deleting ReplicationController proxy-service-r2hk4 took: 6.798786ms
  Dec  9 12:22:42.457: INFO: Terminating ReplicationController proxy-service-r2hk4 pods took: 100.897096ms
  STEP: Destroying namespace "proxy-7675" for this suite. @ 12/09/23 12:22:44.758
• [4.847 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 12/09/23 12:22:44.767
  Dec  9 12:22:44.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename conformance-tests @ 12/09/23 12:22:44.768
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:44.783
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:44.786
  STEP: Getting node addresses @ 12/09/23 12:22:44.789
  Dec  9 12:22:44.789: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Dec  9 12:22:44.794: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-4087" for this suite. @ 12/09/23 12:22:44.798
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 12/09/23 12:22:44.806
  Dec  9 12:22:44.806: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 12:22:44.807
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:44.82
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:44.823
  STEP: Setting up server cert @ 12/09/23 12:22:44.852
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 12:22:45.281
  STEP: Deploying the webhook pod @ 12/09/23 12:22:45.29
  STEP: Wait for the deployment to be ready @ 12/09/23 12:22:45.302
  Dec  9 12:22:45.314: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 12:22:47.326
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 12:22:47.341
  Dec  9 12:22:48.341: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/09/23 12:22:48.349
  STEP: create a pod that should be denied by the webhook @ 12/09/23 12:22:48.364
  STEP: create a pod that causes the webhook to hang @ 12/09/23 12:22:48.372
  STEP: create a configmap that should be denied by the webhook @ 12/09/23 12:22:58.381
  STEP: create a configmap that should be admitted by the webhook @ 12/09/23 12:22:58.419
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/09/23 12:22:58.428
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/09/23 12:22:58.435
  STEP: create a namespace that bypass the webhook @ 12/09/23 12:22:58.441
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 12/09/23 12:22:58.457
  Dec  9 12:22:58.465: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6401" for this suite. @ 12/09/23 12:22:58.521
  STEP: Destroying namespace "webhook-markers-5193" for this suite. @ 12/09/23 12:22:58.528
  STEP: Destroying namespace "exempted-namespace-2340" for this suite. @ 12/09/23 12:22:58.534
• [13.735 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 12/09/23 12:22:58.542
  Dec  9 12:22:58.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:22:58.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:22:58.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:22:58.559
  STEP: Creating projection with secret that has name projected-secret-test-e853a29f-a30b-4220-bf0b-2f9c545c669a @ 12/09/23 12:22:58.562
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:22:58.566
  STEP: Saw pod success @ 12/09/23 12:23:02.591
  Dec  9 12:23:02.594: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-secrets-a643446a-226b-4458-b210-937ae25db8de container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:23:02.601
  Dec  9 12:23:02.618: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9731" for this suite. @ 12/09/23 12:23:02.622
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:488
  STEP: Creating a kubernetes client @ 12/09/23 12:23:02.631
  Dec  9 12:23:02.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 12:23:02.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:02.648
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:02.652
  STEP: creating a Deployment @ 12/09/23 12:23:02.66
  Dec  9 12:23:02.660: INFO: Creating simple deployment test-deployment-z7zzn
  Dec  9 12:23:02.677: INFO: deployment "test-deployment-z7zzn" doesn't have the required revision set
  STEP: Getting /status @ 12/09/23 12:23:04.692
  Dec  9 12:23:04.697: INFO: Deployment test-deployment-z7zzn has Conditions: [{Available True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z7zzn-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 12/09/23 12:23:04.697
  Dec  9 12:23:04.705: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 23, 3, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 23, 3, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 12, 23, 3, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 12, 23, 2, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-z7zzn-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 12/09/23 12:23:04.705
  Dec  9 12:23:04.707: INFO: Observed &Deployment event: ADDED
  Dec  9 12:23:04.707: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z7zzn-5d576bd769"}
  Dec  9 12:23:04.707: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.707: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z7zzn-5d576bd769"}
  Dec  9 12:23:04.707: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  9 12:23:04.707: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.707: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  9 12:23:04.707: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-z7zzn-5d576bd769" is progressing.}
  Dec  9 12:23:04.707: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.708: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  9 12:23:04.708: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z7zzn-5d576bd769" has successfully progressed.}
  Dec  9 12:23:04.708: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.708: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  9 12:23:04.708: INFO: Observed Deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z7zzn-5d576bd769" has successfully progressed.}
  Dec  9 12:23:04.708: INFO: Found Deployment test-deployment-z7zzn in namespace deployment-5420 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  9 12:23:04.708: INFO: Deployment test-deployment-z7zzn has an updated status
  STEP: patching the Statefulset Status @ 12/09/23 12:23:04.708
  Dec  9 12:23:04.708: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec  9 12:23:04.716: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 12/09/23 12:23:04.716
  Dec  9 12:23:04.718: INFO: Observed &Deployment event: ADDED
  Dec  9 12:23:04.718: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z7zzn-5d576bd769"}
  Dec  9 12:23:04.718: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.718: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z7zzn-5d576bd769"}
  Dec  9 12:23:04.718: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  9 12:23:04.718: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.718: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  9 12:23:04.718: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:02 +0000 UTC 2023-12-09 12:23:02 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-z7zzn-5d576bd769" is progressing.}
  Dec  9 12:23:04.718: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.718: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  9 12:23:04.718: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z7zzn-5d576bd769" has successfully progressed.}
  Dec  9 12:23:04.719: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.719: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:03 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  9 12:23:04.719: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-09 12:23:03 +0000 UTC 2023-12-09 12:23:02 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z7zzn-5d576bd769" has successfully progressed.}
  Dec  9 12:23:04.719: INFO: Observed deployment test-deployment-z7zzn in namespace deployment-5420 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  9 12:23:04.719: INFO: Observed &Deployment event: MODIFIED
  Dec  9 12:23:04.719: INFO: Found deployment test-deployment-z7zzn in namespace deployment-5420 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Dec  9 12:23:04.719: INFO: Deployment test-deployment-z7zzn has a patched status
  Dec  9 12:23:04.723: INFO: Deployment "test-deployment-z7zzn":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-z7zzn",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5420",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "345af3cc-1171-496b-8598-e38b614703fe",
      ResourceVersion: (string) (len=4) "7054",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721382,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=3) "e2e": (string) (len=7) "testing"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721382,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=373) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 50 72 6f  |:{\"type\":\"Pro|
              000000a0  67 72 65 73 73 69 6e 67  5c 22 7d 22 3a 7b 22 2e  |gressing\"}":{".|
              000000b0  22 3a 7b 7d 2c 22 66 3a  6c 61 73 74 54 72 61 6e  |":{},"f:lastTran|
              000000c0  73 69 74 69 6f 6e 54 69  6d 65 22 3a 7b 7d 2c 22  |sitionTime":{},"|
              000000d0  66 3a 6c 61 73 74 55 70  64 61 74 65 54 69 6d 65  |f:lastUpdateTime|
              000000e0  22 3a 7b 7d 2c 22 66 3a  6d 65 73 73 61 67 65 22  |":{},"f:message"|
              000000f0  3a 7b 7d 2c 22 66 3a 72  65 61 73 6f 6e 22 3a 7b  |:{},"f:reason":{|
              00000100  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 7d 2c  |},"f:status":{},|
              00000110  22 66 3a 74 79 70 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:type":{}}},"f|
              00000120  3a 6f 62 73 65 72 76 65  64 47 65 6e 65 72 61 74  |:observedGenerat|
              00000130  69 6f 6e 22 3a 7b 7d 2c  22 66 3a 72 65 61 64 79  |ion":{},"f:ready|
              00000140  52 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |Replicas":{},"f:|
              00000150  72 65 70 6c 69 63 61 73  22 3a 7b 7d 2c 22 66 3a  |replicas":{},"f:|
              00000160  75 70 64 61 74 65 64 52  65 70 6c 69 63 61 73 22  |updatedReplicas"|
              00000170  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721384,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "FoundNewReplicaSet",
          Message: (string) (len=56) "Found new replica set \"test-deployment-z7zzn-5d576bd769\""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  9 12:23:04.727: INFO: New ReplicaSet "test-deployment-z7zzn-5d576bd769" of Deployment "test-deployment-z7zzn":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-z7zzn-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-5420",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d1260b30-59a9-42fc-9bd1-16db7a2737e6",
      ResourceVersion: (string) (len=4) "7040",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721382,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-z7zzn",
          UID: (types.UID) (len=36) "345af3cc-1171-496b-8598-e38b614703fe",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721382,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 33 34 35  |k:{\"uid\":\"345|
              00000120  61 66 33 63 63 2d 31 31  37 31 2d 34 39 36 62 2d  |af3cc-1171-496b-|
              00000130  38 35 39 38 2d 65 33 38  62 36 31 34 37 30 33 66  |8598-e38b614703f|
              00000140  65 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |e\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769",
            (string) (len=3) "e2e": (string) (len=7) "testing"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 12:23:04.731: INFO: Pod "test-deployment-z7zzn-5d576bd769-8qqwp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-z7zzn-5d576bd769-8qqwp",
      GenerateName: (string) (len=33) "test-deployment-z7zzn-5d576bd769-",
      Namespace: (string) (len=15) "deployment-5420",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "dd1dec47-96e8-4db5-b74b-fe5113ad9a44",
      ResourceVersion: (string) (len=4) "7038",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721382,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-z7zzn-5d576bd769",
          UID: (types.UID) (len=36) "d1260b30-59a9-42fc-9bd1-16db7a2737e6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721382,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 64 31 32 36 30 62 33  30 2d 35 39 61 39 2d 34  |"d1260b30-59a9-4|
              000000a0  32 66 63 2d 39 62 64 31  2d 31 36 64 62 37 61 32  |2fc-9bd1-16db7a2|
              000000b0  37 33 37 65 36 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |737e6\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 33 38 5c 22 7d  |192.168.34.38\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wd9kz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wd9kz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721382,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721383,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721382,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.38",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.38"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721382,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721383,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0a1c93295e066f8ca967d8a48a7b5932f59279a275f024f7c6f07a902d5a0835",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:23:04.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-5420" for this suite. @ 12/09/23 12:23:04.738
• [2.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 12/09/23 12:23:04.745
  Dec  9 12:23:04.745: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 12:23:04.746
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:04.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:04.766
  STEP: Counting existing ResourceQuota @ 12/09/23 12:23:04.769
  STEP: Creating a ResourceQuota @ 12/09/23 12:23:09.773
  STEP: Ensuring resource quota status is calculated @ 12/09/23 12:23:09.778
  Dec  9 12:23:11.783: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-7084" for this suite. @ 12/09/23 12:23:11.788
• [7.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 12/09/23 12:23:11.796
  Dec  9 12:23:11.796: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename runtimeclass @ 12/09/23 12:23:11.796
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:11.814
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:11.817
  STEP: getting /apis @ 12/09/23 12:23:11.82
  STEP: getting /apis/node.k8s.io @ 12/09/23 12:23:11.824
  STEP: getting /apis/node.k8s.io/v1 @ 12/09/23 12:23:11.826
  STEP: creating @ 12/09/23 12:23:11.827
  STEP: watching @ 12/09/23 12:23:11.843
  Dec  9 12:23:11.843: INFO: starting watch
  STEP: getting @ 12/09/23 12:23:11.851
  STEP: listing @ 12/09/23 12:23:11.853
  STEP: patching @ 12/09/23 12:23:11.856
  STEP: updating @ 12/09/23 12:23:11.867
  Dec  9 12:23:11.872: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 12/09/23 12:23:11.872
  STEP: deleting a collection @ 12/09/23 12:23:11.886
  Dec  9 12:23:11.901: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4717" for this suite. @ 12/09/23 12:23:11.904
• [0.114 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 12/09/23 12:23:11.91
  Dec  9 12:23:11.910: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename namespaces @ 12/09/23 12:23:11.911
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:11.932
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:11.936
  STEP: Creating a test namespace @ 12/09/23 12:23:11.942
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:11.954
  STEP: Creating a pod in the namespace @ 12/09/23 12:23:11.96
  STEP: Waiting for the pod to have running status @ 12/09/23 12:23:11.971
  STEP: Deleting the namespace @ 12/09/23 12:23:13.98
  STEP: Waiting for the namespace to be removed. @ 12/09/23 12:23:13.987
  STEP: Recreating the namespace @ 12/09/23 12:23:24.99
  STEP: Verifying there are no pods in the namespace @ 12/09/23 12:23:25.005
  Dec  9 12:23:25.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2942" for this suite. @ 12/09/23 12:23:25.015
  STEP: Destroying namespace "nsdeletetest-8914" for this suite. @ 12/09/23 12:23:25.024
  Dec  9 12:23:25.027: INFO: Namespace nsdeletetest-8914 was already deleted
  STEP: Destroying namespace "nsdeletetest-1822" for this suite. @ 12/09/23 12:23:25.027
• [13.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 12/09/23 12:23:25.034
  Dec  9 12:23:25.034: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 12:23:25.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:25.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:25.056
  STEP: Creating a pod to test downward api env vars @ 12/09/23 12:23:25.059
  STEP: Saw pod success @ 12/09/23 12:23:27.077
  Dec  9 12:23:27.082: INFO: Trying to get logs from node ip-172-31-77-176 pod downward-api-88db99b0-aca3-4573-9eff-2527c6f7dfc8 container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 12:23:27.088
  Dec  9 12:23:27.101: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5122" for this suite. @ 12/09/23 12:23:27.106
• [2.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 12/09/23 12:23:27.114
  Dec  9 12:23:27.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replicaset @ 12/09/23 12:23:27.115
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:27.13
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:27.133
  Dec  9 12:23:27.137: INFO: Creating ReplicaSet my-hostname-basic-09e92500-9f70-4c0e-bb1f-c31d017093dc
  Dec  9 12:23:27.147: INFO: Pod name my-hostname-basic-09e92500-9f70-4c0e-bb1f-c31d017093dc: Found 0 pods out of 1
  Dec  9 12:23:32.154: INFO: Pod name my-hostname-basic-09e92500-9f70-4c0e-bb1f-c31d017093dc: Found 1 pods out of 1
  Dec  9 12:23:32.154: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-09e92500-9f70-4c0e-bb1f-c31d017093dc" is running
  Dec  9 12:23:32.158: INFO: Pod "my-hostname-basic-09e92500-9f70-4c0e-bb1f-c31d017093dc-54x57" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:23:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:23:27 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:23:27 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:23:27 +0000 UTC Reason: Message:}])
  Dec  9 12:23:32.158: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/09/23 12:23:32.158
  Dec  9 12:23:32.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7437" for this suite. @ 12/09/23 12:23:32.177
• [5.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 12/09/23 12:23:32.188
  Dec  9 12:23:32.188: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 12:23:32.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:32.2
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:32.204
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:23:32.208
  STEP: Saw pod success @ 12/09/23 12:23:36.265
  Dec  9 12:23:36.269: INFO: Trying to get logs from node ip-172-31-38-129 pod downwardapi-volume-6529ffd8-c2d9-4c80-8f24-593a5f15617b container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:23:36.292
  Dec  9 12:23:36.310: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8250" for this suite. @ 12/09/23 12:23:36.315
• [4.136 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 12/09/23 12:23:36.324
  Dec  9 12:23:36.324: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:23:36.325
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:36.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:36.345
  STEP: Creating projection with secret that has name projected-secret-test-35d65ca1-f513-49eb-9a2e-9b40d744331c @ 12/09/23 12:23:36.348
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:23:36.354
  STEP: Saw pod success @ 12/09/23 12:23:40.381
  Dec  9 12:23:40.384: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-secrets-27be8a4f-fe36-40a1-ada5-ebcd07f30428 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:23:40.39
  Dec  9 12:23:40.407: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1151" for this suite. @ 12/09/23 12:23:40.411
• [4.093 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 12/09/23 12:23:40.418
  Dec  9 12:23:40.418: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replicaset @ 12/09/23 12:23:40.418
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:40.431
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:40.435
  Dec  9 12:23:40.450: INFO: Pod name sample-pod: Found 0 pods out of 1
  Dec  9 12:23:45.456: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/09/23 12:23:45.456
  STEP: Scaling up "test-rs" replicaset  @ 12/09/23 12:23:45.456
  Dec  9 12:23:45.466: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 12/09/23 12:23:45.466
  Dec  9 12:23:45.476: INFO: observed ReplicaSet test-rs in namespace replicaset-7316 with ReadyReplicas 1, AvailableReplicas 1
  Dec  9 12:23:45.488: INFO: observed ReplicaSet test-rs in namespace replicaset-7316 with ReadyReplicas 1, AvailableReplicas 1
  Dec  9 12:23:45.506: INFO: observed ReplicaSet test-rs in namespace replicaset-7316 with ReadyReplicas 1, AvailableReplicas 1
  Dec  9 12:23:45.515: INFO: observed ReplicaSet test-rs in namespace replicaset-7316 with ReadyReplicas 1, AvailableReplicas 1
  Dec  9 12:23:46.469: INFO: observed ReplicaSet test-rs in namespace replicaset-7316 with ReadyReplicas 2, AvailableReplicas 2
  Dec  9 12:23:47.388: INFO: observed Replicaset test-rs in namespace replicaset-7316 with ReadyReplicas 3 found true
  Dec  9 12:23:47.388: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-7316" for this suite. @ 12/09/23 12:23:47.393
• [6.986 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 12/09/23 12:23:47.405
  Dec  9 12:23:47.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename daemonsets @ 12/09/23 12:23:47.405
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:47.419
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:47.423
  Dec  9 12:23:47.447: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 12/09/23 12:23:47.454
  Dec  9 12:23:47.457: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:23:47.457: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 12/09/23 12:23:47.457
  Dec  9 12:23:47.484: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:23:47.484: INFO: Node ip-172-31-80-205 is running 0 daemon pod, expected 1
  Dec  9 12:23:48.489: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  9 12:23:48.489: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 12/09/23 12:23:48.492
  Dec  9 12:23:48.507: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  9 12:23:48.507: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  Dec  9 12:23:49.511: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:23:49.511: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 12/09/23 12:23:49.511
  Dec  9 12:23:49.521: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:23:49.521: INFO: Node ip-172-31-80-205 is running 0 daemon pod, expected 1
  Dec  9 12:23:50.526: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  9 12:23:50.526: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/09/23 12:23:50.533
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1453, will wait for the garbage collector to delete the pods @ 12/09/23 12:23:50.533
  Dec  9 12:23:50.594: INFO: Deleting DaemonSet.extensions daemon-set took: 7.38356ms
  Dec  9 12:23:50.694: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.593331ms
  Dec  9 12:23:52.501: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:23:52.501: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  9 12:23:52.504: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7552"},"items":null}

  Dec  9 12:23:52.506: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7553"},"items":null}

  Dec  9 12:23:52.531: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1453" for this suite. @ 12/09/23 12:23:52.539
• [5.142 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 12/09/23 12:23:52.547
  Dec  9 12:23:52.547: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename endpointslice @ 12/09/23 12:23:52.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:52.565
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:52.569
  Dec  9 12:23:52.582: INFO: Endpoints addresses: [172.31.25.73 172.31.38.185] , ports: [6443]
  Dec  9 12:23:52.582: INFO: EndpointSlices addresses: [172.31.25.73 172.31.38.185] , ports: [6443]
  Dec  9 12:23:52.582: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-507" for this suite. @ 12/09/23 12:23:52.587
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 12/09/23 12:23:52.6
  Dec  9 12:23:52.600: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:23:52.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:23:52.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:23:52.631
  STEP: creating service in namespace services-1898 @ 12/09/23 12:23:52.635
  STEP: creating service affinity-nodeport-transition in namespace services-1898 @ 12/09/23 12:23:52.635
  STEP: creating replication controller affinity-nodeport-transition in namespace services-1898 @ 12/09/23 12:23:52.663
  I1209 12:23:52.674024      18 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-1898, replica count: 3
  I1209 12:23:55.725859      18 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 12:23:55.735: INFO: Creating new exec pod
  Dec  9 12:23:58.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1898 exec execpod-affinityxj2bj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  Dec  9 12:23:58.861: INFO: stderr: "+ nc -v -t -w 2 affinity-nodeport-transition 80\n+ echo hostName\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Dec  9 12:23:58.861: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:23:58.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1898 exec execpod-affinityxj2bj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.213 80'
  Dec  9 12:23:58.964: INFO: stderr: "+ nc -v -t -w 2 10.152.183.213 80\n+ echo hostName\nConnection to 10.152.183.213 80 port [tcp/http] succeeded!\n"
  Dec  9 12:23:58.964: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:23:58.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1898 exec execpod-affinityxj2bj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.77.176 32391'
  Dec  9 12:23:59.072: INFO: stderr: "+ nc -v -t -w 2 172.31.77.176 32391\n+ echo hostName\nConnection to 172.31.77.176 32391 port [tcp/*] succeeded!\n"
  Dec  9 12:23:59.072: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:23:59.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1898 exec execpod-affinityxj2bj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.129 32391'
  Dec  9 12:23:59.173: INFO: stderr: "+ nc -v -t -w 2 172.31.38.129 32391\n+ echo hostName\nConnection to 172.31.38.129 32391 port [tcp/*] succeeded!\n"
  Dec  9 12:23:59.173: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:23:59.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1898 exec execpod-affinityxj2bj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.129:32391/ ; done'
  Dec  9 12:23:59.375: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n"
  Dec  9 12:23:59.375: INFO: stdout: "\naffinity-nodeport-transition-hvvf8\naffinity-nodeport-transition-hvvf8\naffinity-nodeport-transition-hvvf8\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-hvvf8\naffinity-nodeport-transition-z7gls\naffinity-nodeport-transition-z7gls\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-hvvf8\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-z7gls\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-z7gls"
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-hvvf8
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-hvvf8
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-hvvf8
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-hvvf8
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-z7gls
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-z7gls
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-hvvf8
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-z7gls
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.375: INFO: Received response from host: affinity-nodeport-transition-z7gls
  Dec  9 12:23:59.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1898 exec execpod-affinityxj2bj -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.129:32391/ ; done'
  Dec  9 12:23:59.584: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32391/\n"
  Dec  9 12:23:59.584: INFO: stdout: "\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5\naffinity-nodeport-transition-6zvc5"
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.584: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.585: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.585: INFO: Received response from host: affinity-nodeport-transition-6zvc5
  Dec  9 12:23:59.585: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:23:59.589: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-1898, will wait for the garbage collector to delete the pods @ 12/09/23 12:23:59.602
  Dec  9 12:23:59.665: INFO: Deleting ReplicationController affinity-nodeport-transition took: 8.370829ms
  Dec  9 12:23:59.765: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.097867ms
  STEP: Destroying namespace "services-1898" for this suite. @ 12/09/23 12:24:02.989
• [10.395 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 12/09/23 12:24:02.996
  Dec  9 12:24:02.996: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sysctl @ 12/09/23 12:24:02.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:03.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:03.015
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 12/09/23 12:24:03.018
  STEP: Watching for error events or started pod @ 12/09/23 12:24:03.025
  STEP: Waiting for pod completion @ 12/09/23 12:24:05.029
  STEP: Checking that the pod succeeded @ 12/09/23 12:24:07.044
  STEP: Getting logs from the pod @ 12/09/23 12:24:07.044
  STEP: Checking that the sysctl is actually updated @ 12/09/23 12:24:07.055
  Dec  9 12:24:07.055: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-1743" for this suite. @ 12/09/23 12:24:07.059
• [4.073 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3326
  STEP: Creating a kubernetes client @ 12/09/23 12:24:07.07
  Dec  9 12:24:07.070: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:24:07.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:07.086
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:07.09
  STEP: creating a Service @ 12/09/23 12:24:07.098
  STEP: watching for the Service to be added @ 12/09/23 12:24:07.11
  Dec  9 12:24:07.113: INFO: Found Service test-service-5kbgk in namespace services-7480 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Dec  9 12:24:07.113: INFO: Service test-service-5kbgk created
  STEP: Getting /status @ 12/09/23 12:24:07.113
  Dec  9 12:24:07.116: INFO: Service test-service-5kbgk has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 12/09/23 12:24:07.116
  STEP: watching for the Service to be patched @ 12/09/23 12:24:07.122
  Dec  9 12:24:07.124: INFO: observed Service test-service-5kbgk in namespace services-7480 with annotations: map[] & LoadBalancer: {[]}
  Dec  9 12:24:07.124: INFO: Found Service test-service-5kbgk in namespace services-7480 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Dec  9 12:24:07.124: INFO: Service test-service-5kbgk has service status patched
  STEP: updating the ServiceStatus @ 12/09/23 12:24:07.124
  Dec  9 12:24:07.134: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 12/09/23 12:24:07.134
  Dec  9 12:24:07.136: INFO: Observed Service test-service-5kbgk in namespace services-7480 with annotations: map[] & Conditions: {[]}
  Dec  9 12:24:07.137: INFO: Observed event: &Service{ObjectMeta:{test-service-5kbgk  services-7480  c6f40f7b-0209-44a3-ba2b-ef0c21bda3d6 7790 0 2023-12-09 12:24:07 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-12-09 12:24:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-12-09 12:24:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.67,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.67],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Dec  9 12:24:07.137: INFO: Found Service test-service-5kbgk in namespace services-7480 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  9 12:24:07.137: INFO: Service test-service-5kbgk has service status updated
  STEP: patching the service @ 12/09/23 12:24:07.137
  STEP: watching for the Service to be patched @ 12/09/23 12:24:07.151
  Dec  9 12:24:07.153: INFO: observed Service test-service-5kbgk in namespace services-7480 with labels: map[test-service-static:true]
  Dec  9 12:24:07.153: INFO: observed Service test-service-5kbgk in namespace services-7480 with labels: map[test-service-static:true]
  Dec  9 12:24:07.153: INFO: observed Service test-service-5kbgk in namespace services-7480 with labels: map[test-service-static:true]
  Dec  9 12:24:07.153: INFO: Found Service test-service-5kbgk in namespace services-7480 with labels: map[test-service:patched test-service-static:true]
  Dec  9 12:24:07.153: INFO: Service test-service-5kbgk patched
  STEP: deleting the service @ 12/09/23 12:24:07.153
  STEP: watching for the Service to be deleted @ 12/09/23 12:24:07.172
  Dec  9 12:24:07.174: INFO: Observed event: ADDED
  Dec  9 12:24:07.174: INFO: Observed event: MODIFIED
  Dec  9 12:24:07.174: INFO: Observed event: MODIFIED
  Dec  9 12:24:07.175: INFO: Observed event: MODIFIED
  Dec  9 12:24:07.175: INFO: Found Service test-service-5kbgk in namespace services-7480 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Dec  9 12:24:07.175: INFO: Service test-service-5kbgk deleted
  Dec  9 12:24:07.175: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-7480" for this suite. @ 12/09/23 12:24:07.179
• [0.117 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 12/09/23 12:24:07.187
  Dec  9 12:24:07.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 12:24:07.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:07.201
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:07.204
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/09/23 12:24:07.208
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/09/23 12:24:07.209
  STEP: creating a pod to probe DNS @ 12/09/23 12:24:07.209
  STEP: submitting the pod to kubernetes @ 12/09/23 12:24:07.209
  STEP: retrieving the pod @ 12/09/23 12:24:13.241
  STEP: looking for the results for each expected name from probers @ 12/09/23 12:24:13.246
  Dec  9 12:24:13.262: INFO: DNS probes using dns-8185/dns-test-eb470bac-fc0a-468d-a19a-bb598d4f3a8d succeeded

  Dec  9 12:24:13.262: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 12:24:13.266
  STEP: Destroying namespace "dns-8185" for this suite. @ 12/09/23 12:24:13.278
• [6.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3117
  STEP: Creating a kubernetes client @ 12/09/23 12:24:13.286
  Dec  9 12:24:13.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:24:13.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:13.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:13.307
  STEP: fetching services @ 12/09/23 12:24:13.311
  Dec  9 12:24:13.314: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4117" for this suite. @ 12/09/23 12:24:13.317
• [0.040 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 12/09/23 12:24:13.327
  Dec  9 12:24:13.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 12:24:13.327
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:13.339
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:13.342
  STEP: Setting up server cert @ 12/09/23 12:24:13.375
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 12:24:13.835
  STEP: Deploying the webhook pod @ 12/09/23 12:24:13.844
  STEP: Wait for the deployment to be ready @ 12/09/23 12:24:13.854
  Dec  9 12:24:13.869: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 12:24:15.882
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 12:24:15.897
  Dec  9 12:24:16.898: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 12/09/23 12:24:16.905
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 12/09/23 12:24:16.922
  STEP: Creating a configMap that should not be mutated @ 12/09/23 12:24:16.931
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 12/09/23 12:24:16.942
  STEP: Creating a configMap that should be mutated @ 12/09/23 12:24:16.948
  Dec  9 12:24:16.974: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8896" for this suite. @ 12/09/23 12:24:17.028
  STEP: Destroying namespace "webhook-markers-6742" for this suite. @ 12/09/23 12:24:17.036
• [3.717 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 12/09/23 12:24:17.044
  Dec  9 12:24:17.044: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename field-validation @ 12/09/23 12:24:17.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:17.06
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:17.063
  Dec  9 12:24:17.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  W1209 12:24:19.614958      18 warnings.go:70] unknown field "alpha"
  W1209 12:24:19.615088      18 warnings.go:70] unknown field "beta"
  W1209 12:24:19.615151      18 warnings.go:70] unknown field "delta"
  W1209 12:24:19.615187      18 warnings.go:70] unknown field "epsilon"
  W1209 12:24:19.615226      18 warnings.go:70] unknown field "gamma"
  Dec  9 12:24:20.146: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6790" for this suite. @ 12/09/23 12:24:20.165
• [3.128 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 12/09/23 12:24:20.172
  Dec  9 12:24:20.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 12:24:20.173
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:20.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:20.19
  Dec  9 12:24:20.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/09/23 12:24:21.58
  Dec  9 12:24:21.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-1572 --namespace=crd-publish-openapi-1572 create -f -'
  Dec  9 12:24:23.868: INFO: stderr: ""
  Dec  9 12:24:23.868: INFO: stdout: "e2e-test-crd-publish-openapi-1003-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec  9 12:24:23.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-1572 --namespace=crd-publish-openapi-1572 delete e2e-test-crd-publish-openapi-1003-crds test-cr'
  Dec  9 12:24:23.937: INFO: stderr: ""
  Dec  9 12:24:23.937: INFO: stdout: "e2e-test-crd-publish-openapi-1003-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Dec  9 12:24:23.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-1572 --namespace=crd-publish-openapi-1572 apply -f -'
  Dec  9 12:24:24.199: INFO: stderr: ""
  Dec  9 12:24:24.199: INFO: stdout: "e2e-test-crd-publish-openapi-1003-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec  9 12:24:24.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-1572 --namespace=crd-publish-openapi-1572 delete e2e-test-crd-publish-openapi-1003-crds test-cr'
  Dec  9 12:24:24.287: INFO: stderr: ""
  Dec  9 12:24:24.287: INFO: stdout: "e2e-test-crd-publish-openapi-1003-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 12/09/23 12:24:24.287
  Dec  9 12:24:24.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-1572 explain e2e-test-crd-publish-openapi-1003-crds'
  Dec  9 12:24:24.394: INFO: stderr: ""
  Dec  9 12:24:24.394: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-1003-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  Dec  9 12:24:25.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1572" for this suite. @ 12/09/23 12:24:25.768
• [5.603 seconds]
------------------------------
SS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 12/09/23 12:24:25.775
  Dec  9 12:24:25.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename security-context-test @ 12/09/23 12:24:25.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:25.793
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:25.796
  Dec  9 12:24:29.823: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-3394" for this suite. @ 12/09/23 12:24:29.826
• [4.058 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 12/09/23 12:24:29.833
  Dec  9 12:24:29.833: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-pred @ 12/09/23 12:24:29.834
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:24:29.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:24:29.852
  Dec  9 12:24:29.856: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  9 12:24:29.864: INFO: Waiting for terminating namespaces to be deleted...
  Dec  9 12:24:29.867: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-38-129 before test
  Dec  9 12:24:29.872: INFO: nginx-ingress-controller-kubernetes-worker-j9sl2 from ingress-nginx-kubernetes-worker started at 2023-12-09 12:04:10 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.872: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 12:24:29.872: INFO: calico-node-j8mjn from kube-system started at 2023-12-09 12:03:58 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.872: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 12:24:29.872: INFO: sonobuoy-e2e-job-f705b9d168e44085 from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:24:29.872: INFO: 	Container e2e ready: true, restart count 0
  Dec  9 12:24:29.872: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:24:29.872: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-k7blf from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:24:29.872: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:24:29.872: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 12:24:29.872: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-77-176 before test
  Dec  9 12:24:29.878: INFO: nginx-ingress-controller-kubernetes-worker-jdvw7 from ingress-nginx-kubernetes-worker started at 2023-12-09 12:10:06 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.878: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 12:24:29.879: INFO: calico-node-rzjq2 from kube-system started at 2023-12-09 11:58:38 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.879: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 12:24:29.879: INFO: busybox-user-65534-49d9810a-0a93-4ce4-a0d9-93697edcba3a from security-context-test-3394 started at 2023-12-09 12:24:25 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.879: INFO: 	Container busybox-user-65534-49d9810a-0a93-4ce4-a0d9-93697edcba3a ready: false, restart count 0
  Dec  9 12:24:29.879: INFO: sonobuoy from sonobuoy started at 2023-12-09 12:07:20 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.879: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  9 12:24:29.879: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-29sdb from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:24:29.879: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:24:29.879: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 12:24:29.879: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-80-205 before test
  Dec  9 12:24:29.883: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-nm9vp from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: nginx-ingress-controller-kubernetes-worker-crj2p from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: calico-node-f2fvk from kube-system started at 2023-12-09 11:58:36 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: coredns-59cfb5bf46-t9rkp from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container coredns ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: kube-state-metrics-78c475f58b-km8l9 from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: metrics-server-v0.6.3-69d7fbfdf8-hlh9f from kube-system started at 2023-12-09 11:58:49 +0000 UTC (2 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: dashboard-metrics-scraper-5dd7cb5fc-jlz46 from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: kubernetes-dashboard-7b899cb9d9-68n2j from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-w5xwq from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 12:24:29.883: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 12:24:29.883: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/09/23 12:24:29.883
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/09/23 12:24:31.903
  STEP: Trying to apply a random label on the found node. @ 12/09/23 12:24:31.918
  STEP: verifying the node has the label kubernetes.io/e2e-18bf117d-91a2-4efc-8ef5-732d1afd0b14 95 @ 12/09/23 12:24:31.926
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 12/09/23 12:24:31.929
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.77.176 on the node which pod4 resides and expect not scheduled @ 12/09/23 12:24:33.945
  STEP: removing the label kubernetes.io/e2e-18bf117d-91a2-4efc-8ef5-732d1afd0b14 off the node ip-172-31-77-176 @ 12/09/23 12:29:33.95
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-18bf117d-91a2-4efc-8ef5-732d1afd0b14 @ 12/09/23 12:29:33.962
  Dec  9 12:29:33.966: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-4464" for this suite. @ 12/09/23 12:29:33.971
• [304.147 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 12/09/23 12:29:33.981
  Dec  9 12:29:33.981: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 12:29:33.981
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:33.995
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:33.998
  STEP: Creating configMap configmap-5351/configmap-test-cc28b20b-fa16-4ab6-b11d-4b51bb6c9a98 @ 12/09/23 12:29:34.002
  STEP: Creating a pod to test consume configMaps @ 12/09/23 12:29:34.006
  STEP: Saw pod success @ 12/09/23 12:29:38.03
  Dec  9 12:29:38.033: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-configmaps-88316134-2b43-48cf-bda0-f1f5070e453c container env-test: <nil>
  STEP: delete the pod @ 12/09/23 12:29:38.051
  Dec  9 12:29:38.067: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5351" for this suite. @ 12/09/23 12:29:38.072
• [4.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 12/09/23 12:29:38.083
  Dec  9 12:29:38.083: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/09/23 12:29:38.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:38.096
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:38.101
  STEP: fetching the /apis discovery document @ 12/09/23 12:29:38.104
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 12/09/23 12:29:38.106
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 12/09/23 12:29:38.106
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 12/09/23 12:29:38.106
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 12/09/23 12:29:38.107
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 12/09/23 12:29:38.107
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 12/09/23 12:29:38.109
  Dec  9 12:29:38.109: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7369" for this suite. @ 12/09/23 12:29:38.112
• [0.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 12/09/23 12:29:38.119
  Dec  9 12:29:38.119: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 12:29:38.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:38.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:38.136
  STEP: Creating configMap with name configmap-test-volume-d3ed22b1-ca77-472f-af47-094b536f8198 @ 12/09/23 12:29:38.139
  STEP: Creating a pod to test consume configMaps @ 12/09/23 12:29:38.144
  STEP: Saw pod success @ 12/09/23 12:29:42.169
  Dec  9 12:29:42.172: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-configmaps-23e3ecda-1e5e-42ad-909f-d351798b414b container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 12:29:42.192
  Dec  9 12:29:42.209: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7646" for this suite. @ 12/09/23 12:29:42.214
• [4.101 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 12/09/23 12:29:42.22
  Dec  9 12:29:42.220: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:29:42.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:42.235
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:42.239
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:29:42.244
  STEP: Saw pod success @ 12/09/23 12:29:46.264
  Dec  9 12:29:46.268: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-7a4f68b7-b7b4-4a98-b88a-356ffe4e2a90 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:29:46.275
  Dec  9 12:29:46.293: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8872" for this suite. @ 12/09/23 12:29:46.298
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 12/09/23 12:29:46.306
  Dec  9 12:29:46.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 12:29:46.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:46.323
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:46.327
  Dec  9 12:29:46.331: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/09/23 12:29:47.671
  Dec  9 12:29:47.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-366 --namespace=crd-publish-openapi-366 create -f -'
  Dec  9 12:29:49.941: INFO: stderr: ""
  Dec  9 12:29:49.941: INFO: stdout: "e2e-test-crd-publish-openapi-3045-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec  9 12:29:49.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-366 --namespace=crd-publish-openapi-366 delete e2e-test-crd-publish-openapi-3045-crds test-cr'
  Dec  9 12:29:50.009: INFO: stderr: ""
  Dec  9 12:29:50.009: INFO: stdout: "e2e-test-crd-publish-openapi-3045-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Dec  9 12:29:50.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-366 --namespace=crd-publish-openapi-366 apply -f -'
  Dec  9 12:29:50.333: INFO: stderr: ""
  Dec  9 12:29:50.333: INFO: stdout: "e2e-test-crd-publish-openapi-3045-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec  9 12:29:50.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-366 --namespace=crd-publish-openapi-366 delete e2e-test-crd-publish-openapi-3045-crds test-cr'
  Dec  9 12:29:50.388: INFO: stderr: ""
  Dec  9 12:29:50.388: INFO: stdout: "e2e-test-crd-publish-openapi-3045-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/09/23 12:29:50.388
  Dec  9 12:29:50.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-366 explain e2e-test-crd-publish-openapi-3045-crds'
  Dec  9 12:29:50.491: INFO: stderr: ""
  Dec  9 12:29:50.491: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-3045-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Dec  9 12:29:51.862: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-366" for this suite. @ 12/09/23 12:29:51.869
• [5.569 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 12/09/23 12:29:51.876
  Dec  9 12:29:51.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 12:29:51.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:51.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:51.9
  STEP: Creating secret with name secret-test-144da847-7e6e-479a-bf7f-61222ad86af4 @ 12/09/23 12:29:51.902
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:29:51.906
  STEP: Saw pod success @ 12/09/23 12:29:55.927
  Dec  9 12:29:55.930: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-secrets-314604d9-cdc7-480a-948c-a2e73f7e5c0c container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:29:55.943
  Dec  9 12:29:55.958: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8585" for this suite. @ 12/09/23 12:29:55.964
• [4.094 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 12/09/23 12:29:55.971
  Dec  9 12:29:55.971: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 12:29:55.972
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:55.993
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:56.006
  STEP: Creating projection with secret that has name secret-emptykey-test-cc870470-731b-49e5-95a0-7a3f0fad109d @ 12/09/23 12:29:56.013
  Dec  9 12:29:56.015: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4161" for this suite. @ 12/09/23 12:29:56.024
• [0.060 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 12/09/23 12:29:56.031
  Dec  9 12:29:56.031: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 12:29:56.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:29:56.051
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:29:56.053
  Dec  9 12:29:56.058: INFO: Creating deployment "webserver-deployment"
  Dec  9 12:29:56.066: INFO: Waiting for observed generation 1
  Dec  9 12:29:58.078: INFO: Waiting for all required pods to come up
  Dec  9 12:29:58.088: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 12/09/23 12:29:58.088
  Dec  9 12:30:00.095: INFO: Waiting for deployment "webserver-deployment" to complete
  Dec  9 12:30:00.101: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Dec  9 12:30:00.110: INFO: Updating deployment webserver-deployment
  Dec  9 12:30:00.110: INFO: Waiting for observed generation 2
  Dec  9 12:30:02.117: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Dec  9 12:30:02.120: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Dec  9 12:30:02.123: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec  9 12:30:02.131: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Dec  9 12:30:02.131: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Dec  9 12:30:02.134: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec  9 12:30:02.139: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Dec  9 12:30:02.139: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Dec  9 12:30:02.149: INFO: Updating deployment webserver-deployment
  Dec  9 12:30:02.149: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Dec  9 12:30:02.154: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Dec  9 12:30:02.159: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Dec  9 12:30:02.167: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "419ac444-70c8-4b1d-ad76-1f7bcb34671f",
      ResourceVersion: (string) (len=4) "9253",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721802,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  9 12:30:02.172: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "da3e4daa-b057-4d6a-9792-c0d84ee11d95",
      ResourceVersion: (string) (len=4) "9255",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "419ac444-70c8-4b1d-ad76-1f7bcb34671f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721802,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 31 39 61 63 34  34 34 2d 37 30 63 38 2d  |\"419ac444-70c8-|
              00000120  34 62 31 64 2d 61 64 37  36 2d 31 66 37 62 63 62  |4b1d-ad76-1f7bcb|
              00000130  33 34 36 37 31 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |34671f\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 12:30:02.173: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Dec  9 12:30:02.173: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
      ResourceVersion: (string) (len=4) "9254",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "419ac444-70c8-4b1d-ad76-1f7bcb34671f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721802,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 31 39 61 63 34  34 34 2d 37 30 63 38 2d  |\"419ac444-70c8-|
              00000120  34 62 31 64 2d 61 64 37  36 2d 31 66 37 62 63 62  |4b1d-ad76-1f7bcb|
              00000130  33 34 36 37 31 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |34671f\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 12:30:02.182: INFO: Pod "webserver-deployment-557759b7c7-5hn6c" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-5hn6c",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c75bcae1-ad63-4572-b98a-89e703795a0c",
      ResourceVersion: (string) (len=4) "9109",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 35 37 5c 22 7d  |192.168.34.57\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jhw6q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jhw6q",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.57",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.57"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721797,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://dc18ea25f3140e24e31a54d7b5d93f03510db57970bf290c799d28887de295c1",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.184: INFO: Pod "webserver-deployment-557759b7c7-8sdl6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-8sdl6",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "b0568803-ff7a-4b49-a043-56e5c3e6faa6",
      ResourceVersion: (string) (len=4) "9261",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721802,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721802,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gqsdl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gqsdl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.188: INFO: Pod "webserver-deployment-557759b7c7-bl4rc" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-bl4rc",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4d423827-f30f-4dee-a351-0b114caa054e",
      ResourceVersion: (string) (len=4) "9111",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 35 38 5c 22 7d  |192.168.34.58\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-j65vk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-j65vk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.58",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.58"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721797,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://34714bc3ddcc54f8dbb2fb0b3a5e78b03b0dae426b9ca97bde54d1ed7231f574",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.190: INFO: Pod "webserver-deployment-557759b7c7-j6xdm" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-j6xdm",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a96bc7d3-3f0d-4ec1-8047-94af4f92a8da",
      ResourceVersion: (string) (len=4) "9067",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 35 30 2e 38 35 5c 22  |192.168.250.85\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-jf4hn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-jf4hn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-205",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.205",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.250.85",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.250.85"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721796,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://e4525c5cee386b5f6318881e6e2c9c8f1eb15360b2a3fb3bdd46c46c4414f5fe",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.199: INFO: Pod "webserver-deployment-557759b7c7-j87jg" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-j87jg",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5f05d15e-9809-496f-8c6a-89c5ab6bf42a",
      ResourceVersion: (string) (len=4) "9103",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 35 36 5c 22 7d  |192.168.34.56\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-zkrgf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-zkrgf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.56",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.56"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721797,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://34e8b68bcc8f7b9871d6fe3c254ed16ca8d8b7d2db78beda34f879490c1e5333",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.200: INFO: Pod "webserver-deployment-557759b7c7-p92sh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-p92sh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "500a6767-08b4-40cd-80f6-08d4b85155d8",
      ResourceVersion: (string) (len=4) "9072",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 35 30 2e 38 34 5c 22  |192.168.250.84\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qghvz",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qghvz",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-205",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.205",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.250.84",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.250.84"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721796,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://5e7a1c9b79e1add05002f86b3ebb8b607ae67d0032df47e884399ed61aba302f",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.201: INFO: Pod "webserver-deployment-557759b7c7-pkt5b" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-pkt5b",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "70f4bc7f-bf31-4e4f-bb8d-febeac9df69f",
      ResourceVersion: (string) (len=4) "9116",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 35 30 2e 38 36 5c 22  |192.168.250.86\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-24fwk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-24fwk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-205",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.205",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.250.86",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.250.86"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721796,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://278411ad981875978e3c22426d24802bef2c66ccd3b0c6d2fb9ca1419720377d",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.204: INFO: Pod "webserver-deployment-557759b7c7-v5nsw" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-v5nsw",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "48b0e2f3-6862-4513-9198-4b4653007194",
      ResourceVersion: (string) (len=4) "9119",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=522) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 30 31 2e 32 31 33 5c  |192.168.201.213\|
              000001e0  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 69  |"}":{".":{},"f:i|
              000001f0  70 22 3a 7b 7d 7d 7d 2c  22 66 3a 73 74 61 72 74  |p":{}}},"f:start|
              00000200  54 69 6d 65 22 3a 7b 7d  7d 7d                    |Time":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5fn5c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5fn5c",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-38-129",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721798,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.38.129",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=15) "192.168.201.213",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.201.213"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721797,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://230249dbcaec70953b97b7ed15a242b43b0fd7eed579306687a865184e8c17bc",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.207: INFO: Pod "webserver-deployment-557759b7c7-xxs4g" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-xxs4g",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3e84d7aa-6364-4358-bb50-62df5df4e8cd",
      ResourceVersion: (string) (len=4) "9257",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721802,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721802,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-wrknh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-wrknh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.208: INFO: Pod "webserver-deployment-557759b7c7-z29vj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-z29vj",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ff68379f-9fc9-4c74-bc4d-ae14f5ef994d",
      ResourceVersion: (string) (len=4) "9105",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0f7710e4-de72-45ca-b802-72d871597eb0",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 66  37 37 31 30 65 34 2d 64  |d\":\"0f7710e4-d|
              00000090  65 37 32 2d 34 35 63 61  2d 62 38 30 32 2d 37 32  |e72-45ca-b802-72|
              000000a0  64 38 37 31 35 39 37 65  62 30 5c 22 7d 22 3a 7b  |d871597eb0\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 35 35 5c 22 7d  |192.168.34.55\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2x5b6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2x5b6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721797,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721796,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.55",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.55"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721796,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837721797,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://a72aa190a77151c0ef00e5970ef5285094f8af383d842ca68fedf020d0b7aa1a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.209: INFO: Pod "webserver-deployment-9b4f5bf69-2trpx" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-2trpx",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "152daf41-abec-4d55-983b-9aeadfefd92b",
      ResourceVersion: (string) (len=4) "9220",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "da3e4daa-b057-4d6a-9792-c0d84ee11d95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 61  33 65 34 64 61 61 2d 62  |d\":\"da3e4daa-b|
              00000090  30 35 37 2d 34 64 36 61  2d 39 37 39 32 2d 63 30  |057-4d6a-9792-c0|
              000000a0  64 38 34 65 65 31 31 64  39 35 5c 22 7d 22 3a 7b  |d84ee11d95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=566) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 32 35 30  2e 38 37 5c 22 7d 22 3a  |.168.250.87\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000220  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000230  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-789t9",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-789t9",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-80-205",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.80.205",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.250.87",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.250.87"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.211: INFO: Pod "webserver-deployment-9b4f5bf69-hdhwj" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-hdhwj",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "975b2a54-a255-4f03-aeeb-56bc51186321",
      ResourceVersion: (string) (len=4) "9230",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "da3e4daa-b057-4d6a-9792-c0d84ee11d95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 61  33 65 34 64 61 61 2d 62  |d\":\"da3e4daa-b|
              00000090  30 35 37 2d 34 64 36 61  2d 39 37 39 32 2d 63 30  |057-4d6a-9792-c0|
              000000a0  64 38 34 65 65 31 31 64  39 35 5c 22 7d 22 3a 7b  |d84ee11d95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721801,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=567) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 32 30 31  2e 32 31 35 5c 22 7d 22  |.168.201.215\"}"|
              00000210  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000220  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000230  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fx5lp",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fx5lp",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-38-129",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.38.129",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=15) "192.168.201.215",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.201.215"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.213: INFO: Pod "webserver-deployment-9b4f5bf69-ht8n9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-ht8n9",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "560d8693-20f5-400b-98d9-1afee516a5de",
      ResourceVersion: (string) (len=4) "9232",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "da3e4daa-b057-4d6a-9792-c0d84ee11d95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 61  33 65 34 64 61 61 2d 62  |d\":\"da3e4daa-b|
              00000090  30 35 37 2d 34 64 36 61  2d 39 37 39 32 2d 63 30  |057-4d6a-9792-c0|
              000000a0  64 38 34 65 65 31 31 64  39 35 5c 22 7d 22 3a 7b  |d84ee11d95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721801,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=567) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 32 30 31  2e 32 31 36 5c 22 7d 22  |.168.201.216\"}"|
              00000210  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              00000220  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000230  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bkvwk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bkvwk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-38-129",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.38.129",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=15) "192.168.201.216",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.201.216"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.214: INFO: Pod "webserver-deployment-9b4f5bf69-jjcgl" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-jjcgl",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "16be5d54-fc00-45d1-82c6-2445ff2cecda",
      ResourceVersion: (string) (len=4) "9259",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721802,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "da3e4daa-b057-4d6a-9792-c0d84ee11d95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721802,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 61  33 65 34 64 61 61 2d 62  |d\":\"da3e4daa-b|
              00000090  30 35 37 2d 34 64 36 61  2d 39 37 39 32 2d 63 30  |057-4d6a-9792-c0|
              000000a0  64 38 34 65 65 31 31 64  39 35 5c 22 7d 22 3a 7b  |d84ee11d95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tz7tm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tz7tm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.215: INFO: Pod "webserver-deployment-9b4f5bf69-m48zz" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-m48zz",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "60896773-a6f9-42c6-9129-c9be5cf913dd",
      ResourceVersion: (string) (len=4) "9251",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "da3e4daa-b057-4d6a-9792-c0d84ee11d95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 61  33 65 34 64 61 61 2d 62  |d\":\"da3e4daa-b|
              00000090  30 35 37 2d 34 64 36 61  2d 39 37 39 32 2d 63 30  |057-4d6a-9792-c0|
              000000a0  64 38 34 65 65 31 31 64  39 35 5c 22 7d 22 3a 7b  |d84ee11d95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721801,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 33 34 2e  36 30 5c 22 7d 22 3a 7b  |.168.34.60\"}":{|
              00000210  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000220  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-z22p7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-z22p7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.60",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.60"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.220: INFO: Pod "webserver-deployment-9b4f5bf69-qn7wq" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-qn7wq",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=15) "deployment-1205",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "040bd32d-5ec6-477d-b06f-ce60308da868",
      ResourceVersion: (string) (len=4) "9248",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "da3e4daa-b057-4d6a-9792-c0d84ee11d95",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 61  33 65 34 64 61 61 2d 62  |d\":\"da3e4daa-b|
              00000090  30 35 37 2d 34 64 36 61  2d 39 37 39 32 2d 63 30  |057-4d6a-9792-c0|
              000000a0  64 38 34 65 65 31 31 64  39 35 5c 22 7d 22 3a 7b  |d84ee11d95\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721801,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 33 34 2e  35 39 5c 22 7d 22 3a 7b  |.168.34.59\"}":{|
              00000210  22 2e 22 3a 7b 7d 2c 22  66 3a 69 70 22 3a 7b 7d  |".":{},"f:ip":{}|
              00000220  7d 7d 2c 22 66 3a 73 74  61 72 74 54 69 6d 65 22  |}},"f:startTime"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-h5dxt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-h5dxt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837721800,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.59",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.59"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837721800,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:30:02.225: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-1205" for this suite. @ 12/09/23 12:30:02.23
• [6.212 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 12/09/23 12:30:02.244
  Dec  9 12:30:02.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 12:30:02.244
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:02.328
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:02.33
  STEP: Counting existing ResourceQuota @ 12/09/23 12:30:02.332
  STEP: Creating a ResourceQuota @ 12/09/23 12:30:07.336
  STEP: Ensuring resource quota status is calculated @ 12/09/23 12:30:07.342
  STEP: Creating a ReplicationController @ 12/09/23 12:30:09.347
  STEP: Ensuring resource quota status captures replication controller creation @ 12/09/23 12:30:09.36
  STEP: Deleting a ReplicationController @ 12/09/23 12:30:11.365
  STEP: Ensuring resource quota status released usage @ 12/09/23 12:30:11.373
  Dec  9 12:30:13.377: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2555" for this suite. @ 12/09/23 12:30:13.38
• [11.143 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 12/09/23 12:30:13.386
  Dec  9 12:30:13.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 12:30:13.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:13.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:13.413
  STEP: Setting up server cert @ 12/09/23 12:30:13.436
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 12:30:14.019
  STEP: Deploying the webhook pod @ 12/09/23 12:30:14.027
  STEP: Wait for the deployment to be ready @ 12/09/23 12:30:14.039
  Dec  9 12:30:14.045: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 12:30:16.055
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 12:30:16.066
  Dec  9 12:30:17.066: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  9 12:30:17.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3158-crds.webhook.example.com via the AdmissionRegistration API @ 12/09/23 12:30:17.583
  STEP: Creating a custom resource while v1 is storage version @ 12/09/23 12:30:17.602
  STEP: Patching Custom Resource Definition to set v2 as storage @ 12/09/23 12:30:19.649
  STEP: Patching the custom resource while v2 is storage version @ 12/09/23 12:30:19.661
  Dec  9 12:30:19.701: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6388" for this suite. @ 12/09/23 12:30:20.269
  STEP: Destroying namespace "webhook-markers-8072" for this suite. @ 12/09/23 12:30:20.277
• [6.900 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 12/09/23 12:30:20.287
  Dec  9 12:30:20.287: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:30:20.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:20.304
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:20.306
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-5597 @ 12/09/23 12:30:20.308
  STEP: changing the ExternalName service to type=ClusterIP @ 12/09/23 12:30:20.312
  STEP: creating replication controller externalname-service in namespace services-5597 @ 12/09/23 12:30:20.328
  I1209 12:30:20.335406      18 runners.go:197] Created replication controller with name: externalname-service, namespace: services-5597, replica count: 2
  I1209 12:30:23.387141      18 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 12:30:23.387: INFO: Creating new exec pod
  Dec  9 12:30:26.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-5597 exec execpodg7qkt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec  9 12:30:26.515: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec  9 12:30:26.515: INFO: stdout: "externalname-service-rllvp"
  Dec  9 12:30:26.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-5597 exec execpodg7qkt -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.79 80'
  Dec  9 12:30:26.617: INFO: stderr: "+ nc -v -t -w 2 10.152.183.79 80\n+ echo hostName\nConnection to 10.152.183.79 80 port [tcp/http] succeeded!\n"
  Dec  9 12:30:26.617: INFO: stdout: "externalname-service-rllvp"
  Dec  9 12:30:26.617: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:30:26.621: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-5597" for this suite. @ 12/09/23 12:30:26.637
• [6.358 seconds]
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 12/09/23 12:30:26.644
  Dec  9 12:30:26.644: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 12:30:26.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:26.666
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:26.668
  Dec  9 12:30:26.670: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/09/23 12:30:27.959
  Dec  9 12:30:27.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-9823 --namespace=crd-publish-openapi-9823 create -f -'
  Dec  9 12:30:28.321: INFO: stderr: ""
  Dec  9 12:30:28.321: INFO: stdout: "e2e-test-crd-publish-openapi-9035-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec  9 12:30:28.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-9823 --namespace=crd-publish-openapi-9823 delete e2e-test-crd-publish-openapi-9035-crds test-cr'
  Dec  9 12:30:28.377: INFO: stderr: ""
  Dec  9 12:30:28.377: INFO: stdout: "e2e-test-crd-publish-openapi-9035-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Dec  9 12:30:28.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-9823 --namespace=crd-publish-openapi-9823 apply -f -'
  Dec  9 12:30:28.642: INFO: stderr: ""
  Dec  9 12:30:28.642: INFO: stdout: "e2e-test-crd-publish-openapi-9035-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec  9 12:30:28.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-9823 --namespace=crd-publish-openapi-9823 delete e2e-test-crd-publish-openapi-9035-crds test-cr'
  Dec  9 12:30:28.695: INFO: stderr: ""
  Dec  9 12:30:28.695: INFO: stdout: "e2e-test-crd-publish-openapi-9035-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/09/23 12:30:28.695
  Dec  9 12:30:28.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-9823 explain e2e-test-crd-publish-openapi-9035-crds'
  Dec  9 12:30:28.808: INFO: stderr: ""
  Dec  9 12:30:28.808: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-9035-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  Dec  9 12:30:30.090: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9823" for this suite. @ 12/09/23 12:30:30.096
• [3.459 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 12/09/23 12:30:30.104
  Dec  9 12:30:30.104: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 12:30:30.104
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:30.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:30.126
  STEP: Setting up server cert @ 12/09/23 12:30:30.161
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 12:30:30.375
  STEP: Deploying the webhook pod @ 12/09/23 12:30:30.38
  STEP: Wait for the deployment to be ready @ 12/09/23 12:30:30.393
  Dec  9 12:30:30.401: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 12:30:32.411
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 12:30:32.422
  Dec  9 12:30:33.422: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  9 12:30:33.429: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7766-crds.webhook.example.com via the AdmissionRegistration API @ 12/09/23 12:30:33.939
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/09/23 12:30:33.956
  Dec  9 12:30:35.998: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2459" for this suite. @ 12/09/23 12:30:36.562
  STEP: Destroying namespace "webhook-markers-4603" for this suite. @ 12/09/23 12:30:36.569
• [6.471 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 12/09/23 12:30:36.576
  Dec  9 12:30:36.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 12:30:36.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:36.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:36.597
  STEP: Setting up server cert @ 12/09/23 12:30:36.621
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 12:30:37.026
  STEP: Deploying the webhook pod @ 12/09/23 12:30:37.031
  STEP: Wait for the deployment to be ready @ 12/09/23 12:30:37.044
  Dec  9 12:30:37.049: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 12:30:39.06
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 12:30:39.07
  Dec  9 12:30:40.070: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 12/09/23 12:30:40.077
  STEP: create a configmap that should be updated by the webhook @ 12/09/23 12:30:40.094
  Dec  9 12:30:40.106: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1607" for this suite. @ 12/09/23 12:30:40.151
  STEP: Destroying namespace "webhook-markers-4566" for this suite. @ 12/09/23 12:30:40.159
• [3.589 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 12/09/23 12:30:40.167
  Dec  9 12:30:40.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 12:30:40.168
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:40.185
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:40.187
  STEP: creating the pod @ 12/09/23 12:30:40.189
  STEP: setting up watch @ 12/09/23 12:30:40.189
  STEP: submitting the pod to kubernetes @ 12/09/23 12:30:40.295
  STEP: verifying the pod is in kubernetes @ 12/09/23 12:30:40.302
  STEP: verifying pod creation was observed @ 12/09/23 12:30:40.308
  STEP: deleting the pod gracefully @ 12/09/23 12:30:42.321
  STEP: verifying pod deletion was observed @ 12/09/23 12:30:42.328
  Dec  9 12:30:43.714: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7104" for this suite. @ 12/09/23 12:30:43.717
• [3.555 seconds]
------------------------------
SSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 12/09/23 12:30:43.723
  Dec  9 12:30:43.723: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 12:30:43.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:30:43.74
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:30:43.742
  STEP: creating the pod with failed condition @ 12/09/23 12:30:43.743
  STEP: updating the pod @ 12/09/23 12:32:43.753
  Dec  9 12:32:44.265: INFO: Successfully updated pod "var-expansion-f60592b5-be18-4c79-9d6a-353e2242f10c"
  STEP: waiting for pod running @ 12/09/23 12:32:44.265
  STEP: deleting the pod gracefully @ 12/09/23 12:32:46.271
  Dec  9 12:32:46.271: INFO: Deleting pod "var-expansion-f60592b5-be18-4c79-9d6a-353e2242f10c" in namespace "var-expansion-4967"
  Dec  9 12:32:46.280: INFO: Wait up to 5m0s for pod "var-expansion-f60592b5-be18-4c79-9d6a-353e2242f10c" to be fully deleted
  Dec  9 12:33:18.353: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4967" for this suite. @ 12/09/23 12:33:18.356
• [154.642 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 12/09/23 12:33:18.365
  Dec  9 12:33:18.365: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 12:33:18.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:33:18.383
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:33:18.385
  STEP: Creating configMap with name configmap-test-upd-4f66babf-035c-45c8-9673-1b4608933027 @ 12/09/23 12:33:18.391
  STEP: Creating the pod @ 12/09/23 12:33:18.395
  STEP: Updating configmap configmap-test-upd-4f66babf-035c-45c8-9673-1b4608933027 @ 12/09/23 12:33:20.428
  STEP: waiting to observe update in volume @ 12/09/23 12:33:20.434
  Dec  9 12:34:26.715: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1584" for this suite. @ 12/09/23 12:34:26.718
• [68.360 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 12/09/23 12:34:26.727
  Dec  9 12:34:26.727: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename proxy @ 12/09/23 12:34:26.728
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:34:26.749
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:34:26.751
  Dec  9 12:34:26.753: INFO: Creating pod...
  Dec  9 12:34:28.768: INFO: Creating service...
  Dec  9 12:34:28.779: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/pods/agnhost/proxy?method=DELETE
  Dec  9 12:34:28.784: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  9 12:34:28.784: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/pods/agnhost/proxy?method=OPTIONS
  Dec  9 12:34:28.788: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  9 12:34:28.788: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/pods/agnhost/proxy?method=PATCH
  Dec  9 12:34:28.793: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  9 12:34:28.793: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/pods/agnhost/proxy?method=POST
  Dec  9 12:34:28.796: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  9 12:34:28.796: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/pods/agnhost/proxy?method=PUT
  Dec  9 12:34:28.799: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  9 12:34:28.799: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/services/e2e-proxy-test-service/proxy?method=DELETE
  Dec  9 12:34:28.804: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  9 12:34:28.804: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Dec  9 12:34:28.808: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  9 12:34:28.808: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/services/e2e-proxy-test-service/proxy?method=PATCH
  Dec  9 12:34:28.813: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  9 12:34:28.813: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/services/e2e-proxy-test-service/proxy?method=POST
  Dec  9 12:34:28.818: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  9 12:34:28.818: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/services/e2e-proxy-test-service/proxy?method=PUT
  Dec  9 12:34:28.822: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  9 12:34:28.822: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/pods/agnhost/proxy?method=GET
  Dec  9 12:34:28.824: INFO: http.Client request:GET StatusCode:301
  Dec  9 12:34:28.824: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/services/e2e-proxy-test-service/proxy?method=GET
  Dec  9 12:34:28.829: INFO: http.Client request:GET StatusCode:301
  Dec  9 12:34:28.830: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/pods/agnhost/proxy?method=HEAD
  Dec  9 12:34:28.832: INFO: http.Client request:HEAD StatusCode:301
  Dec  9 12:34:28.832: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-9372/services/e2e-proxy-test-service/proxy?method=HEAD
  Dec  9 12:34:28.837: INFO: http.Client request:HEAD StatusCode:301
  Dec  9 12:34:28.837: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-9372" for this suite. @ 12/09/23 12:34:28.841
• [2.120 seconds]
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 12/09/23 12:34:28.848
  Dec  9 12:34:28.848: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:34:28.848
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:34:28.863
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:34:28.865
  Dec  9 12:34:28.870: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-493" for this suite. @ 12/09/23 12:34:28.873
• [0.031 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 12/09/23 12:34:28.882
  Dec  9 12:34:28.882: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 12:34:28.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:34:28.898
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:34:28.9
  STEP: creating a replication controller @ 12/09/23 12:34:28.902
  Dec  9 12:34:28.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 create -f -'
  Dec  9 12:34:29.076: INFO: stderr: ""
  Dec  9 12:34:29.076: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/09/23 12:34:29.076
  Dec  9 12:34:29.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:34:29.132: INFO: stderr: ""
  Dec  9 12:34:29.132: INFO: stdout: "update-demo-nautilus-4kj8b update-demo-nautilus-9kx77 "
  Dec  9 12:34:29.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:29.182: INFO: stderr: ""
  Dec  9 12:34:29.182: INFO: stdout: ""
  Dec  9 12:34:29.182: INFO: update-demo-nautilus-4kj8b is created but not running
  Dec  9 12:34:34.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:34:34.262: INFO: stderr: ""
  Dec  9 12:34:34.262: INFO: stdout: "update-demo-nautilus-4kj8b update-demo-nautilus-9kx77 "
  Dec  9 12:34:34.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:34.313: INFO: stderr: ""
  Dec  9 12:34:34.313: INFO: stdout: "true"
  Dec  9 12:34:34.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:34:34.362: INFO: stderr: ""
  Dec  9 12:34:34.362: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:34:34.362: INFO: validating pod update-demo-nautilus-4kj8b
  Dec  9 12:34:34.367: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:34:34.367: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:34:34.367: INFO: update-demo-nautilus-4kj8b is verified up and running
  Dec  9 12:34:34.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-9kx77 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:34.417: INFO: stderr: ""
  Dec  9 12:34:34.417: INFO: stdout: "true"
  Dec  9 12:34:34.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-9kx77 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:34:34.471: INFO: stderr: ""
  Dec  9 12:34:34.471: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:34:34.471: INFO: validating pod update-demo-nautilus-9kx77
  Dec  9 12:34:34.476: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:34:34.477: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:34:34.477: INFO: update-demo-nautilus-9kx77 is verified up and running
  STEP: scaling down the replication controller @ 12/09/23 12:34:34.477
  Dec  9 12:34:34.477: INFO: scanned /root for discovery docs: <nil>
  Dec  9 12:34:34.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  Dec  9 12:34:35.548: INFO: stderr: ""
  Dec  9 12:34:35.548: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/09/23 12:34:35.548
  Dec  9 12:34:35.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:34:35.599: INFO: stderr: ""
  Dec  9 12:34:35.599: INFO: stdout: "update-demo-nautilus-4kj8b update-demo-nautilus-9kx77 "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 12/09/23 12:34:35.599
  Dec  9 12:34:40.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:34:40.649: INFO: stderr: ""
  Dec  9 12:34:40.649: INFO: stdout: "update-demo-nautilus-4kj8b "
  Dec  9 12:34:40.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:40.697: INFO: stderr: ""
  Dec  9 12:34:40.697: INFO: stdout: "true"
  Dec  9 12:34:40.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:34:40.745: INFO: stderr: ""
  Dec  9 12:34:40.745: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:34:40.745: INFO: validating pod update-demo-nautilus-4kj8b
  Dec  9 12:34:40.748: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:34:40.748: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:34:40.748: INFO: update-demo-nautilus-4kj8b is verified up and running
  STEP: scaling up the replication controller @ 12/09/23 12:34:40.748
  Dec  9 12:34:40.749: INFO: scanned /root for discovery docs: <nil>
  Dec  9 12:34:40.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  Dec  9 12:34:41.813: INFO: stderr: ""
  Dec  9 12:34:41.813: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/09/23 12:34:41.813
  Dec  9 12:34:41.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:34:41.862: INFO: stderr: ""
  Dec  9 12:34:41.862: INFO: stdout: "update-demo-nautilus-4kj8b update-demo-nautilus-tvd6h "
  Dec  9 12:34:41.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:41.910: INFO: stderr: ""
  Dec  9 12:34:41.910: INFO: stdout: "true"
  Dec  9 12:34:41.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:34:41.961: INFO: stderr: ""
  Dec  9 12:34:41.961: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:34:41.961: INFO: validating pod update-demo-nautilus-4kj8b
  Dec  9 12:34:41.965: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:34:41.965: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:34:41.965: INFO: update-demo-nautilus-4kj8b is verified up and running
  Dec  9 12:34:41.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-tvd6h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:42.013: INFO: stderr: ""
  Dec  9 12:34:42.013: INFO: stdout: ""
  Dec  9 12:34:42.013: INFO: update-demo-nautilus-tvd6h is created but not running
  Dec  9 12:34:47.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:34:47.067: INFO: stderr: ""
  Dec  9 12:34:47.067: INFO: stdout: "update-demo-nautilus-4kj8b update-demo-nautilus-tvd6h "
  Dec  9 12:34:47.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:47.115: INFO: stderr: ""
  Dec  9 12:34:47.115: INFO: stdout: "true"
  Dec  9 12:34:47.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-4kj8b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:34:47.164: INFO: stderr: ""
  Dec  9 12:34:47.164: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:34:47.164: INFO: validating pod update-demo-nautilus-4kj8b
  Dec  9 12:34:47.168: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:34:47.168: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:34:47.168: INFO: update-demo-nautilus-4kj8b is verified up and running
  Dec  9 12:34:47.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-tvd6h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:34:47.215: INFO: stderr: ""
  Dec  9 12:34:47.215: INFO: stdout: "true"
  Dec  9 12:34:47.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods update-demo-nautilus-tvd6h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:34:47.264: INFO: stderr: ""
  Dec  9 12:34:47.264: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:34:47.264: INFO: validating pod update-demo-nautilus-tvd6h
  Dec  9 12:34:47.269: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:34:47.269: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:34:47.269: INFO: update-demo-nautilus-tvd6h is verified up and running
  STEP: using delete to clean up resources @ 12/09/23 12:34:47.269
  Dec  9 12:34:47.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 delete --grace-period=0 --force -f -'
  Dec  9 12:34:47.320: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:34:47.320: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec  9 12:34:47.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get rc,svc -l name=update-demo --no-headers'
  Dec  9 12:34:47.406: INFO: stderr: "No resources found in kubectl-4446 namespace.\n"
  Dec  9 12:34:47.406: INFO: stdout: ""
  Dec  9 12:34:47.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4446 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec  9 12:34:47.515: INFO: stderr: ""
  Dec  9 12:34:47.515: INFO: stdout: ""
  Dec  9 12:34:47.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4446" for this suite. @ 12/09/23 12:34:47.519
• [18.643 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 12/09/23 12:34:47.525
  Dec  9 12:34:47.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename cronjob @ 12/09/23 12:34:47.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:34:47.545
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:34:47.548
  STEP: Creating a suspended cronjob @ 12/09/23 12:34:47.55
  STEP: Ensuring no jobs are scheduled @ 12/09/23 12:34:47.554
  STEP: Ensuring no job exists by listing jobs explicitly @ 12/09/23 12:39:47.562
  STEP: Removing cronjob @ 12/09/23 12:39:47.565
  Dec  9 12:39:47.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9056" for this suite. @ 12/09/23 12:39:47.575
• [300.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 12/09/23 12:39:47.581
  Dec  9 12:39:47.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename namespaces @ 12/09/23 12:39:47.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:39:47.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:39:47.604
  STEP: Updating Namespace "namespaces-3886" @ 12/09/23 12:39:47.606
  Dec  9 12:39:47.615: INFO: Namespace "namespaces-3886" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"52bbc029-43ee-4e5f-9bdb-3340e795d598", "kubernetes.io/metadata.name":"namespaces-3886", "namespaces-3886":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Dec  9 12:39:47.615: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3886" for this suite. @ 12/09/23 12:39:47.619
• [0.043 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 12/09/23 12:39:47.625
  Dec  9 12:39:47.625: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename subpath @ 12/09/23 12:39:47.625
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:39:47.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:39:47.643
  STEP: Setting up data @ 12/09/23 12:39:47.645
  STEP: Creating pod pod-subpath-test-configmap-nlvf @ 12/09/23 12:39:47.654
  STEP: Creating a pod to test atomic-volume-subpath @ 12/09/23 12:39:47.654
  STEP: Saw pod success @ 12/09/23 12:40:11.722
  Dec  9 12:40:11.724: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-subpath-test-configmap-nlvf container test-container-subpath-configmap-nlvf: <nil>
  STEP: delete the pod @ 12/09/23 12:40:11.744
  STEP: Deleting pod pod-subpath-test-configmap-nlvf @ 12/09/23 12:40:11.76
  Dec  9 12:40:11.760: INFO: Deleting pod "pod-subpath-test-configmap-nlvf" in namespace "subpath-4962"
  Dec  9 12:40:11.763: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-4962" for this suite. @ 12/09/23 12:40:11.767
• [24.148 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 12/09/23 12:40:11.773
  Dec  9 12:40:11.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replication-controller @ 12/09/23 12:40:11.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:11.795
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:11.797
  STEP: Creating replication controller my-hostname-basic-60d35444-7481-43b1-b472-5d320e2c9f32 @ 12/09/23 12:40:11.799
  Dec  9 12:40:11.808: INFO: Pod name my-hostname-basic-60d35444-7481-43b1-b472-5d320e2c9f32: Found 0 pods out of 1
  Dec  9 12:40:16.814: INFO: Pod name my-hostname-basic-60d35444-7481-43b1-b472-5d320e2c9f32: Found 1 pods out of 1
  Dec  9 12:40:16.814: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-60d35444-7481-43b1-b472-5d320e2c9f32" are running
  Dec  9 12:40:16.817: INFO: Pod "my-hostname-basic-60d35444-7481-43b1-b472-5d320e2c9f32-4dxt5" is running and ready(conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:40:11 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:40:12 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:40:12 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-09 12:40:11 +0000 UTC Reason: Message:}])
  Dec  9 12:40:16.817: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/09/23 12:40:16.817
  Dec  9 12:40:16.829: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8268" for this suite. @ 12/09/23 12:40:16.832
• [5.066 seconds]
------------------------------
S
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 12/09/23 12:40:16.84
  Dec  9 12:40:16.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 12:40:16.841
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:16.856
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:16.858
  Dec  9 12:40:16.860: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Dec  9 12:40:16.868: INFO: Pod name sample-pod: Found 0 pods out of 1
  Dec  9 12:40:21.873: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/09/23 12:40:21.873
  Dec  9 12:40:21.874: INFO: Creating deployment "test-rolling-update-deployment"
  Dec  9 12:40:21.879: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Dec  9 12:40:21.888: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  Dec  9 12:40:23.898: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Dec  9 12:40:23.901: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Dec  9 12:40:23.910: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3514",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f6a455a5-1fdd-4429-902f-2cbbd412f8d5",
      ResourceVersion: (string) (len=5) "11633",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837722421,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=82) "ReplicaSet \"test-rolling-update-deployment-7f5c55c64\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  9 12:40:23.914: INFO: New ReplicaSet "test-rolling-update-deployment-7f5c55c64" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3514",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7438e3ce-629b-4f1f-a4f0-d6cceb041bec",
      ResourceVersion: (string) (len=5) "11622",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837722421,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64",
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "f6a455a5-1fdd-4429-902f-2cbbd412f8d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 66 36 61 34 35 35  61 35 2d 31 66 64 64 2d  |\"f6a455a5-1fdd-|
              00000120  34 34 32 39 2d 39 30 32  66 2d 32 63 62 62 64 34  |4429-902f-2cbbd4|
              00000130  31 32 66 38 64 35 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |12f8d5\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 12:40:23.915: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Dec  9 12:40:23.916: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3514",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "5b26682b-c4bb-4a41-9ddd-a307c532980d",
      ResourceVersion: (string) (len=5) "11632",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837722416,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "f6a455a5-1fdd-4429-902f-2cbbd412f8d5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722416,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 66 36 61 34 35 35 61  |"uid\":\"f6a455a|
              000000b0  35 2d 31 66 64 64 2d 34  34 32 39 2d 39 30 32 66  |5-1fdd-4429-902f|
              000000c0  2d 32 63 62 62 64 34 31  32 66 38 64 35 5c 22 7d  |-2cbbd412f8d5\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 12:40:23.919: INFO: Pod "test-rolling-update-deployment-7f5c55c64-lpln2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=46) "test-rolling-update-deployment-7f5c55c64-lpln2",
      GenerateName: (string) (len=41) "test-rolling-update-deployment-7f5c55c64-",
      Namespace: (string) (len=15) "deployment-3514",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3bd4fc99-82ab-441e-9905-24dadef02dce",
      ResourceVersion: (string) (len=5) "11621",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837722421,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64",
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
          UID: (types.UID) (len=36) "7438e3ce-629b-4f1f-a4f0-d6cceb041bec",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 37 34  33 38 65 33 63 65 2d 36  |d\":\"7438e3ce-6|
              00000090  32 39 62 2d 34 66 31 66  2d 61 34 66 30 2d 64 36  |29b-4f1f-a4f0-d6|
              000000a0  63 63 65 62 30 34 31 62  65 63 5c 22 7d 22 3a 7b  |cceb041bec\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=522) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 30 31 2e 32 32 30 5c  |192.168.201.220\|
              000001e0  22 7d 22 3a 7b 22 2e 22  3a 7b 7d 2c 22 66 3a 69  |"}":{".":{},"f:i|
              000001f0  70 22 3a 7b 7d 7d 7d 2c  22 66 3a 73 74 61 72 74  |p":{}}},"f:start|
              00000200  54 69 6d 65 22 3a 7b 7d  7d 7d                    |Time":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2xshc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2xshc",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-38-129",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722423,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837722421,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.38.129",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=15) "192.168.201.220",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=15) "192.168.201.220"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837722421,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837722422,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://0f8e58018fef8657c083b645fea34e5708dd7feb6ce521d7619dab77a652fd18",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 12:40:23.921: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3514" for this suite. @ 12/09/23 12:40:23.925
• [7.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 12/09/23 12:40:23.932
  Dec  9 12:40:23.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 12:40:23.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:23.951
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:23.954
  STEP: Setting up server cert @ 12/09/23 12:40:23.975
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 12:40:24.208
  STEP: Deploying the webhook pod @ 12/09/23 12:40:24.216
  STEP: Wait for the deployment to be ready @ 12/09/23 12:40:24.226
  Dec  9 12:40:24.236: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 12:40:26.245
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 12:40:26.254
  Dec  9 12:40:27.254: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/09/23 12:40:27.261
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/09/23 12:40:27.276
  STEP: Creating a dummy validating-webhook-configuration object @ 12/09/23 12:40:27.29
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 12/09/23 12:40:27.298
  STEP: Creating a dummy mutating-webhook-configuration object @ 12/09/23 12:40:27.304
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 12/09/23 12:40:27.312
  Dec  9 12:40:27.318: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6514" for this suite. @ 12/09/23 12:40:27.368
  STEP: Destroying namespace "webhook-markers-3633" for this suite. @ 12/09/23 12:40:27.376
• [3.449 seconds]
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 12/09/23 12:40:27.381
  Dec  9 12:40:27.381: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/09/23 12:40:27.382
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:27.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:27.401
  STEP: creating @ 12/09/23 12:40:27.403
  STEP: getting @ 12/09/23 12:40:27.419
  STEP: listing in namespace @ 12/09/23 12:40:27.423
  STEP: patching @ 12/09/23 12:40:27.426
  STEP: deleting @ 12/09/23 12:40:27.441
  Dec  9 12:40:27.451: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-1727" for this suite. @ 12/09/23 12:40:27.455
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 12/09/23 12:40:27.463
  Dec  9 12:40:27.463: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename daemonsets @ 12/09/23 12:40:27.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:27.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:27.483
  Dec  9 12:40:27.504: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/09/23 12:40:27.51
  Dec  9 12:40:27.513: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:27.513: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:27.517: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:40:27.517: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  Dec  9 12:40:28.521: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:28.521: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:28.525: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:40:28.525: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  Dec  9 12:40:29.522: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:29.523: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:29.525: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 12:40:29.525: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 12/09/23 12:40:29.538
  STEP: Check that daemon pods images are updated. @ 12/09/23 12:40:29.546
  Dec  9 12:40:29.551: INFO: Wrong image for pod: daemon-set-5sjzv. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  9 12:40:29.551: INFO: Wrong image for pod: daemon-set-rdt2c. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  9 12:40:29.551: INFO: Wrong image for pod: daemon-set-t8njv. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  9 12:40:29.554: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:29.554: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:30.559: INFO: Pod daemon-set-k2ww6 is not available
  Dec  9 12:40:30.559: INFO: Wrong image for pod: daemon-set-rdt2c. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  9 12:40:30.559: INFO: Wrong image for pod: daemon-set-t8njv. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  9 12:40:30.563: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:30.563: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:31.557: INFO: Pod daemon-set-8jkrw is not available
  Dec  9 12:40:31.558: INFO: Wrong image for pod: daemon-set-rdt2c. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  9 12:40:31.561: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:31.561: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:32.558: INFO: Pod daemon-set-kqpdp is not available
  Dec  9 12:40:32.561: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:32.561: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 12/09/23 12:40:32.561
  Dec  9 12:40:32.565: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:32.565: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:32.568: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 12:40:32.568: INFO: Node ip-172-31-77-176 is running 0 daemon pod, expected 1
  Dec  9 12:40:33.573: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:33.573: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:33.576: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 12:40:33.576: INFO: Node ip-172-31-77-176 is running 0 daemon pod, expected 1
  Dec  9 12:40:34.572: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:34.572: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 12:40:34.576: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 12:40:34.576: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/09/23 12:40:34.591
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8864, will wait for the garbage collector to delete the pods @ 12/09/23 12:40:34.591
  Dec  9 12:40:34.651: INFO: Deleting DaemonSet.extensions daemon-set took: 6.880709ms
  Dec  9 12:40:34.752: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.72056ms
  Dec  9 12:40:35.756: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 12:40:35.756: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  9 12:40:35.759: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"11947"},"items":null}

  Dec  9 12:40:35.763: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"11947"},"items":null}

  Dec  9 12:40:35.776: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8864" for this suite. @ 12/09/23 12:40:35.779
• [8.321 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 12/09/23 12:40:35.784
  Dec  9 12:40:35.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename limitrange @ 12/09/23 12:40:35.785
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:35.803
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:35.807
  STEP: Creating LimitRange "e2e-limitrange-cmbqk" in namespace "limitrange-1994" @ 12/09/23 12:40:35.809
  STEP: Creating another limitRange in another namespace @ 12/09/23 12:40:35.814
  Dec  9 12:40:35.830: INFO: Namespace "e2e-limitrange-cmbqk-8935" created
  Dec  9 12:40:35.830: INFO: Creating LimitRange "e2e-limitrange-cmbqk" in namespace "e2e-limitrange-cmbqk-8935"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-cmbqk" @ 12/09/23 12:40:35.837
  Dec  9 12:40:35.840: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-cmbqk" in "limitrange-1994" namespace @ 12/09/23 12:40:35.84
  Dec  9 12:40:35.845: INFO: LimitRange "e2e-limitrange-cmbqk" has been patched
  STEP: Delete LimitRange "e2e-limitrange-cmbqk" by Collection with labelSelector: "e2e-limitrange-cmbqk=patched" @ 12/09/23 12:40:35.845
  STEP: Confirm that the limitRange "e2e-limitrange-cmbqk" has been deleted @ 12/09/23 12:40:35.853
  Dec  9 12:40:35.853: INFO: Requesting list of LimitRange to confirm quantity
  Dec  9 12:40:35.856: INFO: Found 0 LimitRange with label "e2e-limitrange-cmbqk=patched"
  Dec  9 12:40:35.856: INFO: LimitRange "e2e-limitrange-cmbqk" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-cmbqk" @ 12/09/23 12:40:35.856
  Dec  9 12:40:35.859: INFO: Found 1 limitRange
  Dec  9 12:40:35.859: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-1994" for this suite. @ 12/09/23 12:40:35.862
  STEP: Destroying namespace "e2e-limitrange-cmbqk-8935" for this suite. @ 12/09/23 12:40:35.87
• [0.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 12/09/23 12:40:35.877
  Dec  9 12:40:35.877: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 12:40:35.877
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:35.893
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:35.895
  Dec  9 12:40:35.897: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 12/09/23 12:40:37.229
  Dec  9 12:40:37.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 create -f -'
  Dec  9 12:40:37.513: INFO: stderr: ""
  Dec  9 12:40:37.513: INFO: stdout: "e2e-test-crd-publish-openapi-9654-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec  9 12:40:37.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 delete e2e-test-crd-publish-openapi-9654-crds test-foo'
  Dec  9 12:40:37.566: INFO: stderr: ""
  Dec  9 12:40:37.566: INFO: stdout: "e2e-test-crd-publish-openapi-9654-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Dec  9 12:40:37.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 apply -f -'
  Dec  9 12:40:37.682: INFO: stderr: ""
  Dec  9 12:40:37.682: INFO: stdout: "e2e-test-crd-publish-openapi-9654-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec  9 12:40:37.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 delete e2e-test-crd-publish-openapi-9654-crds test-foo'
  Dec  9 12:40:37.754: INFO: stderr: ""
  Dec  9 12:40:37.754: INFO: stdout: "e2e-test-crd-publish-openapi-9654-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 12/09/23 12:40:37.754
  Dec  9 12:40:37.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 create -f -'
  Dec  9 12:40:37.994: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 12/09/23 12:40:37.994
  Dec  9 12:40:37.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 create -f -'
  Dec  9 12:40:38.103: INFO: rc: 1
  Dec  9 12:40:38.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 apply -f -'
  Dec  9 12:40:38.215: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 12/09/23 12:40:38.215
  Dec  9 12:40:38.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 create -f -'
  Dec  9 12:40:38.322: INFO: rc: 1
  Dec  9 12:40:38.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 --namespace=crd-publish-openapi-3589 apply -f -'
  Dec  9 12:40:38.435: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 12/09/23 12:40:38.435
  Dec  9 12:40:38.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 explain e2e-test-crd-publish-openapi-9654-crds'
  Dec  9 12:40:38.538: INFO: stderr: ""
  Dec  9 12:40:38.538: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9654-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 12/09/23 12:40:38.539
  Dec  9 12:40:38.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 explain e2e-test-crd-publish-openapi-9654-crds.metadata'
  Dec  9 12:40:38.647: INFO: stderr: ""
  Dec  9 12:40:38.647: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9654-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Dec  9 12:40:38.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 explain e2e-test-crd-publish-openapi-9654-crds.spec'
  Dec  9 12:40:38.753: INFO: stderr: ""
  Dec  9 12:40:38.753: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9654-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Dec  9 12:40:38.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 explain e2e-test-crd-publish-openapi-9654-crds.spec.bars'
  Dec  9 12:40:38.860: INFO: stderr: ""
  Dec  9 12:40:38.860: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-9654-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 12/09/23 12:40:38.86
  Dec  9 12:40:38.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=crd-publish-openapi-3589 explain e2e-test-crd-publish-openapi-9654-crds.spec.bars2'
  Dec  9 12:40:38.967: INFO: rc: 1
  Dec  9 12:40:40.235: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3589" for this suite. @ 12/09/23 12:40:40.244
• [4.374 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 12/09/23 12:40:40.251
  Dec  9 12:40:40.251: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-watch @ 12/09/23 12:40:40.252
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:40:40.267
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:40:40.27
  Dec  9 12:40:40.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Creating first CR  @ 12/09/23 12:40:42.814
  Dec  9 12:40:42.820: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-09T12:40:42Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-09T12:40:42Z]] name:name1 resourceVersion:12068 uid:7ed0b99b-e594-4401-a716-cfff2f1e8eb3] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Creating second CR @ 12/09/23 12:40:52.822
  Dec  9 12:40:52.828: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-09T12:40:52Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-09T12:40:52Z]] name:name2 resourceVersion:12092 uid:3fac6cee-39fb-4123-9443-ad3204f40c84] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying first CR @ 12/09/23 12:41:02.83
  Dec  9 12:41:02.837: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-09T12:40:42Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-09T12:41:02Z]] name:name1 resourceVersion:12112 uid:7ed0b99b-e594-4401-a716-cfff2f1e8eb3] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Modifying second CR @ 12/09/23 12:41:12.838
  Dec  9 12:41:12.846: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-09T12:40:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-09T12:41:12Z]] name:name2 resourceVersion:12132 uid:3fac6cee-39fb-4123-9443-ad3204f40c84] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting first CR @ 12/09/23 12:41:22.846
  Dec  9 12:41:22.853: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-09T12:40:42Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-09T12:41:02Z]] name:name1 resourceVersion:12151 uid:7ed0b99b-e594-4401-a716-cfff2f1e8eb3] num:map[num1:9223372036854775807 num2:1000000]]}
  STEP: Deleting second CR @ 12/09/23 12:41:32.856
  Dec  9 12:41:32.865: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-09T12:40:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-09T12:41:12Z]] name:name2 resourceVersion:12171 uid:3fac6cee-39fb-4123-9443-ad3204f40c84] num:map[num1:9223372036854775807 num2:1000000]]}
  Dec  9 12:41:43.383: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-3700" for this suite. @ 12/09/23 12:41:43.389
• [63.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 12/09/23 12:41:43.396
  Dec  9 12:41:43.396: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:41:43.397
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:41:43.41
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:41:43.413
  STEP: Creating projection with secret that has name projected-secret-test-map-398972d1-6256-4f48-9181-d52f19df3db9 @ 12/09/23 12:41:43.416
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:41:43.422
  STEP: Saw pod success @ 12/09/23 12:41:47.448
  Dec  9 12:41:47.452: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-secrets-956b1912-d348-40a8-9798-6a5a0e6d3297 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:41:47.468
  Dec  9 12:41:47.482: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5046" for this suite. @ 12/09/23 12:41:47.487
• [4.096 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 12/09/23 12:41:47.493
  Dec  9 12:41:47.493: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl-logs @ 12/09/23 12:41:47.493
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:41:47.511
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:41:47.515
  STEP: creating an pod @ 12/09/23 12:41:47.518
  Dec  9 12:41:47.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.45 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Dec  9 12:41:47.573: INFO: stderr: ""
  Dec  9 12:41:47.573: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 12/09/23 12:41:47.573
  Dec  9 12:41:47.573: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  Dec  9 12:41:49.582: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 12/09/23 12:41:49.582
  Dec  9 12:41:49.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 logs logs-generator logs-generator'
  Dec  9 12:41:49.637: INFO: stderr: ""
  Dec  9 12:41:49.637: INFO: stdout: "I1209 12:41:48.178997       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/l8q6 575\nI1209 12:41:48.379085       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/tz4 373\nI1209 12:41:48.579632       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/58h 437\nI1209 12:41:48.779920       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/w4s 510\nI1209 12:41:48.979084       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/jwtk 330\nI1209 12:41:49.179377       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/llmw 230\nI1209 12:41:49.379673       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/hvm 295\nI1209 12:41:49.579960       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/rf4 499\n"
  STEP: limiting log lines @ 12/09/23 12:41:49.637
  Dec  9 12:41:49.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 logs logs-generator logs-generator --tail=1'
  Dec  9 12:41:49.691: INFO: stderr: ""
  Dec  9 12:41:49.691: INFO: stdout: "I1209 12:41:49.579960       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/rf4 499\n"
  Dec  9 12:41:49.691: INFO: got output "I1209 12:41:49.579960       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/rf4 499\n"
  STEP: limiting log bytes @ 12/09/23 12:41:49.691
  Dec  9 12:41:49.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 logs logs-generator logs-generator --limit-bytes=1'
  Dec  9 12:41:49.747: INFO: stderr: ""
  Dec  9 12:41:49.747: INFO: stdout: "I"
  Dec  9 12:41:49.747: INFO: got output "I"
  STEP: exposing timestamps @ 12/09/23 12:41:49.747
  Dec  9 12:41:49.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 logs logs-generator logs-generator --tail=1 --timestamps'
  Dec  9 12:41:49.809: INFO: stderr: ""
  Dec  9 12:41:49.809: INFO: stdout: "2023-12-09T12:41:49.779265061Z I1209 12:41:49.779190       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/24v4 443\n"
  Dec  9 12:41:49.809: INFO: got output "2023-12-09T12:41:49.779265061Z I1209 12:41:49.779190       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/24v4 443\n"
  STEP: restricting to a time range @ 12/09/23 12:41:49.809
  Dec  9 12:41:52.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 logs logs-generator logs-generator --since=1s'
  Dec  9 12:41:52.365: INFO: stderr: ""
  Dec  9 12:41:52.365: INFO: stdout: "I1209 12:41:51.379326       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/gjtc 290\nI1209 12:41:51.579615       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/n7r 391\nI1209 12:41:51.779903       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/wn4 466\nI1209 12:41:51.979132       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/7vfg 246\nI1209 12:41:52.179423       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/22w 540\n"
  Dec  9 12:41:52.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 logs logs-generator logs-generator --since=24h'
  Dec  9 12:41:52.423: INFO: stderr: ""
  Dec  9 12:41:52.423: INFO: stdout: "I1209 12:41:48.178997       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/l8q6 575\nI1209 12:41:48.379085       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/tz4 373\nI1209 12:41:48.579632       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/58h 437\nI1209 12:41:48.779920       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/w4s 510\nI1209 12:41:48.979084       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/jwtk 330\nI1209 12:41:49.179377       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/llmw 230\nI1209 12:41:49.379673       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/hvm 295\nI1209 12:41:49.579960       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/rf4 499\nI1209 12:41:49.779190       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/24v4 443\nI1209 12:41:49.979477       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/vv6 336\nI1209 12:41:50.179767       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/4kf 345\nI1209 12:41:50.380056       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/vrx 369\nI1209 12:41:50.579342       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/rqh7 339\nI1209 12:41:50.779466       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/6gbv 265\nI1209 12:41:50.979754       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/ghh 275\nI1209 12:41:51.180040       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/prxq 404\nI1209 12:41:51.379326       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/gjtc 290\nI1209 12:41:51.579615       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/n7r 391\nI1209 12:41:51.779903       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/wn4 466\nI1209 12:41:51.979132       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/7vfg 246\nI1209 12:41:52.179423       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/22w 540\nI1209 12:41:52.379713       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/ks5l 295\n"
  Dec  9 12:41:52.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-logs-9886 delete pod logs-generator'
  Dec  9 12:41:53.118: INFO: stderr: ""
  Dec  9 12:41:53.118: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Dec  9 12:41:53.118: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-9886" for this suite. @ 12/09/23 12:41:53.124
• [5.639 seconds]
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 12/09/23 12:41:53.132
  Dec  9 12:41:53.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename gc @ 12/09/23 12:41:53.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:41:53.147
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:41:53.151
  STEP: create the rc @ 12/09/23 12:41:53.158
  W1209 12:41:53.162446      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 12/09/23 12:41:59.177
  STEP: wait for the rc to be deleted @ 12/09/23 12:41:59.185
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 12/09/23 12:42:04.191
  STEP: Gathering metrics @ 12/09/23 12:42:34.204
  W1209 12:42:34.210139      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  9 12:42:34.210: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  9 12:42:34.213: INFO: Deleting pod "simpletest.rc-2hw6j" in namespace "gc-3687"
  Dec  9 12:42:34.224: INFO: Deleting pod "simpletest.rc-2lqv9" in namespace "gc-3687"
  Dec  9 12:42:34.240: INFO: Deleting pod "simpletest.rc-4fhl8" in namespace "gc-3687"
  Dec  9 12:42:34.258: INFO: Deleting pod "simpletest.rc-4mkmg" in namespace "gc-3687"
  Dec  9 12:42:34.270: INFO: Deleting pod "simpletest.rc-4vlsq" in namespace "gc-3687"
  Dec  9 12:42:34.282: INFO: Deleting pod "simpletest.rc-4wd45" in namespace "gc-3687"
  Dec  9 12:42:34.297: INFO: Deleting pod "simpletest.rc-57ljg" in namespace "gc-3687"
  Dec  9 12:42:34.311: INFO: Deleting pod "simpletest.rc-5j6wg" in namespace "gc-3687"
  Dec  9 12:42:34.323: INFO: Deleting pod "simpletest.rc-5qjlm" in namespace "gc-3687"
  Dec  9 12:42:34.338: INFO: Deleting pod "simpletest.rc-5ttdd" in namespace "gc-3687"
  Dec  9 12:42:34.363: INFO: Deleting pod "simpletest.rc-5z6qx" in namespace "gc-3687"
  Dec  9 12:42:34.383: INFO: Deleting pod "simpletest.rc-7hj25" in namespace "gc-3687"
  Dec  9 12:42:34.399: INFO: Deleting pod "simpletest.rc-7rjrr" in namespace "gc-3687"
  Dec  9 12:42:34.413: INFO: Deleting pod "simpletest.rc-7s9dh" in namespace "gc-3687"
  Dec  9 12:42:34.426: INFO: Deleting pod "simpletest.rc-7vjb6" in namespace "gc-3687"
  Dec  9 12:42:34.442: INFO: Deleting pod "simpletest.rc-7vsrt" in namespace "gc-3687"
  Dec  9 12:42:34.455: INFO: Deleting pod "simpletest.rc-7xcvf" in namespace "gc-3687"
  Dec  9 12:42:34.472: INFO: Deleting pod "simpletest.rc-7z2wp" in namespace "gc-3687"
  Dec  9 12:42:34.500: INFO: Deleting pod "simpletest.rc-8dd89" in namespace "gc-3687"
  Dec  9 12:42:34.515: INFO: Deleting pod "simpletest.rc-8nk5x" in namespace "gc-3687"
  Dec  9 12:42:34.528: INFO: Deleting pod "simpletest.rc-8p97k" in namespace "gc-3687"
  Dec  9 12:42:34.541: INFO: Deleting pod "simpletest.rc-8qqm5" in namespace "gc-3687"
  Dec  9 12:42:34.556: INFO: Deleting pod "simpletest.rc-8rhs6" in namespace "gc-3687"
  Dec  9 12:42:34.570: INFO: Deleting pod "simpletest.rc-8wvjk" in namespace "gc-3687"
  Dec  9 12:42:34.582: INFO: Deleting pod "simpletest.rc-99p6l" in namespace "gc-3687"
  Dec  9 12:42:34.597: INFO: Deleting pod "simpletest.rc-9pgth" in namespace "gc-3687"
  Dec  9 12:42:34.616: INFO: Deleting pod "simpletest.rc-9phmh" in namespace "gc-3687"
  Dec  9 12:42:34.631: INFO: Deleting pod "simpletest.rc-9xft4" in namespace "gc-3687"
  Dec  9 12:42:34.647: INFO: Deleting pod "simpletest.rc-bnc8t" in namespace "gc-3687"
  Dec  9 12:42:34.657: INFO: Deleting pod "simpletest.rc-c2hbf" in namespace "gc-3687"
  Dec  9 12:42:34.670: INFO: Deleting pod "simpletest.rc-c2mks" in namespace "gc-3687"
  Dec  9 12:42:34.684: INFO: Deleting pod "simpletest.rc-c69kw" in namespace "gc-3687"
  Dec  9 12:42:34.698: INFO: Deleting pod "simpletest.rc-c6dcb" in namespace "gc-3687"
  Dec  9 12:42:34.714: INFO: Deleting pod "simpletest.rc-cdv2r" in namespace "gc-3687"
  Dec  9 12:42:34.727: INFO: Deleting pod "simpletest.rc-cfnpm" in namespace "gc-3687"
  Dec  9 12:42:34.742: INFO: Deleting pod "simpletest.rc-czgx5" in namespace "gc-3687"
  Dec  9 12:42:34.752: INFO: Deleting pod "simpletest.rc-d27mc" in namespace "gc-3687"
  Dec  9 12:42:34.764: INFO: Deleting pod "simpletest.rc-d4bmg" in namespace "gc-3687"
  Dec  9 12:42:34.777: INFO: Deleting pod "simpletest.rc-d9zp9" in namespace "gc-3687"
  Dec  9 12:42:34.823: INFO: Deleting pod "simpletest.rc-dhq6s" in namespace "gc-3687"
  Dec  9 12:42:34.839: INFO: Deleting pod "simpletest.rc-dmbdr" in namespace "gc-3687"
  Dec  9 12:42:34.860: INFO: Deleting pod "simpletest.rc-dn6gg" in namespace "gc-3687"
  Dec  9 12:42:34.873: INFO: Deleting pod "simpletest.rc-f578k" in namespace "gc-3687"
  Dec  9 12:42:34.886: INFO: Deleting pod "simpletest.rc-f75tt" in namespace "gc-3687"
  Dec  9 12:42:34.900: INFO: Deleting pod "simpletest.rc-fgf7p" in namespace "gc-3687"
  Dec  9 12:42:34.914: INFO: Deleting pod "simpletest.rc-fgz4c" in namespace "gc-3687"
  Dec  9 12:42:34.931: INFO: Deleting pod "simpletest.rc-frfbs" in namespace "gc-3687"
  Dec  9 12:42:34.952: INFO: Deleting pod "simpletest.rc-g5jf9" in namespace "gc-3687"
  Dec  9 12:42:34.966: INFO: Deleting pod "simpletest.rc-gvvcm" in namespace "gc-3687"
  Dec  9 12:42:34.978: INFO: Deleting pod "simpletest.rc-h8p45" in namespace "gc-3687"
  Dec  9 12:42:34.994: INFO: Deleting pod "simpletest.rc-hbmjh" in namespace "gc-3687"
  Dec  9 12:42:35.010: INFO: Deleting pod "simpletest.rc-hnw5v" in namespace "gc-3687"
  Dec  9 12:42:35.026: INFO: Deleting pod "simpletest.rc-hr4c7" in namespace "gc-3687"
  Dec  9 12:42:35.040: INFO: Deleting pod "simpletest.rc-hvztj" in namespace "gc-3687"
  Dec  9 12:42:35.058: INFO: Deleting pod "simpletest.rc-j2z48" in namespace "gc-3687"
  Dec  9 12:42:35.072: INFO: Deleting pod "simpletest.rc-j9lvc" in namespace "gc-3687"
  Dec  9 12:42:35.086: INFO: Deleting pod "simpletest.rc-jj8wt" in namespace "gc-3687"
  Dec  9 12:42:35.101: INFO: Deleting pod "simpletest.rc-k26wb" in namespace "gc-3687"
  Dec  9 12:42:35.116: INFO: Deleting pod "simpletest.rc-kkvsh" in namespace "gc-3687"
  Dec  9 12:42:35.130: INFO: Deleting pod "simpletest.rc-l6qpt" in namespace "gc-3687"
  Dec  9 12:42:35.144: INFO: Deleting pod "simpletest.rc-l9scv" in namespace "gc-3687"
  Dec  9 12:42:35.153: INFO: Deleting pod "simpletest.rc-lcpfm" in namespace "gc-3687"
  Dec  9 12:42:35.167: INFO: Deleting pod "simpletest.rc-lnq4j" in namespace "gc-3687"
  Dec  9 12:42:35.182: INFO: Deleting pod "simpletest.rc-m7mwp" in namespace "gc-3687"
  Dec  9 12:42:35.200: INFO: Deleting pod "simpletest.rc-mfc9w" in namespace "gc-3687"
  Dec  9 12:42:35.216: INFO: Deleting pod "simpletest.rc-nkdx7" in namespace "gc-3687"
  Dec  9 12:42:35.232: INFO: Deleting pod "simpletest.rc-nwqx5" in namespace "gc-3687"
  Dec  9 12:42:35.245: INFO: Deleting pod "simpletest.rc-p6n2t" in namespace "gc-3687"
  Dec  9 12:42:35.262: INFO: Deleting pod "simpletest.rc-pbv5d" in namespace "gc-3687"
  Dec  9 12:42:35.282: INFO: Deleting pod "simpletest.rc-pdmrr" in namespace "gc-3687"
  Dec  9 12:42:35.306: INFO: Deleting pod "simpletest.rc-pktnl" in namespace "gc-3687"
  Dec  9 12:42:35.359: INFO: Deleting pod "simpletest.rc-px5zm" in namespace "gc-3687"
  Dec  9 12:42:35.407: INFO: Deleting pod "simpletest.rc-qdck7" in namespace "gc-3687"
  Dec  9 12:42:35.456: INFO: Deleting pod "simpletest.rc-qfx29" in namespace "gc-3687"
  Dec  9 12:42:35.508: INFO: Deleting pod "simpletest.rc-qk725" in namespace "gc-3687"
  Dec  9 12:42:35.555: INFO: Deleting pod "simpletest.rc-qpj9n" in namespace "gc-3687"
  Dec  9 12:42:35.607: INFO: Deleting pod "simpletest.rc-r6qz8" in namespace "gc-3687"
  Dec  9 12:42:35.661: INFO: Deleting pod "simpletest.rc-r9jmh" in namespace "gc-3687"
  Dec  9 12:42:35.704: INFO: Deleting pod "simpletest.rc-rbv8t" in namespace "gc-3687"
  Dec  9 12:42:35.755: INFO: Deleting pod "simpletest.rc-rcc5v" in namespace "gc-3687"
  Dec  9 12:42:35.813: INFO: Deleting pod "simpletest.rc-rr6jf" in namespace "gc-3687"
  Dec  9 12:42:35.857: INFO: Deleting pod "simpletest.rc-s5d64" in namespace "gc-3687"
  Dec  9 12:42:35.908: INFO: Deleting pod "simpletest.rc-sglqs" in namespace "gc-3687"
  Dec  9 12:42:35.955: INFO: Deleting pod "simpletest.rc-ssjvq" in namespace "gc-3687"
  Dec  9 12:42:36.003: INFO: Deleting pod "simpletest.rc-tbnpq" in namespace "gc-3687"
  Dec  9 12:42:36.055: INFO: Deleting pod "simpletest.rc-ttw5c" in namespace "gc-3687"
  Dec  9 12:42:36.107: INFO: Deleting pod "simpletest.rc-tvgrw" in namespace "gc-3687"
  Dec  9 12:42:36.155: INFO: Deleting pod "simpletest.rc-vc4v7" in namespace "gc-3687"
  Dec  9 12:42:36.223: INFO: Deleting pod "simpletest.rc-vm2vq" in namespace "gc-3687"
  Dec  9 12:42:36.266: INFO: Deleting pod "simpletest.rc-vrp2j" in namespace "gc-3687"
  Dec  9 12:42:36.310: INFO: Deleting pod "simpletest.rc-wls9l" in namespace "gc-3687"
  Dec  9 12:42:36.361: INFO: Deleting pod "simpletest.rc-wnnjc" in namespace "gc-3687"
  Dec  9 12:42:36.408: INFO: Deleting pod "simpletest.rc-wp29f" in namespace "gc-3687"
  Dec  9 12:42:36.457: INFO: Deleting pod "simpletest.rc-xpjgp" in namespace "gc-3687"
  Dec  9 12:42:36.510: INFO: Deleting pod "simpletest.rc-xptll" in namespace "gc-3687"
  Dec  9 12:42:36.561: INFO: Deleting pod "simpletest.rc-xx8kh" in namespace "gc-3687"
  Dec  9 12:42:36.607: INFO: Deleting pod "simpletest.rc-z89pk" in namespace "gc-3687"
  Dec  9 12:42:36.656: INFO: Deleting pod "simpletest.rc-z9zbx" in namespace "gc-3687"
  Dec  9 12:42:36.730: INFO: Deleting pod "simpletest.rc-zgnbk" in namespace "gc-3687"
  Dec  9 12:42:36.755: INFO: Deleting pod "simpletest.rc-zz4pm" in namespace "gc-3687"
  Dec  9 12:42:36.805: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3687" for this suite. @ 12/09/23 12:42:36.869
• [43.767 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 12/09/23 12:42:36.899
  Dec  9 12:42:36.899: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:42:36.9
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:42:36.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:42:36.922
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:42:36.926
  STEP: Saw pod success @ 12/09/23 12:42:42.961
  Dec  9 12:42:42.964: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-097621dd-aa7a-4309-8b1e-9d2e93b26615 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:42:42.972
  Dec  9 12:42:42.993: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8849" for this suite. @ 12/09/23 12:42:42.999
• [6.107 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 12/09/23 12:42:43.008
  Dec  9 12:42:43.008: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 12:42:43.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:42:43.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:42:43.03
  STEP: Creating secret with name secret-test-8867e2fa-36e6-4353-8759-29e5ae310a08 @ 12/09/23 12:42:43.034
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:42:43.038
  STEP: Saw pod success @ 12/09/23 12:42:47.059
  Dec  9 12:42:47.062: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-secrets-6c2c50a1-6991-44a4-b959-b016b1783117 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:42:47.07
  Dec  9 12:42:47.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2227" for this suite. @ 12/09/23 12:42:47.092
• [4.092 seconds]
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 12/09/23 12:42:47.099
  Dec  9 12:42:47.099: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-preemption @ 12/09/23 12:42:47.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:42:47.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:42:47.123
  Dec  9 12:42:47.140: INFO: Waiting up to 1m0s for all nodes to be ready
  Dec  9 12:43:47.161: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/09/23 12:43:47.165
  Dec  9 12:43:47.165: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/09/23 12:43:47.165
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:43:47.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:43:47.186
  STEP: Finding an available node @ 12/09/23 12:43:47.191
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/09/23 12:43:47.191
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/09/23 12:43:49.211
  Dec  9 12:43:49.223: INFO: found a healthy node: ip-172-31-77-176
  Dec  9 12:43:55.306: INFO: pods created so far: [1 1 1]
  Dec  9 12:43:55.306: INFO: length of pods created so far: 3
  Dec  9 12:43:57.317: INFO: pods created so far: [2 2 1]
  Dec  9 12:44:04.317: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:44:04.354: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-8807" for this suite. @ 12/09/23 12:44:04.393
  STEP: Destroying namespace "sched-preemption-7207" for this suite. @ 12/09/23 12:44:04.399
• [77.308 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 12/09/23 12:44:04.407
  Dec  9 12:44:04.407: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename security-context @ 12/09/23 12:44:04.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:44:04.424
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:44:04.429
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/09/23 12:44:04.432
  STEP: Saw pod success @ 12/09/23 12:44:08.459
  Dec  9 12:44:08.462: INFO: Trying to get logs from node ip-172-31-38-129 pod security-context-12e39390-a6d6-42e8-8384-101321a5db7b container test-container: <nil>
  STEP: delete the pod @ 12/09/23 12:44:08.485
  Dec  9 12:44:08.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-1323" for this suite. @ 12/09/23 12:44:08.507
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 12/09/23 12:44:08.516
  Dec  9 12:44:08.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename cronjob @ 12/09/23 12:44:08.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:44:08.531
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:44:08.535
  STEP: Creating a ForbidConcurrent cronjob @ 12/09/23 12:44:08.539
  STEP: Ensuring a job is scheduled @ 12/09/23 12:44:08.544
  STEP: Ensuring exactly one is scheduled @ 12/09/23 12:45:00.551
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/09/23 12:45:00.556
  STEP: Ensuring no more jobs are scheduled @ 12/09/23 12:45:00.559
  STEP: Removing cronjob @ 12/09/23 12:50:00.567
  Dec  9 12:50:00.574: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4104" for this suite. @ 12/09/23 12:50:00.579
• [352.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 12/09/23 12:50:00.587
  Dec  9 12:50:00.587: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 12:50:00.588
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:00.617
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:00.62
  STEP: creating a Deployment @ 12/09/23 12:50:00.628
  STEP: waiting for Deployment to be created @ 12/09/23 12:50:00.633
  STEP: waiting for all Replicas to be Ready @ 12/09/23 12:50:00.635
  Dec  9 12:50:00.637: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:00.637: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:00.653: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:00.653: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:00.669: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:00.669: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:00.700: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:00.700: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  9 12:50:01.457: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec  9 12:50:01.457: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec  9 12:50:02.044: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 12/09/23 12:50:02.044
  Dec  9 12:50:02.054: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 12/09/23 12:50:02.054
  Dec  9 12:50:02.056: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.056: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.056: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.056: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.056: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.056: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 0
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.057: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.060: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.060: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.077: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.077: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:02.112: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:02.112: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:03.059: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:03.059: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:03.078: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  STEP: listing Deployments @ 12/09/23 12:50:03.079
  Dec  9 12:50:03.084: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 12/09/23 12:50:03.084
  Dec  9 12:50:03.093: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 12/09/23 12:50:03.094
  Dec  9 12:50:03.102: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:03.106: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:03.120: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:03.137: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:03.147: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:03.155: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:04.070: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:04.087: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:04.093: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:04.105: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:04.118: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  9 12:50:05.474: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 12/09/23 12:50:05.545
  STEP: fetching the DeploymentStatus @ 12/09/23 12:50:05.555
  Dec  9 12:50:05.569: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:05.569: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:05.569: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 1
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 2
  Dec  9 12:50:05.570: INFO: observed Deployment test-deployment in namespace deployment-4259 with ReadyReplicas 3
  STEP: deleting the Deployment @ 12/09/23 12:50:05.57
  Dec  9 12:50:05.582: INFO: observed event type MODIFIED
  Dec  9 12:50:05.582: INFO: observed event type MODIFIED
  Dec  9 12:50:05.582: INFO: observed event type MODIFIED
  Dec  9 12:50:05.582: INFO: observed event type MODIFIED
  Dec  9 12:50:05.582: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.583: INFO: observed event type MODIFIED
  Dec  9 12:50:05.589: INFO: Log out all the ReplicaSets if there is no deployment created
  Dec  9 12:50:05.596: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4259" for this suite. @ 12/09/23 12:50:05.604
• [5.025 seconds]
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 12/09/23 12:50:05.613
  Dec  9 12:50:05.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename init-container @ 12/09/23 12:50:05.614
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:05.631
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:05.635
  STEP: creating the pod @ 12/09/23 12:50:05.639
  Dec  9 12:50:05.639: INFO: PodSpec: initContainers in spec.initContainers
  Dec  9 12:50:08.661: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9862" for this suite. @ 12/09/23 12:50:08.666
• [3.059 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 12/09/23 12:50:08.673
  Dec  9 12:50:08.673: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 12:50:08.673
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:08.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:08.692
  STEP: Saw pod success @ 12/09/23 12:50:14.759
  Dec  9 12:50:14.763: INFO: Trying to get logs from node ip-172-31-77-176 pod client-envvars-1a4ea995-93ab-49ab-8da1-69fe894dfa08 container env3cont: <nil>
  STEP: delete the pod @ 12/09/23 12:50:14.78
  Dec  9 12:50:14.797: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8230" for this suite. @ 12/09/23 12:50:14.801
• [6.134 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 12/09/23 12:50:14.807
  Dec  9 12:50:14.807: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:50:14.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:14.822
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:14.826
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6533 @ 12/09/23 12:50:14.83
  STEP: changing the ExternalName service to type=NodePort @ 12/09/23 12:50:14.838
  STEP: creating replication controller externalname-service in namespace services-6533 @ 12/09/23 12:50:14.855
  I1209 12:50:14.865953      18 runners.go:197] Created replication controller with name: externalname-service, namespace: services-6533, replica count: 2
  I1209 12:50:17.916440      18 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 12:50:17.916: INFO: Creating new exec pod
  Dec  9 12:50:20.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-6533 exec execpodr4zjm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec  9 12:50:21.055: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec  9 12:50:21.055: INFO: stdout: ""
  Dec  9 12:50:22.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-6533 exec execpodr4zjm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec  9 12:50:22.156: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec  9 12:50:22.156: INFO: stdout: "externalname-service-bslqj"
  Dec  9 12:50:22.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-6533 exec execpodr4zjm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.114 80'
  Dec  9 12:50:22.259: INFO: stderr: "+ + ncecho hostName -v\n -t -w 2 10.152.183.114 80\nConnection to 10.152.183.114 80 port [tcp/http] succeeded!\n"
  Dec  9 12:50:22.259: INFO: stdout: "externalname-service-bslqj"
  Dec  9 12:50:22.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-6533 exec execpodr4zjm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.77.176 30360'
  Dec  9 12:50:22.375: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.77.176 30360\nConnection to 172.31.77.176 30360 port [tcp/*] succeeded!\n"
  Dec  9 12:50:22.375: INFO: stdout: "externalname-service-bslqj"
  Dec  9 12:50:22.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-6533 exec execpodr4zjm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.129 30360'
  Dec  9 12:50:22.479: INFO: stderr: "+ nc -v -t -w 2 172.31.38.129 30360\n+ echo hostName\nConnection to 172.31.38.129 30360 port [tcp/*] succeeded!\n"
  Dec  9 12:50:22.479: INFO: stdout: "externalname-service-bslqj"
  Dec  9 12:50:22.479: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:50:22.483: INFO: Cleaning up the ExternalName to NodePort test service
  STEP: Destroying namespace "services-6533" for this suite. @ 12/09/23 12:50:22.508
• [7.707 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 12/09/23 12:50:22.514
  Dec  9 12:50:22.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 12:50:22.515
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:22.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:22.533
  STEP: creating a secret @ 12/09/23 12:50:22.536
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 12/09/23 12:50:22.545
  STEP: patching the secret @ 12/09/23 12:50:22.549
  STEP: deleting the secret using a LabelSelector @ 12/09/23 12:50:22.557
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 12/09/23 12:50:22.564
  Dec  9 12:50:22.569: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3644" for this suite. @ 12/09/23 12:50:22.573
• [0.065 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 12/09/23 12:50:22.58
  Dec  9 12:50:22.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 12:50:22.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:22.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:22.599
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 12:50:22.604
  STEP: Saw pod success @ 12/09/23 12:50:26.628
  Dec  9 12:50:26.631: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-28a0429e-962c-4e72-b36a-9a15f9375df8 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 12:50:26.638
  Dec  9 12:50:26.656: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6759" for this suite. @ 12/09/23 12:50:26.66
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 12/09/23 12:50:26.668
  Dec  9 12:50:26.668: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 12:50:26.669
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:26.686
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:26.689
  STEP: Creating a test externalName service @ 12/09/23 12:50:26.693
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6371.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6371.svc.cluster.local; sleep 1; done
   @ 12/09/23 12:50:26.699
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6371.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6371.svc.cluster.local; sleep 1; done
   @ 12/09/23 12:50:26.699
  STEP: creating a pod to probe DNS @ 12/09/23 12:50:26.699
  STEP: submitting the pod to kubernetes @ 12/09/23 12:50:26.699
  STEP: retrieving the pod @ 12/09/23 12:50:28.719
  STEP: looking for the results for each expected name from probers @ 12/09/23 12:50:28.722
  Dec  9 12:50:28.732: INFO: DNS probes using dns-test-723c93e5-858d-4f7e-89c7-af48cd09fb58 succeeded

  STEP: changing the externalName to bar.example.com @ 12/09/23 12:50:28.732
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6371.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6371.svc.cluster.local; sleep 1; done
   @ 12/09/23 12:50:28.741
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6371.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6371.svc.cluster.local; sleep 1; done
   @ 12/09/23 12:50:28.741
  STEP: creating a second pod to probe DNS @ 12/09/23 12:50:28.741
  STEP: submitting the pod to kubernetes @ 12/09/23 12:50:28.741
  STEP: retrieving the pod @ 12/09/23 12:50:34.77
  STEP: looking for the results for each expected name from probers @ 12/09/23 12:50:34.774
  Dec  9 12:50:34.784: INFO: DNS probes using dns-test-59d29522-2982-4568-9d78-5a0e76a66059 succeeded

  STEP: changing the service to type=ClusterIP @ 12/09/23 12:50:34.784
  W1209 12:50:34.797628      18 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6371.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6371.svc.cluster.local; sleep 1; done
   @ 12/09/23 12:50:34.797
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6371.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6371.svc.cluster.local; sleep 1; done
   @ 12/09/23 12:50:34.797
  STEP: creating a third pod to probe DNS @ 12/09/23 12:50:34.797
  STEP: submitting the pod to kubernetes @ 12/09/23 12:50:34.803
  STEP: retrieving the pod @ 12/09/23 12:50:36.827
  STEP: looking for the results for each expected name from probers @ 12/09/23 12:50:36.832
  Dec  9 12:50:36.840: INFO: DNS probes using dns-test-9d4e3c14-f96e-4978-89e5-d79971f0a0e5 succeeded

  Dec  9 12:50:36.840: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 12:50:36.845
  STEP: deleting the pod @ 12/09/23 12:50:36.86
  STEP: deleting the pod @ 12/09/23 12:50:36.874
  STEP: deleting the test externalName service @ 12/09/23 12:50:36.889
  STEP: Destroying namespace "dns-6371" for this suite. @ 12/09/23 12:50:36.903
• [10.243 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 12/09/23 12:50:36.911
  Dec  9 12:50:36.911: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 12:50:36.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:36.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:36.932
  STEP: Creating configMap with name configmap-test-volume-6984f5bd-cba9-4474-887c-02f7f82f9af0 @ 12/09/23 12:50:36.98
  STEP: Creating a pod to test consume configMaps @ 12/09/23 12:50:36.984
  STEP: Saw pod success @ 12/09/23 12:50:41.004
  Dec  9 12:50:41.009: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-configmaps-0ae55fa1-801f-409b-a9bc-db3accc8da23 container configmap-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:50:41.016
  Dec  9 12:50:41.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5949" for this suite. @ 12/09/23 12:50:41.035
• [4.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 12/09/23 12:50:41.043
  Dec  9 12:50:41.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename runtimeclass @ 12/09/23 12:50:41.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:41.063
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:41.067
  Dec  9 12:50:41.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-7872" for this suite. @ 12/09/23 12:50:41.101
• [0.067 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 12/09/23 12:50:41.111
  Dec  9 12:50:41.111: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 12:50:41.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:50:41.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:50:41.13
  STEP: Creating pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112 @ 12/09/23 12:50:41.135
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 12:50:43.155
  Dec  9 12:50:43.159: INFO: Initial restart count of pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 is 0
  Dec  9 12:50:43.163: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:45.167: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:47.171: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:49.176: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:51.181: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:53.185: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:55.191: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:57.194: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:50:59.199: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:51:01.204: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:51:03.210: INFO: Get pod liveness-e168e187-a93f-49b1-85eb-778d1e830e45 in namespace container-probe-5112
  Dec  9 12:51:03.210: INFO: Restart count of pod container-probe-5112/liveness-e168e187-a93f-49b1-85eb-778d1e830e45 is now 1 (20.050796117s elapsed)
  Dec  9 12:51:03.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 12:51:03.214
  STEP: Destroying namespace "container-probe-5112" for this suite. @ 12/09/23 12:51:03.228
• [22.125 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 12/09/23 12:51:03.237
  Dec  9 12:51:03.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 12:51:03.238
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:03.258
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:03.262
  Dec  9 12:51:03.307: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6072" for this suite. @ 12/09/23 12:51:03.312
• [0.082 seconds]
------------------------------
S
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 12/09/23 12:51:03.319
  Dec  9 12:51:03.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename disruption @ 12/09/23 12:51:03.32
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:03.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:03.339
  STEP: Waiting for the pdb to be processed @ 12/09/23 12:51:03.347
  STEP: Waiting for all pods to be running @ 12/09/23 12:51:05.38
  Dec  9 12:51:05.397: INFO: running pods: 0 < 3
  Dec  9 12:51:07.401: INFO: running pods: 2 < 3
  Dec  9 12:51:09.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5655" for this suite. @ 12/09/23 12:51:09.411
• [6.099 seconds]
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 12/09/23 12:51:09.419
  Dec  9 12:51:09.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename ingress @ 12/09/23 12:51:09.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:09.435
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:09.439
  STEP: getting /apis @ 12/09/23 12:51:09.447
  STEP: getting /apis/networking.k8s.io @ 12/09/23 12:51:09.451
  STEP: getting /apis/networking.k8s.iov1 @ 12/09/23 12:51:09.453
  STEP: creating @ 12/09/23 12:51:09.454
  STEP: getting @ 12/09/23 12:51:09.472
  STEP: listing @ 12/09/23 12:51:09.476
  STEP: watching @ 12/09/23 12:51:09.481
  Dec  9 12:51:09.481: INFO: starting watch
  STEP: cluster-wide listing @ 12/09/23 12:51:09.483
  STEP: cluster-wide watching @ 12/09/23 12:51:09.487
  Dec  9 12:51:09.487: INFO: starting watch
  STEP: patching @ 12/09/23 12:51:09.489
  STEP: updating @ 12/09/23 12:51:09.495
  Dec  9 12:51:09.511: INFO: waiting for watch events with expected annotations
  Dec  9 12:51:09.511: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/09/23 12:51:09.511
  STEP: updating /status @ 12/09/23 12:51:09.519
  STEP: get /status @ 12/09/23 12:51:09.53
  STEP: deleting @ 12/09/23 12:51:09.536
  STEP: deleting a collection @ 12/09/23 12:51:09.558
  Dec  9 12:51:09.578: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-8536" for this suite. @ 12/09/23 12:51:09.585
• [0.176 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:961
  STEP: Creating a kubernetes client @ 12/09/23 12:51:09.596
  Dec  9 12:51:09.596: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 12:51:09.597
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:09.613
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:09.617
  STEP: Creating service test in namespace statefulset-8721 @ 12/09/23 12:51:09.62
  Dec  9 12:51:09.637: INFO: Found 0 stateful pods, waiting for 1
  Dec  9 12:51:19.642: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 12/09/23 12:51:19.65
  W1209 12:51:19.659682      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  Dec  9 12:51:19.672: INFO: Found 1 stateful pods, waiting for 2
  Dec  9 12:51:29.677: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 12:51:29.677: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 12/09/23 12:51:29.686
  STEP: Delete all of the StatefulSets @ 12/09/23 12:51:29.689
  STEP: Verify that StatefulSets have been deleted @ 12/09/23 12:51:29.697
  Dec  9 12:51:29.701: INFO: Deleting all statefulset in ns statefulset-8721
  Dec  9 12:51:29.719: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8721" for this suite. @ 12/09/23 12:51:29.725
• [20.142 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 12/09/23 12:51:29.739
  Dec  9 12:51:29.740: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 12:51:29.741
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:29.756
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:29.76
  STEP: Creating a pod to test downward api env vars @ 12/09/23 12:51:29.763
  STEP: Saw pod success @ 12/09/23 12:51:33.788
  Dec  9 12:51:33.791: INFO: Trying to get logs from node ip-172-31-77-176 pod downward-api-58829d10-0d4f-43a5-9ae5-98a4af861ae8 container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 12:51:33.8
  Dec  9 12:51:33.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3563" for this suite. @ 12/09/23 12:51:33.823
• [4.090 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 12/09/23 12:51:33.83
  Dec  9 12:51:33.830: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 12:51:33.831
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:33.844
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:33.849
  STEP: Counting existing ResourceQuota @ 12/09/23 12:51:33.853
  STEP: Creating a ResourceQuota @ 12/09/23 12:51:38.862
  STEP: Ensuring resource quota status is calculated @ 12/09/23 12:51:38.87
  STEP: Creating a Service @ 12/09/23 12:51:40.878
  STEP: Creating a NodePort Service @ 12/09/23 12:51:40.904
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 12/09/23 12:51:40.933
  STEP: Ensuring resource quota status captures service creation @ 12/09/23 12:51:40.957
  STEP: Deleting Services @ 12/09/23 12:51:42.962
  STEP: Ensuring resource quota status released usage @ 12/09/23 12:51:43.008
  Dec  9 12:51:45.013: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6011" for this suite. @ 12/09/23 12:51:45.017
• [11.199 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 12/09/23 12:51:45.03
  Dec  9 12:51:45.030: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 12:51:45.031
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:45.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:45.055
  STEP: creating a replication controller @ 12/09/23 12:51:45.069
  Dec  9 12:51:45.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 create -f -'
  Dec  9 12:51:45.237: INFO: stderr: ""
  Dec  9 12:51:45.237: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/09/23 12:51:45.237
  Dec  9 12:51:45.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:51:45.289: INFO: stderr: ""
  Dec  9 12:51:45.289: INFO: stdout: "update-demo-nautilus-8bt9w update-demo-nautilus-pnkm4 "
  Dec  9 12:51:45.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods update-demo-nautilus-8bt9w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:51:45.338: INFO: stderr: ""
  Dec  9 12:51:45.338: INFO: stdout: ""
  Dec  9 12:51:45.338: INFO: update-demo-nautilus-8bt9w is created but not running
  Dec  9 12:51:50.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  9 12:51:50.388: INFO: stderr: ""
  Dec  9 12:51:50.388: INFO: stdout: "update-demo-nautilus-8bt9w update-demo-nautilus-pnkm4 "
  Dec  9 12:51:50.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods update-demo-nautilus-8bt9w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:51:50.436: INFO: stderr: ""
  Dec  9 12:51:50.436: INFO: stdout: "true"
  Dec  9 12:51:50.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods update-demo-nautilus-8bt9w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:51:50.483: INFO: stderr: ""
  Dec  9 12:51:50.483: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:51:50.483: INFO: validating pod update-demo-nautilus-8bt9w
  Dec  9 12:51:50.490: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:51:50.490: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:51:50.490: INFO: update-demo-nautilus-8bt9w is verified up and running
  Dec  9 12:51:50.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods update-demo-nautilus-pnkm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  9 12:51:50.538: INFO: stderr: ""
  Dec  9 12:51:50.538: INFO: stdout: "true"
  Dec  9 12:51:50.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods update-demo-nautilus-pnkm4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  9 12:51:50.588: INFO: stderr: ""
  Dec  9 12:51:50.588: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  9 12:51:50.588: INFO: validating pod update-demo-nautilus-pnkm4
  Dec  9 12:51:50.593: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  9 12:51:50.593: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  9 12:51:50.593: INFO: update-demo-nautilus-pnkm4 is verified up and running
  STEP: using delete to clean up resources @ 12/09/23 12:51:50.593
  Dec  9 12:51:50.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 delete --grace-period=0 --force -f -'
  Dec  9 12:51:50.646: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 12:51:50.646: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec  9 12:51:50.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get rc,svc -l name=update-demo --no-headers'
  Dec  9 12:51:50.719: INFO: stderr: "No resources found in kubectl-2129 namespace.\n"
  Dec  9 12:51:50.719: INFO: stdout: ""
  Dec  9 12:51:50.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2129 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec  9 12:51:50.808: INFO: stderr: ""
  Dec  9 12:51:50.808: INFO: stdout: ""
  Dec  9 12:51:50.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2129" for this suite. @ 12/09/23 12:51:50.813
• [5.794 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 12/09/23 12:51:50.825
  Dec  9 12:51:50.825: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 12:51:50.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:50.846
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:50.855
  STEP: Creating a pod to test downward api env vars @ 12/09/23 12:51:50.861
  STEP: Saw pod success @ 12/09/23 12:51:54.886
  Dec  9 12:51:54.889: INFO: Trying to get logs from node ip-172-31-77-176 pod downward-api-f769a1fe-dcb9-4250-829d-f5b74f053aa7 container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 12:51:54.898
  Dec  9 12:51:54.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2441" for this suite. @ 12/09/23 12:51:54.917
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 12/09/23 12:51:54.925
  Dec  9 12:51:54.925: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replicaset @ 12/09/23 12:51:54.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:51:54.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:51:54.945
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 12/09/23 12:51:54.949
  Dec  9 12:51:54.958: INFO: Pod name sample-pod: Found 0 pods out of 1
  Dec  9 12:51:59.962: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/09/23 12:51:59.962
  STEP: getting scale subresource @ 12/09/23 12:51:59.962
  STEP: updating a scale subresource @ 12/09/23 12:51:59.965
  STEP: verifying the replicaset Spec.Replicas was modified @ 12/09/23 12:51:59.972
  STEP: Patch a scale subresource @ 12/09/23 12:51:59.978
  Dec  9 12:51:59.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-8942" for this suite. @ 12/09/23 12:52:00
• [5.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 12/09/23 12:52:00.013
  Dec  9 12:52:00.013: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubelet-test @ 12/09/23 12:52:00.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:52:00.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:52:00.039
  Dec  9 12:52:00.066: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-2376" for this suite. @ 12/09/23 12:52:00.072
• [0.066 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 12/09/23 12:52:00.079
  Dec  9 12:52:00.079: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 12:52:00.08
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:52:00.097
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:52:00.1
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6804.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-6804.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 12/09/23 12:52:00.104
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-6804.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-6804.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 12/09/23 12:52:00.104
  STEP: creating a pod to probe /etc/hosts @ 12/09/23 12:52:00.104
  STEP: submitting the pod to kubernetes @ 12/09/23 12:52:00.104
  STEP: retrieving the pod @ 12/09/23 12:52:02.126
  STEP: looking for the results for each expected name from probers @ 12/09/23 12:52:02.129
  Dec  9 12:52:02.147: INFO: DNS probes using dns-6804/dns-test-612993c9-e537-4647-b4b6-fac1e3356d95 succeeded

  Dec  9 12:52:02.147: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 12:52:02.151
  STEP: Destroying namespace "dns-6804" for this suite. @ 12/09/23 12:52:02.166
• [2.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 12/09/23 12:52:02.174
  Dec  9 12:52:02.174: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename disruption @ 12/09/23 12:52:02.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:52:02.189
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:52:02.192
  STEP: Creating a kubernetes client @ 12/09/23 12:52:02.196
  Dec  9 12:52:02.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename disruption-2 @ 12/09/23 12:52:02.197
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:52:02.215
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:52:02.22
  STEP: Waiting for the pdb to be processed @ 12/09/23 12:52:02.229
  STEP: Waiting for the pdb to be processed @ 12/09/23 12:52:04.246
  STEP: Waiting for the pdb to be processed @ 12/09/23 12:52:04.257
  STEP: listing a collection of PDBs across all namespaces @ 12/09/23 12:52:04.262
  STEP: listing a collection of PDBs in namespace disruption-1806 @ 12/09/23 12:52:04.267
  STEP: deleting a collection of PDBs @ 12/09/23 12:52:04.27
  STEP: Waiting for the PDB collection to be deleted @ 12/09/23 12:52:04.283
  Dec  9 12:52:04.285: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:52:04.290: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-407" for this suite. @ 12/09/23 12:52:04.293
  STEP: Destroying namespace "disruption-1806" for this suite. @ 12/09/23 12:52:04.3
• [2.133 seconds]
------------------------------
SS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 12/09/23 12:52:04.307
  Dec  9 12:52:04.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename certificates @ 12/09/23 12:52:04.307
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:52:04.319
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:52:04.323
  STEP: getting /apis @ 12/09/23 12:52:04.651
  STEP: getting /apis/certificates.k8s.io @ 12/09/23 12:52:04.655
  STEP: getting /apis/certificates.k8s.io/v1 @ 12/09/23 12:52:04.656
  STEP: creating @ 12/09/23 12:52:04.657
  STEP: getting @ 12/09/23 12:52:04.675
  STEP: listing @ 12/09/23 12:52:04.678
  STEP: watching @ 12/09/23 12:52:04.681
  Dec  9 12:52:04.681: INFO: starting watch
  STEP: patching @ 12/09/23 12:52:04.683
  STEP: updating @ 12/09/23 12:52:04.69
  Dec  9 12:52:04.694: INFO: waiting for watch events with expected annotations
  Dec  9 12:52:04.694: INFO: saw patched and updated annotations
  STEP: getting /approval @ 12/09/23 12:52:04.694
  STEP: patching /approval @ 12/09/23 12:52:04.698
  STEP: updating /approval @ 12/09/23 12:52:04.705
  STEP: getting /status @ 12/09/23 12:52:04.71
  STEP: patching /status @ 12/09/23 12:52:04.713
  STEP: updating /status @ 12/09/23 12:52:04.721
  STEP: deleting @ 12/09/23 12:52:04.729
  STEP: deleting a collection @ 12/09/23 12:52:04.742
  Dec  9 12:52:04.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-6630" for this suite. @ 12/09/23 12:52:04.763
• [0.462 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 12/09/23 12:52:04.77
  Dec  9 12:52:04.770: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename cronjob @ 12/09/23 12:52:04.771
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:52:04.784
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:52:04.788
  STEP: Creating a cronjob @ 12/09/23 12:52:04.792
  STEP: Ensuring more than one job is running at a time @ 12/09/23 12:52:04.797
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 12/09/23 12:54:00.801
  STEP: Removing cronjob @ 12/09/23 12:54:00.804
  Dec  9 12:54:00.811: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-2415" for this suite. @ 12/09/23 12:54:00.815
• [116.052 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 12/09/23 12:54:00.822
  Dec  9 12:54:00.822: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 12:54:00.823
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:54:00.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:54:00.851
  STEP: Creating a pod to test downward api env vars @ 12/09/23 12:54:00.855
  STEP: Saw pod success @ 12/09/23 12:54:04.88
  Dec  9 12:54:04.883: INFO: Trying to get logs from node ip-172-31-38-129 pod downward-api-1885bbe7-6683-492a-8449-a7f0b10965d6 container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 12:54:04.901
  Dec  9 12:54:04.919: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4173" for this suite. @ 12/09/23 12:54:04.922
• [4.106 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 12/09/23 12:54:04.929
  Dec  9 12:54:04.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replication-controller @ 12/09/23 12:54:04.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:54:04.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:54:04.947
  Dec  9 12:54:04.951: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 12/09/23 12:54:05.963
  STEP: Checking rc "condition-test" has the desired failure condition set @ 12/09/23 12:54:05.969
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 12/09/23 12:54:06.978
  Dec  9 12:54:07.012: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 12/09/23 12:54:07.012
  Dec  9 12:54:07.017: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-8813" for this suite. @ 12/09/23 12:54:07.021
• [2.099 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 12/09/23 12:54:07.028
  Dec  9 12:54:07.028: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:54:07.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:54:07.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:54:07.046
  STEP: creating service in namespace services-128 @ 12/09/23 12:54:07.049
  STEP: creating service affinity-nodeport in namespace services-128 @ 12/09/23 12:54:07.049
  STEP: creating replication controller affinity-nodeport in namespace services-128 @ 12/09/23 12:54:07.062
  I1209 12:54:07.074000      18 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-128, replica count: 3
  I1209 12:54:10.124915      18 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 12:54:10.137: INFO: Creating new exec pod
  Dec  9 12:54:13.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-128 exec execpod-affinityx8st9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Dec  9 12:54:13.254: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Dec  9 12:54:13.254: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:54:13.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-128 exec execpod-affinityx8st9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.77 80'
  Dec  9 12:54:13.357: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.77 80\nConnection to 10.152.183.77 80 port [tcp/http] succeeded!\n"
  Dec  9 12:54:13.357: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:54:13.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-128 exec execpod-affinityx8st9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.80.205 32250'
  Dec  9 12:54:13.455: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.80.205 32250\nConnection to 172.31.80.205 32250 port [tcp/*] succeeded!\n"
  Dec  9 12:54:13.455: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:54:13.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-128 exec execpod-affinityx8st9 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.129 32250'
  Dec  9 12:54:13.558: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.129 32250\nConnection to 172.31.38.129 32250 port [tcp/*] succeeded!\n"
  Dec  9 12:54:13.558: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:54:13.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-128 exec execpod-affinityx8st9 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.38.129:32250/ ; done'
  Dec  9 12:54:13.711: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.38.129:32250/\n"
  Dec  9 12:54:13.711: INFO: stdout: "\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6\naffinity-nodeport-lvsn6"
  Dec  9 12:54:13.711: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.711: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Received response from host: affinity-nodeport-lvsn6
  Dec  9 12:54:13.712: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:54:13.716: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-128, will wait for the garbage collector to delete the pods @ 12/09/23 12:54:13.739
  Dec  9 12:54:13.800: INFO: Deleting ReplicationController affinity-nodeport took: 7.170716ms
  Dec  9 12:54:13.902: INFO: Terminating ReplicationController affinity-nodeport pods took: 102.224321ms
  STEP: Destroying namespace "services-128" for this suite. @ 12/09/23 12:54:17.13
• [10.108 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 12/09/23 12:54:17.136
  Dec  9 12:54:17.136: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename cronjob @ 12/09/23 12:54:17.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:54:17.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:54:17.157
  STEP: Creating a ReplaceConcurrent cronjob @ 12/09/23 12:54:17.161
  STEP: Ensuring a job is scheduled @ 12/09/23 12:54:17.166
  STEP: Ensuring exactly one is scheduled @ 12/09/23 12:55:01.17
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/09/23 12:55:01.174
  STEP: Ensuring the job is replaced with a new one @ 12/09/23 12:55:01.177
  STEP: Removing cronjob @ 12/09/23 12:56:01.182
  Dec  9 12:56:01.188: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-1273" for this suite. @ 12/09/23 12:56:01.192
• [104.064 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 12/09/23 12:56:01.201
  Dec  9 12:56:01.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/09/23 12:56:01.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:01.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:01.23
  STEP: create the container to handle the HTTPGet hook request. @ 12/09/23 12:56:01.238
  STEP: create the pod with lifecycle hook @ 12/09/23 12:56:03.263
  STEP: check poststart hook @ 12/09/23 12:56:05.278
  STEP: delete the pod with lifecycle hook @ 12/09/23 12:56:05.301
  Dec  9 12:56:07.318: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1927" for this suite. @ 12/09/23 12:56:07.322
• [6.127 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 12/09/23 12:56:07.329
  Dec  9 12:56:07.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename watch @ 12/09/23 12:56:07.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:07.345
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:07.349
  STEP: creating a watch on configmaps with label A @ 12/09/23 12:56:07.352
  STEP: creating a watch on configmaps with label B @ 12/09/23 12:56:07.353
  STEP: creating a watch on configmaps with label A or B @ 12/09/23 12:56:07.355
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 12/09/23 12:56:07.356
  Dec  9 12:56:07.361: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18961 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:56:07.361: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18961 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 12/09/23 12:56:07.361
  Dec  9 12:56:07.370: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18962 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:56:07.370: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18962 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 12/09/23 12:56:07.37
  Dec  9 12:56:07.379: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18963 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:56:07.379: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18963 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 12/09/23 12:56:07.379
  Dec  9 12:56:07.386: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18964 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:56:07.387: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3590  d2cb8535-8153-41d2-8f39-2b89d35428b8 18964 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 12/09/23 12:56:07.387
  Dec  9 12:56:07.392: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3590  3fbe1501-2fa3-499a-a3ce-f35343549356 18965 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:56:07.393: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3590  3fbe1501-2fa3-499a-a3ce-f35343549356 18965 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 12/09/23 12:56:17.395
  Dec  9 12:56:17.404: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3590  3fbe1501-2fa3-499a-a3ce-f35343549356 19008 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:56:17.404: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3590  3fbe1501-2fa3-499a-a3ce-f35343549356 19008 0 2023-12-09 12:56:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-09 12:56:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 12:56:27.407: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-3590" for this suite. @ 12/09/23 12:56:27.412
• [20.090 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3142
  STEP: Creating a kubernetes client @ 12/09/23 12:56:27.419
  Dec  9 12:56:27.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:56:27.42
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:27.436
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:27.439
  STEP: creating an Endpoint @ 12/09/23 12:56:27.445
  STEP: waiting for available Endpoint @ 12/09/23 12:56:27.449
  STEP: listing all Endpoints @ 12/09/23 12:56:27.451
  STEP: updating the Endpoint @ 12/09/23 12:56:27.455
  STEP: fetching the Endpoint @ 12/09/23 12:56:27.462
  STEP: patching the Endpoint @ 12/09/23 12:56:27.465
  STEP: fetching the Endpoint @ 12/09/23 12:56:27.474
  STEP: deleting the Endpoint by Collection @ 12/09/23 12:56:27.477
  STEP: waiting for Endpoint deletion @ 12/09/23 12:56:27.486
  STEP: fetching the Endpoint @ 12/09/23 12:56:27.488
  Dec  9 12:56:27.492: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4511" for this suite. @ 12/09/23 12:56:27.497
• [0.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 12/09/23 12:56:27.506
  Dec  9 12:56:27.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/09/23 12:56:27.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:27.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:27.525
  STEP: create the container to handle the HTTPGet hook request. @ 12/09/23 12:56:27.531
  STEP: create the pod with lifecycle hook @ 12/09/23 12:56:29.554
  STEP: delete the pod with lifecycle hook @ 12/09/23 12:56:31.576
  STEP: check prestop hook @ 12/09/23 12:56:33.593
  Dec  9 12:56:33.609: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6657" for this suite. @ 12/09/23 12:56:33.612
• [6.113 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 12/09/23 12:56:33.62
  Dec  9 12:56:33.620: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 12:56:33.62
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:33.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:33.64
  STEP: Creating a pod to test substitution in container's command @ 12/09/23 12:56:33.644
  STEP: Saw pod success @ 12/09/23 12:56:37.663
  Dec  9 12:56:37.666: INFO: Trying to get logs from node ip-172-31-77-176 pod var-expansion-3eb856fb-0b65-44a5-9ab8-dc158027279a container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 12:56:37.674
  Dec  9 12:56:37.692: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6918" for this suite. @ 12/09/23 12:56:37.695
• [4.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 12/09/23 12:56:37.704
  Dec  9 12:56:37.704: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 12:56:37.704
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:37.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:37.722
  STEP: set up a multi version CRD @ 12/09/23 12:56:37.726
  Dec  9 12:56:37.728: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: mark a version not serverd @ 12/09/23 12:56:41.03
  STEP: check the unserved version gets removed @ 12/09/23 12:56:41.049
  STEP: check the other version is not changed @ 12/09/23 12:56:41.868
  Dec  9 12:56:44.427: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6984" for this suite. @ 12/09/23 12:56:44.435
• [6.739 seconds]
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1641
  STEP: Creating a kubernetes client @ 12/09/23 12:56:44.442
  Dec  9 12:56:44.442: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 12:56:44.443
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:44.459
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:44.462
  STEP: creating Agnhost RC @ 12/09/23 12:56:44.468
  Dec  9 12:56:44.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3624 create -f -'
  Dec  9 12:56:44.625: INFO: stderr: ""
  Dec  9 12:56:44.625: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/09/23 12:56:44.625
  Dec  9 12:56:45.629: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 12:56:45.629: INFO: Found 0 / 1
  Dec  9 12:56:46.629: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 12:56:46.629: INFO: Found 1 / 1
  Dec  9 12:56:46.629: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 12/09/23 12:56:46.629
  Dec  9 12:56:46.632: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 12:56:46.632: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  9 12:56:46.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-3624 patch pod agnhost-primary-8lv7b -p {"metadata":{"annotations":{"x":"y"}}}'
  Dec  9 12:56:46.687: INFO: stderr: ""
  Dec  9 12:56:46.687: INFO: stdout: "pod/agnhost-primary-8lv7b patched\n"
  STEP: checking annotations @ 12/09/23 12:56:46.687
  Dec  9 12:56:46.691: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 12:56:46.691: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  9 12:56:46.691: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3624" for this suite. @ 12/09/23 12:56:46.695
• [2.259 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 12/09/23 12:56:46.703
  Dec  9 12:56:46.703: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/09/23 12:56:46.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:46.72
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:46.724
  Dec  9 12:56:46.727: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 12:56:47.751: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7664" for this suite. @ 12/09/23 12:56:47.755
• [1.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 12/09/23 12:56:47.763
  Dec  9 12:56:47.763: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:56:47.764
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:47.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:47.781
  STEP: creating service multi-endpoint-test in namespace services-2665 @ 12/09/23 12:56:47.785
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[] @ 12/09/23 12:56:47.799
  Dec  9 12:56:47.810: INFO: successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2665 @ 12/09/23 12:56:47.81
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[pod1:[100]] @ 12/09/23 12:56:49.831
  Dec  9 12:56:49.844: INFO: successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-2665 @ 12/09/23 12:56:49.844
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[pod1:[100] pod2:[101]] @ 12/09/23 12:56:51.859
  Dec  9 12:56:51.877: INFO: successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 12/09/23 12:56:51.877
  Dec  9 12:56:51.877: INFO: Creating new exec pod
  Dec  9 12:56:54.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-2665 exec execpodqps6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Dec  9 12:56:54.999: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Dec  9 12:56:54.999: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:56:55.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-2665 exec execpodqps6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.68 80'
  Dec  9 12:56:55.095: INFO: stderr: "+ nc -v -t -w 2 10.152.183.68 80\n+ echo hostName\nConnection to 10.152.183.68 80 port [tcp/http] succeeded!\n"
  Dec  9 12:56:55.095: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:56:55.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-2665 exec execpodqps6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Dec  9 12:56:55.197: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Dec  9 12:56:55.197: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:56:55.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-2665 exec execpodqps6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.68 81'
  Dec  9 12:56:55.305: INFO: stderr: "+ nc -v -t -w 2 10.152.183.68 81\n+ echo hostName\nConnection to 10.152.183.68 81 port [tcp/*] succeeded!\n"
  Dec  9 12:56:55.305: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2665 @ 12/09/23 12:56:55.305
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[pod2:[101]] @ 12/09/23 12:56:55.332
  Dec  9 12:56:55.360: INFO: successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-2665 @ 12/09/23 12:56:55.36
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2665 to expose endpoints map[] @ 12/09/23 12:56:55.383
  Dec  9 12:56:55.397: INFO: successfully validated that service multi-endpoint-test in namespace services-2665 exposes endpoints map[]
  Dec  9 12:56:55.397: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2665" for this suite. @ 12/09/23 12:56:55.42
• [7.665 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 12/09/23 12:56:55.428
  Dec  9 12:56:55.428: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 12:56:55.429
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:55.442
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:55.446
  STEP: Creating secret with name secret-test-9b65fa21-7b32-4d93-a1b1-1b32b8270044 @ 12/09/23 12:56:55.449
  STEP: Creating a pod to test consume secrets @ 12/09/23 12:56:55.454
  STEP: Saw pod success @ 12/09/23 12:56:57.473
  Dec  9 12:56:57.477: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-secrets-ffffdbe2-6257-427d-bd59-741a23489dc4 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 12:56:57.483
  Dec  9 12:56:57.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6374" for this suite. @ 12/09/23 12:56:57.5
• [2.078 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1781
  STEP: Creating a kubernetes client @ 12/09/23 12:56:57.507
  Dec  9 12:56:57.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 12:56:57.507
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:57.521
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:57.524
  STEP: starting the proxy server @ 12/09/23 12:56:57.528
  Dec  9 12:56:57.528: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4798 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 12/09/23 12:56:57.563
  Dec  9 12:56:57.569: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4798" for this suite. @ 12/09/23 12:56:57.572
• [0.071 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 12/09/23 12:56:57.578
  Dec  9 12:56:57.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename runtimeclass @ 12/09/23 12:56:57.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:57.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:57.599
  Dec  9 12:56:59.625: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2546" for this suite. @ 12/09/23 12:56:59.636
• [2.064 seconds]
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 12/09/23 12:56:59.642
  Dec  9 12:56:59.642: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svcaccounts @ 12/09/23 12:56:59.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:56:59.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:56:59.665
  Dec  9 12:56:59.671: INFO: Got root ca configmap in namespace "svcaccounts-1651"
  Dec  9 12:56:59.679: INFO: Deleted root ca configmap in namespace "svcaccounts-1651"
  STEP: waiting for a new root ca configmap created @ 12/09/23 12:57:00.179
  Dec  9 12:57:00.183: INFO: Recreated root ca configmap in namespace "svcaccounts-1651"
  Dec  9 12:57:00.189: INFO: Updated root ca configmap in namespace "svcaccounts-1651"
  STEP: waiting for the root ca configmap reconciled @ 12/09/23 12:57:00.689
  Dec  9 12:57:00.693: INFO: Reconciled root ca configmap in namespace "svcaccounts-1651"
  Dec  9 12:57:00.694: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-1651" for this suite. @ 12/09/23 12:57:00.697
• [1.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 12/09/23 12:57:00.708
  Dec  9 12:57:00.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 12:57:00.709
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:57:00.721
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:57:00.725
  STEP: creating service in namespace services-626 @ 12/09/23 12:57:00.729
  STEP: creating service affinity-clusterip-transition in namespace services-626 @ 12/09/23 12:57:00.729
  STEP: creating replication controller affinity-clusterip-transition in namespace services-626 @ 12/09/23 12:57:00.743
  I1209 12:57:00.751555      18 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-626, replica count: 3
  I1209 12:57:03.803425      18 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 12:57:03.811: INFO: Creating new exec pod
  Dec  9 12:57:06.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-626 exec execpod-affinity65542 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Dec  9 12:57:06.933: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Dec  9 12:57:06.933: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:57:06.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-626 exec execpod-affinity65542 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.248 80'
  Dec  9 12:57:07.034: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.248 80\nConnection to 10.152.183.248 80 port [tcp/http] succeeded!\n"
  Dec  9 12:57:07.034: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 12:57:07.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-626 exec execpod-affinity65542 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.248:80/ ; done'
  Dec  9 12:57:07.202: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n"
  Dec  9 12:57:07.202: INFO: stdout: "\naffinity-clusterip-transition-5htnz\naffinity-clusterip-transition-5htnz\naffinity-clusterip-transition-5htnz\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-5htnz\naffinity-clusterip-transition-5htnz\naffinity-clusterip-transition-nlf2n\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-5htnz\naffinity-clusterip-transition-5htnz\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-5htnz"
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nlf2n
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.202: INFO: Received response from host: affinity-clusterip-transition-5htnz
  Dec  9 12:57:07.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-626 exec execpod-affinity65542 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.248:80/ ; done'
  Dec  9 12:57:07.358: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.248:80/\n"
  Dec  9 12:57:07.358: INFO: stdout: "\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8\naffinity-clusterip-transition-nhhs8"
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.358: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Received response from host: affinity-clusterip-transition-nhhs8
  Dec  9 12:57:07.359: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 12:57:07.363: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-626, will wait for the garbage collector to delete the pods @ 12/09/23 12:57:07.377
  Dec  9 12:57:07.436: INFO: Deleting ReplicationController affinity-clusterip-transition took: 6.060254ms
  Dec  9 12:57:07.537: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.541859ms
  STEP: Destroying namespace "services-626" for this suite. @ 12/09/23 12:57:10.759
• [10.057 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 12/09/23 12:57:10.766
  Dec  9 12:57:10.766: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 12:57:10.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:57:10.781
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:57:10.784
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/09/23 12:57:10.788
  STEP: Saw pod success @ 12/09/23 12:57:14.806
  Dec  9 12:57:14.810: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-2711c702-121c-4d1e-bd93-234fca62dfc0 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 12:57:14.818
  Dec  9 12:57:14.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4988" for this suite. @ 12/09/23 12:57:14.839
• [4.081 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 12/09/23 12:57:14.849
  Dec  9 12:57:14.849: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 12:57:14.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:57:14.871
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:57:14.876
  Dec  9 12:57:14.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: creating the pod @ 12/09/23 12:57:14.881
  STEP: submitting the pod to kubernetes @ 12/09/23 12:57:14.881
  Dec  9 12:57:16.930: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5615" for this suite. @ 12/09/23 12:57:16.935
• [2.093 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 12/09/23 12:57:16.943
  Dec  9 12:57:16.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 12:57:16.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:57:16.963
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:57:16.969
  STEP: Creating configMap with name projected-configmap-test-volume-aa0e18ed-123e-4aae-9b21-27a174aad45a @ 12/09/23 12:57:16.973
  STEP: Creating a pod to test consume configMaps @ 12/09/23 12:57:16.98
  STEP: Saw pod success @ 12/09/23 12:57:21.008
  Dec  9 12:57:21.012: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-configmaps-67bcc081-fc77-40d3-9571-0af38c99e199 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 12:57:21.02
  Dec  9 12:57:21.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9727" for this suite. @ 12/09/23 12:57:21.042
• [4.105 seconds]
------------------------------
SS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 12/09/23 12:57:21.048
  Dec  9 12:57:21.048: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 12:57:21.048
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:57:21.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:57:21.077
  STEP: Creating a pod to test substitution in volume subpath @ 12/09/23 12:57:21.081
  STEP: Saw pod success @ 12/09/23 12:57:23.102
  Dec  9 12:57:23.105: INFO: Trying to get logs from node ip-172-31-77-176 pod var-expansion-5995ea33-a4ca-43a0-8656-9f16d9785868 container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 12:57:23.111
  Dec  9 12:57:23.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-3333" for this suite. @ 12/09/23 12:57:23.135
• [2.094 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 12/09/23 12:57:23.142
  Dec  9 12:57:23.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 12:57:23.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 12:57:23.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 12:57:23.164
  STEP: Creating pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941 @ 12/09/23 12:57:23.168
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 12:57:25.186
  Dec  9 12:57:25.190: INFO: Initial restart count of pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 is 0
  Dec  9 12:57:25.193: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:27.197: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:29.202: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:31.206: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:33.211: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:35.214: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:37.219: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:39.225: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:41.229: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:43.234: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:45.239: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:47.243: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:49.247: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:51.251: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:53.256: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:55.260: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:57.265: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:57:59.269: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:01.275: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:03.280: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:05.284: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:07.290: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:09.294: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:11.298: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:13.303: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:15.307: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:17.311: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:19.317: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:21.321: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:23.326: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:25.330: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:27.335: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:29.340: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:31.344: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:33.348: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:35.353: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:37.358: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:39.361: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:41.367: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:43.371: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:45.376: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:47.382: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:49.387: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:51.391: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:53.396: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:55.402: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:57.405: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:58:59.410: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:01.414: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:03.419: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:05.422: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:07.426: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:09.430: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:11.435: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:13.439: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:15.443: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:17.446: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:19.450: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:21.454: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:23.458: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:25.463: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:27.466: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:29.471: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:31.475: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:33.479: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:35.483: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:37.486: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:39.491: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:41.496: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:43.501: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:45.512: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:47.517: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:49.522: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:51.527: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:53.532: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:55.535: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:57.539: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 12:59:59.543: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:01.549: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:03.553: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:05.557: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:07.561: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:09.566: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:11.571: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:13.575: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:15.580: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:17.584: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:19.590: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:21.594: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:23.600: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:25.604: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:27.608: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:29.614: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:31.618: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:33.622: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:35.627: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:37.630: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:39.634: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:41.639: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:43.643: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:45.648: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:47.652: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:49.657: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:51.662: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:53.666: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:55.673: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:57.676: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:00:59.680: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:01.686: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:03.690: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:05.694: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:07.700: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:09.704: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:11.709: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:13.714: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:15.718: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:17.723: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:19.727: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:21.733: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:23.737: INFO: Get pod busybox-0cf9571c-db6a-4d9e-b507-9f3eeec98605 in namespace container-probe-5941
  Dec  9 13:01:25.738: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:01:25.743
  STEP: Destroying namespace "container-probe-5941" for this suite. @ 12/09/23 13:01:25.756
• [242.622 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 12/09/23 13:01:25.764
  Dec  9 13:01:25.764: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replication-controller @ 12/09/23 13:01:25.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:01:25.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:01:25.781
  STEP: Creating ReplicationController "e2e-rc-tt9kh" @ 12/09/23 13:01:25.785
  Dec  9 13:01:25.793: INFO: Get Replication Controller "e2e-rc-tt9kh" to confirm replicas
  Dec  9 13:01:26.796: INFO: Get Replication Controller "e2e-rc-tt9kh" to confirm replicas
  Dec  9 13:01:26.800: INFO: Found 1 replicas for "e2e-rc-tt9kh" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-tt9kh" @ 12/09/23 13:01:26.8
  STEP: Updating a scale subresource @ 12/09/23 13:01:26.803
  STEP: Verifying replicas where modified for replication controller "e2e-rc-tt9kh" @ 12/09/23 13:01:26.809
  Dec  9 13:01:26.809: INFO: Get Replication Controller "e2e-rc-tt9kh" to confirm replicas
  Dec  9 13:01:27.816: INFO: Get Replication Controller "e2e-rc-tt9kh" to confirm replicas
  Dec  9 13:01:27.822: INFO: Found 2 replicas for "e2e-rc-tt9kh" replication controller
  Dec  9 13:01:27.822: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-7059" for this suite. @ 12/09/23 13:01:27.825
• [2.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 12/09/23 13:01:27.834
  Dec  9 13:01:27.834: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename gc @ 12/09/23 13:01:27.835
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:01:27.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:01:27.853
  STEP: create the deployment @ 12/09/23 13:01:27.856
  W1209 13:01:27.862832      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/09/23 13:01:27.862
  STEP: delete the deployment @ 12/09/23 13:01:27.867
  STEP: wait for all rs to be garbage collected @ 12/09/23 13:01:27.885
  STEP: expected 0 rs, got 1 rs @ 12/09/23 13:01:27.901
  STEP: expected 0 pods, got 2 pods @ 12/09/23 13:01:27.905
  STEP: Gathering metrics @ 12/09/23 13:01:28.416
  W1209 13:01:28.421658      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  9 13:01:28.421: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  9 13:01:28.421: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4319" for this suite. @ 12/09/23 13:01:28.425
• [0.598 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 12/09/23 13:01:28.435
  Dec  9 13:01:28.435: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename endpointslice @ 12/09/23 13:01:28.435
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:01:28.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:01:28.454
  Dec  9 13:01:28.506: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-2089" for this suite. @ 12/09/23 13:01:28.511
• [0.083 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 12/09/23 13:01:28.518
  Dec  9 13:01:28.518: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:01:28.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:01:28.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:01:28.536
  STEP: Setting up server cert @ 12/09/23 13:01:28.562
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:01:28.679
  STEP: Deploying the webhook pod @ 12/09/23 13:01:28.688
  STEP: Wait for the deployment to be ready @ 12/09/23 13:01:28.7
  Dec  9 13:01:28.710: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 13:01:30.721
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:01:30.731
  Dec  9 13:01:31.731: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/09/23 13:01:31.74
  STEP: create a pod @ 12/09/23 13:01:31.755
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 12/09/23 13:01:33.773
  Dec  9 13:01:33.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=webhook-1524 attach --namespace=webhook-1524 to-be-attached-pod -i -c=container1'
  Dec  9 13:01:33.835: INFO: rc: 1
  Dec  9 13:01:33.835: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1524" for this suite. @ 12/09/23 13:01:33.888
  STEP: Destroying namespace "webhook-markers-941" for this suite. @ 12/09/23 13:01:33.896
• [5.385 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 12/09/23 13:01:33.903
  Dec  9 13:01:33.903: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/09/23 13:01:33.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:01:33.919
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:01:33.924
  Dec  9 13:01:33.927: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:01:40.157: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9390" for this suite. @ 12/09/23 13:01:40.161
• [6.265 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 12/09/23 13:01:40.169
  Dec  9 13:01:40.169: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 13:01:40.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:01:40.186
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:01:40.189
  STEP: Creating pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702 @ 12/09/23 13:01:40.193
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 13:01:42.207
  Dec  9 13:01:42.211: INFO: Initial restart count of pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc is 0
  Dec  9 13:01:42.215: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:44.219: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:46.223: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:48.227: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:50.231: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:52.236: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:54.240: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:56.245: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:01:58.249: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:00.253: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:02.258: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:04.262: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:06.266: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:08.271: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:10.276: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:12.283: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:14.287: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:16.291: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:18.296: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:20.301: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:22.305: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:24.309: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:26.315: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:28.319: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:30.322: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:32.328: INFO: Get pod busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc in namespace container-probe-6702
  Dec  9 13:02:32.328: INFO: Restart count of pod container-probe-6702/busybox-c7a75ab0-b6f7-4f2e-ac7f-6262940a42dc is now 1 (50.11791671s elapsed)
  Dec  9 13:02:32.329: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:02:32.332
  STEP: Destroying namespace "container-probe-6702" for this suite. @ 12/09/23 13:02:32.347
• [52.185 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 12/09/23 13:02:32.355
  Dec  9 13:02:32.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename subpath @ 12/09/23 13:02:32.355
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:02:32.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:02:32.378
  STEP: Setting up data @ 12/09/23 13:02:32.381
  STEP: Creating pod pod-subpath-test-secret-d7dl @ 12/09/23 13:02:32.39
  STEP: Creating a pod to test atomic-volume-subpath @ 12/09/23 13:02:32.391
  STEP: Saw pod success @ 12/09/23 13:02:56.457
  Dec  9 13:02:56.463: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-subpath-test-secret-d7dl container test-container-subpath-secret-d7dl: <nil>
  STEP: delete the pod @ 12/09/23 13:02:56.48
  STEP: Deleting pod pod-subpath-test-secret-d7dl @ 12/09/23 13:02:56.496
  Dec  9 13:02:56.496: INFO: Deleting pod "pod-subpath-test-secret-d7dl" in namespace "subpath-7265"
  Dec  9 13:02:56.500: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7265" for this suite. @ 12/09/23 13:02:56.503
• [24.154 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 12/09/23 13:02:56.51
  Dec  9 13:02:56.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 13:02:56.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:02:56.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:02:56.532
  STEP: creating service endpoint-test2 in namespace services-4474 @ 12/09/23 13:02:56.536
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4474 to expose endpoints map[] @ 12/09/23 13:02:56.548
  Dec  9 13:02:56.563: INFO: successfully validated that service endpoint-test2 in namespace services-4474 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-4474 @ 12/09/23 13:02:56.563
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4474 to expose endpoints map[pod1:[80]] @ 12/09/23 13:02:58.587
  Dec  9 13:02:58.598: INFO: successfully validated that service endpoint-test2 in namespace services-4474 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 12/09/23 13:02:58.598
  Dec  9 13:02:58.598: INFO: Creating new exec pod
  Dec  9 13:03:01.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4474 exec execpod7n9tr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec  9 13:03:01.729: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec  9 13:03:01.729: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 13:03:01.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4474 exec execpod7n9tr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  Dec  9 13:03:01.835: INFO: stderr: "+ nc -v -t -w 2 10.152.183.123 80\n+ echo hostName\nConnection to 10.152.183.123 80 port [tcp/http] succeeded!\n"
  Dec  9 13:03:01.835: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-4474 @ 12/09/23 13:03:01.835
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4474 to expose endpoints map[pod1:[80] pod2:[80]] @ 12/09/23 13:03:03.852
  Dec  9 13:03:03.868: INFO: successfully validated that service endpoint-test2 in namespace services-4474 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 12/09/23 13:03:03.868
  Dec  9 13:03:04.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4474 exec execpod7n9tr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec  9 13:03:04.968: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec  9 13:03:04.969: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 13:03:04.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4474 exec execpod7n9tr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  Dec  9 13:03:05.082: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.123 80\nConnection to 10.152.183.123 80 port [tcp/http] succeeded!\n"
  Dec  9 13:03:05.082: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-4474 @ 12/09/23 13:03:05.082
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4474 to expose endpoints map[pod2:[80]] @ 12/09/23 13:03:05.101
  Dec  9 13:03:06.123: INFO: successfully validated that service endpoint-test2 in namespace services-4474 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 12/09/23 13:03:06.123
  Dec  9 13:03:07.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4474 exec execpod7n9tr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec  9 13:03:07.232: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec  9 13:03:07.232: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  9 13:03:07.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4474 exec execpod7n9tr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.123 80'
  Dec  9 13:03:07.333: INFO: stderr: "+ nc -v -t -w 2 10.152.183.123 80\n+ echo hostName\nConnection to 10.152.183.123 80 port [tcp/http] succeeded!\n"
  Dec  9 13:03:07.333: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-4474 @ 12/09/23 13:03:07.333
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4474 to expose endpoints map[] @ 12/09/23 13:03:07.349
  Dec  9 13:03:07.361: INFO: successfully validated that service endpoint-test2 in namespace services-4474 exposes endpoints map[]
  Dec  9 13:03:07.361: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-4474" for this suite. @ 12/09/23 13:03:07.388
• [10.888 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 12/09/23 13:03:07.399
  Dec  9 13:03:07.399: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:03:07.4
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:07.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:07.422
  STEP: Creating projection with secret that has name projected-secret-test-3f35b334-c5bf-49f6-82bd-4ca5af0e46a0 @ 12/09/23 13:03:07.437
  STEP: Creating a pod to test consume secrets @ 12/09/23 13:03:07.443
  STEP: Saw pod success @ 12/09/23 13:03:11.468
  Dec  9 13:03:11.471: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-secrets-209b823b-45c5-4a39-8841-5d8900c3a361 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 13:03:11.48
  Dec  9 13:03:11.496: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5707" for this suite. @ 12/09/23 13:03:11.499
• [4.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 12/09/23 13:03:11.508
  Dec  9 13:03:11.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename job @ 12/09/23 13:03:11.509
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:11.529
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:11.533
  STEP: Creating a job @ 12/09/23 13:03:11.536
  STEP: Ensuring active pods == parallelism @ 12/09/23 13:03:11.544
  STEP: delete a job @ 12/09/23 13:03:13.549
  STEP: deleting Job.batch foo in namespace job-3443, will wait for the garbage collector to delete the pods @ 12/09/23 13:03:13.549
  Dec  9 13:03:13.609: INFO: Deleting Job.batch foo took: 6.371496ms
  Dec  9 13:03:13.710: INFO: Terminating Job.batch foo pods took: 100.859674ms
  STEP: Ensuring job was deleted @ 12/09/23 13:03:44.611
  Dec  9 13:03:44.614: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-3443" for this suite. @ 12/09/23 13:03:44.617
• [33.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 12/09/23 13:03:44.624
  Dec  9 13:03:44.624: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:03:44.624
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:44.641
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:44.644
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/09/23 13:03:44.648
  STEP: Saw pod success @ 12/09/23 13:03:48.667
  Dec  9 13:03:48.670: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-678d80f7-d5a7-4fe6-a886-05af2e0fb025 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:03:48.676
  Dec  9 13:03:48.692: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-426" for this suite. @ 12/09/23 13:03:48.695
• [4.078 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 12/09/23 13:03:48.702
  Dec  9 13:03:48.702: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename ingressclass @ 12/09/23 13:03:48.703
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:48.716
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:48.719
  STEP: getting /apis @ 12/09/23 13:03:48.723
  STEP: getting /apis/networking.k8s.io @ 12/09/23 13:03:48.726
  STEP: getting /apis/networking.k8s.iov1 @ 12/09/23 13:03:48.728
  STEP: creating @ 12/09/23 13:03:48.729
  STEP: getting @ 12/09/23 13:03:48.744
  STEP: listing @ 12/09/23 13:03:48.75
  STEP: watching @ 12/09/23 13:03:48.754
  Dec  9 13:03:48.754: INFO: starting watch
  STEP: patching @ 12/09/23 13:03:48.755
  STEP: updating @ 12/09/23 13:03:48.76
  Dec  9 13:03:48.764: INFO: waiting for watch events with expected annotations
  Dec  9 13:03:48.764: INFO: saw patched and updated annotations
  STEP: deleting @ 12/09/23 13:03:48.764
  STEP: deleting a collection @ 12/09/23 13:03:48.777
  Dec  9 13:03:48.792: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-6110" for this suite. @ 12/09/23 13:03:48.796
• [0.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 12/09/23 13:03:48.804
  Dec  9 13:03:48.804: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename field-validation @ 12/09/23 13:03:48.805
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:48.819
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:48.822
  Dec  9 13:03:48.825: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  W1209 13:03:51.368284      18 warnings.go:70] unknown field "alpha"
  W1209 13:03:51.368307      18 warnings.go:70] unknown field "beta"
  W1209 13:03:51.368310      18 warnings.go:70] unknown field "delta"
  W1209 13:03:51.368314      18 warnings.go:70] unknown field "epsilon"
  W1209 13:03:51.368317      18 warnings.go:70] unknown field "gamma"
  Dec  9 13:03:51.900: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1098" for this suite. @ 12/09/23 13:03:51.917
• [3.119 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 12/09/23 13:03:51.925
  Dec  9 13:03:51.925: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename events @ 12/09/23 13:03:51.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:51.942
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:51.945
  STEP: Create set of events @ 12/09/23 13:03:51.949
  STEP: get a list of Events with a label in the current namespace @ 12/09/23 13:03:51.964
  STEP: delete a list of events @ 12/09/23 13:03:51.968
  Dec  9 13:03:51.968: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/09/23 13:03:51.989
  Dec  9 13:03:51.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-4059" for this suite. @ 12/09/23 13:03:51.995
• [0.077 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 12/09/23 13:03:52.002
  Dec  9 13:03:52.002: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 13:03:52.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:52.015
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:52.019
  STEP: creating a Pod with a static label @ 12/09/23 13:03:52.028
  STEP: watching for Pod to be ready @ 12/09/23 13:03:52.037
  Dec  9 13:03:52.039: INFO: observed Pod pod-test in namespace pods-5888 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Dec  9 13:03:52.046: INFO: observed Pod pod-test in namespace pods-5888 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:52 +0000 UTC  }]
  Dec  9 13:03:52.061: INFO: observed Pod pod-test in namespace pods-5888 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:52 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:52 +0000 UTC  }]
  Dec  9 13:03:53.577: INFO: Found Pod pod-test in namespace pods-5888 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:53 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:53 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:03:52 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 12/09/23 13:03:53.58
  STEP: getting the Pod and ensuring that it's patched @ 12/09/23 13:03:53.591
  STEP: replacing the Pod's status Ready condition to False @ 12/09/23 13:03:53.599
  STEP: check the Pod again to ensure its Ready conditions are False @ 12/09/23 13:03:53.611
  STEP: deleting the Pod via a Collection with a LabelSelector @ 12/09/23 13:03:53.611
  STEP: watching for the Pod to be deleted @ 12/09/23 13:03:53.62
  Dec  9 13:03:53.622: INFO: observed event type MODIFIED
  Dec  9 13:03:55.587: INFO: observed event type MODIFIED
  Dec  9 13:03:55.902: INFO: observed event type MODIFIED
  Dec  9 13:03:56.584: INFO: observed event type MODIFIED
  Dec  9 13:03:56.592: INFO: observed event type MODIFIED
  Dec  9 13:03:56.602: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5888" for this suite. @ 12/09/23 13:03:56.605
• [4.610 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 12/09/23 13:03:56.616
  Dec  9 13:03:56.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 13:03:56.617
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:03:56.635
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:03:56.641
  STEP: creating the pod @ 12/09/23 13:03:56.644
  STEP: waiting for pod running @ 12/09/23 13:03:56.654
  STEP: creating a file in subpath @ 12/09/23 13:03:58.664
  Dec  9 13:03:58.667: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-4391 PodName:var-expansion-9b417320-ad58-48cb-993c-d70987774515 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:03:58.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:03:58.667: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:03:58.667: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4391/pods/var-expansion-9b417320-ad58-48cb-993c-d70987774515/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 12/09/23 13:03:58.722
  Dec  9 13:03:58.726: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-4391 PodName:var-expansion-9b417320-ad58-48cb-993c-d70987774515 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:03:58.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:03:58.727: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:03:58.727: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-4391/pods/var-expansion-9b417320-ad58-48cb-993c-d70987774515/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 12/09/23 13:03:58.778
  Dec  9 13:03:59.289: INFO: Successfully updated pod "var-expansion-9b417320-ad58-48cb-993c-d70987774515"
  STEP: waiting for annotated pod running @ 12/09/23 13:03:59.289
  STEP: deleting the pod gracefully @ 12/09/23 13:03:59.293
  Dec  9 13:03:59.293: INFO: Deleting pod "var-expansion-9b417320-ad58-48cb-993c-d70987774515" in namespace "var-expansion-4391"
  Dec  9 13:03:59.301: INFO: Wait up to 5m0s for pod "var-expansion-9b417320-ad58-48cb-993c-d70987774515" to be fully deleted
  Dec  9 13:04:31.375: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4391" for this suite. @ 12/09/23 13:04:31.38
• [34.773 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 12/09/23 13:04:31.391
  Dec  9 13:04:31.391: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 12/09/23 13:04:31.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:04:31.412
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:04:31.416
  STEP: Setting up the test @ 12/09/23 13:04:31.421
  STEP: Creating hostNetwork=false pod @ 12/09/23 13:04:31.421
  STEP: Creating hostNetwork=true pod @ 12/09/23 13:04:33.446
  STEP: Running the test @ 12/09/23 13:04:35.468
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 12/09/23 13:04:35.468
  Dec  9 13:04:35.468: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.468: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.468: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.468: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  9 13:04:35.530: INFO: Exec stderr: ""
  Dec  9 13:04:35.530: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.530: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.531: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.531: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  9 13:04:35.578: INFO: Exec stderr: ""
  Dec  9 13:04:35.578: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.579: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.579: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  9 13:04:35.627: INFO: Exec stderr: ""
  Dec  9 13:04:35.627: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.628: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.628: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  9 13:04:35.682: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 12/09/23 13:04:35.682
  Dec  9 13:04:35.682: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.682: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.682: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec  9 13:04:35.734: INFO: Exec stderr: ""
  Dec  9 13:04:35.734: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.735: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.735: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec  9 13:04:35.782: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 12/09/23 13:04:35.782
  Dec  9 13:04:35.782: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.782: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.783: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  9 13:04:35.831: INFO: Exec stderr: ""
  Dec  9 13:04:35.831: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.832: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.832: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  9 13:04:35.879: INFO: Exec stderr: ""
  Dec  9 13:04:35.879: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.879: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.880: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.880: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  9 13:04:35.928: INFO: Exec stderr: ""
  Dec  9 13:04:35.928: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4965 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:35.928: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:35.928: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:35.928: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4965/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  9 13:04:35.992: INFO: Exec stderr: ""
  Dec  9 13:04:35.992: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-4965" for this suite. @ 12/09/23 13:04:35.995
• [4.613 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 12/09/23 13:04:36.005
  Dec  9 13:04:36.005: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename csistoragecapacity @ 12/09/23 13:04:36.005
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:04:36.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:04:36.028
  STEP: getting /apis @ 12/09/23 13:04:36.033
  STEP: getting /apis/storage.k8s.io @ 12/09/23 13:04:36.037
  STEP: getting /apis/storage.k8s.io/v1 @ 12/09/23 13:04:36.039
  STEP: creating @ 12/09/23 13:04:36.04
  STEP: watching @ 12/09/23 13:04:36.057
  Dec  9 13:04:36.057: INFO: starting watch
  STEP: getting @ 12/09/23 13:04:36.065
  STEP: listing in namespace @ 12/09/23 13:04:36.068
  STEP: listing across namespaces @ 12/09/23 13:04:36.071
  STEP: patching @ 12/09/23 13:04:36.075
  STEP: updating @ 12/09/23 13:04:36.079
  Dec  9 13:04:36.084: INFO: waiting for watch events with expected annotations in namespace
  Dec  9 13:04:36.084: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 12/09/23 13:04:36.084
  STEP: deleting a collection @ 12/09/23 13:04:36.097
  Dec  9 13:04:36.113: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-8013" for this suite. @ 12/09/23 13:04:36.116
• [0.118 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 12/09/23 13:04:36.124
  Dec  9 13:04:36.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pod-network-test @ 12/09/23 13:04:36.125
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:04:36.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:04:36.144
  STEP: Performing setup for networking test in namespace pod-network-test-1580 @ 12/09/23 13:04:36.147
  STEP: creating a selector @ 12/09/23 13:04:36.147
  STEP: Creating the service pods in kubernetes @ 12/09/23 13:04:36.147
  Dec  9 13:04:36.148: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 12/09/23 13:04:48.222
  Dec  9 13:04:50.241: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  9 13:04:50.241: INFO: Breadth first check of 192.168.201.221 on host 172.31.38.129...
  Dec  9 13:04:50.244: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.26:9080/dial?request=hostname&protocol=http&host=192.168.201.221&port=8083&tries=1'] Namespace:pod-network-test-1580 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:50.244: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:50.245: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:50.245: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1580/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.26%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.201.221%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  9 13:04:50.303: INFO: Waiting for responses: map[]
  Dec  9 13:04:50.303: INFO: reached 192.168.201.221 after 0/1 tries
  Dec  9 13:04:50.303: INFO: Breadth first check of 192.168.34.24 on host 172.31.77.176...
  Dec  9 13:04:50.306: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.26:9080/dial?request=hostname&protocol=http&host=192.168.34.24&port=8083&tries=1'] Namespace:pod-network-test-1580 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:50.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:50.306: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:50.306: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1580/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.26%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.34.24%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  9 13:04:50.365: INFO: Waiting for responses: map[]
  Dec  9 13:04:50.365: INFO: reached 192.168.34.24 after 0/1 tries
  Dec  9 13:04:50.365: INFO: Breadth first check of 192.168.250.125 on host 172.31.80.205...
  Dec  9 13:04:50.368: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.26:9080/dial?request=hostname&protocol=http&host=192.168.250.125&port=8083&tries=1'] Namespace:pod-network-test-1580 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:04:50.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:04:50.369: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:04:50.369: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1580/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.26%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.250.125%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  9 13:04:50.433: INFO: Waiting for responses: map[]
  Dec  9 13:04:50.434: INFO: reached 192.168.250.125 after 0/1 tries
  Dec  9 13:04:50.434: INFO: Going to retry 0 out of 3 pods....
  Dec  9 13:04:50.434: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1580" for this suite. @ 12/09/23 13:04:50.437
• [14.321 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 12/09/23 13:04:50.446
  Dec  9 13:04:50.446: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename init-container @ 12/09/23 13:04:50.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:04:50.462
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:04:50.466
  STEP: creating the pod @ 12/09/23 13:04:50.47
  Dec  9 13:04:50.470: INFO: PodSpec: initContainers in spec.initContainers
  Dec  9 13:05:31.786: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-1b677f4c-09bd-49a9-8cfc-a3d042ca251b", GenerateName:"", Namespace:"init-container-7313", SelfLink:"", UID:"ed349dfa-64f6-4f2d-9cbc-96d540e3e722", ResourceVersion:"21776", Generation:0, CreationTimestamp:time.Date(2023, time.December, 9, 13, 4, 50, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"470151923"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 9, 13, 4, 50, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ef42e8), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 9, 13, 5, 31, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc000ef4360), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-pvlsg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc00477c1c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pvlsg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pvlsg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-pvlsg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004988818), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-77-176", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00480e310), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0049888a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0049888c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0049888c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0049888cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0014d4110), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 9, 13, 4, 50, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 9, 13, 4, 50, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 9, 13, 4, 50, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 9, 13, 4, 50, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.77.176", HostIPs:[]v1.HostIP(nil), PodIP:"192.168.34.30", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.34.30"}}, StartTime:time.Date(2023, time.December, 9, 13, 4, 50, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00480e3f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00480e460)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://251f77147a6a03d8932f8c4a4e0f0fbae8b65afb9f66c07483c2bb793e272272", Started:(*bool)(0xc00498896f), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00477c240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(0xc004988975), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00477c220), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc004988944), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Dec  9 13:05:31.787: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-7313" for this suite. @ 12/09/23 13:05:31.792
• [41.352 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 12/09/23 13:05:31.799
  Dec  9 13:05:31.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/09/23 13:05:31.799
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:05:31.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:05:31.822
  Dec  9 13:05:31.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:05:32.368: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7559" for this suite. @ 12/09/23 13:05:32.375
• [0.583 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 12/09/23 13:05:32.383
  Dec  9 13:05:32.383: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:05:32.384
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:05:32.4
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:05:32.404
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:05:32.407
  STEP: Saw pod success @ 12/09/23 13:05:34.424
  Dec  9 13:05:34.427: INFO: Trying to get logs from node ip-172-31-38-129 pod downwardapi-volume-9ce7278f-4542-4306-9dcb-afada1f3f5f6 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:05:34.447
  Dec  9 13:05:34.465: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1261" for this suite. @ 12/09/23 13:05:34.469
• [2.091 seconds]
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 12/09/23 13:05:34.475
  Dec  9 13:05:34.475: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pod-network-test @ 12/09/23 13:05:34.475
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:05:34.492
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:05:34.495
  STEP: Performing setup for networking test in namespace pod-network-test-8050 @ 12/09/23 13:05:34.499
  STEP: creating a selector @ 12/09/23 13:05:34.499
  STEP: Creating the service pods in kubernetes @ 12/09/23 13:05:34.499
  Dec  9 13:05:34.499: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 12/09/23 13:05:56.608
  Dec  9 13:05:58.623: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  9 13:05:58.623: INFO: Breadth first check of 192.168.201.194 on host 172.31.38.129...
  Dec  9 13:05:58.627: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.25:9080/dial?request=hostname&protocol=udp&host=192.168.201.194&port=8081&tries=1'] Namespace:pod-network-test-8050 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:05:58.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:05:58.627: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:05:58.627: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8050/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.25%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.201.194%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  9 13:05:58.682: INFO: Waiting for responses: map[]
  Dec  9 13:05:58.682: INFO: reached 192.168.201.194 after 0/1 tries
  Dec  9 13:05:58.682: INFO: Breadth first check of 192.168.34.36 on host 172.31.77.176...
  Dec  9 13:05:58.685: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.25:9080/dial?request=hostname&protocol=udp&host=192.168.34.36&port=8081&tries=1'] Namespace:pod-network-test-8050 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:05:58.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:05:58.686: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:05:58.686: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8050/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.25%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.34.36%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  9 13:05:58.748: INFO: Waiting for responses: map[]
  Dec  9 13:05:58.748: INFO: reached 192.168.34.36 after 0/1 tries
  Dec  9 13:05:58.748: INFO: Breadth first check of 192.168.250.126 on host 172.31.80.205...
  Dec  9 13:05:58.753: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.25:9080/dial?request=hostname&protocol=udp&host=192.168.250.126&port=8081&tries=1'] Namespace:pod-network-test-8050 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:05:58.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:05:58.753: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:05:58.753: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8050/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.25%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.250.126%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  9 13:05:58.805: INFO: Waiting for responses: map[]
  Dec  9 13:05:58.805: INFO: reached 192.168.250.126 after 0/1 tries
  Dec  9 13:05:58.805: INFO: Going to retry 0 out of 3 pods....
  Dec  9 13:05:58.805: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8050" for this suite. @ 12/09/23 13:05:58.81
• [24.343 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 12/09/23 13:05:58.818
  Dec  9 13:05:58.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:05:58.819
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:05:58.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:05:58.838
  STEP: Creating the pod @ 12/09/23 13:05:58.841
  Dec  9 13:06:01.390: INFO: Successfully updated pod "annotationupdate73893f3c-b4fe-4107-ac5c-5b8a0384b6d4"
  Dec  9 13:06:05.410: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8599" for this suite. @ 12/09/23 13:06:05.414
• [6.603 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3552
  STEP: Creating a kubernetes client @ 12/09/23 13:06:05.422
  Dec  9 13:06:05.422: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 13:06:05.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:05.434
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:05.438
  STEP: creating a collection of services @ 12/09/23 13:06:05.443
  Dec  9 13:06:05.443: INFO: Creating e2e-svc-a-z94n7
  Dec  9 13:06:05.453: INFO: Creating e2e-svc-b-g7jc7
  Dec  9 13:06:05.462: INFO: Creating e2e-svc-c-xxccn
  STEP: deleting service collection @ 12/09/23 13:06:05.479
  Dec  9 13:06:05.507: INFO: Collection of services has been deleted
  Dec  9 13:06:05.507: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1821" for this suite. @ 12/09/23 13:06:05.51
• [0.095 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 12/09/23 13:06:05.517
  Dec  9 13:06:05.517: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:06:05.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:05.532
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:05.536
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:06:05.54
  STEP: Saw pod success @ 12/09/23 13:06:09.562
  Dec  9 13:06:09.566: INFO: Trying to get logs from node ip-172-31-38-129 pod downwardapi-volume-769e0a40-74a0-445c-9185-934945631da9 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:06:09.574
  Dec  9 13:06:09.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2224" for this suite. @ 12/09/23 13:06:09.596
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 12/09/23 13:06:09.604
  Dec  9 13:06:09.604: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:06:09.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:09.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:09.628
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:06:09.632
  STEP: Saw pod success @ 12/09/23 13:06:13.661
  Dec  9 13:06:13.664: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-194161db-9770-4fbc-91f7-24932528d809 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:06:13.67
  Dec  9 13:06:13.688: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-616" for this suite. @ 12/09/23 13:06:13.693
• [4.094 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 12/09/23 13:06:13.699
  Dec  9 13:06:13.699: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename limitrange @ 12/09/23 13:06:13.7
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:13.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:13.72
  STEP: Creating a LimitRange @ 12/09/23 13:06:13.723
  STEP: Setting up watch @ 12/09/23 13:06:13.724
  STEP: Submitting a LimitRange @ 12/09/23 13:06:13.826
  STEP: Verifying LimitRange creation was observed @ 12/09/23 13:06:13.832
  STEP: Fetching the LimitRange to ensure it has proper values @ 12/09/23 13:06:13.832
  Dec  9 13:06:13.836: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec  9 13:06:13.836: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 12/09/23 13:06:13.836
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 12/09/23 13:06:13.842
  Dec  9 13:06:13.847: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec  9 13:06:13.847: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 12/09/23 13:06:13.848
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 12/09/23 13:06:13.856
  Dec  9 13:06:13.859: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Dec  9 13:06:13.859: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 12/09/23 13:06:13.859
  STEP: Failing to create a Pod with more than max resources @ 12/09/23 13:06:13.861
  STEP: Updating a LimitRange @ 12/09/23 13:06:13.863
  STEP: Verifying LimitRange updating is effective @ 12/09/23 13:06:13.867
  STEP: Creating a Pod with less than former min resources @ 12/09/23 13:06:15.873
  STEP: Failing to create a Pod with more than max resources @ 12/09/23 13:06:15.879
  STEP: Deleting a LimitRange @ 12/09/23 13:06:15.886
  STEP: Verifying the LimitRange was deleted @ 12/09/23 13:06:15.896
  Dec  9 13:06:20.901: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 12/09/23 13:06:20.902
  Dec  9 13:06:20.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-981" for this suite. @ 12/09/23 13:06:20.922
• [7.232 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 12/09/23 13:06:20.932
  Dec  9 13:06:20.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 13:06:20.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:20.952
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:20.956
  STEP: Creating secret with name secret-test-6441a77e-fc03-4efb-82a1-5eb7210fd589 @ 12/09/23 13:06:20.975
  STEP: Creating a pod to test consume secrets @ 12/09/23 13:06:20.981
  STEP: Saw pod success @ 12/09/23 13:06:25.002
  Dec  9 13:06:25.005: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-secrets-986e617f-c29b-42b6-b29c-0885bc7b7b69 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 13:06:25.013
  Dec  9 13:06:25.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6544" for this suite. @ 12/09/23 13:06:25.038
  STEP: Destroying namespace "secret-namespace-2208" for this suite. @ 12/09/23 13:06:25.044
• [4.118 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1575
  STEP: Creating a kubernetes client @ 12/09/23 13:06:25.051
  Dec  9 13:06:25.051: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:06:25.052
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:25.066
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:25.07
  STEP: creating the pod @ 12/09/23 13:06:25.075
  Dec  9 13:06:25.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 create -f -'
  Dec  9 13:06:25.438: INFO: stderr: ""
  Dec  9 13:06:25.438: INFO: stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 12/09/23 13:06:27.447
  Dec  9 13:06:27.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 label pods pause testing-label=testing-label-value'
  Dec  9 13:06:27.503: INFO: stderr: ""
  Dec  9 13:06:27.503: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 12/09/23 13:06:27.503
  Dec  9 13:06:27.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 get pod pause -L testing-label'
  Dec  9 13:06:27.550: INFO: stderr: ""
  Dec  9 13:06:27.550: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 12/09/23 13:06:27.55
  Dec  9 13:06:27.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 label pods pause testing-label-'
  Dec  9 13:06:27.604: INFO: stderr: ""
  Dec  9 13:06:27.604: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 12/09/23 13:06:27.604
  Dec  9 13:06:27.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 get pod pause -L testing-label'
  Dec  9 13:06:27.654: INFO: stderr: ""
  Dec  9 13:06:27.654: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 12/09/23 13:06:27.654
  Dec  9 13:06:27.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 delete --grace-period=0 --force -f -'
  Dec  9 13:06:27.714: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  9 13:06:27.714: INFO: stdout: "pod \"pause\" force deleted\n"
  Dec  9 13:06:27.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 get rc,svc -l name=pause --no-headers'
  Dec  9 13:06:27.769: INFO: stderr: "No resources found in kubectl-8001 namespace.\n"
  Dec  9 13:06:27.769: INFO: stdout: ""
  Dec  9 13:06:27.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8001 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec  9 13:06:27.818: INFO: stderr: ""
  Dec  9 13:06:27.818: INFO: stdout: ""
  Dec  9 13:06:27.818: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8001" for this suite. @ 12/09/23 13:06:27.822
• [2.779 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 12/09/23 13:06:27.831
  Dec  9 13:06:27.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:06:27.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:27.843
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:27.847
  STEP: Creating configMap that has name configmap-test-emptyKey-2fc74cb0-60af-4ecc-9bd2-3ad2c1422817 @ 12/09/23 13:06:27.85
  Dec  9 13:06:27.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2369" for this suite. @ 12/09/23 13:06:27.856
• [0.031 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 12/09/23 13:06:27.863
  Dec  9 13:06:27.863: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename subjectreview @ 12/09/23 13:06:27.864
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:27.879
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:27.882
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-6809" @ 12/09/23 13:06:27.886
  Dec  9 13:06:27.891: INFO: saUsername: "system:serviceaccount:subjectreview-6809:e2e"
  Dec  9 13:06:27.891: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-6809"}
  Dec  9 13:06:27.891: INFO: saUID: "2afaa618-2ead-417b-94af-0483e9b5be93"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-6809:e2e" @ 12/09/23 13:06:27.891
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-6809:e2e" @ 12/09/23 13:06:27.891
  Dec  9 13:06:27.893: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-6809:e2e" api 'list' configmaps in "subjectreview-6809" namespace @ 12/09/23 13:06:27.893
  Dec  9 13:06:27.895: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-6809:e2e" @ 12/09/23 13:06:27.895
  Dec  9 13:06:27.897: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Dec  9 13:06:27.897: INFO: LocalSubjectAccessReview has been verified
  Dec  9 13:06:27.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-6809" for this suite. @ 12/09/23 13:06:27.901
• [0.047 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 12/09/23 13:06:27.912
  Dec  9 13:06:27.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svcaccounts @ 12/09/23 13:06:27.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:27.922
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:27.926
  STEP: Creating ServiceAccount "e2e-sa-5qh24"  @ 12/09/23 13:06:27.929
  Dec  9 13:06:27.935: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-5qh24"  @ 12/09/23 13:06:27.935
  Dec  9 13:06:27.943: INFO: AutomountServiceAccountToken: true
  Dec  9 13:06:27.943: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-6628" for this suite. @ 12/09/23 13:06:27.946
• [0.041 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 12/09/23 13:06:27.952
  Dec  9 13:06:27.952: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 13:06:27.953
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:27.968
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:27.972
  STEP: Creating a ResourceQuota @ 12/09/23 13:06:27.977
  STEP: Getting a ResourceQuota @ 12/09/23 13:06:27.982
  STEP: Listing all ResourceQuotas with LabelSelector @ 12/09/23 13:06:27.986
  STEP: Patching the ResourceQuota @ 12/09/23 13:06:27.99
  STEP: Deleting a Collection of ResourceQuotas @ 12/09/23 13:06:27.995
  STEP: Verifying the deleted ResourceQuota @ 12/09/23 13:06:28.003
  Dec  9 13:06:28.007: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2262" for this suite. @ 12/09/23 13:06:28.01
• [0.066 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 12/09/23 13:06:28.019
  Dec  9 13:06:28.019: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pod-network-test @ 12/09/23 13:06:28.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:28.035
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:28.038
  STEP: Performing setup for networking test in namespace pod-network-test-251 @ 12/09/23 13:06:28.041
  STEP: creating a selector @ 12/09/23 13:06:28.041
  STEP: Creating the service pods in kubernetes @ 12/09/23 13:06:28.041
  Dec  9 13:06:28.041: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  STEP: Creating test pods @ 12/09/23 13:06:40.132
  Dec  9 13:06:42.169: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  9 13:06:42.169: INFO: Going to poll 192.168.201.238 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec  9 13:06:42.172: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.201.238 8081 | grep -v '^\s*$'] Namespace:pod-network-test-251 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:06:42.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:06:42.172: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:06:42.172: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-251/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.201.238+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  9 13:06:43.217: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec  9 13:06:43.217: INFO: Going to poll 192.168.34.54 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec  9 13:06:43.221: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.34.54 8081 | grep -v '^\s*$'] Namespace:pod-network-test-251 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:06:43.221: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:06:43.221: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:06:43.221: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-251/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.34.54+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  9 13:06:44.282: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec  9 13:06:44.282: INFO: Going to poll 192.168.250.127 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec  9 13:06:44.286: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.250.127 8081 | grep -v '^\s*$'] Namespace:pod-network-test-251 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:06:44.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:06:44.287: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:06:44.287: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-251/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.250.127+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  9 13:06:45.348: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec  9 13:06:45.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-251" for this suite. @ 12/09/23 13:06:45.353
• [17.341 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1806
  STEP: Creating a kubernetes client @ 12/09/23 13:06:45.361
  Dec  9 13:06:45.361: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:06:45.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:45.378
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:45.382
  STEP: Starting the proxy @ 12/09/23 13:06:45.385
  Dec  9 13:06:45.386: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-2811 proxy --unix-socket=/tmp/kubectl-proxy-unix1245364668/test'
  STEP: retrieving proxy /api/ output @ 12/09/23 13:06:45.419
  Dec  9 13:06:45.420: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2811" for this suite. @ 12/09/23 13:06:45.424
• [0.071 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 12/09/23 13:06:45.433
  Dec  9 13:06:45.433: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 13:06:45.433
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:45.45
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:45.454
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 12/09/23 13:06:45.457
  Dec  9 13:06:45.458: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:06:46.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:06:52.038: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-6761" for this suite. @ 12/09/23 13:06:52.045
• [6.620 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 12/09/23 13:06:52.053
  Dec  9 13:06:52.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/09/23 13:06:52.054
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:52.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:52.071
  STEP: create the container to handle the HTTPGet hook request. @ 12/09/23 13:06:52.076
  STEP: create the pod with lifecycle hook @ 12/09/23 13:06:54.096
  STEP: delete the pod with lifecycle hook @ 12/09/23 13:06:56.113
  STEP: check prestop hook @ 12/09/23 13:06:58.126
  Dec  9 13:06:58.140: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6692" for this suite. @ 12/09/23 13:06:58.144
• [6.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 12/09/23 13:06:58.152
  Dec  9 13:06:58.152: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename runtimeclass @ 12/09/23 13:06:58.152
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:58.17
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:58.172
  STEP: Deleting RuntimeClass runtimeclass-791-delete-me @ 12/09/23 13:06:58.178
  STEP: Waiting for the RuntimeClass to disappear @ 12/09/23 13:06:58.184
  Dec  9 13:06:58.192: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-791" for this suite. @ 12/09/23 13:06:58.195
• [0.050 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 12/09/23 13:06:58.202
  Dec  9 13:06:58.202: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename events @ 12/09/23 13:06:58.202
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:58.216
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:58.218
  STEP: Create set of events @ 12/09/23 13:06:58.22
  Dec  9 13:06:58.227: INFO: created test-event-1
  Dec  9 13:06:58.231: INFO: created test-event-2
  Dec  9 13:06:58.234: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 12/09/23 13:06:58.234
  STEP: delete collection of events @ 12/09/23 13:06:58.237
  Dec  9 13:06:58.237: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/09/23 13:06:58.258
  Dec  9 13:06:58.258: INFO: requesting list of events to confirm quantity
  Dec  9 13:06:58.260: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-7731" for this suite. @ 12/09/23 13:06:58.263
• [0.068 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 12/09/23 13:06:58.27
  Dec  9 13:06:58.270: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:06:58.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:06:58.285
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:06:58.287
  STEP: Setting up server cert @ 12/09/23 13:06:58.311
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:06:58.623
  STEP: Deploying the webhook pod @ 12/09/23 13:06:58.63
  STEP: Wait for the deployment to be ready @ 12/09/23 13:06:58.64
  Dec  9 13:06:58.646: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 13:07:00.655
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:07:00.664
  Dec  9 13:07:01.664: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 12/09/23 13:07:01.671
  STEP: Creating a custom resource definition that should be denied by the webhook @ 12/09/23 13:07:01.686
  Dec  9 13:07:01.686: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:07:01.693: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6914" for this suite. @ 12/09/23 13:07:01.736
  STEP: Destroying namespace "webhook-markers-3651" for this suite. @ 12/09/23 13:07:01.742
• [3.482 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 12/09/23 13:07:01.752
  Dec  9 13:07:01.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:07:01.753
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:01.771
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:01.774
  STEP: Creating a pod to test emptydir volume type on node default medium @ 12/09/23 13:07:01.775
  STEP: Saw pod success @ 12/09/23 13:07:05.796
  Dec  9 13:07:05.799: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-c2e8a655-7b1c-46ee-a7ec-31f4c60c3304 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:07:05.81
  Dec  9 13:07:05.827: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1005" for this suite. @ 12/09/23 13:07:05.831
• [4.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 12/09/23 13:07:05.837
  Dec  9 13:07:05.837: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename field-validation @ 12/09/23 13:07:05.838
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:05.856
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:05.858
  Dec  9 13:07:05.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:07:08.940: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1115" for this suite. @ 12/09/23 13:07:08.954
• [3.123 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 12/09/23 13:07:08.963
  Dec  9 13:07:08.963: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 13:07:08.964
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:08.983
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:08.985
  STEP: creating secret secrets-2515/secret-test-839f6864-45dd-475f-be39-5f43680d5f8a @ 12/09/23 13:07:08.987
  STEP: Creating a pod to test consume secrets @ 12/09/23 13:07:08.991
  STEP: Saw pod success @ 12/09/23 13:07:13.009
  Dec  9 13:07:13.012: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-configmaps-0f23f1c2-eab5-4101-b6f4-4bd5c39fb9e9 container env-test: <nil>
  STEP: delete the pod @ 12/09/23 13:07:13.019
  Dec  9 13:07:13.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2515" for this suite. @ 12/09/23 13:07:13.036
• [4.080 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 12/09/23 13:07:13.043
  Dec  9 13:07:13.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/09/23 13:07:13.044
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:13.059
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:13.061
  Dec  9 13:07:13.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:07:16.363: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2711" for this suite. @ 12/09/23 13:07:16.367
• [3.334 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 12/09/23 13:07:16.378
  Dec  9 13:07:16.378: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:07:16.379
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:16.399
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:16.408
  STEP: Setting up server cert @ 12/09/23 13:07:16.44
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:07:16.642
  STEP: Deploying the webhook pod @ 12/09/23 13:07:16.646
  STEP: Wait for the deployment to be ready @ 12/09/23 13:07:16.657
  Dec  9 13:07:16.663: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 13:07:18.672
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:07:18.681
  Dec  9 13:07:19.681: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 12/09/23 13:07:19.687
  STEP: create a namespace for the webhook @ 12/09/23 13:07:19.702
  STEP: create a configmap should be unconditionally rejected by the webhook @ 12/09/23 13:07:19.719
  Dec  9 13:07:19.759: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-210" for this suite. @ 12/09/23 13:07:19.805
  STEP: Destroying namespace "webhook-markers-8521" for this suite. @ 12/09/23 13:07:19.811
  STEP: Destroying namespace "fail-closed-namespace-1937" for this suite. @ 12/09/23 13:07:19.818
• [3.446 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 12/09/23 13:07:19.825
  Dec  9 13:07:19.825: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:07:19.826
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:19.841
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:19.843
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:07:19.844
  STEP: Saw pod success @ 12/09/23 13:07:23.862
  Dec  9 13:07:23.865: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-f82b8f77-917e-4ca5-b0ed-514ac274fe31 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:07:23.872
  Dec  9 13:07:23.887: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5516" for this suite. @ 12/09/23 13:07:23.891
• [4.073 seconds]
------------------------------
SSSS
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 12/09/23 13:07:23.898
  Dec  9 13:07:23.898: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename podtemplate @ 12/09/23 13:07:23.899
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:23.915
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:23.917
  Dec  9 13:07:23.944: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5255" for this suite. @ 12/09/23 13:07:23.947
• [0.056 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:901
  STEP: Creating a kubernetes client @ 12/09/23 13:07:23.955
  Dec  9 13:07:23.955: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 13:07:23.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:23.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:23.974
  STEP: Creating service test in namespace statefulset-8760 @ 12/09/23 13:07:23.976
  STEP: Creating statefulset ss in namespace statefulset-8760 @ 12/09/23 13:07:23.981
  Dec  9 13:07:23.991: INFO: Found 0 stateful pods, waiting for 1
  Dec  9 13:07:33.997: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 12/09/23 13:07:34.005
  STEP: updating a scale subresource @ 12/09/23 13:07:34.008
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/09/23 13:07:34.015
  STEP: Patch a scale subresource @ 12/09/23 13:07:34.018
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/09/23 13:07:34.041
  Dec  9 13:07:34.045: INFO: Deleting all statefulset in ns statefulset-8760
  Dec  9 13:07:34.050: INFO: Scaling statefulset ss to 0
  Dec  9 13:07:44.075: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 13:07:44.078: INFO: Deleting statefulset ss
  Dec  9 13:07:44.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-8760" for this suite. @ 12/09/23 13:07:44.095
• [20.147 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 12/09/23 13:07:44.102
  Dec  9 13:07:44.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 13:07:44.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:44.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:44.123
  Dec  9 13:07:44.124: INFO: Creating deployment "test-recreate-deployment"
  Dec  9 13:07:44.130: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Dec  9 13:07:44.136: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
  Dec  9 13:07:46.144: INFO: Waiting deployment "test-recreate-deployment" to complete
  Dec  9 13:07:46.146: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Dec  9 13:07:46.156: INFO: Updating deployment test-recreate-deployment
  Dec  9 13:07:46.156: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Dec  9 13:07:46.245: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4524",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ec36bb76-4d99-41d9-b074-e880f5f51fbf",
      ResourceVersion: (string) (len=5) "23248",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724064,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724064,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  9 13:07:46.250: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4524",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "21e6ba07-0460-4144-9ed4-e924e14797be",
      ResourceVersion: (string) (len=5) "23247",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "ec36bb76-4d99-41d9-b074-e880f5f51fbf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 63 33 36 62 62  37 36 2d 34 64 39 39 2d  |\"ec36bb76-4d99-|
              00000120  34 31 64 39 2d 62 30 37  34 2d 65 38 38 30 66 35  |41d9-b074-e880f5|
              00000130  66 35 31 66 62 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f51fbf\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45",
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:07:46.251: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Dec  9 13:07:46.251: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-dd4bc9d6d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4524",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "19f0377a-9294-4fef-ad4c-9e6acabec194",
      ResourceVersion: (string) (len=5) "23237",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724064,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "ec36bb76-4d99-41d9-b074-e880f5f51fbf",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 65 63 33 36 62 62  37 36 2d 34 64 39 39 2d  |\"ec36bb76-4d99-|
              00000120  34 31 64 39 2d 62 30 37  34 2d 65 38 38 30 66 35  |41d9-b074-e880f5|
              00000130  66 35 31 66 62 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f51fbf\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:07:46.257: INFO: Pod "test-recreate-deployment-76fb77d45-zggf9" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-zggf9",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-4524",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "52f74f3b-5ea8-40ae-9071-c5de647978f6",
      ResourceVersion: (string) (len=5) "23249",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "21e6ba07-0460-4144-9ed4-e924e14797be",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 32 31  65 36 62 61 30 37 2d 30  |d\":\"21e6ba07-0|
              00000090  34 36 30 2d 34 31 34 34  2d 39 65 64 34 2d 65 39  |460-4144-9ed4-e9|
              000000a0  32 34 65 31 34 37 39 37  62 65 5c 22 7d 22 3a 7b  |24e14797be\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-5pj6r",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-5pj6r",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 13:07:46.259: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4524" for this suite. @ 12/09/23 13:07:46.263
• [2.167 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 12/09/23 13:07:46.27
  Dec  9 13:07:46.270: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:07:46.27
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:46.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:46.289
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:07:46.292
  STEP: Saw pod success @ 12/09/23 13:07:48.312
  Dec  9 13:07:48.316: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-5273875a-5769-4af3-a4dd-09b5c5163f8a container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:07:48.322
  Dec  9 13:07:48.336: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-729" for this suite. @ 12/09/23 13:07:48.339
• [2.076 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 12/09/23 13:07:48.347
  Dec  9 13:07:48.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:07:48.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:48.362
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:48.365
  STEP: Setting up server cert @ 12/09/23 13:07:48.389
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:07:48.705
  STEP: Deploying the webhook pod @ 12/09/23 13:07:48.713
  STEP: Wait for the deployment to be ready @ 12/09/23 13:07:48.724
  Dec  9 13:07:48.731: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 13:07:50.74
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:07:50.748
  Dec  9 13:07:51.749: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 12/09/23 13:07:51.756
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 12/09/23 13:07:51.757
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 12/09/23 13:07:51.757
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 12/09/23 13:07:51.757
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 12/09/23 13:07:51.757
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/09/23 13:07:51.758
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/09/23 13:07:51.758
  Dec  9 13:07:51.758: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9780" for this suite. @ 12/09/23 13:07:51.796
  STEP: Destroying namespace "webhook-markers-4523" for this suite. @ 12/09/23 13:07:51.802
• [3.465 seconds]
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 12/09/23 13:07:51.812
  Dec  9 13:07:51.812: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:07:51.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:51.827
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:51.83
  STEP: creating a ConfigMap @ 12/09/23 13:07:51.832
  STEP: fetching the ConfigMap @ 12/09/23 13:07:51.837
  STEP: patching the ConfigMap @ 12/09/23 13:07:51.84
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 12/09/23 13:07:51.845
  STEP: deleting the ConfigMap by collection with a label selector @ 12/09/23 13:07:51.847
  STEP: listing all ConfigMaps in test namespace @ 12/09/23 13:07:51.856
  Dec  9 13:07:51.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5123" for this suite. @ 12/09/23 13:07:51.862
• [0.055 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 12/09/23 13:07:51.87
  Dec  9 13:07:51.870: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-webhook @ 12/09/23 13:07:51.871
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:51.887
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:51.889
  STEP: Setting up server cert @ 12/09/23 13:07:51.89
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/09/23 13:07:52.065
  STEP: Deploying the custom resource conversion webhook pod @ 12/09/23 13:07:52.071
  STEP: Wait for the deployment to be ready @ 12/09/23 13:07:52.082
  Dec  9 13:07:52.088: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  STEP: Deploying the webhook service @ 12/09/23 13:07:54.098
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:07:54.107
  Dec  9 13:07:55.107: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  9 13:07:55.113: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Creating a v1 custom resource @ 12/09/23 13:07:57.679
  STEP: v2 custom resource should be converted @ 12/09/23 13:07:57.685
  Dec  9 13:07:57.688: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-webhook-11" for this suite. @ 12/09/23 13:07:58.243
• [6.382 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 12/09/23 13:07:58.252
  Dec  9 13:07:58.252: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:07:58.253
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:07:58.27
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:07:58.272
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/09/23 13:07:58.274
  STEP: Saw pod success @ 12/09/23 13:08:02.293
  Dec  9 13:08:02.296: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-97500b6c-7fab-403d-a155-c7c0f789ff52 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:08:02.306
  Dec  9 13:08:02.319: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5502" for this suite. @ 12/09/23 13:08:02.323
• [4.077 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 12/09/23 13:08:02.329
  Dec  9 13:08:02.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 13:08:02.33
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:02.346
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:02.348
  Dec  9 13:08:02.357: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  Dec  9 13:08:07.361: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/09/23 13:08:07.361
  Dec  9 13:08:07.361: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 12/09/23 13:08:07.369
  Dec  9 13:08:07.381: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7840",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "31b7ddd9-efd0-4898-b396-74a3094e2b22",
      ResourceVersion: (string) (len=5) "23583",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724087,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724087,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 0,
      Replicas: (int32) 0,
      UpdatedReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) <nil>,
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  9 13:08:07.386: INFO: New ReplicaSet "test-cleanup-deployment-58dcc84f74" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-58dcc84f74",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7840",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4c9da424-2d6d-4181-801f-17f2039b5f22",
      ResourceVersion: (string) (len=5) "23585",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724087,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "31b7ddd9-efd0-4898-b396-74a3094e2b22",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724087,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 33 31 62 37 64 64  64 39 2d 65 66 64 30 2d  |\"31b7ddd9-efd0-|
              00000120  34 38 39 38 2d 62 33 39  36 2d 37 34 61 33 30 39  |4898-b396-74a309|
              00000130  34 65 32 62 32 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |4e2b22\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 0,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:08:07.386: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
  Dec  9 13:08:07.386: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7840",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "77517d10-a6cd-49cb-9322-b4e00fa7aeac",
      ResourceVersion: (string) (len=5) "23584",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724082,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "31b7ddd9-efd0-4898-b396-74a3094e2b22",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724082,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=483) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000050  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000060  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000070  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000080  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000090  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              000000a0  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000b0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000c0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000d0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000e0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000f0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000100  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000110  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000120  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000130  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000140  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000160  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000170  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000180  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000190  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000001a0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001b0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001c0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001d0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001e0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724083,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724087,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=103) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000020  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              00000030  22 75 69 64 5c 22 3a 5c  22 33 31 62 37 64 64 64  |"uid\":\"31b7ddd|
              00000040  39 2d 65 66 64 30 2d 34  38 39 38 2d 62 33 39 36  |9-efd0-4898-b396|
              00000050  2d 37 34 61 33 30 39 34  65 32 62 32 32 5c 22 7d  |-74a3094e2b22\"}|
              00000060  22 3a 7b 7d 7d 7d 7d                              |":{}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:08:07.396: INFO: Pod "test-cleanup-controller-7wdnd" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=29) "test-cleanup-controller-7wdnd",
      GenerateName: (string) (len=24) "test-cleanup-controller-",
      Namespace: (string) (len=15) "deployment-7840",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "de249d01-0bd6-40e4-b3a2-565a8ab754a8",
      ResourceVersion: (string) (len=5) "23560",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724082,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=23) "test-cleanup-controller",
          UID: (types.UID) (len=36) "77517d10-a6cd-49cb-9322-b4e00fa7aeac",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724082,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=500) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 2c 22 66  |},"f:pod":{}},"f|
              00000050  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000060  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000070  75 69 64 5c 22 3a 5c 22  37 37 35 31 37 64 31 30  |uid\":\"77517d10|
              00000080  2d 61 36 63 64 2d 34 39  63 62 2d 39 33 32 32 2d  |-a6cd-49cb-9322-|
              00000090  62 34 65 30 30 66 61 37  61 65 61 63 5c 22 7d 22  |b4e00fa7aeac\"}"|
              000000a0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000b0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000c0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              000000d0  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              000000e0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              000000f0  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000100  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000110  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000120  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000130  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000140  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000150  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000160  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              00000170  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              00000180  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              00000190  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001a0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001b0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001c0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              000001d0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              000001e0  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              000001f0  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724083,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=519) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 35 5c 22 7d 22  |192.168.34.5\"}"|
              000001e0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 70 22 3a  |:{".":{},"f:ip":|
              000001f0  7b 7d 7d 7d 2c 22 66 3a  73 74 61 72 74 54 69 6d  |{}}},"f:startTim|
              00000200  65 22 3a 7b 7d 7d 7d                              |e":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-mfj69",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-mfj69",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)(<nil>),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724082,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724083,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724083,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724082,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=12) "192.168.34.5",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=12) "192.168.34.5"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724082,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837724082,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://85ff87da59e185e29eadb85db2cbd1b8ccedd1d262dbd26d8c33e360da3dc012",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 13:08:07.404: INFO: Pod "test-cleanup-deployment-58dcc84f74-wwk7c" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-58dcc84f74-wwk7c",
      GenerateName: (string) (len=35) "test-cleanup-deployment-58dcc84f74-",
      Namespace: (string) (len=15) "deployment-7840",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "27300229-3f98-41d2-9cd9-82b97f6a2943",
      ResourceVersion: (string) (len=5) "23586",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837724087,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74",
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-58dcc84f74",
          UID: (types.UID) (len=36) "4c9da424-2d6d-4181-801f-17f2039b5f22",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837724087,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 63  39 64 61 34 32 34 2d 32  |d\":\"4c9da424-2|
              00000090  64 36 64 2d 34 31 38 31  2d 38 30 31 66 2d 31 37  |d6d-4181-801f-17|
              000000a0  66 32 30 33 39 62 35 66  32 32 5c 22 7d 22 3a 7b  |f2039b5f22\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hzn8k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hzn8k",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 13:08:07.405: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7840" for this suite. @ 12/09/23 13:08:07.409
• [5.093 seconds]
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 12/09/23 13:08:07.423
  Dec  9 13:08:07.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replication-controller @ 12/09/23 13:08:07.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:07.439
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:07.44
  STEP: creating a ReplicationController @ 12/09/23 13:08:07.447
  STEP: waiting for RC to be added @ 12/09/23 13:08:07.452
  STEP: waiting for available Replicas @ 12/09/23 13:08:07.452
  STEP: patching ReplicationController @ 12/09/23 13:08:08.12
  STEP: waiting for RC to be modified @ 12/09/23 13:08:08.127
  STEP: patching ReplicationController status @ 12/09/23 13:08:08.128
  STEP: waiting for RC to be modified @ 12/09/23 13:08:08.133
  STEP: waiting for available Replicas @ 12/09/23 13:08:08.133
  STEP: fetching ReplicationController status @ 12/09/23 13:08:08.138
  STEP: patching ReplicationController scale @ 12/09/23 13:08:08.141
  STEP: waiting for RC to be modified @ 12/09/23 13:08:08.145
  STEP: waiting for ReplicationController's scale to be the max amount @ 12/09/23 13:08:08.147
  STEP: fetching ReplicationController; ensuring that it's patched @ 12/09/23 13:08:09.406
  STEP: updating ReplicationController status @ 12/09/23 13:08:09.41
  STEP: waiting for RC to be modified @ 12/09/23 13:08:09.416
  STEP: listing all ReplicationControllers @ 12/09/23 13:08:09.416
  STEP: checking that ReplicationController has expected values @ 12/09/23 13:08:09.421
  STEP: deleting ReplicationControllers by collection @ 12/09/23 13:08:09.421
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 12/09/23 13:08:09.428
  Dec  9 13:08:09.468: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1209 13:08:09.469216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-9373" for this suite. @ 12/09/23 13:08:09.472
• [2.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 12/09/23 13:08:09.481
  Dec  9 13:08:09.481: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 13:08:09.481
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:09.5
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:09.502
  STEP: Creating a pod to test env composition @ 12/09/23 13:08:09.504
  E1209 13:08:10.469364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:11.469461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:12.469559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:13.470244      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:08:13.526
  Dec  9 13:08:13.529: INFO: Trying to get logs from node ip-172-31-77-176 pod var-expansion-987fd11f-1fc0-4822-91cd-a909c1baf550 container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 13:08:13.536
  Dec  9 13:08:13.548: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9080" for this suite. @ 12/09/23 13:08:13.551
• [4.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 12/09/23 13:08:13.558
  Dec  9 13:08:13.558: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:08:13.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:13.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:13.579
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/09/23 13:08:13.581
  E1209 13:08:14.471100      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:15.471186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:16.471281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:17.471413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:08:17.605
  Dec  9 13:08:17.607: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-d0472bd0-bd1c-4375-b5e5-3028d1f9c6f1 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:08:17.615
  Dec  9 13:08:17.635: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2227" for this suite. @ 12/09/23 13:08:17.641
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 12/09/23 13:08:17.652
  Dec  9 13:08:17.652: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename watch @ 12/09/23 13:08:17.653
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:17.675
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:17.678
  STEP: creating a watch on configmaps with a certain label @ 12/09/23 13:08:17.695
  STEP: creating a new configmap @ 12/09/23 13:08:17.698
  STEP: modifying the configmap once @ 12/09/23 13:08:17.703
  STEP: changing the label value of the configmap @ 12/09/23 13:08:17.71
  STEP: Expecting to observe a delete notification for the watched object @ 12/09/23 13:08:17.718
  Dec  9 13:08:17.718: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6726  6b0eda71-2b51-4032-9342-ac17e2897f4c 23786 0 2023-12-09 13:08:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-09 13:08:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:08:17.718: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6726  6b0eda71-2b51-4032-9342-ac17e2897f4c 23787 0 2023-12-09 13:08:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-09 13:08:17 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:08:17.719: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6726  6b0eda71-2b51-4032-9342-ac17e2897f4c 23788 0 2023-12-09 13:08:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-09 13:08:17 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 12/09/23 13:08:17.719
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 12/09/23 13:08:17.726
  E1209 13:08:18.471905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:19.472113      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:20.472264      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:21.472362      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:22.472475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:23.472969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:24.473142      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:25.473388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:26.473609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:27.473693      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 12/09/23 13:08:27.727
  STEP: modifying the configmap a third time @ 12/09/23 13:08:27.735
  STEP: deleting the configmap @ 12/09/23 13:08:27.743
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 12/09/23 13:08:27.748
  Dec  9 13:08:27.748: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6726  6b0eda71-2b51-4032-9342-ac17e2897f4c 23834 0 2023-12-09 13:08:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-09 13:08:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:08:27.748: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6726  6b0eda71-2b51-4032-9342-ac17e2897f4c 23835 0 2023-12-09 13:08:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-09 13:08:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:08:27.749: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6726  6b0eda71-2b51-4032-9342-ac17e2897f4c 23836 0 2023-12-09 13:08:17 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-09 13:08:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:08:27.749: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6726" for this suite. @ 12/09/23 13:08:27.752
• [10.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 12/09/23 13:08:27.761
  Dec  9 13:08:27.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename podtemplate @ 12/09/23 13:08:27.761
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:27.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:27.78
  STEP: Create set of pod templates @ 12/09/23 13:08:27.782
  Dec  9 13:08:27.786: INFO: created test-podtemplate-1
  Dec  9 13:08:27.793: INFO: created test-podtemplate-2
  Dec  9 13:08:27.797: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 12/09/23 13:08:27.797
  STEP: delete collection of pod templates @ 12/09/23 13:08:27.799
  Dec  9 13:08:27.799: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 12/09/23 13:08:27.818
  Dec  9 13:08:27.818: INFO: requesting list of pod templates to confirm quantity
  Dec  9 13:08:27.821: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-3015" for this suite. @ 12/09/23 13:08:27.825
• [0.070 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 12/09/23 13:08:27.831
  Dec  9 13:08:27.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:08:27.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:27.849
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:27.851
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:08:27.852
  E1209 13:08:28.474211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:29.474309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:30.475325      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:31.475424      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:08:31.872
  Dec  9 13:08:31.875: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-8f7fe8b2-7058-4911-8f52-6567181acde2 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:08:31.881
  Dec  9 13:08:31.896: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4494" for this suite. @ 12/09/23 13:08:31.899
• [4.074 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 12/09/23 13:08:31.906
  Dec  9 13:08:31.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/09/23 13:08:31.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:31.924
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:31.926
  STEP: creating a target pod @ 12/09/23 13:08:31.928
  E1209 13:08:32.475698      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:33.475875      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 12/09/23 13:08:33.945
  E1209 13:08:34.476109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:35.476232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 12/09/23 13:08:35.963
  Dec  9 13:08:35.963: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-1562 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:08:35.963: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:08:35.963: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:08:35.963: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-1562/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Dec  9 13:08:36.024: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 12/09/23 13:08:36.031
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 12/09/23 13:08:36.035
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 12/09/23 13:08:36.044
  Dec  9 13:08:36.047: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-1562" for this suite. @ 12/09/23 13:08:36.05
• [4.151 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 12/09/23 13:08:36.058
  Dec  9 13:08:36.058: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename job @ 12/09/23 13:08:36.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:36.074
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:36.076
  STEP: Creating a job @ 12/09/23 13:08:36.08
  STEP: Ensuring job reaches completions @ 12/09/23 13:08:36.085
  E1209 13:08:36.476420      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:37.477280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:38.477405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:39.477501      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:40.478033      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:41.478259      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:42.478333      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:43.478586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:44.478691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:45.478859      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:08:46.088: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7534" for this suite. @ 12/09/23 13:08:46.092
• [10.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 12/09/23 13:08:46.099
  Dec  9 13:08:46.099: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:08:46.099
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:46.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:46.116
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/09/23 13:08:46.118
  E1209 13:08:46.479898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:47.480010      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:48.480968      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:49.481212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:08:50.135
  Dec  9 13:08:50.138: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-c42dd7a2-ac19-4912-8f91-b92b4af67786 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:08:50.149
  Dec  9 13:08:50.163: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6943" for this suite. @ 12/09/23 13:08:50.166
• [4.073 seconds]
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 12/09/23 13:08:50.172
  Dec  9 13:08:50.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 13:08:50.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:08:50.185
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:08:50.187
  STEP: Counting existing ResourceQuota @ 12/09/23 13:08:50.189
  E1209 13:08:50.482809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:51.482831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:52.483909      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:53.484153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:54.484382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/09/23 13:08:55.192
  STEP: Ensuring resource quota status is calculated @ 12/09/23 13:08:55.198
  E1209 13:08:55.484898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:56.485005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 12/09/23 13:08:57.202
  STEP: Ensuring ResourceQuota status captures the pod usage @ 12/09/23 13:08:57.217
  E1209 13:08:57.485419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:08:58.485729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 12/09/23 13:08:59.22
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 12/09/23 13:08:59.222
  STEP: Ensuring a pod cannot update its resource requirements @ 12/09/23 13:08:59.224
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 12/09/23 13:08:59.228
  E1209 13:08:59.485851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:00.486114      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/09/23 13:09:01.232
  STEP: Ensuring resource quota status released the pod usage @ 12/09/23 13:09:01.242
  E1209 13:09:01.486239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:02.486345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:03.246: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6197" for this suite. @ 12/09/23 13:09:03.25
• [13.088 seconds]
------------------------------
SS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 12/09/23 13:09:03.26
  Dec  9 13:09:03.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename containers @ 12/09/23 13:09:03.26
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:09:03.278
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:09:03.28
  STEP: Creating a pod to test override command @ 12/09/23 13:09:03.284
  E1209 13:09:03.487274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:04.487363      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:05.487828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:06.488222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:09:07.304
  Dec  9 13:09:07.306: INFO: Trying to get logs from node ip-172-31-77-176 pod client-containers-98f64c33-59db-4e3a-b6f0-eecf687c5df6 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:09:07.313
  Dec  9 13:09:07.329: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5915" for this suite. @ 12/09/23 13:09:07.332
• [4.081 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 12/09/23 13:09:07.34
  Dec  9 13:09:07.341: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:09:07.341
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:09:07.358
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:09:07.36
  STEP: Creating Pod @ 12/09/23 13:09:07.362
  E1209 13:09:07.488543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:08.488675      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 12/09/23 13:09:09.378
  Dec  9 13:09:09.378: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1675 PodName:pod-sharedvolume-b079389a-8cfd-44d1-806b-75994c070b45 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:09:09.378: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:09:09.379: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:09:09.379: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-1675/pods/pod-sharedvolume-b079389a-8cfd-44d1-806b-75994c070b45/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Dec  9 13:09:09.438: INFO: Exec stderr: ""
  Dec  9 13:09:09.438: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1675" for this suite. @ 12/09/23 13:09:09.442
• [2.108 seconds]
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 12/09/23 13:09:09.448
  Dec  9 13:09:09.448: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename disruption @ 12/09/23 13:09:09.449
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:09:09.467
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:09:09.469
  STEP: Waiting for the pdb to be processed @ 12/09/23 13:09:09.475
  E1209 13:09:09.489342      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:10.489580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 12/09/23 13:09:11.483
  E1209 13:09:11.490232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 12/09/23 13:09:11.493
  Dec  9 13:09:11.497: INFO: running pods: 0 < 1
  E1209 13:09:12.490683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:13.490842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 12/09/23 13:09:13.501
  STEP: Waiting for the pdb to be processed @ 12/09/23 13:09:13.512
  STEP: Patching PodDisruptionBudget status @ 12/09/23 13:09:13.518
  STEP: Waiting for the pdb to be processed @ 12/09/23 13:09:13.527
  Dec  9 13:09:13.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-5266" for this suite. @ 12/09/23 13:09:13.533
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 12/09/23 13:09:13.542
  Dec  9 13:09:13.542: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svc-latency @ 12/09/23 13:09:13.542
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:09:13.559
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:09:13.561
  Dec  9 13:09:13.563: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-2619 @ 12/09/23 13:09:13.563
  I1209 13:09:13.569246      18 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2619, replica count: 1
  E1209 13:09:14.491235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1209 13:09:14.620576      18 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 13:09:14.734: INFO: Created: latency-svc-fwf7n
  Dec  9 13:09:14.740: INFO: Got endpoints: latency-svc-fwf7n [19.73527ms]
  Dec  9 13:09:14.751: INFO: Created: latency-svc-pdpzx
  Dec  9 13:09:14.756: INFO: Created: latency-svc-prbnx
  Dec  9 13:09:14.758: INFO: Got endpoints: latency-svc-pdpzx [17.387598ms]
  Dec  9 13:09:14.764: INFO: Got endpoints: latency-svc-prbnx [22.720922ms]
  Dec  9 13:09:14.766: INFO: Created: latency-svc-k8cg8
  Dec  9 13:09:14.773: INFO: Got endpoints: latency-svc-k8cg8 [31.954886ms]
  Dec  9 13:09:14.774: INFO: Created: latency-svc-lzgwl
  Dec  9 13:09:14.779: INFO: Got endpoints: latency-svc-lzgwl [38.088089ms]
  Dec  9 13:09:14.783: INFO: Created: latency-svc-4qnh2
  Dec  9 13:09:14.789: INFO: Got endpoints: latency-svc-4qnh2 [48.090446ms]
  Dec  9 13:09:14.793: INFO: Created: latency-svc-w7zs7
  Dec  9 13:09:14.795: INFO: Created: latency-svc-mfrrr
  Dec  9 13:09:14.797: INFO: Got endpoints: latency-svc-w7zs7 [55.377265ms]
  Dec  9 13:09:14.802: INFO: Got endpoints: latency-svc-mfrrr [59.945119ms]
  Dec  9 13:09:14.807: INFO: Created: latency-svc-rqhzx
  Dec  9 13:09:14.813: INFO: Got endpoints: latency-svc-rqhzx [71.728529ms]
  Dec  9 13:09:14.816: INFO: Created: latency-svc-lj4s9
  Dec  9 13:09:14.822: INFO: Got endpoints: latency-svc-lj4s9 [80.757874ms]
  Dec  9 13:09:14.823: INFO: Created: latency-svc-l8frc
  Dec  9 13:09:14.827: INFO: Got endpoints: latency-svc-l8frc [85.59448ms]
  Dec  9 13:09:14.831: INFO: Created: latency-svc-cwmdn
  Dec  9 13:09:14.838: INFO: Got endpoints: latency-svc-cwmdn [96.250589ms]
  Dec  9 13:09:14.841: INFO: Created: latency-svc-phg2n
  Dec  9 13:09:14.845: INFO: Got endpoints: latency-svc-phg2n [103.459355ms]
  Dec  9 13:09:14.848: INFO: Created: latency-svc-qtl6s
  Dec  9 13:09:14.851: INFO: Got endpoints: latency-svc-qtl6s [109.573237ms]
  Dec  9 13:09:14.856: INFO: Created: latency-svc-q8w7p
  Dec  9 13:09:14.860: INFO: Got endpoints: latency-svc-q8w7p [118.017934ms]
  Dec  9 13:09:14.865: INFO: Created: latency-svc-xpdlj
  Dec  9 13:09:14.870: INFO: Got endpoints: latency-svc-xpdlj [128.690917ms]
  Dec  9 13:09:14.871: INFO: Created: latency-svc-skg8g
  Dec  9 13:09:14.877: INFO: Created: latency-svc-d2rt9
  Dec  9 13:09:14.878: INFO: Got endpoints: latency-svc-skg8g [120.007539ms]
  Dec  9 13:09:14.886: INFO: Got endpoints: latency-svc-d2rt9 [122.66439ms]
  Dec  9 13:09:14.889: INFO: Created: latency-svc-5q5k8
  Dec  9 13:09:14.892: INFO: Created: latency-svc-p46rw
  Dec  9 13:09:14.898: INFO: Created: latency-svc-jqk85
  Dec  9 13:09:14.904: INFO: Created: latency-svc-lnfs4
  Dec  9 13:09:14.910: INFO: Created: latency-svc-f8d26
  Dec  9 13:09:14.911: INFO: Got endpoints: latency-svc-5q5k8 [138.026428ms]
  Dec  9 13:09:14.917: INFO: Got endpoints: latency-svc-p46rw [137.663768ms]
  Dec  9 13:09:14.920: INFO: Created: latency-svc-pz5n7
  Dec  9 13:09:14.932: INFO: Got endpoints: latency-svc-lnfs4 [134.29038ms]
  Dec  9 13:09:14.932: INFO: Got endpoints: latency-svc-jqk85 [142.234748ms]
  Dec  9 13:09:14.932: INFO: Created: latency-svc-nj9gm
  Dec  9 13:09:14.934: INFO: Got endpoints: latency-svc-f8d26 [132.727601ms]
  Dec  9 13:09:14.939: INFO: Created: latency-svc-l7prk
  Dec  9 13:09:14.942: INFO: Created: latency-svc-ghl8k
  Dec  9 13:09:14.950: INFO: Created: latency-svc-k5w5c
  Dec  9 13:09:14.951: INFO: Got endpoints: latency-svc-pz5n7 [137.643714ms]
  Dec  9 13:09:14.951: INFO: Got endpoints: latency-svc-nj9gm [128.451714ms]
  Dec  9 13:09:14.955: INFO: Got endpoints: latency-svc-ghl8k [116.710113ms]
  Dec  9 13:09:14.955: INFO: Got endpoints: latency-svc-l7prk [127.792619ms]
  Dec  9 13:09:14.960: INFO: Created: latency-svc-gtrkz
  Dec  9 13:09:14.967: INFO: Created: latency-svc-ccggl
  Dec  9 13:09:14.973: INFO: Got endpoints: latency-svc-k5w5c [128.092873ms]
  Dec  9 13:09:14.973: INFO: Got endpoints: latency-svc-gtrkz [122.138035ms]
  Dec  9 13:09:14.978: INFO: Created: latency-svc-bvtps
  Dec  9 13:09:14.982: INFO: Got endpoints: latency-svc-ccggl [121.828756ms]
  Dec  9 13:09:14.985: INFO: Created: latency-svc-tfdn5
  Dec  9 13:09:14.992: INFO: Got endpoints: latency-svc-bvtps [121.856374ms]
  Dec  9 13:09:14.996: INFO: Created: latency-svc-ccmh2
  Dec  9 13:09:15.000: INFO: Got endpoints: latency-svc-tfdn5 [121.577747ms]
  Dec  9 13:09:15.007: INFO: Created: latency-svc-sshdn
  Dec  9 13:09:15.010: INFO: Got endpoints: latency-svc-ccmh2 [123.358738ms]
  Dec  9 13:09:15.010: INFO: Created: latency-svc-qr7tx
  Dec  9 13:09:15.012: INFO: Got endpoints: latency-svc-sshdn [100.502163ms]
  Dec  9 13:09:15.017: INFO: Created: latency-svc-wwn29
  Dec  9 13:09:15.024: INFO: Got endpoints: latency-svc-qr7tx [106.397703ms]
  Dec  9 13:09:15.028: INFO: Created: latency-svc-klj45
  Dec  9 13:09:15.030: INFO: Created: latency-svc-dfvpj
  Dec  9 13:09:15.037: INFO: Created: latency-svc-cgcmx
  Dec  9 13:09:15.039: INFO: Got endpoints: latency-svc-wwn29 [107.015736ms]
  Dec  9 13:09:15.046: INFO: Created: latency-svc-r5rw4
  Dec  9 13:09:15.053: INFO: Created: latency-svc-258rq
  Dec  9 13:09:15.056: INFO: Created: latency-svc-jskrl
  Dec  9 13:09:15.064: INFO: Created: latency-svc-c9kbm
  Dec  9 13:09:15.067: INFO: Created: latency-svc-xgsjw
  Dec  9 13:09:15.075: INFO: Created: latency-svc-grbrg
  Dec  9 13:09:15.082: INFO: Created: latency-svc-ggrkn
  Dec  9 13:09:15.085: INFO: Created: latency-svc-rkjwd
  Dec  9 13:09:15.091: INFO: Got endpoints: latency-svc-klj45 [159.082254ms]
  Dec  9 13:09:15.094: INFO: Created: latency-svc-thcsk
  Dec  9 13:09:15.101: INFO: Created: latency-svc-mnp4n
  Dec  9 13:09:15.106: INFO: Created: latency-svc-bmc49
  Dec  9 13:09:15.110: INFO: Created: latency-svc-hvkfk
  Dec  9 13:09:15.118: INFO: Created: latency-svc-n8l5v
  Dec  9 13:09:15.136: INFO: Got endpoints: latency-svc-dfvpj [201.966306ms]
  Dec  9 13:09:15.146: INFO: Created: latency-svc-m6js5
  Dec  9 13:09:15.187: INFO: Got endpoints: latency-svc-cgcmx [235.784158ms]
  Dec  9 13:09:15.198: INFO: Created: latency-svc-jbqk6
  Dec  9 13:09:15.237: INFO: Got endpoints: latency-svc-r5rw4 [286.180208ms]
  Dec  9 13:09:15.249: INFO: Created: latency-svc-2t4vq
  Dec  9 13:09:15.287: INFO: Got endpoints: latency-svc-258rq [331.776958ms]
  Dec  9 13:09:15.296: INFO: Created: latency-svc-rlv9j
  Dec  9 13:09:15.340: INFO: Got endpoints: latency-svc-jskrl [384.735785ms]
  Dec  9 13:09:15.349: INFO: Created: latency-svc-jvnjj
  Dec  9 13:09:15.388: INFO: Got endpoints: latency-svc-c9kbm [415.15895ms]
  Dec  9 13:09:15.399: INFO: Created: latency-svc-m859n
  Dec  9 13:09:15.437: INFO: Got endpoints: latency-svc-xgsjw [463.65359ms]
  Dec  9 13:09:15.448: INFO: Created: latency-svc-tcm5b
  Dec  9 13:09:15.487: INFO: Got endpoints: latency-svc-grbrg [505.596683ms]
  E1209 13:09:15.491253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:15.496: INFO: Created: latency-svc-wgh68
  Dec  9 13:09:15.539: INFO: Got endpoints: latency-svc-ggrkn [547.011989ms]
  Dec  9 13:09:15.553: INFO: Created: latency-svc-bzwrk
  Dec  9 13:09:15.587: INFO: Got endpoints: latency-svc-rkjwd [586.787611ms]
  Dec  9 13:09:15.597: INFO: Created: latency-svc-md7gg
  Dec  9 13:09:15.638: INFO: Got endpoints: latency-svc-thcsk [628.61264ms]
  Dec  9 13:09:15.649: INFO: Created: latency-svc-dspjj
  Dec  9 13:09:15.688: INFO: Got endpoints: latency-svc-mnp4n [675.522498ms]
  Dec  9 13:09:15.699: INFO: Created: latency-svc-pvvxm
  Dec  9 13:09:15.737: INFO: Got endpoints: latency-svc-bmc49 [713.165954ms]
  Dec  9 13:09:15.747: INFO: Created: latency-svc-ftqvg
  Dec  9 13:09:15.788: INFO: Got endpoints: latency-svc-hvkfk [749.599939ms]
  Dec  9 13:09:15.797: INFO: Created: latency-svc-lncsq
  Dec  9 13:09:15.839: INFO: Got endpoints: latency-svc-n8l5v [747.890409ms]
  Dec  9 13:09:15.849: INFO: Created: latency-svc-m2z8p
  Dec  9 13:09:15.888: INFO: Got endpoints: latency-svc-m6js5 [751.943383ms]
  Dec  9 13:09:15.898: INFO: Created: latency-svc-lj24w
  Dec  9 13:09:15.937: INFO: Got endpoints: latency-svc-jbqk6 [750.300942ms]
  Dec  9 13:09:15.948: INFO: Created: latency-svc-d9vcb
  Dec  9 13:09:15.988: INFO: Got endpoints: latency-svc-2t4vq [751.106812ms]
  Dec  9 13:09:15.999: INFO: Created: latency-svc-x25vf
  Dec  9 13:09:16.037: INFO: Got endpoints: latency-svc-rlv9j [749.955052ms]
  Dec  9 13:09:16.046: INFO: Created: latency-svc-v577v
  Dec  9 13:09:16.090: INFO: Got endpoints: latency-svc-jvnjj [750.271732ms]
  Dec  9 13:09:16.099: INFO: Created: latency-svc-9zdjg
  Dec  9 13:09:16.138: INFO: Got endpoints: latency-svc-m859n [749.394362ms]
  Dec  9 13:09:16.148: INFO: Created: latency-svc-4zrlq
  Dec  9 13:09:16.187: INFO: Got endpoints: latency-svc-tcm5b [749.593408ms]
  Dec  9 13:09:16.197: INFO: Created: latency-svc-w6q98
  Dec  9 13:09:16.240: INFO: Got endpoints: latency-svc-wgh68 [752.67285ms]
  Dec  9 13:09:16.250: INFO: Created: latency-svc-2nfg9
  Dec  9 13:09:16.291: INFO: Got endpoints: latency-svc-bzwrk [751.394522ms]
  Dec  9 13:09:16.302: INFO: Created: latency-svc-mcxlc
  Dec  9 13:09:16.337: INFO: Got endpoints: latency-svc-md7gg [750.410178ms]
  Dec  9 13:09:16.347: INFO: Created: latency-svc-pz7pq
  Dec  9 13:09:16.394: INFO: Got endpoints: latency-svc-dspjj [754.996278ms]
  Dec  9 13:09:16.405: INFO: Created: latency-svc-4brq6
  Dec  9 13:09:16.438: INFO: Got endpoints: latency-svc-pvvxm [750.177544ms]
  Dec  9 13:09:16.450: INFO: Created: latency-svc-vr7d2
  Dec  9 13:09:16.490: INFO: Got endpoints: latency-svc-ftqvg [752.928407ms]
  E1209 13:09:16.491423      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:16.500: INFO: Created: latency-svc-f6vxq
  Dec  9 13:09:16.538: INFO: Got endpoints: latency-svc-lncsq [749.541604ms]
  Dec  9 13:09:16.547: INFO: Created: latency-svc-zvxms
  Dec  9 13:09:16.590: INFO: Got endpoints: latency-svc-m2z8p [750.537503ms]
  Dec  9 13:09:16.600: INFO: Created: latency-svc-wjs2d
  Dec  9 13:09:16.639: INFO: Got endpoints: latency-svc-lj24w [750.263887ms]
  Dec  9 13:09:16.648: INFO: Created: latency-svc-rkzjs
  Dec  9 13:09:16.688: INFO: Got endpoints: latency-svc-d9vcb [750.681025ms]
  Dec  9 13:09:16.699: INFO: Created: latency-svc-tttbs
  Dec  9 13:09:16.739: INFO: Got endpoints: latency-svc-x25vf [750.003176ms]
  Dec  9 13:09:16.752: INFO: Created: latency-svc-ks6v9
  Dec  9 13:09:16.789: INFO: Got endpoints: latency-svc-v577v [752.062489ms]
  Dec  9 13:09:16.798: INFO: Created: latency-svc-rwb4z
  Dec  9 13:09:16.837: INFO: Got endpoints: latency-svc-9zdjg [747.143786ms]
  Dec  9 13:09:16.847: INFO: Created: latency-svc-658wk
  Dec  9 13:09:16.888: INFO: Got endpoints: latency-svc-4zrlq [750.001674ms]
  Dec  9 13:09:16.898: INFO: Created: latency-svc-rxvlx
  Dec  9 13:09:16.938: INFO: Got endpoints: latency-svc-w6q98 [750.934574ms]
  Dec  9 13:09:16.948: INFO: Created: latency-svc-cwjlx
  Dec  9 13:09:16.988: INFO: Got endpoints: latency-svc-2nfg9 [748.398521ms]
  Dec  9 13:09:16.998: INFO: Created: latency-svc-cj5f2
  Dec  9 13:09:17.039: INFO: Got endpoints: latency-svc-mcxlc [748.014544ms]
  Dec  9 13:09:17.050: INFO: Created: latency-svc-5tpbg
  Dec  9 13:09:17.089: INFO: Got endpoints: latency-svc-pz7pq [752.011158ms]
  Dec  9 13:09:17.099: INFO: Created: latency-svc-czjcr
  Dec  9 13:09:17.138: INFO: Got endpoints: latency-svc-4brq6 [744.609166ms]
  Dec  9 13:09:17.148: INFO: Created: latency-svc-mch2f
  Dec  9 13:09:17.187: INFO: Got endpoints: latency-svc-vr7d2 [748.904576ms]
  Dec  9 13:09:17.197: INFO: Created: latency-svc-5xzxk
  Dec  9 13:09:17.240: INFO: Got endpoints: latency-svc-f6vxq [749.690844ms]
  Dec  9 13:09:17.248: INFO: Created: latency-svc-rn7v5
  Dec  9 13:09:17.291: INFO: Got endpoints: latency-svc-zvxms [752.753745ms]
  Dec  9 13:09:17.303: INFO: Created: latency-svc-x868q
  Dec  9 13:09:17.339: INFO: Got endpoints: latency-svc-wjs2d [748.840722ms]
  Dec  9 13:09:17.349: INFO: Created: latency-svc-224j2
  Dec  9 13:09:17.388: INFO: Got endpoints: latency-svc-rkzjs [749.523405ms]
  Dec  9 13:09:17.397: INFO: Created: latency-svc-tfdjf
  Dec  9 13:09:17.438: INFO: Got endpoints: latency-svc-tttbs [749.698491ms]
  Dec  9 13:09:17.449: INFO: Created: latency-svc-dxtxq
  Dec  9 13:09:17.488: INFO: Got endpoints: latency-svc-ks6v9 [749.754181ms]
  E1209 13:09:17.491849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:17.500: INFO: Created: latency-svc-f29jj
  Dec  9 13:09:17.539: INFO: Got endpoints: latency-svc-rwb4z [749.352833ms]
  Dec  9 13:09:17.549: INFO: Created: latency-svc-5kwjz
  Dec  9 13:09:17.588: INFO: Got endpoints: latency-svc-658wk [750.606791ms]
  Dec  9 13:09:17.597: INFO: Created: latency-svc-qblv9
  Dec  9 13:09:17.638: INFO: Got endpoints: latency-svc-rxvlx [750.148857ms]
  Dec  9 13:09:17.650: INFO: Created: latency-svc-68sgl
  Dec  9 13:09:17.689: INFO: Got endpoints: latency-svc-cwjlx [750.96707ms]
  Dec  9 13:09:17.697: INFO: Created: latency-svc-jdcnx
  Dec  9 13:09:17.741: INFO: Got endpoints: latency-svc-cj5f2 [752.612463ms]
  Dec  9 13:09:17.752: INFO: Created: latency-svc-bc6zk
  Dec  9 13:09:17.789: INFO: Got endpoints: latency-svc-5tpbg [750.0041ms]
  Dec  9 13:09:17.800: INFO: Created: latency-svc-rzrnt
  Dec  9 13:09:17.838: INFO: Got endpoints: latency-svc-czjcr [748.720889ms]
  Dec  9 13:09:17.848: INFO: Created: latency-svc-lc8qp
  Dec  9 13:09:17.888: INFO: Got endpoints: latency-svc-mch2f [750.073881ms]
  Dec  9 13:09:17.897: INFO: Created: latency-svc-dmgwv
  Dec  9 13:09:17.938: INFO: Got endpoints: latency-svc-5xzxk [751.285258ms]
  Dec  9 13:09:17.949: INFO: Created: latency-svc-rzlzm
  Dec  9 13:09:17.989: INFO: Got endpoints: latency-svc-rn7v5 [749.0194ms]
  Dec  9 13:09:17.999: INFO: Created: latency-svc-p45md
  Dec  9 13:09:18.039: INFO: Got endpoints: latency-svc-x868q [748.724213ms]
  Dec  9 13:09:18.049: INFO: Created: latency-svc-qqsns
  Dec  9 13:09:18.088: INFO: Got endpoints: latency-svc-224j2 [749.417672ms]
  Dec  9 13:09:18.099: INFO: Created: latency-svc-fvd6s
  Dec  9 13:09:18.138: INFO: Got endpoints: latency-svc-tfdjf [750.127106ms]
  Dec  9 13:09:18.154: INFO: Created: latency-svc-nc84v
  Dec  9 13:09:18.188: INFO: Got endpoints: latency-svc-dxtxq [749.476585ms]
  Dec  9 13:09:18.198: INFO: Created: latency-svc-z2dgf
  Dec  9 13:09:18.239: INFO: Got endpoints: latency-svc-f29jj [750.386056ms]
  Dec  9 13:09:18.249: INFO: Created: latency-svc-79h85
  Dec  9 13:09:18.289: INFO: Got endpoints: latency-svc-5kwjz [750.031527ms]
  Dec  9 13:09:18.299: INFO: Created: latency-svc-hxh68
  Dec  9 13:09:18.339: INFO: Got endpoints: latency-svc-qblv9 [750.920537ms]
  Dec  9 13:09:18.350: INFO: Created: latency-svc-7zh57
  Dec  9 13:09:18.388: INFO: Got endpoints: latency-svc-68sgl [750.294458ms]
  Dec  9 13:09:18.399: INFO: Created: latency-svc-4tw6z
  Dec  9 13:09:18.439: INFO: Got endpoints: latency-svc-jdcnx [750.342771ms]
  Dec  9 13:09:18.449: INFO: Created: latency-svc-frptt
  Dec  9 13:09:18.489: INFO: Got endpoints: latency-svc-bc6zk [747.419505ms]
  E1209 13:09:18.492030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:18.499: INFO: Created: latency-svc-d5x8v
  Dec  9 13:09:18.538: INFO: Got endpoints: latency-svc-rzrnt [749.089821ms]
  Dec  9 13:09:18.551: INFO: Created: latency-svc-d8pzs
  Dec  9 13:09:18.589: INFO: Got endpoints: latency-svc-lc8qp [750.944809ms]
  Dec  9 13:09:18.598: INFO: Created: latency-svc-qqzf9
  Dec  9 13:09:18.639: INFO: Got endpoints: latency-svc-dmgwv [750.626952ms]
  Dec  9 13:09:18.649: INFO: Created: latency-svc-kf6ff
  Dec  9 13:09:18.689: INFO: Got endpoints: latency-svc-rzlzm [750.565562ms]
  Dec  9 13:09:18.702: INFO: Created: latency-svc-cq7bj
  Dec  9 13:09:18.745: INFO: Got endpoints: latency-svc-p45md [755.992926ms]
  Dec  9 13:09:18.758: INFO: Created: latency-svc-rf9z6
  Dec  9 13:09:18.788: INFO: Got endpoints: latency-svc-qqsns [748.463575ms]
  Dec  9 13:09:18.801: INFO: Created: latency-svc-fmzd8
  Dec  9 13:09:18.839: INFO: Got endpoints: latency-svc-fvd6s [749.925184ms]
  Dec  9 13:09:18.853: INFO: Created: latency-svc-l5jt6
  Dec  9 13:09:18.889: INFO: Got endpoints: latency-svc-nc84v [750.195808ms]
  Dec  9 13:09:18.898: INFO: Created: latency-svc-b4zbf
  Dec  9 13:09:18.938: INFO: Got endpoints: latency-svc-z2dgf [750.692949ms]
  Dec  9 13:09:18.948: INFO: Created: latency-svc-5g8sq
  Dec  9 13:09:18.989: INFO: Got endpoints: latency-svc-79h85 [749.744019ms]
  Dec  9 13:09:18.999: INFO: Created: latency-svc-xdnqf
  Dec  9 13:09:19.037: INFO: Got endpoints: latency-svc-hxh68 [748.2683ms]
  Dec  9 13:09:19.048: INFO: Created: latency-svc-swj5h
  Dec  9 13:09:19.090: INFO: Got endpoints: latency-svc-7zh57 [750.361413ms]
  Dec  9 13:09:19.101: INFO: Created: latency-svc-tswhl
  Dec  9 13:09:19.139: INFO: Got endpoints: latency-svc-4tw6z [750.670903ms]
  Dec  9 13:09:19.149: INFO: Created: latency-svc-jkbp4
  Dec  9 13:09:19.189: INFO: Got endpoints: latency-svc-frptt [749.300527ms]
  Dec  9 13:09:19.201: INFO: Created: latency-svc-26bcf
  Dec  9 13:09:19.239: INFO: Got endpoints: latency-svc-d5x8v [750.059349ms]
  Dec  9 13:09:19.249: INFO: Created: latency-svc-7srrx
  Dec  9 13:09:19.287: INFO: Got endpoints: latency-svc-d8pzs [748.678293ms]
  Dec  9 13:09:19.298: INFO: Created: latency-svc-cd7xp
  Dec  9 13:09:19.338: INFO: Got endpoints: latency-svc-qqzf9 [749.166692ms]
  Dec  9 13:09:19.347: INFO: Created: latency-svc-qm9xt
  Dec  9 13:09:19.390: INFO: Got endpoints: latency-svc-kf6ff [750.08395ms]
  Dec  9 13:09:19.399: INFO: Created: latency-svc-666s9
  Dec  9 13:09:19.439: INFO: Got endpoints: latency-svc-cq7bj [750.553989ms]
  Dec  9 13:09:19.452: INFO: Created: latency-svc-9t6cp
  Dec  9 13:09:19.487: INFO: Got endpoints: latency-svc-rf9z6 [741.972793ms]
  E1209 13:09:19.492311      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:19.497: INFO: Created: latency-svc-llx8t
  Dec  9 13:09:19.539: INFO: Got endpoints: latency-svc-fmzd8 [750.615369ms]
  Dec  9 13:09:19.548: INFO: Created: latency-svc-dndfc
  Dec  9 13:09:19.587: INFO: Got endpoints: latency-svc-l5jt6 [747.6563ms]
  Dec  9 13:09:19.598: INFO: Created: latency-svc-s6m7x
  Dec  9 13:09:19.638: INFO: Got endpoints: latency-svc-b4zbf [749.564939ms]
  Dec  9 13:09:19.648: INFO: Created: latency-svc-xz8cq
  Dec  9 13:09:19.688: INFO: Got endpoints: latency-svc-5g8sq [749.595248ms]
  Dec  9 13:09:19.698: INFO: Created: latency-svc-z972q
  Dec  9 13:09:19.739: INFO: Got endpoints: latency-svc-xdnqf [750.756143ms]
  Dec  9 13:09:19.752: INFO: Created: latency-svc-7r9k5
  Dec  9 13:09:19.789: INFO: Got endpoints: latency-svc-swj5h [751.780689ms]
  Dec  9 13:09:19.798: INFO: Created: latency-svc-jsmjm
  Dec  9 13:09:19.837: INFO: Got endpoints: latency-svc-tswhl [747.670729ms]
  Dec  9 13:09:19.849: INFO: Created: latency-svc-prwjn
  Dec  9 13:09:19.888: INFO: Got endpoints: latency-svc-jkbp4 [748.489815ms]
  Dec  9 13:09:19.899: INFO: Created: latency-svc-qqvkj
  Dec  9 13:09:19.937: INFO: Got endpoints: latency-svc-26bcf [747.982861ms]
  Dec  9 13:09:19.946: INFO: Created: latency-svc-9rxk5
  Dec  9 13:09:19.988: INFO: Got endpoints: latency-svc-7srrx [749.467615ms]
  Dec  9 13:09:19.998: INFO: Created: latency-svc-x7c7w
  Dec  9 13:09:20.040: INFO: Got endpoints: latency-svc-cd7xp [753.297687ms]
  Dec  9 13:09:20.050: INFO: Created: latency-svc-6wxk8
  Dec  9 13:09:20.088: INFO: Got endpoints: latency-svc-qm9xt [749.748737ms]
  Dec  9 13:09:20.100: INFO: Created: latency-svc-9n2xs
  Dec  9 13:09:20.137: INFO: Got endpoints: latency-svc-666s9 [747.125487ms]
  Dec  9 13:09:20.147: INFO: Created: latency-svc-9tmlw
  Dec  9 13:09:20.189: INFO: Got endpoints: latency-svc-9t6cp [749.677676ms]
  Dec  9 13:09:20.200: INFO: Created: latency-svc-k6svd
  Dec  9 13:09:20.239: INFO: Got endpoints: latency-svc-llx8t [752.168398ms]
  Dec  9 13:09:20.248: INFO: Created: latency-svc-6bvg6
  Dec  9 13:09:20.289: INFO: Got endpoints: latency-svc-dndfc [750.240362ms]
  Dec  9 13:09:20.299: INFO: Created: latency-svc-qxkbf
  Dec  9 13:09:20.337: INFO: Got endpoints: latency-svc-s6m7x [750.398996ms]
  Dec  9 13:09:20.348: INFO: Created: latency-svc-vfsxz
  Dec  9 13:09:20.387: INFO: Got endpoints: latency-svc-xz8cq [748.460885ms]
  Dec  9 13:09:20.396: INFO: Created: latency-svc-skf8t
  Dec  9 13:09:20.438: INFO: Got endpoints: latency-svc-z972q [750.068626ms]
  Dec  9 13:09:20.448: INFO: Created: latency-svc-sksrn
  Dec  9 13:09:20.489: INFO: Got endpoints: latency-svc-7r9k5 [749.504683ms]
  E1209 13:09:20.492463      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:20.501: INFO: Created: latency-svc-mk2fb
  Dec  9 13:09:20.539: INFO: Got endpoints: latency-svc-jsmjm [749.369987ms]
  Dec  9 13:09:20.547: INFO: Created: latency-svc-hl4r2
  Dec  9 13:09:20.587: INFO: Got endpoints: latency-svc-prwjn [749.997051ms]
  Dec  9 13:09:20.598: INFO: Created: latency-svc-mfmmp
  Dec  9 13:09:20.637: INFO: Got endpoints: latency-svc-qqvkj [749.448583ms]
  Dec  9 13:09:20.648: INFO: Created: latency-svc-g6mfq
  Dec  9 13:09:20.689: INFO: Got endpoints: latency-svc-9rxk5 [752.002642ms]
  Dec  9 13:09:20.697: INFO: Created: latency-svc-wnj5s
  Dec  9 13:09:20.739: INFO: Got endpoints: latency-svc-x7c7w [750.96138ms]
  Dec  9 13:09:20.755: INFO: Created: latency-svc-g74v5
  Dec  9 13:09:20.788: INFO: Got endpoints: latency-svc-6wxk8 [747.805038ms]
  Dec  9 13:09:20.798: INFO: Created: latency-svc-qhxgt
  Dec  9 13:09:20.837: INFO: Got endpoints: latency-svc-9n2xs [748.618565ms]
  Dec  9 13:09:20.847: INFO: Created: latency-svc-c78hz
  Dec  9 13:09:20.888: INFO: Got endpoints: latency-svc-9tmlw [751.205576ms]
  Dec  9 13:09:20.899: INFO: Created: latency-svc-78bpn
  Dec  9 13:09:20.941: INFO: Got endpoints: latency-svc-k6svd [751.510651ms]
  Dec  9 13:09:20.952: INFO: Created: latency-svc-xlmll
  Dec  9 13:09:20.989: INFO: Got endpoints: latency-svc-6bvg6 [749.833007ms]
  Dec  9 13:09:20.997: INFO: Created: latency-svc-jvj2j
  Dec  9 13:09:21.037: INFO: Got endpoints: latency-svc-qxkbf [747.769873ms]
  Dec  9 13:09:21.047: INFO: Created: latency-svc-tzlkz
  Dec  9 13:09:21.088: INFO: Got endpoints: latency-svc-vfsxz [750.625327ms]
  Dec  9 13:09:21.099: INFO: Created: latency-svc-74btd
  Dec  9 13:09:21.138: INFO: Got endpoints: latency-svc-skf8t [751.220255ms]
  Dec  9 13:09:21.147: INFO: Created: latency-svc-nr5x7
  Dec  9 13:09:21.190: INFO: Got endpoints: latency-svc-sksrn [751.705531ms]
  Dec  9 13:09:21.199: INFO: Created: latency-svc-6djh9
  Dec  9 13:09:21.239: INFO: Got endpoints: latency-svc-mk2fb [750.33772ms]
  Dec  9 13:09:21.249: INFO: Created: latency-svc-nfcqx
  Dec  9 13:09:21.286: INFO: Got endpoints: latency-svc-hl4r2 [747.679531ms]
  Dec  9 13:09:21.298: INFO: Created: latency-svc-rzvzh
  Dec  9 13:09:21.337: INFO: Got endpoints: latency-svc-mfmmp [749.486126ms]
  Dec  9 13:09:21.346: INFO: Created: latency-svc-tjkl4
  Dec  9 13:09:21.390: INFO: Got endpoints: latency-svc-g6mfq [752.383974ms]
  Dec  9 13:09:21.402: INFO: Created: latency-svc-qz8xh
  Dec  9 13:09:21.438: INFO: Got endpoints: latency-svc-wnj5s [749.502165ms]
  Dec  9 13:09:21.448: INFO: Created: latency-svc-hb889
  Dec  9 13:09:21.489: INFO: Got endpoints: latency-svc-g74v5 [749.536991ms]
  E1209 13:09:21.493429      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:21.498: INFO: Created: latency-svc-tc9nk
  Dec  9 13:09:21.538: INFO: Got endpoints: latency-svc-qhxgt [749.480822ms]
  Dec  9 13:09:21.550: INFO: Created: latency-svc-gm2r7
  Dec  9 13:09:21.589: INFO: Got endpoints: latency-svc-c78hz [752.187985ms]
  Dec  9 13:09:21.598: INFO: Created: latency-svc-ffd22
  Dec  9 13:09:21.638: INFO: Got endpoints: latency-svc-78bpn [749.927494ms]
  Dec  9 13:09:21.648: INFO: Created: latency-svc-vgglh
  Dec  9 13:09:21.689: INFO: Got endpoints: latency-svc-xlmll [747.451682ms]
  Dec  9 13:09:21.698: INFO: Created: latency-svc-44mmg
  Dec  9 13:09:21.737: INFO: Got endpoints: latency-svc-jvj2j [747.878403ms]
  Dec  9 13:09:21.750: INFO: Created: latency-svc-qwnft
  Dec  9 13:09:21.786: INFO: Got endpoints: latency-svc-tzlkz [749.454621ms]
  Dec  9 13:09:21.797: INFO: Created: latency-svc-xzz64
  Dec  9 13:09:21.839: INFO: Got endpoints: latency-svc-74btd [750.608694ms]
  Dec  9 13:09:21.850: INFO: Created: latency-svc-xktkx
  Dec  9 13:09:21.890: INFO: Got endpoints: latency-svc-nr5x7 [751.977931ms]
  Dec  9 13:09:21.899: INFO: Created: latency-svc-lgw2h
  Dec  9 13:09:21.939: INFO: Got endpoints: latency-svc-6djh9 [749.190268ms]
  Dec  9 13:09:21.948: INFO: Created: latency-svc-rp89r
  Dec  9 13:09:21.988: INFO: Got endpoints: latency-svc-nfcqx [749.093788ms]
  Dec  9 13:09:21.998: INFO: Created: latency-svc-stqhs
  Dec  9 13:09:22.037: INFO: Got endpoints: latency-svc-rzvzh [750.18919ms]
  Dec  9 13:09:22.046: INFO: Created: latency-svc-rcfc5
  Dec  9 13:09:22.089: INFO: Got endpoints: latency-svc-tjkl4 [751.937459ms]
  Dec  9 13:09:22.098: INFO: Created: latency-svc-jpvsf
  Dec  9 13:09:22.140: INFO: Got endpoints: latency-svc-qz8xh [750.824998ms]
  Dec  9 13:09:22.150: INFO: Created: latency-svc-zxfpj
  Dec  9 13:09:22.189: INFO: Got endpoints: latency-svc-hb889 [750.505868ms]
  Dec  9 13:09:22.199: INFO: Created: latency-svc-vgvfr
  Dec  9 13:09:22.237: INFO: Got endpoints: latency-svc-tc9nk [748.322003ms]
  Dec  9 13:09:22.249: INFO: Created: latency-svc-f2fbx
  Dec  9 13:09:22.289: INFO: Got endpoints: latency-svc-gm2r7 [750.872213ms]
  Dec  9 13:09:22.300: INFO: Created: latency-svc-nlg8g
  Dec  9 13:09:22.339: INFO: Got endpoints: latency-svc-ffd22 [749.870332ms]
  Dec  9 13:09:22.348: INFO: Created: latency-svc-bx598
  Dec  9 13:09:22.389: INFO: Got endpoints: latency-svc-vgglh [750.890718ms]
  Dec  9 13:09:22.398: INFO: Created: latency-svc-cd6jh
  Dec  9 13:09:22.441: INFO: Got endpoints: latency-svc-44mmg [752.299308ms]
  Dec  9 13:09:22.451: INFO: Created: latency-svc-w8cv7
  E1209 13:09:22.493483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:22.495: INFO: Got endpoints: latency-svc-qwnft [758.438049ms]
  Dec  9 13:09:22.505: INFO: Created: latency-svc-6g9qq
  Dec  9 13:09:22.544: INFO: Got endpoints: latency-svc-xzz64 [757.201126ms]
  Dec  9 13:09:22.553: INFO: Created: latency-svc-qbksf
  Dec  9 13:09:22.588: INFO: Got endpoints: latency-svc-xktkx [749.252114ms]
  Dec  9 13:09:22.638: INFO: Got endpoints: latency-svc-lgw2h [747.097713ms]
  Dec  9 13:09:22.687: INFO: Got endpoints: latency-svc-rp89r [747.849155ms]
  Dec  9 13:09:22.740: INFO: Got endpoints: latency-svc-stqhs [751.946937ms]
  Dec  9 13:09:22.787: INFO: Got endpoints: latency-svc-rcfc5 [750.324796ms]
  Dec  9 13:09:22.837: INFO: Got endpoints: latency-svc-jpvsf [748.422716ms]
  Dec  9 13:09:22.887: INFO: Got endpoints: latency-svc-zxfpj [746.863729ms]
  Dec  9 13:09:22.940: INFO: Got endpoints: latency-svc-vgvfr [750.821695ms]
  Dec  9 13:09:22.987: INFO: Got endpoints: latency-svc-f2fbx [749.566944ms]
  Dec  9 13:09:23.040: INFO: Got endpoints: latency-svc-nlg8g [751.122969ms]
  Dec  9 13:09:23.086: INFO: Got endpoints: latency-svc-bx598 [747.457128ms]
  Dec  9 13:09:23.138: INFO: Got endpoints: latency-svc-cd6jh [749.425095ms]
  Dec  9 13:09:23.188: INFO: Got endpoints: latency-svc-w8cv7 [747.241882ms]
  Dec  9 13:09:23.239: INFO: Got endpoints: latency-svc-6g9qq [743.804799ms]
  Dec  9 13:09:23.289: INFO: Got endpoints: latency-svc-qbksf [744.969942ms]
  Dec  9 13:09:23.289: INFO: Latencies: [17.387598ms 22.720922ms 31.954886ms 38.088089ms 48.090446ms 55.377265ms 59.945119ms 71.728529ms 80.757874ms 85.59448ms 96.250589ms 100.502163ms 103.459355ms 106.397703ms 107.015736ms 109.573237ms 116.710113ms 118.017934ms 120.007539ms 121.577747ms 121.828756ms 121.856374ms 122.138035ms 122.66439ms 123.358738ms 127.792619ms 128.092873ms 128.451714ms 128.690917ms 132.727601ms 134.29038ms 137.643714ms 137.663768ms 138.026428ms 142.234748ms 159.082254ms 201.966306ms 235.784158ms 286.180208ms 331.776958ms 384.735785ms 415.15895ms 463.65359ms 505.596683ms 547.011989ms 586.787611ms 628.61264ms 675.522498ms 713.165954ms 741.972793ms 743.804799ms 744.609166ms 744.969942ms 746.863729ms 747.097713ms 747.125487ms 747.143786ms 747.241882ms 747.419505ms 747.451682ms 747.457128ms 747.6563ms 747.670729ms 747.679531ms 747.769873ms 747.805038ms 747.849155ms 747.878403ms 747.890409ms 747.982861ms 748.014544ms 748.2683ms 748.322003ms 748.398521ms 748.422716ms 748.460885ms 748.463575ms 748.489815ms 748.618565ms 748.678293ms 748.720889ms 748.724213ms 748.840722ms 748.904576ms 749.0194ms 749.089821ms 749.093788ms 749.166692ms 749.190268ms 749.252114ms 749.300527ms 749.352833ms 749.369987ms 749.394362ms 749.417672ms 749.425095ms 749.448583ms 749.454621ms 749.467615ms 749.476585ms 749.480822ms 749.486126ms 749.502165ms 749.504683ms 749.523405ms 749.536991ms 749.541604ms 749.564939ms 749.566944ms 749.593408ms 749.595248ms 749.599939ms 749.677676ms 749.690844ms 749.698491ms 749.744019ms 749.748737ms 749.754181ms 749.833007ms 749.870332ms 749.925184ms 749.927494ms 749.955052ms 749.997051ms 750.001674ms 750.003176ms 750.0041ms 750.031527ms 750.059349ms 750.068626ms 750.073881ms 750.08395ms 750.127106ms 750.148857ms 750.177544ms 750.18919ms 750.195808ms 750.240362ms 750.263887ms 750.271732ms 750.294458ms 750.300942ms 750.324796ms 750.33772ms 750.342771ms 750.361413ms 750.386056ms 750.398996ms 750.410178ms 750.505868ms 750.537503ms 750.553989ms 750.565562ms 750.606791ms 750.608694ms 750.615369ms 750.625327ms 750.626952ms 750.670903ms 750.681025ms 750.692949ms 750.756143ms 750.821695ms 750.824998ms 750.872213ms 750.890718ms 750.920537ms 750.934574ms 750.944809ms 750.96138ms 750.96707ms 751.106812ms 751.122969ms 751.205576ms 751.220255ms 751.285258ms 751.394522ms 751.510651ms 751.705531ms 751.780689ms 751.937459ms 751.943383ms 751.946937ms 751.977931ms 752.002642ms 752.011158ms 752.062489ms 752.168398ms 752.187985ms 752.299308ms 752.383974ms 752.612463ms 752.67285ms 752.753745ms 752.928407ms 753.297687ms 754.996278ms 755.992926ms 757.201126ms 758.438049ms]
  Dec  9 13:09:23.289: INFO: 50 %ile: 749.480822ms
  Dec  9 13:09:23.289: INFO: 90 %ile: 751.937459ms
  Dec  9 13:09:23.289: INFO: 99 %ile: 757.201126ms
  Dec  9 13:09:23.289: INFO: Total sample count: 200
  Dec  9 13:09:23.290: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-2619" for this suite. @ 12/09/23 13:09:23.294
• [9.758 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 12/09/23 13:09:23.3
  Dec  9 13:09:23.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:09:23.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:09:23.316
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:09:23.318
  STEP: Setting up server cert @ 12/09/23 13:09:23.341
  E1209 13:09:23.494387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:09:23.513
  STEP: Deploying the webhook pod @ 12/09/23 13:09:23.521
  STEP: Wait for the deployment to be ready @ 12/09/23 13:09:23.533
  Dec  9 13:09:23.541: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1209 13:09:24.495031      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:25.495905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/09/23 13:09:25.551
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:09:25.56
  E1209 13:09:26.495991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:09:26.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 12/09/23 13:09:26.566
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/09/23 13:09:26.581
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 12/09/23 13:09:26.589
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/09/23 13:09:26.599
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 12/09/23 13:09:26.609
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/09/23 13:09:26.637
  Dec  9 13:09:26.658: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9093" for this suite. @ 12/09/23 13:09:26.709
  STEP: Destroying namespace "webhook-markers-1074" for this suite. @ 12/09/23 13:09:26.722
• [3.428 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 12/09/23 13:09:26.737
  Dec  9 13:09:26.737: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 13:09:26.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:09:26.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:09:26.757
  E1209 13:09:27.496114      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:28.496539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:29.496789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:30.496874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:31.497743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:32.498585      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:33.499087      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:34.499917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:35.500737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:36.500854      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:37.501012      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:38.501715      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:39.502634      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:40.502851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:41.502950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:42.503031      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:43.503881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:44.503984      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:45.504825      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:46.505895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:47.506766      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:48.507792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:49.507906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:50.508198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:51.508286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:52.508543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:53.508609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:54.508685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:55.509534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:56.509823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:57.509916      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:58.510745      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:09:59.511663      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:00.511747      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:01.512073      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:02.512179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:03.512952      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:04.513855      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:05.513944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:06.514040      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:07.514884      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:08.515257      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:09.515919      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:10.516548      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:11.516704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:12.517704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:13.518337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:14.519281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:15.519374      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:16.519470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:17.519637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:18.520554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:19.520683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:20.521593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:21.521678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:22.522600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:23.523428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:24.523892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:25.524741      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:26.524792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:10:26.772: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-545" for this suite. @ 12/09/23 13:10:26.775
• [60.045 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 12/09/23 13:10:26.782
  Dec  9 13:10:26.782: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-preemption @ 12/09/23 13:10:26.783
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:10:26.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:10:26.803
  Dec  9 13:10:26.820: INFO: Waiting up to 1m0s for all nodes to be ready
  E1209 13:10:27.525584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:28.525653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:29.525835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:30.525911      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:31.526187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:32.527154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:33.527621      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:34.527906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:35.528012      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:36.528286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:37.528406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:38.528617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:39.528724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:40.528813      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:41.529438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:42.529498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:43.529893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:44.530054      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:45.530258      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:46.530418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:47.530549      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:48.530914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:49.531912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:50.532099      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:51.532212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:52.532382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:53.532965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:54.533136      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:55.534203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:56.534365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:57.534469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:58.534680      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:10:59.534850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:00.534933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:01.535866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:02.536003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:03.536590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:04.536665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:05.536761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:06.537095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:07.537190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:08.537459      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:09.537550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:10.538024      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:11.539042      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:12.539093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:13.539772      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:14.540394      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:15.540472      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:16.540555      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:17.540661      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:18.541044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:19.541637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:20.541812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:21.542665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:22.542900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:23.543890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:24.544077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:25.545034      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:26.545107      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:11:26.852: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/09/23 13:11:26.856
  Dec  9 13:11:26.879: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec  9 13:11:26.885: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec  9 13:11:26.906: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec  9 13:11:26.911: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec  9 13:11:26.926: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec  9 13:11:26.936: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/09/23 13:11:26.936
  E1209 13:11:27.545922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:28.546185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 12/09/23 13:11:28.957
  E1209 13:11:29.546284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:30.546381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:31.546464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:32.546682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:11:33.046: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3511" for this suite. @ 12/09/23 13:11:33.086
• [66.309 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:792
  STEP: Creating a kubernetes client @ 12/09/23 13:11:33.092
  Dec  9 13:11:33.092: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 13:11:33.092
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:11:33.111
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:11:33.114
  STEP: Creating service test in namespace statefulset-7982 @ 12/09/23 13:11:33.116
  STEP: Looking for a node to schedule stateful set and pod @ 12/09/23 13:11:33.121
  STEP: Creating pod with conflicting port in namespace statefulset-7982 @ 12/09/23 13:11:33.125
  STEP: Waiting until pod test-pod will start running in namespace statefulset-7982 @ 12/09/23 13:11:33.135
  E1209 13:11:33.547544      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:34.548010      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-7982 @ 12/09/23 13:11:35.142
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7982 @ 12/09/23 13:11:35.149
  Dec  9 13:11:35.163: INFO: Observed stateful pod in namespace: statefulset-7982, name: ss-0, uid: 786c392a-c161-4291-9afd-4e4b54122d69, status phase: Pending. Waiting for statefulset controller to delete.
  Dec  9 13:11:35.184: INFO: Observed stateful pod in namespace: statefulset-7982, name: ss-0, uid: 786c392a-c161-4291-9afd-4e4b54122d69, status phase: Failed. Waiting for statefulset controller to delete.
  Dec  9 13:11:35.192: INFO: Observed stateful pod in namespace: statefulset-7982, name: ss-0, uid: 786c392a-c161-4291-9afd-4e4b54122d69, status phase: Failed. Waiting for statefulset controller to delete.
  Dec  9 13:11:35.198: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7982
  STEP: Removing pod with conflicting port in namespace statefulset-7982 @ 12/09/23 13:11:35.198
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7982 and will be in running state @ 12/09/23 13:11:35.22
  E1209 13:11:35.548115      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:36.548290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:11:37.228: INFO: Deleting all statefulset in ns statefulset-7982
  Dec  9 13:11:37.231: INFO: Scaling statefulset ss to 0
  E1209 13:11:37.548367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:38.548542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:39.548597      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:40.548809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:41.549066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:42.549234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:43.549298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:44.549462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:45.549569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:46.550436      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:11:47.249: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 13:11:47.251: INFO: Deleting statefulset ss
  Dec  9 13:11:47.263: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7982" for this suite. @ 12/09/23 13:11:47.267
• [14.181 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 12/09/23 13:11:47.274
  Dec  9 13:11:47.274: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename daemonsets @ 12/09/23 13:11:47.275
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:11:47.292
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:11:47.294
  STEP: Creating simple DaemonSet "daemon-set" @ 12/09/23 13:11:47.317
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/09/23 13:11:47.321
  Dec  9 13:11:47.325: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:11:47.325: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:11:47.328: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 13:11:47.328: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  E1209 13:11:47.550840      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:11:48.333: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:11:48.333: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:11:48.337: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  9 13:11:48.337: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  E1209 13:11:48.551297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:11:49.332: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:11:49.332: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:11:49.336: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 13:11:49.336: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 12/09/23 13:11:49.339
  Dec  9 13:11:49.342: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 12/09/23 13:11:49.343
  Dec  9 13:11:49.351: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 12/09/23 13:11:49.351
  Dec  9 13:11:49.353: INFO: Observed &DaemonSet event: ADDED
  Dec  9 13:11:49.353: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.353: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.353: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.353: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.354: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.354: INFO: Found daemon set daemon-set in namespace daemonsets-137 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  9 13:11:49.354: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 12/09/23 13:11:49.354
  STEP: watching for the daemon set status to be patched @ 12/09/23 13:11:49.362
  Dec  9 13:11:49.363: INFO: Observed &DaemonSet event: ADDED
  Dec  9 13:11:49.364: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.364: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.364: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.364: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.364: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.364: INFO: Observed daemon set daemon-set in namespace daemonsets-137 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  9 13:11:49.364: INFO: Observed &DaemonSet event: MODIFIED
  Dec  9 13:11:49.364: INFO: Found daemon set daemon-set in namespace daemonsets-137 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Dec  9 13:11:49.364: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 12/09/23 13:11:49.37
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-137, will wait for the garbage collector to delete the pods @ 12/09/23 13:11:49.37
  Dec  9 13:11:49.430: INFO: Deleting DaemonSet.extensions daemon-set took: 6.519857ms
  Dec  9 13:11:49.531: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.051449ms
  E1209 13:11:49.551975      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:50.552047      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:11:50.836: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 13:11:50.836: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  9 13:11:50.838: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"26902"},"items":null}

  Dec  9 13:11:50.841: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"26902"},"items":null}

  Dec  9 13:11:50.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-137" for this suite. @ 12/09/23 13:11:50.856
• [3.590 seconds]
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 12/09/23 13:11:50.864
  Dec  9 13:11:50.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename job @ 12/09/23 13:11:50.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:11:50.881
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:11:50.883
  STEP: Creating Indexed job @ 12/09/23 13:11:50.886
  STEP: Ensuring job reaches completions @ 12/09/23 13:11:50.89
  E1209 13:11:51.552388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:52.553090      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:53.553980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:54.554189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:55.554529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:56.554615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 12/09/23 13:11:56.894
  Dec  9 13:11:56.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-2502" for this suite. @ 12/09/23 13:11:56.9
• [6.041 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:320
  STEP: Creating a kubernetes client @ 12/09/23 13:11:56.906
  Dec  9 13:11:56.906: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 13:11:56.907
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:11:56.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:11:56.927
  STEP: Creating service test in namespace statefulset-4346 @ 12/09/23 13:11:56.928
  STEP: Creating a new StatefulSet @ 12/09/23 13:11:56.935
  Dec  9 13:11:56.943: INFO: Found 0 stateful pods, waiting for 3
  E1209 13:11:57.555368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:58.555462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:11:59.555570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:00.556045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:01.556673      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:02.556981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:03.558069      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:04.558235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:05.558332      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:06.558505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:12:06.947: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:12:06.947: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:12:06.947: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:12:06.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-4346 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 13:12:07.064: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 13:12:07.064: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 13:12:07.064: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1209 13:12:07.559369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:08.559622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:09.560534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:10.560609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:11.560764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:12.560845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:13.560994      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:14.561166      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:15.561321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:16.561379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/09/23 13:12:17.078
  Dec  9 13:12:17.098: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/09/23 13:12:17.098
  E1209 13:12:17.561804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:18.562016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:19.562203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:20.562462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:21.562569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:22.562648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:23.563574      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:24.563932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:25.564077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:26.564443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 12/09/23 13:12:27.113
  Dec  9 13:12:27.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-4346 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 13:12:27.229: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  9 13:12:27.229: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 13:12:27.229: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1209 13:12:27.564928      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:28.565684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:29.565957      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:30.566265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:31.566365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:32.566421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:33.566765      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:34.566865      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:35.567943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:36.568152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:12:37.251: INFO: Waiting for StatefulSet statefulset-4346/ss2 to complete update
  E1209 13:12:37.568773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:38.569789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:39.569997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:40.570243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:41.570327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:42.570503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:43.571008      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:44.571889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:45.571988      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:46.572165      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 12/09/23 13:12:47.258
  Dec  9 13:12:47.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-4346 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 13:12:47.375: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 13:12:47.375: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 13:12:47.375: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1209 13:12:47.573191      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:48.573529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:49.573623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:50.573863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:51.573961      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:52.574067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:53.574135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:54.574229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:55.575250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:56.575343      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:12:57.409: INFO: Updating stateful set ss2
  E1209 13:12:57.575898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:58.575969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:12:59.576129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:00.576201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:01.576352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:02.576438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:03.577067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:04.577162      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:05.577326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:06.577533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 12/09/23 13:13:07.424
  Dec  9 13:13:07.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-4346 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 13:13:07.537: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  9 13:13:07.538: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 13:13:07.538: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1209 13:13:07.578464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:08.578550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:09.578846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:10.578886      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:11.579968      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:12.580113      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:13.580206      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:14.580486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:15.580582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:16.580673      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:13:17.558: INFO: Deleting all statefulset in ns statefulset-4346
  Dec  9 13:13:17.560: INFO: Scaling statefulset ss2 to 0
  E1209 13:13:17.580764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:18.581792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:19.581869      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:20.581964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:21.582145      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:22.582302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:23.582349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:24.582444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:25.582617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:26.583494      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:13:27.577: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 13:13:27.582: INFO: Deleting statefulset ss2
  E1209 13:13:27.584133      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:13:27.600: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4346" for this suite. @ 12/09/23 13:13:27.605
• [90.708 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 12/09/23 13:13:27.616
  Dec  9 13:13:27.616: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename endpointslice @ 12/09/23 13:13:27.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:13:27.633
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:13:27.635
  E1209 13:13:28.584943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:29.585973      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:30.586077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:31.586155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:32.586304      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 12/09/23 13:13:32.702
  E1209 13:13:33.586723      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:34.586844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:35.587902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:36.588080      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:37.588142      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 12/09/23 13:13:37.71
  E1209 13:13:38.589023      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:39.589116      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:40.589293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:41.589447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:42.589697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 12/09/23 13:13:42.718
  E1209 13:13:43.589972      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:44.590041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:45.590533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:46.591484      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:47.591499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 12/09/23 13:13:47.725
  Dec  9 13:13:47.746: INFO: EndpointSlice for Service endpointslice-4797/example-named-port not found
  E1209 13:13:48.592329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:49.592498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:50.592685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:51.592757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:52.592852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:53.593518      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:54.593523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:55.593682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:56.593870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:57.593957      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:13:57.754: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4797" for this suite. @ 12/09/23 13:13:57.758
• [30.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1674
  STEP: Creating a kubernetes client @ 12/09/23 13:13:57.767
  Dec  9 13:13:57.767: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:13:57.767
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:13:57.788
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:13:57.79
  Dec  9 13:13:57.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-8191 version'
  Dec  9 13:13:57.834: INFO: stderr: ""
  Dec  9 13:13:57.834: INFO: stdout: "Client Version: v1.28.4\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.28.4\n"
  Dec  9 13:13:57.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8191" for this suite. @ 12/09/23 13:13:57.838
• [0.077 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 12/09/23 13:13:57.845
  Dec  9 13:13:57.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:13:57.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:13:57.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:13:57.862
  STEP: Creating configMap with name configmap-test-upd-f40d6640-3898-49d2-a24c-21dd6bf830ec @ 12/09/23 13:13:57.868
  STEP: Creating the pod @ 12/09/23 13:13:57.872
  E1209 13:13:58.594827      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:13:59.595905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 12/09/23 13:13:59.892
  STEP: Waiting for pod with binary data @ 12/09/23 13:13:59.91
  Dec  9 13:13:59.917: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2193" for this suite. @ 12/09/23 13:13:59.921
• [2.084 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 12/09/23 13:13:59.929
  Dec  9 13:13:59.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replication-controller @ 12/09/23 13:13:59.929
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:13:59.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:13:59.949
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 12/09/23 13:13:59.951
  E1209 13:14:00.596010      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:01.596126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:02.596203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:03.597033      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 12/09/23 13:14:03.976
  STEP: Then the orphan pod is adopted @ 12/09/23 13:14:03.983
  E1209 13:14:04.597552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:04.991: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-3505" for this suite. @ 12/09/23 13:14:04.995
• [5.072 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 12/09/23 13:14:05.002
  Dec  9 13:14:05.002: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:14:05.003
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:14:05.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:14:05.028
  STEP: Creating a pod to test downward api env vars @ 12/09/23 13:14:05.029
  E1209 13:14:05.597644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:06.597732      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:14:07.053
  Dec  9 13:14:07.056: INFO: Trying to get logs from node ip-172-31-77-176 pod downward-api-ffb59e5b-5fe5-41a6-bf5b-4d271aa9f08a container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 13:14:07.063
  Dec  9 13:14:07.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2096" for this suite. @ 12/09/23 13:14:07.083
• [2.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 12/09/23 13:14:07.09
  Dec  9 13:14:07.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 13:14:07.091
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:14:07.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:14:07.112
  STEP: Creating pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059 @ 12/09/23 13:14:07.114
  E1209 13:14:07.598479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:08.598770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 13:14:09.13
  Dec  9 13:14:09.134: INFO: Initial restart count of pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 is 0
  Dec  9 13:14:09.136: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:09.599479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:10.599572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:11.140: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:11.599893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:12.600097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:13.143: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:13.600729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:14.600818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:15.147: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:15.601260      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:16.601335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:17.151: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:17.601433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:18.602366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:19.156: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:19.602630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:20.602821      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:21.161: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:21.603755      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:22.603944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:23.165: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:23.604419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:24.605359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:25.170: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:25.606164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:26.606164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:27.174: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:27.606800      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:28.607827      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:29.177: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:29.608205      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:30.608373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:31.181: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:31.608466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:32.608553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:33.184: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:33.608720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:34.608887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:35.187: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:35.609173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:36.609480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:37.190: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:37.610478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:38.610778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:39.195: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:39.610846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:40.610922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:41.199: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:41.611795      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:42.612335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:43.203: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:43.612807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:44.612893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:45.207: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:45.612960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:46.613039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:47.211: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:47.613144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:48.613894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:49.215: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:49.614619      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:50.614730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:51.218: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:51.614853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:52.614913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:53.221: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:53.615312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:54.615386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:55.224: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:55.616333      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:56.616418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:57.228: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:57.616511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:14:58.616723      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:14:59.232: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:14:59.616789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:00.617633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:01.237: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:01.618563      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:02.618648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:03.242: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:03.618839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:04.618931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:05.246: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:05.619683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:06.619784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:07.249: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:07.620025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:08.620837      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:09.253: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:09.621499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:10.621607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:11.257: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:11.621682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:12.621773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:13.260: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:13.622163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:14.622245      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:15.264: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:15.622757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:16.622862      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:17.267: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:17.623877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:18.624628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:19.272: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:19.624897      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:20.625029      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:21.276: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:21.625827      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:22.626012      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:23.279: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:23.626090      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:24.626188      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:25.283: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:25.626520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:26.626681      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:27.286: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:27.627099      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:28.627791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:29.290: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:29.627846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:30.628015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:31.294: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:31.628650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:32.629640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:33.299: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:33.630594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:34.630743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:35.302: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:35.631237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:36.631892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:37.307: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:37.632744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:38.632817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:39.312: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:39.633525      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:40.634013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:41.316: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:41.635015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:42.635106      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:43.320: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:43.635885      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:44.636028      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:45.325: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:45.636650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:46.637118      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:47.328: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:47.638155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:48.638478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:49.332: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:49.639533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:50.639889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:51.335: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:51.640318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:52.640979      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:53.340: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:53.641469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:54.641555      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:55.343: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:55.642626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:56.642837      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:57.346: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:57.643756      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:15:58.643807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:15:59.350: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:15:59.644064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:00.644129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:01.354: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:01.645063      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:02.645114      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:03.358: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:03.645560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:04.645761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:05.362: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:05.646339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:06.647067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:07.365: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:07.647250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:08.647528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:09.369: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:09.647622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:10.647891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:11.372: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:11.647990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:12.648151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:13.376: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:13.648382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:14.648553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:15.379: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:15.648779      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:16.648932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:17.382: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:17.649830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:18.650888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:19.386: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:19.651880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:20.652003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:21.390: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:21.652916      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:22.653084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:23.394: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:23.653963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:24.654050      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:25.398: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:25.654700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:26.654830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:27.401: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:27.655882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:28.656082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:29.406: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:29.656530      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:30.656630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:31.409: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:31.657077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:32.657173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:33.413: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:33.657682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:34.657835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:35.417: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:35.658306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:36.658392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:37.420: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:37.659248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:38.659335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:39.424: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:39.660190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:40.660287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:41.428: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:41.660416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:42.660486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:43.431: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:43.660739      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:44.661001      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:45.434: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:45.661103      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:46.661173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:47.438: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:47.662222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:48.662252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:49.442: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:49.663216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:50.663317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:51.445: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:51.664211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:52.664301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:53.449: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:53.665162      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:54.665271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:55.453: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:55.665322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:56.666161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:57.457: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:57.666879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:16:58.667893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:16:59.461: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:16:59.668735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:00.668828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:01.465: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:01.669353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:02.669441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:03.469: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:03.670051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:04.670150      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:05.473: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:05.671055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:06.671159      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:07.477: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:07.671870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:08.672892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:09.481: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:09.672927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:10.673082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:11.485: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:11.673863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:12.674037      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:13.489: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:13.674679      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:14.674833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:15.493: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:15.675717      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:16.676745      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:17.496: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:17.677164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:18.677432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:19.501: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:19.677531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:20.677895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:21.504: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:21.678760      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:22.678826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:23.509: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:23.679287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:24.679379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:25.512: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:25.679460      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:26.679891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:27.516: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:27.680323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:28.680101      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:29.520: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:29.680332      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:30.680492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:31.524: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:31.681368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:32.681566      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:33.528: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:33.682306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:34.682395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:35.531: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:35.683120      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:36.683197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:37.535: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:37.683878      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:38.683917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:39.539: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:39.684056      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:40.684209      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:41.543: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:41.684270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:42.684423      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:43.547: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:43.685217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:44.685305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:45.551: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:45.685354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:46.685449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:47.555: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:47.685706      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:48.685834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:49.560: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:49.686377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:50.687154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:51.565: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:51.687602      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:52.687891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:53.568: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:53.688150      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:54.688250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:55.572: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:55.689112      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:56.689271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:57.576: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:57.689489      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:17:58.689584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:17:59.582: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:17:59.690579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:00.690816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:01.585: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:18:01.691116      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:02.691210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:03.589: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:18:03.691560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:04.691883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:05.593: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:18:05.692251      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:06.693079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:07.597: INFO: Get pod test-webserver-de3c38a3-a331-45b6-a2d1-2824b2d0bbc5 in namespace container-probe-2059
  E1209 13:18:07.693946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:08.694147      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:09.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:18:09.603
  STEP: Destroying namespace "container-probe-2059" for this suite. @ 12/09/23 13:18:09.619
• [242.536 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 12/09/23 13:18:09.627
  Dec  9 13:18:09.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 13:18:09.628
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:09.644
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:09.646
  STEP: Discovering how many secrets are in namespace by default @ 12/09/23 13:18:09.648
  E1209 13:18:09.694798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:10.695088      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:11.695794      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:12.696226      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:13.696588      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/09/23 13:18:14.652
  E1209 13:18:14.696972      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:15.697936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:16.698317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:17.699185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:18.699411      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/09/23 13:18:19.66
  STEP: Ensuring resource quota status is calculated @ 12/09/23 13:18:19.666
  E1209 13:18:19.699576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:20.699674      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 12/09/23 13:18:21.67
  STEP: Ensuring resource quota status captures secret creation @ 12/09/23 13:18:21.681
  E1209 13:18:21.700280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:22.700434      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 12/09/23 13:18:23.685
  STEP: Ensuring resource quota status released usage @ 12/09/23 13:18:23.691
  E1209 13:18:23.700596      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:24.700704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:25.695: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1137" for this suite. @ 12/09/23 13:18:25.698
  E1209 13:18:25.700804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
• [16.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 12/09/23 13:18:25.709
  Dec  9 13:18:25.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 13:18:25.71
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:25.728
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:25.73
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 12/09/23 13:18:25.731
  Dec  9 13:18:25.732: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  E1209 13:18:26.700944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:26.968: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  E1209 13:18:27.701412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:28.701960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:29.702645      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:30.702694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:31.703496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:32.110: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7882" for this suite. @ 12/09/23 13:18:32.119
• [6.418 seconds]
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 12/09/23 13:18:32.127
  Dec  9 13:18:32.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 13:18:32.128
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:32.141
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:32.145
  STEP: Creating secret with name secret-test-202ddaca-5c1b-4dd6-84c9-2974bbc193d4 @ 12/09/23 13:18:32.149
  STEP: Creating a pod to test consume secrets @ 12/09/23 13:18:32.154
  E1209 13:18:32.703565      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:33.703684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:34.703906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:35.704085      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:18:36.173
  Dec  9 13:18:36.178: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-secrets-f093e407-3e04-46d1-8de1-e14053ee85f2 container secret-env-test: <nil>
  STEP: delete the pod @ 12/09/23 13:18:36.195
  Dec  9 13:18:36.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6322" for this suite. @ 12/09/23 13:18:36.214
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 12/09/23 13:18:36.227
  Dec  9 13:18:36.227: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/09/23 13:18:36.228
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:36.244
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:36.248
  STEP: Creating two CSIDrivers @ 12/09/23 13:18:36.253
  STEP: Getting "inline-driver-75abc529-e138-405c-8fdd-74a1561f13f3" & "inline-driver-4cb749e6-2f37-4726-a724-ce774500c538" @ 12/09/23 13:18:36.271
  STEP: Patching the CSIDriver "inline-driver-4cb749e6-2f37-4726-a724-ce774500c538" @ 12/09/23 13:18:36.278
  STEP: Updating the CSIDriver "inline-driver-4cb749e6-2f37-4726-a724-ce774500c538" @ 12/09/23 13:18:36.284
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-4563" @ 12/09/23 13:18:36.295
  STEP: Deleting CSIDriver "inline-driver-75abc529-e138-405c-8fdd-74a1561f13f3" @ 12/09/23 13:18:36.299
  STEP: Confirm deletion of CSIDriver "inline-driver-75abc529-e138-405c-8fdd-74a1561f13f3" @ 12/09/23 13:18:36.306
  STEP: Deleting CSIDriver "inline-driver-4cb749e6-2f37-4726-a724-ce774500c538" via DeleteCollection @ 12/09/23 13:18:36.31
  STEP: Confirm deletion of CSIDriver "inline-driver-4cb749e6-2f37-4726-a724-ce774500c538" @ 12/09/23 13:18:36.319
  Dec  9 13:18:36.324: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-4563" for this suite. @ 12/09/23 13:18:36.329
• [0.108 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 12/09/23 13:18:36.341
  Dec  9 13:18:36.341: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:18:36.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:36.356
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:36.36
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/09/23 13:18:36.364
  Dec  9 13:18:36.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-9851 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec  9 13:18:36.482: INFO: stderr: ""
  Dec  9 13:18:36.482: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 12/09/23 13:18:36.482
  Dec  9 13:18:36.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-9851 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Dec  9 13:18:36.561: INFO: stderr: ""
  Dec  9 13:18:36.561: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/09/23 13:18:36.561
  Dec  9 13:18:36.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-9851 delete pods e2e-test-httpd-pod'
  E1209 13:18:36.704156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:37.704275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:38.313: INFO: stderr: ""
  Dec  9 13:18:38.313: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec  9 13:18:38.313: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9851" for this suite. @ 12/09/23 13:18:38.318
• [1.984 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 12/09/23 13:18:38.325
  Dec  9 13:18:38.325: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 13:18:38.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:38.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:38.344
  STEP: Creating a test headless service @ 12/09/23 13:18:38.347
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7269.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7269.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7269.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7269.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 100.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.100_udp@PTR;check="$$(dig +tcp +noall +answer +search 100.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.100_tcp@PTR;sleep 1; done
   @ 12/09/23 13:18:38.367
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7269.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7269.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7269.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7269.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7269.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 100.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.100_udp@PTR;check="$$(dig +tcp +noall +answer +search 100.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.100_tcp@PTR;sleep 1; done
   @ 12/09/23 13:18:38.367
  STEP: creating a pod to probe DNS @ 12/09/23 13:18:38.367
  STEP: submitting the pod to kubernetes @ 12/09/23 13:18:38.368
  E1209 13:18:38.704348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:39.705272      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/09/23 13:18:40.387
  STEP: looking for the results for each expected name from probers @ 12/09/23 13:18:40.39
  Dec  9 13:18:40.395: INFO: Unable to read wheezy_udp@dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.400: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.403: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.407: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.426: INFO: Unable to read jessie_udp@dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.430: INFO: Unable to read jessie_tcp@dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.434: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.438: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local from pod dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1: the server could not find the requested resource (get pods dns-test-908b31af-c716-4c5f-b918-d35898324ca1)
  Dec  9 13:18:40.453: INFO: Lookups using dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1 failed for: [wheezy_udp@dns-test-service.dns-7269.svc.cluster.local wheezy_tcp@dns-test-service.dns-7269.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local jessie_udp@dns-test-service.dns-7269.svc.cluster.local jessie_tcp@dns-test-service.dns-7269.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7269.svc.cluster.local]

  Dec  9 13:18:40.461: INFO: Pod client logs for webserver: 
  Dec  9 13:18:40.466: INFO: Pod client logs for querier: 
  Dec  9 13:18:40.472: INFO: Pod client logs for jessie-querier: 
  E1209 13:18:40.706129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:41.706215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:42.706284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:43.706440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:44.707297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:45.535: INFO: DNS probes using dns-7269/dns-test-908b31af-c716-4c5f-b918-d35898324ca1 succeeded

  Dec  9 13:18:45.535: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:18:45.54
  STEP: deleting the test service @ 12/09/23 13:18:45.553
  STEP: deleting the test headless service @ 12/09/23 13:18:45.582
  STEP: Destroying namespace "dns-7269" for this suite. @ 12/09/23 13:18:45.596
• [7.278 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 12/09/23 13:18:45.604
  Dec  9 13:18:45.604: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 13:18:45.604
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:45.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:45.623
  STEP: creating pod @ 12/09/23 13:18:45.627
  E1209 13:18:45.707458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:46.707553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:18:47.654: INFO: Pod pod-hostip-ed23935f-fa93-4b45-92aa-dc0725c4a620 has hostIP: 172.31.77.176
  Dec  9 13:18:47.654: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-2073" for this suite. @ 12/09/23 13:18:47.66
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 12/09/23 13:18:47.671
  Dec  9 13:18:47.671: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 13:18:47.672
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:47.69
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:47.696
  STEP: Creating secret with name secret-test-ab615701-c21a-40c6-98e7-d624b34ae563 @ 12/09/23 13:18:47.7
  STEP: Creating a pod to test consume secrets @ 12/09/23 13:18:47.707
  E1209 13:18:47.708525      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:48.708813      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:49.708991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:50.709190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:51.709271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:18:51.736
  Dec  9 13:18:51.741: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-secrets-413eea67-38f6-4b45-a3e2-f89bb7adbcd4 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 13:18:51.747
  Dec  9 13:18:51.763: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6384" for this suite. @ 12/09/23 13:18:51.767
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 12/09/23 13:18:51.775
  Dec  9 13:18:51.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:18:51.775
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:51.794
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:51.799
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:18:51.803
  E1209 13:18:52.709352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:53.709654      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:18:53.827
  Dec  9 13:18:53.830: INFO: Trying to get logs from node ip-172-31-38-129 pod downwardapi-volume-67428328-4162-4909-a111-48e286a6dc7c container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:18:53.849
  Dec  9 13:18:53.868: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4927" for this suite. @ 12/09/23 13:18:53.871
• [2.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 12/09/23 13:18:53.879
  Dec  9 13:18:53.879: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 13:18:53.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:53.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:53.898
  STEP: creating the pod @ 12/09/23 13:18:53.903
  STEP: submitting the pod to kubernetes @ 12/09/23 13:18:53.903
  E1209 13:18:54.709705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:55.709876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/09/23 13:18:55.927
  STEP: updating the pod @ 12/09/23 13:18:55.931
  Dec  9 13:18:56.444: INFO: Successfully updated pod "pod-update-905fa7b3-cc4e-4921-9f68-d589ce9659e0"
  STEP: verifying the updated pod is in kubernetes @ 12/09/23 13:18:56.449
  Dec  9 13:18:56.454: INFO: Pod update OK
  Dec  9 13:18:56.454: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-1340" for this suite. @ 12/09/23 13:18:56.458
• [2.585 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 12/09/23 13:18:56.465
  Dec  9 13:18:56.465: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:18:56.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:56.481
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:56.485
  STEP: Creating configMap configmap-4971/configmap-test-3f132dca-ab0e-4dfb-b935-e26667e2aeab @ 12/09/23 13:18:56.489
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:18:56.496
  E1209 13:18:56.710799      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:57.710859      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:18:58.513
  Dec  9 13:18:58.516: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-configmaps-fe673e7d-999c-4472-95be-f3a18d79f3ef container env-test: <nil>
  STEP: delete the pod @ 12/09/23 13:18:58.523
  Dec  9 13:18:58.540: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4971" for this suite. @ 12/09/23 13:18:58.543
• [2.086 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 12/09/23 13:18:58.552
  Dec  9 13:18:58.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-runtime @ 12/09/23 13:18:58.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:18:58.569
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:18:58.572
  STEP: create the container @ 12/09/23 13:18:58.576
  W1209 13:18:58.585066      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 12/09/23 13:18:58.585
  E1209 13:18:58.711844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:18:59.712774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:00.713783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/09/23 13:19:01.604
  STEP: the container should be terminated @ 12/09/23 13:19:01.608
  STEP: the termination message should be set @ 12/09/23 13:19:01.608
  Dec  9 13:19:01.608: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/09/23 13:19:01.608
  Dec  9 13:19:01.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-8284" for this suite. @ 12/09/23 13:19:01.629
• [3.085 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 12/09/23 13:19:01.638
  Dec  9 13:19:01.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-preemption @ 12/09/23 13:19:01.639
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:19:01.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:19:01.659
  Dec  9 13:19:01.679: INFO: Waiting up to 1m0s for all nodes to be ready
  E1209 13:19:01.714079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:02.714185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:03.714458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:04.714559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:05.715190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:06.715882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:07.716564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:08.717609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:09.718340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:10.718447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:11.719380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:12.719486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:13.719868      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:14.719991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:15.720180      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:16.721281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:17.722257      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:18.722542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:19.723310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:20.723408      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:21.723891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:22.724047      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:23.724184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:24.724360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:25.725275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:26.725814      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:27.726218      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:28.727190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:29.728152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:30.729163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:31.729221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:32.729368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:33.730382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:34.730583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:35.731593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:36.731694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:37.732164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:38.732419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:39.733127      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:40.733221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:41.733529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:42.733620      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:43.733677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:44.733875      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:45.734435      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:46.734563      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:47.735524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:48.735623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:49.736304      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:50.737011      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:51.737313      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:52.737583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:53.737868      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:54.737958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:55.738761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:56.738826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:57.739887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:58.740028      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:19:59.740302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:00.740594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:01.714: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/09/23 13:20:01.717
  Dec  9 13:20:01.717: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/09/23 13:20:01.718
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:20:01.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:20:01.737
  E1209 13:20:01.740589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:01.754: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Dec  9 13:20:01.758: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Dec  9 13:20:01.778: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 13:20:01.795: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-2599" for this suite. @ 12/09/23 13:20:01.844
  STEP: Destroying namespace "sched-preemption-6842" for this suite. @ 12/09/23 13:20:01.851
• [60.220 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 12/09/23 13:20:01.859
  Dec  9 13:20:01.859: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename namespaces @ 12/09/23 13:20:01.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:20:01.875
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:20:01.878
  STEP: creating a Namespace @ 12/09/23 13:20:01.882
  STEP: patching the Namespace @ 12/09/23 13:20:01.897
  STEP: get the Namespace and ensuring it has the label @ 12/09/23 13:20:01.904
  Dec  9 13:20:01.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-255" for this suite. @ 12/09/23 13:20:01.916
  STEP: Destroying namespace "nspatchtest-7c9b1474-5f30-45f0-acc6-07a69587ea27-2171" for this suite. @ 12/09/23 13:20:01.923
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 12/09/23 13:20:01.929
  Dec  9 13:20:01.929: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:20:01.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:20:01.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:20:01.948
  STEP: Creating the pod @ 12/09/23 13:20:01.951
  E1209 13:20:02.741629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:03.741956      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:04.495: INFO: Successfully updated pod "labelsupdatece5af1ca-b987-4970-84bc-e140ccfb7372"
  E1209 13:20:04.742928      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:05.743013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:06.743208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:07.743319      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:08.520: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3387" for this suite. @ 12/09/23 13:20:08.525
• [6.603 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 12/09/23 13:20:08.533
  Dec  9 13:20:08.533: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename events @ 12/09/23 13:20:08.533
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:20:08.55
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:20:08.553
  STEP: creating a test event @ 12/09/23 13:20:08.557
  STEP: listing events in all namespaces @ 12/09/23 13:20:08.564
  STEP: listing events in test namespace @ 12/09/23 13:20:08.568
  STEP: listing events with field selection filtering on source @ 12/09/23 13:20:08.572
  STEP: listing events with field selection filtering on reportingController @ 12/09/23 13:20:08.575
  STEP: getting the test event @ 12/09/23 13:20:08.578
  STEP: patching the test event @ 12/09/23 13:20:08.581
  STEP: getting the test event @ 12/09/23 13:20:08.59
  STEP: updating the test event @ 12/09/23 13:20:08.594
  STEP: getting the test event @ 12/09/23 13:20:08.601
  STEP: deleting the test event @ 12/09/23 13:20:08.605
  STEP: listing events in all namespaces @ 12/09/23 13:20:08.613
  STEP: listing events in test namespace @ 12/09/23 13:20:08.618
  Dec  9 13:20:08.621: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1093" for this suite. @ 12/09/23 13:20:08.626
• [0.101 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 12/09/23 13:20:08.634
  Dec  9 13:20:08.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 13:20:08.635
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:20:08.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:20:08.651
  STEP: Creating pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994 @ 12/09/23 13:20:08.655
  E1209 13:20:08.743718      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:09.744285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 13:20:10.673
  Dec  9 13:20:10.676: INFO: Initial restart count of pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 is 0
  Dec  9 13:20:10.680: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:10.745288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:11.745379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:12.684: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:12.746376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:13.746457      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:14.689: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:14.747246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:15.747901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:16.694: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:16.748421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:17.748628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:18.698: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:18.749192      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:19.749225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:20.703: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:20.749520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:21.749617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:22.707: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:22.750004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:23.750921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:24.711: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:24.751607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:25.751696      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:26.716: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:26.752450      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:27.752689      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:28.721: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:28.753387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:29.753466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:30.724: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  Dec  9 13:20:30.724: INFO: Restart count of pod container-probe-5994/liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 is now 1 (20.048317362s elapsed)
  E1209 13:20:30.754024      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:31.754123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:32.729: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:32.754351      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:33.754737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:34.732: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:34.755068      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:35.755919      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:36.736: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:36.756032      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:37.756080      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:38.741: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:38.757091      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:39.757194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:40.745: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:40.757794      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:41.757889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:42.750: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:42.758719      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:43.758853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:44.755: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:44.759664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:45.759961      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:46.760201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:46.760: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:47.760651      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:48.760943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:48.765: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:49.761026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:50.761099      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:50.770: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  Dec  9 13:20:50.770: INFO: Restart count of pod container-probe-5994/liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 is now 2 (40.09376964s elapsed)
  E1209 13:20:51.761192      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:52.761262      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:52.775: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:53.761382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:54.761472      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:54.780: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:55.761571      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:56.761653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:56.787: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:57.761743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:20:58.761912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:20:58.791: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:20:59.762770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:00.762892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:00.796: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:01.763041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:02.763097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:02.802: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:03.763879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:04.763990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:04.808: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:05.764179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:06.764367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:06.813: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:07.764464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:08.764540      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:08.817: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:09.764641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:10.764728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:10.822: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  Dec  9 13:21:10.822: INFO: Restart count of pod container-probe-5994/liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 is now 3 (1m0.146144937s elapsed)
  E1209 13:21:11.764838      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:12.764917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:12.826: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:13.765764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:14.765951      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:14.830: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:15.766994      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:16.768051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:16.835: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:17.768146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:18.768472      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:18.839: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:19.768570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:20.768750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:20.843: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:21.769387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:22.769466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:22.848: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:23.769542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:24.769623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:24.853: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:25.769711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:26.769994      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:26.859: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:27.770741      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:28.770844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:28.863: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:29.770936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:30.771903      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:30.869: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  Dec  9 13:21:30.869: INFO: Restart count of pod container-probe-5994/liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 is now 4 (1m20.192638911s elapsed)
  E1209 13:21:31.772059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:32.772254      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:32.873: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:33.772339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:34.772452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:34.877: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:35.773249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:36.773402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:36.882: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:37.773485      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:38.773554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:38.887: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:39.774120      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:40.774799      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:40.892: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:41.775626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:42.776672      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:42.897: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:43.776758      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:44.776840      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:44.902: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:45.776952      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:46.777126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:46.906: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:47.777479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:48.777565      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:48.910: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:49.777665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:50.777827      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:50.927: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:51.777858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:52.777954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:52.931: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:53.778063      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:54.778312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:54.937: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:55.778823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:56.778929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:56.942: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:57.779896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:21:58.779945      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:21:58.947: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:21:59.780889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:00.781070      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:00.952: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:01.781316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:02.781475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:02.957: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:03.782215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:04.783268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:04.961: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:05.783357      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:06.783883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:06.965: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:07.784559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:08.784644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:08.970: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:09.785570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:10.785665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:10.975: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:11.785767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:12.786610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:12.980: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:13.787120      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:14.787217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:14.985: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:15.787887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:16.788045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:16.989: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:17.788076      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:18.788280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:18.993: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:19.788418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:20.788506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:20.997: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:21.788600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:22.788759      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:23.002: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:23.789814      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:24.789866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:25.008: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:25.789950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:26.790115      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:27.012: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:27.790170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:28.790427      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:29.016: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:29.791385      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:30.791473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:31.021: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:31.791729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:32.791815      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:33.027: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  E1209 13:22:33.791899      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:34.792063      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:35.032: INFO: Get pod liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 in namespace container-probe-5994
  Dec  9 13:22:35.032: INFO: Restart count of pod container-probe-5994/liveness-efb3aa91-962f-4ee0-ba09-1e3020b89e62 is now 5 (2m24.355632023s elapsed)
  Dec  9 13:22:35.032: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:22:35.037
  STEP: Destroying namespace "container-probe-5994" for this suite. @ 12/09/23 13:22:35.051
• [146.426 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 12/09/23 13:22:35.061
  Dec  9 13:22:35.061: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 13:22:35.061
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:22:35.076
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:22:35.08
  STEP: Creating a test headless service @ 12/09/23 13:22:35.083
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1830 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1830;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1830 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1830;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1830.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1830.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1830.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1830.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1830.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1830.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1830.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1830.svc;check="$$(dig +notcp +noall +answer +search 81.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.81_udp@PTR;check="$$(dig +tcp +noall +answer +search 81.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.81_tcp@PTR;sleep 1; done
   @ 12/09/23 13:22:35.102
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1830 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1830;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1830 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1830;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1830.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1830.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1830.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1830.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1830.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1830.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1830.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1830.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1830.svc;check="$$(dig +notcp +noall +answer +search 81.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.81_udp@PTR;check="$$(dig +tcp +noall +answer +search 81.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.81_tcp@PTR;sleep 1; done
   @ 12/09/23 13:22:35.102
  STEP: creating a pod to probe DNS @ 12/09/23 13:22:35.102
  STEP: submitting the pod to kubernetes @ 12/09/23 13:22:35.103
  E1209 13:22:35.792854      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:36.792940      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/09/23 13:22:37.128
  STEP: looking for the results for each expected name from probers @ 12/09/23 13:22:37.133
  Dec  9 13:22:37.137: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.141: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.146: INFO: Unable to read wheezy_udp@dns-test-service.dns-1830 from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.150: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1830 from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.154: INFO: Unable to read wheezy_udp@dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.159: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.162: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.166: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.185: INFO: Unable to read jessie_udp@dns-test-service from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.189: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.194: INFO: Unable to read jessie_udp@dns-test-service.dns-1830 from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.197: INFO: Unable to read jessie_tcp@dns-test-service.dns-1830 from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.201: INFO: Unable to read jessie_udp@dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.205: INFO: Unable to read jessie_tcp@dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.208: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.212: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1830.svc from pod dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674: the server could not find the requested resource (get pods dns-test-04f0e639-999b-417e-88fd-92e00acb8674)
  Dec  9 13:22:37.227: INFO: Lookups using dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-1830 wheezy_tcp@dns-test-service.dns-1830 wheezy_udp@dns-test-service.dns-1830.svc wheezy_tcp@dns-test-service.dns-1830.svc wheezy_udp@_http._tcp.dns-test-service.dns-1830.svc wheezy_tcp@_http._tcp.dns-test-service.dns-1830.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-1830 jessie_tcp@dns-test-service.dns-1830 jessie_udp@dns-test-service.dns-1830.svc jessie_tcp@dns-test-service.dns-1830.svc jessie_udp@_http._tcp.dns-test-service.dns-1830.svc jessie_tcp@_http._tcp.dns-test-service.dns-1830.svc]

  Dec  9 13:22:37.240: INFO: Pod client logs for webserver: 
  Dec  9 13:22:37.247: INFO: Pod client logs for querier: 
  Dec  9 13:22:37.253: INFO: Pod client logs for jessie-querier: 
  E1209 13:22:37.793907      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:38.794108      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:39.794179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:40.794271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:41.794345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:22:42.345: INFO: DNS probes using dns-1830/dns-test-04f0e639-999b-417e-88fd-92e00acb8674 succeeded

  Dec  9 13:22:42.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:22:42.349
  STEP: deleting the test service @ 12/09/23 13:22:42.371
  STEP: deleting the test headless service @ 12/09/23 13:22:42.396
  STEP: Destroying namespace "dns-1830" for this suite. @ 12/09/23 13:22:42.419
• [7.368 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 12/09/23 13:22:42.429
  Dec  9 13:22:42.429: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename taint-multiple-pods @ 12/09/23 13:22:42.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:22:42.443
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:22:42.448
  Dec  9 13:22:42.451: INFO: Waiting up to 1m0s for all nodes to be ready
  E1209 13:22:42.794832      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:43.794938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:44.795026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:45.795102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:46.795500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:47.795576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:48.795682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:49.795762      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:50.796184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:51.796271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:52.796735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:53.797073      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:54.797694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:55.797918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:56.798005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:57.798688      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:58.799602      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:22:59.799684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:00.799734      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:01.799826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:02.799909      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:03.800262      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:04.801321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:05.801404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:06.802408      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:07.802500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:08.802587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:09.802678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:10.802991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:11.803905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:12.804686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:13.805028      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:14.805584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:15.805678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:16.806392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:17.806452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:18.807179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:19.807255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:20.807871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:21.808018      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:22.808559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:23.808651      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:24.808744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:25.808997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:26.809470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:27.809778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:28.809569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:29.809846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:30.810658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:31.810824      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:32.810914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:33.811927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:34.812331      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:35.812422      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:36.813270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:37.813482      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:38.813969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:39.814131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:40.815065      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:41.815839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:23:42.468: INFO: Waiting for terminating namespaces to be deleted...
  Dec  9 13:23:42.471: INFO: Starting informer...
  STEP: Starting pods... @ 12/09/23 13:23:42.471
  Dec  9 13:23:42.694: INFO: Pod1 is running on ip-172-31-77-176. Tainting Node
  E1209 13:23:42.816160      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:43.816665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:44.816747      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:23:44.922: INFO: Pod2 is running on ip-172-31-77-176. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/09/23 13:23:44.922
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/09/23 13:23:44.933
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 12/09/23 13:23:44.938
  E1209 13:23:45.817622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:46.817796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:47.818384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:48.819368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:49.819445      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:50.819545      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:23:50.868: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E1209 13:23:51.819563      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:52.819655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:53.820013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:54.820321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:55.820410      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:56.820495      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:57.820653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:58.820735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:23:59.820911      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:00.821078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:01.821237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:02.821324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:03.821417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:04.822291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:05.822378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:06.822589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:07.822778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:08.822834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:09.823893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:10.824027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:10.906: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Dec  9 13:24:10.906: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/09/23 13:24:10.955
  STEP: Destroying namespace "taint-multiple-pods-8972" for this suite. @ 12/09/23 13:24:10.96
• [88.550 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 12/09/23 13:24:10.981
  Dec  9 13:24:10.981: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/09/23 13:24:10.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:11.005
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:11.011
  E1209 13:24:11.824858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:12.825247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:13.053: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 12/09/23 13:24:13.057
  STEP: Cleaning up the configmap @ 12/09/23 13:24:13.063
  STEP: Cleaning up the pod @ 12/09/23 13:24:13.07
  STEP: Destroying namespace "emptydir-wrapper-5991" for this suite. @ 12/09/23 13:24:13.086
• [2.111 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 12/09/23 13:24:13.093
  Dec  9 13:24:13.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 13:24:13.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:13.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:13.112
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4946 @ 12/09/23 13:24:13.115
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/09/23 13:24:13.125
  STEP: creating service externalsvc in namespace services-4946 @ 12/09/23 13:24:13.126
  STEP: creating replication controller externalsvc in namespace services-4946 @ 12/09/23 13:24:13.14
  I1209 13:24:13.148465      18 runners.go:197] Created replication controller with name: externalsvc, namespace: services-4946, replica count: 2
  E1209 13:24:13.825425      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:14.825714      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:15.825807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1209 13:24:16.200364      18 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 12/09/23 13:24:16.203
  Dec  9 13:24:16.220: INFO: Creating new exec pod
  E1209 13:24:16.826198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:17.826274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:18.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-4946 exec execpodzf9l6 -- /bin/sh -x -c nslookup clusterip-service.services-4946.svc.cluster.local'
  Dec  9 13:24:18.359: INFO: stderr: "+ nslookup clusterip-service.services-4946.svc.cluster.local\n"
  Dec  9 13:24:18.359: INFO: stdout: "Server:\t\t10.152.183.120\nAddress:\t10.152.183.120#53\n\nclusterip-service.services-4946.svc.cluster.local\tcanonical name = externalsvc.services-4946.svc.cluster.local.\nName:\texternalsvc.services-4946.svc.cluster.local\nAddress: 10.152.183.172\n\n"
  Dec  9 13:24:18.359: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-4946, will wait for the garbage collector to delete the pods @ 12/09/23 13:24:18.364
  Dec  9 13:24:18.426: INFO: Deleting ReplicationController externalsvc took: 7.583549ms
  Dec  9 13:24:18.526: INFO: Terminating ReplicationController externalsvc pods took: 100.248989ms
  E1209 13:24:18.827021      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:19.828062      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:20.828075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:21.150: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-4946" for this suite. @ 12/09/23 13:24:21.16
• [8.076 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 12/09/23 13:24:21.169
  Dec  9 13:24:21.169: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename gc @ 12/09/23 13:24:21.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:21.183
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:21.187
  Dec  9 13:24:21.230: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"99c70527-f537-4100-b2f5-9d8ae1959f6d", Controller:(*bool)(0xc0061d249e), BlockOwnerDeletion:(*bool)(0xc0061d249f)}}
  Dec  9 13:24:21.238: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"baa47bd6-a7e2-4da6-900d-2d8c1ea04ea8", Controller:(*bool)(0xc004c167de), BlockOwnerDeletion:(*bool)(0xc004c167df)}}
  Dec  9 13:24:21.244: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fd33ea0a-c2c4-4465-bdb8-e3284ca77385", Controller:(*bool)(0xc004c16a7e), BlockOwnerDeletion:(*bool)(0xc004c16a7f)}}
  E1209 13:24:21.828587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:22.828692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:23.828766      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:24.828950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:25.829040      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:26.255: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2672" for this suite. @ 12/09/23 13:24:26.259
• [5.096 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 12/09/23 13:24:26.266
  Dec  9 13:24:26.266: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 13:24:26.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:26.281
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:26.286
  Dec  9 13:24:26.290: INFO: Creating simple deployment test-new-deployment
  Dec  9 13:24:26.309: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E1209 13:24:26.829969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:27.830167      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 12/09/23 13:24:28.324
  STEP: updating a scale subresource @ 12/09/23 13:24:28.328
  STEP: verifying the deployment Spec.Replicas was modified @ 12/09/23 13:24:28.333
  STEP: Patch a scale subresource @ 12/09/23 13:24:28.337
  Dec  9 13:24:28.362: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3481",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "024747d2-3938-4538-8a3a-607e231cd79f",
      ResourceVersion: (string) (len=5) "30219",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  9 13:24:28.371: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3481",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "0654e77d-3943-4729-8f33-c272c671ef58",
      ResourceVersion: (string) (len=5) "30222",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "5",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "4"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "024747d2-3938-4538-8a3a-607e231cd79f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 32 34 37 34 37  64 32 2d 33 39 33 38 2d  |\"024747d2-3938-|
              00000120  34 35 33 38 2d 38 61 33  61 2d 36 30 37 65 32 33  |4538-8a3a-607e23|
              00000130  31 63 64 37 39 66 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |1cd79f\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(4),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:24:28.378: INFO: Pod "test-new-deployment-557759b7c7-vh2z2" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-vh2z2",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-3481",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f680712d-9e23-49b1-857c-94fbf94f12e1",
      ResourceVersion: (string) (len=5) "30213",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0654e77d-3943-4729-8f33-c272c671ef58",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 36  35 34 65 37 37 64 2d 33  |d\":\"0654e77d-3|
              00000090  39 34 33 2d 34 37 32 39  2d 38 66 33 33 2d 63 32  |943-4729-8f33-c2|
              000000a0  37 32 63 36 37 31 65 66  35 38 5c 22 7d 22 3a 7b  |72c671ef58\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 32 34 5c 22 7d  |192.168.34.24\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-89rx5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-89rx5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725067,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725066,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.24",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.24"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725066,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837725066,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://1ceb92a37acbb6231534c061537606d515e5d20ecdddb3d3240ee72d5b2a83c8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 13:24:28.380: INFO: Pod "test-new-deployment-557759b7c7-wbbrc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-wbbrc",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-3481",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d54d4aba-4e1e-4f62-816a-3e5379df08f6",
      ResourceVersion: (string) (len=5) "30230",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725068,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "0654e77d-3943-4729-8f33-c272c671ef58",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 30 36  35 34 65 37 37 64 2d 33  |d\":\"0654e77d-3|
              00000090  39 34 33 2d 34 37 32 39  2d 38 66 33 33 2d 63 32  |943-4729-8f33-c2|
              000000a0  37 32 63 36 37 31 65 66  35 38 5c 22 7d 22 3a 7b  |72c671ef58\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-pbt8m",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-pbt8m",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-38-129",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.38.129",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725068,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 13:24:28.382: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3481" for this suite. @ 12/09/23 13:24:28.392
• [2.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 12/09/23 13:24:28.404
  Dec  9 13:24:28.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename deployment @ 12/09/23 13:24:28.404
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:28.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:28.434
  Dec  9 13:24:28.449: INFO: Pod name rollover-pod: Found 0 pods out of 1
  E1209 13:24:28.831303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:29.831329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:30.831395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:31.831923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:32.832026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:33.455: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/09/23 13:24:33.455
  Dec  9 13:24:33.455: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  E1209 13:24:33.832469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:34.832562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:35.460: INFO: Creating deployment "test-rollover-deployment"
  Dec  9 13:24:35.469: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  E1209 13:24:35.832639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:36.832716      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:37.479: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Dec  9 13:24:37.487: INFO: Ensure that both replica sets have 1 created replica
  Dec  9 13:24:37.494: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Dec  9 13:24:37.504: INFO: Updating deployment test-rollover-deployment
  Dec  9 13:24:37.504: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  E1209 13:24:37.832812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:38.832968      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:39.513: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Dec  9 13:24:39.520: INFO: Make sure deployment "test-rollover-deployment" is complete
  Dec  9 13:24:39.527: INFO: all replica sets need to contain the pod-template-hash label
  Dec  9 13:24:39.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1209 13:24:39.833070      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:40.833152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:41.536: INFO: all replica sets need to contain the pod-template-hash label
  Dec  9 13:24:41.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1209 13:24:41.833670      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:42.833850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:43.536: INFO: all replica sets need to contain the pod-template-hash label
  Dec  9 13:24:43.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1209 13:24:43.834621      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:44.835010      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:45.535: INFO: all replica sets need to contain the pod-template-hash label
  Dec  9 13:24:45.535: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1209 13:24:45.835902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:46.836225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:47.536: INFO: all replica sets need to contain the pod-template-hash label
  Dec  9 13:24:47.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 24, 38, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 24, 35, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1209 13:24:47.836725      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:48.836994      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:49.536: INFO: 
  Dec  9 13:24:49.536: INFO: Ensure that both old replica sets have no replicas
  Dec  9 13:24:49.547: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7041",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "01e8fcb7-4af7-45b8-b9b6-f35ec0043090",
      ResourceVersion: (string) (len=5) "30419",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725075,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725075,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5d484bf7f9\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  9 13:24:49.553: INFO: New ReplicaSet "test-rollover-deployment-5d484bf7f9" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7041",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8feae5bb-1c06-4118-8616-df880ac2c035",
      ResourceVersion: (string) (len=5) "30409",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725077,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "01e8fcb7-4af7-45b8-b9b6-f35ec0043090",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 31 65 38 66 63  62 37 2d 34 61 66 37 2d  |\"01e8fcb7-4af7-|
              00000120  34 35 62 38 2d 62 39 62  36 2d 66 33 35 65 63 30  |45b8-b9b6-f35ec0|
              00000130  30 34 33 30 39 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |043090\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:24:49.554: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Dec  9 13:24:49.554: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7041",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "314afa66-8191-46c3-a622-be6d99734969",
      ResourceVersion: (string) (len=5) "30418",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725068,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "01e8fcb7-4af7-45b8-b9b6-f35ec0043090",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725068,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725088,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  30 31 65 38 66 63 62 37  2d 34 61 66 37 2d 34 35  |01e8fcb7-4af7-45|
              000000c0  62 38 2d 62 39 62 36 2d  66 33 35 65 63 30 30 34  |b8-b9b6-f35ec004|
              000000d0  33 30 39 30 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |3090\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725089,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:24:49.555: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-7041",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "78f56cdf-5d60-43aa-929d-7a8c4da9370b",
      ResourceVersion: (string) (len=5) "30371",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725075,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "01e8fcb7-4af7-45b8-b9b6-f35ec0043090",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 30 31 65 38 66 63  62 37 2d 34 61 66 37 2d  |\"01e8fcb7-4af7-|
              00000120  34 35 62 38 2d 62 39 62  36 2d 66 33 35 65 63 30  |45b8-b9b6-f35ec0|
              00000130  30 34 33 30 39 30 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |043090\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  9 13:24:49.559: INFO: Pod "test-rollover-deployment-5d484bf7f9-k4qzv" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5d484bf7f9-k4qzv",
      GenerateName: (string) (len=36) "test-rollover-deployment-5d484bf7f9-",
      Namespace: (string) (len=15) "deployment-7041",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "19490acb-02c2-4a58-b83c-7dda414d2b46",
      ResourceVersion: (string) (len=5) "30387",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725077,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
          UID: (types.UID) (len=36) "8feae5bb-1c06-4118-8616-df880ac2c035",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 38 66  65 61 65 35 62 62 2d 31  |d\":\"8feae5bb-1|
              00000090  63 30 36 2d 34 31 31 38  2d 38 36 31 36 2d 64 66  |c06-4118-8616-df|
              000000a0  38 38 30 61 63 32 63 30  33 35 5c 22 7d 22 3a 7b  |880ac2c035\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725078,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  33 34 2e 33 30 5c 22 7d  |192.168.34.30\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-kzgqf",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-kzgqf",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-77-176",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725078,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725078,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837725077,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.77.176",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.34.30",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.34.30"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837725077,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837725078,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://0d797ce5d0a5c32080b2e050224d69c2219c7bee157c62f7494f973b6cc92bcc",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  9 13:24:49.561: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-7041" for this suite. @ 12/09/23 13:24:49.565
• [21.168 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 12/09/23 13:24:49.572
  Dec  9 13:24:49.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:24:49.573
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:49.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:49.592
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/09/23 13:24:49.595
  E1209 13:24:49.837085      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:50.837396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:51.837788      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:52.837913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:24:53.619
  Dec  9 13:24:53.622: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-7ba35fb7-fb29-4c7a-ad64-9cc1a2175ad0 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:24:53.637
  Dec  9 13:24:53.653: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1575" for this suite. @ 12/09/23 13:24:53.657
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 12/09/23 13:24:53.664
  Dec  9 13:24:53.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:24:53.665
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:53.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:53.688
  STEP: validating api versions @ 12/09/23 13:24:53.696
  Dec  9 13:24:53.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-7500 api-versions'
  Dec  9 13:24:53.747: INFO: stderr: ""
  Dec  9 13:24:53.747: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Dec  9 13:24:53.747: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7500" for this suite. @ 12/09/23 13:24:53.752
• [0.095 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 12/09/23 13:24:53.759
  Dec  9 13:24:53.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 13:24:53.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:24:53.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:24:53.777
  STEP: creating the pod @ 12/09/23 13:24:53.781
  STEP: submitting the pod to kubernetes @ 12/09/23 13:24:53.781
  W1209 13:24:53.791231      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E1209 13:24:53.838416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:54.838478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/09/23 13:24:55.802
  STEP: updating the pod @ 12/09/23 13:24:55.807
  E1209 13:24:55.839396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:24:56.328: INFO: Successfully updated pod "pod-update-activedeadlineseconds-1974a890-7bbf-426d-808c-979fb3cc487e"
  E1209 13:24:56.839561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:57.839651      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:58.839738      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:24:59.839826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:25:00.341: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6661" for this suite. @ 12/09/23 13:25:00.344
• [6.591 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 12/09/23 13:25:00.352
  Dec  9 13:25:00.352: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename controllerrevisions @ 12/09/23 13:25:00.352
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:25:00.369
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:25:00.372
  STEP: Creating DaemonSet "e2e-gwsqk-daemon-set" @ 12/09/23 13:25:00.399
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/09/23 13:25:00.404
  Dec  9 13:25:00.410: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:25:00.410: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:25:00.414: INFO: Number of nodes with available pods controlled by daemonset e2e-gwsqk-daemon-set: 0
  Dec  9 13:25:00.414: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  E1209 13:25:00.840682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:25:01.418: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:25:01.418: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:25:01.422: INFO: Number of nodes with available pods controlled by daemonset e2e-gwsqk-daemon-set: 1
  Dec  9 13:25:01.422: INFO: Node ip-172-31-77-176 is running 0 daemon pod, expected 1
  E1209 13:25:01.841045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:25:02.419: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:25:02.419: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:25:02.423: INFO: Number of nodes with available pods controlled by daemonset e2e-gwsqk-daemon-set: 3
  Dec  9 13:25:02.423: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-gwsqk-daemon-set
  STEP: Confirm DaemonSet "e2e-gwsqk-daemon-set" successfully created with "daemonset-name=e2e-gwsqk-daemon-set" label @ 12/09/23 13:25:02.428
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-gwsqk-daemon-set" @ 12/09/23 13:25:02.434
  Dec  9 13:25:02.439: INFO: Located ControllerRevision: "e2e-gwsqk-daemon-set-dbbd67d44"
  STEP: Patching ControllerRevision "e2e-gwsqk-daemon-set-dbbd67d44" @ 12/09/23 13:25:02.442
  Dec  9 13:25:02.448: INFO: e2e-gwsqk-daemon-set-dbbd67d44 has been patched
  STEP: Create a new ControllerRevision @ 12/09/23 13:25:02.448
  Dec  9 13:25:02.455: INFO: Created ControllerRevision: e2e-gwsqk-daemon-set-66b77fd698
  STEP: Confirm that there are two ControllerRevisions @ 12/09/23 13:25:02.455
  Dec  9 13:25:02.455: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  9 13:25:02.458: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-gwsqk-daemon-set-dbbd67d44" @ 12/09/23 13:25:02.458
  STEP: Confirm that there is only one ControllerRevision @ 12/09/23 13:25:02.465
  Dec  9 13:25:02.465: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  9 13:25:02.468: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-gwsqk-daemon-set-66b77fd698" @ 12/09/23 13:25:02.472
  Dec  9 13:25:02.482: INFO: e2e-gwsqk-daemon-set-66b77fd698 has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 12/09/23 13:25:02.482
  W1209 13:25:02.488487      18 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 12/09/23 13:25:02.488
  Dec  9 13:25:02.488: INFO: Requesting list of ControllerRevisions to confirm quantity
  E1209 13:25:02.841853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:25:03.494: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  9 13:25:03.498: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-gwsqk-daemon-set-66b77fd698=updated" @ 12/09/23 13:25:03.498
  STEP: Confirm that there is only one ControllerRevision @ 12/09/23 13:25:03.506
  Dec  9 13:25:03.506: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  9 13:25:03.510: INFO: Found 1 ControllerRevisions
  Dec  9 13:25:03.514: INFO: ControllerRevision "e2e-gwsqk-daemon-set-68d95cffd7" has revision 3
  STEP: Deleting DaemonSet "e2e-gwsqk-daemon-set" @ 12/09/23 13:25:03.517
  STEP: deleting DaemonSet.extensions e2e-gwsqk-daemon-set in namespace controllerrevisions-1190, will wait for the garbage collector to delete the pods @ 12/09/23 13:25:03.517
  Dec  9 13:25:03.578: INFO: Deleting DaemonSet.extensions e2e-gwsqk-daemon-set took: 5.729693ms
  Dec  9 13:25:03.678: INFO: Terminating DaemonSet.extensions e2e-gwsqk-daemon-set pods took: 100.10492ms
  E1209 13:25:03.841901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:04.842262      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:25:05.283: INFO: Number of nodes with available pods controlled by daemonset e2e-gwsqk-daemon-set: 0
  Dec  9 13:25:05.283: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-gwsqk-daemon-set
  Dec  9 13:25:05.287: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"30678"},"items":null}

  Dec  9 13:25:05.290: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"30678"},"items":null}

  Dec  9 13:25:05.304: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-1190" for this suite. @ 12/09/23 13:25:05.309
• [4.964 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 12/09/23 13:25:05.317
  Dec  9 13:25:05.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 13:25:05.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:25:05.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:25:05.337
  E1209 13:25:05.843015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:06.843882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:25:07.363: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 13:25:07.368: INFO: Deleting pod "var-expansion-d04c15e2-83f9-4ff1-8084-95ef9ec29c42" in namespace "var-expansion-4623"
  Dec  9 13:25:07.377: INFO: Wait up to 5m0s for pod "var-expansion-d04c15e2-83f9-4ff1-8084-95ef9ec29c42" to be fully deleted
  E1209 13:25:07.843973      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:08.844030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-4623" for this suite. @ 12/09/23 13:25:09.387
• [4.076 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 12/09/23 13:25:09.394
  Dec  9 13:25:09.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 13:25:09.395
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:25:09.411
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:25:09.415
  STEP: Creating a ResourceQuota with best effort scope @ 12/09/23 13:25:09.42
  STEP: Ensuring ResourceQuota status is calculated @ 12/09/23 13:25:09.44
  E1209 13:25:09.845065      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:10.845186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 12/09/23 13:25:11.445
  STEP: Ensuring ResourceQuota status is calculated @ 12/09/23 13:25:11.45
  E1209 13:25:11.846060      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:12.846168      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 12/09/23 13:25:13.455
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 12/09/23 13:25:13.469
  E1209 13:25:13.846991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:14.847083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 12/09/23 13:25:15.475
  E1209 13:25:15.847161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:16.848159      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/09/23 13:25:17.479
  STEP: Ensuring resource quota status released the pod usage @ 12/09/23 13:25:17.493
  E1209 13:25:17.848355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:18.848612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 12/09/23 13:25:19.498
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 12/09/23 13:25:19.509
  E1209 13:25:19.849587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:20.849664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 12/09/23 13:25:21.513
  E1209 13:25:21.849761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:22.849921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/09/23 13:25:23.518
  STEP: Ensuring resource quota status released the pod usage @ 12/09/23 13:25:23.537
  E1209 13:25:23.850977      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:24.851064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:25:25.542: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9114" for this suite. @ 12/09/23 13:25:25.549
• [16.166 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 12/09/23 13:25:25.561
  Dec  9 13:25:25.561: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename subpath @ 12/09/23 13:25:25.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:25:25.588
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:25:25.592
  STEP: Setting up data @ 12/09/23 13:25:25.597
  STEP: Creating pod pod-subpath-test-downwardapi-xhjz @ 12/09/23 13:25:25.61
  STEP: Creating a pod to test atomic-volume-subpath @ 12/09/23 13:25:25.61
  E1209 13:25:25.851599      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:26.851694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:27.851921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:28.851990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:29.852883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:30.853804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:31.853898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:32.854053      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:33.854826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:34.854901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:35.855399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:36.855483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:37.856479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:38.856567      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:39.857022      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:40.857168      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:41.858224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:42.858326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:43.858408      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:44.858563      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:45.858635      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:46.859088      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:47.859655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:48.859882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:25:49.695
  Dec  9 13:25:49.699: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-subpath-test-downwardapi-xhjz container test-container-subpath-downwardapi-xhjz: <nil>
  STEP: delete the pod @ 12/09/23 13:25:49.709
  STEP: Deleting pod pod-subpath-test-downwardapi-xhjz @ 12/09/23 13:25:49.723
  Dec  9 13:25:49.723: INFO: Deleting pod "pod-subpath-test-downwardapi-xhjz" in namespace "subpath-512"
  Dec  9 13:25:49.727: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-512" for this suite. @ 12/09/23 13:25:49.732
• [24.177 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 12/09/23 13:25:49.739
  Dec  9 13:25:49.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pod-network-test @ 12/09/23 13:25:49.739
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:25:49.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:25:49.758
  STEP: Performing setup for networking test in namespace pod-network-test-8759 @ 12/09/23 13:25:49.763
  STEP: creating a selector @ 12/09/23 13:25:49.763
  STEP: Creating the service pods in kubernetes @ 12/09/23 13:25:49.763
  Dec  9 13:25:49.763: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1209 13:25:49.860131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:50.860225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:51.861174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:52.861360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:53.861556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:54.861743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:55.862749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:56.862838      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:57.863873      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:58.863973      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:25:59.864995      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:00.865119      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/09/23 13:26:01.847
  E1209 13:26:01.865298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:02.865436      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:03.866450      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:03.877: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  9 13:26:03.878: INFO: Going to poll 192.168.201.247 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec  9 13:26:03.882: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.201.247:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8759 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:26:03.882: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:26:03.882: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:26:03.882: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8759/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.201.247%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  9 13:26:03.955: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec  9 13:26:03.955: INFO: Going to poll 192.168.34.51 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec  9 13:26:03.958: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.34.51:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8759 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:26:03.958: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:26:03.959: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:26:03.959: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8759/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.34.51%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  9 13:26:04.007: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec  9 13:26:04.007: INFO: Going to poll 192.168.250.78 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec  9 13:26:04.011: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.250.78:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8759 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:26:04.011: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:26:04.011: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:26:04.011: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8759/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.250.78%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  9 13:26:04.067: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec  9 13:26:04.067: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-8759" for this suite. @ 12/09/23 13:26:04.075
• [14.344 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 12/09/23 13:26:04.084
  Dec  9 13:26:04.084: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:26:04.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:26:04.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:26:04.103
  STEP: Creating the pod @ 12/09/23 13:26:04.107
  E1209 13:26:04.866590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:05.866781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:06.647: INFO: Successfully updated pod "labelsupdatea5136fa6-8c75-4e05-979b-7620234ee6f9"
  E1209 13:26:06.867764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:07.867851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:08.868706      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:09.868807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:10.669: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-242" for this suite. @ 12/09/23 13:26:10.673
• [6.597 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 12/09/23 13:26:10.682
  Dec  9 13:26:10.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename init-container @ 12/09/23 13:26:10.683
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:26:10.694
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:26:10.698
  STEP: creating the pod @ 12/09/23 13:26:10.702
  Dec  9 13:26:10.702: INFO: PodSpec: initContainers in spec.initContainers
  E1209 13:26:10.868909      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:11.869134      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:12.870158      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:13.871127      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:14.871905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:15.486: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9310" for this suite. @ 12/09/23 13:26:15.491
• [4.817 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 12/09/23 13:26:15.499
  Dec  9 13:26:15.499: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 13:26:15.499
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:26:15.514
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:26:15.518
  E1209 13:26:15.872902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:16.872975      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:17.873059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:18.873967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:19.874071      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:20.874789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:21.875003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:22.875085      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:23.875902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:24.876053      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:25.877060      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:26.877152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:27.877251      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:28.877312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:29.877934      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:30.878466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:31.879523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:32.879621      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:33.880458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:34.881216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:35.881719      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:36.881807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:37.592: INFO: Container started at 2023-12-09 13:26:16 +0000 UTC, pod became ready at 2023-12-09 13:26:35 +0000 UTC
  Dec  9 13:26:37.592: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-8833" for this suite. @ 12/09/23 13:26:37.595
• [22.104 seconds]
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:1030
  STEP: Creating a kubernetes client @ 12/09/23 13:26:37.603
  Dec  9 13:26:37.603: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 13:26:37.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:26:37.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:26:37.622
  STEP: Creating service test in namespace statefulset-2079 @ 12/09/23 13:26:37.625
  STEP: Creating statefulset ss in namespace statefulset-2079 @ 12/09/23 13:26:37.634
  Dec  9 13:26:37.645: INFO: Found 0 stateful pods, waiting for 1
  E1209 13:26:37.882832      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:38.882845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:39.882957      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:40.883021      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:41.883089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:42.883926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:43.883995      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:44.884615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:45.884759      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:46.884864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:47.650: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 12/09/23 13:26:47.659
  STEP: Getting /status @ 12/09/23 13:26:47.666
  Dec  9 13:26:47.670: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 12/09/23 13:26:47.67
  Dec  9 13:26:47.680: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 12/09/23 13:26:47.68
  Dec  9 13:26:47.682: INFO: Observed &StatefulSet event: ADDED
  Dec  9 13:26:47.682: INFO: Found Statefulset ss in namespace statefulset-2079 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  9 13:26:47.682: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 12/09/23 13:26:47.682
  Dec  9 13:26:47.682: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec  9 13:26:47.690: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 12/09/23 13:26:47.69
  Dec  9 13:26:47.692: INFO: Observed &StatefulSet event: ADDED
  Dec  9 13:26:47.692: INFO: Deleting all statefulset in ns statefulset-2079
  Dec  9 13:26:47.696: INFO: Scaling statefulset ss to 0
  E1209 13:26:47.885805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:48.886866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:49.887900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:50.888046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:51.888097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:52.888204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:53.888911      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:54.888981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:55.889146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:56.889238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:57.712: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 13:26:57.717: INFO: Deleting statefulset ss
  Dec  9 13:26:57.729: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2079" for this suite. @ 12/09/23 13:26:57.734
• [20.138 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 12/09/23 13:26:57.743
  Dec  9 13:26:57.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 13:26:57.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:26:57.757
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:26:57.761
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 12/09/23 13:26:57.767
  Dec  9 13:26:57.777: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7272  2e19cc3e-3d53-4ce4-8882-a7c339e655e2 31359 0 2023-12-09 13:26:57 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-12-09 13:26:57 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7w7bt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.45,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7w7bt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E1209 13:26:57.889850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:26:58.890060      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 12/09/23 13:26:59.785
  Dec  9 13:26:59.785: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7272 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:26:59.785: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:26:59.786: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:26:59.786: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7272/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 12/09/23 13:26:59.849
  Dec  9 13:26:59.849: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7272 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:26:59.849: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:26:59.850: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:26:59.850: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7272/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1209 13:26:59.890241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:26:59.912: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 13:26:59.917: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-7272" for this suite. @ 12/09/23 13:26:59.932
• [2.197 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 12/09/23 13:26:59.941
  Dec  9 13:26:59.941: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename proxy @ 12/09/23 13:26:59.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:26:59.982
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:26:59.986
  Dec  9 13:26:59.989: INFO: Creating pod...
  E1209 13:27:00.890590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:01.890852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:02.004: INFO: Creating service...
  Dec  9 13:27:02.013: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/pods/agnhost/proxy/some/path/with/DELETE
  Dec  9 13:27:02.022: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  9 13:27:02.022: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/pods/agnhost/proxy/some/path/with/GET
  Dec  9 13:27:02.027: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec  9 13:27:02.027: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/pods/agnhost/proxy/some/path/with/HEAD
  Dec  9 13:27:02.030: INFO: http.Client request:HEAD | StatusCode:200
  Dec  9 13:27:02.030: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/pods/agnhost/proxy/some/path/with/OPTIONS
  Dec  9 13:27:02.034: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  9 13:27:02.034: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/pods/agnhost/proxy/some/path/with/PATCH
  Dec  9 13:27:02.038: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  9 13:27:02.038: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/pods/agnhost/proxy/some/path/with/POST
  Dec  9 13:27:02.043: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  9 13:27:02.043: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/pods/agnhost/proxy/some/path/with/PUT
  Dec  9 13:27:02.047: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  9 13:27:02.047: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/services/test-service/proxy/some/path/with/DELETE
  Dec  9 13:27:02.055: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  9 13:27:02.055: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/services/test-service/proxy/some/path/with/GET
  Dec  9 13:27:02.059: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec  9 13:27:02.060: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/services/test-service/proxy/some/path/with/HEAD
  Dec  9 13:27:02.066: INFO: http.Client request:HEAD | StatusCode:200
  Dec  9 13:27:02.066: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/services/test-service/proxy/some/path/with/OPTIONS
  Dec  9 13:27:02.073: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  9 13:27:02.073: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/services/test-service/proxy/some/path/with/PATCH
  Dec  9 13:27:02.077: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  9 13:27:02.077: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/services/test-service/proxy/some/path/with/POST
  Dec  9 13:27:02.083: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  9 13:27:02.083: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-8999/services/test-service/proxy/some/path/with/PUT
  Dec  9 13:27:02.090: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  9 13:27:02.090: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-8999" for this suite. @ 12/09/23 13:27:02.094
• [2.160 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 12/09/23 13:27:02.101
  Dec  9 13:27:02.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename runtimeclass @ 12/09/23 13:27:02.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:02.117
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:02.12
  Dec  9 13:27:02.131: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2471" for this suite. @ 12/09/23 13:27:02.134
• [0.040 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 12/09/23 13:27:02.142
  Dec  9 13:27:02.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename security-context-test @ 12/09/23 13:27:02.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:02.155
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:02.159
  E1209 13:27:02.890929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:03.891914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:04.892914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:05.893866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:06.203: INFO: Got logs for pod "busybox-privileged-false-70fb82d8-4bbf-40cb-9ab3-1d97cf5d2271": "ip: RTNETLINK answers: Operation not permitted\n"
  Dec  9 13:27:06.203: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-1373" for this suite. @ 12/09/23 13:27:06.207
• [4.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 12/09/23 13:27:06.216
  Dec  9 13:27:06.216: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename cronjob @ 12/09/23 13:27:06.216
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:06.231
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:06.234
  STEP: Creating a cronjob @ 12/09/23 13:27:06.238
  STEP: creating @ 12/09/23 13:27:06.238
  STEP: getting @ 12/09/23 13:27:06.244
  STEP: listing @ 12/09/23 13:27:06.248
  STEP: watching @ 12/09/23 13:27:06.251
  Dec  9 13:27:06.251: INFO: starting watch
  STEP: cluster-wide listing @ 12/09/23 13:27:06.253
  STEP: cluster-wide watching @ 12/09/23 13:27:06.256
  Dec  9 13:27:06.256: INFO: starting watch
  STEP: patching @ 12/09/23 13:27:06.258
  STEP: updating @ 12/09/23 13:27:06.264
  Dec  9 13:27:06.273: INFO: waiting for watch events with expected annotations
  Dec  9 13:27:06.273: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/09/23 13:27:06.273
  STEP: updating /status @ 12/09/23 13:27:06.279
  STEP: get /status @ 12/09/23 13:27:06.286
  STEP: deleting @ 12/09/23 13:27:06.29
  STEP: deleting a collection @ 12/09/23 13:27:06.305
  Dec  9 13:27:06.318: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-3956" for this suite. @ 12/09/23 13:27:06.323
• [0.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 12/09/23 13:27:06.331
  Dec  9 13:27:06.331: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 13:27:06.332
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:06.352
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:06.356
  Dec  9 13:27:06.398: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1669" for this suite. @ 12/09/23 13:27:06.401
• [0.077 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 12/09/23 13:27:06.409
  Dec  9 13:27:06.409: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename gc @ 12/09/23 13:27:06.41
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:06.426
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:06.429
  STEP: create the deployment @ 12/09/23 13:27:06.434
  W1209 13:27:06.439249      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/09/23 13:27:06.439
  E1209 13:27:06.894686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the deployment @ 12/09/23 13:27:06.952
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 12/09/23 13:27:06.959
  STEP: Gathering metrics @ 12/09/23 13:27:07.484
  W1209 13:27:07.488912      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  9 13:27:07.488: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  9 13:27:07.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9717" for this suite. @ 12/09/23 13:27:07.493
• [1.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 12/09/23 13:27:07.503
  Dec  9 13:27:07.503: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename field-validation @ 12/09/23 13:27:07.503
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:07.518
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:07.522
  STEP: apply creating a deployment @ 12/09/23 13:27:07.526
  Dec  9 13:27:07.528: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-509" for this suite. @ 12/09/23 13:27:07.545
• [0.049 seconds]
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1741
  STEP: Creating a kubernetes client @ 12/09/23 13:27:07.552
  Dec  9 13:27:07.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:27:07.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:07.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:07.571
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/09/23 13:27:07.575
  Dec  9 13:27:07.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1693 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec  9 13:27:07.632: INFO: stderr: ""
  Dec  9 13:27:07.632: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 12/09/23 13:27:07.632
  E1209 13:27:07.895650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:08.895920      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:09.895996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:10.896317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:11.897075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/09/23 13:27:12.683
  Dec  9 13:27:12.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1693 get pod e2e-test-httpd-pod -o json'
  Dec  9 13:27:12.755: INFO: stderr: ""
  Dec  9 13:27:12.755: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-12-09T13:27:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1693\",\n        \"resourceVersion\": \"31585\",\n        \"uid\": \"73100941-31c6-49f7-b4fe-a6c9d9b43e7e\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-w6c96\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-77-176\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-w6c96\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-09T13:27:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-09T13:27:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-09T13:27:08Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-09T13:27:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://1e3e5f9f1415d4bf6158f77d5c42c404e5d3d0c0f19840f09c6a67200612120e\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-12-09T13:27:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.77.176\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.34.59\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.34.59\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-12-09T13:27:07Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 12/09/23 13:27:12.755
  Dec  9 13:27:12.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1693 replace -f -'
  E1209 13:27:12.897270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:12.998: INFO: stderr: ""
  Dec  9 13:27:12.998: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 12/09/23 13:27:12.998
  Dec  9 13:27:13.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1693 delete pods e2e-test-httpd-pod'
  E1209 13:27:13.898099      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:14.315: INFO: stderr: ""
  Dec  9 13:27:14.315: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec  9 13:27:14.315: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1693" for this suite. @ 12/09/23 13:27:14.318
• [6.773 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 12/09/23 13:27:14.325
  Dec  9 13:27:14.325: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename job @ 12/09/23 13:27:14.326
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:14.341
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:14.344
  STEP: Creating a job @ 12/09/23 13:27:14.348
  STEP: Ensuring active pods == parallelism @ 12/09/23 13:27:14.353
  E1209 13:27:14.898960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:15.899080      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 12/09/23 13:27:16.357
  Dec  9 13:27:16.874: INFO: Successfully updated pod "adopt-release-2lx98"
  STEP: Checking that the Job readopts the Pod @ 12/09/23 13:27:16.874
  E1209 13:27:16.899230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:17.899347      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 12/09/23 13:27:18.885
  E1209 13:27:18.899598      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:19.397: INFO: Successfully updated pod "adopt-release-2lx98"
  STEP: Checking that the Job releases the Pod @ 12/09/23 13:27:19.397
  E1209 13:27:19.900366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:20.900432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:21.406: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1604" for this suite. @ 12/09/23 13:27:21.41
• [7.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 12/09/23 13:27:21.419
  Dec  9 13:27:21.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svcaccounts @ 12/09/23 13:27:21.419
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:21.441
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:21.445
  Dec  9 13:27:21.468: INFO: created pod pod-service-account-defaultsa
  Dec  9 13:27:21.468: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Dec  9 13:27:21.475: INFO: created pod pod-service-account-mountsa
  Dec  9 13:27:21.475: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Dec  9 13:27:21.481: INFO: created pod pod-service-account-nomountsa
  Dec  9 13:27:21.481: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Dec  9 13:27:21.486: INFO: created pod pod-service-account-defaultsa-mountspec
  Dec  9 13:27:21.487: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Dec  9 13:27:21.498: INFO: created pod pod-service-account-mountsa-mountspec
  Dec  9 13:27:21.498: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Dec  9 13:27:21.512: INFO: created pod pod-service-account-nomountsa-mountspec
  Dec  9 13:27:21.512: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Dec  9 13:27:21.526: INFO: created pod pod-service-account-defaultsa-nomountspec
  Dec  9 13:27:21.526: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Dec  9 13:27:21.554: INFO: created pod pod-service-account-mountsa-nomountspec
  Dec  9 13:27:21.555: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Dec  9 13:27:21.568: INFO: created pod pod-service-account-nomountsa-nomountspec
  Dec  9 13:27:21.568: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Dec  9 13:27:21.568: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8129" for this suite. @ 12/09/23 13:27:21.577
• [0.169 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 12/09/23 13:27:21.589
  Dec  9 13:27:21.589: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename server-version @ 12/09/23 13:27:21.59
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:21.606
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:21.61
  STEP: Request ServerVersion @ 12/09/23 13:27:21.617
  STEP: Confirm major version @ 12/09/23 13:27:21.63
  Dec  9 13:27:21.630: INFO: Major version: 1
  STEP: Confirm minor version @ 12/09/23 13:27:21.63
  Dec  9 13:27:21.630: INFO: cleanMinorVersion: 28
  Dec  9 13:27:21.630: INFO: Minor version: 28
  Dec  9 13:27:21.630: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-1909" for this suite. @ 12/09/23 13:27:21.636
• [0.071 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 12/09/23 13:27:21.661
  Dec  9 13:27:21.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:27:21.662
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:21.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:21.687
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/09/23 13:27:21.706
  E1209 13:27:21.901798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:22.902144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:23.902163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:24.902241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:27:25.734
  Dec  9 13:27:25.739: INFO: Trying to get logs from node ip-172-31-80-205 pod pod-aeb89905-82b3-4644-834e-12d93c515665 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:27:25.755
  Dec  9 13:27:25.769: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5088" for this suite. @ 12/09/23 13:27:25.773
• [4.118 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 12/09/23 13:27:25.78
  Dec  9 13:27:25.780: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:27:25.78
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:25.793
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:25.797
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 12/09/23 13:27:25.8
  E1209 13:27:25.903002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:26.903170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:27.903751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:28.903244      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:27:29.826
  Dec  9 13:27:29.829: INFO: Trying to get logs from node ip-172-31-80-205 pod pod-4f32f0d2-d3db-4792-8018-17cc706ba881 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:27:29.837
  Dec  9 13:27:29.855: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6533" for this suite. @ 12/09/23 13:27:29.858
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 12/09/23 13:27:29.867
  Dec  9 13:27:29.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:27:29.868
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:29.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:29.886
  STEP: create deployment with httpd image @ 12/09/23 13:27:29.889
  Dec  9 13:27:29.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4715 create -f -'
  E1209 13:27:29.903286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:30.017: INFO: stderr: ""
  Dec  9 13:27:30.017: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 12/09/23 13:27:30.017
  Dec  9 13:27:30.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4715 diff -f -'
  Dec  9 13:27:30.147: INFO: rc: 1
  Dec  9 13:27:30.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-4715 delete -f -'
  Dec  9 13:27:30.201: INFO: stderr: ""
  Dec  9 13:27:30.201: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Dec  9 13:27:30.201: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4715" for this suite. @ 12/09/23 13:27:30.205
• [0.344 seconds]
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 12/09/23 13:27:30.211
  Dec  9 13:27:30.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svcaccounts @ 12/09/23 13:27:30.212
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:30.226
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:30.23
  STEP: creating a ServiceAccount @ 12/09/23 13:27:30.233
  STEP: watching for the ServiceAccount to be added @ 12/09/23 13:27:30.242
  STEP: patching the ServiceAccount @ 12/09/23 13:27:30.245
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 12/09/23 13:27:30.25
  STEP: deleting the ServiceAccount @ 12/09/23 13:27:30.255
  Dec  9 13:27:30.270: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-696" for this suite. @ 12/09/23 13:27:30.275
• [0.070 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 12/09/23 13:27:30.281
  Dec  9 13:27:30.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:27:30.282
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:30.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:30.307
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:27:30.314
  E1209 13:27:30.903427      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:31.903510      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:32.903908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:33.903983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:27:34.342
  Dec  9 13:27:34.346: INFO: Trying to get logs from node ip-172-31-38-129 pod downwardapi-volume-8d9efe2b-40c0-4882-9957-d1db0f170dfb container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:27:34.353
  Dec  9 13:27:34.371: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2807" for this suite. @ 12/09/23 13:27:34.376
• [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 12/09/23 13:27:34.385
  Dec  9 13:27:34.385: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename prestop @ 12/09/23 13:27:34.386
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:34.403
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:34.407
  STEP: Creating server pod server in namespace prestop-3204 @ 12/09/23 13:27:34.41
  STEP: Waiting for pods to come up. @ 12/09/23 13:27:34.42
  E1209 13:27:34.904084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:35.904349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-3204 @ 12/09/23 13:27:36.431
  E1209 13:27:36.907543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:37.907536      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 12/09/23 13:27:38.449
  E1209 13:27:38.907909      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:39.907978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:40.908183      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:41.908208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:42.908298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:27:43.464: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Dec  9 13:27:43.465: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 12/09/23 13:27:43.468
  STEP: Destroying namespace "prestop-3204" for this suite. @ 12/09/23 13:27:43.479
• [9.101 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 12/09/23 13:27:43.491
  Dec  9 13:27:43.491: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-preemption @ 12/09/23 13:27:43.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:27:43.507
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:27:43.511
  Dec  9 13:27:43.527: INFO: Waiting up to 1m0s for all nodes to be ready
  E1209 13:27:43.908385      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:44.908463      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:45.909233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:46.909392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:47.909870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:48.910906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:49.911641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:50.911746      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:51.911894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:52.911957      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:53.912885      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:54.912972      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:55.913514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:56.913601      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:57.913701      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:58.913790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:27:59.914557      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:00.914680      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:01.914780      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:02.914842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:03.914947      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:04.915031      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:05.915751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:06.915830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:07.915930      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:08.916045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:09.916885      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:10.917720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:11.918558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:12.918654      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:13.919155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:14.919229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:15.919403      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:16.919510      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:17.919598      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:18.919847      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:19.919962      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:20.920599      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:21.920771      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:22.920834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:23.920961      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:24.921055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:25.921176      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:26.921552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:27.921811      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:28.922072      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:29.923141      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:30.923785      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:31.923830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:32.923988      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:33.924671      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:34.925334      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:35.925420      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:36.925516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:37.925826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:38.926059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:39.926069      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:40.926179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:41.926252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:42.927089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:28:43.548: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/09/23 13:28:43.552
  Dec  9 13:28:43.573: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec  9 13:28:43.580: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec  9 13:28:43.599: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec  9 13:28:43.605: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec  9 13:28:43.626: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec  9 13:28:43.633: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/09/23 13:28:43.633
  E1209 13:28:43.927848      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:44.927840      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 12/09/23 13:28:45.659
  E1209 13:28:45.927991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:46.928249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:47.928224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:48.928504      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:28:49.704: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3500" for this suite. @ 12/09/23 13:28:49.744
• [66.259 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 12/09/23 13:28:49.75
  Dec  9 13:28:49.750: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:28:49.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:28:49.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:28:49.774
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/09/23 13:28:49.777
  E1209 13:28:49.928595      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:50.929936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:51.929995      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:52.930073      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:28:53.801
  Dec  9 13:28:53.805: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-f4ff0c27-c1c7-4b13-ad7f-458abc73d365 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:28:53.819
  Dec  9 13:28:53.832: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3025" for this suite. @ 12/09/23 13:28:53.837
• [4.093 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 12/09/23 13:28:53.843
  Dec  9 13:28:53.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename subpath @ 12/09/23 13:28:53.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:28:53.857
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:28:53.862
  STEP: Setting up data @ 12/09/23 13:28:53.865
  STEP: Creating pod pod-subpath-test-projected-2b4h @ 12/09/23 13:28:53.874
  STEP: Creating a pod to test atomic-volume-subpath @ 12/09/23 13:28:53.874
  E1209 13:28:53.930369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:54.930456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:55.930683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:56.930847      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:57.931888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:58.932164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:28:59.932999      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:00.933874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:01.934600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:02.934846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:03.935873      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:04.935991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:05.936349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:06.936818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:07.937239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:08.937550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:09.938424      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:10.939498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:11.939587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:12.940680      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:13.941712      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:14.941851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:15.942035      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:16.942225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:29:17.937
  Dec  9 13:29:17.940: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-subpath-test-projected-2b4h container test-container-subpath-projected-2b4h: <nil>
  E1209 13:29:17.942767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod @ 12/09/23 13:29:17.947
  STEP: Deleting pod pod-subpath-test-projected-2b4h @ 12/09/23 13:29:17.965
  Dec  9 13:29:17.965: INFO: Deleting pod "pod-subpath-test-projected-2b4h" in namespace "subpath-6152"
  Dec  9 13:29:17.968: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-6152" for this suite. @ 12/09/23 13:29:17.973
• [24.136 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 12/09/23 13:29:17.98
  Dec  9 13:29:17.980: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename endpointslicemirroring @ 12/09/23 13:29:17.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:29:17.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:29:17.998
  STEP: mirroring a new custom Endpoint @ 12/09/23 13:29:18.012
  Dec  9 13:29:18.022: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E1209 13:29:18.943771      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:19.944470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 12/09/23 13:29:20.026
  Dec  9 13:29:20.035: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E1209 13:29:20.944538      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:21.944720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 12/09/23 13:29:22.04
  Dec  9 13:29:22.050: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E1209 13:29:22.945390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:23.945724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:29:24.054: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-4650" for this suite. @ 12/09/23 13:29:24.059
• [6.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 12/09/23 13:29:24.066
  Dec  9 13:29:24.066: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:29:24.067
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:29:24.082
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:29:24.085
  STEP: Setting up server cert @ 12/09/23 13:29:24.11
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:29:24.524
  STEP: Deploying the webhook pod @ 12/09/23 13:29:24.533
  STEP: Wait for the deployment to be ready @ 12/09/23 13:29:24.544
  Dec  9 13:29:24.556: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1209 13:29:24.946412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:25.946510      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/09/23 13:29:26.569
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:29:26.58
  E1209 13:29:26.946845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:29:27.580: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  9 13:29:27.588: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  E1209 13:29:27.947383      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9627-crds.webhook.example.com via the AdmissionRegistration API @ 12/09/23 13:29:28.101
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/09/23 13:29:28.116
  E1209 13:29:28.948133      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:29.948216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:29:30.143: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8826" for this suite. @ 12/09/23 13:29:30.717
  STEP: Destroying namespace "webhook-markers-4530" for this suite. @ 12/09/23 13:29:30.723
• [6.663 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 12/09/23 13:29:30.73
  Dec  9 13:29:30.730: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:29:30.731
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:29:30.75
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:29:30.754
  STEP: Setting up server cert @ 12/09/23 13:29:30.777
  E1209 13:29:30.948996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:29:31.067
  STEP: Deploying the webhook pod @ 12/09/23 13:29:31.072
  STEP: Wait for the deployment to be ready @ 12/09/23 13:29:31.085
  Dec  9 13:29:31.096: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1209 13:29:31.949203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:32.949225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:29:33.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 9, 13, 29, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 29, 31, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 9, 13, 29, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 9, 13, 29, 31, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1209 13:29:33.950152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:34.950225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/09/23 13:29:35.113
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:29:35.125
  E1209 13:29:35.950829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:29:36.126: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 12/09/23 13:29:36.133
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/09/23 13:29:36.133
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 12/09/23 13:29:36.149
  E1209 13:29:36.951927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 12/09/23 13:29:37.16
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/09/23 13:29:37.16
  E1209 13:29:37.952003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 12/09/23 13:29:38.195
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/09/23 13:29:38.195
  E1209 13:29:38.953012      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:39.953090      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:40.953228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:41.953321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:42.954100      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 12/09/23 13:29:43.233
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/09/23 13:29:43.233
  E1209 13:29:43.954256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:44.954355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:45.954500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:46.954687      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:47.954850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:29:48.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-8737" for this suite. @ 12/09/23 13:29:48.331
  STEP: Destroying namespace "webhook-markers-5721" for this suite. @ 12/09/23 13:29:48.339
• [17.615 seconds]
------------------------------
SSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 12/09/23 13:29:48.346
  Dec  9 13:29:48.346: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename security-context @ 12/09/23 13:29:48.347
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:29:48.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:29:48.364
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/09/23 13:29:48.367
  E1209 13:29:48.954946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:49.955684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:50.956684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:51.956786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:29:52.392
  Dec  9 13:29:52.396: INFO: Trying to get logs from node ip-172-31-77-176 pod security-context-dcb31419-c81a-4e39-ad8d-9ee962e0475b container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:29:52.402
  Dec  9 13:29:52.419: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-4827" for this suite. @ 12/09/23 13:29:52.423
• [4.083 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 12/09/23 13:29:52.429
  Dec  9 13:29:52.429: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 13:29:52.43
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:29:52.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:29:52.447
  STEP: Creating a test headless service @ 12/09/23 13:29:52.451
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6994.svc.cluster.local;sleep 1; done
   @ 12/09/23 13:29:52.457
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6994.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6994.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6994.svc.cluster.local;sleep 1; done
   @ 12/09/23 13:29:52.457
  STEP: creating a pod to probe DNS @ 12/09/23 13:29:52.457
  STEP: submitting the pod to kubernetes @ 12/09/23 13:29:52.457
  E1209 13:29:52.957589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:53.957667      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/09/23 13:29:54.482
  STEP: looking for the results for each expected name from probers @ 12/09/23 13:29:54.486
  Dec  9 13:29:54.491: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.495: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.499: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.502: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.506: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.511: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.514: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.518: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6994.svc.cluster.local from pod dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff: the server could not find the requested resource (get pods dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff)
  Dec  9 13:29:54.518: INFO: Lookups using dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6994.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6994.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6994.svc.cluster.local jessie_udp@dns-test-service-2.dns-6994.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6994.svc.cluster.local]

  Dec  9 13:29:54.525: INFO: Pod client logs for webserver: 
  Dec  9 13:29:54.532: INFO: Pod client logs for querier: 
  Dec  9 13:29:54.537: INFO: Pod client logs for jessie-querier: 
  E1209 13:29:54.958516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:55.958728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:56.958829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:57.958935      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:29:58.959887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:29:59.571: INFO: DNS probes using dns-6994/dns-test-7a86bd61-6ee4-4653-8800-c015a4ed59ff succeeded

  Dec  9 13:29:59.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:29:59.575
  STEP: deleting the test headless service @ 12/09/23 13:29:59.593
  STEP: Destroying namespace "dns-6994" for this suite. @ 12/09/23 13:29:59.607
• [7.185 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 12/09/23 13:29:59.615
  Dec  9 13:29:59.615: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename security-context-test @ 12/09/23 13:29:59.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:29:59.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:29:59.636
  E1209 13:29:59.959989      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:00.960083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:01.960782      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:02.960862      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:30:03.670: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-6346" for this suite. @ 12/09/23 13:30:03.673
• [4.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 12/09/23 13:30:03.682
  Dec  9 13:30:03.682: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubelet-test @ 12/09/23 13:30:03.682
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:03.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:03.7
  E1209 13:30:03.961866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:04.961974      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:30:05.732: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7970" for this suite. @ 12/09/23 13:30:05.736
• [2.061 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 12/09/23 13:30:05.743
  Dec  9 13:30:05.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename security-context-test @ 12/09/23 13:30:05.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:05.758
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:05.761
  E1209 13:30:05.962009      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:06.962098      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:07.962705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:08.962856      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:30:09.789: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-8651" for this suite. @ 12/09/23 13:30:09.793
• [4.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 12/09/23 13:30:09.799
  Dec  9 13:30:09.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename watch @ 12/09/23 13:30:09.8
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:09.818
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:09.821
  STEP: creating a watch on configmaps @ 12/09/23 13:30:09.825
  STEP: creating a new configmap @ 12/09/23 13:30:09.826
  STEP: modifying the configmap once @ 12/09/23 13:30:09.832
  STEP: closing the watch once it receives two notifications @ 12/09/23 13:30:09.841
  Dec  9 13:30:09.841: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8491  ddb66e6e-2361-467a-b13c-2fd40ae12570 33131 0 2023-12-09 13:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-09 13:30:09 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:30:09.841: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8491  ddb66e6e-2361-467a-b13c-2fd40ae12570 33133 0 2023-12-09 13:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-09 13:30:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 12/09/23 13:30:09.841
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 12/09/23 13:30:09.85
  STEP: deleting the configmap @ 12/09/23 13:30:09.852
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 12/09/23 13:30:09.858
  Dec  9 13:30:09.858: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8491  ddb66e6e-2361-467a-b13c-2fd40ae12570 33134 0 2023-12-09 13:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-09 13:30:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:30:09.858: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8491  ddb66e6e-2361-467a-b13c-2fd40ae12570 33135 0 2023-12-09 13:30:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-09 13:30:09 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  9 13:30:09.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8491" for this suite. @ 12/09/23 13:30:09.862
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 12/09/23 13:30:09.869
  Dec  9 13:30:09.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:30:09.87
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:09.883
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:09.887
  STEP: Creating configMap with name configmap-test-volume-map-02b95770-5929-4d4a-90ad-2ff6d87b2030 @ 12/09/23 13:30:09.891
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:30:09.894
  E1209 13:30:09.963539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:10.963728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:11.964561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:12.964753      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:30:13.916
  Dec  9 13:30:13.919: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-configmaps-5c8c58e3-4cbd-4746-a79e-83ac241ea728 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:30:13.934
  Dec  9 13:30:13.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-7722" for this suite. @ 12/09/23 13:30:13.956
• [4.095 seconds]
------------------------------
SSSSSSSSSS  E1209 13:30:13.964754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
SSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 12/09/23 13:30:13.965
  Dec  9 13:30:13.965: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:30:13.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:13.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:13.983
  STEP: Creating configMap with name projected-configmap-test-volume-1ac11e28-5059-449a-98e3-d4470b3057c6 @ 12/09/23 13:30:13.986
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:30:13.99
  E1209 13:30:14.964959      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:15.965042      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:30:16.009
  Dec  9 13:30:16.013: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-configmaps-d44742ae-bd22-4644-9d80-484b2078f346 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 13:30:16.019
  Dec  9 13:30:16.037: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-56" for this suite. @ 12/09/23 13:30:16.041
• [2.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 12/09/23 13:30:16.052
  Dec  9 13:30:16.052: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-runtime @ 12/09/23 13:30:16.053
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:16.069
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:16.073
  STEP: create the container @ 12/09/23 13:30:16.077
  W1209 13:30:16.086091      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/09/23 13:30:16.086
  E1209 13:30:16.965133      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:17.965900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:18.966041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/09/23 13:30:19.105
  STEP: the container should be terminated @ 12/09/23 13:30:19.11
  STEP: the termination message should be set @ 12/09/23 13:30:19.11
  Dec  9 13:30:19.110: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 12/09/23 13:30:19.11
  Dec  9 13:30:19.123: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-8215" for this suite. @ 12/09/23 13:30:19.13
• [3.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:169
  STEP: Creating a kubernetes client @ 12/09/23 13:30:19.139
  Dec  9 13:30:19.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename discovery @ 12/09/23 13:30:19.14
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:19.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:19.16
  STEP: Setting up server cert @ 12/09/23 13:30:19.166
  STEP: Requesting APIResourceList from "/api/v1" @ 12/09/23 13:30:19.472
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 12/09/23 13:30:19.474
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 12/09/23 13:30:19.476
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 12/09/23 13:30:19.478
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 12/09/23 13:30:19.479
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 12/09/23 13:30:19.481
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 12/09/23 13:30:19.482
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 12/09/23 13:30:19.484
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 12/09/23 13:30:19.485
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 12/09/23 13:30:19.487
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 12/09/23 13:30:19.488
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 12/09/23 13:30:19.489
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 12/09/23 13:30:19.491
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 12/09/23 13:30:19.492
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 12/09/23 13:30:19.494
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 12/09/23 13:30:19.495
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 12/09/23 13:30:19.497
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 12/09/23 13:30:19.498
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 12/09/23 13:30:19.5
  Dec  9 13:30:19.501: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1666" for this suite. @ 12/09/23 13:30:19.506
• [0.374 seconds]
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 12/09/23 13:30:19.513
  Dec  9 13:30:19.513: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-runtime @ 12/09/23 13:30:19.514
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:19.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:19.531
  STEP: create the container @ 12/09/23 13:30:19.535
  W1209 13:30:19.542672      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/09/23 13:30:19.542
  E1209 13:30:19.966915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:20.967452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:21.967624      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/09/23 13:30:22.569
  STEP: the container should be terminated @ 12/09/23 13:30:22.573
  STEP: the termination message should be set @ 12/09/23 13:30:22.573
  Dec  9 13:30:22.573: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 12/09/23 13:30:22.573
  Dec  9 13:30:22.589: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5404" for this suite. @ 12/09/23 13:30:22.599
• [3.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 12/09/23 13:30:22.607
  Dec  9 13:30:22.607: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:30:22.608
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:22.624
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:22.628
  STEP: Setting up server cert @ 12/09/23 13:30:22.651
  E1209 13:30:22.968553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:30:22.994
  STEP: Deploying the webhook pod @ 12/09/23 13:30:23.003
  STEP: Wait for the deployment to be ready @ 12/09/23 13:30:23.016
  Dec  9 13:30:23.028: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1209 13:30:23.968662      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:24.968822      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/09/23 13:30:25.038
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:30:25.048
  E1209 13:30:25.969006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:30:26.048: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 12/09/23 13:30:26.055
  STEP: create a pod that should be updated by the webhook @ 12/09/23 13:30:26.071
  Dec  9 13:30:26.088: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6330" for this suite. @ 12/09/23 13:30:26.149
  STEP: Destroying namespace "webhook-markers-427" for this suite. @ 12/09/23 13:30:26.156
• [3.554 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 12/09/23 13:30:26.162
  Dec  9 13:30:26.162: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:30:26.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:26.178
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:26.182
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-d72aec5d-ef5d-44f2-96e4-5b41376a01bd @ 12/09/23 13:30:26.19
  STEP: Creating the pod @ 12/09/23 13:30:26.196
  E1209 13:30:26.969126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:27.969285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-d72aec5d-ef5d-44f2-96e4-5b41376a01bd @ 12/09/23 13:30:28.225
  STEP: waiting to observe update in volume @ 12/09/23 13:30:28.23
  E1209 13:30:28.970330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:29.971315      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:30.971404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:31.971491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:30:32.255: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6177" for this suite. @ 12/09/23 13:30:32.26
• [6.104 seconds]
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 12/09/23 13:30:32.267
  Dec  9 13:30:32.267: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replicaset @ 12/09/23 13:30:32.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:32.291
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:32.295
  STEP: Create a ReplicaSet @ 12/09/23 13:30:32.299
  STEP: Verify that the required pods have come up @ 12/09/23 13:30:32.305
  Dec  9 13:30:32.308: INFO: Pod name sample-pod: Found 0 pods out of 3
  E1209 13:30:32.972491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:33.973437      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:34.973633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:35.973786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:36.973876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:30:37.313: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 12/09/23 13:30:37.313
  Dec  9 13:30:37.318: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 12/09/23 13:30:37.318
  STEP: DeleteCollection of the ReplicaSets @ 12/09/23 13:30:37.321
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 12/09/23 13:30:37.329
  Dec  9 13:30:37.336: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-790" for this suite. @ 12/09/23 13:30:37.342
• [5.105 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 12/09/23 13:30:37.373
  Dec  9 13:30:37.373: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:30:37.373
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:30:37.388
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:30:37.393
  STEP: Creating configMap with name cm-test-opt-del-3759b3d8-a29f-4ede-a615-b0132b8b2a4f @ 12/09/23 13:30:37.402
  STEP: Creating configMap with name cm-test-opt-upd-776d1389-51f8-4b64-aecb-2c2eaf34d6a6 @ 12/09/23 13:30:37.406
  STEP: Creating the pod @ 12/09/23 13:30:37.411
  E1209 13:30:37.974841      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:38.974839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-3759b3d8-a29f-4ede-a615-b0132b8b2a4f @ 12/09/23 13:30:39.455
  STEP: Updating configmap cm-test-opt-upd-776d1389-51f8-4b64-aecb-2c2eaf34d6a6 @ 12/09/23 13:30:39.462
  STEP: Creating configMap with name cm-test-opt-create-29968ede-299a-4c62-83fe-f19cce2b7197 @ 12/09/23 13:30:39.467
  STEP: waiting to observe update in volume @ 12/09/23 13:30:39.474
  E1209 13:30:39.975883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:40.975998      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:41.976589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:42.976697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:43.976782      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:44.976870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:45.977275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:46.977319      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:47.977368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:48.977679      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:49.978031      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:50.978178      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:51.979089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:52.979174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:53.979501      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:54.979595      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:55.979883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:56.980082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:57.980183      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:58.980568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:30:59.980663      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:00.980830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:01.981786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:02.981864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:03.982946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:04.983912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:05.984512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:06.985459      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:07.986538      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:08.987297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:09.988298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:10.988396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:11.989253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:12.989333      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:13.989431      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:14.989531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:15.990509      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:16.990691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:17.991323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:18.991403      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:19.991876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:20.992067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:21.992162      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:22.992332      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:23.993280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:24.993365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:25.993903      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:26.994440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:27.995435      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:28.995694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:29.996265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:30.997103      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:31.998113      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:32.998204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:33.998601      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:34.998764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:35.999564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:36.999639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:38.000285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:39.000677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:40.000694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:41.000892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:42.001616      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:43.001910      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:44.001995      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:45.002094      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:46.002530      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:47.002687      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:48.003149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:49.003907      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:50.004369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:51.004475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:52.004811      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:53.005030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:54.005339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:55.005672      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:56.005829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:57.005920      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:58.006784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:31:59.006843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:00.007629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:01.007888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:02.008672      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:03.009267      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:04.010015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:05.010196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:06.010525      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:07.010697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:07.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9777" for this suite. @ 12/09/23 13:32:07.918
• [90.552 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 12/09/23 13:32:07.925
  Dec  9 13:32:07.925: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename daemonsets @ 12/09/23 13:32:07.925
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:32:07.94
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:32:07.944
  Dec  9 13:32:07.969: INFO: Create a RollingUpdate DaemonSet
  Dec  9 13:32:07.974: INFO: Check that daemon pods launch on every node of the cluster
  Dec  9 13:32:07.978: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:07.978: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:07.982: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 13:32:07.982: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  E1209 13:32:08.011456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:08.986: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:08.986: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:08.991: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 13:32:08.991: INFO: Node ip-172-31-80-205 is running 0 daemon pod, expected 1
  E1209 13:32:09.012383      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:09.988: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:09.988: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:09.992: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 13:32:09.992: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Dec  9 13:32:09.992: INFO: Update the DaemonSet to trigger a rollout
  Dec  9 13:32:10.003: INFO: Updating DaemonSet daemon-set
  E1209 13:32:10.012492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:11.012641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:11.021: INFO: Roll back the DaemonSet before rollout is complete
  Dec  9 13:32:11.031: INFO: Updating DaemonSet daemon-set
  Dec  9 13:32:11.031: INFO: Make sure DaemonSet rollback is complete
  Dec  9 13:32:11.038: INFO: Wrong image for pod: daemon-set-qbmzc. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Dec  9 13:32:11.038: INFO: Pod daemon-set-qbmzc is not available
  Dec  9 13:32:11.045: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:11.045: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1209 13:32:12.013597      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:12.054: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:12.054: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1209 13:32:13.014083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:13.050: INFO: Pod daemon-set-bzc7q is not available
  Dec  9 13:32:13.053: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:32:13.054: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 12/09/23 13:32:13.068
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6038, will wait for the garbage collector to delete the pods @ 12/09/23 13:32:13.068
  Dec  9 13:32:13.129: INFO: Deleting DaemonSet.extensions daemon-set took: 7.00649ms
  Dec  9 13:32:13.230: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.16736ms
  E1209 13:32:14.014067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:14.937: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 13:32:14.937: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  9 13:32:14.942: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33953"},"items":null}

  Dec  9 13:32:14.944: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33953"},"items":null}

  Dec  9 13:32:14.959: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6038" for this suite. @ 12/09/23 13:32:14.963
• [7.045 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 12/09/23 13:32:14.97
  Dec  9 13:32:14.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename tables @ 12/09/23 13:32:14.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:32:14.987
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:32:14.99
  Dec  9 13:32:14.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-6849" for this suite. @ 12/09/23 13:32:15.002
• [0.039 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 12/09/23 13:32:15.009
  Dec  9 13:32:15.009: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svcaccounts @ 12/09/23 13:32:15.01
  E1209 13:32:15.014211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:32:15.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:32:15.028
  STEP: Creating a pod to test service account token:  @ 12/09/23 13:32:15.032
  E1209 13:32:16.014849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:17.014937      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:32:17.06
  Dec  9 13:32:17.063: INFO: Trying to get logs from node ip-172-31-77-176 pod test-pod-17417f5b-7af8-4ab2-9499-4b05987013e9 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:32:17.083
  Dec  9 13:32:17.100: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8755" for this suite. @ 12/09/23 13:32:17.103
• [2.100 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 12/09/23 13:32:17.11
  Dec  9 13:32:17.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/09/23 13:32:17.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:32:17.126
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:32:17.13
  STEP: create the container to handle the HTTPGet hook request. @ 12/09/23 13:32:17.14
  E1209 13:32:18.015664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:19.015836      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/09/23 13:32:19.166
  E1209 13:32:20.016093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:21.016263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 12/09/23 13:32:21.185
  STEP: delete the pod with lifecycle hook @ 12/09/23 13:32:21.192
  E1209 13:32:22.016688      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:23.017606      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:23.213: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-4794" for this suite. @ 12/09/23 13:32:23.218
• [6.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 12/09/23 13:32:23.226
  Dec  9 13:32:23.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 13:32:23.227
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:32:23.247
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:32:23.253
  STEP: creating service nodeport-test with type=NodePort in namespace services-1804 @ 12/09/23 13:32:23.257
  STEP: creating replication controller nodeport-test in namespace services-1804 @ 12/09/23 13:32:23.272
  I1209 13:32:23.291074      18 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-1804, replica count: 2
  E1209 13:32:24.017783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:25.018020      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:26.018324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1209 13:32:26.341841      18 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  9 13:32:26.341: INFO: Creating new exec pod
  E1209 13:32:27.018413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:28.018520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:29.019381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:29.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1804 exec execpodpg5kk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Dec  9 13:32:29.480: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Dec  9 13:32:29.480: INFO: stdout: "nodeport-test-6mt7q"
  Dec  9 13:32:29.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1804 exec execpodpg5kk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.79 80'
  Dec  9 13:32:29.587: INFO: stderr: "+ nc -v -t -w 2 10.152.183.79 80\n+ echo hostName\nConnection to 10.152.183.79 80 port [tcp/http] succeeded!\n"
  Dec  9 13:32:29.587: INFO: stdout: ""
  E1209 13:32:30.019895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:30.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1804 exec execpodpg5kk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.79 80'
  Dec  9 13:32:30.698: INFO: stderr: "+ nc -v -t -w 2 10.152.183.79 80\n+ echo hostName\nConnection to 10.152.183.79 80 port [tcp/http] succeeded!\n"
  Dec  9 13:32:30.698: INFO: stdout: ""
  E1209 13:32:31.020506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:31.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1804 exec execpodpg5kk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.79 80'
  Dec  9 13:32:31.689: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.79 80\nConnection to 10.152.183.79 80 port [tcp/http] succeeded!\n"
  Dec  9 13:32:31.689: INFO: stdout: ""
  E1209 13:32:32.020985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:32:32.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1804 exec execpodpg5kk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.79 80'
  Dec  9 13:32:32.683: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.79 80\nConnection to 10.152.183.79 80 port [tcp/http] succeeded!\n"
  Dec  9 13:32:32.683: INFO: stdout: "nodeport-test-6mt7q"
  Dec  9 13:32:32.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1804 exec execpodpg5kk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.38.129 30487'
  Dec  9 13:32:32.790: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.38.129 30487\nConnection to 172.31.38.129 30487 port [tcp/*] succeeded!\n"
  Dec  9 13:32:32.790: INFO: stdout: "nodeport-test-mwzjt"
  Dec  9 13:32:32.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-1804 exec execpodpg5kk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.77.176 30487'
  Dec  9 13:32:32.896: INFO: stderr: "+ nc -v -t -w 2 172.31.77.176 30487\n+ echo hostName\nConnection to 172.31.77.176 30487 port [tcp/*] succeeded!\n"
  Dec  9 13:32:32.896: INFO: stdout: "nodeport-test-mwzjt"
  Dec  9 13:32:32.896: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-1804" for this suite. @ 12/09/23 13:32:32.9
• [9.682 seconds]
------------------------------
SS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 12/09/23 13:32:32.908
  Dec  9 13:32:32.908: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename job @ 12/09/23 13:32:32.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:32:32.923
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:32:32.927
  STEP: Creating a suspended job @ 12/09/23 13:32:32.935
  STEP: Patching the Job @ 12/09/23 13:32:32.939
  STEP: Watching for Job to be patched @ 12/09/23 13:32:32.956
  Dec  9 13:32:32.958: INFO: Event ADDED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9] and annotations: map[]
  Dec  9 13:32:32.958: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9] and annotations: map[]
  Dec  9 13:32:32.958: INFO: Event MODIFIED found for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[]
  STEP: Updating the job @ 12/09/23 13:32:32.958
  STEP: Watching for Job to be updated @ 12/09/23 13:32:32.968
  Dec  9 13:32:32.970: INFO: Event MODIFIED found for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:32.970: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 12/09/23 13:32:32.97
  Dec  9 13:32:32.975: INFO: Job: e2e-mm5w9 as labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched]
  STEP: Waiting for job to complete @ 12/09/23 13:32:32.975
  E1209 13:32:33.021047      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:34.021749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:35.022600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:36.022692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:37.023734      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:38.023831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:39.024771      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:40.025087      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 12/09/23 13:32:40.98
  STEP: Watching for Job to be deleted @ 12/09/23 13:32:40.99
  Dec  9 13:32:40.993: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:40.993: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:40.993: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:40.993: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:40.993: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:40.993: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:40.993: INFO: Event MODIFIED observed for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  Dec  9 13:32:40.993: INFO: Event DELETED found for Job e2e-mm5w9 in namespace job-7876 with labels: map[e2e-job-label:e2e-mm5w9 e2e-mm5w9:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 12/09/23 13:32:40.993
  Dec  9 13:32:40.999: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7876" for this suite. @ 12/09/23 13:32:41.006
• [8.107 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 12/09/23 13:32:41.017
  Dec  9 13:32:41.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svcaccounts @ 12/09/23 13:32:41.018
  E1209 13:32:41.025386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:32:41.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:32:41.043
  Dec  9 13:32:41.060: INFO: created pod
  E1209 13:32:42.025502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:43.025595      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:44.025986      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:45.026105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:32:45.076
  E1209 13:32:46.026848      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:47.026956      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:48.027024      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:49.027904      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:50.028073      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:51.028154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:52.028242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:53.028594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:54.028959      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:55.029124      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:56.029421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:57.029572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:58.030246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:32:59.030379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:00.030467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:01.030652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:02.030850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:03.030905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:04.030972      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:05.031075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:06.031913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:07.032092      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:08.032294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:09.032962      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:10.033114      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:11.033174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:12.033265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:13.033710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:14.034050      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:15.034155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:33:15.076: INFO: polling logs
  Dec  9 13:33:15.083: INFO: Pod logs: 
  I1209 13:32:41.655277       1 log.go:194] OK: Got token
  I1209 13:32:41.655327       1 log.go:194] validating with in-cluster discovery
  I1209 13:32:41.655547       1 log.go:194] OK: got issuer https://kubernetes.default.svc
  I1209 13:32:41.655575       1 log.go:194] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8706:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc00024dc50), NotBefore:(*jwt.NumericDate)(0xc00024dd38), IssuedAt:(*jwt.NumericDate)(0xc00024dc60), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8706", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6c324311-c5d3-419a-b122-cfc20623c2de"}}}
  I1209 13:32:41.664704       1 log.go:194] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I1209 13:32:41.670938       1 log.go:194] OK: Validated signature on JWT
  I1209 13:32:41.671107       1 log.go:194] OK: Got valid claims from token!
  I1209 13:32:41.671152       1 log.go:194] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-8706:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc000049368), NotBefore:(*jwt.NumericDate)(0xc0000493a0), IssuedAt:(*jwt.NumericDate)(0xc000049370), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-8706", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"6c324311-c5d3-419a-b122-cfc20623c2de"}}}

  Dec  9 13:33:15.083: INFO: completed pod
  Dec  9 13:33:15.089: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-8706" for this suite. @ 12/09/23 13:33:15.094
• [34.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 12/09/23 13:33:15.102
  Dec  9 13:33:15.102: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/09/23 13:33:15.103
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:33:15.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:33:15.123
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 12/09/23 13:33:15.127
  Dec  9 13:33:15.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  E1209 13:33:16.034180      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:17.034628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:18.034779      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:19.035244      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:20.035355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 12/09/23 13:33:20.157
  Dec  9 13:33:20.157: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  E1209 13:33:21.036265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:33:21.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  E1209 13:33:22.037187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:23.038172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:24.038644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:25.039692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:26.040549      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:33:26.623: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-232" for this suite. @ 12/09/23 13:33:26.631
• [11.535 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 12/09/23 13:33:26.639
  Dec  9 13:33:26.639: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:33:26.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:33:26.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:33:26.661
  STEP: Creating configMap with name projected-configmap-test-volume-map-8ab974c3-1421-4085-bd68-977367f6ec37 @ 12/09/23 13:33:26.665
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:33:26.67
  E1209 13:33:27.040846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:28.040923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:29.041285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:30.041400      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:33:30.692
  Dec  9 13:33:30.696: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-configmaps-32bb9132-b4a0-4f96-b2e2-bba1eefe835f container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:33:30.703
  Dec  9 13:33:30.722: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6174" for this suite. @ 12/09/23 13:33:30.726
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1707
  STEP: Creating a kubernetes client @ 12/09/23 13:33:30.735
  Dec  9 13:33:30.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:33:30.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:33:30.754
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:33:30.759
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/09/23 13:33:30.763
  Dec  9 13:33:30.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-6917 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Dec  9 13:33:30.818: INFO: stderr: ""
  Dec  9 13:33:30.818: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/09/23 13:33:30.818
  Dec  9 13:33:30.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-6917 delete pods e2e-test-httpd-pod'
  E1209 13:33:31.042016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:32.042092      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:33:32.054: INFO: stderr: ""
  Dec  9 13:33:32.055: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec  9 13:33:32.055: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-6917" for this suite. @ 12/09/23 13:33:32.059
• [1.331 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 12/09/23 13:33:32.067
  Dec  9 13:33:32.067: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 13:33:32.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:33:32.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:33:32.086
  STEP: Creating secret with name s-test-opt-del-83120ed9-6ab2-4981-9b0d-bb2e16461b5c @ 12/09/23 13:33:32.093
  STEP: Creating secret with name s-test-opt-upd-5e69c660-87bc-49ab-bbf0-b25713b5ea40 @ 12/09/23 13:33:32.098
  STEP: Creating the pod @ 12/09/23 13:33:32.102
  E1209 13:33:33.042839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:34.043907      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-83120ed9-6ab2-4981-9b0d-bb2e16461b5c @ 12/09/23 13:33:34.144
  STEP: Updating secret s-test-opt-upd-5e69c660-87bc-49ab-bbf0-b25713b5ea40 @ 12/09/23 13:33:34.152
  STEP: Creating secret with name s-test-opt-create-7b677d93-c9d2-457f-b080-33c9c2db10d5 @ 12/09/23 13:33:34.157
  STEP: waiting to observe update in volume @ 12/09/23 13:33:34.163
  E1209 13:33:35.044628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:36.044711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:37.044942      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:38.045052      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:39.045979      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:40.046198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:41.046807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:42.046852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:43.047752      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:44.047912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:45.047989      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:46.048521      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:47.049529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:48.049625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:49.049648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:50.050384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:51.051395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:52.051415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:53.051894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:54.052197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:55.052302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:56.052481      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:57.052571      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:58.052653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:33:59.052743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:00.052918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:01.053568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:02.053650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:03.053706      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:04.054013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:05.054118      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:06.054214      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:07.055190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:08.055915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:09.056598      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:10.056674      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:11.056775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:12.056880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:13.057156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:14.057486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:15.057583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:16.057711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:17.057797      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:18.057978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:19.058064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:20.058263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:21.058353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:22.058505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:23.059483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:24.059562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:25.059896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:26.060076      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:27.060854      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:28.060935      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:29.061792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:30.061892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:31.062918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:32.063014      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:33.063914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:34.064314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:35.064395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:36.065240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:37.065335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:38.065400      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:38.445: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4535" for this suite. @ 12/09/23 13:34:38.448
• [66.388 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 12/09/23 13:34:38.456
  Dec  9 13:34:38.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 13:34:38.456
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:34:38.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:34:38.48
  STEP: Creating pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165 @ 12/09/23 13:34:38.484
  E1209 13:34:39.066104      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:40.066623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 13:34:40.502
  Dec  9 13:34:40.505: INFO: Initial restart count of pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 is 0
  Dec  9 13:34:40.508: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:41.067549      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:42.067641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:42.512: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:43.067891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:44.068253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:44.517: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:45.068367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:46.069069      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:46.520: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:47.069162      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:48.069380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:48.525: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:49.070061      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:50.070243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:50.530: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:51.070999      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:52.071094      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:52.534: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:53.071179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:54.071896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:54.538: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:55.072856      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:56.072949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:56.542: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:57.073634      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:34:58.074349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:34:58.547: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:34:59.074700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:00.074831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:00.551: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:01.075615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:02.075718      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:02.555: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:03.075791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:04.076284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:04.558: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:05.076376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:06.077398      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:06.564: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:07.078157      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:08.078229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:08.568: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:09.078345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:10.078416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:10.572: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:11.079410      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:12.079908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:12.578: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:13.080035      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:14.081059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:14.583: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:15.081443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:16.081618      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:16.588: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:17.082541      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:18.082831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:18.593: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:19.083590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:20.083639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:20.597: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:21.083728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:22.084192      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:22.601: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:23.084795      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:24.085047      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:24.605: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:25.085281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:26.085461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:26.610: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:27.086356      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:28.087308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:28.615: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:29.087889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:30.087975      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:30.620: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:31.088876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:32.088964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:32.626: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:33.089591      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:34.089735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:34.629: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:35.089943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:36.090077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:36.634: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:37.091150      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:38.092008      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:38.639: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:39.092983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:40.093072      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:40.643: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:41.094025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:42.094236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:42.648: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:43.094903      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:44.095000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:44.652: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:45.095895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:46.096120      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:46.657: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:47.096378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:48.096472      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:48.661: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:49.097296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:50.097640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:50.666: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:51.098405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:52.099346      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:52.670: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:53.099377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:54.099468      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:54.675: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:55.100445      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:56.100534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:56.679: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:57.101134      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:35:58.101223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:35:58.684: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:35:59.101867      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:00.102024      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:00.688: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:01.102900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:02.102988      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:02.693: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:03.103846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:04.104055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:04.697: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:05.104136      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:06.104290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:06.702: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:07.104508      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:08.104874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:08.707: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:09.104984      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:10.105144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:10.711: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:11.105652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:12.105757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:12.715: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:13.105943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:14.106051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:14.719: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:15.106129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:16.107089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:16.724: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:17.107161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:18.108149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:18.729: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:19.108237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:20.108330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:20.734: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:21.108449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:22.108538      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:22.738: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:23.109592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:24.109970      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:24.743: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:25.110797      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:26.110845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:26.749: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:27.111539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:28.112179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:28.754: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:29.112295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:30.112376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:30.759: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:31.113323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:32.113573      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:32.764: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:33.114596      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:34.114884      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:34.768: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:35.115432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:36.115888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:36.773: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:37.116190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:38.117235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:38.777: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:39.118210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:40.118399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:40.782: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:41.118912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:42.119002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:42.786: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:43.119532      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:44.119629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:44.789: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:45.119721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:46.119901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:46.793: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:47.120541      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:48.120627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:48.797: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:49.121664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:50.121757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:50.802: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:51.122418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:52.122516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:52.805: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:53.123078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:54.123415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:54.808: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:55.124243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:56.124410      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:56.814: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:57.125447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:36:58.125536      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:36:58.817: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:36:59.126288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:00.126373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:00.821: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:01.127372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:02.127879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:02.827: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:03.128020      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:04.128464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:04.831: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:05.129078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:06.129172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:06.836: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:07.129264      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:08.129452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:08.841: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:09.129600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:10.130046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:10.846: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:11.130562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:12.130653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:12.849: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:13.131165      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:14.131939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:14.854: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:15.131987      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:16.132209      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:16.859: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:17.132336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:18.132609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:18.863: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:19.133380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:20.133484      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:20.868: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:21.134330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:22.134419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:22.872: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:23.134584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:24.134818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:24.877: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:25.135399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:26.135489      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:26.884: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:27.135671      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:28.135893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:28.888: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:29.136568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:30.136652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:30.893: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:31.137611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:32.137807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:32.898: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:33.138432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:34.138816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:34.903: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:35.139751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:36.139905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:36.908: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:37.140570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:38.140750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:38.913: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:39.141691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:40.141861      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:40.917: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:41.142866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:42.143891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:42.923: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:43.144881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:44.144966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:44.928: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:45.145201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:46.146097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:46.935: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:47.146323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:48.146428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:48.938: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:49.146903      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:50.146997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:50.942: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:51.147767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:52.147913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:52.947: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:53.148758      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:54.149110      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:54.951: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:55.149680      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:56.149843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:56.955: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:57.150286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:37:58.150472      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:37:58.960: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:37:59.151184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:00.151278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:00.965: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:01.151381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:02.151886      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:02.970: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:03.152296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:04.152579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:04.974: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:05.152780      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:06.152820      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:06.979: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:07.153284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:08.153446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:08.984: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:09.153969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:10.154758      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:10.989: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:11.155572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:12.155665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:12.993: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:13.156313      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:14.156396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:14.997: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:15.157438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:16.158246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:17.002: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:17.158684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:18.158829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:19.006: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:19.159880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:20.159982      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:21.011: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:21.160444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:22.160616      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:23.015: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:23.161504      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:24.161605      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:25.020: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:25.162035      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:26.162194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:27.032: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:27.162884      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:28.162982      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:29.037: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:29.163209      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:30.163308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:31.041: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:31.164102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:32.164998      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:33.047: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:33.165714      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:34.165913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:35.051: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:35.166522      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:36.166704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:37.057: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:37.166776      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:38.166849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:39.063: INFO: Get pod test-grpc-c3cb6030-ba97-4ed3-a44b-6e146f5f37b4 in namespace container-probe-7165
  E1209 13:38:39.167364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:40.167899      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:41.063: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:38:41.068
  STEP: Destroying namespace "container-probe-7165" for this suite. @ 12/09/23 13:38:41.08
• [242.633 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 12/09/23 13:38:41.089
  Dec  9 13:38:41.089: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:38:41.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:38:41.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:38:41.118
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:38:41.121
  E1209 13:38:41.168635      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:42.168680      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:43.168896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:44.169082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:38:45.146
  Dec  9 13:38:45.150: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-e60f8cfd-4015-4c57-be79-d1255b8a7692 container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:38:45.167
  E1209 13:38:45.169188      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:45.181: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1481" for this suite. @ 12/09/23 13:38:45.184
• [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 12/09/23 13:38:45.195
  Dec  9 13:38:45.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubelet-test @ 12/09/23 13:38:45.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:38:45.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:38:45.213
  STEP: Waiting for pod completion @ 12/09/23 13:38:45.225
  E1209 13:38:46.169323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:47.169412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:48.170467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:49.171318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:38:49.247: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3529" for this suite. @ 12/09/23 13:38:49.25
• [4.061 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 12/09/23 13:38:49.256
  Dec  9 13:38:49.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename field-validation @ 12/09/23 13:38:49.257
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:38:49.272
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:38:49.275
  STEP: apply creating a deployment @ 12/09/23 13:38:49.278
  Dec  9 13:38:49.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7053" for this suite. @ 12/09/23 13:38:49.298
• [0.049 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 12/09/23 13:38:49.305
  Dec  9 13:38:49.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename downward-api @ 12/09/23 13:38:49.306
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:38:49.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:38:49.332
  STEP: Creating a pod to test downward API volume plugin @ 12/09/23 13:38:49.336
  E1209 13:38:50.171409      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:51.171489      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:52.172339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:53.172514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:38:53.364
  Dec  9 13:38:53.367: INFO: Trying to get logs from node ip-172-31-77-176 pod downwardapi-volume-82449ce3-b432-43ba-a7db-a8be593653ee container client-container: <nil>
  STEP: delete the pod @ 12/09/23 13:38:53.373
  Dec  9 13:38:53.393: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6121" for this suite. @ 12/09/23 13:38:53.397
• [4.100 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 12/09/23 13:38:53.406
  Dec  9 13:38:53.406: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename gc @ 12/09/23 13:38:53.406
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:38:53.423
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:38:53.427
  STEP: create the rc @ 12/09/23 13:38:53.43
  W1209 13:38:53.437700      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1209 13:38:54.173238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:55.173274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:56.173366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:57.173537      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:38:58.173620      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/09/23 13:38:58.441
  STEP: wait for all pods to be garbage collected @ 12/09/23 13:38:58.449
  E1209 13:38:59.174256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:00.174430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:01.174608      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:02.174686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:03.174831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/09/23 13:39:03.457
  W1209 13:39:03.464801      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  9 13:39:03.464: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  9 13:39:03.464: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-9521" for this suite. @ 12/09/23 13:39:03.468
• [10.069 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 12/09/23 13:39:03.475
  Dec  9 13:39:03.475: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replicaset @ 12/09/23 13:39:03.476
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:03.492
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:03.495
  STEP: Create a Replicaset @ 12/09/23 13:39:03.503
  STEP: Verify that the required pods have come up. @ 12/09/23 13:39:03.508
  Dec  9 13:39:03.512: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1209 13:39:04.175345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:05.176178      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:06.176244      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:07.176321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:08.176414      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:39:08.517: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/09/23 13:39:08.517
  STEP: Getting /status @ 12/09/23 13:39:08.517
  Dec  9 13:39:08.520: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 12/09/23 13:39:08.52
  Dec  9 13:39:08.530: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 12/09/23 13:39:08.53
  Dec  9 13:39:08.532: INFO: Observed &ReplicaSet event: ADDED
  Dec  9 13:39:08.532: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  9 13:39:08.532: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  9 13:39:08.532: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  9 13:39:08.532: INFO: Found replicaset test-rs in namespace replicaset-1690 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  9 13:39:08.532: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 12/09/23 13:39:08.532
  Dec  9 13:39:08.532: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec  9 13:39:08.539: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 12/09/23 13:39:08.539
  Dec  9 13:39:08.541: INFO: Observed &ReplicaSet event: ADDED
  Dec  9 13:39:08.541: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  9 13:39:08.541: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  9 13:39:08.541: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  9 13:39:08.541: INFO: Observed replicaset test-rs in namespace replicaset-1690 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  9 13:39:08.541: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  9 13:39:08.541: INFO: Found replicaset test-rs in namespace replicaset-1690 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Dec  9 13:39:08.541: INFO: Replicaset test-rs has a patched status
  Dec  9 13:39:08.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1690" for this suite. @ 12/09/23 13:39:08.545
• [5.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 12/09/23 13:39:08.552
  Dec  9 13:39:08.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-pred @ 12/09/23 13:39:08.553
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:08.571
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:08.575
  Dec  9 13:39:08.578: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  9 13:39:08.588: INFO: Waiting for terminating namespaces to be deleted...
  Dec  9 13:39:08.590: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-38-129 before test
  Dec  9 13:39:08.598: INFO: nginx-ingress-controller-kubernetes-worker-j9sl2 from ingress-nginx-kubernetes-worker started at 2023-12-09 12:04:10 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.598: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 13:39:08.598: INFO: calico-node-j8mjn from kube-system started at 2023-12-09 12:03:58 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.598: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 13:39:08.598: INFO: sonobuoy-e2e-job-f705b9d168e44085 from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:39:08.598: INFO: 	Container e2e ready: true, restart count 0
  Dec  9 13:39:08.598: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:39:08.598: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-k7blf from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:39:08.598: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:39:08.598: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 13:39:08.598: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-77-176 before test
  Dec  9 13:39:08.603: INFO: nginx-ingress-controller-kubernetes-worker-tdr5k from ingress-nginx-kubernetes-worker started at 2023-12-09 13:24:10 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.603: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 13:39:08.603: INFO: calico-node-rzjq2 from kube-system started at 2023-12-09 11:58:38 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.603: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 13:39:08.603: INFO: test-rs-ncfxz from replicaset-1690 started at 2023-12-09 13:39:03 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.603: INFO: 	Container httpd ready: true, restart count 0
  Dec  9 13:39:08.603: INFO: sonobuoy from sonobuoy started at 2023-12-09 12:07:20 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.603: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  9 13:39:08.603: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-29sdb from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:39:08.603: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:39:08.603: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 13:39:08.603: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-80-205 before test
  Dec  9 13:39:08.608: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-nm9vp from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.608: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  9 13:39:08.608: INFO: nginx-ingress-controller-kubernetes-worker-crj2p from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.608: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 13:39:08.608: INFO: calico-node-f2fvk from kube-system started at 2023-12-09 11:58:36 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.608: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 13:39:08.608: INFO: coredns-59cfb5bf46-t9rkp from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.608: INFO: 	Container coredns ready: true, restart count 0
  Dec  9 13:39:08.608: INFO: kube-state-metrics-78c475f58b-km8l9 from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.608: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  9 13:39:08.608: INFO: metrics-server-v0.6.3-69d7fbfdf8-hlh9f from kube-system started at 2023-12-09 11:58:49 +0000 UTC (2 container statuses recorded)
  Dec  9 13:39:08.608: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  9 13:39:08.608: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  9 13:39:08.608: INFO: dashboard-metrics-scraper-5dd7cb5fc-jlz46 from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.609: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  9 13:39:08.609: INFO: kubernetes-dashboard-7b899cb9d9-68n2j from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:39:08.609: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  9 13:39:08.609: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-w5xwq from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:39:08.609: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:39:08.609: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-38-129 @ 12/09/23 13:39:08.625
  STEP: verifying the node has the label node ip-172-31-77-176 @ 12/09/23 13:39:08.642
  STEP: verifying the node has the label node ip-172-31-80-205 @ 12/09/23 13:39:08.657
  Dec  9 13:39:08.672: INFO: Pod default-http-backend-kubernetes-worker-5c79cc75ff-nm9vp requesting resource cpu=10m on Node ip-172-31-80-205
  Dec  9 13:39:08.672: INFO: Pod nginx-ingress-controller-kubernetes-worker-crj2p requesting resource cpu=0m on Node ip-172-31-80-205
  Dec  9 13:39:08.672: INFO: Pod nginx-ingress-controller-kubernetes-worker-j9sl2 requesting resource cpu=0m on Node ip-172-31-38-129
  Dec  9 13:39:08.672: INFO: Pod nginx-ingress-controller-kubernetes-worker-tdr5k requesting resource cpu=0m on Node ip-172-31-77-176
  Dec  9 13:39:08.672: INFO: Pod calico-node-f2fvk requesting resource cpu=250m on Node ip-172-31-80-205
  Dec  9 13:39:08.672: INFO: Pod calico-node-j8mjn requesting resource cpu=250m on Node ip-172-31-38-129
  Dec  9 13:39:08.672: INFO: Pod calico-node-rzjq2 requesting resource cpu=250m on Node ip-172-31-77-176
  Dec  9 13:39:08.672: INFO: Pod coredns-59cfb5bf46-t9rkp requesting resource cpu=100m on Node ip-172-31-80-205
  Dec  9 13:39:08.672: INFO: Pod kube-state-metrics-78c475f58b-km8l9 requesting resource cpu=0m on Node ip-172-31-80-205
  Dec  9 13:39:08.672: INFO: Pod metrics-server-v0.6.3-69d7fbfdf8-hlh9f requesting resource cpu=5m on Node ip-172-31-80-205
  Dec  9 13:39:08.672: INFO: Pod dashboard-metrics-scraper-5dd7cb5fc-jlz46 requesting resource cpu=0m on Node ip-172-31-80-205
  Dec  9 13:39:08.673: INFO: Pod kubernetes-dashboard-7b899cb9d9-68n2j requesting resource cpu=0m on Node ip-172-31-80-205
  Dec  9 13:39:08.673: INFO: Pod test-rs-ncfxz requesting resource cpu=0m on Node ip-172-31-77-176
  Dec  9 13:39:08.673: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-77-176
  Dec  9 13:39:08.673: INFO: Pod sonobuoy-e2e-job-f705b9d168e44085 requesting resource cpu=0m on Node ip-172-31-38-129
  Dec  9 13:39:08.673: INFO: Pod sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-29sdb requesting resource cpu=0m on Node ip-172-31-77-176
  Dec  9 13:39:08.673: INFO: Pod sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-k7blf requesting resource cpu=0m on Node ip-172-31-38-129
  Dec  9 13:39:08.673: INFO: Pod sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-w5xwq requesting resource cpu=0m on Node ip-172-31-80-205
  STEP: Starting Pods to consume most of the cluster CPU. @ 12/09/23 13:39:08.673
  Dec  9 13:39:08.673: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-38-129
  Dec  9 13:39:08.683: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-77-176
  Dec  9 13:39:08.694: INFO: Creating a pod which consumes cpu=1144m on Node ip-172-31-80-205
  E1209 13:39:09.176603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:10.176775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 12/09/23 13:39:10.721
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-64b44d37-2a82-4591-9eb1-600e82961aae.179f2d7145f3c0de], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3054/filler-pod-64b44d37-2a82-4591-9eb1-600e82961aae to ip-172-31-77-176] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-64b44d37-2a82-4591-9eb1-600e82961aae.179f2d7165e010bd], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-64b44d37-2a82-4591-9eb1-600e82961aae.179f2d7166efdbf0], Reason = [Created], Message = [Created container filler-pod-64b44d37-2a82-4591-9eb1-600e82961aae] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-64b44d37-2a82-4591-9eb1-600e82961aae.179f2d716a13c08f], Reason = [Started], Message = [Started container filler-pod-64b44d37-2a82-4591-9eb1-600e82961aae] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cdc28fde-930a-4e20-afd9-c514f8e122b4.179f2d7145a419c9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3054/filler-pod-cdc28fde-930a-4e20-afd9-c514f8e122b4 to ip-172-31-38-129] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cdc28fde-930a-4e20-afd9-c514f8e122b4.179f2d716640257a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cdc28fde-930a-4e20-afd9-c514f8e122b4.179f2d7167521f49], Reason = [Created], Message = [Created container filler-pod-cdc28fde-930a-4e20-afd9-c514f8e122b4] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-cdc28fde-930a-4e20-afd9-c514f8e122b4.179f2d716ae61a9c], Reason = [Started], Message = [Started container filler-pod-cdc28fde-930a-4e20-afd9-c514f8e122b4] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e6eca305-784d-4339-b984-f544fb1cf335.179f2d714676a8f8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3054/filler-pod-e6eca305-784d-4339-b984-f544fb1cf335 to ip-172-31-80-205] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e6eca305-784d-4339-b984-f544fb1cf335.179f2d71674d6e4f], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e6eca305-784d-4339-b984-f544fb1cf335.179f2d71683437b7], Reason = [Created], Message = [Created container filler-pod-e6eca305-784d-4339-b984-f544fb1cf335] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-e6eca305-784d-4339-b984-f544fb1cf335.179f2d716b568768], Reason = [Started], Message = [Started container filler-pod-e6eca305-784d-4339-b984-f544fb1cf335] @ 12/09/23 13:39:10.725
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.179f2d71bf5ca36e], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod..] @ 12/09/23 13:39:10.741
  E1209 13:39:11.176929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ip-172-31-38-129 @ 12/09/23 13:39:11.741
  STEP: verifying the node doesn't have the label node @ 12/09/23 13:39:11.778
  STEP: removing the label node off the node ip-172-31-77-176 @ 12/09/23 13:39:11.787
  STEP: verifying the node doesn't have the label node @ 12/09/23 13:39:11.804
  STEP: removing the label node off the node ip-172-31-80-205 @ 12/09/23 13:39:11.809
  STEP: verifying the node doesn't have the label node @ 12/09/23 13:39:11.841
  Dec  9 13:39:11.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3054" for this suite. @ 12/09/23 13:39:11.853
• [3.306 seconds]
------------------------------
SSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 12/09/23 13:39:11.859
  Dec  9 13:39:11.859: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename dns @ 12/09/23 13:39:11.86
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:11.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:11.881
  STEP: Creating a test headless service @ 12/09/23 13:39:11.886
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 12/09/23 13:39:11.895
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3819.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 12/09/23 13:39:11.895
  STEP: creating a pod to probe DNS @ 12/09/23 13:39:11.895
  STEP: submitting the pod to kubernetes @ 12/09/23 13:39:11.895
  E1209 13:39:12.177871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:13.177959      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/09/23 13:39:13.922
  STEP: looking for the results for each expected name from probers @ 12/09/23 13:39:13.926
  Dec  9 13:39:13.944: INFO: DNS probes using dns-3819/dns-test-f3d4d84a-644f-463d-86b7-4279ec2868b3 succeeded

  Dec  9 13:39:13.944: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:39:13.948
  STEP: deleting the test headless service @ 12/09/23 13:39:13.959
  STEP: Destroying namespace "dns-3819" for this suite. @ 12/09/23 13:39:13.979
• [2.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 12/09/23 13:39:13.987
  Dec  9 13:39:13.987: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/09/23 13:39:13.988
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:14.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:14.008
  STEP: creating a target pod @ 12/09/23 13:39:14.012
  E1209 13:39:14.178505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:15.178896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 12/09/23 13:39:16.032
  E1209 13:39:16.179281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:17.179938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:18.179992      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:19.180206      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 12/09/23 13:39:20.053
  Dec  9 13:39:20.053: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-64 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  9 13:39:20.053: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  Dec  9 13:39:20.053: INFO: ExecWithOptions: Clientset creation
  Dec  9 13:39:20.053: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-64/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Dec  9 13:39:20.110: INFO: Exec stderr: ""
  Dec  9 13:39:20.118: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-64" for this suite. @ 12/09/23 13:39:20.122
• [6.142 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 12/09/23 13:39:20.129
  Dec  9 13:39:20.129: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:39:20.13
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:20.145
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:20.149
  STEP: Setting up server cert @ 12/09/23 13:39:20.173
  E1209 13:39:20.181132      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:39:20.415
  STEP: Deploying the webhook pod @ 12/09/23 13:39:20.437
  STEP: Wait for the deployment to be ready @ 12/09/23 13:39:20.452
  Dec  9 13:39:20.464: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1209 13:39:21.181256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:22.181345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/09/23 13:39:22.475
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:39:22.485
  E1209 13:39:23.182201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:39:23.485: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  9 13:39:23.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 12/09/23 13:39:24.001
  STEP: Creating a custom resource that should be denied by the webhook @ 12/09/23 13:39:24.016
  E1209 13:39:24.182781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:25.182839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 12/09/23 13:39:26.043
  STEP: Updating the custom resource with disallowed data should be denied @ 12/09/23 13:39:26.05
  STEP: Deleting the custom resource should be denied @ 12/09/23 13:39:26.06
  STEP: Remove the offending key and value from the custom resource data @ 12/09/23 13:39:26.068
  STEP: Deleting the updated custom resource should be successful @ 12/09/23 13:39:26.079
  Dec  9 13:39:26.087: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1209 13:39:26.183503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-4995" for this suite. @ 12/09/23 13:39:26.659
  STEP: Destroying namespace "webhook-markers-8828" for this suite. @ 12/09/23 13:39:26.666
• [6.543 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 12/09/23 13:39:26.674
  Dec  9 13:39:26.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 13:39:26.674
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:26.691
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:26.694
  E1209 13:39:27.183754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:28.183834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:29.184507      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:30.185248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:31.185939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:32.186927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:33.187879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:34.187985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:35.188070      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:36.188993      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:37.189380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:38.189534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:39.190353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:40.191023      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:41.191545      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:42.191782      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:43.192365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/09/23 13:39:43.702
  E1209 13:39:44.192446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:45.192538      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:46.193292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:47.194108      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:48.194817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/09/23 13:39:48.707
  STEP: Ensuring resource quota status is calculated @ 12/09/23 13:39:48.713
  E1209 13:39:49.195093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:50.195348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 12/09/23 13:39:50.717
  STEP: Ensuring resource quota status captures configMap creation @ 12/09/23 13:39:50.728
  E1209 13:39:51.195885      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:52.196109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 12/09/23 13:39:52.733
  STEP: Ensuring resource quota status released usage @ 12/09/23 13:39:52.74
  E1209 13:39:53.196881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:54.197816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:39:54.744: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2300" for this suite. @ 12/09/23 13:39:54.751
• [28.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 12/09/23 13:39:54.759
  Dec  9 13:39:54.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename secrets @ 12/09/23 13:39:54.76
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:54.775
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:54.779
  STEP: Creating secret with name secret-test-map-eab2ee11-42b6-4106-b6f5-0745d2a693bc @ 12/09/23 13:39:54.782
  STEP: Creating a pod to test consume secrets @ 12/09/23 13:39:54.786
  E1209 13:39:55.197978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:56.198209      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:57.198992      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:39:58.199921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:39:58.809
  Dec  9 13:39:58.813: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-secrets-e024e4ed-d2e1-4f65-b82b-8c70287800b0 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/09/23 13:39:58.832
  Dec  9 13:39:58.848: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-3927" for this suite. @ 12/09/23 13:39:58.852
• [4.101 seconds]
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 12/09/23 13:39:58.861
  Dec  9 13:39:58.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename namespaces @ 12/09/23 13:39:58.861
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:58.874
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:58.877
  STEP: Read namespace status @ 12/09/23 13:39:58.881
  Dec  9 13:39:58.884: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 12/09/23 13:39:58.884
  Dec  9 13:39:58.891: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 12/09/23 13:39:58.891
  Dec  9 13:39:58.898: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Dec  9 13:39:58.899: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2293" for this suite. @ 12/09/23 13:39:58.903
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 12/09/23 13:39:58.912
  Dec  9 13:39:58.912: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename daemonsets @ 12/09/23 13:39:58.913
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:39:58.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:39:58.929
  STEP: Creating simple DaemonSet "daemon-set" @ 12/09/23 13:39:58.952
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/09/23 13:39:58.957
  Dec  9 13:39:58.964: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:39:58.964: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:39:58.968: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 13:39:58.968: INFO: Node ip-172-31-38-129 is running 0 daemon pod, expected 1
  E1209 13:39:59.200996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:39:59.974: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:39:59.974: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:39:59.979: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 13:39:59.979: INFO: Node ip-172-31-80-205 is running 0 daemon pod, expected 1
  E1209 13:40:00.201444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:00.972: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:00.972: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:00.977: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 13:40:00.977: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 12/09/23 13:40:00.98
  Dec  9 13:40:00.996: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:00.996: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:01.000: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 13:40:01.000: INFO: Node ip-172-31-77-176 is running 0 daemon pod, expected 1
  E1209 13:40:01.201531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:02.005: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:02.005: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:02.009: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  9 13:40:02.009: INFO: Node ip-172-31-77-176 is running 0 daemon pod, expected 1
  E1209 13:40:02.202296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:03.005: INFO: DaemonSet pods can't tolerate node ip-172-31-25-73 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:03.005: INFO: DaemonSet pods can't tolerate node ip-172-31-38-185 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  9 13:40:03.010: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  9 13:40:03.010: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/09/23 13:40:03.013
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6556, will wait for the garbage collector to delete the pods @ 12/09/23 13:40:03.013
  Dec  9 13:40:03.073: INFO: Deleting DaemonSet.extensions daemon-set took: 6.340549ms
  Dec  9 13:40:03.174: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.919214ms
  E1209 13:40:03.202736      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:04.202929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:04.778: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  9 13:40:04.778: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  9 13:40:04.782: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36143"},"items":null}

  Dec  9 13:40:04.786: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36143"},"items":null}

  Dec  9 13:40:04.802: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6556" for this suite. @ 12/09/23 13:40:04.805
• [5.899 seconds]
------------------------------
SS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 12/09/23 13:40:04.812
  Dec  9 13:40:04.812: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename container-probe @ 12/09/23 13:40:04.812
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:40:04.828
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:40:04.832
  STEP: Creating pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945 @ 12/09/23 13:40:04.835
  E1209 13:40:05.203038      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:06.203138      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/09/23 13:40:06.855
  Dec  9 13:40:06.860: INFO: Initial restart count of pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 is 0
  Dec  9 13:40:06.863: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:07.203717      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:08.203832      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:08.867: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:09.204096      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:10.204304      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:10.871: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:11.205196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:12.206061      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:12.877: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:13.206295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:14.206561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:14.881: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:15.207067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:16.207242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:16.885: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:17.207904      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:18.208026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:18.890: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:19.208511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:20.208609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:20.895: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:21.208698      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:22.208867      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:22.898: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:23.209048      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:24.209436      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:24.903: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:25.209637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:26.209717      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:26.907: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:27.210399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:28.210496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:28.911: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:29.210673      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:30.210843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:30.915: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:31.211078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:32.211901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:32.921: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:33.211945      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:34.212110      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:34.925: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:35.212844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:36.212924      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:36.930: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:37.213780      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:38.213951      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:38.934: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:39.214646      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:40.215347      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:40.939: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:41.216349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:42.216509      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:42.943: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:43.216611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:44.217510      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:44.948: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:45.218221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:46.218840      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:46.953: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:47.218925      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:48.219887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:48.957: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:49.220009      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:50.220194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:50.962: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:51.220871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:52.221165      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:52.966: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:53.221398      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:54.222377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:54.971: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:55.222473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:56.222843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:56.974: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:57.223295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:40:58.223893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:40:58.979: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:40:59.224594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:00.224698      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:00.984: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:41:01.225476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:02.225638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:02.987: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:41:03.226047      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:04.226207      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:04.992: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:41:05.226639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:06.226755      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:06.997: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:41:07.226778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:08.226860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:09.001: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  E1209 13:41:09.227596      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:10.228591      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:11.006: INFO: Get pod test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 in namespace container-probe-3945
  Dec  9 13:41:11.006: INFO: Restart count of pod container-probe-3945/test-grpc-0f24456c-e788-4739-bfaf-a0632fc4e368 is now 1 (1m4.145857015s elapsed)
  Dec  9 13:41:11.006: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/09/23 13:41:11.011
  STEP: Destroying namespace "container-probe-3945" for this suite. @ 12/09/23 13:41:11.024
• [66.221 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 12/09/23 13:41:11.034
  Dec  9 13:41:11.034: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:41:11.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:11.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:11.056
  STEP: Creating configMap with name configmap-test-volume-map-2eed551b-8d04-4934-88fd-0bef24b6e9b4 @ 12/09/23 13:41:11.059
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:41:11.063
  E1209 13:41:11.229661      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:12.229770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:41:13.079
  Dec  9 13:41:13.083: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-configmaps-b0b42d6e-7921-49b9-b5e3-6836a4940c4c container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:41:13.096
  Dec  9 13:41:13.114: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9872" for this suite. @ 12/09/23 13:41:13.117
• [2.091 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 12/09/23 13:41:13.125
  Dec  9 13:41:13.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:41:13.126
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:13.14
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:13.143
  STEP: Setting up server cert @ 12/09/23 13:41:13.171
  E1209 13:41:13.230252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:41:13.404
  STEP: Deploying the webhook pod @ 12/09/23 13:41:13.412
  STEP: Wait for the deployment to be ready @ 12/09/23 13:41:13.425
  Dec  9 13:41:13.440: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1209 13:41:14.230846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:15.231915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/09/23 13:41:15.453
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:41:15.463
  E1209 13:41:16.232003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:16.464: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/09/23 13:41:16.542
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/09/23 13:41:16.578
  STEP: Deleting the collection of validation webhooks @ 12/09/23 13:41:16.609
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/09/23 13:41:16.661
  Dec  9 13:41:16.672: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1025" for this suite. @ 12/09/23 13:41:16.713
  STEP: Destroying namespace "webhook-markers-1104" for this suite. @ 12/09/23 13:41:16.723
• [3.605 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 12/09/23 13:41:16.731
  Dec  9 13:41:16.731: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:41:16.732
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:16.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:16.749
  STEP: Creating configMap with name projected-configmap-test-volume-map-19cc82b4-b868-477b-aa89-b950ea7fca35 @ 12/09/23 13:41:16.794
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:41:16.799
  E1209 13:41:17.232996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:18.233093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:19.234139      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:20.234239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:41:20.823
  Dec  9 13:41:20.826: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-configmaps-040f47d8-d9f7-43d3-9008-c9f4b8421c1e container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:41:20.834
  Dec  9 13:41:20.852: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9463" for this suite. @ 12/09/23 13:41:20.856
• [4.132 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 12/09/23 13:41:20.864
  Dec  9 13:41:20.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:41:20.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:20.884
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:20.887
  STEP: Creating configMap with name configmap-test-volume-e279fdb6-80bc-4a0a-a5c9-cf0bd24519b7 @ 12/09/23 13:41:20.892
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:41:20.897
  E1209 13:41:21.234997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:22.235913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:23.236379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:24.239888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:41:24.921
  Dec  9 13:41:24.924: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-configmaps-41b48ce5-d181-405a-a044-8f5961694957 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:41:24.933
  Dec  9 13:41:24.948: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1622" for this suite. @ 12/09/23 13:41:24.951
• [4.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 12/09/23 13:41:24.959
  Dec  9 13:41:24.960: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 13:41:24.96
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:24.975
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:24.979
  E1209 13:41:25.240863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:26.241017      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:27.001: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  9 13:41:27.004: INFO: Deleting pod "var-expansion-612aa737-db14-4a19-90be-07a4c5a6bb14" in namespace "var-expansion-6392"
  Dec  9 13:41:27.013: INFO: Wait up to 5m0s for pod "var-expansion-612aa737-db14-4a19-90be-07a4c5a6bb14" to be fully deleted
  E1209 13:41:27.241373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:28.241236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-6392" for this suite. @ 12/09/23 13:41:29.021
• [4.069 seconds]
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 12/09/23 13:41:29.029
  Dec  9 13:41:29.029: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename gc @ 12/09/23 13:41:29.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:29.044
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:29.048
  STEP: create the rc1 @ 12/09/23 13:41:29.056
  STEP: create the rc2 @ 12/09/23 13:41:29.066
  E1209 13:41:29.241301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:30.241583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:31.242900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:32.244145      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:33.244587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:34.253291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 12/09/23 13:41:35.116
  E1209 13:41:35.254123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc simpletest-rc-to-be-deleted @ 12/09/23 13:41:35.877
  STEP: wait for the rc to be deleted @ 12/09/23 13:41:35.889
  E1209 13:41:36.256337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:37.256400      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:38.257039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:39.257187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:40.257261      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:40.902: INFO: 70 pods remaining
  Dec  9 13:41:40.902: INFO: 70 pods has nil DeletionTimestamp
  Dec  9 13:41:40.902: INFO: 
  E1209 13:41:41.257399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:42.257543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:43.257792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:44.257985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:45.259032      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/09/23 13:41:45.899
  W1209 13:41:45.904284      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  9 13:41:45.904: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  9 13:41:45.904: INFO: Deleting pod "simpletest-rc-to-be-deleted-2f62k" in namespace "gc-394"
  Dec  9 13:41:45.920: INFO: Deleting pod "simpletest-rc-to-be-deleted-2fd46" in namespace "gc-394"
  Dec  9 13:41:45.933: INFO: Deleting pod "simpletest-rc-to-be-deleted-2t8db" in namespace "gc-394"
  Dec  9 13:41:45.948: INFO: Deleting pod "simpletest-rc-to-be-deleted-2tzzc" in namespace "gc-394"
  Dec  9 13:41:45.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-4d9zv" in namespace "gc-394"
  Dec  9 13:41:45.978: INFO: Deleting pod "simpletest-rc-to-be-deleted-4k8bv" in namespace "gc-394"
  Dec  9 13:41:45.992: INFO: Deleting pod "simpletest-rc-to-be-deleted-4xc4c" in namespace "gc-394"
  Dec  9 13:41:46.007: INFO: Deleting pod "simpletest-rc-to-be-deleted-5668s" in namespace "gc-394"
  Dec  9 13:41:46.026: INFO: Deleting pod "simpletest-rc-to-be-deleted-5htkn" in namespace "gc-394"
  Dec  9 13:41:46.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-5n9mj" in namespace "gc-394"
  Dec  9 13:41:46.059: INFO: Deleting pod "simpletest-rc-to-be-deleted-5w5d4" in namespace "gc-394"
  Dec  9 13:41:46.077: INFO: Deleting pod "simpletest-rc-to-be-deleted-6bdrj" in namespace "gc-394"
  Dec  9 13:41:46.093: INFO: Deleting pod "simpletest-rc-to-be-deleted-6cskp" in namespace "gc-394"
  Dec  9 13:41:46.107: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hsjw" in namespace "gc-394"
  Dec  9 13:41:46.125: INFO: Deleting pod "simpletest-rc-to-be-deleted-6jztc" in namespace "gc-394"
  Dec  9 13:41:46.143: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mn28" in namespace "gc-394"
  Dec  9 13:41:46.160: INFO: Deleting pod "simpletest-rc-to-be-deleted-6n2lw" in namespace "gc-394"
  Dec  9 13:41:46.173: INFO: Deleting pod "simpletest-rc-to-be-deleted-7fdw9" in namespace "gc-394"
  Dec  9 13:41:46.186: INFO: Deleting pod "simpletest-rc-to-be-deleted-7htjh" in namespace "gc-394"
  Dec  9 13:41:46.197: INFO: Deleting pod "simpletest-rc-to-be-deleted-7n5fm" in namespace "gc-394"
  Dec  9 13:41:46.213: INFO: Deleting pod "simpletest-rc-to-be-deleted-88qtl" in namespace "gc-394"
  Dec  9 13:41:46.226: INFO: Deleting pod "simpletest-rc-to-be-deleted-8hngc" in namespace "gc-394"
  Dec  9 13:41:46.242: INFO: Deleting pod "simpletest-rc-to-be-deleted-8p7q4" in namespace "gc-394"
  Dec  9 13:41:46.257: INFO: Deleting pod "simpletest-rc-to-be-deleted-98zcf" in namespace "gc-394"
  E1209 13:41:46.259531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:46.272: INFO: Deleting pod "simpletest-rc-to-be-deleted-9h8f5" in namespace "gc-394"
  Dec  9 13:41:46.284: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zhbg" in namespace "gc-394"
  Dec  9 13:41:46.294: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zlbh" in namespace "gc-394"
  Dec  9 13:41:46.306: INFO: Deleting pod "simpletest-rc-to-be-deleted-b7lg9" in namespace "gc-394"
  Dec  9 13:41:46.322: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnxfg" in namespace "gc-394"
  Dec  9 13:41:46.334: INFO: Deleting pod "simpletest-rc-to-be-deleted-bspxs" in namespace "gc-394"
  Dec  9 13:41:46.358: INFO: Deleting pod "simpletest-rc-to-be-deleted-bvps8" in namespace "gc-394"
  Dec  9 13:41:46.371: INFO: Deleting pod "simpletest-rc-to-be-deleted-bw5mq" in namespace "gc-394"
  Dec  9 13:41:46.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-c4xk8" in namespace "gc-394"
  Dec  9 13:41:46.405: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8b4c" in namespace "gc-394"
  Dec  9 13:41:46.419: INFO: Deleting pod "simpletest-rc-to-be-deleted-cd6p2" in namespace "gc-394"
  Dec  9 13:41:46.442: INFO: Deleting pod "simpletest-rc-to-be-deleted-cktkv" in namespace "gc-394"
  Dec  9 13:41:46.459: INFO: Deleting pod "simpletest-rc-to-be-deleted-cwq6k" in namespace "gc-394"
  Dec  9 13:41:46.471: INFO: Deleting pod "simpletest-rc-to-be-deleted-d5x5m" in namespace "gc-394"
  Dec  9 13:41:46.490: INFO: Deleting pod "simpletest-rc-to-be-deleted-dkbb6" in namespace "gc-394"
  Dec  9 13:41:46.515: INFO: Deleting pod "simpletest-rc-to-be-deleted-dlj5t" in namespace "gc-394"
  Dec  9 13:41:46.530: INFO: Deleting pod "simpletest-rc-to-be-deleted-dr6xj" in namespace "gc-394"
  Dec  9 13:41:46.543: INFO: Deleting pod "simpletest-rc-to-be-deleted-dstcs" in namespace "gc-394"
  Dec  9 13:41:46.558: INFO: Deleting pod "simpletest-rc-to-be-deleted-f59qg" in namespace "gc-394"
  Dec  9 13:41:46.572: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7j6s" in namespace "gc-394"
  Dec  9 13:41:46.585: INFO: Deleting pod "simpletest-rc-to-be-deleted-f88vm" in namespace "gc-394"
  Dec  9 13:41:46.606: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgzxm" in namespace "gc-394"
  Dec  9 13:41:46.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-fnt9p" in namespace "gc-394"
  Dec  9 13:41:46.637: INFO: Deleting pod "simpletest-rc-to-be-deleted-fxgdp" in namespace "gc-394"
  Dec  9 13:41:46.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-g2w4p" in namespace "gc-394"
  Dec  9 13:41:46.662: INFO: Deleting pod "simpletest-rc-to-be-deleted-gf8md" in namespace "gc-394"
  Dec  9 13:41:46.678: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-394" for this suite. @ 12/09/23 13:41:46.683
• [17.665 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 12/09/23 13:41:46.695
  Dec  9 13:41:46.695: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 13:41:46.696
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:46.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:46.714
  Dec  9 13:41:46.718: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: creating the pod @ 12/09/23 13:41:46.719
  STEP: submitting the pod to kubernetes @ 12/09/23 13:41:46.719
  E1209 13:41:47.260362      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:48.263246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:48.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7884" for this suite. @ 12/09/23 13:41:48.821
• [2.135 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 12/09/23 13:41:48.832
  Dec  9 13:41:48.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:41:48.832
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:48.848
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:48.852
  STEP: Creating secret with name s-test-opt-del-8721f6ab-2dd9-4268-940a-d8b0105fe5e6 @ 12/09/23 13:41:48.862
  STEP: Creating secret with name s-test-opt-upd-4b14abc8-9ae3-41f0-b2e3-44fb3246632e @ 12/09/23 13:41:48.867
  STEP: Creating the pod @ 12/09/23 13:41:48.872
  E1209 13:41:49.263345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:50.263415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-8721f6ab-2dd9-4268-940a-d8b0105fe5e6 @ 12/09/23 13:41:50.94
  STEP: Updating secret s-test-opt-upd-4b14abc8-9ae3-41f0-b2e3-44fb3246632e @ 12/09/23 13:41:50.948
  STEP: Creating secret with name s-test-opt-create-3193bf82-8fc5-42f8-9402-d5ce1b489838 @ 12/09/23 13:41:50.952
  STEP: waiting to observe update in volume @ 12/09/23 13:41:50.958
  E1209 13:41:51.263472      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:52.263571      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:53.264102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:54.264923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:41:55.000: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5934" for this suite. @ 12/09/23 13:41:55.005
• [6.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 12/09/23 13:41:55.015
  Dec  9 13:41:55.015: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename services @ 12/09/23 13:41:55.016
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:41:55.032
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:41:55.035
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-2077 @ 12/09/23 13:41:55.039
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/09/23 13:41:55.054
  STEP: creating service externalsvc in namespace services-2077 @ 12/09/23 13:41:55.054
  STEP: creating replication controller externalsvc in namespace services-2077 @ 12/09/23 13:41:55.07
  I1209 13:41:55.082455      18 runners.go:197] Created replication controller with name: externalsvc, namespace: services-2077, replica count: 2
  E1209 13:41:55.265795      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:56.265961      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:57.266726      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1209 13:41:58.133505      18 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 12/09/23 13:41:58.137
  Dec  9 13:41:58.162: INFO: Creating new exec pod
  E1209 13:41:58.266969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:41:59.267060      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:00.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=services-2077 exec execpodgdxll -- /bin/sh -x -c nslookup nodeport-service.services-2077.svc.cluster.local'
  E1209 13:42:00.267981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:00.345: INFO: stderr: "+ nslookup nodeport-service.services-2077.svc.cluster.local\n"
  Dec  9 13:42:00.345: INFO: stdout: "Server:\t\t10.152.183.120\nAddress:\t10.152.183.120#53\n\nnodeport-service.services-2077.svc.cluster.local\tcanonical name = externalsvc.services-2077.svc.cluster.local.\nName:\texternalsvc.services-2077.svc.cluster.local\nAddress: 10.152.183.223\n\n"
  Dec  9 13:42:00.345: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-2077, will wait for the garbage collector to delete the pods @ 12/09/23 13:42:00.349
  Dec  9 13:42:00.410: INFO: Deleting ReplicationController externalsvc took: 6.154095ms
  Dec  9 13:42:00.511: INFO: Terminating ReplicationController externalsvc pods took: 100.531202ms
  E1209 13:42:01.269018      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:02.269122      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:03.269754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:03.830: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-2077" for this suite. @ 12/09/23 13:42:03.843
• [8.837 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 12/09/23 13:42:03.852
  Dec  9 13:42:03.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename configmap @ 12/09/23 13:42:03.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:42:03.869
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:42:03.873
  STEP: Creating configMap with name configmap-test-volume-map-281fb64c-9ca4-4b18-b26b-a7a8f297e094 @ 12/09/23 13:42:03.876
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:42:03.881
  E1209 13:42:04.269887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:05.269959      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:42:05.897
  Dec  9 13:42:05.901: INFO: Trying to get logs from node ip-172-31-38-129 pod pod-configmaps-7488b820-3394-4d1b-9191-6e87334123d0 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:42:05.907
  Dec  9 13:42:05.921: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9722" for this suite. @ 12/09/23 13:42:05.925
• [2.080 seconds]
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1481
  STEP: Creating a kubernetes client @ 12/09/23 13:42:05.932
  Dec  9 13:42:05.932: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubectl @ 12/09/23 13:42:05.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:42:05.948
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:42:05.952
  STEP: creating Agnhost RC @ 12/09/23 13:42:05.955
  Dec  9 13:42:05.955: INFO: namespace kubectl-1631
  Dec  9 13:42:05.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1631 create -f -'
  Dec  9 13:42:06.118: INFO: stderr: ""
  Dec  9 13:42:06.118: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/09/23 13:42:06.118
  E1209 13:42:06.270964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:07.123: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 13:42:07.123: INFO: Found 0 / 1
  E1209 13:42:07.271518      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:08.124: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 13:42:08.124: INFO: Found 1 / 1
  Dec  9 13:42:08.124: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec  9 13:42:08.128: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  9 13:42:08.128: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  9 13:42:08.128: INFO: wait on agnhost-primary startup in kubectl-1631 
  Dec  9 13:42:08.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1631 logs agnhost-primary-nx8rl agnhost-primary'
  Dec  9 13:42:08.192: INFO: stderr: ""
  Dec  9 13:42:08.192: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 12/09/23 13:42:08.192
  Dec  9 13:42:08.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1631 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Dec  9 13:42:08.264: INFO: stderr: ""
  Dec  9 13:42:08.264: INFO: stdout: "service/rm2 exposed\n"
  Dec  9 13:42:08.267: INFO: Service rm2 in namespace kubectl-1631 found.
  E1209 13:42:08.272302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:09.272407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:10.273153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 12/09/23 13:42:10.276
  Dec  9 13:42:10.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=kubectl-1631 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Dec  9 13:42:10.397: INFO: stderr: ""
  Dec  9 13:42:10.397: INFO: stdout: "service/rm3 exposed\n"
  Dec  9 13:42:10.402: INFO: Service rm3 in namespace kubectl-1631 found.
  E1209 13:42:11.273291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:12.273355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:12.411: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1631" for this suite. @ 12/09/23 13:42:12.415
• [6.491 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 12/09/23 13:42:12.424
  Dec  9 13:42:12.424: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:42:12.424
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:42:12.451
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:42:12.455
  STEP: Creating configMap with name projected-configmap-test-volume-f901dd37-a9d2-4e92-97e3-a3954b54937a @ 12/09/23 13:42:12.458
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:42:12.463
  E1209 13:42:13.273806      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:14.273908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:15.274890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:16.275907      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:42:16.493
  Dec  9 13:42:16.497: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-configmaps-8c600be1-125c-4eb3-b078-ea182f436ea2 container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:42:16.503
  Dec  9 13:42:16.524: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9994" for this suite. @ 12/09/23 13:42:16.528
• [4.114 seconds]
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 12/09/23 13:42:16.538
  Dec  9 13:42:16.538: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename svcaccounts @ 12/09/23 13:42:16.538
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:42:16.556
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:42:16.562
  E1209 13:42:17.276767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:18.277514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: reading a file in the container @ 12/09/23 13:42:18.589
  Dec  9 13:42:18.589: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7630 pod-service-account-a2fe96ed-2298-4e61-b30f-c8a410011c0d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 12/09/23 13:42:18.704
  Dec  9 13:42:18.704: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7630 pod-service-account-a2fe96ed-2298-4e61-b30f-c8a410011c0d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 12/09/23 13:42:18.815
  Dec  9 13:42:18.815: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-7630 pod-service-account-a2fe96ed-2298-4e61-b30f-c8a410011c0d -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Dec  9 13:42:18.928: INFO: Got root ca configmap in namespace "svcaccounts-7630"
  Dec  9 13:42:18.931: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7630" for this suite. @ 12/09/23 13:42:18.935
• [2.405 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 12/09/23 13:42:18.943
  Dec  9 13:42:18.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:42:18.943
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:42:18.962
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:42:18.966
  STEP: Creating the pod @ 12/09/23 13:42:18.97
  E1209 13:42:19.278531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:20.278843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:21.278940      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:21.510: INFO: Successfully updated pod "annotationupdate239328ac-c1d7-49e3-9378-4a91eb71dc41"
  E1209 13:42:22.279920      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:23.280113      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:24.280204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:25.280480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:25.534: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4053" for this suite. @ 12/09/23 13:42:25.538
• [6.604 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 12/09/23 13:42:25.548
  Dec  9 13:42:25.548: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:42:25.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:42:25.566
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:42:25.569
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/09/23 13:42:25.573
  E1209 13:42:26.280833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:27.280901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:28.281425      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:29.281517      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:42:29.595
  Dec  9 13:42:29.599: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-fa01b254-6adf-450e-a553-1bd709cf1e07 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:42:29.606
  Dec  9 13:42:29.622: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-5834" for this suite. @ 12/09/23 13:42:29.626
• [4.086 seconds]
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:750
  STEP: Creating a kubernetes client @ 12/09/23 13:42:29.634
  Dec  9 13:42:29.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 13:42:29.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:42:29.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:42:29.652
  STEP: Creating service test in namespace statefulset-833 @ 12/09/23 13:42:29.655
  STEP: Creating stateful set ss in namespace statefulset-833 @ 12/09/23 13:42:29.661
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-833 @ 12/09/23 13:42:29.668
  Dec  9 13:42:29.673: INFO: Found 0 stateful pods, waiting for 1
  E1209 13:42:30.282554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:31.282653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:32.283840      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:33.284132      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:34.285009      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:35.285331      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:36.285622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:37.285860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:38.286527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:39.286612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:39.678: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 12/09/23 13:42:39.678
  Dec  9 13:42:39.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-833 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 13:42:39.790: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 13:42:39.790: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 13:42:39.790: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 13:42:39.794: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1209 13:42:40.286728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:41.286848      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:42.286936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:43.287086      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:44.287194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:45.287288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:46.287896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:47.288076      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:48.288508      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:42:49.288751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:49.799: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 13:42:49.799: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  9 13:42:49.817: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
  Dec  9 13:42:49.817: INFO: ss-0  ip-172-31-77-176  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:39 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:39 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:29 +0000 UTC  }]
  Dec  9 13:42:49.817: INFO: 
  Dec  9 13:42:49.817: INFO: StatefulSet ss has not reached scale 3, at 1
  E1209 13:42:50.289685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:50.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996418862s
  E1209 13:42:51.290017      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:51.827: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990863918s
  E1209 13:42:52.290925      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:52.831: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987020847s
  E1209 13:42:53.291430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:53.836: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982765942s
  E1209 13:42:54.291908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:54.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977504346s
  E1209 13:42:55.292512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:55.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971346152s
  E1209 13:42:56.292980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:56.853: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966081074s
  E1209 13:42:57.293908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:57.857: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.961040002s
  E1209 13:42:58.294842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:42:58.862: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.700328ms
  E1209 13:42:59.295652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-833 @ 12/09/23 13:42:59.862
  Dec  9 13:42:59.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-833 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 13:42:59.976: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  9 13:42:59.976: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 13:42:59.976: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  9 13:42:59.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-833 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 13:43:00.085: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec  9 13:43:00.085: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 13:43:00.085: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  9 13:43:00.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-833 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  9 13:43:00.201: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec  9 13:43:00.201: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  9 13:43:00.201: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  9 13:43:00.205: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:43:00.205: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:43:00.205: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 12/09/23 13:43:00.205
  Dec  9 13:43:00.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-833 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  E1209 13:43:00.296671      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:00.312: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 13:43:00.312: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 13:43:00.312: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 13:43:00.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-833 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 13:43:00.415: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 13:43:00.415: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 13:43:00.415: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 13:43:00.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3056150943 --namespace=statefulset-833 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  9 13:43:00.524: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  9 13:43:00.524: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  9 13:43:00.524: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  9 13:43:00.524: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  9 13:43:00.527: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E1209 13:43:01.297059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:02.297156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:03.298092      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:04.298196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:05.298290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:06.298401      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:07.299329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:08.299515      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:09.300220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:10.300577      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:10.535: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 13:43:10.535: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 13:43:10.535: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec  9 13:43:10.551: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
  Dec  9 13:43:10.551: INFO: ss-0  ip-172-31-77-176  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:29 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:43:00 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:29 +0000 UTC  }]
  Dec  9 13:43:10.551: INFO: ss-1  ip-172-31-80-205  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:43:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:43:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:49 +0000 UTC  }]
  Dec  9 13:43:10.551: INFO: ss-2  ip-172-31-38-129  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:43:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:43:01 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-09 13:42:49 +0000 UTC  }]
  Dec  9 13:43:10.551: INFO: 
  Dec  9 13:43:10.551: INFO: StatefulSet ss has not reached scale 0, at 3
  E1209 13:43:11.300864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:11.555: INFO: Verifying statefulset ss doesn't scale past 0 for another 8.994297803s
  E1209 13:43:12.301762      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:12.559: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.990572609s
  E1209 13:43:13.302770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:13.564: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.986359744s
  E1209 13:43:14.303816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:14.570: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.981381101s
  E1209 13:43:15.304593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:15.574: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.975595635s
  E1209 13:43:16.304754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:16.579: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.971530524s
  E1209 13:43:17.305064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:17.583: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.967116628s
  E1209 13:43:18.305132      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:18.588: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.963050873s
  E1209 13:43:19.306019      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:19.591: INFO: Verifying statefulset ss doesn't scale past 0 for another 958.296723ms
  E1209 13:43:20.306123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-833 @ 12/09/23 13:43:20.592
  Dec  9 13:43:20.597: INFO: Scaling statefulset ss to 0
  Dec  9 13:43:20.607: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 13:43:20.611: INFO: Deleting all statefulset in ns statefulset-833
  Dec  9 13:43:20.614: INFO: Scaling statefulset ss to 0
  Dec  9 13:43:20.626: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 13:43:20.628: INFO: Deleting statefulset ss
  Dec  9 13:43:20.643: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-833" for this suite. @ 12/09/23 13:43:20.647
• [51.020 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 12/09/23 13:43:20.656
  Dec  9 13:43:20.656: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 13:43:20.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:43:20.678
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:43:20.682
  STEP: creating the pod @ 12/09/23 13:43:20.685
  STEP: submitting the pod to kubernetes @ 12/09/23 13:43:20.685
  STEP: verifying QOS class is set on the pod @ 12/09/23 13:43:20.693
  Dec  9 13:43:20.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7626" for this suite. @ 12/09/23 13:43:20.702
• [0.056 seconds]
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 12/09/23 13:43:20.712
  Dec  9 13:43:20.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/09/23 13:43:20.713
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:43:20.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:43:20.737
  STEP: Creating 50 configmaps @ 12/09/23 13:43:20.741
  STEP: Creating RC which spawns configmap-volume pods @ 12/09/23 13:43:20.984
  Dec  9 13:43:21.068: INFO: Pod name wrapped-volume-race-80a3be92-cb2d-4327-9e37-603f195085f9: Found 3 pods out of 5
  E1209 13:43:21.306742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:22.306845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:23.307093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:24.307183      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:25.307374      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:26.074: INFO: Pod name wrapped-volume-race-80a3be92-cb2d-4327-9e37-603f195085f9: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/09/23 13:43:26.074
  STEP: Creating RC which spawns configmap-volume pods @ 12/09/23 13:43:26.098
  Dec  9 13:43:26.111: INFO: Pod name wrapped-volume-race-d52592f6-6c8d-4b7a-b917-b0c893f54e13: Found 0 pods out of 5
  E1209 13:43:26.307930      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:27.308284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:28.308877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:29.308953      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:30.309147      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:31.119: INFO: Pod name wrapped-volume-race-d52592f6-6c8d-4b7a-b917-b0c893f54e13: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/09/23 13:43:31.119
  STEP: Creating RC which spawns configmap-volume pods @ 12/09/23 13:43:31.141
  Dec  9 13:43:31.154: INFO: Pod name wrapped-volume-race-e1b14f5f-0bb1-4cb3-88b5-53468e8ed41e: Found 0 pods out of 5
  E1209 13:43:31.309997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:32.310387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:33.310837      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:34.310836      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:35.311889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:36.161: INFO: Pod name wrapped-volume-race-e1b14f5f-0bb1-4cb3-88b5-53468e8ed41e: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/09/23 13:43:36.161
  Dec  9 13:43:36.180: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-e1b14f5f-0bb1-4cb3-88b5-53468e8ed41e in namespace emptydir-wrapper-3407, will wait for the garbage collector to delete the pods @ 12/09/23 13:43:36.184
  Dec  9 13:43:36.246: INFO: Deleting ReplicationController wrapped-volume-race-e1b14f5f-0bb1-4cb3-88b5-53468e8ed41e took: 7.598875ms
  E1209 13:43:36.312839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:43:36.347: INFO: Terminating ReplicationController wrapped-volume-race-e1b14f5f-0bb1-4cb3-88b5-53468e8ed41e pods took: 100.875057ms
  E1209 13:43:37.313371      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-d52592f6-6c8d-4b7a-b917-b0c893f54e13 in namespace emptydir-wrapper-3407, will wait for the garbage collector to delete the pods @ 12/09/23 13:43:37.848
  Dec  9 13:43:37.910: INFO: Deleting ReplicationController wrapped-volume-race-d52592f6-6c8d-4b7a-b917-b0c893f54e13 took: 7.946474ms
  Dec  9 13:43:38.011: INFO: Terminating ReplicationController wrapped-volume-race-d52592f6-6c8d-4b7a-b917-b0c893f54e13 pods took: 100.443633ms
  E1209 13:43:38.313944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:39.314480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting ReplicationController wrapped-volume-race-80a3be92-cb2d-4327-9e37-603f195085f9 in namespace emptydir-wrapper-3407, will wait for the garbage collector to delete the pods @ 12/09/23 13:43:39.811
  Dec  9 13:43:39.875: INFO: Deleting ReplicationController wrapped-volume-race-80a3be92-cb2d-4327-9e37-603f195085f9 took: 8.940695ms
  Dec  9 13:43:39.976: INFO: Terminating ReplicationController wrapped-volume-race-80a3be92-cb2d-4327-9e37-603f195085f9 pods took: 100.825707ms
  E1209 13:43:40.315353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:41.316171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Cleaning up the configMaps @ 12/09/23 13:43:41.777
  STEP: Destroying namespace "emptydir-wrapper-3407" for this suite. @ 12/09/23 13:43:42.092
• [21.387 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 12/09/23 13:43:42.101
  Dec  9 13:43:42.101: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename var-expansion @ 12/09/23 13:43:42.102
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:43:42.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:43:42.121
  STEP: Creating a pod to test substitution in container's args @ 12/09/23 13:43:42.127
  E1209 13:43:42.317095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:43.318140      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:44.318997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:45.319079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:43:46.153
  Dec  9 13:43:46.157: INFO: Trying to get logs from node ip-172-31-77-176 pod var-expansion-01c19733-fb7a-4fe6-8090-86af5db62943 container dapi-container: <nil>
  STEP: delete the pod @ 12/09/23 13:43:46.168
  Dec  9 13:43:46.183: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4730" for this suite. @ 12/09/23 13:43:46.186
• [4.093 seconds]
------------------------------
SSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 12/09/23 13:43:46.195
  Dec  9 13:43:46.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename disruption @ 12/09/23 13:43:46.195
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:43:46.212
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:43:46.215
  STEP: Creating a pdb that targets all three pods in a test replica set @ 12/09/23 13:43:46.219
  STEP: Waiting for the pdb to be processed @ 12/09/23 13:43:46.223
  E1209 13:43:46.319395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:47.319496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 12/09/23 13:43:48.237
  STEP: Waiting for all pods to be running @ 12/09/23 13:43:48.237
  Dec  9 13:43:48.240: INFO: pods: 0 < 3
  E1209 13:43:48.319679      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:49.319777      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 12/09/23 13:43:50.245
  STEP: Updating the pdb to allow a pod to be evicted @ 12/09/23 13:43:50.255
  STEP: Waiting for the pdb to be processed @ 12/09/23 13:43:50.265
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/09/23 13:43:50.269
  STEP: Waiting for all pods to be running @ 12/09/23 13:43:50.269
  STEP: Waiting for the pdb to observed all healthy pods @ 12/09/23 13:43:50.273
  STEP: Patching the pdb to disallow a pod to be evicted @ 12/09/23 13:43:50.303
  STEP: Waiting for the pdb to be processed @ 12/09/23 13:43:50.317
  E1209 13:43:50.320349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:51.320575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:52.320660      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 12/09/23 13:43:52.326
  STEP: locating a running pod @ 12/09/23 13:43:52.331
  STEP: Deleting the pdb to allow a pod to be evicted @ 12/09/23 13:43:52.34
  STEP: Waiting for the pdb to be deleted @ 12/09/23 13:43:52.347
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/09/23 13:43:52.35
  STEP: Waiting for all pods to be running @ 12/09/23 13:43:52.35
  Dec  9 13:43:52.371: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3051" for this suite. @ 12/09/23 13:43:52.375
• [6.191 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 12/09/23 13:43:52.386
  Dec  9 13:43:52.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename replicaset @ 12/09/23 13:43:52.387
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:43:52.415
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:43:52.419
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 12/09/23 13:43:52.422
  E1209 13:43:53.320817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:54.321135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 12/09/23 13:43:54.445
  STEP: Then the orphan pod is adopted @ 12/09/23 13:43:54.452
  E1209 13:43:55.321220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 12/09/23 13:43:55.459
  Dec  9 13:43:55.464: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/09/23 13:43:55.475
  Dec  9 13:43:55.484: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4732" for this suite. @ 12/09/23 13:43:55.491
• [3.121 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 12/09/23 13:43:55.508
  Dec  9 13:43:55.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename emptydir @ 12/09/23 13:43:55.508
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:43:55.528
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:43:55.533
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/09/23 13:43:55.536
  E1209 13:43:56.321318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:57.321499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:58.321750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:43:59.321860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:43:59.56
  Dec  9 13:43:59.563: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-d448cb65-62ca-4f82-b9fc-0571103d6ba3 container test-container: <nil>
  STEP: delete the pod @ 12/09/23 13:43:59.57
  Dec  9 13:43:59.588: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8961" for this suite. @ 12/09/23 13:43:59.593
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 12/09/23 13:43:59.602
  Dec  9 13:43:59.602: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename sched-pred @ 12/09/23 13:43:59.603
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:43:59.619
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:43:59.622
  Dec  9 13:43:59.626: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  9 13:43:59.633: INFO: Waiting for terminating namespaces to be deleted...
  Dec  9 13:43:59.637: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-38-129 before test
  Dec  9 13:43:59.642: INFO: nginx-ingress-controller-kubernetes-worker-j9sl2 from ingress-nginx-kubernetes-worker started at 2023-12-09 12:04:10 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.642: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 13:43:59.642: INFO: calico-node-j8mjn from kube-system started at 2023-12-09 12:03:58 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.642: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 13:43:59.642: INFO: sonobuoy-e2e-job-f705b9d168e44085 from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:43:59.642: INFO: 	Container e2e ready: true, restart count 0
  Dec  9 13:43:59.642: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:43:59.642: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-k7blf from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:43:59.642: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:43:59.642: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 13:43:59.642: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-77-176 before test
  Dec  9 13:43:59.649: INFO: nginx-ingress-controller-kubernetes-worker-tdr5k from ingress-nginx-kubernetes-worker started at 2023-12-09 13:24:10 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.649: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 13:43:59.649: INFO: calico-node-rzjq2 from kube-system started at 2023-12-09 11:58:38 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.649: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 13:43:59.650: INFO: pod-adoption-release from replicaset-4732 started at 2023-12-09 13:43:52 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.650: INFO: 	Container pod-adoption-release ready: true, restart count 0
  Dec  9 13:43:59.650: INFO: pod-adoption-release-jx45k from replicaset-4732 started at 2023-12-09 13:43:55 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.650: INFO: 	Container pod-adoption-release ready: false, restart count 0
  Dec  9 13:43:59.650: INFO: sonobuoy from sonobuoy started at 2023-12-09 12:07:20 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.650: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  9 13:43:59.650: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-29sdb from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:43:59.650: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:43:59.650: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  9 13:43:59.650: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-80-205 before test
  Dec  9 13:43:59.655: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-nm9vp from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: nginx-ingress-controller-kubernetes-worker-crj2p from ingress-nginx-kubernetes-worker started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: calico-node-f2fvk from kube-system started at 2023-12-09 11:58:36 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container calico-node ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: coredns-59cfb5bf46-t9rkp from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container coredns ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: kube-state-metrics-78c475f58b-km8l9 from kube-system started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: metrics-server-v0.6.3-69d7fbfdf8-hlh9f from kube-system started at 2023-12-09 11:58:49 +0000 UTC (2 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: dashboard-metrics-scraper-5dd7cb5fc-jlz46 from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: kubernetes-dashboard-7b899cb9d9-68n2j from kubernetes-dashboard started at 2023-12-09 11:58:49 +0000 UTC (1 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: sonobuoy-systemd-logs-daemon-set-3145c2bd17ee4f62-w5xwq from sonobuoy started at 2023-12-09 12:07:22 +0000 UTC (2 container statuses recorded)
  Dec  9 13:43:59.655: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  9 13:43:59.655: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/09/23 13:43:59.655
  E1209 13:44:00.321928      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:01.322124      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/09/23 13:44:01.678
  STEP: Trying to apply a random label on the found node. @ 12/09/23 13:44:01.69
  STEP: verifying the node has the label kubernetes.io/e2e-1eea715e-6f30-49db-a207-dff7f636ae73 42 @ 12/09/23 13:44:01.7
  STEP: Trying to relaunch the pod, now with labels. @ 12/09/23 13:44:01.706
  E1209 13:44:02.322287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:03.322564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-1eea715e-6f30-49db-a207-dff7f636ae73 off the node ip-172-31-38-129 @ 12/09/23 13:44:03.726
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-1eea715e-6f30-49db-a207-dff7f636ae73 @ 12/09/23 13:44:03.737
  Dec  9 13:44:03.745: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-3525" for this suite. @ 12/09/23 13:44:03.749
• [4.154 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 12/09/23 13:44:03.757
  Dec  9 13:44:03.757: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename events @ 12/09/23 13:44:03.758
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:44:03.778
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:44:03.781
  STEP: creating a test event @ 12/09/23 13:44:03.785
  STEP: listing all events in all namespaces @ 12/09/23 13:44:03.79
  STEP: patching the test event @ 12/09/23 13:44:03.794
  STEP: fetching the test event @ 12/09/23 13:44:03.801
  STEP: updating the test event @ 12/09/23 13:44:03.804
  STEP: getting the test event @ 12/09/23 13:44:03.815
  STEP: deleting the test event @ 12/09/23 13:44:03.819
  STEP: listing all events in all namespaces @ 12/09/23 13:44:03.827
  Dec  9 13:44:03.830: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-2839" for this suite. @ 12/09/23 13:44:03.834
• [0.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 12/09/23 13:44:03.844
  Dec  9 13:44:03.844: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename resourcequota @ 12/09/23 13:44:03.845
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:44:03.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:44:03.863
  STEP: Creating a ResourceQuota with terminating scope @ 12/09/23 13:44:03.867
  STEP: Ensuring ResourceQuota status is calculated @ 12/09/23 13:44:03.873
  E1209 13:44:04.323438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:05.324459      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 12/09/23 13:44:05.877
  STEP: Ensuring ResourceQuota status is calculated @ 12/09/23 13:44:05.883
  E1209 13:44:06.324542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:07.324639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 12/09/23 13:44:07.887
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 12/09/23 13:44:07.899
  E1209 13:44:08.325260      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:09.325516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 12/09/23 13:44:09.904
  E1209 13:44:10.326557      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:11.327078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/09/23 13:44:11.908
  STEP: Ensuring resource quota status released the pod usage @ 12/09/23 13:44:11.923
  E1209 13:44:12.327771      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:13.328259      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 12/09/23 13:44:13.927
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 12/09/23 13:44:13.938
  E1209 13:44:14.328826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:15.328929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 12/09/23 13:44:15.942
  E1209 13:44:16.329419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:17.329493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/09/23 13:44:17.946
  STEP: Ensuring resource quota status released the pod usage @ 12/09/23 13:44:17.964
  E1209 13:44:18.329932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:19.330025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:19.969: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-606" for this suite. @ 12/09/23 13:44:19.973
• [16.137 seconds]
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 12/09/23 13:44:19.981
  Dec  9 13:44:19.981: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename field-validation @ 12/09/23 13:44:19.982
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:44:19.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:44:20
  Dec  9 13:44:20.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  W1209 13:44:20.004548      18 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0013d0a80 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E1209 13:44:20.330576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:21.331171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:22.331285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1209 13:44:22.550923      18 warnings.go:70] unknown field "alpha"
  W1209 13:44:22.550942      18 warnings.go:70] unknown field "beta"
  W1209 13:44:22.550946      18 warnings.go:70] unknown field "delta"
  W1209 13:44:22.550950      18 warnings.go:70] unknown field "epsilon"
  W1209 13:44:22.550954      18 warnings.go:70] unknown field "gamma"
  Dec  9 13:44:23.081: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9242" for this suite. @ 12/09/23 13:44:23.098
• [3.123 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 12/09/23 13:44:23.105
  Dec  9 13:44:23.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename watch @ 12/09/23 13:44:23.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:44:23.118
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:44:23.123
  STEP: getting a starting resourceVersion @ 12/09/23 13:44:23.127
  STEP: starting a background goroutine to produce watch events @ 12/09/23 13:44:23.129
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 12/09/23 13:44:23.129
  E1209 13:44:23.331387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:24.331670      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:25.332550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:25.910: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-2130" for this suite. @ 12/09/23 13:44:25.961
• [2.909 seconds]
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 12/09/23 13:44:26.014
  Dec  9 13:44:26.014: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename gc @ 12/09/23 13:44:26.014
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:44:26.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:44:26.03
  STEP: create the rc @ 12/09/23 13:44:26.037
  W1209 13:44:26.041790      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1209 13:44:26.333042      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:27.334430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:28.337176      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:29.338236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/09/23 13:44:30.048
  STEP: wait for the rc to be deleted @ 12/09/23 13:44:30.063
  E1209 13:44:30.338391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:31.099: INFO: 80 pods remaining
  Dec  9 13:44:31.099: INFO: 80 pods has nil DeletionTimestamp
  Dec  9 13:44:31.099: INFO: 
  E1209 13:44:31.338982      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:32.100: INFO: 70 pods remaining
  Dec  9 13:44:32.100: INFO: 70 pods has nil DeletionTimestamp
  Dec  9 13:44:32.100: INFO: 
  E1209 13:44:32.341623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:33.075: INFO: 60 pods remaining
  Dec  9 13:44:33.075: INFO: 60 pods has nil DeletionTimestamp
  Dec  9 13:44:33.075: INFO: 
  E1209 13:44:33.342467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:34.075: INFO: 40 pods remaining
  Dec  9 13:44:34.075: INFO: 40 pods has nil DeletionTimestamp
  Dec  9 13:44:34.075: INFO: 
  E1209 13:44:34.342988      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:35.088: INFO: 30 pods remaining
  Dec  9 13:44:35.088: INFO: 30 pods has nil DeletionTimestamp
  Dec  9 13:44:35.088: INFO: 
  E1209 13:44:35.343822      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:44:36.076: INFO: 20 pods remaining
  Dec  9 13:44:36.076: INFO: 20 pods has nil DeletionTimestamp
  Dec  9 13:44:36.076: INFO: 
  E1209 13:44:36.346050      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/09/23 13:44:37.076
  W1209 13:44:37.081537      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  9 13:44:37.081: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  9 13:44:37.082: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-8264" for this suite. @ 12/09/23 13:44:37.086
• [11.078 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 12/09/23 13:44:37.093
  Dec  9 13:44:37.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename projected @ 12/09/23 13:44:37.094
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:44:37.11
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:44:37.114
  STEP: Creating configMap with name projected-configmap-test-volume-map-6e9976f6-9a7d-4703-a7cc-e6d48bf4b998 @ 12/09/23 13:44:37.118
  STEP: Creating a pod to test consume configMaps @ 12/09/23 13:44:37.124
  E1209 13:44:37.347842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:38.348581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:39.349212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:40.349307      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:44:41.146
  Dec  9 13:44:41.150: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-projected-configmaps-7118de01-74ed-4941-98e4-044c5026efef container agnhost-container: <nil>
  STEP: delete the pod @ 12/09/23 13:44:41.157
  Dec  9 13:44:41.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-4034" for this suite. @ 12/09/23 13:44:41.176
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 12/09/23 13:44:41.184
  Dec  9 13:44:41.184: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename subpath @ 12/09/23 13:44:41.185
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:44:41.204
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:44:41.21
  STEP: Setting up data @ 12/09/23 13:44:41.214
  STEP: Creating pod pod-subpath-test-configmap-q9b2 @ 12/09/23 13:44:41.225
  STEP: Creating a pod to test atomic-volume-subpath @ 12/09/23 13:44:41.225
  E1209 13:44:41.349802      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:42.350107      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:43.350790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:44.350880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:45.351096      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:46.351187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:47.351748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:48.352573      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:49.352899      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:50.353003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:51.353724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:52.353835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:53.354069      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:54.354160      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:55.354324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:56.354391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:57.355359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:58.355592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:44:59.355917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:00.356016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:01.356627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:02.356633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:03.357145      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:04.357415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/09/23 13:45:05.301
  Dec  9 13:45:05.304: INFO: Trying to get logs from node ip-172-31-77-176 pod pod-subpath-test-configmap-q9b2 container test-container-subpath-configmap-q9b2: <nil>
  STEP: delete the pod @ 12/09/23 13:45:05.312
  STEP: Deleting pod pod-subpath-test-configmap-q9b2 @ 12/09/23 13:45:05.33
  Dec  9 13:45:05.330: INFO: Deleting pod "pod-subpath-test-configmap-q9b2" in namespace "subpath-1111"
  Dec  9 13:45:05.334: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-1111" for this suite. @ 12/09/23 13:45:05.338
• [24.162 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 12/09/23 13:45:05.347
  Dec  9 13:45:05.347: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubelet-test @ 12/09/23 13:45:05.347
  E1209 13:45:05.357704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:45:05.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:45:05.369
  E1209 13:45:06.358492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:07.358590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:08.359671      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:09.359731      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:45:09.409: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-4034" for this suite. @ 12/09/23 13:45:09.413
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 12/09/23 13:45:09.423
  Dec  9 13:45:09.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename webhook @ 12/09/23 13:45:09.423
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:45:09.446
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:45:09.45
  STEP: Setting up server cert @ 12/09/23 13:45:09.481
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/09/23 13:45:09.836
  STEP: Deploying the webhook pod @ 12/09/23 13:45:09.844
  STEP: Wait for the deployment to be ready @ 12/09/23 13:45:09.861
  Dec  9 13:45:09.872: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1209 13:45:10.359895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:11.360067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/09/23 13:45:11.883
  STEP: Verifying the service has paired with the endpoint @ 12/09/23 13:45:11.895
  E1209 13:45:12.360163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:45:12.896: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/09/23 13:45:12.964
  STEP: Creating a configMap that should be mutated @ 12/09/23 13:45:12.975
  STEP: Deleting the collection of validation webhooks @ 12/09/23 13:45:13
  STEP: Creating a configMap that should not be mutated @ 12/09/23 13:45:13.06
  Dec  9 13:45:13.072: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3343" for this suite. @ 12/09/23 13:45:13.121
  STEP: Destroying namespace "webhook-markers-9896" for this suite. @ 12/09/23 13:45:13.128
• [3.714 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:125
  STEP: Creating a kubernetes client @ 12/09/23 13:45:13.142
  Dec  9 13:45:13.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename discovery @ 12/09/23 13:45:13.143
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:45:13.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:45:13.162
  STEP: Setting up server cert @ 12/09/23 13:45:13.167
  E1209 13:45:13.360576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:45:13.442: INFO: Checking APIGroup: apiregistration.k8s.io
  Dec  9 13:45:13.443: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Dec  9 13:45:13.443: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Dec  9 13:45:13.443: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Dec  9 13:45:13.443: INFO: Checking APIGroup: apps
  Dec  9 13:45:13.445: INFO: PreferredVersion.GroupVersion: apps/v1
  Dec  9 13:45:13.445: INFO: Versions found [{apps/v1 v1}]
  Dec  9 13:45:13.445: INFO: apps/v1 matches apps/v1
  Dec  9 13:45:13.445: INFO: Checking APIGroup: events.k8s.io
  Dec  9 13:45:13.446: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Dec  9 13:45:13.446: INFO: Versions found [{events.k8s.io/v1 v1}]
  Dec  9 13:45:13.446: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Dec  9 13:45:13.446: INFO: Checking APIGroup: authentication.k8s.io
  Dec  9 13:45:13.448: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Dec  9 13:45:13.448: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Dec  9 13:45:13.448: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Dec  9 13:45:13.448: INFO: Checking APIGroup: authorization.k8s.io
  Dec  9 13:45:13.449: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Dec  9 13:45:13.449: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Dec  9 13:45:13.449: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Dec  9 13:45:13.449: INFO: Checking APIGroup: autoscaling
  Dec  9 13:45:13.451: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Dec  9 13:45:13.451: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Dec  9 13:45:13.451: INFO: autoscaling/v2 matches autoscaling/v2
  Dec  9 13:45:13.451: INFO: Checking APIGroup: batch
  Dec  9 13:45:13.452: INFO: PreferredVersion.GroupVersion: batch/v1
  Dec  9 13:45:13.452: INFO: Versions found [{batch/v1 v1}]
  Dec  9 13:45:13.452: INFO: batch/v1 matches batch/v1
  Dec  9 13:45:13.452: INFO: Checking APIGroup: certificates.k8s.io
  Dec  9 13:45:13.453: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Dec  9 13:45:13.453: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Dec  9 13:45:13.453: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Dec  9 13:45:13.453: INFO: Checking APIGroup: networking.k8s.io
  Dec  9 13:45:13.455: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Dec  9 13:45:13.455: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Dec  9 13:45:13.455: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Dec  9 13:45:13.455: INFO: Checking APIGroup: policy
  Dec  9 13:45:13.456: INFO: PreferredVersion.GroupVersion: policy/v1
  Dec  9 13:45:13.456: INFO: Versions found [{policy/v1 v1}]
  Dec  9 13:45:13.456: INFO: policy/v1 matches policy/v1
  Dec  9 13:45:13.456: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Dec  9 13:45:13.458: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Dec  9 13:45:13.458: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Dec  9 13:45:13.458: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Dec  9 13:45:13.458: INFO: Checking APIGroup: storage.k8s.io
  Dec  9 13:45:13.459: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Dec  9 13:45:13.459: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Dec  9 13:45:13.459: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Dec  9 13:45:13.459: INFO: Checking APIGroup: admissionregistration.k8s.io
  Dec  9 13:45:13.460: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Dec  9 13:45:13.460: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Dec  9 13:45:13.460: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Dec  9 13:45:13.460: INFO: Checking APIGroup: apiextensions.k8s.io
  Dec  9 13:45:13.462: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Dec  9 13:45:13.462: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Dec  9 13:45:13.462: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Dec  9 13:45:13.462: INFO: Checking APIGroup: scheduling.k8s.io
  Dec  9 13:45:13.463: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Dec  9 13:45:13.463: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Dec  9 13:45:13.463: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Dec  9 13:45:13.463: INFO: Checking APIGroup: coordination.k8s.io
  Dec  9 13:45:13.464: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Dec  9 13:45:13.465: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Dec  9 13:45:13.465: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Dec  9 13:45:13.465: INFO: Checking APIGroup: node.k8s.io
  Dec  9 13:45:13.466: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Dec  9 13:45:13.466: INFO: Versions found [{node.k8s.io/v1 v1}]
  Dec  9 13:45:13.466: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Dec  9 13:45:13.466: INFO: Checking APIGroup: discovery.k8s.io
  Dec  9 13:45:13.467: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Dec  9 13:45:13.467: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Dec  9 13:45:13.467: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Dec  9 13:45:13.467: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Dec  9 13:45:13.469: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Dec  9 13:45:13.469: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Dec  9 13:45:13.469: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Dec  9 13:45:13.469: INFO: Checking APIGroup: metrics.k8s.io
  Dec  9 13:45:13.470: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Dec  9 13:45:13.470: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Dec  9 13:45:13.470: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Dec  9 13:45:13.470: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-1414" for this suite. @ 12/09/23 13:45:13.474
• [0.340 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 12/09/23 13:45:13.482
  Dec  9 13:45:13.482: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename pods @ 12/09/23 13:45:13.483
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:45:13.498
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:45:13.501
  STEP: Create a pod @ 12/09/23 13:45:13.505
  E1209 13:45:14.361477      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:15.362539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 12/09/23 13:45:15.528
  Dec  9 13:45:15.545: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Dec  9 13:45:15.545: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6111" for this suite. @ 12/09/23 13:45:15.549
• [2.076 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:331
  STEP: Creating a kubernetes client @ 12/09/23 13:45:15.56
  Dec  9 13:45:15.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename statefulset @ 12/09/23 13:45:15.561
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:45:15.577
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:45:15.582
  STEP: Creating service test in namespace statefulset-1539 @ 12/09/23 13:45:15.586
  STEP: Creating a new StatefulSet @ 12/09/23 13:45:15.591
  Dec  9 13:45:15.603: INFO: Found 0 stateful pods, waiting for 3
  E1209 13:45:16.362900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:17.363911      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:18.364575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:19.364686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:20.364777      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:21.364846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:22.364938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:23.365173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:24.365331      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:25.365878      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:45:25.608: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:45:25.608: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:45:25.608: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/09/23 13:45:25.619
  Dec  9 13:45:25.639: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/09/23 13:45:25.639
  E1209 13:45:26.366035      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:27.366121      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:28.366511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:29.366607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:30.366861      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:31.366937      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:32.367045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:33.367131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:34.367896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:35.367969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 12/09/23 13:45:35.658
  STEP: Performing a canary update @ 12/09/23 13:45:35.658
  Dec  9 13:45:35.679: INFO: Updating stateful set ss2
  Dec  9 13:45:35.690: INFO: Waiting for Pod statefulset-1539/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1209 13:45:36.368157      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:37.368341      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:38.368664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:39.368779      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:40.368939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:41.369058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:42.369236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:43.370270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:44.370471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:45.370626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 12/09/23 13:45:45.698
  Dec  9 13:45:45.746: INFO: Found 2 stateful pods, waiting for 3
  E1209 13:45:46.371348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:47.371449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:48.371527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:49.371627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:50.371724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:51.371945      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:52.372116      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:53.373206      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:54.373279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:55.374272      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:45:55.750: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:45:55.750: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  9 13:45:55.750: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 12/09/23 13:45:55.758
  Dec  9 13:45:55.778: INFO: Updating stateful set ss2
  Dec  9 13:45:55.787: INFO: Waiting for Pod statefulset-1539/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1209 13:45:56.374492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:57.374575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:58.374887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:45:59.374977      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:00.375900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:01.376041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:02.376270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:03.377137      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:04.377236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:05.377407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:46:05.815: INFO: Updating stateful set ss2
  Dec  9 13:46:05.824: INFO: Waiting for StatefulSet statefulset-1539/ss2 to complete update
  Dec  9 13:46:05.824: INFO: Waiting for Pod statefulset-1539/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1209 13:46:06.377833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:07.378471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:08.378683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:09.378828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:10.378917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:11.379890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:12.380069      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:13.380122      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:14.380794      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:15.380958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:46:15.832: INFO: Deleting all statefulset in ns statefulset-1539
  Dec  9 13:46:15.836: INFO: Scaling statefulset ss2 to 0
  E1209 13:46:16.381993      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:17.383006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:18.383890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:19.383987      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:20.384156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:21.384254      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:22.384458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:23.384824      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:24.384913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:25.385064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:46:25.861: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  9 13:46:25.865: INFO: Deleting statefulset ss2
  Dec  9 13:46:25.879: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1539" for this suite. @ 12/09/23 13:46:25.885
• [70.333 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 12/09/23 13:46:25.893
  Dec  9 13:46:25.893: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename kubelet-test @ 12/09/23 13:46:25.894
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:46:25.908
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:46:25.912
  E1209 13:46:26.385933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1209 13:46:27.386677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  9 13:46:27.949: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-9437" for this suite. @ 12/09/23 13:46:27.953
• [2.068 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 12/09/23 13:46:27.961
  Dec  9 13:46:27.961: INFO: >>> kubeConfig: /tmp/kubeconfig-3056150943
  STEP: Building a namespace api object, basename namespaces @ 12/09/23 13:46:27.962
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/09/23 13:46:27.984
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/09/23 13:46:27.99
  STEP: Creating namespace "e2e-ns-2wkhs" @ 12/09/23 13:46:27.993
  Dec  9 13:46:28.006: INFO: Namespace "e2e-ns-2wkhs-3092" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-2wkhs-3092" @ 12/09/23 13:46:28.006
  Dec  9 13:46:28.017: INFO: Namespace "e2e-ns-2wkhs-3092" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-2wkhs-3092" @ 12/09/23 13:46:28.017
  Dec  9 13:46:28.026: INFO: Namespace "e2e-ns-2wkhs-3092" has []v1.FinalizerName{"kubernetes"}
  Dec  9 13:46:28.026: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3252" for this suite. @ 12/09/23 13:46:28.03
  STEP: Destroying namespace "e2e-ns-2wkhs-3092" for this suite. @ 12/09/23 13:46:28.038
• [0.082 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Dec  9 13:46:28.045: INFO: Running AfterSuite actions on node 1
  Dec  9 13:46:28.045: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:157
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:585
[ReportAfterSuite] PASSED [0.033 seconds]
------------------------------

Ran 380 of 7389 Specs in 5934.624 seconds
SUCCESS! -- 380 Passed | 0 Failed | 0 Pending | 7009 Skipped
PASS

Ginkgo ran 1 suite in 1h38m54.901640832s
Test Suite Passed
