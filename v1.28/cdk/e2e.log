  I1202 12:07:55.393256      18 e2e.go:117] Starting e2e run "68aca84b-8ec8-41fd-9bbb-f6cca6ab0a52" on Ginkgo node 1
  Dec  2 12:07:55.415: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1701518875 - will randomize all specs

Will run 380 of 7389 specs
------------------------------
[ReportBeforeSuite] 
test/e2e/e2e_test.go:153
[ReportBeforeSuite] PASSED [0.000 seconds]
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:77
  Dec  2 12:07:55.558: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:07:55.559: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
  Dec  2 12:07:55.591: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
  Dec  2 12:07:55.595: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
  Dec  2 12:07:55.595: INFO: e2e test version: v1.28.4
  Dec  2 12:07:55.596: INFO: kube-apiserver version: v1.28.4
  Dec  2 12:07:55.596: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:07:55.601: INFO: Cluster IP family: ipv4
[SynchronizedBeforeSuite] PASSED [0.043 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:109
  STEP: Creating a kubernetes client @ 12/02/23 12:07:55.971
  Dec  2 12:07:55.971: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:07:55.971
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:07:55.988
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:07:55.991
  STEP: Creating configMap with name configmap-test-volume-map-e2a68559-5db1-47f7-a76c-714f9ce1bc94 @ 12/02/23 12:07:55.993
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:07:56.003
  STEP: Saw pod success @ 12/02/23 12:08:06.042
  Dec  2 12:08:06.046: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-1100c919-eba9-4420-bd65-15fb6f9ada65 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:08:06.063
  Dec  2 12:08:06.079: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-9424" for this suite. @ 12/02/23 12:08:06.082
• [10.117 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]
test/e2e/auth/service_accounts.go:78
  STEP: Creating a kubernetes client @ 12/02/23 12:08:06.088
  Dec  2 12:08:06.088: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svcaccounts @ 12/02/23 12:08:06.089
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:08:06.108
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:08:06.11
  STEP: reading a file in the container @ 12/02/23 12:08:08.137
  Dec  2 12:08:08.137: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5091 pod-service-account-2306fc24-d329-468f-a4d7-878dae2a7f2f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
  STEP: reading a file in the container @ 12/02/23 12:08:08.252
  Dec  2 12:08:08.252: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5091 pod-service-account-2306fc24-d329-468f-a4d7-878dae2a7f2f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
  STEP: reading a file in the container @ 12/02/23 12:08:08.373
  Dec  2 12:08:08.373: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5091 pod-service-account-2306fc24-d329-468f-a4d7-878dae2a7f2f -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
  Dec  2 12:08:08.495: INFO: Got root ca configmap in namespace "svcaccounts-5091"
  Dec  2 12:08:08.497: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-5091" for this suite. @ 12/02/23 12:08:08.5
• [2.417 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]
test/e2e/apps/daemon_set.go:205
  STEP: Creating a kubernetes client @ 12/02/23 12:08:08.506
  Dec  2 12:08:08.506: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename daemonsets @ 12/02/23 12:08:08.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:08:08.52
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:08:08.525
  Dec  2 12:08:08.547: INFO: Creating daemon "daemon-set" with a node selector
  STEP: Initially, daemon pods should not be running on any nodes. @ 12/02/23 12:08:08.553
  Dec  2 12:08:08.557: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:08.557: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Change node label to blue, check that daemon pod is launched. @ 12/02/23 12:08:08.558
  Dec  2 12:08:08.578: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:08.578: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  Dec  2 12:08:09.581: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:09.581: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  Dec  2 12:08:10.581: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:10.581: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  Dec  2 12:08:11.582: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:11.582: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  Dec  2 12:08:12.582: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  2 12:08:12.582: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Update the node label to green, and wait for daemons to be unscheduled @ 12/02/23 12:08:12.587
  Dec  2 12:08:12.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  2 12:08:12.604: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
  Dec  2 12:08:13.608: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:13.608: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate @ 12/02/23 12:08:13.608
  Dec  2 12:08:13.620: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:13.620: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  Dec  2 12:08:14.625: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:14.625: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  Dec  2 12:08:15.625: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:15.625: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  Dec  2 12:08:16.626: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  2 12:08:16.626: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/02/23 12:08:16.632
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-260, will wait for the garbage collector to delete the pods @ 12/02/23 12:08:16.632
  Dec  2 12:08:16.694: INFO: Deleting DaemonSet.extensions daemon-set took: 7.509256ms
  Dec  2 12:08:16.794: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.135839ms
  Dec  2 12:08:18.099: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:08:18.099: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  2 12:08:18.104: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"2472"},"items":null}

  Dec  2 12:08:18.108: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"2472"},"items":null}

  Dec  2 12:08:18.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-260" for this suite. @ 12/02/23 12:08:18.135
• [9.637 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support rollover [Conformance]
test/e2e/apps/deployment.go:132
  STEP: Creating a kubernetes client @ 12/02/23 12:08:18.144
  Dec  2 12:08:18.144: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 12:08:18.144
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:08:18.158
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:08:18.161
  Dec  2 12:08:18.171: INFO: Pod name rollover-pod: Found 0 pods out of 1
  Dec  2 12:08:23.176: INFO: Pod name rollover-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/02/23 12:08:23.176
  Dec  2 12:08:23.176: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
  Dec  2 12:08:25.181: INFO: Creating deployment "test-rollover-deployment"
  Dec  2 12:08:25.189: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
  Dec  2 12:08:27.198: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
  Dec  2 12:08:27.205: INFO: Ensure that both replica sets have 1 created replica
  Dec  2 12:08:27.213: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
  Dec  2 12:08:27.226: INFO: Updating deployment test-rollover-deployment
  Dec  2 12:08:27.226: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
  Dec  2 12:08:29.235: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
  Dec  2 12:08:29.244: INFO: Make sure deployment "test-rollover-deployment" is complete
  Dec  2 12:08:29.251: INFO: all replica sets need to contain the pod-template-hash label
  Dec  2 12:08:29.251: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 27, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  2 12:08:31.259: INFO: all replica sets need to contain the pod-template-hash label
  Dec  2 12:08:31.259: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  2 12:08:33.260: INFO: all replica sets need to contain the pod-template-hash label
  Dec  2 12:08:33.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  2 12:08:35.258: INFO: all replica sets need to contain the pod-template-hash label
  Dec  2 12:08:35.258: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  2 12:08:37.261: INFO: all replica sets need to contain the pod-template-hash label
  Dec  2 12:08:37.261: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  2 12:08:39.257: INFO: all replica sets need to contain the pod-template-hash label
  Dec  2 12:08:39.258: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 31, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  2 12:08:41.258: INFO: 
  Dec  2 12:08:41.258: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 8, 41, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 8, 25, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-5d484bf7f9\" is progressing."}}, CollisionCount:(*int32)(nil)}
  Dec  2 12:08:43.259: INFO: 
  Dec  2 12:08:43.259: INFO: Ensure that both old replica sets have no replicas
  Dec  2 12:08:43.271: INFO: Deployment "test-rollover-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2530",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8204da97-0e22-4b04-964e-7e0d1a2e36b1",
      ResourceVersion: (string) (len=4) "2630",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837115705,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115707,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=660) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000040  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000050  2c 22 66 3a 70 72 6f 67  72 65 73 73 44 65 61 64  |,"f:progressDead|
              00000060  6c 69 6e 65 53 65 63 6f  6e 64 73 22 3a 7b 7d 2c  |lineSeconds":{},|
              00000070  22 66 3a 72 65 70 6c 69  63 61 73 22 3a 7b 7d 2c  |"f:replicas":{},|
              00000080  22 66 3a 72 65 76 69 73  69 6f 6e 48 69 73 74 6f  |"f:revisionHisto|
              00000090  72 79 4c 69 6d 69 74 22  3a 7b 7d 2c 22 66 3a 73  |ryLimit":{},"f:s|
              000000a0  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 73  |elector":{},"f:s|
              000000b0  74 72 61 74 65 67 79 22  3a 7b 22 66 3a 72 6f 6c  |trategy":{"f:rol|
              000000c0  6c 69 6e 67 55 70 64 61  74 65 22 3a 7b 22 2e 22  |lingUpdate":{"."|
              000000d0  3a 7b 7d 2c 22 66 3a 6d  61 78 53 75 72 67 65 22  |:{},"f:maxSurge"|
              000000e0  3a 7b 7d 2c 22 66 3a 6d  61 78 55 6e 61 76 61 69  |:{},"f:maxUnavai|
              000000f0  6c 61 62 6c 65 22 3a 7b  7d 7d 2c 22 66 3a 74 79  |lable":{}},"f:ty|
              00000100  70 65 22 3a 7b 7d 7d 2c  22 66 3a 74 65 6d 70 6c  |pe":{}},"f:templ|
              00000110  61 74 65 22 3a 7b 22 66  3a 6d 65 74 61 64 61 74  |ate":{"f:metadat|
              00000120  61 22 3a 7b 22 66 3a 6c  61 62 65 6c 73 22 3a 7b  |a":{"f:labels":{|
              00000130  22 2e 22 3a 7b 7d 2c 22  66 3a 6e 61 6d 65 22 3a  |".":{},"f:name":|
              00000140  7b 7d 7d 7d 2c 22 66 3a  73 70 65 63 22 3a 7b 22  |{}}},"f:spec":{"|
              00000150  66 3a 63 6f 6e 74 61 69  6e 65 72 73 22 3a 7b 22  |f:containers":{"|
              00000160  6b 3a 7b 5c 22 6e 61 6d  65 5c 22 3a 5c 22 61 67  |k:{\"name\":\"ag|
              00000170  6e 68 6f 73 74 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |nhost\"}":{".":{|
              00000180  7d 2c 22 66 3a 69 6d 61  67 65 22 3a 7b 7d 2c 22  |},"f:image":{},"|
              00000190  66 3a 69 6d 61 67 65 50  75 6c 6c 50 6f 6c 69 63  |f:imagePullPolic|
              000001a0  79 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |y":{},"f:name":{|
              000001b0  7d 2c 22 66 3a 72 65 73  6f 75 72 63 65 73 22 3a  |},"f:resources":|
              000001c0  7b 7d 2c 22 66 3a 73 65  63 75 72 69 74 79 43 6f  |{},"f:securityCo|
              000001d0  6e 74 65 78 74 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ntext":{},"f:ter|
              000001e0  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000001f0  61 74 68 22 3a 7b 7d 2c  22 66 3a 74 65 72 6d 69  |ath":{},"f:termi|
              00000200  6e 61 74 69 6f 6e 4d 65  73 73 61 67 65 50 6f 6c  |nationMessagePol|
              00000210  69 63 79 22 3a 7b 7d 7d  7d 2c 22 66 3a 64 6e 73  |icy":{}}},"f:dns|
              00000220  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 72 65  |Policy":{},"f:re|
              00000230  73 74 61 72 74 50 6f 6c  69 63 79 22 3a 7b 7d 2c  |startPolicy":{},|
              00000240  22 66 3a 73 63 68 65 64  75 6c 65 72 4e 61 6d 65  |"f:schedulerName|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 47 72 61 63 65 50  |erminationGraceP|
              00000280  65 72 69 6f 64 53 65 63  6f 6e 64 73 22 3a 7b 7d  |eriodSeconds":{}|
              00000290  7d 7d 7d 7d                                       |}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 0,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 1,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 10,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115705,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=77) "ReplicaSet \"test-rollover-deployment-5d484bf7f9\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  2 12:08:43.274: INFO: New ReplicaSet "test-rollover-deployment-5d484bf7f9" of Deployment "test-rollover-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2530",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "a0633aa3-02be-4f1b-96c7-c6d300c4cd17",
      ResourceVersion: (string) (len=4) "2620",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837115707,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "8204da97-0e22-4b04-964e-7e0d1a2e36b1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115707,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=806) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 32 30 34 64 61  39 37 2d 30 65 32 32 2d  |\"8204da97-0e22-|
              00000120  34 62 30 34 2d 39 36 34  65 2d 37 65 30 64 31 61  |4b04-964e-7e0d1a|
              00000130  32 65 33 36 62 31 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |2e36b1\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  61 67 6e 68 6f 73 74 5c  22 7d 22 3a 7b 22 2e 22  |agnhost\"}":{"."|
              00000210  3a 7b 7d 2c 22 66 3a 69  6d 61 67 65 22 3a 7b 7d  |:{},"f:image":{}|
              00000220  2c 22 66 3a 69 6d 61 67  65 50 75 6c 6c 50 6f 6c  |,"f:imagePullPol|
              00000230  69 63 79 22 3a 7b 7d 2c  22 66 3a 6e 61 6d 65 22  |icy":{},"f:name"|
              00000240  3a 7b 7d 2c 22 66 3a 72  65 73 6f 75 72 63 65 73  |:{},"f:resources|
              00000250  22 3a 7b 7d 2c 22 66 3a  73 65 63 75 72 69 74 79  |":{},"f:security|
              00000260  43 6f 6e 74 65 78 74 22  3a 7b 7d 2c 22 66 3a 74  |Context":{},"f:t|
              00000270  65 72 6d 69 6e 61 74 69  6f 6e 4d 65 73 73 61 67  |erminationMessag|
              00000280  65 50 61 74 68 22 3a 7b  7d 2c 22 66 3a 74 65 72  |ePath":{},"f:ter|
              00000290  6d 69 6e 61 74 69 6f 6e  4d 65 73 73 61 67 65 50  |minationMessageP|
              000002a0  6f 6c 69 63 79 22 3a 7b  7d 7d 7d 2c 22 66 3a 64  |olicy":{}}},"f:d|
              000002b0  6e 73 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |nsPolicy":{},"f:|
              000002c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000002d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000002e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000002f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000300  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000310  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000320  7b 7d 7d 7d 7d 7d                                 |{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9",
          (string) (len=4) "name": (string) (len=12) "rollover-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "rollover-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:08:43.276: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
  Dec  2 12:08:43.276: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-rollover-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2530",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "72840f42-e67c-4bcc-94f4-d38fa244d5d4",
      ResourceVersion: (string) (len=4) "2629",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837115698,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=2) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "8204da97-0e22-4b04-964e-7e0d1a2e36b1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115698,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=467) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              00000030  3a 70 6f 64 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |:pod":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  73 65 6c 65 63 74 6f 72  |ec":{"f:selector|
              00000050  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000060  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000070  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              00000080  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000090  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              000000a0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              000000b0  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              000000c0  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              000000d0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              000000e0  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              000000f0  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000100  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000110  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |rces":{},"f:term|
              00000120  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000130  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000140  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000150  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000160  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              00000170  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              00000180  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              00000190  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000001a0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              000001b0  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              000001c0  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              000001d0  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=249) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 7d 2c 22 66  3a 6f 77 6e 65 72 52 65  |":{}},"f:ownerRe|
              00000090  66 65 72 65 6e 63 65 73  22 3a 7b 22 2e 22 3a 7b  |ferences":{".":{|
              000000a0  7d 2c 22 6b 3a 7b 5c 22  75 69 64 5c 22 3a 5c 22  |},"k:{\"uid\":\"|
              000000b0  38 32 30 34 64 61 39 37  2d 30 65 32 32 2d 34 62  |8204da97-0e22-4b|
              000000c0  30 34 2d 39 36 34 65 2d  37 65 30 64 31 61 32 65  |04-964e-7e0d1a2e|
              000000d0  33 36 62 31 5c 22 7d 22  3a 7b 7d 7d 7d 2c 22 66  |36b1\"}":{}}},"f|
              000000e0  3a 73 70 65 63 22 3a 7b  22 66 3a 72 65 70 6c 69  |:spec":{"f:repli|
              000000f0  63 61 73 22 3a 7b 7d 7d  7d                       |cas":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115721,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "pod": (string) (len=5) "httpd",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:08:43.277: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=35) "test-rollover-deployment-664fc6c874",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2530",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "277f46ba-b362-4c53-a726-f9c99d6cdd7f",
      ResourceVersion: (string) (len=4) "2575",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837115705,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-rollover-deployment",
          UID: (types.UID) (len=36) "8204da97-0e22-4b04-964e-7e0d1a2e36b1",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115707,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=810) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 38 32 30 34 64 61  39 37 2d 30 65 32 32 2d  |\"8204da97-0e22-|
              00000120  34 62 30 34 2d 39 36 34  65 2d 37 65 30 64 31 61  |4b04-964e-7e0d1a|
              00000130  32 65 33 36 62 31 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |2e36b1\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 6d 69 6e  |"f:spec":{"f:min|
              00000150  52 65 61 64 79 53 65 63  6f 6e 64 73 22 3a 7b 7d  |ReadySeconds":{}|
              00000160  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000170  2c 22 66 3a 73 65 6c 65  63 74 6f 72 22 3a 7b 7d  |,"f:selector":{}|
              00000180  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000190  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              000001a0  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              000001b0  22 66 3a 6e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 70  |"f:name":{},"f:p|
              000001c0  6f 64 2d 74 65 6d 70 6c  61 74 65 2d 68 61 73 68  |od-template-hash|
              000001d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000001e0  7b 22 66 3a 63 6f 6e 74  61 69 6e 65 72 73 22 3a  |{"f:containers":|
              000001f0  7b 22 6b 3a 7b 5c 22 6e  61 6d 65 5c 22 3a 5c 22  |{"k:{\"name\":\"|
              00000200  72 65 64 69 73 2d 73 6c  61 76 65 5c 22 7d 22 3a  |redis-slave\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000220  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000230  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000240  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000250  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000260  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000270  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000280  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              00000290  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000002a0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000002b0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000002c0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000002d0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000002e0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              000002f0  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000300  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000310  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000320  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115707,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 10,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "rollover-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "664fc6c874",
            (string) (len=4) "name": (string) (len=12) "rollover-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=11) "redis-slave",
              Image: (string) (len=47) "gcr.io/google_samples/gb-redisslave:nonexistent",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:08:43.281: INFO: Pod "test-rollover-deployment-5d484bf7f9-zj2mb" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=41) "test-rollover-deployment-5d484bf7f9-zj2mb",
      GenerateName: (string) (len=36) "test-rollover-deployment-5d484bf7f9-",
      Namespace: (string) (len=15) "deployment-2530",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "bac9d1e0-4d09-4d7e-9652-6abf1544d824",
      ResourceVersion: (string) (len=4) "2597",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837115707,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "rollover-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d484bf7f9"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=35) "test-rollover-deployment-5d484bf7f9",
          UID: (types.UID) (len=36) "a0633aa3-02be-4f1b-96c7-c6d300c4cd17",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115707,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 61 30  36 33 33 61 61 33 2d 30  |d\":\"a0633aa3-0|
              00000090  32 62 65 2d 34 66 31 62  2d 39 36 63 37 2d 63 36  |2be-4f1b-96c7-c6|
              000000a0  64 33 30 30 63 34 63 64  31 37 5c 22 7d 22 3a 7b  |d300c4cd17\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115711,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 33 30 2e 33 5c 22 7d  |192.168.230.3\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-t697h",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-t697h",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115707,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115711,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115711,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837115707,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.230.3",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.230.3"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837115707,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837115710,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://09eb2ea1ce634021387abc96b90b12cf43bc7d38fb8c8b2c60d5b1f78173ceab",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 12:08:43.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2530" for this suite. @ 12/02/23 12:08:43.286
• [25.150 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:124
  STEP: Creating a kubernetes client @ 12/02/23 12:08:43.294
  Dec  2 12:08:43.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:08:43.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:08:43.313
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:08:43.316
  STEP: Creating configMap with name configmap-test-upd-de66affb-074d-4c57-b3de-cadc04e782ba @ 12/02/23 12:08:43.323
  STEP: Creating the pod @ 12/02/23 12:08:43.326
  STEP: Updating configmap configmap-test-upd-de66affb-074d-4c57-b3de-cadc04e782ba @ 12/02/23 12:08:45.356
  STEP: waiting to observe update in volume @ 12/02/23 12:08:45.362
  Dec  2 12:09:49.628: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1172" for this suite. @ 12/02/23 12:09:49.633
• [66.345 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]
test/e2e/common/node/runtimeclass.go:189
  STEP: Creating a kubernetes client @ 12/02/23 12:09:49.64
  Dec  2 12:09:49.640: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename runtimeclass @ 12/02/23 12:09:49.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:09:49.656
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:09:49.658
  STEP: getting /apis @ 12/02/23 12:09:49.661
  STEP: getting /apis/node.k8s.io @ 12/02/23 12:09:49.665
  STEP: getting /apis/node.k8s.io/v1 @ 12/02/23 12:09:49.666
  STEP: creating @ 12/02/23 12:09:49.667
  STEP: watching @ 12/02/23 12:09:49.684
  Dec  2 12:09:49.684: INFO: starting watch
  STEP: getting @ 12/02/23 12:09:49.689
  STEP: listing @ 12/02/23 12:09:49.693
  STEP: patching @ 12/02/23 12:09:49.696
  STEP: updating @ 12/02/23 12:09:49.7
  Dec  2 12:09:49.705: INFO: waiting for watch events with expected annotations
  STEP: deleting @ 12/02/23 12:09:49.706
  STEP: deleting a collection @ 12/02/23 12:09:49.718
  Dec  2 12:09:49.735: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-8957" for this suite. @ 12/02/23 12:09:49.738
• [0.104 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]
test/e2e/apimachinery/webhook.go:301
  STEP: Creating a kubernetes client @ 12/02/23 12:09:49.744
  Dec  2 12:09:49.744: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 12:09:49.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:09:49.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:09:49.782
  STEP: Setting up server cert @ 12/02/23 12:09:49.809
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 12:09:49.97
  STEP: Deploying the webhook pod @ 12/02/23 12:09:49.978
  STEP: Wait for the deployment to be ready @ 12/02/23 12:09:49.993
  Dec  2 12:09:50.006: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  STEP: Deploying the webhook service @ 12/02/23 12:09:52.017
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 12:09:52.031
  Dec  2 12:09:53.031: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the crd webhook via the AdmissionRegistration API @ 12/02/23 12:09:53.038
  STEP: Creating a custom resource definition that should be denied by the webhook @ 12/02/23 12:09:53.054
  Dec  2 12:09:53.054: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:09:53.063: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5198" for this suite. @ 12/02/23 12:09:53.121
  STEP: Destroying namespace "webhook-markers-1369" for this suite. @ 12/02/23 12:09:53.13
• [3.393 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:205
  STEP: Creating a kubernetes client @ 12/02/23 12:09:53.137
  Dec  2 12:09:53.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 12:09:53.138
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:09:53.156
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:09:53.158
  STEP: Creating secret with name s-test-opt-del-5923ed14-23d4-450b-8325-f5f4046faeb4 @ 12/02/23 12:09:53.164
  STEP: Creating secret with name s-test-opt-upd-c7747f74-9d99-4c43-a067-8e8f3431d81a @ 12/02/23 12:09:53.179
  STEP: Creating the pod @ 12/02/23 12:09:53.183
  STEP: Deleting secret s-test-opt-del-5923ed14-23d4-450b-8325-f5f4046faeb4 @ 12/02/23 12:09:55.242
  STEP: Updating secret s-test-opt-upd-c7747f74-9d99-4c43-a067-8e8f3431d81a @ 12/02/23 12:09:55.259
  STEP: Creating secret with name s-test-opt-create-3b849841-a8b5-4b7e-90f4-b883442fd448 @ 12/02/23 12:09:55.265
  STEP: waiting to observe update in volume @ 12/02/23 12:09:55.271
  Dec  2 12:11:11.608: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7859" for this suite. @ 12/02/23 12:11:11.612
• [78.484 seconds]
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]
test/e2e/storage/subpath.go:91
  STEP: Creating a kubernetes client @ 12/02/23 12:11:11.621
  Dec  2 12:11:11.621: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename subpath @ 12/02/23 12:11:11.622
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:11:11.638
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:11:11.64
  STEP: Setting up data @ 12/02/23 12:11:11.643
  STEP: Creating pod pod-subpath-test-downwardapi-pr4n @ 12/02/23 12:11:11.654
  STEP: Creating a pod to test atomic-volume-subpath @ 12/02/23 12:11:11.654
  STEP: Saw pod success @ 12/02/23 12:11:35.721
  Dec  2 12:11:35.724: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-subpath-test-downwardapi-pr4n container test-container-subpath-downwardapi-pr4n: <nil>
  STEP: delete the pod @ 12/02/23 12:11:35.741
  STEP: Deleting pod pod-subpath-test-downwardapi-pr4n @ 12/02/23 12:11:35.758
  Dec  2 12:11:35.758: INFO: Deleting pod "pod-subpath-test-downwardapi-pr4n" in namespace "subpath-5139"
  Dec  2 12:11:35.761: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-5139" for this suite. @ 12/02/23 12:11:35.764
• [24.151 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]
test/e2e/apimachinery/resource_quota.go:451
  STEP: Creating a kubernetes client @ 12/02/23 12:11:35.774
  Dec  2 12:11:35.774: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 12:11:35.774
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:11:35.792
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:11:35.795
  STEP: Counting existing ResourceQuota @ 12/02/23 12:11:35.8
  STEP: Creating a ResourceQuota @ 12/02/23 12:11:40.803
  STEP: Ensuring resource quota status is calculated @ 12/02/23 12:11:40.81
  STEP: Creating a ReplicaSet @ 12/02/23 12:11:42.815
  STEP: Ensuring resource quota status captures replicaset creation @ 12/02/23 12:11:42.827
  STEP: Deleting a ReplicaSet @ 12/02/23 12:11:44.832
  STEP: Ensuring resource quota status released usage @ 12/02/23 12:11:44.841
  Dec  2 12:11:46.844: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2070" for this suite. @ 12/02/23 12:11:46.849
• [11.081 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:125
  STEP: Creating a kubernetes client @ 12/02/23 12:11:46.855
  Dec  2 12:11:46.855: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename discovery @ 12/02/23 12:11:46.855
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:11:46.87
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:11:46.872
  STEP: Setting up server cert @ 12/02/23 12:11:46.876
  Dec  2 12:11:47.104: INFO: Checking APIGroup: apiregistration.k8s.io
  Dec  2 12:11:47.106: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
  Dec  2 12:11:47.106: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
  Dec  2 12:11:47.106: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
  Dec  2 12:11:47.106: INFO: Checking APIGroup: apps
  Dec  2 12:11:47.107: INFO: PreferredVersion.GroupVersion: apps/v1
  Dec  2 12:11:47.107: INFO: Versions found [{apps/v1 v1}]
  Dec  2 12:11:47.107: INFO: apps/v1 matches apps/v1
  Dec  2 12:11:47.107: INFO: Checking APIGroup: events.k8s.io
  Dec  2 12:11:47.108: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
  Dec  2 12:11:47.108: INFO: Versions found [{events.k8s.io/v1 v1}]
  Dec  2 12:11:47.108: INFO: events.k8s.io/v1 matches events.k8s.io/v1
  Dec  2 12:11:47.108: INFO: Checking APIGroup: authentication.k8s.io
  Dec  2 12:11:47.109: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
  Dec  2 12:11:47.109: INFO: Versions found [{authentication.k8s.io/v1 v1}]
  Dec  2 12:11:47.109: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
  Dec  2 12:11:47.109: INFO: Checking APIGroup: authorization.k8s.io
  Dec  2 12:11:47.110: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
  Dec  2 12:11:47.110: INFO: Versions found [{authorization.k8s.io/v1 v1}]
  Dec  2 12:11:47.110: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
  Dec  2 12:11:47.110: INFO: Checking APIGroup: autoscaling
  Dec  2 12:11:47.111: INFO: PreferredVersion.GroupVersion: autoscaling/v2
  Dec  2 12:11:47.111: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1}]
  Dec  2 12:11:47.111: INFO: autoscaling/v2 matches autoscaling/v2
  Dec  2 12:11:47.111: INFO: Checking APIGroup: batch
  Dec  2 12:11:47.112: INFO: PreferredVersion.GroupVersion: batch/v1
  Dec  2 12:11:47.112: INFO: Versions found [{batch/v1 v1}]
  Dec  2 12:11:47.112: INFO: batch/v1 matches batch/v1
  Dec  2 12:11:47.112: INFO: Checking APIGroup: certificates.k8s.io
  Dec  2 12:11:47.113: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
  Dec  2 12:11:47.113: INFO: Versions found [{certificates.k8s.io/v1 v1}]
  Dec  2 12:11:47.113: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
  Dec  2 12:11:47.113: INFO: Checking APIGroup: networking.k8s.io
  Dec  2 12:11:47.114: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
  Dec  2 12:11:47.114: INFO: Versions found [{networking.k8s.io/v1 v1}]
  Dec  2 12:11:47.114: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
  Dec  2 12:11:47.114: INFO: Checking APIGroup: policy
  Dec  2 12:11:47.114: INFO: PreferredVersion.GroupVersion: policy/v1
  Dec  2 12:11:47.115: INFO: Versions found [{policy/v1 v1}]
  Dec  2 12:11:47.115: INFO: policy/v1 matches policy/v1
  Dec  2 12:11:47.115: INFO: Checking APIGroup: rbac.authorization.k8s.io
  Dec  2 12:11:47.115: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
  Dec  2 12:11:47.115: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
  Dec  2 12:11:47.115: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
  Dec  2 12:11:47.116: INFO: Checking APIGroup: storage.k8s.io
  Dec  2 12:11:47.117: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
  Dec  2 12:11:47.117: INFO: Versions found [{storage.k8s.io/v1 v1}]
  Dec  2 12:11:47.117: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
  Dec  2 12:11:47.117: INFO: Checking APIGroup: admissionregistration.k8s.io
  Dec  2 12:11:47.117: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
  Dec  2 12:11:47.117: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
  Dec  2 12:11:47.117: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
  Dec  2 12:11:47.117: INFO: Checking APIGroup: apiextensions.k8s.io
  Dec  2 12:11:47.119: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
  Dec  2 12:11:47.119: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
  Dec  2 12:11:47.119: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
  Dec  2 12:11:47.119: INFO: Checking APIGroup: scheduling.k8s.io
  Dec  2 12:11:47.120: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
  Dec  2 12:11:47.120: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
  Dec  2 12:11:47.120: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
  Dec  2 12:11:47.120: INFO: Checking APIGroup: coordination.k8s.io
  Dec  2 12:11:47.121: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
  Dec  2 12:11:47.121: INFO: Versions found [{coordination.k8s.io/v1 v1}]
  Dec  2 12:11:47.121: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
  Dec  2 12:11:47.121: INFO: Checking APIGroup: node.k8s.io
  Dec  2 12:11:47.122: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
  Dec  2 12:11:47.122: INFO: Versions found [{node.k8s.io/v1 v1}]
  Dec  2 12:11:47.122: INFO: node.k8s.io/v1 matches node.k8s.io/v1
  Dec  2 12:11:47.122: INFO: Checking APIGroup: discovery.k8s.io
  Dec  2 12:11:47.123: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
  Dec  2 12:11:47.123: INFO: Versions found [{discovery.k8s.io/v1 v1}]
  Dec  2 12:11:47.123: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
  Dec  2 12:11:47.123: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
  Dec  2 12:11:47.124: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta3
  Dec  2 12:11:47.124: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta3 v1beta3} {flowcontrol.apiserver.k8s.io/v1beta2 v1beta2}]
  Dec  2 12:11:47.124: INFO: flowcontrol.apiserver.k8s.io/v1beta3 matches flowcontrol.apiserver.k8s.io/v1beta3
  Dec  2 12:11:47.124: INFO: Checking APIGroup: metrics.k8s.io
  Dec  2 12:11:47.125: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
  Dec  2 12:11:47.125: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
  Dec  2 12:11:47.125: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
  Dec  2 12:11:47.125: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-9848" for this suite. @ 12/02/23 12:11:47.129
• [0.280 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]
test/e2e/common/node/expansion.go:300
  STEP: Creating a kubernetes client @ 12/02/23 12:11:47.134
  Dec  2 12:11:47.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 12:11:47.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:11:47.148
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:11:47.151
  STEP: creating the pod @ 12/02/23 12:11:47.154
  STEP: waiting for pod running @ 12/02/23 12:11:47.162
  STEP: creating a file in subpath @ 12/02/23 12:11:49.171
  Dec  2 12:11:49.175: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2953 PodName:var-expansion-01a887d6-c26a-404b-8c2e-994fe25f52e9 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 12:11:49.175: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:11:49.176: INFO: ExecWithOptions: Clientset creation
  Dec  2 12:11:49.176: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-2953/pods/var-expansion-01a887d6-c26a-404b-8c2e-994fe25f52e9/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: test for file in mounted path @ 12/02/23 12:11:49.243
  Dec  2 12:11:49.246: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2953 PodName:var-expansion-01a887d6-c26a-404b-8c2e-994fe25f52e9 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 12:11:49.246: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:11:49.246: INFO: ExecWithOptions: Clientset creation
  Dec  2 12:11:49.246: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-2953/pods/var-expansion-01a887d6-c26a-404b-8c2e-994fe25f52e9/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
  STEP: updating the annotation value @ 12/02/23 12:11:49.314
  Dec  2 12:11:49.825: INFO: Successfully updated pod "var-expansion-01a887d6-c26a-404b-8c2e-994fe25f52e9"
  STEP: waiting for annotated pod running @ 12/02/23 12:11:49.825
  STEP: deleting the pod gracefully @ 12/02/23 12:11:49.829
  Dec  2 12:11:49.829: INFO: Deleting pod "var-expansion-01a887d6-c26a-404b-8c2e-994fe25f52e9" in namespace "var-expansion-2953"
  Dec  2 12:11:49.837: INFO: Wait up to 5m0s for pod "var-expansion-01a887d6-c26a-404b-8c2e-994fe25f52e9" to be fully deleted
  Dec  2 12:12:21.915: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-2953" for this suite. @ 12/02/23 12:12:21.918
• [34.791 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]
test/e2e/apimachinery/discovery.go:169
  STEP: Creating a kubernetes client @ 12/02/23 12:12:21.926
  Dec  2 12:12:21.926: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename discovery @ 12/02/23 12:12:21.927
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:12:21.944
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:12:21.947
  STEP: Setting up server cert @ 12/02/23 12:12:21.951
  STEP: Requesting APIResourceList from "/api/v1" @ 12/02/23 12:12:22.099
  STEP: Requesting APIResourceList from "/apis/admissionregistration.k8s.io/v1" @ 12/02/23 12:12:22.101
  STEP: Requesting APIResourceList from "/apis/apiextensions.k8s.io/v1" @ 12/02/23 12:12:22.102
  STEP: Requesting APIResourceList from "/apis/apiregistration.k8s.io/v1" @ 12/02/23 12:12:22.103
  STEP: Requesting APIResourceList from "/apis/apps/v1" @ 12/02/23 12:12:22.104
  STEP: Requesting APIResourceList from "/apis/authentication.k8s.io/v1" @ 12/02/23 12:12:22.105
  STEP: Requesting APIResourceList from "/apis/authorization.k8s.io/v1" @ 12/02/23 12:12:22.106
  STEP: Requesting APIResourceList from "/apis/autoscaling/v1" @ 12/02/23 12:12:22.107
  STEP: Requesting APIResourceList from "/apis/autoscaling/v2" @ 12/02/23 12:12:22.108
  STEP: Requesting APIResourceList from "/apis/batch/v1" @ 12/02/23 12:12:22.109
  STEP: Requesting APIResourceList from "/apis/certificates.k8s.io/v1" @ 12/02/23 12:12:22.111
  STEP: Requesting APIResourceList from "/apis/coordination.k8s.io/v1" @ 12/02/23 12:12:22.112
  STEP: Requesting APIResourceList from "/apis/discovery.k8s.io/v1" @ 12/02/23 12:12:22.113
  STEP: Requesting APIResourceList from "/apis/events.k8s.io/v1" @ 12/02/23 12:12:22.114
  STEP: Requesting APIResourceList from "/apis/networking.k8s.io/v1" @ 12/02/23 12:12:22.115
  STEP: Requesting APIResourceList from "/apis/node.k8s.io/v1" @ 12/02/23 12:12:22.116
  STEP: Requesting APIResourceList from "/apis/policy/v1" @ 12/02/23 12:12:22.117
  STEP: Requesting APIResourceList from "/apis/scheduling.k8s.io/v1" @ 12/02/23 12:12:22.118
  STEP: Requesting APIResourceList from "/apis/storage.k8s.io/v1" @ 12/02/23 12:12:22.119
  Dec  2 12:12:22.120: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "discovery-9958" for this suite. @ 12/02/23 12:12:22.124
• [0.205 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/replica_set.go:111
  STEP: Creating a kubernetes client @ 12/02/23 12:12:22.132
  Dec  2 12:12:22.132: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replicaset @ 12/02/23 12:12:22.133
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:12:22.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:12:22.149
  Dec  2 12:12:22.152: INFO: Creating ReplicaSet my-hostname-basic-61b56e7b-d6eb-4e46-afc5-343de5e14695
  Dec  2 12:12:22.160: INFO: Pod name my-hostname-basic-61b56e7b-d6eb-4e46-afc5-343de5e14695: Found 0 pods out of 1
  Dec  2 12:12:27.163: INFO: Pod name my-hostname-basic-61b56e7b-d6eb-4e46-afc5-343de5e14695: Found 1 pods out of 1
  Dec  2 12:12:27.163: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-61b56e7b-d6eb-4e46-afc5-343de5e14695" is running
  Dec  2 12:12:27.167: INFO: Pod "my-hostname-basic-61b56e7b-d6eb-4e46-afc5-343de5e14695-6w8w9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 12:12:22 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 12:12:23 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 12:12:23 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 12:12:22 +0000 UTC Reason: Message:}])
  Dec  2 12:12:27.167: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/02/23 12:12:27.167
  Dec  2 12:12:27.181: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4366" for this suite. @ 12/02/23 12:12:27.186
• [5.065 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:198
  STEP: Creating a kubernetes client @ 12/02/23 12:12:27.197
  Dec  2 12:12:27.197: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/02/23 12:12:27.198
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:12:27.217
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:12:27.22
  STEP: fetching the /apis discovery document @ 12/02/23 12:12:27.228
  STEP: finding the apiextensions.k8s.io API group in the /apis discovery document @ 12/02/23 12:12:27.229
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document @ 12/02/23 12:12:27.229
  STEP: fetching the /apis/apiextensions.k8s.io discovery document @ 12/02/23 12:12:27.229
  STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document @ 12/02/23 12:12:27.231
  STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document @ 12/02/23 12:12:27.231
  STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document @ 12/02/23 12:12:27.232
  Dec  2 12:12:27.232: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2763" for this suite. @ 12/02/23 12:12:27.238
• [0.048 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:309
  STEP: Creating a kubernetes client @ 12/02/23 12:12:27.246
  Dec  2 12:12:27.246: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 12:12:27.247
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:12:27.261
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:12:27.263
  STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation @ 12/02/23 12:12:27.267
  Dec  2 12:12:27.268: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation @ 12/02/23 12:12:32.281
  Dec  2 12:12:32.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:12:33.587: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:12:38.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-66" for this suite. @ 12/02/23 12:12:38.626
• [11.387 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:87
  STEP: Creating a kubernetes client @ 12/02/23 12:12:38.634
  Dec  2 12:12:38.634: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 12:12:38.634
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:12:38.65
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:12:38.652
  STEP: Creating a pod to test emptydir volume type on tmpfs @ 12/02/23 12:12:38.654
  STEP: Saw pod success @ 12/02/23 12:12:40.67
  Dec  2 12:12:40.673: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-ce699993-c32f-4b80-92da-8276daa2219a container test-container: <nil>
  STEP: delete the pod @ 12/02/23 12:12:40.685
  Dec  2 12:12:40.700: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-884" for this suite. @ 12/02/23 12:12:40.704
• [2.076 seconds]
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]
test/e2e/storage/subpath.go:59
  STEP: Creating a kubernetes client @ 12/02/23 12:12:40.71
  Dec  2 12:12:40.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename subpath @ 12/02/23 12:12:40.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:12:40.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:12:40.73
  STEP: Setting up data @ 12/02/23 12:12:40.732
  STEP: Creating pod pod-subpath-test-secret-7cfl @ 12/02/23 12:12:40.742
  STEP: Creating a pod to test atomic-volume-subpath @ 12/02/23 12:12:40.742
  STEP: Saw pod success @ 12/02/23 12:13:02.804
  Dec  2 12:13:02.807: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-subpath-test-secret-7cfl container test-container-subpath-secret-7cfl: <nil>
  STEP: delete the pod @ 12/02/23 12:13:02.813
  STEP: Deleting pod pod-subpath-test-secret-7cfl @ 12/02/23 12:13:02.831
  Dec  2 12:13:02.831: INFO: Deleting pod "pod-subpath-test-secret-7cfl" in namespace "subpath-7137"
  Dec  2 12:13:02.833: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-7137" for this suite. @ 12/02/23 12:13:02.836
• [22.133 seconds]
------------------------------
SS
------------------------------
[sig-network] DNS should provide DNS for ExternalName services [Conformance]
test/e2e/network/dns.go:329
  STEP: Creating a kubernetes client @ 12/02/23 12:13:02.844
  Dec  2 12:13:02.844: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 12:13:02.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:02.862
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:02.864
  STEP: Creating a test externalName service @ 12/02/23 12:13:02.866
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2059.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2059.svc.cluster.local; sleep 1; done
   @ 12/02/23 12:13:02.871
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2059.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2059.svc.cluster.local; sleep 1; done
   @ 12/02/23 12:13:02.871
  STEP: creating a pod to probe DNS @ 12/02/23 12:13:02.871
  STEP: submitting the pod to kubernetes @ 12/02/23 12:13:02.871
  STEP: retrieving the pod @ 12/02/23 12:13:10.905
  STEP: looking for the results for each expected name from probers @ 12/02/23 12:13:10.908
  Dec  2 12:13:10.916: INFO: DNS probes using dns-test-9f90592b-c3da-4009-ada3-186e7375aa0e succeeded

  STEP: changing the externalName to bar.example.com @ 12/02/23 12:13:10.916
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2059.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2059.svc.cluster.local; sleep 1; done
   @ 12/02/23 12:13:10.923
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2059.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2059.svc.cluster.local; sleep 1; done
   @ 12/02/23 12:13:10.923
  STEP: creating a second pod to probe DNS @ 12/02/23 12:13:10.923
  STEP: submitting the pod to kubernetes @ 12/02/23 12:13:10.923
  STEP: retrieving the pod @ 12/02/23 12:13:16.945
  STEP: looking for the results for each expected name from probers @ 12/02/23 12:13:16.948
  Dec  2 12:13:16.956: INFO: DNS probes using dns-test-2be49171-a538-49fb-a2f4-5c1fb1acbeef succeeded

  STEP: changing the service to type=ClusterIP @ 12/02/23 12:13:16.956
  W1202 12:13:16.970141      18 warnings.go:70] spec.externalName is ignored when spec.type is not "ExternalName"
  STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2059.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2059.svc.cluster.local; sleep 1; done
   @ 12/02/23 12:13:16.97
  STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2059.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2059.svc.cluster.local; sleep 1; done
   @ 12/02/23 12:13:16.97
  STEP: creating a third pod to probe DNS @ 12/02/23 12:13:16.97
  STEP: submitting the pod to kubernetes @ 12/02/23 12:13:16.974
  STEP: retrieving the pod @ 12/02/23 12:13:18.991
  STEP: looking for the results for each expected name from probers @ 12/02/23 12:13:18.996
  Dec  2 12:13:19.003: INFO: DNS probes using dns-test-36f07f8f-d196-4005-a3e9-ffe16aeaa646 succeeded

  Dec  2 12:13:19.003: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 12:13:19.007
  STEP: deleting the pod @ 12/02/23 12:13:19.039
  STEP: deleting the pod @ 12/02/23 12:13:19.06
  STEP: deleting the test externalName service @ 12/02/23 12:13:19.075
  STEP: Destroying namespace "dns-2059" for this suite. @ 12/02/23 12:13:19.092
• [16.260 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:85
  STEP: Creating a kubernetes client @ 12/02/23 12:13:19.104
  Dec  2 12:13:19.104: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:13:19.105
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:19.124
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:19.126
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 12:13:19.128
  STEP: Saw pod success @ 12/02/23 12:13:23.154
  Dec  2 12:13:23.157: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-db581cf2-0dfd-4b2b-a23c-a9c9175a52f1 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 12:13:23.167
  Dec  2 12:13:23.184: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2561" for this suite. @ 12/02/23 12:13:23.187
• [4.102 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]
test/e2e/storage/empty_dir_wrapper.go:188
  STEP: Creating a kubernetes client @ 12/02/23 12:13:23.207
  Dec  2 12:13:23.207: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/02/23 12:13:23.208
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:23.274
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:23.277
  STEP: Creating 50 configmaps @ 12/02/23 12:13:23.279
  STEP: Creating RC which spawns configmap-volume pods @ 12/02/23 12:13:23.478
  Dec  2 12:13:23.752: INFO: Pod name wrapped-volume-race-296b29b2-695c-410c-b016-be8a04a7c9f2: Found 2 pods out of 5
  Dec  2 12:13:28.759: INFO: Pod name wrapped-volume-race-296b29b2-695c-410c-b016-be8a04a7c9f2: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/02/23 12:13:28.759
  STEP: Creating RC which spawns configmap-volume pods @ 12/02/23 12:13:28.779
  Dec  2 12:13:28.794: INFO: Pod name wrapped-volume-race-3043df9c-33cb-469d-badb-55f5a4070493: Found 0 pods out of 5
  Dec  2 12:13:33.802: INFO: Pod name wrapped-volume-race-3043df9c-33cb-469d-badb-55f5a4070493: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/02/23 12:13:33.802
  STEP: Creating RC which spawns configmap-volume pods @ 12/02/23 12:13:33.821
  Dec  2 12:13:33.834: INFO: Pod name wrapped-volume-race-6e812fb6-a349-41db-a1b7-17d12b3b1911: Found 0 pods out of 5
  Dec  2 12:13:38.841: INFO: Pod name wrapped-volume-race-6e812fb6-a349-41db-a1b7-17d12b3b1911: Found 5 pods out of 5
  STEP: Ensuring each pod is running @ 12/02/23 12:13:38.841
  Dec  2 12:13:38.857: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController wrapped-volume-race-6e812fb6-a349-41db-a1b7-17d12b3b1911 in namespace emptydir-wrapper-7931, will wait for the garbage collector to delete the pods @ 12/02/23 12:13:38.861
  Dec  2 12:13:38.923: INFO: Deleting ReplicationController wrapped-volume-race-6e812fb6-a349-41db-a1b7-17d12b3b1911 took: 8.448154ms
  Dec  2 12:13:39.024: INFO: Terminating ReplicationController wrapped-volume-race-6e812fb6-a349-41db-a1b7-17d12b3b1911 pods took: 100.559722ms
  STEP: deleting ReplicationController wrapped-volume-race-3043df9c-33cb-469d-badb-55f5a4070493 in namespace emptydir-wrapper-7931, will wait for the garbage collector to delete the pods @ 12/02/23 12:13:40.924
  Dec  2 12:13:40.985: INFO: Deleting ReplicationController wrapped-volume-race-3043df9c-33cb-469d-badb-55f5a4070493 took: 7.298361ms
  Dec  2 12:13:41.086: INFO: Terminating ReplicationController wrapped-volume-race-3043df9c-33cb-469d-badb-55f5a4070493 pods took: 101.029063ms
  STEP: deleting ReplicationController wrapped-volume-race-296b29b2-695c-410c-b016-be8a04a7c9f2 in namespace emptydir-wrapper-7931, will wait for the garbage collector to delete the pods @ 12/02/23 12:13:42.887
  Dec  2 12:13:42.948: INFO: Deleting ReplicationController wrapped-volume-race-296b29b2-695c-410c-b016-be8a04a7c9f2 took: 7.46141ms
  Dec  2 12:13:43.049: INFO: Terminating ReplicationController wrapped-volume-race-296b29b2-695c-410c-b016-be8a04a7c9f2 pods took: 101.085402ms
  STEP: Cleaning up the configMaps @ 12/02/23 12:13:44.55
  STEP: Destroying namespace "emptydir-wrapper-7931" for this suite. @ 12/02/23 12:13:44.837
• [21.635 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]
test/e2e/kubectl/kubectl.go:1575
  STEP: Creating a kubernetes client @ 12/02/23 12:13:44.843
  Dec  2 12:13:44.843: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 12:13:44.843
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:44.86
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:44.862
  STEP: creating the pod @ 12/02/23 12:13:44.864
  Dec  2 12:13:44.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 create -f -'
  Dec  2 12:13:45.035: INFO: stderr: ""
  Dec  2 12:13:45.035: INFO: stdout: "pod/pause created\n"
  STEP: adding the label testing-label with value testing-label-value to a pod @ 12/02/23 12:13:47.043
  Dec  2 12:13:47.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 label pods pause testing-label=testing-label-value'
  Dec  2 12:13:47.140: INFO: stderr: ""
  Dec  2 12:13:47.140: INFO: stdout: "pod/pause labeled\n"
  STEP: verifying the pod has the label testing-label with the value testing-label-value @ 12/02/23 12:13:47.14
  Dec  2 12:13:47.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 get pod pause -L testing-label'
  Dec  2 12:13:47.230: INFO: stderr: ""
  Dec  2 12:13:47.230: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
  STEP: removing the label testing-label of a pod @ 12/02/23 12:13:47.23
  Dec  2 12:13:47.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 label pods pause testing-label-'
  Dec  2 12:13:47.323: INFO: stderr: ""
  Dec  2 12:13:47.323: INFO: stdout: "pod/pause unlabeled\n"
  STEP: verifying the pod doesn't have the label testing-label @ 12/02/23 12:13:47.323
  Dec  2 12:13:47.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 get pod pause -L testing-label'
  Dec  2 12:13:47.401: INFO: stderr: ""
  Dec  2 12:13:47.401: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
  STEP: using delete to clean up resources @ 12/02/23 12:13:47.401
  Dec  2 12:13:47.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 delete --grace-period=0 --force -f -'
  Dec  2 12:13:47.467: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 12:13:47.467: INFO: stdout: "pod \"pause\" force deleted\n"
  Dec  2 12:13:47.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 get rc,svc -l name=pause --no-headers'
  Dec  2 12:13:47.520: INFO: stderr: "No resources found in kubectl-5281 namespace.\n"
  Dec  2 12:13:47.520: INFO: stdout: ""
  Dec  2 12:13:47.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5281 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec  2 12:13:47.567: INFO: stderr: ""
  Dec  2 12:13:47.568: INFO: stdout: ""
  Dec  2 12:13:47.568: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5281" for this suite. @ 12/02/23 12:13:47.571
• [2.737 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:85
  STEP: Creating a kubernetes client @ 12/02/23 12:13:47.581
  Dec  2 12:13:47.581: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/02/23 12:13:47.581
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:47.6
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:47.602
  Dec  2 12:13:47.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:13:53.805: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-7210" for this suite. @ 12/02/23 12:13:53.81
• [6.235 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:57
  STEP: Creating a kubernetes client @ 12/02/23 12:13:53.816
  Dec  2 12:13:53.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:13:53.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:53.835
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:53.837
  STEP: Creating configMap with name projected-configmap-test-volume-31c35315-359b-4549-b291-1c06f8c84e2c @ 12/02/23 12:13:53.839
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:13:53.847
  STEP: Saw pod success @ 12/02/23 12:13:57.869
  Dec  2 12:13:57.872: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-configmaps-c26d9222-74db-4193-be9e-0a8138c1e685 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:13:57.878
  Dec  2 12:13:57.894: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9922" for this suite. @ 12/02/23 12:13:57.897
• [4.088 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:41
  STEP: Creating a kubernetes client @ 12/02/23 12:13:57.905
  Dec  2 12:13:57.905: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename containers @ 12/02/23 12:13:57.905
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:57.921
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:57.923
  Dec  2 12:13:59.959: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-603" for this suite. @ 12/02/23 12:13:59.962
• [2.064 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:195
  STEP: Creating a kubernetes client @ 12/02/23 12:13:59.969
  Dec  2 12:13:59.969: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-runtime @ 12/02/23 12:13:59.97
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:13:59.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:13:59.988
  STEP: create the container @ 12/02/23 12:13:59.99
  W1202 12:13:59.999448      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/02/23 12:13:59.999
  STEP: get the container status @ 12/02/23 12:14:03.024
  STEP: the container should be terminated @ 12/02/23 12:14:03.027
  STEP: the termination message should be set @ 12/02/23 12:14:03.027
  Dec  2 12:14:03.027: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/02/23 12:14:03.027
  Dec  2 12:14:03.045: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6035" for this suite. @ 12/02/23 12:14:03.052
• [3.088 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
test/e2e/apimachinery/garbage_collector.go:638
  STEP: Creating a kubernetes client @ 12/02/23 12:14:03.057
  Dec  2 12:14:03.057: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename gc @ 12/02/23 12:14:03.058
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:14:03.072
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:14:03.074
  STEP: create the rc @ 12/02/23 12:14:03.081
  W1202 12:14:03.087547      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: delete the rc @ 12/02/23 12:14:09.094
  STEP: wait for the rc to be deleted @ 12/02/23 12:14:09.101
  Dec  2 12:14:10.117: INFO: 80 pods remaining
  Dec  2 12:14:10.117: INFO: 80 pods has nil DeletionTimestamp
  Dec  2 12:14:10.117: INFO: 
  Dec  2 12:14:11.113: INFO: 71 pods remaining
  Dec  2 12:14:11.113: INFO: 71 pods has nil DeletionTimestamp
  Dec  2 12:14:11.113: INFO: 
  Dec  2 12:14:12.113: INFO: 60 pods remaining
  Dec  2 12:14:12.113: INFO: 60 pods has nil DeletionTimestamp
  Dec  2 12:14:12.113: INFO: 
  Dec  2 12:14:13.114: INFO: 40 pods remaining
  Dec  2 12:14:13.124: INFO: 40 pods has nil DeletionTimestamp
  Dec  2 12:14:13.124: INFO: 
  Dec  2 12:14:14.203: INFO: 32 pods remaining
  Dec  2 12:14:14.203: INFO: 29 pods has nil DeletionTimestamp
  Dec  2 12:14:14.203: INFO: 
  Dec  2 12:14:15.115: INFO: 20 pods remaining
  Dec  2 12:14:15.117: INFO: 20 pods has nil DeletionTimestamp
  Dec  2 12:14:15.117: INFO: 
  STEP: Gathering metrics @ 12/02/23 12:14:16.112
  W1202 12:14:16.117927      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  2 12:14:16.118: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  2 12:14:16.118: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-1132" for this suite. @ 12/02/23 12:14:16.124
• [13.077 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]
test/e2e/apps/rc.go:112
  STEP: Creating a kubernetes client @ 12/02/23 12:14:16.134
  Dec  2 12:14:16.134: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replication-controller @ 12/02/23 12:14:16.135
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:14:16.154
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:14:16.157
  STEP: creating a ReplicationController @ 12/02/23 12:14:16.168
  STEP: waiting for RC to be added @ 12/02/23 12:14:16.175
  STEP: waiting for available Replicas @ 12/02/23 12:14:16.175
  STEP: patching ReplicationController @ 12/02/23 12:14:17.515
  STEP: waiting for RC to be modified @ 12/02/23 12:14:17.524
  STEP: patching ReplicationController status @ 12/02/23 12:14:17.524
  STEP: waiting for RC to be modified @ 12/02/23 12:14:17.531
  STEP: waiting for available Replicas @ 12/02/23 12:14:17.531
  STEP: fetching ReplicationController status @ 12/02/23 12:14:17.538
  STEP: patching ReplicationController scale @ 12/02/23 12:14:17.541
  STEP: waiting for RC to be modified @ 12/02/23 12:14:17.55
  STEP: waiting for ReplicationController's scale to be the max amount @ 12/02/23 12:14:17.55
  STEP: fetching ReplicationController; ensuring that it's patched @ 12/02/23 12:14:18.9
  STEP: updating ReplicationController status @ 12/02/23 12:14:18.903
  STEP: waiting for RC to be modified @ 12/02/23 12:14:18.91
  STEP: listing all ReplicationControllers @ 12/02/23 12:14:18.91
  STEP: checking that ReplicationController has expected values @ 12/02/23 12:14:18.914
  STEP: deleting ReplicationControllers by collection @ 12/02/23 12:14:18.914
  STEP: waiting for ReplicationController to have a DELETED watchEvent @ 12/02/23 12:14:18.924
  Dec  2 12:14:18.968: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1202 12:14:18.968999      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "replication-controller-5436" for this suite. @ 12/02/23 12:14:18.972
• [2.845 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:272
  STEP: Creating a kubernetes client @ 12/02/23 12:14:18.979
  Dec  2 12:14:18.980: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename namespaces @ 12/02/23 12:14:18.98
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:14:18.997
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:14:18.999
  STEP: creating a Namespace @ 12/02/23 12:14:19.002
  STEP: patching the Namespace @ 12/02/23 12:14:19.022
  STEP: get the Namespace and ensuring it has the label @ 12/02/23 12:14:19.029
  Dec  2 12:14:19.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-3736" for this suite. @ 12/02/23 12:14:19.038
  STEP: Destroying namespace "nspatchtest-d0559df3-9673-46d3-9898-beff1ee29276-1749" for this suite. @ 12/02/23 12:14:19.044
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
test/e2e/apimachinery/resource_quota.go:76
  STEP: Creating a kubernetes client @ 12/02/23 12:14:19.055
  Dec  2 12:14:19.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 12:14:19.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:14:19.075
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:14:19.077
  STEP: Counting existing ResourceQuota @ 12/02/23 12:14:19.079
  E1202 12:14:19.969136      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:20.970080      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:21.970300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:22.970347      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:23.970907      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/02/23 12:14:24.084
  STEP: Ensuring resource quota status is calculated @ 12/02/23 12:14:24.091
  E1202 12:14:24.971093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:25.971456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:14:26.096: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-2137" for this suite. @ 12/02/23 12:14:26.099
• [7.051 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]
test/e2e/apimachinery/watch.go:334
  STEP: Creating a kubernetes client @ 12/02/23 12:14:26.107
  Dec  2 12:14:26.107: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename watch @ 12/02/23 12:14:26.107
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:14:26.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:14:26.127
  STEP: getting a starting resourceVersion @ 12/02/23 12:14:26.129
  STEP: starting a background goroutine to produce watch events @ 12/02/23 12:14:26.133
  STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order @ 12/02/23 12:14:26.133
  E1202 12:14:26.972368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:27.973355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:14:28.913: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-6211" for this suite. @ 12/02/23 12:14:28.962
  E1202 12:14:28.974238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
• [2.909 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:240
  STEP: Creating a kubernetes client @ 12/02/23 12:14:29.016
  Dec  2 12:14:29.017: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:14:29.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:14:29.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:14:29.038
  STEP: Creating configMap with name cm-test-opt-del-c3add6f6-a028-4057-965f-3fbe32172cff @ 12/02/23 12:14:29.044
  STEP: Creating configMap with name cm-test-opt-upd-893d7bb0-dac6-4b89-ac99-105cd610654c @ 12/02/23 12:14:29.048
  STEP: Creating the pod @ 12/02/23 12:14:29.053
  E1202 12:14:29.975286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:30.976119      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-c3add6f6-a028-4057-965f-3fbe32172cff @ 12/02/23 12:14:31.092
  STEP: Updating configmap cm-test-opt-upd-893d7bb0-dac6-4b89-ac99-105cd610654c @ 12/02/23 12:14:31.099
  STEP: Creating configMap with name cm-test-opt-create-fa282d1c-e0e2-4660-9fe1-289ee80269bb @ 12/02/23 12:14:31.103
  STEP: waiting to observe update in volume @ 12/02/23 12:14:31.108
  E1202 12:14:31.977172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:32.977279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:33.977971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:34.978056      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:35.978727      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:36.979516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:37.979893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:38.980735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:39.981105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:40.981315      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:41.981386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:42.981580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:43.982218      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:44.982311      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:45.982617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:46.983274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:47.983655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:48.983817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:49.983967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:50.984008      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:51.984638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:52.984752      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:53.988900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:54.989160      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:55.989246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:56.990306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:57.991286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:58.991603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:14:59.992608      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:00.992954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:01.993936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:02.994770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:03.995017      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:04.995058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:05.996087      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:06.996174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:07.996269      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:08.996440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:09.996523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:10.997284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:11.997857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:12.997967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:13.998718      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:14.998763      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:15.999296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:16.999382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:17.999540      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:18.999630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:19.999663      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:20.999918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:22.000458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:23.000493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:24.001392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:25.001502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:26.001983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:27.002079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:28.002236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:29.003214      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:30.003315      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:31.003419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:32.004247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:33.004424      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:34.004554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:35.004658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:36.005012      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:37.005157      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:38.005669      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:39.005768      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:40.005867      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:41.006167      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:42.006914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:43.007292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:44.008075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:45.008184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:46.008492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:47.008688      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:48.009354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:49.009506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:50.009772      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:51.010774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:52.011288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:53.011373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:54.011415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:55.011524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:56.012590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:57.012665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:15:57.463: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1109" for this suite. @ 12/02/23 12:15:57.467
• [88.455 seconds]
------------------------------
SSS
------------------------------
[sig-apps] Job should delete a job [Conformance]
test/e2e/apps/job.go:485
  STEP: Creating a kubernetes client @ 12/02/23 12:15:57.472
  Dec  2 12:15:57.472: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename job @ 12/02/23 12:15:57.473
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:15:57.489
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:15:57.492
  STEP: Creating a job @ 12/02/23 12:15:57.494
  STEP: Ensuring active pods == parallelism @ 12/02/23 12:15:57.5
  E1202 12:15:58.013517      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:15:59.014440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:00.015270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:01.015550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete a job @ 12/02/23 12:16:01.505
  STEP: deleting Job.batch foo in namespace job-8987, will wait for the garbage collector to delete the pods @ 12/02/23 12:16:01.505
  Dec  2 12:16:01.564: INFO: Deleting Job.batch foo took: 6.221306ms
  Dec  2 12:16:01.665: INFO: Terminating Job.batch foo pods took: 100.887573ms
  E1202 12:16:02.015586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:03.015994      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:04.016734      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:05.017754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:06.017981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:07.018940      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:08.019865      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:09.020872      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:10.021830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:11.022892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:12.022932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:13.023845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:14.024397      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:15.025355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:16.025589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:17.026609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:18.027599      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:19.027666      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:20.028645      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:21.029712      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:22.030574      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:23.031568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:24.031992      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:25.032979      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:26.033151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:27.034032      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:28.034959      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:29.035835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:30.035877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:31.035955      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:32.036484      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring job was deleted @ 12/02/23 12:16:32.266
  Dec  2 12:16:32.269: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8987" for this suite. @ 12/02/23 12:16:32.274
• [34.808 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:47
  STEP: Creating a kubernetes client @ 12/02/23 12:16:32.28
  Dec  2 12:16:32.280: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:16:32.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:16:32.301
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:16:32.303
  STEP: Creating configMap with name configmap-test-volume-84aecba3-c2f6-454d-bf4e-80a1adcced5a @ 12/02/23 12:16:32.306
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:16:32.31
  E1202 12:16:33.036806      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:34.037378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:35.038183      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:36.038221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:16:36.331
  Dec  2 12:16:36.335: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-0f62ee2a-ddd9-4d30-b369-064e41cfc0fe container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:16:36.341
  Dec  2 12:16:36.356: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-464" for this suite. @ 12/02/23 12:16:36.359
• [4.084 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should delete old replica sets [Conformance]
test/e2e/apps/deployment.go:122
  STEP: Creating a kubernetes client @ 12/02/23 12:16:36.365
  Dec  2 12:16:36.365: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 12:16:36.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:16:36.381
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:16:36.383
  Dec  2 12:16:36.397: INFO: Pod name cleanup-pod: Found 0 pods out of 1
  E1202 12:16:37.039066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:38.039863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:39.039941      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:40.040112      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:41.040204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:41.401: INFO: Pod name cleanup-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/02/23 12:16:41.401
  Dec  2 12:16:41.401: INFO: Creating deployment test-cleanup-deployment
  STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up @ 12/02/23 12:16:41.42
  E1202 12:16:42.040764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:43.041138      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:43.470: INFO: Deployment "test-cleanup-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=23) "test-cleanup-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3774",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c14cb8f8-d60f-416a-89d7-73e010f643ea",
      ResourceVersion: (string) (len=4) "7904",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116201,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116203,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(0),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116203,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=76) "ReplicaSet \"test-cleanup-deployment-58dcc84f74\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  2 12:16:43.476: INFO: New ReplicaSet "test-cleanup-deployment-58dcc84f74" of Deployment "test-cleanup-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-cleanup-deployment-58dcc84f74",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3774",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3f87e09a-83ba-4afb-96b9-19abc1ff5195",
      ResourceVersion: (string) (len=4) "7894",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116201,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=23) "test-cleanup-deployment",
          UID: (types.UID) (len=36) "c14cb8f8-d60f-416a-89d7-73e010f643ea",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 31 34 63 62 38  66 38 2d 64 36 30 66 2d  |\"c14cb8f8-d60f-|
              00000120  34 31 36 61 2d 38 39 64  37 2d 37 33 65 30 31 30  |416a-89d7-73e010|
              00000130  66 36 34 33 65 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |f643ea\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116203,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=11) "cleanup-pod",
          (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=11) "cleanup-pod",
            (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:16:43.480: INFO: Pod "test-cleanup-deployment-58dcc84f74-dwfnp" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-cleanup-deployment-58dcc84f74-dwfnp",
      GenerateName: (string) (len=35) "test-cleanup-deployment-58dcc84f74-",
      Namespace: (string) (len=15) "deployment-3774",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6cc86269-448d-4b22-8a39-b8e70e6658db",
      ResourceVersion: (string) (len=4) "7893",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116201,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=11) "cleanup-pod",
        (string) (len=17) "pod-template-hash": (string) (len=10) "58dcc84f74"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-cleanup-deployment-58dcc84f74",
          UID: (types.UID) (len=36) "3f87e09a-83ba-4afb-96b9-19abc1ff5195",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 33 66  38 37 65 30 39 61 2d 38  |d\":\"3f87e09a-8|
              00000090  33 62 61 2d 34 61 66 62  2d 39 36 62 39 2d 31 39  |3ba-4afb-96b9-19|
              000000a0  61 62 63 31 66 66 35 31  39 35 5c 22 7d 22 3a 7b  |abc1ff5195\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116203,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 33 30 2e 34 35 5c 22  |192.168.230.45\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-z2kl5",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-z2kl5",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116203,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116203,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116201,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.230.45",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.230.45"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116201,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837116202,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://5b8638dde44ff2f23bccfa8200c33e663d247e0e7012f166da4550605391aec1",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 12:16:43.481: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3774" for this suite. @ 12/02/23 12:16:43.485
• [7.147 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:125
  STEP: Creating a kubernetes client @ 12/02/23 12:16:43.512
  Dec  2 12:16:43.512: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 12:16:43.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:16:43.53
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:16:43.532
  STEP: Creating secret with name secret-test-3924a3d9-dd6b-4656-9c60-e332d99b19de @ 12/02/23 12:16:43.534
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:16:43.541
  E1202 12:16:44.041834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:45.042242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:46.043066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:47.043559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:16:47.561
  Dec  2 12:16:47.566: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-secrets-695fe02f-ebb9-4bf6-a9f4-8125b7d3f1c2 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:16:47.572
  Dec  2 12:16:47.588: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7608" for this suite. @ 12/02/23 12:16:47.591
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]
test/e2e/apps/daemon_set.go:875
  STEP: Creating a kubernetes client @ 12/02/23 12:16:47.599
  Dec  2 12:16:47.599: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename daemonsets @ 12/02/23 12:16:47.6
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:16:47.62
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:16:47.622
  STEP: Creating simple DaemonSet "daemon-set" @ 12/02/23 12:16:47.647
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/02/23 12:16:47.655
  Dec  2 12:16:47.660: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:47.660: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:47.665: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:16:47.665: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:16:48.043655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:48.669: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:48.669: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:48.673: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:16:48.673: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:16:49.044981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:49.670: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:49.670: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:49.674: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  2 12:16:49.674: INFO: Node ip-172-31-74-39 is running 0 daemon pod, expected 1
  E1202 12:16:50.045335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:50.670: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:50.670: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:50.674: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  2 12:16:50.674: INFO: Node ip-172-31-74-39 is running 0 daemon pod, expected 1
  E1202 12:16:51.045392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:51.669: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:51.669: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:16:51.672: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 12:16:51.672: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Getting /status @ 12/02/23 12:16:51.675
  Dec  2 12:16:51.677: INFO: Daemon Set daemon-set has Conditions: []
  STEP: updating the DaemonSet Status @ 12/02/23 12:16:51.677
  Dec  2 12:16:51.687: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the daemon set status to be updated @ 12/02/23 12:16:51.687
  Dec  2 12:16:51.688: INFO: Observed &DaemonSet event: ADDED
  Dec  2 12:16:51.688: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.689: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.689: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.689: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.689: INFO: Found daemon set daemon-set in namespace daemonsets-9433 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  2 12:16:51.689: INFO: Daemon set daemon-set has an updated status
  STEP: patching the DaemonSet Status @ 12/02/23 12:16:51.689
  STEP: watching for the daemon set status to be patched @ 12/02/23 12:16:51.7
  Dec  2 12:16:51.701: INFO: Observed &DaemonSet event: ADDED
  Dec  2 12:16:51.701: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.702: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.702: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.702: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.702: INFO: Observed daemon set daemon-set in namespace daemonsets-9433 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  2 12:16:51.702: INFO: Observed &DaemonSet event: MODIFIED
  Dec  2 12:16:51.702: INFO: Found daemon set daemon-set in namespace daemonsets-9433 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
  Dec  2 12:16:51.702: INFO: Daemon set daemon-set has a patched status
  STEP: Deleting DaemonSet "daemon-set" @ 12/02/23 12:16:51.706
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9433, will wait for the garbage collector to delete the pods @ 12/02/23 12:16:51.707
  Dec  2 12:16:51.766: INFO: Deleting DaemonSet.extensions daemon-set took: 6.538885ms
  Dec  2 12:16:51.867: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.387438ms
  E1202 12:16:52.046375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:53.046879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:54.047392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:54.272: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:16:54.272: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  2 12:16:54.274: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8075"},"items":null}

  Dec  2 12:16:54.277: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8075"},"items":null}

  Dec  2 12:16:54.289: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-9433" for this suite. @ 12/02/23 12:16:54.292
• [6.700 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]
test/e2e/apps/replica_set.go:131
  STEP: Creating a kubernetes client @ 12/02/23 12:16:54.3
  Dec  2 12:16:54.300: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replicaset @ 12/02/23 12:16:54.301
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:16:54.318
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:16:54.32
  STEP: Given a Pod with a 'name' label pod-adoption-release is created @ 12/02/23 12:16:54.322
  E1202 12:16:55.048256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:16:56.048276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replicaset with a matching selector is created @ 12/02/23 12:16:56.344
  STEP: Then the orphan pod is adopted @ 12/02/23 12:16:56.348
  E1202 12:16:57.048367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When the matched label of one of its pods change @ 12/02/23 12:16:57.356
  Dec  2 12:16:57.359: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/02/23 12:16:57.369
  E1202 12:16:58.048880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:16:58.377: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-1839" for this suite. @ 12/02/23 12:16:58.381
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:78
  STEP: Creating a kubernetes client @ 12/02/23 12:16:58.388
  Dec  2 12:16:58.388: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:16:58.389
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:16:58.404
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:16:58.406
  STEP: Creating projection with secret that has name projected-secret-test-map-61384d81-025a-4732-8604-b8bd8ba8f713 @ 12/02/23 12:16:58.409
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:16:58.415
  E1202 12:16:59.049882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:00.050839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:17:00.429
  Dec  2 12:17:00.433: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-projected-secrets-ae764920-e7ae-4a6a-a8a9-ecb979311d1c container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:17:00.451
  Dec  2 12:17:00.467: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3141" for this suite. @ 12/02/23 12:17:00.471
• [2.088 seconds]
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:256
  STEP: Creating a kubernetes client @ 12/02/23 12:17:00.477
  Dec  2 12:17:00.477: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename init-container @ 12/02/23 12:17:00.478
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:00.496
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:00.499
  STEP: creating the pod @ 12/02/23 12:17:00.501
  Dec  2 12:17:00.501: INFO: PodSpec: initContainers in spec.initContainers
  E1202 12:17:01.051426      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:02.052451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:03.052620      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:04.053631      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:04.218: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-9617" for this suite. @ 12/02/23 12:17:04.222
• [3.754 seconds]
------------------------------
[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]
test/e2e/network/service.go:1416
  STEP: Creating a kubernetes client @ 12/02/23 12:17:04.231
  Dec  2 12:17:04.231: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 12:17:04.231
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:04.248
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:04.25
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-6331 @ 12/02/23 12:17:04.252
  STEP: changing the ExternalName service to type=ClusterIP @ 12/02/23 12:17:04.256
  STEP: creating replication controller externalname-service in namespace services-6331 @ 12/02/23 12:17:04.271
  I1202 12:17:04.279779      18 runners.go:197] Created replication controller with name: externalname-service, namespace: services-6331, replica count: 2
  E1202 12:17:05.053990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:06.054616      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:07.055695      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 12:17:07.331093      18 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 12:17:07.331: INFO: Creating new exec pod
  E1202 12:17:08.055783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:09.055858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:10.056589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:10.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6331 exec execpodwmn5b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec  2 12:17:10.470: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec  2 12:17:10.470: INFO: stdout: "externalname-service-cdqsl"
  Dec  2 12:17:10.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6331 exec execpodwmn5b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.251 80'
  Dec  2 12:17:10.585: INFO: stderr: "+ nc -v -t -w 2 10.152.183.251 80\nConnection to 10.152.183.251 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Dec  2 12:17:10.585: INFO: stdout: ""
  E1202 12:17:11.057449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:11.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6331 exec execpodwmn5b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.251 80'
  Dec  2 12:17:11.700: INFO: stderr: "+ nc -v -t -w 2 10.152.183.251 80\nConnection to 10.152.183.251 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Dec  2 12:17:11.700: INFO: stdout: ""
  E1202 12:17:12.058038      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:12.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6331 exec execpodwmn5b -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.251 80'
  Dec  2 12:17:12.697: INFO: stderr: "+ nc -v -t -w 2 10.152.183.251 80\n+ echo hostName\nConnection to 10.152.183.251 80 port [tcp/http] succeeded!\n"
  Dec  2 12:17:12.697: INFO: stdout: "externalname-service-btlhx"
  Dec  2 12:17:12.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 12:17:12.701: INFO: Cleaning up the ExternalName to ClusterIP test service
  STEP: Destroying namespace "services-6331" for this suite. @ 12/02/23 12:17:12.718
• [8.496 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:47
  STEP: Creating a kubernetes client @ 12/02/23 12:17:12.728
  Dec  2 12:17:12.728: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 12:17:12.729
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:12.745
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:12.747
  STEP: Creating a pod to test env composition @ 12/02/23 12:17:12.75
  E1202 12:17:13.058921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:14.059099      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:15.059623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:16.059799      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:17:16.771
  Dec  2 12:17:16.774: INFO: Trying to get logs from node ip-172-31-1-50 pod var-expansion-2fd17431-d5a0-4f69-8e14-3812b70294e1 container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 12:17:16.78
  Dec  2 12:17:16.798: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-5218" for this suite. @ 12/02/23 12:17:16.801
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]
test/e2e/network/endpointslicemirroring.go:55
  STEP: Creating a kubernetes client @ 12/02/23 12:17:16.808
  Dec  2 12:17:16.808: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename endpointslicemirroring @ 12/02/23 12:17:16.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:16.826
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:16.829
  STEP: mirroring a new custom Endpoint @ 12/02/23 12:17:16.842
  Dec  2 12:17:16.851: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
  E1202 12:17:17.060853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:18.060947      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring an update to a custom Endpoint @ 12/02/23 12:17:18.854
  Dec  2 12:17:18.862: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
  E1202 12:17:19.061917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:20.062257      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mirroring deletion of a custom Endpoint @ 12/02/23 12:17:20.867
  Dec  2 12:17:20.876: INFO: Waiting for 0 EndpointSlices to exist, got 1
  E1202 12:17:21.062092      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:22.062240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:22.884: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslicemirroring-6962" for this suite. @ 12/02/23 12:17:22.888
• [6.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:248
  STEP: Creating a kubernetes client @ 12/02/23 12:17:22.895
  Dec  2 12:17:22.895: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-runtime @ 12/02/23 12:17:22.896
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:22.914
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:22.916
  STEP: create the container @ 12/02/23 12:17:22.919
  W1202 12:17:22.927609      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/02/23 12:17:22.927
  E1202 12:17:23.062617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:24.062931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:25.063250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/02/23 12:17:25.943
  STEP: the container should be terminated @ 12/02/23 12:17:25.947
  STEP: the termination message should be set @ 12/02/23 12:17:25.947
  Dec  2 12:17:25.947: INFO: Expected: &{OK} to match Container's Termination Message: OK --
  STEP: delete the container @ 12/02/23 12:17:25.947
  Dec  2 12:17:25.969: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-7919" for this suite. @ 12/02/23 12:17:25.976
• [3.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to create a functioning NodePort service [Conformance]
test/e2e/network/service.go:1280
  STEP: Creating a kubernetes client @ 12/02/23 12:17:25.982
  Dec  2 12:17:25.982: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 12:17:25.983
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:26
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:26.003
  STEP: creating service nodeport-test with type=NodePort in namespace services-6538 @ 12/02/23 12:17:26.005
  STEP: creating replication controller nodeport-test in namespace services-6538 @ 12/02/23 12:17:26.031
  I1202 12:17:26.049467      18 runners.go:197] Created replication controller with name: nodeport-test, namespace: services-6538, replica count: 2
  E1202 12:17:26.064130      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:27.064236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:28.064893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:29.064962      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 12:17:29.101205      18 runners.go:197] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 12:17:29.101: INFO: Creating new exec pod
  E1202 12:17:30.065048      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:31.065154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:32.065232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:32.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6538 exec execpodzjnjj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
  Dec  2 12:17:32.237: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
  Dec  2 12:17:32.237: INFO: stdout: "nodeport-test-8qnp2"
  Dec  2 12:17:32.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6538 exec execpodzjnjj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.44 80'
  Dec  2 12:17:32.353: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.44 80\nConnection to 10.152.183.44 80 port [tcp/http] succeeded!\n"
  Dec  2 12:17:32.353: INFO: stdout: "nodeport-test-j96gf"
  Dec  2 12:17:32.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6538 exec execpodzjnjj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.74.39 30441'
  Dec  2 12:17:32.482: INFO: stderr: "+ nc -v -t -w 2 172.31.74.39 30441\n+ echo hostName\nConnection to 172.31.74.39 30441 port [tcp/*] succeeded!\n"
  Dec  2 12:17:32.482: INFO: stdout: "nodeport-test-8qnp2"
  Dec  2 12:17:32.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-6538 exec execpodzjnjj -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.1.50 30441'
  Dec  2 12:17:32.588: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.1.50 30441\nConnection to 172.31.1.50 30441 port [tcp/*] succeeded!\n"
  Dec  2 12:17:32.588: INFO: stdout: "nodeport-test-8qnp2"
  Dec  2 12:17:32.588: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6538" for this suite. @ 12/02/23 12:17:32.592
• [6.616 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]
test/e2e/instrumentation/core_events.go:57
  STEP: Creating a kubernetes client @ 12/02/23 12:17:32.599
  Dec  2 12:17:32.599: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename events @ 12/02/23 12:17:32.599
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:32.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:32.62
  STEP: creating a test event @ 12/02/23 12:17:32.622
  STEP: listing all events in all namespaces @ 12/02/23 12:17:32.627
  STEP: patching the test event @ 12/02/23 12:17:32.633
  STEP: fetching the test event @ 12/02/23 12:17:32.642
  STEP: updating the test event @ 12/02/23 12:17:32.645
  STEP: getting the test event @ 12/02/23 12:17:32.653
  STEP: deleting the test event @ 12/02/23 12:17:32.656
  STEP: listing all events in all namespaces @ 12/02/23 12:17:32.664
  Dec  2 12:17:32.670: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-8899" for this suite. @ 12/02/23 12:17:32.673
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]
test/e2e/auth/service_accounts.go:740
  STEP: Creating a kubernetes client @ 12/02/23 12:17:32.679
  Dec  2 12:17:32.679: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svcaccounts @ 12/02/23 12:17:32.679
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:32.697
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:32.699
  Dec  2 12:17:32.704: INFO: Got root ca configmap in namespace "svcaccounts-3002"
  Dec  2 12:17:32.710: INFO: Deleted root ca configmap in namespace "svcaccounts-3002"
  E1202 12:17:33.065336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for a new root ca configmap created @ 12/02/23 12:17:33.211
  Dec  2 12:17:33.214: INFO: Recreated root ca configmap in namespace "svcaccounts-3002"
  Dec  2 12:17:33.220: INFO: Updated root ca configmap in namespace "svcaccounts-3002"
  STEP: waiting for the root ca configmap reconciled @ 12/02/23 12:17:33.721
  Dec  2 12:17:33.724: INFO: Reconciled root ca configmap in namespace "svcaccounts-3002"
  Dec  2 12:17:33.724: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-3002" for this suite. @ 12/02/23 12:17:33.728
• [1.056 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
test/e2e/apps/job.go:370
  STEP: Creating a kubernetes client @ 12/02/23 12:17:33.735
  Dec  2 12:17:33.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename job @ 12/02/23 12:17:33.735
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:33.753
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:33.755
  STEP: Creating Indexed job @ 12/02/23 12:17:33.76
  STEP: Ensuring job reaches completions @ 12/02/23 12:17:33.766
  E1202 12:17:34.066247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:35.066327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:36.066421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:37.066506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:38.067175      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:39.068196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:40.068277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:41.068690      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring pods with index for job exist @ 12/02/23 12:17:41.77
  Dec  2 12:17:41.774: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-1304" for this suite. @ 12/02/23 12:17:41.778
• [8.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:54
  STEP: Creating a kubernetes client @ 12/02/23 12:17:41.786
  Dec  2 12:17:41.786: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 12:17:41.787
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:41.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:41.808
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 12:17:41.81
  E1202 12:17:42.068892      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:43.069075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:44.069169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:45.069249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:17:45.835
  Dec  2 12:17:45.838: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-877c371b-b2f2-467e-b40b-c5723f44318a container client-container: <nil>
  STEP: delete the pod @ 12/02/23 12:17:45.845
  Dec  2 12:17:45.863: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2696" for this suite. @ 12/02/23 12:17:45.868
• [4.089 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]
test/e2e/apps/rc.go:424
  STEP: Creating a kubernetes client @ 12/02/23 12:17:45.876
  Dec  2 12:17:45.876: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replication-controller @ 12/02/23 12:17:45.876
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:45.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:45.896
  STEP: Creating ReplicationController "e2e-rc-9sc5z" @ 12/02/23 12:17:45.899
  Dec  2 12:17:45.904: INFO: Get Replication Controller "e2e-rc-9sc5z" to confirm replicas
  E1202 12:17:46.069295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:46.908: INFO: Get Replication Controller "e2e-rc-9sc5z" to confirm replicas
  Dec  2 12:17:46.919: INFO: Found 1 replicas for "e2e-rc-9sc5z" replication controller
  STEP: Getting scale subresource for ReplicationController "e2e-rc-9sc5z" @ 12/02/23 12:17:46.919
  STEP: Updating a scale subresource @ 12/02/23 12:17:46.923
  STEP: Verifying replicas where modified for replication controller "e2e-rc-9sc5z" @ 12/02/23 12:17:46.929
  Dec  2 12:17:46.929: INFO: Get Replication Controller "e2e-rc-9sc5z" to confirm replicas
  E1202 12:17:47.069748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:47.934: INFO: Get Replication Controller "e2e-rc-9sc5z" to confirm replicas
  Dec  2 12:17:47.939: INFO: Found 2 replicas for "e2e-rc-9sc5z" replication controller
  Dec  2 12:17:47.939: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-361" for this suite. @ 12/02/23 12:17:47.944
• [2.077 seconds]
------------------------------
S
------------------------------
[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]
test/e2e/common/node/podtemplates.go:53
  STEP: Creating a kubernetes client @ 12/02/23 12:17:47.954
  Dec  2 12:17:47.954: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename podtemplate @ 12/02/23 12:17:47.954
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:47.971
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:47.974
  Dec  2 12:17:48.024: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5600" for this suite. @ 12/02/23 12:17:48.028
• [0.083 seconds]
------------------------------
SSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:148
  STEP: Creating a kubernetes client @ 12/02/23 12:17:48.037
  Dec  2 12:17:48.037: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubelet-test @ 12/02/23 12:17:48.038
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:48.056
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:48.06
  E1202 12:17:48.070240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 12/02/23 12:17:48.078
  E1202 12:17:49.071306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:50.071477      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:51.071559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:52.071654      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:17:52.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-8760" for this suite. @ 12/02/23 12:17:52.101
• [4.072 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
test/e2e/apps/statefulset.go:750
  STEP: Creating a kubernetes client @ 12/02/23 12:17:52.109
  Dec  2 12:17:52.109: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 12:17:52.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:17:52.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:17:52.131
  STEP: Creating service test in namespace statefulset-1148 @ 12/02/23 12:17:52.134
  STEP: Creating stateful set ss in namespace statefulset-1148 @ 12/02/23 12:17:52.141
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1148 @ 12/02/23 12:17:52.148
  Dec  2 12:17:52.151: INFO: Found 0 stateful pods, waiting for 1
  E1202 12:17:53.072450      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:54.072617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:55.072697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:56.073160      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:57.073191      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:58.073287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:17:59.073506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:00.073592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:01.073851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:02.074699      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:02.155: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod @ 12/02/23 12:18:02.155
  Dec  2 12:18:02.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-1148 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 12:18:02.271: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 12:18:02.271: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 12:18:02.271: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 12:18:02.275: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1202 12:18:03.074808      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:04.074946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:05.074963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:06.075174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:07.075257      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:08.075339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:09.076194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:10.076298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:11.076571      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:12.077443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:12.281: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 12:18:12.281: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  2 12:18:12.296: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
  Dec  2 12:18:12.296: INFO: ss-0  ip-172-31-1-50  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:17:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:17:52 +0000 UTC  }]
  Dec  2 12:18:12.296: INFO: 
  Dec  2 12:18:12.296: INFO: StatefulSet ss has not reached scale 3, at 1
  E1202 12:18:13.077537      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:13.301: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997086759s
  E1202 12:18:14.077623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:14.306: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992164409s
  E1202 12:18:15.077675      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:15.310: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986863823s
  E1202 12:18:16.078494      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:16.314: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983030837s
  E1202 12:18:17.078991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:17.319: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978693834s
  E1202 12:18:18.079972      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:18.323: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973549171s
  E1202 12:18:19.080058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:19.327: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96940239s
  E1202 12:18:20.080676      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:20.332: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965893597s
  E1202 12:18:21.081044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:21.336: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.52254ms
  E1202 12:18:22.081879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1148 @ 12/02/23 12:18:22.336
  Dec  2 12:18:22.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-1148 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  2 12:18:22.453: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  2 12:18:22.453: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 12:18:22.453: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  2 12:18:22.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-1148 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  2 12:18:22.568: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec  2 12:18:22.568: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 12:18:22.568: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  2 12:18:22.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-1148 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  2 12:18:22.699: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
  Dec  2 12:18:22.699: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 12:18:22.699: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  2 12:18:22.702: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:18:22.702: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:18:22.702: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Scale down will not halt with unhealthy stateful pod @ 12/02/23 12:18:22.702
  Dec  2 12:18:22.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-1148 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 12:18:22.820: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 12:18:22.820: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 12:18:22.820: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 12:18:22.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-1148 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 12:18:22.941: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 12:18:22.941: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 12:18:22.941: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 12:18:22.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-1148 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 12:18:23.057: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 12:18:23.057: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 12:18:23.057: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 12:18:23.057: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  2 12:18:23.061: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E1202 12:18:23.082301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:24.082430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:25.083296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:26.083369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:27.083456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:28.083569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:29.084297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:30.084375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:31.084745      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:32.084831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:33.069: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 12:18:33.069: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 12:18:33.069: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 12:18:33.083: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
  Dec  2 12:18:33.083: INFO: ss-0  ip-172-31-1-50    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:17:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:17:52 +0000 UTC  }]
  Dec  2 12:18:33.083: INFO: ss-1  ip-172-31-74-39   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:12 +0000 UTC  }]
  Dec  2 12:18:33.083: INFO: ss-2  ip-172-31-89-192  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:12 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:12 +0000 UTC  }]
  Dec  2 12:18:33.083: INFO: 
  Dec  2 12:18:33.083: INFO: StatefulSet ss has not reached scale 0, at 3
  E1202 12:18:33.085393      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:34.086170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:34.087: INFO: POD   NODE              PHASE      GRACE  CONDITIONS
  Dec  2 12:18:34.087: INFO: ss-2  ip-172-31-89-192  Succeeded  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:12 +0000 UTC PodCompleted } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC PodCompleted } {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:23 +0000 UTC PodCompleted } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 12:18:12 +0000 UTC  }]
  Dec  2 12:18:34.087: INFO: 
  Dec  2 12:18:34.087: INFO: StatefulSet ss has not reached scale 0, at 1
  E1202 12:18:35.086224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:35.091: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.992831298s
  E1202 12:18:36.086722      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:36.095: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.988269301s
  E1202 12:18:37.086805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:37.098: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.984191869s
  E1202 12:18:38.087065      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:38.103: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.980904368s
  E1202 12:18:39.087799      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:39.107: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.976189543s
  E1202 12:18:40.088370      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:40.110: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.97261108s
  E1202 12:18:41.088455      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:41.114: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.968522571s
  E1202 12:18:42.088542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:42.119: INFO: Verifying statefulset ss doesn't scale past 0 for another 964.470425ms
  E1202 12:18:43.088857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1148 @ 12/02/23 12:18:43.12
  Dec  2 12:18:43.124: INFO: Scaling statefulset ss to 0
  Dec  2 12:18:43.136: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 12:18:43.140: INFO: Deleting all statefulset in ns statefulset-1148
  Dec  2 12:18:43.143: INFO: Scaling statefulset ss to 0
  Dec  2 12:18:43.156: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 12:18:43.159: INFO: Deleting statefulset ss
  Dec  2 12:18:43.172: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-1148" for this suite. @ 12/02/23 12:18:43.18
• [51.078 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:69
  STEP: Creating a kubernetes client @ 12/02/23 12:18:43.187
  Dec  2 12:18:43.187: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:18:43.188
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:18:43.209
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:18:43.213
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 12:18:43.218
  E1202 12:18:44.088936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:45.089284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:18:45.239
  Dec  2 12:18:45.242: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-607efb70-853e-4818-8c0b-22fa14bc7328 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 12:18:45.251
  Dec  2 12:18:45.267: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1793" for this suite. @ 12/02/23 12:18:45.27
• [2.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:157
  STEP: Creating a kubernetes client @ 12/02/23 12:18:45.278
  Dec  2 12:18:45.278: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 12:18:45.279
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:18:45.295
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:18:45.298
  STEP: Creating a pod to test emptydir volume type on node default medium @ 12/02/23 12:18:45.3
  E1202 12:18:46.089670      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:47.089754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:48.089862      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:49.090185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:18:49.321
  Dec  2 12:18:49.325: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-901d8bf1-9c1d-4f21-9d51-b762eb69fe8c container test-container: <nil>
  STEP: delete the pod @ 12/02/23 12:18:49.331
  Dec  2 12:18:49.349: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-775" for this suite. @ 12/02/23 12:18:49.353
• [4.097 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]
test/e2e/kubectl/kubectl.go:1741
  STEP: Creating a kubernetes client @ 12/02/23 12:18:49.376
  Dec  2 12:18:49.376: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 12:18:49.376
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:18:49.395
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:18:49.398
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/02/23 12:18:49.4
  Dec  2 12:18:49.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-3423 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec  2 12:18:49.453: INFO: stderr: ""
  Dec  2 12:18:49.453: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod is running @ 12/02/23 12:18:49.453
  E1202 12:18:50.091241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:51.091390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:52.091488      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:53.091583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:54.092538      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/02/23 12:18:54.505
  Dec  2 12:18:54.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-3423 get pod e2e-test-httpd-pod -o json'
  Dec  2 12:18:54.550: INFO: stderr: ""
  Dec  2 12:18:54.550: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2023-12-02T12:18:49Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3423\",\n        \"resourceVersion\": \"9375\",\n        \"uid\": \"0dbdf1cc-cc49-45c5-be6d-225fcb299660\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-76qrh\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-1-50\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-76qrh\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-02T12:18:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-02T12:18:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-02T12:18:51Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2023-12-02T12:18:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://aa8210383b47e77594c733301902fee184daf1d3711b3d88a4b76ddeca37d630\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-4\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2023-12-02T12:18:50Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.1.50\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.21.211\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.21.211\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2023-12-02T12:18:49Z\"\n    }\n}\n"
  STEP: replace the image in the pod @ 12/02/23 12:18:54.55
  Dec  2 12:18:54.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-3423 replace -f -'
  Dec  2 12:18:54.693: INFO: stderr: ""
  Dec  2 12:18:54.693: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-4 @ 12/02/23 12:18:54.693
  Dec  2 12:18:54.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-3423 delete pods e2e-test-httpd-pod'
  E1202 12:18:55.093564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:56.093643      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:18:56.097: INFO: stderr: ""
  Dec  2 12:18:56.097: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec  2 12:18:56.097: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-3423" for this suite. @ 12/02/23 12:18:56.1
• [6.732 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]
test/e2e/auth/service_accounts.go:161
  STEP: Creating a kubernetes client @ 12/02/23 12:18:56.109
  Dec  2 12:18:56.109: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svcaccounts @ 12/02/23 12:18:56.109
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:18:56.125
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:18:56.127
  Dec  2 12:18:56.147: INFO: created pod pod-service-account-defaultsa
  Dec  2 12:18:56.147: INFO: pod pod-service-account-defaultsa service account token volume mount: true
  Dec  2 12:18:56.151: INFO: created pod pod-service-account-mountsa
  Dec  2 12:18:56.151: INFO: pod pod-service-account-mountsa service account token volume mount: true
  Dec  2 12:18:56.159: INFO: created pod pod-service-account-nomountsa
  Dec  2 12:18:56.159: INFO: pod pod-service-account-nomountsa service account token volume mount: false
  Dec  2 12:18:56.164: INFO: created pod pod-service-account-defaultsa-mountspec
  Dec  2 12:18:56.164: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
  Dec  2 12:18:56.172: INFO: created pod pod-service-account-mountsa-mountspec
  Dec  2 12:18:56.172: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
  Dec  2 12:18:56.185: INFO: created pod pod-service-account-nomountsa-mountspec
  Dec  2 12:18:56.185: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
  Dec  2 12:18:56.191: INFO: created pod pod-service-account-defaultsa-nomountspec
  Dec  2 12:18:56.191: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
  Dec  2 12:18:56.202: INFO: created pod pod-service-account-mountsa-nomountspec
  Dec  2 12:18:56.202: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
  Dec  2 12:18:56.208: INFO: created pod pod-service-account-nomountsa-nomountspec
  Dec  2 12:18:56.208: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
  Dec  2 12:18:56.208: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-2225" for this suite. @ 12/02/23 12:18:56.225
• [0.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:163
  STEP: Creating a kubernetes client @ 12/02/23 12:18:56.234
  Dec  2 12:18:56.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 12:18:56.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:18:56.251
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:18:56.254
  STEP: Creating the pod @ 12/02/23 12:18:56.257
  E1202 12:18:57.094379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:58.094650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:18:59.095050      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:00.096002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:01.096100      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:02.096182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:19:02.830: INFO: Successfully updated pod "annotationupdate6a9aaf29-066a-4eb4-b2a0-dd73e9d49662"
  E1202 12:19:03.096623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:04.097147      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:19:04.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3721" for this suite. @ 12/02/23 12:19:04.85
• [8.621 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:124
  STEP: Creating a kubernetes client @ 12/02/23 12:19:04.857
  Dec  2 12:19:04.857: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pod-network-test @ 12/02/23 12:19:04.857
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:19:04.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:19:04.875
  STEP: Performing setup for networking test in namespace pod-network-test-1011 @ 12/02/23 12:19:04.877
  STEP: creating a selector @ 12/02/23 12:19:04.878
  STEP: Creating the service pods in kubernetes @ 12/02/23 12:19:04.878
  Dec  2 12:19:04.878: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1202 12:19:05.097849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:06.098046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:07.098239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:08.098414      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:09.099290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:10.099399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:11.099926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:12.100101      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:13.100467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:14.100519      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:15.101286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:16.101675      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/02/23 12:19:16.966
  E1202 12:19:17.102157      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:18.102246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:19:19.001: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  2 12:19:19.001: INFO: Going to poll 192.168.21.210 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec  2 12:19:19.003: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.21.210 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1011 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 12:19:19.003: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:19:19.004: INFO: ExecWithOptions: Clientset creation
  Dec  2 12:19:19.004: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1011/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.21.210+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1202 12:19:19.103077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:19:20.072: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec  2 12:19:20.072: INFO: Going to poll 192.168.230.57 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec  2 12:19:20.077: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.230.57 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1011 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 12:19:20.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:19:20.077: INFO: ExecWithOptions: Clientset creation
  Dec  2 12:19:20.077: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1011/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.230.57+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1202 12:19:20.103582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:21.103894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:19:21.148: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec  2 12:19:21.148: INFO: Going to poll 192.168.95.176 on port 8081 at least 0 times, with a maximum of 39 tries before failing
  Dec  2 12:19:21.152: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.95.176 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1011 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 12:19:21.152: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:19:21.152: INFO: ExecWithOptions: Clientset creation
  Dec  2 12:19:21.152: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1011/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.95.176+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1202 12:19:22.104073      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:19:22.224: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec  2 12:19:22.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-1011" for this suite. @ 12/02/23 12:19:22.228
• [17.378 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]
test/e2e/storage/subpath.go:79
  STEP: Creating a kubernetes client @ 12/02/23 12:19:22.235
  Dec  2 12:19:22.235: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename subpath @ 12/02/23 12:19:22.236
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:19:22.257
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:19:22.259
  STEP: Setting up data @ 12/02/23 12:19:22.261
  STEP: Creating pod pod-subpath-test-configmap-t86s @ 12/02/23 12:19:22.271
  STEP: Creating a pod to test atomic-volume-subpath @ 12/02/23 12:19:22.271
  E1202 12:19:23.104829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:24.105388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:25.105476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:26.105749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:27.106045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:28.106237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:29.106579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:30.107295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:31.107693      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:32.107882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:33.107969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:34.108520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:35.108612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:36.108971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:37.109725      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:38.109815      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:39.110230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:40.110314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:41.110703      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:42.111289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:43.111379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:44.111544      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:45.112543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:46.113327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:19:46.334
  Dec  2 12:19:46.337: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-subpath-test-configmap-t86s container test-container-subpath-configmap-t86s: <nil>
  STEP: delete the pod @ 12/02/23 12:19:46.343
  STEP: Deleting pod pod-subpath-test-configmap-t86s @ 12/02/23 12:19:46.359
  Dec  2 12:19:46.359: INFO: Deleting pod "pod-subpath-test-configmap-t86s" in namespace "subpath-3060"
  Dec  2 12:19:46.361: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-3060" for this suite. @ 12/02/23 12:19:46.366
• [24.137 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should get a host IP [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:205
  STEP: Creating a kubernetes client @ 12/02/23 12:19:46.374
  Dec  2 12:19:46.374: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 12:19:46.374
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:19:46.39
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:19:46.393
  STEP: creating pod @ 12/02/23 12:19:46.395
  E1202 12:19:47.113580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:48.113678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:19:48.418: INFO: Pod pod-hostip-cdf9d88c-0184-413e-9bd1-70d473aaa166 has hostIP: 172.31.1.50
  Dec  2 12:19:48.418: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4415" for this suite. @ 12/02/23 12:19:48.421
• [2.065 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:47
  STEP: Creating a kubernetes client @ 12/02/23 12:19:48.439
  Dec  2 12:19:48.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 12:19:48.44
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:19:48.475
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:19:48.477
  STEP: Creating secret with name secret-test-db675103-e2b2-40d5-9c2a-b9f7e062a39e @ 12/02/23 12:19:48.479
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:19:48.485
  E1202 12:19:49.114401      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:50.114582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:51.114838      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:52.115050      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:19:52.51
  Dec  2 12:19:52.513: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-secrets-e991abed-ade2-45d9-be0e-e3c2bfcbc8ac container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:19:52.518
  Dec  2 12:19:52.536: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8235" for this suite. @ 12/02/23 12:19:52.54
• [4.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:250
  STEP: Creating a kubernetes client @ 12/02/23 12:19:52.548
  Dec  2 12:19:52.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 12:19:52.549
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:19:52.564
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:19:52.566
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 12:19:52.569
  E1202 12:19:53.115128      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:54.115201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:55.115330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:56.115734      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:19:56.587
  Dec  2 12:19:56.590: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-95846ae9-101a-465e-94a7-96d03bd8e4c5 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 12:19:56.596
  Dec  2 12:19:56.611: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-4506" for this suite. @ 12/02/23 12:19:56.614
• [4.078 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]
test/e2e/kubectl/kubectl.go:1316
  STEP: Creating a kubernetes client @ 12/02/23 12:19:56.627
  Dec  2 12:19:56.627: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 12:19:56.627
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:19:56.646
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:19:56.648
  STEP: validating cluster-info @ 12/02/23 12:19:56.65
  Dec  2 12:19:56.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7785 cluster-info'
  Dec  2 12:19:56.697: INFO: stderr: ""
  Dec  2 12:19:56.697: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
  Dec  2 12:19:56.697: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7785" for this suite. @ 12/02/23 12:19:56.702
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:215
  STEP: Creating a kubernetes client @ 12/02/23 12:19:56.71
  Dec  2 12:19:56.710: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:19:56.711
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:19:56.727
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:19:56.729
  STEP: Creating secret with name s-test-opt-del-d60a5a7a-8f79-4be3-b34e-77398b55137b @ 12/02/23 12:19:56.734
  STEP: Creating secret with name s-test-opt-upd-114c9b66-4dd7-4b59-b664-ceb8ff4a37a8 @ 12/02/23 12:19:56.737
  STEP: Creating the pod @ 12/02/23 12:19:56.742
  E1202 12:19:57.116114      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:19:58.116470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting secret s-test-opt-del-d60a5a7a-8f79-4be3-b34e-77398b55137b @ 12/02/23 12:19:58.782
  STEP: Updating secret s-test-opt-upd-114c9b66-4dd7-4b59-b664-ceb8ff4a37a8 @ 12/02/23 12:19:58.787
  STEP: Creating secret with name s-test-opt-create-1e27a585-22c6-47d1-b176-db1c7672a88a @ 12/02/23 12:19:58.793
  STEP: waiting to observe update in volume @ 12/02/23 12:19:58.796
  E1202 12:19:59.117142      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:00.117269      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:01.117440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:02.117536      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:03.118480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:04.118586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:05.119498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:06.119604      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:07.120364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:08.120461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:09.121487      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:10.121715      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:11.122272      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:12.123297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:13.123855      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:14.124134      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:15.124203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:16.124327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:17.124828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:18.124943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:19.125127      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:20.125289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:21.126051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:22.126215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:23.127144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:24.127302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:25.127345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:26.127719      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:27.128258      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:28.128348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:29.129198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:30.129354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:31.130176      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:32.130241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:33.131280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:34.131368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:35.131549      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:36.132110      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:37.132981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:38.133461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:39.134429      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:40.135297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:41.135767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:42.135921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:43.136910      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:44.137072      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:45.137461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:46.137995      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:47.138614      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:48.139417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:49.139850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:50.139960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:51.140524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:52.140608      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:53.141075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:54.141179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:55.142058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:56.142234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:57.142915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:58.143018      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:20:59.143038      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:00.143155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:01.143618      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:02.143719      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:03.144744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:04.145759      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:05.145768      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:06.146140      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:07.146329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:08.146463      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:09.078: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6797" for this suite. @ 12/02/23 12:21:09.081
• [72.378 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:134
  STEP: Creating a kubernetes client @ 12/02/23 12:21:09.089
  Dec  2 12:21:09.089: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 12:21:09.09
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:21:09.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:21:09.109
  STEP: Creating pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335 @ 12/02/23 12:21:09.111
  E1202 12:21:09.147261      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:10.147627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 12:21:11.128
  Dec  2 12:21:11.131: INFO: Initial restart count of pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 is 0
  Dec  2 12:21:11.134: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:11.148493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:12.148633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:13.138: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:13.148966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:14.149146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:15.142: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:15.149648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:16.149871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:17.147: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:17.150360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:18.151309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:19.150: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:19.151724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:20.151849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:21.152121      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:21.154: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:22.152253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:23.152350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:23.158: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:24.153046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:25.153901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:25.162: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:26.154395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:27.154490      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:27.167: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:28.154583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:29.154662      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:29.171: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:30.155284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:31.155359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:31.174: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:32.155712      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:33.155963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:33.178: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:34.156055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:35.156152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:35.182: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:36.157042      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:37.157135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:37.186: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:38.157422      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:39.157493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:39.192: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:40.157583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:41.157833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:41.196: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:42.158235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:43.159307      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:43.201: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:44.160186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:45.160255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:45.205: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:46.160404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:47.160488      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:47.211: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:48.161271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:49.161448      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:49.215: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:50.162140      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:51.162233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:51.218: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:52.162339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:53.162395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:53.222: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:54.162500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:55.163294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:55.226: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:56.164196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:57.164252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:57.231: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:21:58.164373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:21:59.164451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:21:59.234: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  E1202 12:22:00.164496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:01.165387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:22:01.239: INFO: Get pod busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 in namespace container-probe-8335
  Dec  2 12:22:01.239: INFO: Restart count of pod container-probe-8335/busybox-1dbc2e0b-2578-41a8-a905-0a8aafffcf19 is now 1 (50.107221098s elapsed)
  Dec  2 12:22:01.239: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 12:22:01.242
  STEP: Destroying namespace "container-probe-8335" for this suite. @ 12/02/23 12:22:01.261
• [52.181 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:147
  STEP: Creating a kubernetes client @ 12/02/23 12:22:01.272
  Dec  2 12:22:01.272: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 12:22:01.272
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:22:01.288
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:22:01.291
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/02/23 12:22:01.293
  E1202 12:22:02.165438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:03.165557      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:04.165925      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:05.166032      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:22:05.321
  Dec  2 12:22:05.325: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-bd7ed9c1-0b26-46eb-9af8-33bb1837f06c container test-container: <nil>
  STEP: delete the pod @ 12/02/23 12:22:05.331
  Dec  2 12:22:05.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-3801" for this suite. @ 12/02/23 12:22:05.355
• [4.089 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:113
  STEP: Creating a kubernetes client @ 12/02/23 12:22:05.362
  Dec  2 12:22:05.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 12:22:05.362
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:22:05.38
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:22:05.383
  Dec  2 12:22:05.385: INFO: Creating deployment "test-recreate-deployment"
  Dec  2 12:22:05.390: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
  Dec  2 12:22:05.395: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
  E1202 12:22:06.166238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:07.167278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:22:07.404: INFO: Waiting deployment "test-recreate-deployment" to complete
  Dec  2 12:22:07.407: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
  Dec  2 12:22:07.415: INFO: Updating deployment test-recreate-deployment
  Dec  2 12:22:07.415: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
  Dec  2 12:22:07.494: INFO: Deployment "test-recreate-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=24) "test-recreate-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8008",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d4a4c29b-8aaf-4ac0-b674-64720851bad4",
      ResourceVersion: (string) (len=5) "10401",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=570) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |":{"f:type":{}},|
              000000b0  22 66 3a 74 65 6d 70 6c  61 74 65 22 3a 7b 22 66  |"f:template":{"f|
              000000c0  3a 6d 65 74 61 64 61 74  61 22 3a 7b 22 66 3a 6c  |:metadata":{"f:l|
              000000d0  61 62 65 6c 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |abels":{".":{},"|
              000000e0  66 3a 6e 61 6d 65 22 3a  7b 7d 7d 7d 2c 22 66 3a  |f:name":{}}},"f:|
              000000f0  73 70 65 63 22 3a 7b 22  66 3a 63 6f 6e 74 61 69  |spec":{"f:contai|
              00000100  6e 65 72 73 22 3a 7b 22  6b 3a 7b 5c 22 6e 61 6d  |ners":{"k:{\"nam|
              00000110  65 5c 22 3a 5c 22 68 74  74 70 64 5c 22 7d 22 3a  |e\":\"httpd\"}":|
              00000120  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |{".":{},"f:image|
              00000130  22 3a 7b 7d 2c 22 66 3a  69 6d 61 67 65 50 75 6c  |":{},"f:imagePul|
              00000140  6c 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 6e  |lPolicy":{},"f:n|
              00000150  61 6d 65 22 3a 7b 7d 2c  22 66 3a 72 65 73 6f 75  |ame":{},"f:resou|
              00000160  72 63 65 73 22 3a 7b 7d  2c 22 66 3a 73 65 63 75  |rces":{},"f:secu|
              00000170  72 69 74 79 43 6f 6e 74  65 78 74 22 3a 7b 7d 2c  |rityContext":{},|
              00000180  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000190  73 73 61 67 65 50 61 74  68 22 3a 7b 7d 2c 22 66  |ssagePath":{},"f|
              000001a0  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 4d 65 73 73  |:terminationMess|
              000001b0  61 67 65 50 6f 6c 69 63  79 22 3a 7b 7d 7d 7d 2c  |agePolicy":{}}},|
              000001c0  22 66 3a 64 6e 73 50 6f  6c 69 63 79 22 3a 7b 7d  |"f:dnsPolicy":{}|
              000001d0  2c 22 66 3a 72 65 73 74  61 72 74 50 6f 6c 69 63  |,"f:restartPolic|
              000001e0  79 22 3a 7b 7d 2c 22 66  3a 73 63 68 65 64 75 6c  |y":{},"f:schedul|
              000001f0  65 72 4e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 73 65  |erName":{},"f:se|
              00000200  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000210  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000220  47 72 61 63 65 50 65 72  69 6f 64 53 65 63 6f 6e  |GracePeriodSecon|
              00000230  64 73 22 3a 7b 7d 7d 7d  7d 7d                    |ds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=495) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 63 6f 6e 64 69 74 69  6f 6e 73 22 3a 7b 22 2e  |:conditions":{".|
              00000070  22 3a 7b 7d 2c 22 6b 3a  7b 5c 22 74 79 70 65 5c  |":{},"k:{\"type\|
              00000080  22 3a 5c 22 41 76 61 69  6c 61 62 6c 65 5c 22 7d  |":\"Available\"}|
              00000090  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 6c 61 73  |":{".":{},"f:las|
              000000a0  74 54 72 61 6e 73 69 74  69 6f 6e 54 69 6d 65 22  |tTransitionTime"|
              000000b0  3a 7b 7d 2c 22 66 3a 6c  61 73 74 55 70 64 61 74  |:{},"f:lastUpdat|
              000000c0  65 54 69 6d 65 22 3a 7b  7d 2c 22 66 3a 6d 65 73  |eTime":{},"f:mes|
              000000d0  73 61 67 65 22 3a 7b 7d  2c 22 66 3a 72 65 61 73  |sage":{},"f:reas|
              000000e0  6f 6e 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |on":{},"f:status|
              000000f0  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000100  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              00000110  22 50 72 6f 67 72 65 73  73 69 6e 67 5c 22 7d 22  |"Progressing\"}"|
              00000120  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              00000130  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000140  7b 7d 2c 22 66 3a 6c 61  73 74 55 70 64 61 74 65  |{},"f:lastUpdate|
              00000150  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6d 65 73 73  |Time":{},"f:mess|
              00000160  61 67 65 22 3a 7b 7d 2c  22 66 3a 72 65 61 73 6f  |age":{},"f:reaso|
              00000170  6e 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |n":{},"f:status"|
              00000180  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000190  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              000001a0  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              000001b0  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 75  |eplicas":{},"f:u|
              000001c0  6e 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |navailableReplic|
              000001d0  61 73 22 3a 7b 7d 2c 22  66 3a 75 70 64 61 74 65  |as":{},"f:update|
              000001e0  64 52 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 7d     |dReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=8) "Recreate",
        RollingUpdate: (*v1.RollingUpdateDeployment)(<nil>)
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      UnavailableReplicas: (int32) 1,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=26) "MinimumReplicasUnavailable",
          Message: (string) (len=46) "Deployment does not have minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116525,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=63) "ReplicaSet \"test-recreate-deployment-76fb77d45\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  2 12:22:07.497: INFO: New ReplicaSet "test-recreate-deployment-76fb77d45" of Deployment "test-recreate-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8008",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d82aaa52-dac1-4d88-9726-a96ca8b5d580",
      ResourceVersion: (string) (len=5) "10398",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "d4a4c29b-8aaf-4ac0-b674-64720851bad4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 34 61 34 63 32  39 62 2d 38 61 61 66 2d  |\"d4a4c29b-8aaf-|
              00000120  34 61 63 30 2d 62 36 37  34 2d 36 34 37 32 30 38  |4ac0-b674-647208|
              00000130  35 31 62 61 64 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |51bad4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:22:07.499: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
  Dec  2 12:22:07.500: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=34) "test-recreate-deployment-dd4bc9d6d",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-8008",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "345e2b69-bc50-40b1-ab63-e0c2b1b9bcc8",
      ResourceVersion: (string) (len=5) "10390",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116525,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "1",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=24) "test-recreate-deployment",
          UID: (types.UID) (len=36) "d4a4c29b-8aaf-4ac0-b674-64720851bad4",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 64 34 61 34 63 32  39 62 2d 38 61 61 66 2d  |\"d4a4c29b-8aaf-|
              00000120  34 61 63 30 2d 62 36 37  34 2d 36 34 37 32 30 38  |4ac0-b674-647208|
              00000130  35 31 62 61 64 34 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |51bad4\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=12) "sample-pod-3",
          (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=12) "sample-pod-3",
            (string) (len=17) "pod-template-hash": (string) (len=9) "dd4bc9d6d"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:22:07.503: INFO: Pod "test-recreate-deployment-76fb77d45-jtv24" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-recreate-deployment-76fb77d45-jtv24",
      GenerateName: (string) (len=35) "test-recreate-deployment-76fb77d45-",
      Namespace: (string) (len=15) "deployment-8008",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3a953d82-a3cf-4507-b37e-3885486bc8c3",
      ResourceVersion: (string) (len=5) "10402",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=12) "sample-pod-3",
        (string) (len=17) "pod-template-hash": (string) (len=9) "76fb77d45"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=34) "test-recreate-deployment-76fb77d45",
          UID: (types.UID) (len=36) "d82aaa52-dac1-4d88-9726-a96ca8b5d580",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 64 38  32 61 61 61 35 32 2d 64  |d\":\"d82aaa52-d|
              00000090  61 63 31 2d 34 64 38 38  2d 39 37 32 36 2d 61 39  |ac1-4d88-9726-a9|
              000000a0  36 63 61 38 62 35 64 35  38 30 5c 22 7d 22 3a 7b  |6ca8b5d580\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=482) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 73 74 61 72 74  54 69 6d 65 22 3a 7b 7d  |"f:startTime":{}|
              000001e0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-qls5k",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-qls5k",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837116527,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837116527,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=17) "ContainerCreating",
              Message: (string) ""
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 12:22:07.505: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-8008" for this suite. @ 12/02/23 12:22:07.508
• [2.151 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:61
  STEP: Creating a kubernetes client @ 12/02/23 12:22:07.517
  Dec  2 12:22:07.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename containers @ 12/02/23 12:22:07.517
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:22:07.536
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:22:07.538
  STEP: Creating a pod to test override arguments @ 12/02/23 12:22:07.541
  E1202 12:22:08.168157      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:09.168250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:10.168569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:11.168653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:22:11.562
  Dec  2 12:22:11.566: INFO: Trying to get logs from node ip-172-31-1-50 pod client-containers-7d7b5fde-cc32-42b8-9e8c-82a874032b17 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:22:11.571
  Dec  2 12:22:11.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-5526" for this suite. @ 12/02/23 12:22:11.597
• [4.087 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]
test/e2e/auth/subjectreviews.go:50
  STEP: Creating a kubernetes client @ 12/02/23 12:22:11.604
  Dec  2 12:22:11.604: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename subjectreview @ 12/02/23 12:22:11.605
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:22:11.623
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:22:11.626
  STEP: Creating a Serviceaccount "e2e" in namespace "subjectreview-4637" @ 12/02/23 12:22:11.629
  Dec  2 12:22:11.633: INFO: saUsername: "system:serviceaccount:subjectreview-4637:e2e"
  Dec  2 12:22:11.633: INFO: saGroups: []string{"system:authenticated", "system:serviceaccounts", "system:serviceaccounts:subjectreview-4637"}
  Dec  2 12:22:11.633: INFO: saUID: "5f32a948-f9f0-480d-ad89-6b705eef3939"
  STEP: Creating clientset to impersonate "system:serviceaccount:subjectreview-4637:e2e" @ 12/02/23 12:22:11.633
  STEP: Creating SubjectAccessReview for "system:serviceaccount:subjectreview-4637:e2e" @ 12/02/23 12:22:11.633
  Dec  2 12:22:11.634: INFO: sarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  STEP: Verifying as "system:serviceaccount:subjectreview-4637:e2e" api 'list' configmaps in "subjectreview-4637" namespace @ 12/02/23 12:22:11.634
  Dec  2 12:22:11.635: INFO: SubjectAccessReview has been verified
  STEP: Creating a LocalSubjectAccessReview for "system:serviceaccount:subjectreview-4637:e2e" @ 12/02/23 12:22:11.635
  Dec  2 12:22:11.637: INFO: lsarResponse Status: v1.SubjectAccessReviewStatus{Allowed:false, Denied:false, Reason:"", EvaluationError:""}
  Dec  2 12:22:11.637: INFO: LocalSubjectAccessReview has been verified
  Dec  2 12:22:11.637: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subjectreview-4637" for this suite. @ 12/02/23 12:22:11.643
• [0.045 seconds]
------------------------------
SS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:55
  STEP: Creating a kubernetes client @ 12/02/23 12:22:11.65
  Dec  2 12:22:11.650: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename runtimeclass @ 12/02/23 12:22:11.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:22:11.665
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:22:11.667
  Dec  2 12:22:11.676: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-3179" for this suite. @ 12/02/23 12:22:11.681
• [0.038 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:398
  STEP: Creating a kubernetes client @ 12/02/23 12:22:11.688
  Dec  2 12:22:11.688: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename namespaces @ 12/02/23 12:22:11.688
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:22:11.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:22:11.704
  STEP: Creating namespace "e2e-ns-z5p2f" @ 12/02/23 12:22:11.706
  Dec  2 12:22:11.726: INFO: Namespace "e2e-ns-z5p2f-3698" has []v1.FinalizerName{"kubernetes"}
  STEP: Adding e2e finalizer to namespace "e2e-ns-z5p2f-3698" @ 12/02/23 12:22:11.726
  Dec  2 12:22:11.737: INFO: Namespace "e2e-ns-z5p2f-3698" has []v1.FinalizerName{"kubernetes", "e2e.example.com/fakeFinalizer"}
  STEP: Removing e2e finalizer from namespace "e2e-ns-z5p2f-3698" @ 12/02/23 12:22:11.737
  Dec  2 12:22:11.746: INFO: Namespace "e2e-ns-z5p2f-3698" has []v1.FinalizerName{"kubernetes"}
  Dec  2 12:22:11.746: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-6356" for this suite. @ 12/02/23 12:22:11.75
  STEP: Destroying namespace "e2e-ns-z5p2f-3698" for this suite. @ 12/02/23 12:22:11.755
• [0.075 seconds]
------------------------------
S
------------------------------
[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
test/e2e/apps/cronjob.go:125
  STEP: Creating a kubernetes client @ 12/02/23 12:22:11.762
  Dec  2 12:22:11.762: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename cronjob @ 12/02/23 12:22:11.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:22:11.777
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:22:11.78
  STEP: Creating a ForbidConcurrent cronjob @ 12/02/23 12:22:11.782
  STEP: Ensuring a job is scheduled @ 12/02/23 12:22:11.788
  E1202 12:22:12.169524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:13.169728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:14.170067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:15.170311      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:16.171268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:17.171424      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:18.172103      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:19.172299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:20.172930      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:21.173984      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:22.174714      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:23.174803      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:24.175280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:25.175367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:26.175846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:27.175985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:28.176991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:29.177054      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:30.177430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:31.177594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:32.177727      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:33.178568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:34.179250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:35.179461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:36.180323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:37.180412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:38.181116      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:39.181894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:40.182644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:41.182753      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:42.182792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:43.182860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:44.183469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:45.183683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:46.184378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:47.184503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:48.184590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:49.185424      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:50.185623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:51.185917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:52.186228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:53.186265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:54.187246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:55.187351      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:56.188199      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:57.188432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:58.188521      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:22:59.188674      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:00.188775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:01.188890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 12/02/23 12:23:01.792
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/02/23 12:23:01.795
  STEP: Ensuring no more jobs are scheduled @ 12/02/23 12:23:01.799
  E1202 12:23:02.189664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:03.189747      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:04.190691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:05.190781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:06.191030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:07.191105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:08.191173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:09.191264      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:10.191384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:11.191462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:12.192306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:13.192490      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:14.192570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:15.192676      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:16.192752      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:17.192849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:18.192937      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:19.193113      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:20.193195      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:21.193293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:22.193376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:23.193561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:24.194542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:25.194625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:26.194828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:27.194913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:28.195567      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:29.195666      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:30.195981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:31.196196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:32.196442      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:33.196641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:34.197412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:35.198357      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:36.199317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:37.199493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:38.199997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:39.200612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:40.200725      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:41.200795      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:42.200897      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:43.201126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:44.201203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:45.201283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:46.201947      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:47.202139      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:48.202552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:49.202632      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:50.203258      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:51.203505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:52.203621      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:53.204181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:54.204275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:55.204452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:56.204898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:57.205178      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:58.205895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:23:59.206084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:00.206137      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:01.206220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:02.206321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:03.207313      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:04.207675      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:05.207851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:06.208638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:07.208791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:08.208889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:09.208970      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:10.209523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:11.209782      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:12.210095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:13.210258      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:14.210578      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:15.210514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:16.210828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:17.211774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:18.212401      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:19.212589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:20.212893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:21.212991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:22.213521      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:23.213759      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:24.214327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:25.214415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:26.214981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:27.215276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:28.215369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:29.215952      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:30.216006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:31.216464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:32.217132      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:33.217227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:34.218056      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:35.218214      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:36.218963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:37.219275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:38.219883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:39.220259      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:40.220904      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:41.221237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:42.221533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:43.221625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:44.221963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:45.222154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:46.223082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:47.223365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:48.224054      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:49.224163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:50.224729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:51.224812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:52.225007      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:53.226054      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:54.226852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:55.227824      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:56.228833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:57.228880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:58.229255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:24:59.229407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:00.229496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:01.229786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:02.229888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:03.230582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:04.231108      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:05.231307      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:06.231879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:07.232535      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:08.233158      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:09.233893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:10.234950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:11.235091      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:12.235181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:13.235350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:14.235436      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:15.236164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:16.236859      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:17.237196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:18.237567      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:19.237767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:20.238468      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:21.238553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:22.239097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:23.239197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:24.239269      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:25.239362      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:26.239446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:27.239611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:28.239978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:29.240066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:30.240273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:31.240614      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:32.241250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:33.241881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:34.242146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:35.242216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:36.242834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:37.242913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:38.243000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:39.243281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:40.243533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:41.243850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:42.243984      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:43.244179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:44.244926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:45.245083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:46.245411      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:47.245503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:48.246068      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:49.246217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:50.246306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:51.247359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:52.247904      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:53.247986      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:54.248043      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:55.248149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:56.248226      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:57.248777      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:58.248948      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:25:59.249081      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:00.249622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:01.249870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:02.250212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:03.250334      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:04.250397      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:05.251280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:06.252008      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:07.252173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:08.253093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:09.253240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:10.253633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:11.254536      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:12.255560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:13.256592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:14.256870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:15.256783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:16.257347      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:17.257403      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:18.257476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:19.257584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:20.258402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:21.259279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:22.259611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:23.260551      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:24.260610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:25.261588      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:26.261679      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:27.261851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:28.262009      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:29.262174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:30.262299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:31.263281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:32.264192      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:33.265282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:34.265361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:35.266325      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:36.267284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:37.267447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:38.267833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:39.267991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:40.268322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:41.268402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:42.268755      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:43.268989      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:44.269824      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:45.270040      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:46.270733      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:47.270935      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:48.271283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:49.271443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:50.272321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:51.272418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:52.273207      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:53.273348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:54.273626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:55.273818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:56.273981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:57.274078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:58.274281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:26:59.275284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:00.275367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:01.276059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:02.276546      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:03.276780      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:04.277170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:05.277348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:06.277700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:07.277783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:08.278720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:09.278828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:10.278910      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:11.279097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:12.279375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:13.279539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:14.280152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:15.280311      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:16.280439      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:17.280644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:18.280922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:19.281019      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:20.281874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:21.281963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:22.282224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:23.283293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:24.283633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:25.283690      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:26.284270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:27.284444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:28.285343      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:29.285443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:30.286216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:31.286232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:32.286980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:33.287366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:34.287459      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:35.287550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:36.288003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:37.288169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:38.288634      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:39.288802      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:40.288901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:41.289148      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:42.290051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:43.290225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:44.291284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:45.291443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:46.292034      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:47.292240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:48.292322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:49.292491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:50.292875      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:51.293096      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:52.293298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:53.293910      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:54.294603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:55.294692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:56.294956      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:57.295046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:58.296130      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:27:59.296419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:00.297301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:01.297614      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 12/02/23 12:28:01.807
  Dec  2 12:28:01.812: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-369" for this suite. @ 12/02/23 12:28:01.816
• [350.062 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]
test/e2e/apps/disruption.go:87
  STEP: Creating a kubernetes client @ 12/02/23 12:28:01.824
  Dec  2 12:28:01.824: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename disruption @ 12/02/23 12:28:01.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:28:01.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:28:01.848
  STEP: Creating a kubernetes client @ 12/02/23 12:28:01.85
  Dec  2 12:28:01.850: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename disruption-2 @ 12/02/23 12:28:01.851
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:28:01.868
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:28:01.87
  STEP: Waiting for the pdb to be processed @ 12/02/23 12:28:01.882
  STEP: Waiting for the pdb to be processed @ 12/02/23 12:28:01.891
  STEP: Waiting for the pdb to be processed @ 12/02/23 12:28:01.901
  STEP: listing a collection of PDBs across all namespaces @ 12/02/23 12:28:01.906
  STEP: listing a collection of PDBs in namespace disruption-6387 @ 12/02/23 12:28:01.91
  STEP: deleting a collection of PDBs @ 12/02/23 12:28:01.913
  STEP: Waiting for the PDB collection to be deleted @ 12/02/23 12:28:01.926
  Dec  2 12:28:01.928: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 12:28:01.933: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-2-4576" for this suite. @ 12/02/23 12:28:01.936
  STEP: Destroying namespace "disruption-6387" for this suite. @ 12/02/23 12:28:01.943
• [0.125 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:262
  STEP: Creating a kubernetes client @ 12/02/23 12:28:01.951
  Dec  2 12:28:01.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 12:28:01.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:28:01.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:28:01.969
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 12:28:01.971
  E1202 12:28:02.298098      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:03.298235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:04.299242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:05.300153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:28:05.996
  Dec  2 12:28:05.999: INFO: Trying to get logs from node ip-172-31-74-39 pod downwardapi-volume-eb9a9b64-3509-42c0-90c1-48d07ef4e5ad container client-container: <nil>
  STEP: delete the pod @ 12/02/23 12:28:06.015
  Dec  2 12:28:06.034: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-9364" for this suite. @ 12/02/23 12:28:06.037
• [4.093 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:236
  STEP: Creating a kubernetes client @ 12/02/23 12:28:06.044
  Dec  2 12:28:06.044: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 12:28:06.045
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:28:06.062
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:28:06.065
  Dec  2 12:28:06.067: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 12:28:06.301188      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:07.302065      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/02/23 12:28:07.368
  Dec  2 12:28:07.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-3457 --namespace=crd-publish-openapi-3457 create -f -'
  E1202 12:28:08.302694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:09.303287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:28:09.647: INFO: stderr: ""
  Dec  2 12:28:09.647: INFO: stdout: "e2e-test-crd-publish-openapi-1270-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec  2 12:28:09.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-3457 --namespace=crd-publish-openapi-3457 delete e2e-test-crd-publish-openapi-1270-crds test-cr'
  Dec  2 12:28:09.724: INFO: stderr: ""
  Dec  2 12:28:09.724: INFO: stdout: "e2e-test-crd-publish-openapi-1270-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  Dec  2 12:28:09.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-3457 --namespace=crd-publish-openapi-3457 apply -f -'
  Dec  2 12:28:09.841: INFO: stderr: ""
  Dec  2 12:28:09.841: INFO: stdout: "e2e-test-crd-publish-openapi-1270-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
  Dec  2 12:28:09.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-3457 --namespace=crd-publish-openapi-3457 delete e2e-test-crd-publish-openapi-1270-crds test-cr'
  Dec  2 12:28:09.898: INFO: stderr: ""
  Dec  2 12:28:09.898: INFO: stdout: "e2e-test-crd-publish-openapi-1270-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/02/23 12:28:09.898
  Dec  2 12:28:09.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-3457 explain e2e-test-crd-publish-openapi-1270-crds'
  Dec  2 12:28:10.227: INFO: stderr: ""
  Dec  2 12:28:10.227: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-in-nested.example.com\nKIND:       e2e-test-crd-publish-openapi-1270-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties in nested field for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E1202 12:28:10.303833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:11.303887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:28:11.523: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3457" for this suite. @ 12/02/23 12:28:11.532
• [5.495 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:423
  STEP: Creating a kubernetes client @ 12/02/23 12:28:11.542
  Dec  2 12:28:11.542: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:28:11.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:28:11.56
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:28:11.562
  STEP: Creating configMap with name configmap-test-volume-605ccbaa-883f-435d-bc28-ce20f6ef7511 @ 12/02/23 12:28:11.565
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:28:11.569
  E1202 12:28:12.304797      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:13.304889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:14.304978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:15.305065      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:28:15.593
  Dec  2 12:28:15.597: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-c2ef435e-aae3-4331-84a5-831f41204ac3 container configmap-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:28:15.615
  Dec  2 12:28:15.630: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1830" for this suite. @ 12/02/23 12:28:15.634
• [4.098 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]
test/e2e/apimachinery/webhook.go:199
  STEP: Creating a kubernetes client @ 12/02/23 12:28:15.642
  Dec  2 12:28:15.642: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 12:28:15.643
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:28:15.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:28:15.659
  STEP: Setting up server cert @ 12/02/23 12:28:15.682
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 12:28:15.907
  STEP: Deploying the webhook pod @ 12/02/23 12:28:15.915
  STEP: Wait for the deployment to be ready @ 12/02/23 12:28:15.928
  Dec  2 12:28:15.934: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1202 12:28:16.305178      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:17.305403      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 12:28:17.946
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 12:28:17.958
  E1202 12:28:18.305989      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:28:18.959: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/02/23 12:28:18.966
  STEP: create a pod that should be denied by the webhook @ 12/02/23 12:28:18.982
  STEP: create a pod that causes the webhook to hang @ 12/02/23 12:28:18.991
  E1202 12:28:19.306550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:20.307498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:21.307568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:22.307652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:23.307808      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:24.307908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:25.307991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:26.308281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:27.308373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:28.308551      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create a configmap that should be denied by the webhook @ 12/02/23 12:28:28.999
  STEP: create a configmap that should be admitted by the webhook @ 12/02/23 12:28:29.038
  STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/02/23 12:28:29.048
  STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook @ 12/02/23 12:28:29.056
  STEP: create a namespace that bypass the webhook @ 12/02/23 12:28:29.062
  STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace @ 12/02/23 12:28:29.077
  Dec  2 12:28:29.085: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-5469" for this suite. @ 12/02/23 12:28:29.138
  STEP: Destroying namespace "webhook-markers-6007" for this suite. @ 12/02/23 12:28:29.147
  STEP: Destroying namespace "exempted-namespace-396" for this suite. @ 12/02/23 12:28:29.154
• [13.519 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]
test/e2e/apps/statefulset.go:331
  STEP: Creating a kubernetes client @ 12/02/23 12:28:29.163
  Dec  2 12:28:29.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 12:28:29.163
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:28:29.175
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:28:29.178
  STEP: Creating service test in namespace statefulset-7692 @ 12/02/23 12:28:29.181
  STEP: Creating a new StatefulSet @ 12/02/23 12:28:29.189
  Dec  2 12:28:29.203: INFO: Found 0 stateful pods, waiting for 3
  E1202 12:28:29.308970      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:30.309141      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:31.309220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:32.309332      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:33.309475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:34.309586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:35.309804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:36.310255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:37.310241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:38.310337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:28:39.208: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:28:39.208: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:28:39.208: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/02/23 12:28:39.218
  Dec  2 12:28:39.238: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/02/23 12:28:39.238
  E1202 12:28:39.310406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:40.310511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:41.310593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:42.310674      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:43.311312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:44.311494      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:45.312466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:46.312487      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:47.312658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:48.312880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not applying an update when the partition is greater than the number of replicas @ 12/02/23 12:28:49.257
  STEP: Performing a canary update @ 12/02/23 12:28:49.257
  Dec  2 12:28:49.277: INFO: Updating stateful set ss2
  Dec  2 12:28:49.290: INFO: Waiting for Pod statefulset-7692/ss2-2 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1202 12:28:49.313940      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:50.314056      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:51.314222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:52.314316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:53.315314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:54.315412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:55.315593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:56.316027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:57.316098      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:28:58.316268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Restoring Pods to the correct revision when they are deleted @ 12/02/23 12:28:59.298
  E1202 12:28:59.317280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:28:59.364: INFO: Found 1 stateful pods, waiting for 3
  E1202 12:29:00.317465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:01.318338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:02.319303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:03.320374      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:04.320458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:05.320548      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:06.320946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:07.321102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:08.321189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:09.321345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:09.369: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:29:09.369: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:29:09.369: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Performing a phased rolling update @ 12/02/23 12:29:09.376
  Dec  2 12:29:09.394: INFO: Updating stateful set ss2
  Dec  2 12:29:09.401: INFO: Waiting for Pod statefulset-7692/ss2-1 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1202 12:29:10.321454      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:11.322314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:12.323299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:13.326256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:14.326345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:15.326434      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:16.327367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:17.327460      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:18.327550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:19.327640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:19.431: INFO: Updating stateful set ss2
  Dec  2 12:29:19.454: INFO: Waiting for StatefulSet statefulset-7692/ss2 to complete update
  Dec  2 12:29:19.454: INFO: Waiting for Pod statefulset-7692/ss2-0 to have revision ss2-5459d8585b update revision ss2-7b6c9599d5
  E1202 12:29:20.328377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:21.328462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:22.328621      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:23.328740      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:24.328940      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:25.329004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:26.329345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:27.329431      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:28.329640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:29.329911      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:29.463: INFO: Deleting all statefulset in ns statefulset-7692
  Dec  2 12:29:29.467: INFO: Scaling statefulset ss2 to 0
  E1202 12:29:30.329996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:31.330266      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:32.330352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:33.330440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:34.331289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:35.331387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:36.331556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:37.331641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:38.331720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:39.331790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:39.486: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 12:29:39.489: INFO: Deleting statefulset ss2
  Dec  2 12:29:39.510: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7692" for this suite. @ 12/02/23 12:29:39.516
• [70.361 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]
test/e2e/apps/daemon_set.go:305
  STEP: Creating a kubernetes client @ 12/02/23 12:29:39.525
  Dec  2 12:29:39.525: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename daemonsets @ 12/02/23 12:29:39.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:29:39.541
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:29:39.544
  STEP: Creating a simple DaemonSet "daemon-set" @ 12/02/23 12:29:39.565
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/02/23 12:29:39.569
  Dec  2 12:29:39.573: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:39.573: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:39.577: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:29:39.577: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:29:40.332733      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:40.582: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:40.582: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:40.585: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  2 12:29:40.585: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:29:41.332977      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:41.581: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:41.581: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:41.585: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 12:29:41.585: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. @ 12/02/23 12:29:41.588
  Dec  2 12:29:41.606: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:41.606: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:41.611: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  2 12:29:41.611: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:29:42.333208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:42.615: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:42.615: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:42.619: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  2 12:29:42.619: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:29:43.334036      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:43.616: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:43.616: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:29:43.620: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 12:29:43.620: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Wait for the failed daemon pod to be completely deleted. @ 12/02/23 12:29:43.62
  STEP: Deleting DaemonSet "daemon-set" @ 12/02/23 12:29:43.626
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1516, will wait for the garbage collector to delete the pods @ 12/02/23 12:29:43.626
  Dec  2 12:29:43.687: INFO: Deleting DaemonSet.extensions daemon-set took: 6.760071ms
  Dec  2 12:29:43.788: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.610288ms
  E1202 12:29:44.334126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:45.335094      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:45.393: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:29:45.393: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  2 12:29:45.395: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12152"},"items":null}

  Dec  2 12:29:45.398: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12152"},"items":null}

  Dec  2 12:29:45.412: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-1516" for this suite. @ 12/02/23 12:29:45.417
• [5.901 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:550
  STEP: Creating a kubernetes client @ 12/02/23 12:29:45.427
  Dec  2 12:29:45.427: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 12:29:45.428
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:29:45.444
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:29:45.446
  STEP: Creating pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553 @ 12/02/23 12:29:45.449
  E1202 12:29:46.335400      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:47.335581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 12:29:47.468
  Dec  2 12:29:47.471: INFO: Initial restart count of pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c is 0
  Dec  2 12:29:47.475: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:29:48.335669      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:49.335757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:49.479: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:29:50.335852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:51.336146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:51.483: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:29:52.336646      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:53.336737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:53.487: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:29:54.337526      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:55.337607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:55.491: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:29:56.338062      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:57.338235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:57.494: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:29:58.339302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:29:59.340242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:29:59.498: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:00.340323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:01.340597      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:01.504: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:02.341533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:03.341705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:03.509: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:04.341805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:05.341981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:05.512: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:06.342581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:07.342649      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:07.517: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:08.343376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:09.343490      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:09.521: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:10.343529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:11.343604      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:11.527: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:12.344268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:13.344438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:13.531: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:14.344533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:15.345322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:15.536: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:16.345906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:17.345992      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:17.540: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:18.346235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:19.347295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:19.545: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:20.347338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:21.347418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:21.549: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:22.348183      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:23.348280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:23.552: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:24.349289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:25.349475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:25.556: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:26.349563      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:27.349658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:27.560: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:28.350685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:29.350781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:29.564: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:30.351850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:31.352074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:31.569: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:32.352186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:33.352284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:33.572: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:34.352353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:35.352649      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:35.577: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:36.353696      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:37.353792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:37.581: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:38.354336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:39.354354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:39.586: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:40.354895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:41.354986      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:41.591: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:42.355090      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:43.355175      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:43.596: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:44.356203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:45.356306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:45.599: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:46.356721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:47.356798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:47.603: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:48.357657      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:49.357857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:49.607: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:50.358235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:51.359286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:51.613: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:52.359392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:53.359582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:53.617: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:54.359841      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:55.359918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:55.621: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:56.360290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:57.360359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:57.627: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:30:58.361039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:30:59.361123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:30:59.631: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  E1202 12:31:00.361171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:01.361251      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:31:01.635: INFO: Get pod test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c in namespace container-probe-2553
  Dec  2 12:31:01.635: INFO: Restart count of pod container-probe-2553/test-grpc-73138111-16ac-4a48-bd1b-ef3c5019eb4c is now 1 (1m14.163923264s elapsed)
  Dec  2 12:31:01.635: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 12:31:01.639
  STEP: Destroying namespace "container-probe-2553" for this suite. @ 12/02/23 12:31:01.65
• [76.229 seconds]
------------------------------
SS
------------------------------
[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]
test/e2e/common/node/configmap.go:169
  STEP: Creating a kubernetes client @ 12/02/23 12:31:01.657
  Dec  2 12:31:01.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:31:01.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:31:01.672
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:31:01.675
  STEP: creating a ConfigMap @ 12/02/23 12:31:01.678
  STEP: fetching the ConfigMap @ 12/02/23 12:31:01.683
  STEP: patching the ConfigMap @ 12/02/23 12:31:01.686
  STEP: listing all ConfigMaps in all namespaces with a label selector @ 12/02/23 12:31:01.69
  STEP: deleting the ConfigMap by collection with a label selector @ 12/02/23 12:31:01.694
  STEP: listing all ConfigMaps in test namespace @ 12/02/23 12:31:01.702
  Dec  2 12:31:01.706: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-6211" for this suite. @ 12/02/23 12:31:01.716
• [0.066 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:262
  STEP: Creating a kubernetes client @ 12/02/23 12:31:01.723
  Dec  2 12:31:01.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:31:01.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:31:01.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:31:01.742
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 12:31:01.745
  E1202 12:31:02.361633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:03.361850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:04.362240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:05.362333      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:31:05.766
  Dec  2 12:31:05.769: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-7cacb0e9-bb48-4de0-b9c0-a8ef0614a27b container client-container: <nil>
  STEP: delete the pod @ 12/02/23 12:31:05.782
  Dec  2 12:31:05.800: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-496" for this suite. @ 12/02/23 12:31:05.805
• [4.089 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:117
  STEP: Creating a kubernetes client @ 12/02/23 12:31:05.813
  Dec  2 12:31:05.813: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename field-validation @ 12/02/23 12:31:05.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:31:05.838
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:31:05.843
  STEP: apply creating a deployment @ 12/02/23 12:31:05.851
  Dec  2 12:31:05.853: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-7560" for this suite. @ 12/02/23 12:31:05.88
• [0.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:67
  STEP: Creating a kubernetes client @ 12/02/23 12:31:05.889
  Dec  2 12:31:05.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:31:05.889
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:31:05.907
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:31:05.911
  STEP: Creating projection with secret that has name projected-secret-test-82dc3e20-0c3b-4774-a2cd-a1b9ad06b67d @ 12/02/23 12:31:05.914
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:31:05.917
  E1202 12:31:06.363303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:07.363422      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:08.364365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:09.364432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:31:09.934
  Dec  2 12:31:09.938: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-secrets-6dfb4c53-fe8e-4ec5-b1ae-05ef23ea08e8 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:31:09.946
  Dec  2 12:31:09.965: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3413" for this suite. @ 12/02/23 12:31:09.968
• [4.087 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]
test/e2e/apimachinery/resource_quota.go:232
  STEP: Creating a kubernetes client @ 12/02/23 12:31:09.976
  Dec  2 12:31:09.976: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 12:31:09.976
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:31:09.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:31:09.993
  STEP: Counting existing ResourceQuota @ 12/02/23 12:31:09.997
  E1202 12:31:10.364606      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:11.364705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:12.364798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:13.364878      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:14.365248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/02/23 12:31:15.001
  STEP: Ensuring resource quota status is calculated @ 12/02/23 12:31:15.005
  E1202 12:31:15.366195      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:16.366248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod that fits quota @ 12/02/23 12:31:17.01
  STEP: Ensuring ResourceQuota status captures the pod usage @ 12/02/23 12:31:17.026
  E1202 12:31:17.366282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:18.367295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Not allowing a pod to be created that exceeds remaining quota @ 12/02/23 12:31:19.03
  STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) @ 12/02/23 12:31:19.032
  STEP: Ensuring a pod cannot update its resource requirements @ 12/02/23 12:31:19.034
  STEP: Ensuring attempts to update pod resource requirements did not change quota usage @ 12/02/23 12:31:19.037
  E1202 12:31:19.367623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:20.367705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/02/23 12:31:21.042
  STEP: Ensuring resource quota status released the pod usage @ 12/02/23 12:31:21.054
  E1202 12:31:21.367781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:22.368731      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:31:23.058: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-4208" for this suite. @ 12/02/23 12:31:23.062
• [13.094 seconds]
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
test/e2e/scheduling/preemption.go:812
  STEP: Creating a kubernetes client @ 12/02/23 12:31:23.07
  Dec  2 12:31:23.070: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-preemption @ 12/02/23 12:31:23.071
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:31:23.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:31:23.092
  Dec  2 12:31:23.109: INFO: Waiting up to 1m0s for all nodes to be ready
  E1202 12:31:23.368817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:24.368962      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:25.369485      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:26.370039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:27.370696      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:28.370768      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:29.370869      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:30.371301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:31.371741      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:32.372151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:33.372875      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:34.372971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:35.373068      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:36.373447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:37.374141      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:38.374286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:39.375084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:40.375273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:41.376019      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:42.376278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:43.376949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:44.377048      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:45.377372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:46.377607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:47.378228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:48.378302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:49.379124      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:50.379283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:51.379887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:52.379982      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:53.380682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:54.380774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:55.381376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:56.381479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:57.381908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:58.382002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:31:59.382387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:00.383285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:01.383970      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:02.384143      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:03.384824      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:04.384881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:05.385700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:06.385787      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:07.386857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:08.386944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:09.386986      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:10.387915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:11.388031      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:12.388184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:13.389076      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:14.389163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:15.390082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:16.390218      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:17.390843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:18.390929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:19.391034      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:20.391286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:21.391871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:22.391964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:32:23.127: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/02/23 12:32:23.131
  Dec  2 12:32:23.131: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/02/23 12:32:23.132
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:32:23.146
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:32:23.149
  Dec  2 12:32:23.165: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
  Dec  2 12:32:23.169: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
  Dec  2 12:32:23.186: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 12:32:23.204: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-9107" for this suite. @ 12/02/23 12:32:23.242
  STEP: Destroying namespace "sched-preemption-3964" for this suite. @ 12/02/23 12:32:23.257
• [60.195 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]
test/e2e/apps/job.go:513
  STEP: Creating a kubernetes client @ 12/02/23 12:32:23.266
  Dec  2 12:32:23.267: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename job @ 12/02/23 12:32:23.267
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:32:23.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:32:23.283
  STEP: Creating a job @ 12/02/23 12:32:23.286
  STEP: Ensuring active pods == parallelism @ 12/02/23 12:32:23.294
  E1202 12:32:23.392222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:24.392333      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Orphaning one of the Job's Pods @ 12/02/23 12:32:25.298
  E1202 12:32:25.393046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:32:25.815: INFO: Successfully updated pod "adopt-release-kmsk8"
  STEP: Checking that the Job readopts the Pod @ 12/02/23 12:32:25.815
  E1202 12:32:26.393441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:27.393527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing the labels from the Job's Pod @ 12/02/23 12:32:27.827
  Dec  2 12:32:28.342: INFO: Successfully updated pod "adopt-release-kmsk8"
  STEP: Checking that the Job releases the Pod @ 12/02/23 12:32:28.342
  E1202 12:32:28.394320      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:29.394404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:32:30.351: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5953" for this suite. @ 12/02/23 12:32:30.355
• [7.097 seconds]
------------------------------
S
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:52
  STEP: Creating a kubernetes client @ 12/02/23 12:32:30.364
  Dec  2 12:32:30.364: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-runtime @ 12/02/23 12:32:30.364
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:32:30.377
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:32:30.38
  STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' @ 12/02/23 12:32:30.392
  E1202 12:32:30.395377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:31.395527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:32.395841      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:33.396350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:34.396969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:35.397471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:36.398251      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:37.398341      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:38.398416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:39.398517      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:40.399534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:41.400579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:42.400681      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:43.400845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:44.401159      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:45.401342      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:46.401440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:47.401843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' @ 12/02/23 12:32:47.473
  STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition @ 12/02/23 12:32:47.476
  STEP: Container 'terminate-cmd-rpa': should get the expected 'State' @ 12/02/23 12:32:47.483
  STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] @ 12/02/23 12:32:47.483
  STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' @ 12/02/23 12:32:47.51
  E1202 12:32:48.402563      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:49.403263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:50.403530      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' @ 12/02/23 12:32:50.526
  E1202 12:32:51.403644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition @ 12/02/23 12:32:51.535
  STEP: Container 'terminate-cmd-rpof': should get the expected 'State' @ 12/02/23 12:32:51.543
  STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] @ 12/02/23 12:32:51.543
  STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' @ 12/02/23 12:32:51.567
  E1202 12:32:52.404422      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' @ 12/02/23 12:32:52.581
  E1202 12:32:53.404499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:54.404529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition @ 12/02/23 12:32:54.592
  STEP: Container 'terminate-cmd-rpn': should get the expected 'State' @ 12/02/23 12:32:54.6
  STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] @ 12/02/23 12:32:54.6
  Dec  2 12:32:54.615: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-5928" for this suite. @ 12/02/23 12:32:54.632
• [24.277 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]
test/e2e/apps/replica_set.go:143
  STEP: Creating a kubernetes client @ 12/02/23 12:32:54.641
  Dec  2 12:32:54.641: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replicaset @ 12/02/23 12:32:54.642
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:32:54.673
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:32:54.677
  STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota @ 12/02/23 12:32:54.681
  Dec  2 12:32:54.690: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1202 12:32:55.405453      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:56.406005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:57.406079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:58.406236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:32:59.407284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:32:59.695: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/02/23 12:32:59.695
  STEP: getting scale subresource @ 12/02/23 12:32:59.695
  STEP: updating a scale subresource @ 12/02/23 12:32:59.699
  STEP: verifying the replicaset Spec.Replicas was modified @ 12/02/23 12:32:59.704
  STEP: Patch a scale subresource @ 12/02/23 12:32:59.709
  Dec  2 12:32:59.733: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-6370" for this suite. @ 12/02/23 12:32:59.74
• [5.123 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]
test/e2e/scheduling/predicates.go:444
  STEP: Creating a kubernetes client @ 12/02/23 12:32:59.765
  Dec  2 12:32:59.765: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-pred @ 12/02/23 12:32:59.765
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:32:59.79
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:32:59.794
  Dec  2 12:32:59.799: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  2 12:32:59.810: INFO: Waiting for terminating namespaces to be deleted...
  Dec  2 12:32:59.815: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-1-50 before test
  Dec  2 12:32:59.821: INFO: nginx-ingress-controller-kubernetes-worker-bl8w7 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:04:04 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.821: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: adopt-release-9pfp7 from job-5953 started at 2023-12-02 12:32:29 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.821: INFO: 	Container c ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: adopt-release-ktqqg from job-5953 started at 2023-12-02 12:32:23 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.821: INFO: 	Container c ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: calico-node-lzsm2 from kube-system started at 2023-12-02 12:03:38 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.821: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: test-rs-4xkl6 from replicaset-6370 started at 2023-12-02 12:32:54 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.821: INFO: 	Container httpd ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: sonobuoy from sonobuoy started at 2023-12-02 12:07:42 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.821: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-28gq4 from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 12:32:59.821: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 12:32:59.821: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-74-39 before test
  Dec  2 12:32:59.827: INFO: nginx-ingress-controller-kubernetes-worker-p5kqq from ingress-nginx-kubernetes-worker started at 2023-12-02 12:05:07 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.827: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 12:32:59.827: INFO: adopt-release-kmsk8 from job-5953 started at 2023-12-02 12:32:23 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.827: INFO: 	Container c ready: true, restart count 0
  Dec  2 12:32:59.827: INFO: calico-node-jvhbz from kube-system started at 2023-12-02 12:04:51 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.827: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 12:32:59.827: INFO: test-rs-dxdrp from replicaset-6370 started at 2023-12-02 12:32:59 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.827: INFO: 	Container httpd ready: false, restart count 0
  Dec  2 12:32:59.827: INFO: sonobuoy-e2e-job-e9309236a19947ce from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 12:32:59.827: INFO: 	Container e2e ready: true, restart count 0
  Dec  2 12:32:59.827: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 12:32:59.827: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-fz89t from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 12:32:59.827: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 12:32:59.827: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 12:32:59.827: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-89-192 before test
  Dec  2 12:32:59.833: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-5sm95 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: nginx-ingress-controller-kubernetes-worker-g5cfp from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: calico-node-ql9q7 from kube-system started at 2023-12-02 12:01:42 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: coredns-59cfb5bf46-4zw4x from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container coredns ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: kube-state-metrics-78c475f58b-9brf7 from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: metrics-server-v0.6.3-69d7fbfdf8-q6h8s from kube-system started at 2023-12-02 12:02:20 +0000 UTC (2 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: dashboard-metrics-scraper-5dd7cb5fc-srsz2 from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: kubernetes-dashboard-7b899cb9d9-vfzmg from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: test-rs-cd4c5 from replicaset-6370 started at 2023-12-02 12:32:59 +0000 UTC (1 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container httpd ready: false, restart count 0
  Dec  2 12:32:59.833: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-ldh7p from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 12:32:59.833: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 12:32:59.833: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to schedule Pod with nonempty NodeSelector. @ 12/02/23 12:32:59.833
  E1202 12:33:00.407552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:01.407770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:02.407900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:03.408094      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:04.409095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:05.409227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Considering event: 
  Type = [Warning], Name = [restricted-pod.179d03c6a497873d], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling..] @ 12/02/23 12:33:05.922
  E1202 12:33:06.409967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:33:06.922: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2379" for this suite. @ 12/02/23 12:33:06.926
• [7.167 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]
test/e2e/apimachinery/webhook.go:332
  STEP: Creating a kubernetes client @ 12/02/23 12:33:06.932
  Dec  2 12:33:06.932: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 12:33:06.933
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:33:06.949
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:33:06.952
  STEP: Setting up server cert @ 12/02/23 12:33:06.974
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 12:33:07.232
  STEP: Deploying the webhook pod @ 12/02/23 12:33:07.241
  STEP: Wait for the deployment to be ready @ 12/02/23 12:33:07.253
  Dec  2 12:33:07.271: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 12:33:07.410227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:08.410322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 12:33:09.282
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 12:33:09.296
  E1202 12:33:09.410369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:33:10.296: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  2 12:33:10.305: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 12:33:10.411270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9757-crds.webhook.example.com via the AdmissionRegistration API @ 12/02/23 12:33:10.817
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/02/23 12:33:10.832
  E1202 12:33:11.411528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:12.411789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:33:12.872: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1202 12:33:13.411871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-7033" for this suite. @ 12/02/23 12:33:13.45
  STEP: Destroying namespace "webhook-markers-6179" for this suite. @ 12/02/23 12:33:13.457
• [6.533 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
test/e2e/instrumentation/events.go:98
  STEP: Creating a kubernetes client @ 12/02/23 12:33:13.465
  Dec  2 12:33:13.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename events @ 12/02/23 12:33:13.465
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:33:13.485
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:33:13.488
  STEP: creating a test event @ 12/02/23 12:33:13.491
  STEP: listing events in all namespaces @ 12/02/23 12:33:13.499
  STEP: listing events in test namespace @ 12/02/23 12:33:13.505
  STEP: listing events with field selection filtering on source @ 12/02/23 12:33:13.509
  STEP: listing events with field selection filtering on reportingController @ 12/02/23 12:33:13.513
  STEP: getting the test event @ 12/02/23 12:33:13.517
  STEP: patching the test event @ 12/02/23 12:33:13.519
  STEP: getting the test event @ 12/02/23 12:33:13.53
  STEP: updating the test event @ 12/02/23 12:33:13.532
  STEP: getting the test event @ 12/02/23 12:33:13.539
  STEP: deleting the test event @ 12/02/23 12:33:13.542
  STEP: listing events in all namespaces @ 12/02/23 12:33:13.55
  STEP: listing events in test namespace @ 12/02/23 12:33:13.558
  Dec  2 12:33:13.561: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-5066" for this suite. @ 12/02/23 12:33:13.564
• [0.121 seconds]
------------------------------
S
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:110
  STEP: Creating a kubernetes client @ 12/02/23 12:33:13.586
  Dec  2 12:33:13.586: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubelet-test @ 12/02/23 12:33:13.586
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:33:13.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:33:13.605
  E1202 12:33:14.412812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:15.413232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:16.413318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:17.413493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:33:17.626: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-7745" for this suite. @ 12/02/23 12:33:17.63
• [4.051 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]
test/e2e/apimachinery/resource_quota.go:161
  STEP: Creating a kubernetes client @ 12/02/23 12:33:17.639
  Dec  2 12:33:17.639: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 12:33:17.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:33:17.655
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:33:17.658
  STEP: Discovering how many secrets are in namespace by default @ 12/02/23 12:33:17.661
  E1202 12:33:18.413568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:19.413677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:20.414301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:21.414514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:22.415365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/02/23 12:33:22.665
  E1202 12:33:23.415735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:24.415809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:25.416217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:26.416305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:27.416361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/02/23 12:33:27.67
  STEP: Ensuring resource quota status is calculated @ 12/02/23 12:33:27.675
  E1202 12:33:28.417283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:29.417371      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Secret @ 12/02/23 12:33:29.679
  STEP: Ensuring resource quota status captures secret creation @ 12/02/23 12:33:29.688
  E1202 12:33:30.417558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:31.417729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a secret @ 12/02/23 12:33:31.693
  STEP: Ensuring resource quota status released usage @ 12/02/23 12:33:31.699
  E1202 12:33:32.418167      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:33.418233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:33:33.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3031" for this suite. @ 12/02/23 12:33:33.706
• [16.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:187
  STEP: Creating a kubernetes client @ 12/02/23 12:33:33.715
  Dec  2 12:33:33.715: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 12:33:33.716
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:33:33.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:33:33.742
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/02/23 12:33:33.749
  E1202 12:33:34.418342      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:35.419208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:33:35.769
  Dec  2 12:33:35.773: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-ba9648b2-8785-4fc5-b325-6159bb7281e4 container test-container: <nil>
  STEP: delete the pod @ 12/02/23 12:33:35.79
  Dec  2 12:33:35.810: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9314" for this suite. @ 12/02/23 12:33:35.813
• [2.105 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]
test/e2e/scheduling/preemption.go:130
  STEP: Creating a kubernetes client @ 12/02/23 12:33:35.82
  Dec  2 12:33:35.820: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-preemption @ 12/02/23 12:33:35.821
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:33:35.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:33:35.841
  Dec  2 12:33:35.856: INFO: Waiting up to 1m0s for all nodes to be ready
  E1202 12:33:36.419255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:37.419574      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:38.420443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:39.420526      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:40.421534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:41.422236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:42.422929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:43.423296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:44.423979      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:45.424492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:46.425317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:47.425396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:48.425503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:49.425581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:50.426324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:51.426406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:52.427273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:53.427437      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:54.427532      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:55.427891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:56.427983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:57.428146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:58.428950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:33:59.429003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:00.429528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:01.429616      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:02.430181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:03.430248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:04.430318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:05.430681      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:06.431380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:07.431566      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:08.431643      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:09.431869      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:10.432353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:11.432514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:12.432925      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:13.433101      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:14.434077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:15.434476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:16.434513      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:17.434596      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:18.434682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:19.435339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:20.435504      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:21.435601      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:22.435694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:23.435784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:24.436287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:25.436680      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:26.437515      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:27.437610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:28.437869      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:29.438263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:30.438679      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:31.438776      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:32.438850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:33.439287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:34.439811      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:35.440505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:34:35.876: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/02/23 12:34:35.88
  Dec  2 12:34:35.901: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec  2 12:34:35.913: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec  2 12:34:35.930: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec  2 12:34:35.938: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec  2 12:34:35.959: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec  2 12:34:35.981: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/02/23 12:34:35.981
  E1202 12:34:36.441505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:37.441732      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:38.441784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:39.441958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a high priority pod that has same requirements as that of lower priority pod @ 12/02/23 12:34:40.012
  E1202 12:34:40.442315      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:41.442405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:42.443252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:43.443343      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:34:44.051: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-4712" for this suite. @ 12/02/23 12:34:44.091
• [68.278 seconds]
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]
test/e2e/apps/statefulset.go:320
  STEP: Creating a kubernetes client @ 12/02/23 12:34:44.099
  Dec  2 12:34:44.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 12:34:44.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:34:44.116
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:34:44.119
  STEP: Creating service test in namespace statefulset-2925 @ 12/02/23 12:34:44.122
  STEP: Creating a new StatefulSet @ 12/02/23 12:34:44.127
  Dec  2 12:34:44.142: INFO: Found 0 stateful pods, waiting for 3
  E1202 12:34:44.443767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:45.444628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:46.444721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:47.444813      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:48.445303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:49.448017      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:50.448343      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:51.448524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:52.448701      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:53.448800      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:34:54.145: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:34:54.145: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:34:54.145: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:34:54.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-2925 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 12:34:54.288: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 12:34:54.288: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 12:34:54.288: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1202 12:34:54.449120      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:55.449187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:56.449266      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:57.449471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:58.449560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:34:59.449748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:00.450562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:01.451284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:02.451371      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:03.451465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-4 to registry.k8s.io/e2e-test-images/httpd:2.4.39-4 @ 12/02/23 12:35:04.303
  Dec  2 12:35:04.324: INFO: Updating stateful set ss2
  STEP: Creating a new revision @ 12/02/23 12:35:04.324
  E1202 12:35:04.451708      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:05.452618      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:06.452748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:07.452830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:08.452985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:09.453085      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:10.453566      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:11.453658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:12.453767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:13.454520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating Pods in reverse ordinal order @ 12/02/23 12:35:14.338
  Dec  2 12:35:14.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-2925 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1202 12:35:14.455298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:35:14.472: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  2 12:35:14.472: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 12:35:14.472: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1202 12:35:15.455496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:16.455681      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:17.455765      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:18.455862      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:19.455966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:20.456568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:21.456982      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:22.457175      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:23.457338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:24.457417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back to a previous revision @ 12/02/23 12:35:24.493
  Dec  2 12:35:24.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-2925 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 12:35:24.616: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 12:35:24.616: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 12:35:24.616: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  E1202 12:35:25.457697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:26.457783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:27.458205      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:28.458248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:29.458337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:30.458564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:31.459299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:32.459393      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:33.459496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:34.459577      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:35:34.650: INFO: Updating stateful set ss2
  E1202 12:35:35.460208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:36.460922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:37.461071      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:38.461430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:39.461530      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:40.462560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:41.463287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:42.464282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:43.465145      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:44.465523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Rolling back update in reverse ordinal order @ 12/02/23 12:35:44.675
  Dec  2 12:35:44.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-2925 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  2 12:35:44.796: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  2 12:35:44.796: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 12:35:44.796: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  E1202 12:35:45.466286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:46.466338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:47.466428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:48.466527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:49.466617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:50.467505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:51.467601      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:52.467699      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:53.467793      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:54.468499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:35:54.850: INFO: Deleting all statefulset in ns statefulset-2925
  Dec  2 12:35:54.854: INFO: Scaling statefulset ss2 to 0
  E1202 12:35:55.469262      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:56.469449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:57.469487      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:58.469647      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:35:59.469837      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:00.470765      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:01.470837      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:02.471088      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:03.471533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:04.471705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:04.879: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 12:36:04.883: INFO: Deleting statefulset ss2
  Dec  2 12:36:04.895: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-2925" for this suite. @ 12/02/23 12:36:04.898
• [80.809 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:164
  STEP: Creating a kubernetes client @ 12/02/23 12:36:04.908
  Dec  2 12:36:04.908: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename security-context @ 12/02/23 12:36:04.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:36:04.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:36:04.927
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/02/23 12:36:04.93
  E1202 12:36:05.472521      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:06.472775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:07.472870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:08.472976      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:36:08.954
  Dec  2 12:36:08.957: INFO: Trying to get logs from node ip-172-31-1-50 pod security-context-857105ef-8bc0-43de-81ea-a1eb8a93b934 container test-container: <nil>
  STEP: delete the pod @ 12/02/23 12:36:08.97
  Dec  2 12:36:08.985: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-8089" for this suite. @ 12/02/23 12:36:08.989
• [4.087 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:175
  STEP: Creating a kubernetes client @ 12/02/23 12:36:08.995
  Dec  2 12:36:08.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:36:08.996
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:36:09.023
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:36:09.026
  STEP: Creating configMap with name configmap-test-upd-fc74c3fa-6034-4700-94f6-c31a54b7e476 @ 12/02/23 12:36:09.033
  STEP: Creating the pod @ 12/02/23 12:36:09.037
  E1202 12:36:09.472990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:10.473601      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod with text data @ 12/02/23 12:36:11.056
  STEP: Waiting for pod with binary data @ 12/02/23 12:36:11.063
  Dec  2 12:36:11.071: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4348" for this suite. @ 12/02/23 12:36:11.075
• [2.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:528
  STEP: Creating a kubernetes client @ 12/02/23 12:36:11.085
  Dec  2 12:36:11.085: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename security-context-test @ 12/02/23 12:36:11.086
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:36:11.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:36:11.103
  E1202 12:36:11.474349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:12.475298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:13.476046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:14.476135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:15.147: INFO: Got logs for pod "busybox-privileged-false-d0d72f5b-0311-4d95-948e-2695afd978ff": "ip: RTNETLINK answers: Operation not permitted\n"
  Dec  2 12:36:15.147: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-77" for this suite. @ 12/02/23 12:36:15.151
• [4.073 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:527
  STEP: Creating a kubernetes client @ 12/02/23 12:36:15.158
  Dec  2 12:36:15.158: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 12:36:15.159
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:36:15.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:36:15.186
  STEP: Creating pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538 @ 12/02/23 12:36:15.189
  E1202 12:36:15.476980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:16.477119      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 12:36:17.209
  Dec  2 12:36:17.212: INFO: Initial restart count of pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 is 0
  Dec  2 12:36:17.216: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:17.477673      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:18.477761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:19.220: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:19.478698      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:20.479519      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:21.224: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:21.480006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:22.480156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:23.229: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:23.481098      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:24.481197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:25.233: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:25.481402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:26.481479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:27.237: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:27.482129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:28.482225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:29.241: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:29.482324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:30.482637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:31.245: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:31.483175      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:32.483355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:33.249: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:33.484260      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:34.484296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:35.255: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:35.484698      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:36.485091      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:37.259: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:37.486168      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:38.486229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:39.264: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:39.486704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:40.487064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:41.267: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:41.488021      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:42.488770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:43.273: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:43.489196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:44.489288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:45.279: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:45.489588      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:46.489676      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:47.282: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:47.490499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:48.491285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:49.287: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:49.492109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:50.492677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:51.291: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:51.492980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:52.493135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:53.297: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:53.493728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:54.493845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:55.301: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:55.494443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:56.494498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:57.305: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:57.495285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:36:58.495597      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:36:59.309: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:36:59.496409      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:00.496603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:01.313: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:01.496953      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:02.497039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:03.317: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:03.497104      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:04.497351      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:05.321: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:05.498034      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:06.498220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:07.326: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:07.498586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:08.498685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:09.330: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:09.499542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:10.500588      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:11.334: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:11.501106      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:12.501204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:13.338: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:13.502181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:14.502237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:15.343: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:15.503278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:16.503422      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:17.347: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:17.504260      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:18.504444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:19.351: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:19.504859      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:20.505119      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:21.355: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:21.505485      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:22.505572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:23.359: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:23.506450      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:24.507279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:25.363: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:25.507358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:26.507518      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:27.367: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:27.507607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:28.508547      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:29.372: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:29.508946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:30.509263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:31.376: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:31.509734      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:32.509830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:33.381: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:33.510330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:34.510427      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:35.385: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:35.510949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:36.511278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:37.390: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:37.511641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:38.511744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:39.395: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:39.512365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:40.512619      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:41.398: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:41.512710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:42.513104      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:43.401: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:43.513346      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:44.513588      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:45.407: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:45.514473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:46.515301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:47.411: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:47.515749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:48.515922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:49.415: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:49.516969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:50.517880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:51.419: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:51.517935      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:52.518244      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:53.425: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:53.518543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:54.518641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:55.430: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:55.518880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:56.519301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:57.434: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:57.520159      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:37:58.520375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:37:59.438: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:37:59.520616      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:00.520625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:01.442: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:01.521527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:02.521629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:03.447: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:03.522451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:04.522548      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:05.451: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:05.523541      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:06.523581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:07.455: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:07.524330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:08.524520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:09.458: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:09.524697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:10.525001      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:11.463: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:11.525922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:12.526126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:13.468: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:13.526277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:14.526406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:15.473: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:15.527219      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:16.527319      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:17.476: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:17.527609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:18.527807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:19.480: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:19.528041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:20.528685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:21.484: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:21.528965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:22.529145      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:23.489: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:23.529851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:24.529957      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:25.493: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:25.530763      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:26.530844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:27.496: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:27.531812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:28.532027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:29.501: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:29.532427      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:30.532636      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:31.505: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:31.533255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:32.533415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:33.509: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:33.533779      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:34.534307      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:35.514: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:35.534906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:36.535256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:37.519: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:37.535407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:38.535573      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:39.523: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:39.536578      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:40.536830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:41.526: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:41.537044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:42.537185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:43.530: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:43.537280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:44.537727      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:45.535: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:45.538451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:46.539277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:47.539: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:47.540095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:48.540232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:49.540434      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:49.544: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:50.540551      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:51.540711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:51.549: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:52.540800      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:53.540895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:53.554: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:54.540996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:55.541039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:55.559: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:56.541555      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:57.541730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:57.563: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:38:58.541827      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:38:59.541899      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:38:59.568: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:00.542742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:01.543309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:01.573: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:02.543928      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:03.544825      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:03.577: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:04.545471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:05.546301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:05.582: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:06.547031      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:07.547295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:07.586: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:08.547389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:09.547436      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:09.589: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:10.547521      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:11.547595      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:11.595: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:12.548196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:13.548432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:13.598: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:14.549375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:15.550294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:15.604: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:16.550592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:17.550678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:17.607: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:18.551300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:19.552259      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:19.613: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:20.552659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:21.552771      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:21.617: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:22.553097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:23.553184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:23.620: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:24.553591      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:25.554360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:25.626: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:26.555299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:27.555463      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:27.631: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:28.555894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:29.555987      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:29.635: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:30.556667      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:31.556770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:31.641: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:32.556857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:33.557044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:33.645: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:34.557140      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:35.557208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:35.649: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:36.557996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:37.558177      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:37.654: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:38.558213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:39.558309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:39.657: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:40.558860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:41.559296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:41.662: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:42.559391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:43.559625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:43.667: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:44.559719      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:45.560085      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:45.672: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:46.560802      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:47.560960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:47.678: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:48.561156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:49.561330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:49.682: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:50.561659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:51.561736      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:51.687: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:52.562234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:53.563311      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:53.691: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:54.563386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:55.563692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:55.695: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:56.564533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:57.565378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:57.699: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:39:58.565480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:39:59.565570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:39:59.704: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:00.565617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:01.565726      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:01.708: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:02.566033      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:03.566364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:03.712: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:04.567303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:05.568358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:05.716: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:06.569105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:07.569252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:07.720: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:08.570139      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:09.570300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:09.724: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:10.570820      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:11.571828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:11.728: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:12.571915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:13.572079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:13.732: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:14.572127      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:15.572587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:15.737: INFO: Get pod test-grpc-8d4d8b59-1fb7-44d0-b787-62ba1131e129 in namespace container-probe-538
  E1202 12:40:16.572767      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:17.573386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:17.737: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 12:40:17.741
  STEP: Destroying namespace "container-probe-538" for this suite. @ 12/02/23 12:40:17.752
• [242.603 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
test/e2e/network/endpointslice.go:207
  STEP: Creating a kubernetes client @ 12/02/23 12:40:17.762
  Dec  2 12:40:17.763: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename endpointslice @ 12/02/23 12:40:17.763
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:40:17.779
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:40:17.784
  E1202 12:40:18.573476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:19.573569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:20.573847      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:21.574337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:22.575292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing a single matching pod @ 12/02/23 12:40:22.856
  E1202 12:40:23.575389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:24.575933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:25.576496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:26.576569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:27.576750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: referencing matching pods with named port @ 12/02/23 12:40:27.863
  E1202 12:40:28.576874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:29.577046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:30.577669      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:31.577756      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:32.578410      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: creating empty Endpoints and EndpointSlices for no matching Pods @ 12/02/23 12:40:32.87
  E1202 12:40:33.578484      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:34.582648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:35.583627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:36.583861      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:37.583940      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: recreating EndpointSlices after they've been deleted @ 12/02/23 12:40:37.88
  Dec  2 12:40:37.901: INFO: EndpointSlice for Service endpointslice-4013/example-named-port not found
  E1202 12:40:38.584016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:39.584112      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:40.584845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:41.585479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:42.586178      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:43.586245      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:44.587281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:45.587645      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:46.588152      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:47.588340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:40:47.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-4013" for this suite. @ 12/02/23 12:40:47.912
• [30.160 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should provide secure master service  [Conformance]
test/e2e/network/service.go:775
  STEP: Creating a kubernetes client @ 12/02/23 12:40:47.924
  Dec  2 12:40:47.924: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 12:40:47.924
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:40:47.938
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:40:47.941
  Dec  2 12:40:47.960: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-6901" for this suite. @ 12/02/23 12:40:47.965
• [0.050 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]
test/e2e/apimachinery/garbage_collector.go:379
  STEP: Creating a kubernetes client @ 12/02/23 12:40:47.975
  Dec  2 12:40:47.975: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename gc @ 12/02/23 12:40:47.975
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:40:47.986
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:40:47.989
  STEP: create the rc @ 12/02/23 12:40:47.997
  W1202 12:40:48.001393      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1202 12:40:48.589858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:49.590809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:50.591770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:51.592441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:52.593091      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:53.608852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/02/23 12:40:54.027
  STEP: wait for the rc to be deleted @ 12/02/23 12:40:54.042
  E1202 12:40:54.609295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:55.609699      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:56.609806      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:57.610474      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:40:58.610547      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods @ 12/02/23 12:40:59.047
  E1202 12:40:59.611354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:00.611720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:01.611815      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:02.611977      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:03.619297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:04.619387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:05.619709      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:06.619879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:07.620036      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:08.620146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:09.620343      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:10.620454      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:11.621331      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:12.621416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:13.621486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:14.622443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:15.622796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:16.622862      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:17.623291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:18.623451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:19.623540      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:20.623729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:21.624013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:22.625033      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:23.625118      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:24.625272      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:25.625352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:26.625497      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:27.625661      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:28.626283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/02/23 12:41:29.057
  W1202 12:41:29.061909      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  2 12:41:29.062: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  2 12:41:29.062: INFO: Deleting pod "simpletest.rc-222t8" in namespace "gc-5842"
  Dec  2 12:41:29.073: INFO: Deleting pod "simpletest.rc-2457r" in namespace "gc-5842"
  Dec  2 12:41:29.086: INFO: Deleting pod "simpletest.rc-24k8k" in namespace "gc-5842"
  Dec  2 12:41:29.103: INFO: Deleting pod "simpletest.rc-257bf" in namespace "gc-5842"
  Dec  2 12:41:29.125: INFO: Deleting pod "simpletest.rc-25qt6" in namespace "gc-5842"
  Dec  2 12:41:29.137: INFO: Deleting pod "simpletest.rc-25xpx" in namespace "gc-5842"
  Dec  2 12:41:29.152: INFO: Deleting pod "simpletest.rc-46r7h" in namespace "gc-5842"
  Dec  2 12:41:29.170: INFO: Deleting pod "simpletest.rc-4d5f9" in namespace "gc-5842"
  Dec  2 12:41:29.180: INFO: Deleting pod "simpletest.rc-4gzf6" in namespace "gc-5842"
  Dec  2 12:41:29.190: INFO: Deleting pod "simpletest.rc-4hkjj" in namespace "gc-5842"
  Dec  2 12:41:29.202: INFO: Deleting pod "simpletest.rc-4shv4" in namespace "gc-5842"
  Dec  2 12:41:29.212: INFO: Deleting pod "simpletest.rc-4vzmz" in namespace "gc-5842"
  Dec  2 12:41:29.223: INFO: Deleting pod "simpletest.rc-592tl" in namespace "gc-5842"
  Dec  2 12:41:29.235: INFO: Deleting pod "simpletest.rc-5h68z" in namespace "gc-5842"
  Dec  2 12:41:29.248: INFO: Deleting pod "simpletest.rc-5ns6k" in namespace "gc-5842"
  Dec  2 12:41:29.262: INFO: Deleting pod "simpletest.rc-5stq6" in namespace "gc-5842"
  Dec  2 12:41:29.277: INFO: Deleting pod "simpletest.rc-628t7" in namespace "gc-5842"
  Dec  2 12:41:29.290: INFO: Deleting pod "simpletest.rc-685qd" in namespace "gc-5842"
  Dec  2 12:41:29.302: INFO: Deleting pod "simpletest.rc-68zgv" in namespace "gc-5842"
  Dec  2 12:41:29.316: INFO: Deleting pod "simpletest.rc-69cbh" in namespace "gc-5842"
  Dec  2 12:41:29.325: INFO: Deleting pod "simpletest.rc-74bgv" in namespace "gc-5842"
  Dec  2 12:41:29.341: INFO: Deleting pod "simpletest.rc-7fzwk" in namespace "gc-5842"
  Dec  2 12:41:29.358: INFO: Deleting pod "simpletest.rc-7pn4f" in namespace "gc-5842"
  Dec  2 12:41:29.369: INFO: Deleting pod "simpletest.rc-7v7pc" in namespace "gc-5842"
  Dec  2 12:41:29.383: INFO: Deleting pod "simpletest.rc-85wrw" in namespace "gc-5842"
  Dec  2 12:41:29.401: INFO: Deleting pod "simpletest.rc-87kxw" in namespace "gc-5842"
  Dec  2 12:41:29.413: INFO: Deleting pod "simpletest.rc-8fqmn" in namespace "gc-5842"
  Dec  2 12:41:29.429: INFO: Deleting pod "simpletest.rc-8j7jt" in namespace "gc-5842"
  Dec  2 12:41:29.445: INFO: Deleting pod "simpletest.rc-9kbj4" in namespace "gc-5842"
  Dec  2 12:41:29.457: INFO: Deleting pod "simpletest.rc-9nsgj" in namespace "gc-5842"
  Dec  2 12:41:29.471: INFO: Deleting pod "simpletest.rc-bbn8w" in namespace "gc-5842"
  Dec  2 12:41:29.486: INFO: Deleting pod "simpletest.rc-bbt54" in namespace "gc-5842"
  Dec  2 12:41:29.499: INFO: Deleting pod "simpletest.rc-bcn6g" in namespace "gc-5842"
  Dec  2 12:41:29.513: INFO: Deleting pod "simpletest.rc-bh4fg" in namespace "gc-5842"
  Dec  2 12:41:29.529: INFO: Deleting pod "simpletest.rc-brszd" in namespace "gc-5842"
  Dec  2 12:41:29.545: INFO: Deleting pod "simpletest.rc-c4dm9" in namespace "gc-5842"
  Dec  2 12:41:29.558: INFO: Deleting pod "simpletest.rc-c55r9" in namespace "gc-5842"
  Dec  2 12:41:29.571: INFO: Deleting pod "simpletest.rc-c5wqj" in namespace "gc-5842"
  Dec  2 12:41:29.585: INFO: Deleting pod "simpletest.rc-cbz7k" in namespace "gc-5842"
  Dec  2 12:41:29.597: INFO: Deleting pod "simpletest.rc-cjt57" in namespace "gc-5842"
  Dec  2 12:41:29.608: INFO: Deleting pod "simpletest.rc-cv8qm" in namespace "gc-5842"
  Dec  2 12:41:29.622: INFO: Deleting pod "simpletest.rc-ds9mg" in namespace "gc-5842"
  E1202 12:41:29.626520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:29.640: INFO: Deleting pod "simpletest.rc-dvj2l" in namespace "gc-5842"
  Dec  2 12:41:29.663: INFO: Deleting pod "simpletest.rc-fb6ll" in namespace "gc-5842"
  Dec  2 12:41:29.682: INFO: Deleting pod "simpletest.rc-flr4n" in namespace "gc-5842"
  Dec  2 12:41:29.695: INFO: Deleting pod "simpletest.rc-g5g5f" in namespace "gc-5842"
  Dec  2 12:41:29.710: INFO: Deleting pod "simpletest.rc-gct25" in namespace "gc-5842"
  Dec  2 12:41:29.721: INFO: Deleting pod "simpletest.rc-gfs9f" in namespace "gc-5842"
  Dec  2 12:41:29.733: INFO: Deleting pod "simpletest.rc-gkwms" in namespace "gc-5842"
  Dec  2 12:41:29.746: INFO: Deleting pod "simpletest.rc-gljxz" in namespace "gc-5842"
  Dec  2 12:41:29.759: INFO: Deleting pod "simpletest.rc-h74cc" in namespace "gc-5842"
  Dec  2 12:41:29.770: INFO: Deleting pod "simpletest.rc-h9vxq" in namespace "gc-5842"
  Dec  2 12:41:29.783: INFO: Deleting pod "simpletest.rc-hbj7d" in namespace "gc-5842"
  Dec  2 12:41:29.797: INFO: Deleting pod "simpletest.rc-j7r7z" in namespace "gc-5842"
  Dec  2 12:41:29.810: INFO: Deleting pod "simpletest.rc-k6crs" in namespace "gc-5842"
  Dec  2 12:41:29.822: INFO: Deleting pod "simpletest.rc-k87qb" in namespace "gc-5842"
  Dec  2 12:41:29.834: INFO: Deleting pod "simpletest.rc-kblkb" in namespace "gc-5842"
  Dec  2 12:41:29.847: INFO: Deleting pod "simpletest.rc-l7x92" in namespace "gc-5842"
  Dec  2 12:41:29.861: INFO: Deleting pod "simpletest.rc-l8zk7" in namespace "gc-5842"
  Dec  2 12:41:29.877: INFO: Deleting pod "simpletest.rc-l9sg2" in namespace "gc-5842"
  Dec  2 12:41:29.888: INFO: Deleting pod "simpletest.rc-ll29f" in namespace "gc-5842"
  Dec  2 12:41:29.898: INFO: Deleting pod "simpletest.rc-lvz6z" in namespace "gc-5842"
  Dec  2 12:41:29.913: INFO: Deleting pod "simpletest.rc-m2mxk" in namespace "gc-5842"
  Dec  2 12:41:29.925: INFO: Deleting pod "simpletest.rc-n647c" in namespace "gc-5842"
  Dec  2 12:41:29.938: INFO: Deleting pod "simpletest.rc-nb9jl" in namespace "gc-5842"
  Dec  2 12:41:29.958: INFO: Deleting pod "simpletest.rc-nbqng" in namespace "gc-5842"
  Dec  2 12:41:29.969: INFO: Deleting pod "simpletest.rc-ncgvf" in namespace "gc-5842"
  Dec  2 12:41:30.022: INFO: Deleting pod "simpletest.rc-ndtbh" in namespace "gc-5842"
  Dec  2 12:41:30.062: INFO: Deleting pod "simpletest.rc-pchjs" in namespace "gc-5842"
  Dec  2 12:41:30.112: INFO: Deleting pod "simpletest.rc-pdwt4" in namespace "gc-5842"
  Dec  2 12:41:30.175: INFO: Deleting pod "simpletest.rc-pl94b" in namespace "gc-5842"
  Dec  2 12:41:30.213: INFO: Deleting pod "simpletest.rc-plz9j" in namespace "gc-5842"
  Dec  2 12:41:30.264: INFO: Deleting pod "simpletest.rc-pzthk" in namespace "gc-5842"
  Dec  2 12:41:30.313: INFO: Deleting pod "simpletest.rc-q6jff" in namespace "gc-5842"
  Dec  2 12:41:30.364: INFO: Deleting pod "simpletest.rc-qvb59" in namespace "gc-5842"
  Dec  2 12:41:30.419: INFO: Deleting pod "simpletest.rc-r46d9" in namespace "gc-5842"
  Dec  2 12:41:30.464: INFO: Deleting pod "simpletest.rc-rbx8v" in namespace "gc-5842"
  Dec  2 12:41:30.530: INFO: Deleting pod "simpletest.rc-rcpn8" in namespace "gc-5842"
  Dec  2 12:41:30.572: INFO: Deleting pod "simpletest.rc-rn2vs" in namespace "gc-5842"
  Dec  2 12:41:30.614: INFO: Deleting pod "simpletest.rc-rw5j6" in namespace "gc-5842"
  E1202 12:41:30.627579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:30.661: INFO: Deleting pod "simpletest.rc-rx6w4" in namespace "gc-5842"
  Dec  2 12:41:30.714: INFO: Deleting pod "simpletest.rc-s44vv" in namespace "gc-5842"
  Dec  2 12:41:30.760: INFO: Deleting pod "simpletest.rc-sbtd5" in namespace "gc-5842"
  Dec  2 12:41:30.809: INFO: Deleting pod "simpletest.rc-skpw2" in namespace "gc-5842"
  Dec  2 12:41:30.863: INFO: Deleting pod "simpletest.rc-t6pgt" in namespace "gc-5842"
  Dec  2 12:41:30.911: INFO: Deleting pod "simpletest.rc-tgsgh" in namespace "gc-5842"
  Dec  2 12:41:30.962: INFO: Deleting pod "simpletest.rc-tgwk4" in namespace "gc-5842"
  Dec  2 12:41:31.020: INFO: Deleting pod "simpletest.rc-tkrzk" in namespace "gc-5842"
  Dec  2 12:41:31.065: INFO: Deleting pod "simpletest.rc-tqxrq" in namespace "gc-5842"
  Dec  2 12:41:31.110: INFO: Deleting pod "simpletest.rc-v6k6q" in namespace "gc-5842"
  Dec  2 12:41:31.164: INFO: Deleting pod "simpletest.rc-w9lqv" in namespace "gc-5842"
  Dec  2 12:41:31.208: INFO: Deleting pod "simpletest.rc-wfq28" in namespace "gc-5842"
  Dec  2 12:41:31.262: INFO: Deleting pod "simpletest.rc-wfzzm" in namespace "gc-5842"
  Dec  2 12:41:31.314: INFO: Deleting pod "simpletest.rc-wjhh6" in namespace "gc-5842"
  Dec  2 12:41:31.369: INFO: Deleting pod "simpletest.rc-xfzjd" in namespace "gc-5842"
  Dec  2 12:41:31.422: INFO: Deleting pod "simpletest.rc-xglqn" in namespace "gc-5842"
  Dec  2 12:41:31.469: INFO: Deleting pod "simpletest.rc-z7tsz" in namespace "gc-5842"
  Dec  2 12:41:31.512: INFO: Deleting pod "simpletest.rc-zdcjz" in namespace "gc-5842"
  Dec  2 12:41:31.562: INFO: Deleting pod "simpletest.rc-zgpl7" in namespace "gc-5842"
  Dec  2 12:41:31.618: INFO: Deleting pod "simpletest.rc-zhh48" in namespace "gc-5842"
  E1202 12:41:31.632310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:31.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-5842" for this suite. @ 12/02/23 12:41:31.703
• [43.783 seconds]
------------------------------
SSSS
------------------------------
[sig-network] DNS should support configurable pod DNS nameservers [Conformance]
test/e2e/network/dns.go:407
  STEP: Creating a kubernetes client @ 12/02/23 12:41:31.758
  Dec  2 12:41:31.758: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 12:41:31.759
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:41:31.774
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:41:31.778
  STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... @ 12/02/23 12:41:31.781
  Dec  2 12:41:31.793: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-7740  581be89c-0f29-4ba8-ac38-dd8a16f5791f 16744 0 2023-12-02 12:41:31 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2023-12-02 12:41:31 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zcnlc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.45,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},Claims:[]ResourceClaim{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zcnlc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,ResizePolicy:[]ContainerResizePolicy{},RestartPolicy:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,SchedulingGates:[]PodSchedulingGate{},ResourceClaims:[]PodResourceClaim{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},Resize:,ResourceClaimStatuses:[]PodResourceClaimStatus{},HostIPs:[]HostIP{},},}
  E1202 12:41:32.632737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:33.638352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:34.638373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:35.638764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying customized DNS suffix list is configured on pod... @ 12/02/23 12:41:35.808
  Dec  2 12:41:35.808: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-7740 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 12:41:35.808: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:41:35.809: INFO: ExecWithOptions: Clientset creation
  Dec  2 12:41:35.809: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7740/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  STEP: Verifying customized DNS server is configured on pod... @ 12/02/23 12:41:35.889
  Dec  2 12:41:35.889: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-7740 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 12:41:35.889: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 12:41:35.889: INFO: ExecWithOptions: Clientset creation
  Dec  2 12:41:35.889: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-7740/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  2 12:41:35.968: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 12:41:35.973: INFO: Deleting pod test-dns-nameservers...
  STEP: Destroying namespace "dns-7740" for this suite. @ 12/02/23 12:41:35.988
• [4.239 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:56
  STEP: Creating a kubernetes client @ 12/02/23 12:41:35.998
  Dec  2 12:41:35.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:41:35.999
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:41:36.016
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:41:36.021
  STEP: Creating projection with secret that has name projected-secret-test-433f989c-eebd-4fcc-a5fc-569307b60c82 @ 12/02/23 12:41:36.025
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:41:36.033
  E1202 12:41:36.638866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:37.638952      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:38.639044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:39.639295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:41:40.063
  Dec  2 12:41:40.067: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-secrets-4dcbda0b-e975-42ff-af07-6dc8114d89e7 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:41:40.086
  Dec  2 12:41:40.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9263" for this suite. @ 12/02/23 12:41:40.11
• [4.121 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:99
  STEP: Creating a kubernetes client @ 12/02/23 12:41:40.12
  Dec  2 12:41:40.120: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:41:40.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:41:40.138
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:41:40.141
  STEP: Creating configMap with name projected-configmap-test-volume-map-7107a815-800a-4679-8bfa-ac9424f3e049 @ 12/02/23 12:41:40.146
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:41:40.15
  E1202 12:41:40.639755      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:41.639873      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:42.640389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:43.641026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:41:44.18
  Dec  2 12:41:44.185: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-configmaps-d6dc97a1-30ba-4624-b07b-d419b5e1bc53 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:41:44.192
  Dec  2 12:41:44.209: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-407" for this suite. @ 12/02/23 12:41:44.213
• [4.101 seconds]
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]
test/e2e/apps/daemon_set.go:177
  STEP: Creating a kubernetes client @ 12/02/23 12:41:44.221
  Dec  2 12:41:44.221: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename daemonsets @ 12/02/23 12:41:44.222
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:41:44.241
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:41:44.244
  STEP: Creating simple DaemonSet "daemon-set" @ 12/02/23 12:41:44.272
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/02/23 12:41:44.276
  Dec  2 12:41:44.280: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:44.280: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:44.285: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:41:44.285: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:41:44.641277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:45.290: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:45.290: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:45.295: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:41:45.295: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:41:45.641980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:46.290: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:46.290: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:46.293: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 12:41:46.293: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Stop a daemon pod, check that the daemon pod is revived. @ 12/02/23 12:41:46.297
  Dec  2 12:41:46.313: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:46.313: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:46.317: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  2 12:41:46.317: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:41:46.642803      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:47.320: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:47.320: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:47.324: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  2 12:41:47.324: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 12:41:47.643293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:48.321: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:48.321: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 12:41:48.325: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 12:41:48.325: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/02/23 12:41:48.329
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7963, will wait for the garbage collector to delete the pods @ 12/02/23 12:41:48.329
  Dec  2 12:41:48.391: INFO: Deleting DaemonSet.extensions daemon-set took: 8.380507ms
  Dec  2 12:41:48.492: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.758365ms
  E1202 12:41:48.644155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:49.496: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 12:41:49.496: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  2 12:41:49.500: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"17717"},"items":null}

  Dec  2 12:41:49.503: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"17717"},"items":null}

  Dec  2 12:41:49.515: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-7963" for this suite. @ 12/02/23 12:41:49.52
• [5.321 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]
test/e2e/apimachinery/resource_quota.go:1013
  STEP: Creating a kubernetes client @ 12/02/23 12:41:49.543
  Dec  2 12:41:49.543: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 12:41:49.543
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:41:49.585
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:41:49.587
  STEP: Creating resourceQuota "e2e-rq-status-s6wtc" @ 12/02/23 12:41:49.596
  Dec  2 12:41:49.606: INFO: Resource quota "e2e-rq-status-s6wtc" reports spec: hard cpu limit of 500m
  Dec  2 12:41:49.606: INFO: Resource quota "e2e-rq-status-s6wtc" reports spec: hard memory limit of 500Mi
  STEP: Updating resourceQuota "e2e-rq-status-s6wtc" /status @ 12/02/23 12:41:49.606
  STEP: Confirm /status for "e2e-rq-status-s6wtc" resourceQuota via watch @ 12/02/23 12:41:49.615
  Dec  2 12:41:49.617: INFO: observed resourceQuota "e2e-rq-status-s6wtc" in namespace "resourcequota-3595" with hard status: v1.ResourceList(nil)
  Dec  2 12:41:49.617: INFO: Found resourceQuota "e2e-rq-status-s6wtc" in namespace "resourcequota-3595" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec  2 12:41:49.617: INFO: ResourceQuota "e2e-rq-status-s6wtc" /status was updated
  STEP: Patching hard spec values for cpu & memory @ 12/02/23 12:41:49.619
  Dec  2 12:41:49.625: INFO: Resource quota "e2e-rq-status-s6wtc" reports spec: hard cpu limit of 1
  Dec  2 12:41:49.625: INFO: Resource quota "e2e-rq-status-s6wtc" reports spec: hard memory limit of 1Gi
  STEP: Patching "e2e-rq-status-s6wtc" /status @ 12/02/23 12:41:49.625
  STEP: Confirm /status for "e2e-rq-status-s6wtc" resourceQuota via watch @ 12/02/23 12:41:49.631
  Dec  2 12:41:49.632: INFO: observed resourceQuota "e2e-rq-status-s6wtc" in namespace "resourcequota-3595" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:500, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:524288000, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"500Mi", Format:"BinarySI"}}
  Dec  2 12:41:49.632: INFO: Found resourceQuota "e2e-rq-status-s6wtc" in namespace "resourcequota-3595" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:1, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:1073741824, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"1Gi", Format:"BinarySI"}}
  Dec  2 12:41:49.632: INFO: ResourceQuota "e2e-rq-status-s6wtc" /status was patched
  STEP: Get "e2e-rq-status-s6wtc" /status @ 12/02/23 12:41:49.632
  Dec  2 12:41:49.636: INFO: Resourcequota "e2e-rq-status-s6wtc" reports status: hard cpu of 1
  Dec  2 12:41:49.636: INFO: Resourcequota "e2e-rq-status-s6wtc" reports status: hard memory of 1Gi
  STEP: Repatching "e2e-rq-status-s6wtc" /status before checking Spec is unchanged @ 12/02/23 12:41:49.64
  Dec  2 12:41:49.643: INFO: Resourcequota "e2e-rq-status-s6wtc" reports status: hard cpu of 2
  Dec  2 12:41:49.643: INFO: Resourcequota "e2e-rq-status-s6wtc" reports status: hard memory of 2Gi
  E1202 12:41:49.644858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:41:49.644: INFO: Found resourceQuota "e2e-rq-status-s6wtc" in namespace "resourcequota-3595" with hard status: v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:2, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:2147483648, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"2Gi", Format:"BinarySI"}}
  E1202 12:41:50.645760      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:51.645855      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:52.645940      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:53.646031      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:54.646241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:55.646695      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:56.646850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:57.646930      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:58.647024      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:41:59.647302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:00.647787      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:01.648059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:02.648938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:03.649013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:04.649312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:05.649720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:06.650230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:07.650326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:08.650397      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:09.651123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:10.651753      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:11.651849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:12.651927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:13.652088      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:14.652584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:15.652799      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:16.652887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:17.652965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:18.653123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:19.654083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:20.654752      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:21.655303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:22.655376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:23.655475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:24.655745      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:25.655871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:26.656033      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:27.656786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:28.656877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:29.657526      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:30.658615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:31.659531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:32.659726      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:33.659817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:34.660046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:35.660778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:36.661186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:37.661281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:38.661604      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:39.662524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:40.662703      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:41.663280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:42.663444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:43.663536      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:44.663985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:45.664712      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:46.665329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:47.665417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:48.665886      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:42:49.653: INFO: ResourceQuota "e2e-rq-status-s6wtc" Spec was unchanged and /status reset
  Dec  2 12:42:49.653: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-3595" for this suite. @ 12/02/23 12:42:49.657
• [60.120 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease lease API should be available [Conformance]
test/e2e/common/node/lease.go:72
  STEP: Creating a kubernetes client @ 12/02/23 12:42:49.664
  Dec  2 12:42:49.664: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename lease-test @ 12/02/23 12:42:49.665
  E1202 12:42:49.666627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:42:49.684
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:42:49.687
  Dec  2 12:42:49.743: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "lease-test-6156" for this suite. @ 12/02/23 12:42:49.747
• [0.091 seconds]
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:354
  STEP: Creating a kubernetes client @ 12/02/23 12:42:49.755
  Dec  2 12:42:49.755: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 12:42:49.756
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:42:49.77
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:42:49.772
  STEP: creating a replication controller @ 12/02/23 12:42:49.775
  Dec  2 12:42:49.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 create -f -'
  Dec  2 12:42:50.083: INFO: stderr: ""
  Dec  2 12:42:50.083: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/02/23 12:42:50.083
  Dec  2 12:42:50.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  2 12:42:50.135: INFO: stderr: ""
  Dec  2 12:42:50.135: INFO: stdout: "update-demo-nautilus-rf4j6 update-demo-nautilus-txndz "
  Dec  2 12:42:50.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-rf4j6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 12:42:50.182: INFO: stderr: ""
  Dec  2 12:42:50.182: INFO: stdout: ""
  Dec  2 12:42:50.182: INFO: update-demo-nautilus-rf4j6 is created but not running
  E1202 12:42:50.666916      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:51.667300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:52.667471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:53.668093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:54.668285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:42:55.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  2 12:42:55.232: INFO: stderr: ""
  Dec  2 12:42:55.232: INFO: stdout: "update-demo-nautilus-rf4j6 update-demo-nautilus-txndz "
  Dec  2 12:42:55.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-rf4j6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 12:42:55.279: INFO: stderr: ""
  Dec  2 12:42:55.279: INFO: stdout: "true"
  Dec  2 12:42:55.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-rf4j6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  2 12:42:55.326: INFO: stderr: ""
  Dec  2 12:42:55.326: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  2 12:42:55.326: INFO: validating pod update-demo-nautilus-rf4j6
  Dec  2 12:42:55.332: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  2 12:42:55.332: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  2 12:42:55.332: INFO: update-demo-nautilus-rf4j6 is verified up and running
  Dec  2 12:42:55.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-txndz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 12:42:55.379: INFO: stderr: ""
  Dec  2 12:42:55.379: INFO: stdout: "true"
  Dec  2 12:42:55.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-txndz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  2 12:42:55.428: INFO: stderr: ""
  Dec  2 12:42:55.428: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  2 12:42:55.428: INFO: validating pod update-demo-nautilus-txndz
  Dec  2 12:42:55.432: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  2 12:42:55.432: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  2 12:42:55.432: INFO: update-demo-nautilus-txndz is verified up and running
  STEP: scaling down the replication controller @ 12/02/23 12:42:55.432
  Dec  2 12:42:55.433: INFO: scanned /root for discovery docs: <nil>
  Dec  2 12:42:55.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
  E1202 12:42:55.669134      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:42:56.498: INFO: stderr: ""
  Dec  2 12:42:56.498: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/02/23 12:42:56.498
  Dec  2 12:42:56.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  2 12:42:56.547: INFO: stderr: ""
  Dec  2 12:42:56.547: INFO: stdout: "update-demo-nautilus-rf4j6 update-demo-nautilus-txndz "
  STEP: Replicas for name=update-demo: expected=1 actual=2 @ 12/02/23 12:42:56.547
  E1202 12:42:56.669276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:57.669350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:58.669457      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:42:59.669554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:00.669750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:43:01.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  2 12:43:01.595: INFO: stderr: ""
  Dec  2 12:43:01.595: INFO: stdout: "update-demo-nautilus-txndz "
  Dec  2 12:43:01.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-txndz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 12:43:01.645: INFO: stderr: ""
  Dec  2 12:43:01.645: INFO: stdout: "true"
  Dec  2 12:43:01.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-txndz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  E1202 12:43:01.670409      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:43:01.695: INFO: stderr: ""
  Dec  2 12:43:01.695: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  2 12:43:01.695: INFO: validating pod update-demo-nautilus-txndz
  Dec  2 12:43:01.699: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  2 12:43:01.699: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  2 12:43:01.700: INFO: update-demo-nautilus-txndz is verified up and running
  STEP: scaling up the replication controller @ 12/02/23 12:43:01.7
  Dec  2 12:43:01.700: INFO: scanned /root for discovery docs: <nil>
  Dec  2 12:43:01.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
  E1202 12:43:02.670709      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:43:02.768: INFO: stderr: ""
  Dec  2 12:43:02.768: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/02/23 12:43:02.768
  Dec  2 12:43:02.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  2 12:43:02.818: INFO: stderr: ""
  Dec  2 12:43:02.818: INFO: stdout: "update-demo-nautilus-mbmzk update-demo-nautilus-txndz "
  Dec  2 12:43:02.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-mbmzk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 12:43:02.866: INFO: stderr: ""
  Dec  2 12:43:02.866: INFO: stdout: "true"
  Dec  2 12:43:02.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-mbmzk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  2 12:43:02.913: INFO: stderr: ""
  Dec  2 12:43:02.913: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  2 12:43:02.913: INFO: validating pod update-demo-nautilus-mbmzk
  Dec  2 12:43:02.919: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  2 12:43:02.919: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  2 12:43:02.919: INFO: update-demo-nautilus-mbmzk is verified up and running
  Dec  2 12:43:02.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-txndz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 12:43:02.968: INFO: stderr: ""
  Dec  2 12:43:02.968: INFO: stdout: "true"
  Dec  2 12:43:02.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods update-demo-nautilus-txndz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  2 12:43:03.016: INFO: stderr: ""
  Dec  2 12:43:03.016: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  2 12:43:03.016: INFO: validating pod update-demo-nautilus-txndz
  Dec  2 12:43:03.025: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  2 12:43:03.025: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  2 12:43:03.025: INFO: update-demo-nautilus-txndz is verified up and running
  STEP: using delete to clean up resources @ 12/02/23 12:43:03.025
  Dec  2 12:43:03.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 delete --grace-period=0 --force -f -'
  Dec  2 12:43:03.077: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 12:43:03.077: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec  2 12:43:03.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get rc,svc -l name=update-demo --no-headers'
  Dec  2 12:43:03.147: INFO: stderr: "No resources found in kubectl-1828 namespace.\n"
  Dec  2 12:43:03.147: INFO: stdout: ""
  Dec  2 12:43:03.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1828 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec  2 12:43:03.207: INFO: stderr: ""
  Dec  2 12:43:03.208: INFO: stdout: ""
  Dec  2 12:43:03.208: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1828" for this suite. @ 12/02/23 12:43:03.212
• [13.462 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]
test/e2e/apps/rc.go:94
  STEP: Creating a kubernetes client @ 12/02/23 12:43:03.218
  Dec  2 12:43:03.218: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replication-controller @ 12/02/23 12:43:03.218
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:43:03.25
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:43:03.252
  STEP: Given a Pod with a 'name' label pod-adoption is created @ 12/02/23 12:43:03.256
  E1202 12:43:03.671278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:04.671362      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: When a replication controller with a matching selector is created @ 12/02/23 12:43:05.277
  STEP: Then the orphan pod is adopted @ 12/02/23 12:43:05.282
  E1202 12:43:05.672076      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:43:06.290: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-9985" for this suite. @ 12/02/23 12:43:06.294
• [3.083 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:88
  STEP: Creating a kubernetes client @ 12/02/23 12:43:06.302
  Dec  2 12:43:06.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:43:06.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:43:06.316
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:43:06.32
  STEP: Creating projection with secret that has name projected-secret-test-map-af6c0202-b187-4575-9e1f-c8ae489580ed @ 12/02/23 12:43:06.323
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:43:06.327
  E1202 12:43:06.672224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:07.672428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:08.672506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:09.672670      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:43:10.35
  Dec  2 12:43:10.354: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-projected-secrets-94d2814f-f0e2-41f7-b3c2-acc3bf3ca56f container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:43:10.377
  Dec  2 12:43:10.390: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2569" for this suite. @ 12/02/23 12:43:10.395
• [4.098 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]
test/e2e/apimachinery/resource_quota.go:806
  STEP: Creating a kubernetes client @ 12/02/23 12:43:10.401
  Dec  2 12:43:10.401: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 12:43:10.401
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:43:10.418
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:43:10.421
  STEP: Creating a ResourceQuota with best effort scope @ 12/02/23 12:43:10.424
  STEP: Ensuring ResourceQuota status is calculated @ 12/02/23 12:43:10.444
  E1202 12:43:10.673466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:11.673531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not best effort scope @ 12/02/23 12:43:12.448
  STEP: Ensuring ResourceQuota status is calculated @ 12/02/23 12:43:12.452
  E1202 12:43:12.674361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:13.675310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a best-effort pod @ 12/02/23 12:43:14.456
  STEP: Ensuring resource quota with best effort scope captures the pod usage @ 12/02/23 12:43:14.467
  E1202 12:43:14.675383      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:15.675435      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not best effort ignored the pod usage @ 12/02/23 12:43:16.471
  E1202 12:43:16.676399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:17.676476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/02/23 12:43:18.474
  STEP: Ensuring resource quota status released the pod usage @ 12/02/23 12:43:18.5
  E1202 12:43:18.677249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:19.677543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a not best-effort pod @ 12/02/23 12:43:20.505
  STEP: Ensuring resource quota with not best effort scope captures the pod usage @ 12/02/23 12:43:20.513
  E1202 12:43:20.678063      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:21.678229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with best effort scope ignored the pod usage @ 12/02/23 12:43:22.518
  E1202 12:43:22.678671      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:23.679300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/02/23 12:43:24.523
  STEP: Ensuring resource quota status released the pod usage @ 12/02/23 12:43:24.537
  E1202 12:43:24.679531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:25.679909      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:43:26.541: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6968" for this suite. @ 12/02/23 12:43:26.545
• [16.152 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
test/e2e/common/node/init_container.go:335
  STEP: Creating a kubernetes client @ 12/02/23 12:43:26.553
  Dec  2 12:43:26.553: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename init-container @ 12/02/23 12:43:26.554
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:43:26.568
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:43:26.574
  STEP: creating the pod @ 12/02/23 12:43:26.576
  Dec  2 12:43:26.576: INFO: PodSpec: initContainers in spec.initContainers
  E1202 12:43:26.679960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:27.680800      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:28.681013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:29.681319      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:30.681693      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:31.681863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:32.681958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:33.682977      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:34.683062      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:35.683143      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:36.683180      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:37.683348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:38.683529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:39.683857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:40.684698      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:41.685406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:42.685572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:43.685727      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:44.685971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:45.686493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:46.686589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:47.686675      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:48.687295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:49.687450      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:50.687552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:51.687730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:52.687808      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:53.688482      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:54.689463      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:55.690501      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:56.691281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:57.691365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:58.691580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:43:59.691670      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:00.691889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:01.692051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:02.692228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:03.692404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:04.692594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:05.693023      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:06.693110      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:07.693360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:08.693561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:08.712: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-948595d2-3d2e-438d-93f9-0f0f966ffd76", GenerateName:"", Namespace:"init-container-5329", SelfLink:"", UID:"cdb55f85-6718-4def-a960-dfa4023990da", ResourceVersion:"18308", Generation:0, CreationTimestamp:time.Date(2023, time.December, 2, 12, 43, 26, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"576850836"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 2, 12, 43, 26, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004091a70), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2023, time.December, 2, 12, 44, 8, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc004091aa0), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-kf8xf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0000b8a00), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf8xf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil), Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf8xf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.9", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Claims:[]v1.ResourceClaim(nil)}, ResizePolicy:[]v1.ContainerResizePolicy(nil), RestartPolicy:(*v1.ContainerRestartPolicy)(nil), VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-kf8xf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004120fc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-1-50", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0005228c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004121050)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004121070)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004121078), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00412107c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00105a7c0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil), SchedulingGates:[]v1.PodSchedulingGate(nil), ResourceClaims:[]v1.PodResourceClaim(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 2, 12, 43, 26, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 2, 12, 43, 26, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 2, 12, 43, 26, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2023, time.December, 2, 12, 43, 26, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.1.50", HostIPs:[]v1.HostIP(nil), PodIP:"192.168.21.225", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.21.225"}}, StartTime:time.Date(2023, time.December, 2, 12, 43, 26, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc004091b00), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000522af0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:2e0f836850e09b8b7cc937681d6194537a09fbd5f6b9e08f4d646a85128e8937", ContainerID:"containerd://b9d0dd1cfc123a5e434d68e5e0cbed008262fdaac1b0879bd59eec2793f30868", Started:(*bool)(0xc004121115), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0000b8b00), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-4", ImageID:"", ContainerID:"", Started:(*bool)(0xc00412111b), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0000b8ac0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.9", ImageID:"", ContainerID:"", Started:(*bool)(0xc0041210ff), AllocatedResources:v1.ResourceList(nil), Resources:(*v1.ResourceRequirements)(nil)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil), Resize:"", ResourceClaimStatuses:[]v1.PodResourceClaimStatus(nil)}}
  Dec  2 12:44:08.713: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5329" for this suite. @ 12/02/23 12:44:08.717
• [42.171 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:391
  STEP: Creating a kubernetes client @ 12/02/23 12:44:08.725
  Dec  2 12:44:08.725: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 12:44:08.725
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:08.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:08.747
  STEP: set up a multi version CRD @ 12/02/23 12:44:08.751
  Dec  2 12:44:08.751: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 12:44:09.694215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:10.694686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:11.695473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: rename a version @ 12/02/23 12:44:11.992
  STEP: check the new version name is served @ 12/02/23 12:44:12.015
  E1202 12:44:12.696003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the old version name is removed @ 12/02/23 12:44:12.935
  STEP: check the other version is not changed @ 12/02/23 12:44:13.566
  E1202 12:44:13.696852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:14.697665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:15.698127      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:16.151: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-3228" for this suite. @ 12/02/23 12:44:16.158
• [7.439 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]
test/e2e/apps/disruption.go:349
  STEP: Creating a kubernetes client @ 12/02/23 12:44:16.165
  Dec  2 12:44:16.165: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename disruption @ 12/02/23 12:44:16.166
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:16.181
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:16.183
  STEP: Creating a pdb that targets all three pods in a test replica set @ 12/02/23 12:44:16.186
  STEP: Waiting for the pdb to be processed @ 12/02/23 12:44:16.191
  E1202 12:44:16.698761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:17.698823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: First trying to evict a pod which shouldn't be evictable @ 12/02/23 12:44:18.209
  STEP: Waiting for all pods to be running @ 12/02/23 12:44:18.209
  Dec  2 12:44:18.211: INFO: pods: 0 < 3
  E1202 12:44:18.699000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:19.699039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 12/02/23 12:44:20.215
  STEP: Updating the pdb to allow a pod to be evicted @ 12/02/23 12:44:20.226
  STEP: Waiting for the pdb to be processed @ 12/02/23 12:44:20.234
  E1202 12:44:20.699748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:21.699811      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/02/23 12:44:22.241
  STEP: Waiting for all pods to be running @ 12/02/23 12:44:22.241
  STEP: Waiting for the pdb to observed all healthy pods @ 12/02/23 12:44:22.245
  STEP: Patching the pdb to disallow a pod to be evicted @ 12/02/23 12:44:22.271
  STEP: Waiting for the pdb to be processed @ 12/02/23 12:44:22.287
  E1202 12:44:22.699904      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:23.700003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 12/02/23 12:44:24.295
  STEP: locating a running pod @ 12/02/23 12:44:24.299
  STEP: Deleting the pdb to allow a pod to be evicted @ 12/02/23 12:44:24.308
  STEP: Waiting for the pdb to be deleted @ 12/02/23 12:44:24.314
  STEP: Trying to evict the same pod we tried earlier which should now be evictable @ 12/02/23 12:44:24.318
  STEP: Waiting for all pods to be running @ 12/02/23 12:44:24.318
  Dec  2 12:44:24.336: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-9380" for this suite. @ 12/02/23 12:44:24.343
• [8.187 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:79
  STEP: Creating a kubernetes client @ 12/02/23 12:44:24.353
  Dec  2 12:44:24.353: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 12:44:24.354
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:24.368
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:24.371
  STEP: Creating secret with name secret-test-map-5473f2cc-c780-496a-9516-012d09a0286d @ 12/02/23 12:44:24.374
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:44:24.377
  E1202 12:44:24.700101      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:25.700517      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:26.701088      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:27.701172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:44:28.399
  Dec  2 12:44:28.402: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-secrets-265bac6b-e885-43ab-8981-86353d8450ac container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:44:28.416
  Dec  2 12:44:28.431: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8689" for this suite. @ 12/02/23 12:44:28.434
• [4.087 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
test/e2e/node/pods.go:163
  STEP: Creating a kubernetes client @ 12/02/23 12:44:28.441
  Dec  2 12:44:28.441: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 12:44:28.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:28.455
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:28.46
  STEP: creating the pod @ 12/02/23 12:44:28.463
  STEP: submitting the pod to kubernetes @ 12/02/23 12:44:28.463
  STEP: verifying QOS class is set on the pod @ 12/02/23 12:44:28.471
  Dec  2 12:44:28.476: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9651" for this suite. @ 12/02/23 12:44:28.48
• [0.046 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]
test/e2e/architecture/conformance.go:39
  STEP: Creating a kubernetes client @ 12/02/23 12:44:28.487
  Dec  2 12:44:28.487: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename conformance-tests @ 12/02/23 12:44:28.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:28.504
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:28.506
  STEP: Getting node addresses @ 12/02/23 12:44:28.509
  Dec  2 12:44:28.509: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  Dec  2 12:44:28.514: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "conformance-tests-517" for this suite. @ 12/02/23 12:44:28.518
• [0.037 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
test/e2e/apimachinery/webhook.go:273
  STEP: Creating a kubernetes client @ 12/02/23 12:44:28.526
  Dec  2 12:44:28.526: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 12:44:28.526
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:28.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:28.541
  STEP: Setting up server cert @ 12/02/23 12:44:28.563
  E1202 12:44:28.701809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 12:44:28.829
  STEP: Deploying the webhook pod @ 12/02/23 12:44:28.837
  STEP: Wait for the deployment to be ready @ 12/02/23 12:44:28.851
  Dec  2 12:44:28.865: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 12:44:29.701895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:30.701942      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:30.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 12, 44, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 44, 28, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 12, 44, 28, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 12, 44, 28, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7646f658cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 12:44:31.702009      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:32.702249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 12:44:32.882
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 12:44:32.897
  E1202 12:44:33.702335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:33.897: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/02/23 12:44:33.905
  STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API @ 12/02/23 12:44:33.918
  STEP: Creating a dummy validating-webhook-configuration object @ 12/02/23 12:44:33.934
  STEP: Deleting the validating-webhook-configuration, which should be possible to remove @ 12/02/23 12:44:33.943
  STEP: Creating a dummy mutating-webhook-configuration object @ 12/02/23 12:44:33.949
  STEP: Deleting the mutating-webhook-configuration, which should be possible to remove @ 12/02/23 12:44:33.957
  Dec  2 12:44:33.963: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1393" for this suite. @ 12/02/23 12:44:34.022
  STEP: Destroying namespace "webhook-markers-3253" for this suite. @ 12/02/23 12:44:34.029
• [5.510 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]
test/e2e/apimachinery/namespace.go:370
  STEP: Creating a kubernetes client @ 12/02/23 12:44:34.036
  Dec  2 12:44:34.036: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename namespaces @ 12/02/23 12:44:34.037
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:34.055
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:34.059
  STEP: Updating Namespace "namespaces-185" @ 12/02/23 12:44:34.064
  Dec  2 12:44:34.080: INFO: Namespace "namespaces-185" now has labels, map[string]string{"e2e-framework":"namespaces", "e2e-run":"68aca84b-8ec8-41fd-9bbb-f6cca6ab0a52", "kubernetes.io/metadata.name":"namespaces-185", "namespaces-185":"updated", "pod-security.kubernetes.io/audit":"baseline", "pod-security.kubernetes.io/enforce":"baseline", "pod-security.kubernetes.io/warn":"baseline"}
  Dec  2 12:44:34.080: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-185" for this suite. @ 12/02/23 12:44:34.09
• [0.062 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]
test/e2e/network/service.go:1493
  STEP: Creating a kubernetes client @ 12/02/23 12:44:34.099
  Dec  2 12:44:34.099: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 12:44:34.1
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:34.119
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:34.123
  STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9531 @ 12/02/23 12:44:34.131
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/02/23 12:44:34.142
  STEP: creating service externalsvc in namespace services-9531 @ 12/02/23 12:44:34.142
  STEP: creating replication controller externalsvc in namespace services-9531 @ 12/02/23 12:44:34.153
  I1202 12:44:34.158593      18 runners.go:197] Created replication controller with name: externalsvc, namespace: services-9531, replica count: 2
  E1202 12:44:34.703336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:35.704139      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:36.704555      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 12:44:37.210243      18 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the ClusterIP service to type=ExternalName @ 12/02/23 12:44:37.213
  Dec  2 12:44:37.228: INFO: Creating new exec pod
  E1202 12:44:37.704640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:38.705189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:39.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-9531 exec execpod9szmz -- /bin/sh -x -c nslookup clusterip-service.services-9531.svc.cluster.local'
  Dec  2 12:44:39.380: INFO: stderr: "+ nslookup clusterip-service.services-9531.svc.cluster.local\n"
  Dec  2 12:44:39.380: INFO: stdout: "Server:\t\t10.152.183.66\nAddress:\t10.152.183.66#53\n\nclusterip-service.services-9531.svc.cluster.local\tcanonical name = externalsvc.services-9531.svc.cluster.local.\nName:\texternalsvc.services-9531.svc.cluster.local\nAddress: 10.152.183.20\n\n"
  Dec  2 12:44:39.380: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-9531, will wait for the garbage collector to delete the pods @ 12/02/23 12:44:39.384
  Dec  2 12:44:39.444: INFO: Deleting ReplicationController externalsvc took: 6.535667ms
  Dec  2 12:44:39.544: INFO: Terminating ReplicationController externalsvc pods took: 100.53063ms
  E1202 12:44:39.706165      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:40.706218      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:41.706386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:42.462: INFO: Cleaning up the ClusterIP to ExternalName test service
  STEP: Destroying namespace "services-9531" for this suite. @ 12/02/23 12:44:42.473
• [8.382 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]
test/e2e/apps/rc.go:85
  STEP: Creating a kubernetes client @ 12/02/23 12:44:42.481
  Dec  2 12:44:42.481: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replication-controller @ 12/02/23 12:44:42.482
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:42.499
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:42.502
  Dec  2 12:44:42.504: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
  E1202 12:44:42.706835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating rc "condition-test" that asks for more than the allowed pod quota @ 12/02/23 12:44:43.515
  STEP: Checking rc "condition-test" has the desired failure condition set @ 12/02/23 12:44:43.52
  E1202 12:44:43.707288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down rc "condition-test" to satisfy pod quota @ 12/02/23 12:44:44.528
  Dec  2 12:44:44.536: INFO: Updating replication controller "condition-test"
  STEP: Checking rc "condition-test" has no failure condition set @ 12/02/23 12:44:44.536
  E1202 12:44:44.707931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:45.546: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-387" for this suite. @ 12/02/23 12:44:45.55
• [3.076 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:119
  STEP: Creating a kubernetes client @ 12/02/23 12:44:45.558
  Dec  2 12:44:45.558: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:44:45.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:45.574
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:45.576
  STEP: Creating secret with name projected-secret-test-4d33c12c-ea45-4791-8a98-bb2efee361d7 @ 12/02/23 12:44:45.579
  STEP: Creating a pod to test consume secrets @ 12/02/23 12:44:45.583
  E1202 12:44:45.708442      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:46.708534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:44:47.601
  Dec  2 12:44:47.605: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-projected-secrets-5b59f684-ef2d-40ec-9030-485f591171e6 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 12:44:47.621
  Dec  2 12:44:47.635: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-2275" for this suite. @ 12/02/23 12:44:47.639
• [2.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]
test/e2e/apps/statefulset.go:961
  STEP: Creating a kubernetes client @ 12/02/23 12:44:47.645
  Dec  2 12:44:47.645: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 12:44:47.646
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:44:47.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:44:47.664
  STEP: Creating service test in namespace statefulset-4086 @ 12/02/23 12:44:47.667
  Dec  2 12:44:47.688: INFO: Found 0 stateful pods, waiting for 1
  E1202 12:44:47.709040      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:48.709147      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:49.709339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:50.709660      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:51.709758      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:52.709902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:53.710127      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:54.710241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:55.710309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:56.711328      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:57.693: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: patching the StatefulSet @ 12/02/23 12:44:57.701
  W1202 12:44:57.710470      18 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
  E1202 12:44:57.711512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:44:57.731: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:44:57.731: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Pending - Ready=false
  E1202 12:44:58.711647      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:44:59.712529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:00.712759      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:01.713370      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:02.713472      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:03.713548      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:04.713617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:05.713926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:06.714416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:07.714458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:45:07.736: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 12:45:07.736: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Listing all StatefulSets @ 12/02/23 12:45:07.743
  STEP: Delete all of the StatefulSets @ 12/02/23 12:45:07.747
  STEP: Verify that StatefulSets have been deleted @ 12/02/23 12:45:07.755
  Dec  2 12:45:07.759: INFO: Deleting all statefulset in ns statefulset-4086
  Dec  2 12:45:07.774: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4086" for this suite. @ 12/02/23 12:45:07.782
• [20.144 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should mount projected service account token [Conformance]
test/e2e/auth/service_accounts.go:275
  STEP: Creating a kubernetes client @ 12/02/23 12:45:07.791
  Dec  2 12:45:07.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svcaccounts @ 12/02/23 12:45:07.792
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:07.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:07.811
  STEP: Creating a pod to test service account token:  @ 12/02/23 12:45:07.815
  E1202 12:45:08.714948      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:09.715656      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:10.716588      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:11.716679      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:45:11.838
  Dec  2 12:45:11.841: INFO: Trying to get logs from node ip-172-31-1-50 pod test-pod-0caa45d4-490d-4342-bf35-83d472963d05 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:45:11.848
  Dec  2 12:45:11.870: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-9432" for this suite. @ 12/02/23 12:45:11.873
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:572
  STEP: Creating a kubernetes client @ 12/02/23 12:45:11.881
  Dec  2 12:45:11.881: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 12:45:11.882
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:11.895
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:11.898
  STEP: Setting up server cert @ 12/02/23 12:45:11.918
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 12:45:12.275
  STEP: Deploying the webhook pod @ 12/02/23 12:45:12.283
  STEP: Wait for the deployment to be ready @ 12/02/23 12:45:12.294
  Dec  2 12:45:12.304: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 12:45:12.716875      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:13.716922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 12:45:14.315
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 12:45:14.326
  E1202 12:45:14.717212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:45:15.326: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/02/23 12:45:15.398
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/02/23 12:45:15.438
  STEP: Deleting the collection of validation webhooks @ 12/02/23 12:45:15.467
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/02/23 12:45:15.519
  Dec  2 12:45:15.530: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-4456" for this suite. @ 12/02/23 12:45:15.569
  STEP: Destroying namespace "webhook-markers-2348" for this suite. @ 12/02/23 12:45:15.58
• [3.706 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController should release no longer matching pods [Conformance]
test/e2e/apps/rc.go:103
  STEP: Creating a kubernetes client @ 12/02/23 12:45:15.593
  Dec  2 12:45:15.593: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replication-controller @ 12/02/23 12:45:15.594
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:15.609
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:15.612
  STEP: Given a ReplicationController is created @ 12/02/23 12:45:15.614
  STEP: When the matched label of one of its pods change @ 12/02/23 12:45:15.619
  Dec  2 12:45:15.623: INFO: Pod name pod-release: Found 0 pods out of 1
  E1202 12:45:15.717523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:16.717753      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:17.717867      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:18.717943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:19.718019      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:45:20.627: INFO: Pod name pod-release: Found 1 pods out of 1
  STEP: Then the pod is released @ 12/02/23 12:45:20.638
  E1202 12:45:20.718533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:45:21.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-119" for this suite. @ 12/02/23 12:45:21.65
• [6.063 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]
test/e2e/apimachinery/garbage_collector.go:817
  STEP: Creating a kubernetes client @ 12/02/23 12:45:21.657
  Dec  2 12:45:21.657: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename gc @ 12/02/23 12:45:21.657
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:21.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:21.674
  E1202 12:45:21.718557      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:45:21.750: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"2a6a13a1-9cb1-4fc0-b8b9-ca72e8fcf83f", Controller:(*bool)(0xc004f7f746), BlockOwnerDeletion:(*bool)(0xc004f7f747)}}
  Dec  2 12:45:21.755: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f5840226-d02b-44c3-8aad-5037b3be51b2", Controller:(*bool)(0xc001babd1e), BlockOwnerDeletion:(*bool)(0xc001babd1f)}}
  Dec  2 12:45:21.761: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"8f4745e7-6f60-4b20-9308-301ae817e83f", Controller:(*bool)(0xc004f7f976), BlockOwnerDeletion:(*bool)(0xc004f7f977)}}
  E1202 12:45:22.718650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:23.718742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:24.718834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:25.718857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:26.718965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:45:26.775: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4860" for this suite. @ 12/02/23 12:45:26.78
• [5.131 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:213
  STEP: Creating a kubernetes client @ 12/02/23 12:45:26.788
  Dec  2 12:45:26.788: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/02/23 12:45:26.789
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:26.802
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:26.805
  STEP: create the container to handle the HTTPGet hook request. @ 12/02/23 12:45:26.811
  E1202 12:45:27.719095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:28.719273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/02/23 12:45:28.835
  E1202 12:45:29.719369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:30.719596      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 12/02/23 12:45:30.86
  E1202 12:45:31.719872      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:32.719956      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:33.720049      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:34.720138      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 12/02/23 12:45:34.884
  Dec  2 12:45:34.896: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1646" for this suite. @ 12/02/23 12:45:34.901
• [8.123 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:177
  STEP: Creating a kubernetes client @ 12/02/23 12:45:34.912
  Dec  2 12:45:34.912: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 12:45:34.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:34.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:34.931
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/02/23 12:45:34.977
  E1202 12:45:35.720784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:36.720882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:37.720985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:38.721064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:45:39
  Dec  2 12:45:39.002: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-ed0dd199-d69d-4955-82e6-e434ba055ac5 container test-container: <nil>
  STEP: delete the pod @ 12/02/23 12:45:39.01
  Dec  2 12:45:39.028: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2889" for this suite. @ 12/02/23 12:45:39.031
• [4.127 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]
test/e2e/network/endpointslice.go:355
  STEP: Creating a kubernetes client @ 12/02/23 12:45:39.04
  Dec  2 12:45:39.040: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename endpointslice @ 12/02/23 12:45:39.04
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:39.053
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:39.056
  STEP: getting /apis @ 12/02/23 12:45:39.059
  STEP: getting /apis/discovery.k8s.io @ 12/02/23 12:45:39.062
  STEP: getting /apis/discovery.k8s.iov1 @ 12/02/23 12:45:39.063
  STEP: creating @ 12/02/23 12:45:39.064
  STEP: getting @ 12/02/23 12:45:39.076
  STEP: listing @ 12/02/23 12:45:39.08
  STEP: watching @ 12/02/23 12:45:39.083
  Dec  2 12:45:39.083: INFO: starting watch
  STEP: cluster-wide listing @ 12/02/23 12:45:39.084
  STEP: cluster-wide watching @ 12/02/23 12:45:39.087
  Dec  2 12:45:39.087: INFO: starting watch
  STEP: patching @ 12/02/23 12:45:39.088
  STEP: updating @ 12/02/23 12:45:39.094
  Dec  2 12:45:39.101: INFO: waiting for watch events with expected annotations
  Dec  2 12:45:39.101: INFO: saw patched and updated annotations
  STEP: deleting @ 12/02/23 12:45:39.101
  STEP: deleting a collection @ 12/02/23 12:45:39.115
  Dec  2 12:45:39.134: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3084" for this suite. @ 12/02/23 12:45:39.138
• [0.105 seconds]
------------------------------
SSSS
------------------------------
[sig-network] Services should test the lifecycle of an Endpoint [Conformance]
test/e2e/network/service.go:3142
  STEP: Creating a kubernetes client @ 12/02/23 12:45:39.145
  Dec  2 12:45:39.145: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 12:45:39.146
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:39.16
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:39.162
  STEP: creating an Endpoint @ 12/02/23 12:45:39.168
  STEP: waiting for available Endpoint @ 12/02/23 12:45:39.173
  STEP: listing all Endpoints @ 12/02/23 12:45:39.174
  STEP: updating the Endpoint @ 12/02/23 12:45:39.178
  STEP: fetching the Endpoint @ 12/02/23 12:45:39.183
  STEP: patching the Endpoint @ 12/02/23 12:45:39.187
  STEP: fetching the Endpoint @ 12/02/23 12:45:39.194
  STEP: deleting the Endpoint by Collection @ 12/02/23 12:45:39.197
  STEP: waiting for Endpoint deletion @ 12/02/23 12:45:39.204
  STEP: fetching the Endpoint @ 12/02/23 12:45:39.206
  Dec  2 12:45:39.210: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2740" for this suite. @ 12/02/23 12:45:39.213
• [0.075 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:145
  STEP: Creating a kubernetes client @ 12/02/23 12:45:39.221
  Dec  2 12:45:39.221: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/02/23 12:45:39.221
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:39.233
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:39.236
  Dec  2 12:45:39.238: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 12:45:39.721847      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:45:39.778: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2759" for this suite. @ 12/02/23 12:45:39.783
• [0.571 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:47
  STEP: Creating a kubernetes client @ 12/02/23 12:45:39.792
  Dec  2 12:45:39.792: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:45:39.792
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:39.806
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:39.809
  STEP: Creating configMap with name projected-configmap-test-volume-681d38da-4c08-4138-9e6f-127401c455d8 @ 12/02/23 12:45:39.812
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:45:39.815
  E1202 12:45:40.722677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:41.723306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:42.723449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:43.723535      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:45:43.838
  Dec  2 12:45:43.841: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-configmaps-f3436388-53b6-4b17-85fd-a8f83ed8011d container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:45:43.849
  Dec  2 12:45:43.867: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-6710" for this suite. @ 12/02/23 12:45:43.872
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:218
  STEP: Creating a kubernetes client @ 12/02/23 12:45:43.88
  Dec  2 12:45:43.880: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 12:45:43.88
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:43.894
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:43.897
  STEP: Creating a pod to test downward api env vars @ 12/02/23 12:45:43.9
  E1202 12:45:44.723628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:45.724561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:46.725302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:47.725390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:45:47.92
  Dec  2 12:45:47.923: INFO: Trying to get logs from node ip-172-31-1-50 pod downward-api-fd8a40ef-82b9-458c-810f-4cc923e24941 container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 12:45:47.931
  Dec  2 12:45:47.945: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-3955" for this suite. @ 12/02/23 12:45:47.949
• [4.076 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:109
  STEP: Creating a kubernetes client @ 12/02/23 12:45:47.956
  Dec  2 12:45:47.956: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:45:47.956
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:47.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:47.983
  STEP: Creating configMap with name projected-configmap-test-volume-map-57f3358a-3527-4ff2-8476-2ecb4e63f2ac @ 12/02/23 12:45:47.986
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:45:47.99
  E1202 12:45:48.726277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:49.726388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:50.727298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:51.727392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:45:52.01
  Dec  2 12:45:52.013: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-configmaps-f78b678e-2516-4d17-9ffd-ab97e5c8c26d container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:45:52.02
  Dec  2 12:45:52.036: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9307" for this suite. @ 12/02/23 12:45:52.039
• [4.090 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]
test/e2e/apimachinery/resource_quota.go:693
  STEP: Creating a kubernetes client @ 12/02/23 12:45:52.047
  Dec  2 12:45:52.047: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 12:45:52.047
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:45:52.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:45:52.064
  STEP: Creating a ResourceQuota with terminating scope @ 12/02/23 12:45:52.067
  STEP: Ensuring ResourceQuota status is calculated @ 12/02/23 12:45:52.071
  E1202 12:45:52.727647      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:53.727754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota with not terminating scope @ 12/02/23 12:45:54.074
  STEP: Ensuring ResourceQuota status is calculated @ 12/02/23 12:45:54.08
  E1202 12:45:54.727838      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:55.728771      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a long running pod @ 12/02/23 12:45:56.083
  STEP: Ensuring resource quota with not terminating scope captures the pod usage @ 12/02/23 12:45:56.098
  E1202 12:45:56.729793      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:57.729902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with terminating scope ignored the pod usage @ 12/02/23 12:45:58.102
  E1202 12:45:58.729992      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:45:59.730066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/02/23 12:46:00.107
  STEP: Ensuring resource quota status released the pod usage @ 12/02/23 12:46:00.118
  E1202 12:46:00.730858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:01.731291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a terminating pod @ 12/02/23 12:46:02.122
  STEP: Ensuring resource quota with terminating scope captures the pod usage @ 12/02/23 12:46:02.135
  E1202 12:46:02.732165      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:03.732247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring resource quota with not terminating scope ignored the pod usage @ 12/02/23 12:46:04.139
  E1202 12:46:04.732600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:05.732766      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the pod @ 12/02/23 12:46:06.143
  STEP: Ensuring resource quota status released the pod usage @ 12/02/23 12:46:06.155
  E1202 12:46:06.733126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:07.733222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:08.159: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9587" for this suite. @ 12/02/23 12:46:08.162
• [16.123 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]
test/e2e/apimachinery/webhook.go:646
  STEP: Creating a kubernetes client @ 12/02/23 12:46:08.169
  Dec  2 12:46:08.169: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 12:46:08.17
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:46:08.184
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:46:08.186
  STEP: Setting up server cert @ 12/02/23 12:46:08.209
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 12:46:08.343
  STEP: Deploying the webhook pod @ 12/02/23 12:46:08.355
  STEP: Wait for the deployment to be ready @ 12/02/23 12:46:08.368
  Dec  2 12:46:08.374: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1202 12:46:08.733771      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:09.734038      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 12:46:10.385
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 12:46:10.394
  E1202 12:46:10.735025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:11.394: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Listing all of the created validation webhooks @ 12/02/23 12:46:11.476
  STEP: Creating a configMap that should be mutated @ 12/02/23 12:46:11.489
  STEP: Deleting the collection of validation webhooks @ 12/02/23 12:46:11.52
  STEP: Creating a configMap that should not be mutated @ 12/02/23 12:46:11.615
  Dec  2 12:46:11.630: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1202 12:46:11.735125      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-7715" for this suite. @ 12/02/23 12:46:11.785
  STEP: Destroying namespace "webhook-markers-8997" for this suite. @ 12/02/23 12:46:11.799
• [3.643 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]
test/e2e/apimachinery/namespace.go:303
  STEP: Creating a kubernetes client @ 12/02/23 12:46:11.814
  Dec  2 12:46:11.814: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename namespaces @ 12/02/23 12:46:11.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:46:11.832
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:46:11.835
  STEP: Read namespace status @ 12/02/23 12:46:11.84
  Dec  2 12:46:11.842: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
  STEP: Patch namespace status @ 12/02/23 12:46:11.842
  Dec  2 12:46:11.849: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
  STEP: Update namespace status @ 12/02/23 12:46:11.849
  Dec  2 12:46:11.857: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
  Dec  2 12:46:11.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-2946" for this suite. @ 12/02/23 12:46:11.862
• [0.057 seconds]
------------------------------
[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:399
  STEP: Creating a kubernetes client @ 12/02/23 12:46:11.872
  Dec  2 12:46:11.872: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 12:46:11.872
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:46:11.891
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:46:11.894
  STEP: creating the pod @ 12/02/23 12:46:11.897
  STEP: submitting the pod to kubernetes @ 12/02/23 12:46:11.897
  W1202 12:46:11.906465      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  E1202 12:46:12.735270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:13.735357      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/02/23 12:46:13.923
  STEP: updating the pod @ 12/02/23 12:46:13.927
  Dec  2 12:46:14.438: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9ff64e45-1774-4354-a4ce-1d471ea14501"
  E1202 12:46:14.735950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:15.736050      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:16.736116      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:17.736202      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:18.448: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-5729" for this suite. @ 12/02/23 12:46:18.451
• [6.587 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:207
  STEP: Creating a kubernetes client @ 12/02/23 12:46:18.459
  Dec  2 12:46:18.459: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 12:46:18.46
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:46:18.473
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:46:18.479
  STEP: Creating a pod to test emptydir 0666 on node default medium @ 12/02/23 12:46:18.483
  E1202 12:46:18.736882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:19.736865      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:20.737871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:21.737966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:46:22.506
  Dec  2 12:46:22.510: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-085beec1-e7fb-49ad-9f61-603d5eb52fd0 container test-container: <nil>
  STEP: delete the pod @ 12/02/23 12:46:22.516
  Dec  2 12:46:22.532: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1536" for this suite. @ 12/02/23 12:46:22.539
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:57
  STEP: Creating a kubernetes client @ 12/02/23 12:46:22.548
  Dec  2 12:46:22.548: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 12:46:22.548
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:46:22.569
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:46:22.571
  STEP: Creating configMap with name configmap-test-volume-499b2908-5450-43d0-b4db-f8ec9c0b9b20 @ 12/02/23 12:46:22.574
  STEP: Creating a pod to test consume configMaps @ 12/02/23 12:46:22.579
  E1202 12:46:22.738535      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:23.738638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:24.739094      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:25.739175      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:46:26.612
  Dec  2 12:46:26.616: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-c28430be-b89c-4b65-9434-ecb99743f96e container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 12:46:26.623
  Dec  2 12:46:26.639: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-3010" for this suite. @ 12/02/23 12:46:26.642
• [4.101 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:347
  STEP: Creating a kubernetes client @ 12/02/23 12:46:26.649
  Dec  2 12:46:26.649: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename security-context-test @ 12/02/23 12:46:26.65
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:46:26.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:46:26.686
  E1202 12:46:26.739737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:27.739978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:28.740309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:29.740470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:30.709: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9996" for this suite. @ 12/02/23 12:46:30.713
• [4.071 seconds]
------------------------------
S
------------------------------
[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:183
  STEP: Creating a kubernetes client @ 12/02/23 12:46:30.721
  Dec  2 12:46:30.721: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 12:46:30.721
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:46:30.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:46:30.74
  E1202 12:46:30.740461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231 @ 12/02/23 12:46:30.743
  E1202 12:46:31.740740      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:32.741035      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 12:46:32.762
  Dec  2 12:46:32.764: INFO: Initial restart count of pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 is 0
  Dec  2 12:46:32.768: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:33.741243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:34.741327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:34.776: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:35.741465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:36.742396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:36.780: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:37.742465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:38.743271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:38.784: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:39.743572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:40.743746      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:40.788: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:41.743861      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:42.743953      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:42.793: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:43.744184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:44.744263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:44.796: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:45.744533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:46.744615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:46.801: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:47.745636      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:48.745800      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:48.804: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:49.745848      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:50.746585      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:50.810: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:51.747304      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:52.747902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:52.814: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:53.748005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:54.748168      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:54.820: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:55.748773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:56.748876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:56.824: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:57.749164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:46:58.749340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:46:58.828: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:46:59.749411      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:00.750406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:00.832: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:01.750498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:02.751297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:02.838: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:03.752012      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:04.752096      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:04.842: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:05.752207      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:06.752270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:06.847: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:07.752577      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:08.752666      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:08.851: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:09.752757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:10.753753      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:10.854: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:11.753849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:12.754506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:12.859: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:13.754048      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:14.754213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:14.862: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:15.754777      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:16.754878      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:16.866: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:17.755660      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:18.755809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:18.870: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:19.755954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:20.756056      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:20.874: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:21.756624      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:22.756805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:22.879: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:23.757401      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:24.757562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:24.883: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:25.758533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:26.758617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:26.888: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:27.759279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:28.760191      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:28.893: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:29.760564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:30.760650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:30.897: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:31.760793      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:32.760874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:32.902: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:33.761245      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:34.761392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:34.906: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:35.761483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:36.761650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:36.910: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:37.761796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:38.762750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:38.915: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:39.762844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:40.763690      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:40.918: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:41.764253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:42.765078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:42.922: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:43.765165      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:44.765262      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:44.927: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:45.765845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:46.765936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:46.930: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:47.766334      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:48.766425      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:48.934: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:49.767293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:50.767398      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:50.939: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:51.767471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:52.768505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:52.943: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:53.768827      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:54.769595      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:54.949: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:55.769689      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:56.769823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:56.952: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:57.770216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:47:58.771281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:47:58.956: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:47:59.771402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:00.771491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:00.961: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:01.771580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:02.771769      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:02.966: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:03.772462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:04.772550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:04.971: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:05.772672      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:06.772774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:06.975: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:07.773796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:08.774210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:08.979: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:09.775276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:10.775540      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:10.984: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:11.776225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:12.776458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:12.987: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:13.776544      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:14.776627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:14.992: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:15.777590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:16.777781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:16.996: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:17.777900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:18.777971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:19.000: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:19.778215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:20.779277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:21.005: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:21.779455      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:22.779551      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:23.009: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:23.780297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:24.780389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:25.012: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:25.780514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:26.781200      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:27.016: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:27.781281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:28.781318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:29.022: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:29.781392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:30.782205      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:31.026: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:31.782485      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:32.782858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:33.031: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:33.783420      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:34.784423      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:35.036: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:35.784790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:36.785592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:37.040: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:37.786213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:38.787276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:39.045: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:39.787864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:40.787949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:41.048: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:41.788132      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:42.788278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:43.053: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:43.788373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:44.788461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:45.057: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:45.789435      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:46.789523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:47.061: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:47.790348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:48.790441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:49.065: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:49.791274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:50.792328      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:51.070: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:51.792412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:52.792579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:53.073: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:53.793551      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:54.794142      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:55.080: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:55.794220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:56.794328      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:57.085: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:57.795282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:48:58.795404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:48:59.089: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:48:59.795488      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:00.795658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:01.093: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:01.795748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:02.795956      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:03.096: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:03.796534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:04.796624      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:05.101: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:05.796883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:06.797844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:07.104: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:07.798600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:08.798695      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:09.109: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:09.799313      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:10.799486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:11.113: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:11.800176      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:12.800406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:13.118: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:13.800540      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:14.800741      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:15.123: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:15.801271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:16.801434      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:17.128: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:17.801526      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:18.801698      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:19.131: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:19.802365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:20.802453      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:21.134: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:21.803273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:22.804229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:23.138: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:23.805228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:24.805469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:25.143: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:25.806209      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:26.807272      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:27.147: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:27.808061      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:28.808303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:29.151: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:29.809162      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:30.809248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:31.154: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:31.809329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:32.809457      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:33.158: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:33.810346      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:34.811277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:35.161: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:35.811828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:36.811920      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:37.166: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:37.812534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:38.812676      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:39.170: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:39.812746      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:40.812802      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:41.174: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:41.813500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:42.814200      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:43.179: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:43.814219      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:44.814337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:45.183: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:45.814640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:46.815312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:47.188: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:47.815750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:48.816826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:49.191: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:49.817277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:50.817548      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:51.195: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:51.817856      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:52.818005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:53.199: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:53.818334      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:54.819279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:55.203: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:55.819592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:56.819687      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:57.206: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:57.819717      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:49:58.819804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:49:59.210: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:49:59.819866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:00.819946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:01.214: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:01.820467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:02.820962      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:03.218: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:03.821447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:04.822074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:05.222: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:05.822861      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:06.822938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:07.226: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:07.823276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:08.823411      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:09.230: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:09.823497      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:10.823761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:11.235: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:11.824155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:12.824247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:13.238: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:13.825250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:14.825338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:15.243: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:15.826372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:16.826467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:17.246: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:17.826557      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:18.826659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:19.251: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:19.826980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:20.827023      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:21.255: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:21.827282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:22.827821      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:23.262: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:23.827908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:24.828055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:25.273: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:25.828635      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:26.829340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:27.278: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:27.830002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:28.830265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:29.281: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:29.830352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:30.830700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:31.286: INFO: Get pod liveness-9a2c0bf0-c5cc-416c-9936-73231d0fda46 in namespace container-probe-5231
  E1202 12:50:31.830913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:32.831410      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:50:33.287: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 12:50:33.29
  STEP: Destroying namespace "container-probe-5231" for this suite. @ 12/02/23 12:50:33.303
• [242.589 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]
test/e2e/apps/cronjob.go:97
  STEP: Creating a kubernetes client @ 12/02/23 12:50:33.31
  Dec  2 12:50:33.311: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename cronjob @ 12/02/23 12:50:33.311
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:50:33.327
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:50:33.33
  STEP: Creating a suspended cronjob @ 12/02/23 12:50:33.332
  STEP: Ensuring no jobs are scheduled @ 12/02/23 12:50:33.34
  E1202 12:50:33.832420      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:34.832515      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:35.833368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:36.833520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:37.833574      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:38.834136      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:39.835109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:40.835314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:41.836175      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:42.836269      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:43.837249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:44.837506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:45.837633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:46.838232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:47.838323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:48.839301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:49.839386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:50.839647      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:51.840508      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:52.840594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:53.841650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:54.841761      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:55.841786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:56.841881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:57.842235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:58.843295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:50:59.844277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:00.844366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:01.845229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:02.845316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:03.846358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:04.847290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:05.848093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:06.848607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:07.849376      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:08.849467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:09.849556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:10.849792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:11.849893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:12.850138      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:13.850178      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:14.850235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:15.851278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:16.851448      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:17.851917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:18.852172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:19.852637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:20.852729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:21.853430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:22.854271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:23.854775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:24.855277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:25.855495      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:26.856451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:27.857501      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:28.857718      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:29.857843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:30.858659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:31.858742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:32.859274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:33.860246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:34.860333      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:35.861092      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:36.861396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:37.862058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:38.862218      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:39.863274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:40.863356      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:41.863445      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:42.863545      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:43.864485      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:44.864709      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:45.865022      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:46.865710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:47.866725      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:48.867273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:49.868182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:50.868270      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:51.868449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:52.868579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:53.869438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:54.869610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:55.869692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:56.869851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:57.870889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:58.870980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:51:59.871426      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:00.872292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:01.873353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:02.873586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:03.874556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:04.874648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:05.875275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:06.875369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:07.875784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:08.875947      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:09.876884      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:10.877556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:11.877946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:12.878121      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:13.879003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:14.879281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:15.880327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:16.880424      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:17.880677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:18.880846      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:19.881097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:20.882026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:21.882369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:22.883288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:23.884008      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:24.884960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:25.885069      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:26.885492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:27.886211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:28.887274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:29.888212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:30.888483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:31.888583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:32.888680      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:33.888764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:34.888860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:35.889238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:36.889407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:37.889512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:38.889808      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:39.890217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:40.890310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:41.891239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:42.891415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:43.891746      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:44.891834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:45.892729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:46.892818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:47.892860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:48.893027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:49.893760      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:50.894622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:51.894882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:52.895282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:53.895830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:54.896002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:55.896473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:56.897137      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:57.897738      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:58.897965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:52:59.898805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:00.899182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:01.900122      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:02.901184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:03.901273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:04.901479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:05.901580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:06.901746      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:07.901833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:08.902073      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:09.902838      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:10.903026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:11.903667      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:12.903902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:13.904553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:14.904558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:15.905318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:16.905510      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:17.906285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:18.906375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:19.907279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:20.907363      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:21.908384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:22.908791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:23.909137      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:24.909306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:25.909570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:26.909725      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:27.909813      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:28.910554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:29.910646      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:30.911274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:31.911361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:32.911453      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:33.911542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:34.912562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:35.912863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:36.912950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:37.913037      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:38.913063      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:39.913141      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:40.914129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:41.914220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:42.914325      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:43.915291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:44.915678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:45.916358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:46.916448      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:47.917203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:48.917379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:49.917496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:50.917783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:51.917853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:52.918009      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:53.918095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:54.918213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:55.919274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:56.920186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:57.920567      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:58.920728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:53:59.921765      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:00.921852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:01.922555      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:02.922626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:03.922712      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:04.923281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:05.924079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:06.924185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:07.924212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:08.925279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:09.926203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:10.926286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:11.927151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:12.928079      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:13.928170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:14.928413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:15.929096      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:16.929182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:17.930204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:18.930229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:19.930807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:20.930895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:21.931893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:22.931990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:23.932470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:24.932599      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:25.932684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:26.932836      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:27.932926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:28.933072      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:29.933111      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:30.933196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:31.933770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:32.933918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:33.934423      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:34.934725      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:35.934901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:36.935329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:37.936201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:38.936291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:39.937283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:40.937393      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:41.937568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:42.937721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:43.938247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:44.938316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:45.939348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:46.940327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:47.940924      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:48.940993      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:49.941853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:50.941939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:51.942727      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:52.943280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:53.943877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:54.944685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:55.945412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:56.946035      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:57.946637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:58.946727      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:54:59.947245      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:00.947343      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:01.947426      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:02.947655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:03.948459      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:04.949275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:05.949592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:06.950576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:07.950671      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:08.951281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:09.951514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:10.951794      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:11.952058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:12.952306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:13.952373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:14.952457      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:15.953402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:16.953546      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:17.953602      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:18.953770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:19.954201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:20.955238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:21.955553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:22.955656      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:23.955742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:24.955828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:25.956710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:26.957521      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:27.958320      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:28.959281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:29.959637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:30.959728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:31.960762      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:32.961265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring no job exists by listing jobs explicitly @ 12/02/23 12:55:33.348
  STEP: Removing cronjob @ 12/02/23 12:55:33.352
  Dec  2 12:55:33.357: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4569" for this suite. @ 12/02/23 12:55:33.361
• [300.057 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]
test/e2e/apps/deployment.go:105
  STEP: Creating a kubernetes client @ 12/02/23 12:55:33.369
  Dec  2 12:55:33.369: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 12:55:33.37
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:55:33.385
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:55:33.387
  Dec  2 12:55:33.390: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
  Dec  2 12:55:33.398: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1202 12:55:33.961666      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:34.961747      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:35.962186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:36.962249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:37.962320      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:38.402: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/02/23 12:55:38.402
  Dec  2 12:55:38.402: INFO: Creating deployment "test-rolling-update-deployment"
  Dec  2 12:55:38.408: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
  Dec  2 12:55:38.418: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
  E1202 12:55:38.962430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:39.962508      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:40.427: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
  Dec  2 12:55:40.430: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
  Dec  2 12:55:40.440: INFO: Deployment "test-rolling-update-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2051",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ced30cc7-87f8-4276-8aba-cad920a39f82",
      ResourceVersion: (string) (len=5) "21285",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837118538,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=637) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 61  67 6e 68 6f 73 74 5c 22  |me\":\"agnhost\"|
              00000160  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000170  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000180  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000190  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              000001a0  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              000001b0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001c0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              000001d0  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              000001e0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001f0  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000200  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              00000210  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              00000220  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              00000230  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000270  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=10) "sample-pod"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=82) "ReplicaSet \"test-rolling-update-deployment-7f5c55c64\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  2 12:55:40.444: INFO: New ReplicaSet "test-rolling-update-deployment-7f5c55c64" of Deployment "test-rolling-update-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2051",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "978b26e8-9afb-4ded-9fe7-0bb14814bc03",
      ResourceVersion: (string) (len=5) "21275",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837118538,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305833"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "ced30cc7-87f8-4276-8aba-cad920a39f82",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=783) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 63 65 64 33 30 63  63 37 2d 38 37 66 38 2d  |\"ced30cc7-87f8-|
              00000120  34 32 37 36 2d 38 61 62  61 2d 63 61 64 39 32 30  |4276-8aba-cad920|
              00000130  61 33 39 66 38 32 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |a39f82\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 61 67 6e 68 6f 73 74  |name\":\"agnhost|
              000001f0  5c 22 7d 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |\"}":{".":{},"f:|
              00000200  69 6d 61 67 65 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |image":{},"f:ima|
              00000210  67 65 50 75 6c 6c 50 6f  6c 69 63 79 22 3a 7b 7d  |gePullPolicy":{}|
              00000220  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000230  72 65 73 6f 75 72 63 65  73 22 3a 7b 7d 2c 22 66  |resources":{},"f|
              00000240  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              00000250  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000260  69 6f 6e 4d 65 73 73 61  67 65 50 61 74 68 22 3a  |ionMessagePath":|
              00000270  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000280  6e 4d 65 73 73 61 67 65  50 6f 6c 69 63 79 22 3a  |nMessagePolicy":|
              00000290  7b 7d 7d 7d 2c 22 66 3a  64 6e 73 50 6f 6c 69 63  |{}}},"f:dnsPolic|
              000002a0  79 22 3a 7b 7d 2c 22 66  3a 72 65 73 74 61 72 74  |y":{},"f:restart|
              000002b0  50 6f 6c 69 63 79 22 3a  7b 7d 2c 22 66 3a 73 63  |Policy":{},"f:sc|
              000002c0  68 65 64 75 6c 65 72 4e  61 6d 65 22 3a 7b 7d 2c  |hedulerName":{},|
              000002d0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000002e0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000002f0  61 74 69 6f 6e 47 72 61  63 65 50 65 72 69 6f 64  |ationGracePeriod|
              00000300  53 65 63 6f 6e 64 73 22  3a 7b 7d 7d 7d 7d 7d     |Seconds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64",
          (string) (len=4) "name": (string) (len=10) "sample-pod"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=7) "agnhost",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:55:40.445: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
  Dec  2 12:55:40.445: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-rolling-update-controller",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-2051",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8d8aedc5-e273-4020-9f1f-da8af0b27359",
      ResourceVersion: (string) (len=5) "21284",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837118533,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=10) "sample-pod",
        (string) (len=3) "pod": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=19) "3546343826724305832"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=30) "test-rolling-update-deployment",
          UID: (types.UID) (len=36) "ced30cc7-87f8-4276-8aba-cad920a39f82",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118533,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=533) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  2c 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |,"f:labels":{"."|
              00000060  3a 7b 7d 2c 22 66 3a 6e  61 6d 65 22 3a 7b 7d 2c  |:{},"f:name":{},|
              00000070  22 66 3a 70 6f 64 22 3a  7b 7d 7d 7d 2c 22 66 3a  |"f:pod":{}}},"f:|
              00000080  73 70 65 63 22 3a 7b 22  66 3a 73 65 6c 65 63 74  |spec":{"f:select|
              00000090  6f 72 22 3a 7b 7d 2c 22  66 3a 74 65 6d 70 6c 61  |or":{},"f:templa|
              000000a0  74 65 22 3a 7b 22 66 3a  6d 65 74 61 64 61 74 61  |te":{"f:metadata|
              000000b0  22 3a 7b 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |":{"f:labels":{"|
              000000c0  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              000000d0  7d 2c 22 66 3a 70 6f 64  22 3a 7b 7d 7d 7d 2c 22  |},"f:pod":{}}},"|
              000000e0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000f0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              00000100  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              00000110  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000120  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000130  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000140  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000150  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 74 65  |ources":{},"f:te|
              00000160  72 6d 69 6e 61 74 69 6f  6e 4d 65 73 73 61 67 65  |rminationMessage|
              00000170  50 61 74 68 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |Path":{},"f:term|
              00000180  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 6f  |inationMessagePo|
              00000190  6c 69 63 79 22 3a 7b 7d  7d 7d 2c 22 66 3a 64 6e  |licy":{}}},"f:dn|
              000001a0  73 50 6f 6c 69 63 79 22  3a 7b 7d 2c 22 66 3a 72  |sPolicy":{},"f:r|
              000001b0  65 73 74 61 72 74 50 6f  6c 69 63 79 22 3a 7b 7d  |estartPolicy":{}|
              000001c0  2c 22 66 3a 73 63 68 65  64 75 6c 65 72 4e 61 6d  |,"f:schedulerNam|
              000001d0  65 22 3a 7b 7d 2c 22 66  3a 73 65 63 75 72 69 74  |e":{},"f:securit|
              000001e0  79 43 6f 6e 74 65 78 74  22 3a 7b 7d 2c 22 66 3a  |yContext":{},"f:|
              000001f0  74 65 72 6d 69 6e 61 74  69 6f 6e 47 72 61 63 65  |terminationGrace|
              00000200  50 65 72 69 6f 64 53 65  63 6f 6e 64 73 22 3a 7b  |PeriodSeconds":{|
              00000210  7d 7d 7d 7d 7d                                    |}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=242) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 66 3a 64 65 70 6c 6f  79 6d 65 6e 74 2e 6b 75  |"f:deployment.ku|
              00000030  62 65 72 6e 65 74 65 73  2e 69 6f 2f 64 65 73 69  |bernetes.io/desi|
              00000040  72 65 64 2d 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |red-replicas":{}|
              00000050  2c 22 66 3a 64 65 70 6c  6f 79 6d 65 6e 74 2e 6b  |,"f:deployment.k|
              00000060  75 62 65 72 6e 65 74 65  73 2e 69 6f 2f 6d 61 78  |ubernetes.io/max|
              00000070  2d 72 65 70 6c 69 63 61  73 22 3a 7b 7d 7d 2c 22  |-replicas":{}},"|
              00000080  66 3a 6f 77 6e 65 72 52  65 66 65 72 65 6e 63 65  |f:ownerReference|
              00000090  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 6b 3a 7b 5c  |s":{".":{},"k:{\|
              000000a0  22 75 69 64 5c 22 3a 5c  22 63 65 64 33 30 63 63  |"uid\":\"ced30cc|
              000000b0  37 2d 38 37 66 38 2d 34  32 37 36 2d 38 61 62 61  |7-87f8-4276-8aba|
              000000c0  2d 63 61 64 39 32 30 61  33 39 66 38 32 5c 22 7d  |-cad920a39f82\"}|
              000000d0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 70 65 63 22 3a  |":{}}},"f:spec":|
              000000e0  7b 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |{"f:replicas":{}|
              000000f0  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=10) "sample-pod",
          (string) (len=3) "pod": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=10) "sample-pod",
            (string) (len=3) "pod": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)(<nil>),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 12:55:40.450: INFO: Pod "test-rolling-update-deployment-7f5c55c64-hjwlh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=46) "test-rolling-update-deployment-7f5c55c64-hjwlh",
      GenerateName: (string) (len=41) "test-rolling-update-deployment-7f5c55c64-",
      Namespace: (string) (len=15) "deployment-2051",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "36678ee3-e0dd-487a-a07f-828a7a42927a",
      ResourceVersion: (string) (len=5) "21274",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837118538,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "7f5c55c64",
        (string) (len=4) "name": (string) (len=10) "sample-pod"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=40) "test-rolling-update-deployment-7f5c55c64",
          UID: (types.UID) (len=36) "978b26e8-9afb-4ded-9fe7-0bb14814bc03",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=539) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 39 37  38 62 32 36 65 38 2d 39  |d\":\"978b26e8-9|
              00000090  61 66 62 2d 34 64 65 64  2d 39 66 65 37 2d 30 62  |afb-4ded-9fe7-0b|
              000000a0  62 31 34 38 31 34 62 63  30 33 5c 22 7d 22 3a 7b  |b14814bc03\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 61 67 6e  |:{\"name\":\"agn|
              000000e0  68 6f 73 74 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |host\"}":{".":{}|
              000000f0  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000100  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000110  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000120  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000130  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000140  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000150  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000160  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000170  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              00000180  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              00000190  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 65 6e 61  |olicy":{},"f:ena|
              000001a0  62 6c 65 53 65 72 76 69  63 65 4c 69 6e 6b 73 22  |bleServiceLinks"|
              000001b0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000001c0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000001d0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000001e0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000210  63 6f 6e 64 73 22 3a 7b  7d 7d 7d                 |conds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 31 2e 31 39 38 5c 22  |192.168.21.198\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fvljl",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=7) "agnhost",
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fvljl",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118539,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837118538,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.198",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.198"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837118538,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=7) "agnhost",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837118539,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
          ImageID: (string) (len=111) "registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4",
          ContainerID: (string) (len=77) "containerd://1b3228de74d611b6a4e3d948741eeaf44b7a4caed5546a8a6a88046f251d7390",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 12:55:40.452: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-2051" for this suite. @ 12/02/23 12:55:40.456
• [7.094 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:153
  STEP: Creating a kubernetes client @ 12/02/23 12:55:40.463
  Dec  2 12:55:40.463: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 12:55:40.464
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:55:40.477
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:55:40.48
  Dec  2 12:55:40.483: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 12:55:40.962597      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/02/23 12:55:41.709
  Dec  2 12:55:41.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-4202 --namespace=crd-publish-openapi-4202 create -f -'
  E1202 12:55:41.962667      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:42.072: INFO: stderr: ""
  Dec  2 12:55:42.072: INFO: stdout: "e2e-test-crd-publish-openapi-8356-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec  2 12:55:42.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-4202 --namespace=crd-publish-openapi-4202 delete e2e-test-crd-publish-openapi-8356-crds test-cr'
  Dec  2 12:55:42.125: INFO: stderr: ""
  Dec  2 12:55:42.125: INFO: stdout: "e2e-test-crd-publish-openapi-8356-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  Dec  2 12:55:42.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-4202 --namespace=crd-publish-openapi-4202 apply -f -'
  Dec  2 12:55:42.234: INFO: stderr: ""
  Dec  2 12:55:42.234: INFO: stdout: "e2e-test-crd-publish-openapi-8356-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
  Dec  2 12:55:42.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-4202 --namespace=crd-publish-openapi-4202 delete e2e-test-crd-publish-openapi-8356-crds test-cr'
  Dec  2 12:55:42.301: INFO: stderr: ""
  Dec  2 12:55:42.301: INFO: stdout: "e2e-test-crd-publish-openapi-8356-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR without validation schema @ 12/02/23 12:55:42.301
  Dec  2 12:55:42.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-4202 explain e2e-test-crd-publish-openapi-8356-crds'
  Dec  2 12:55:42.610: INFO: stderr: ""
  Dec  2 12:55:42.610: INFO: stdout: "GROUP:      crd-publish-openapi-test-empty.example.com\nKIND:       e2e-test-crd-publish-openapi-8356-crd\nVERSION:    v1\n\nDESCRIPTION:\n    <empty>\nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n\n"
  E1202 12:55:42.963068      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:43.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-4202" for this suite. @ 12/02/23 12:55:43.842
• [3.385 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:208
  STEP: Creating a kubernetes client @ 12/02/23 12:55:43.849
  Dec  2 12:55:43.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 12:55:43.849
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:55:43.886
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:55:43.889
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 12:55:43.894
  E1202 12:55:43.963696      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:44.963733      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:45.963901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:46.964037      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 12:55:47.915
  Dec  2 12:55:47.918: INFO: Trying to get logs from node ip-172-31-74-39 pod downwardapi-volume-d30f22a4-5c32-4c68-b7b6-8ab41d7ba792 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 12:55:47.934
  Dec  2 12:55:47.951: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-290" for this suite. @ 12/02/23 12:55:47.954
• [4.111 seconds]
------------------------------
[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:214
  STEP: Creating a kubernetes client @ 12/02/23 12:55:47.96
  Dec  2 12:55:47.960: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 12:55:47.961
  E1202 12:55:47.964849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:55:47.979
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:55:47.981
  STEP: Creating pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384 @ 12/02/23 12:55:47.983
  E1202 12:55:48.964983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:49.965913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 12:55:50
  Dec  2 12:55:50.003: INFO: Initial restart count of pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 is 0
  Dec  2 12:55:50.005: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:55:50.966024      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:51.966131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:52.011: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:55:52.966340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:53.967115      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:54.014: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:55:54.967144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:55.967221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:56.019: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:55:56.967590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:57.967672      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:55:58.023: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:55:58.967833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:55:59.967921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:00.027: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:00.967996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:01.968330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:02.032: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:02.968489      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:03.968737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:04.036: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:04.968829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:05.968951      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:06.041: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:06.969003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:07.969181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:08.044: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:08.969905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:09.969999      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:10.048: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:10.970233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:11.971294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:12.054: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:12.972229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:13.972308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:14.058: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:14.972950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:15.973002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:16.062: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:16.973078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:17.973177      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:18.067: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:18.973834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:19.973923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:20.070: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:20.974437      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:21.974535      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:22.075: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:22.975291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:23.976705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:24.080: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:24.976774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:25.976867      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:26.084: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:26.977871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:27.978032      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:28.088: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:28.978294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:29.978369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:30.093: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:30.978860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:31.978955      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:32.098: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:32.979043      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:33.979295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:34.101: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:34.979598      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:35.979691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:36.105: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:36.979780      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:37.979962      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:38.110: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:38.980434      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:39.980614      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:40.115: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:40.981016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:41.981134      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:42.119: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:42.981210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:43.981418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:44.123: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:44.981491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:45.982208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:46.126: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:46.982236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:47.982324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:48.131: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:48.983290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:49.983371      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:50.135: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:50.983857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:51.983978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:52.140: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:52.984305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:53.986681      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:54.144: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:54.987443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:55.987774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:56.148: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:56.988513      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:57.988610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:56:58.152: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:56:58.989438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:56:59.989529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:00.156: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:00.989963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:01.990055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:02.160: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:02.990973      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:03.991332      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:04.163: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:04.991830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:05.991967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:06.167: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:06.992075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:07.992294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:08.173: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:08.993239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:09.993870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:10.177: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:10.994629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:11.994744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:12.181: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:12.995583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:13.995714      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:14.185: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:14.996103      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:15.996204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:16.190: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:16.996869      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:17.997147      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:18.194: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:18.998168      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:19.998225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:20.197: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:20.999296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:21.999390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:22.201: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:23.000200      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:24.000812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:24.205: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:25.000895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:26.001593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:26.209: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:27.001683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:28.001854      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:28.214: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:29.001879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:30.001958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:30.217: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:31.002063      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:32.002235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:32.221: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:33.002326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:34.002463      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:34.225: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:35.003383      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:36.003560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:36.229: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:37.003842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:38.003935      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:38.232: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:39.004571      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:40.005427      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:40.237: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:41.005886      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:42.005971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:42.240: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:43.006231      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:44.006316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:44.244: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:45.007168      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:46.007236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:46.248: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:47.007323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:48.007425      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:48.253: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:49.008487      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:50.008565      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:50.257: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:51.009007      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:52.009164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:52.260: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:53.009415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:54.009504      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:54.265: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:55.009998      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:56.010636      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:56.269: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:57.011275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:57:58.011542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:57:58.273: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:57:59.012438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:00.012529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:00.278: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:01.013042      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:02.013213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:02.282: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:03.013411      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:04.013507      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:04.286: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:05.013924      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:06.014867      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:06.290: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:07.015364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:08.015520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:08.294: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:09.015938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:10.016191      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:10.299: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:11.016375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:12.016462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:12.303: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:13.017510      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:14.017682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:14.306: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:15.018211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:16.019283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:16.310: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:17.019605      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:18.020476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:18.314: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:19.021493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:20.022308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:20.317: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:21.022396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:22.022488      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:22.322: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:23.023500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:24.023639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:24.326: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:25.024028      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:26.024227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:26.330: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:27.024318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:28.024424      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:28.335: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:29.024989      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:30.025074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:30.339: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:31.025406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:32.025906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:32.401: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:33.026783      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:34.026868      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:34.405: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:35.026958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:36.027013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:36.409: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:37.027104      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:38.027197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:38.415: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:39.027953      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:40.028043      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:40.419: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:41.028136      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:42.029123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:42.423: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:43.029355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:44.029449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:44.428: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:45.029553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:46.029884      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:46.432: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:47.030131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:48.030817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:48.438: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:49.031300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:50.031475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:50.443: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:51.032365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:52.032568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:52.447: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:53.033253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:54.033904      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:54.452: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:55.034250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:56.034321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:56.457: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:57.034516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:58:58.035575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:58:58.461: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:58:59.036544      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:00.036731      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:00.466: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:01.037274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:02.037369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:02.470: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:03.038325      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:04.039289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:04.475: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:05.040070      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:06.040462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:06.479: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:07.041027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:08.041086      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:08.484: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:09.041967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:10.042077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:10.488: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:11.042172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:12.042238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:12.491: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:13.043296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:14.043469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:14.497: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:15.044299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:16.044631      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:16.501: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:17.045361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:18.045449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:18.505: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:19.045948      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:20.046044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:20.509: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:21.046231      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:22.046323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:22.514: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:23.046808      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:24.046882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:24.518: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:25.047030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:26.047065      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:26.522: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:27.047284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:28.047475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:28.526: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:29.048265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:30.048358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:30.530: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:31.048603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:32.048686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:32.535: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:33.048775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:34.049003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:34.539: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:35.049711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:36.049968      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:36.543: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:37.050283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:38.051286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:38.549: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:39.051889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:40.051969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:40.553: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:41.052749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:42.052922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:42.557: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:43.053523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:44.053727      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:44.561: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:45.054326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:46.055284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:46.565: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:47.055362      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:48.055613      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:48.570: INFO: Get pod test-webserver-59477cc1-293d-4cd9-811b-642a1b380954 in namespace container-probe-384
  E1202 12:59:49.056243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:50.056394      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:50.571: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 12:59:50.574
  STEP: Destroying namespace "container-probe-384" for this suite. @ 12/02/23 12:59:50.588
• [242.637 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:184
  STEP: Creating a kubernetes client @ 12/02/23 12:59:50.597
  Dec  2 12:59:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubelet-test @ 12/02/23 12:59:50.598
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:59:50.616
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:59:50.618
  E1202 12:59:51.057033      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:52.057217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 12:59:52.653: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-1366" for this suite. @ 12/02/23 12:59:52.657
• [2.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:124
  STEP: Creating a kubernetes client @ 12/02/23 12:59:52.663
  Dec  2 12:59:52.663: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 12:59:52.664
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 12:59:52.681
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 12:59:52.684
  STEP: Creating projection with configMap that has name projected-configmap-test-upd-87d931e7-3973-4695-99bf-8ec562ce1244 @ 12/02/23 12:59:52.689
  STEP: Creating the pod @ 12/02/23 12:59:52.693
  E1202 12:59:53.058352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:54.058385      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating configmap projected-configmap-test-upd-87d931e7-3973-4695-99bf-8ec562ce1244 @ 12/02/23 12:59:54.724
  STEP: waiting to observe update in volume @ 12/02/23 12:59:54.728
  E1202 12:59:55.059275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:56.059380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:57.059466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:58.059639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 12:59:59.060273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:00.060448      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:01.060849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:02.061016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:03.061116      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:04.061342      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:05.062212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:06.062249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:07.062634      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:08.062723      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:09.063349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:10.063445      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:11.064151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:12.064234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:13.064845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:14.065243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:15.065784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:16.066173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:17.066225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:18.067288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:19.068300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:20.068479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:21.068934      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:22.069105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:23.069243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:24.069409      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:25.070210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:26.070547      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:27.071281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:28.071392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:29.072395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:30.072500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:31.072584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:32.072677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:33.073256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:34.074297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:35.074810      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:36.074908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:37.074993      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:38.075131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:39.075819      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:40.076156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:41.076832      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:42.076931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:43.077853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:44.078174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:45.079188      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:46.079313      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:47.079383      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:48.079483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:49.079706      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:50.080784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:51.081389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:52.082377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:53.083032      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:54.083156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:55.083745      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:56.083864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:57.084797      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:58.084894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:00:59.085936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:00.086172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:01.086428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:02.087300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:03.087359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:04.087519      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:05.087954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:06.088186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:07.088375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:08.088553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:09.088752      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:10.088950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:11.089758      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:12.089877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:13.090449      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:14.090550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:15.091505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:16.091756      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:17.092413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:18.092590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:19.093393      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:20.093647      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:21.093818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:22.093945      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:23.094062      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:24.094236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:25.086: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-7200" for this suite. @ 12/02/23 13:01:25.089
  E1202 13:01:25.094694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
• [92.434 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:498
  STEP: Creating a kubernetes client @ 12/02/23 13:01:25.098
  Dec  2 13:01:25.098: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:01:25.098
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:25.121
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:25.123
  STEP: Setting up server cert @ 12/02/23 13:01:25.146
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:01:25.449
  STEP: Deploying the webhook pod @ 12/02/23 13:01:25.46
  STEP: Wait for the deployment to be ready @ 12/02/23 13:01:25.473
  Dec  2 13:01:25.481: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1202 13:01:26.095471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:27.095556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:01:27.493
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:01:27.504
  E1202 13:01:28.096541      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:28.505: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a mutating webhook configuration @ 12/02/23 13:01:28.511
  STEP: Updating a mutating webhook configuration's rules to not include the create operation @ 12/02/23 13:01:28.53
  STEP: Creating a configMap that should not be mutated @ 12/02/23 13:01:28.538
  STEP: Patching a mutating webhook configuration's rules to include the create operation @ 12/02/23 13:01:28.548
  STEP: Creating a configMap that should be mutated @ 12/02/23 13:01:28.556
  Dec  2 13:01:28.581: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3510" for this suite. @ 12/02/23 13:01:28.626
  STEP: Destroying namespace "webhook-markers-6761" for this suite. @ 12/02/23 13:01:28.633
• [3.545 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:486
  STEP: Creating a kubernetes client @ 12/02/23 13:01:28.644
  Dec  2 13:01:28.644: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename security-context-test @ 12/02/23 13:01:28.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:28.66
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:28.664
  E1202 13:01:29.097365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:30.097567      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:31.098298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:32.099297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:32.703: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-9243" for this suite. @ 12/02/23 13:01:32.707
• [4.071 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:74
  STEP: Creating a kubernetes client @ 12/02/23 13:01:32.716
  Dec  2 13:01:32.716: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:01:32.717
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:32.733
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:32.736
  STEP: Creating configMap with name projected-configmap-test-volume-e08f625a-71e1-469d-94d3-5bafe02953af @ 12/02/23 13:01:32.738
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:01:32.742
  E1202 13:01:33.100253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:34.100372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:35.101061      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:36.101141      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:01:36.763
  Dec  2 13:01:36.766: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-configmaps-cb1dcb95-cbce-411a-b2e8-6e39b7579375 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 13:01:36.781
  Dec  2 13:01:36.799: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1635" for this suite. @ 12/02/23 13:01:36.803
• [4.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should serve multiport endpoints from pods  [Conformance]
test/e2e/network/service.go:846
  STEP: Creating a kubernetes client @ 12/02/23 13:01:36.812
  Dec  2 13:01:36.813: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:01:36.813
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:36.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:36.834
  STEP: creating service multi-endpoint-test in namespace services-603 @ 12/02/23 13:01:36.838
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-603 to expose endpoints map[] @ 12/02/23 13:01:36.85
  Dec  2 13:01:36.854: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
  E1202 13:01:37.101831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:37.864: INFO: successfully validated that service multi-endpoint-test in namespace services-603 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-603 @ 12/02/23 13:01:37.864
  E1202 13:01:38.101884      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:39.101957      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-603 to expose endpoints map[pod1:[100]] @ 12/02/23 13:01:39.887
  Dec  2 13:01:39.896: INFO: successfully validated that service multi-endpoint-test in namespace services-603 exposes endpoints map[pod1:[100]]
  STEP: Creating pod pod2 in namespace services-603 @ 12/02/23 13:01:39.896
  E1202 13:01:40.102057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:41.102074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-603 to expose endpoints map[pod1:[100] pod2:[101]] @ 12/02/23 13:01:41.914
  Dec  2 13:01:41.927: INFO: successfully validated that service multi-endpoint-test in namespace services-603 exposes endpoints map[pod1:[100] pod2:[101]]
  STEP: Checking if the Service forwards traffic to pods @ 12/02/23 13:01:41.927
  Dec  2 13:01:41.927: INFO: Creating new exec pod
  E1202 13:01:42.102628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:43.102773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:44.103057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:44.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-603 exec execpodc5gt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
  Dec  2 13:01:45.057: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
  Dec  2 13:01:45.057: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:01:45.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-603 exec execpodc5gt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.130 80'
  E1202 13:01:45.103392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:45.168: INFO: stderr: "+ nc -v -t -w 2 10.152.183.130 80\n+ echo hostName\nConnection to 10.152.183.130 80 port [tcp/http] succeeded!\n"
  Dec  2 13:01:45.168: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:01:45.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-603 exec execpodc5gt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
  Dec  2 13:01:45.286: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
  Dec  2 13:01:45.286: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:01:45.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-603 exec execpodc5gt4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.130 81'
  Dec  2 13:01:45.397: INFO: stderr: "+ nc -v -t -w 2 10.152.183.130 81\n+ echo hostName\nConnection to 10.152.183.130 81 port [tcp/*] succeeded!\n"
  Dec  2 13:01:45.397: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-603 @ 12/02/23 13:01:45.397
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-603 to expose endpoints map[pod2:[101]] @ 12/02/23 13:01:45.417
  Dec  2 13:01:45.426: INFO: successfully validated that service multi-endpoint-test in namespace services-603 exposes endpoints map[pod2:[101]]
  STEP: Deleting pod pod2 in namespace services-603 @ 12/02/23 13:01:45.426
  STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-603 to expose endpoints map[] @ 12/02/23 13:01:45.44
  E1202 13:01:46.103605      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:46.458: INFO: successfully validated that service multi-endpoint-test in namespace services-603 exposes endpoints map[]
  Dec  2 13:01:46.458: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-603" for this suite. @ 12/02/23 13:01:46.477
• [9.673 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]
test/e2e/kubectl/kubectl.go:1707
  STEP: Creating a kubernetes client @ 12/02/23 13:01:46.487
  Dec  2 13:01:46.487: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:01:46.488
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:46.502
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:46.504
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/02/23 13:01:46.507
  Dec  2 13:01:46.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5508 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4'
  Dec  2 13:01:46.561: INFO: stderr: ""
  Dec  2 13:01:46.561: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: verifying the pod e2e-test-httpd-pod was created @ 12/02/23 13:01:46.561
  Dec  2 13:01:46.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-5508 delete pods e2e-test-httpd-pod'
  E1202 13:01:47.103817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:48.104278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:48.478: INFO: stderr: ""
  Dec  2 13:01:48.478: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec  2 13:01:48.478: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-5508" for this suite. @ 12/02/23 13:01:48.482
• [2.001 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]
test/e2e/network/proxy.go:380
  STEP: Creating a kubernetes client @ 12/02/23 13:01:48.49
  Dec  2 13:01:48.490: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename proxy @ 12/02/23 13:01:48.491
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:48.51
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:48.513
  Dec  2 13:01:48.515: INFO: Creating pod...
  E1202 13:01:49.105331      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:50.105410      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:50.532: INFO: Creating service...
  Dec  2 13:01:50.543: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/pods/agnhost/proxy?method=DELETE
  Dec  2 13:01:50.555: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  2 13:01:50.555: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/pods/agnhost/proxy?method=OPTIONS
  Dec  2 13:01:50.563: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  2 13:01:50.563: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/pods/agnhost/proxy?method=PATCH
  Dec  2 13:01:50.567: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  2 13:01:50.567: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/pods/agnhost/proxy?method=POST
  Dec  2 13:01:50.574: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  2 13:01:50.574: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/pods/agnhost/proxy?method=PUT
  Dec  2 13:01:50.591: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  2 13:01:50.591: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/services/e2e-proxy-test-service/proxy?method=DELETE
  Dec  2 13:01:50.601: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  2 13:01:50.601: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/services/e2e-proxy-test-service/proxy?method=OPTIONS
  Dec  2 13:01:50.608: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  2 13:01:50.608: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/services/e2e-proxy-test-service/proxy?method=PATCH
  Dec  2 13:01:50.623: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  2 13:01:50.623: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/services/e2e-proxy-test-service/proxy?method=POST
  Dec  2 13:01:50.630: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  2 13:01:50.630: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/services/e2e-proxy-test-service/proxy?method=PUT
  Dec  2 13:01:50.640: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  2 13:01:50.640: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/pods/agnhost/proxy?method=GET
  Dec  2 13:01:50.646: INFO: http.Client request:GET StatusCode:301
  Dec  2 13:01:50.646: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/services/e2e-proxy-test-service/proxy?method=GET
  Dec  2 13:01:50.651: INFO: http.Client request:GET StatusCode:301
  Dec  2 13:01:50.651: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/pods/agnhost/proxy?method=HEAD
  Dec  2 13:01:50.655: INFO: http.Client request:HEAD StatusCode:301
  Dec  2 13:01:50.655: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4447/services/e2e-proxy-test-service/proxy?method=HEAD
  Dec  2 13:01:50.662: INFO: http.Client request:HEAD StatusCode:301
  Dec  2 13:01:50.662: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-4447" for this suite. @ 12/02/23 13:01:50.666
• [2.182 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
test/e2e/common/node/expansion.go:189
  STEP: Creating a kubernetes client @ 12/02/23 13:01:50.674
  Dec  2 13:01:50.674: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 13:01:50.675
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:50.692
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:50.697
  E1202 13:01:51.105585      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:52.105817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:01:52.716: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:01:52.720: INFO: Deleting pod "var-expansion-2ffba2f7-4658-4b77-95ea-7f4c1421a39d" in namespace "var-expansion-6641"
  Dec  2 13:01:52.728: INFO: Wait up to 5m0s for pod "var-expansion-2ffba2f7-4658-4b77-95ea-7f4c1421a39d" to be fully deleted
  E1202 13:01:53.106002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:54.106232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-6641" for this suite. @ 12/02/23 13:01:54.736
• [4.068 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2165
  STEP: Creating a kubernetes client @ 12/02/23 13:01:54.743
  Dec  2 13:01:54.743: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:01:54.743
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:01:54.759
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:01:54.761
  STEP: creating service in namespace services-580 @ 12/02/23 13:01:54.764
  STEP: creating service affinity-clusterip in namespace services-580 @ 12/02/23 13:01:54.764
  STEP: creating replication controller affinity-clusterip in namespace services-580 @ 12/02/23 13:01:54.775
  I1202 13:01:54.783194      18 runners.go:197] Created replication controller with name: affinity-clusterip, namespace: services-580, replica count: 3
  E1202 13:01:55.107220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:56.108287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:57.108372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:01:57.834290      18 runners.go:197] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 13:01:57.840: INFO: Creating new exec pod
  E1202 13:01:58.108924      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:01:59.109531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:00.110213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:02:00.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-580 exec execpod-affinitybdwnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
  Dec  2 13:02:00.986: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip 80\n+ echo hostName\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
  Dec  2 13:02:00.986: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:02:00.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-580 exec execpod-affinitybdwnn -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.241 80'
  Dec  2 13:02:01.093: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.241 80\nConnection to 10.152.183.241 80 port [tcp/http] succeeded!\n"
  Dec  2 13:02:01.093: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:02:01.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-580 exec execpod-affinitybdwnn -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.241:80/ ; done'
  E1202 13:02:01.111129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:02:01.265: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.241:80/\n"
  Dec  2 13:02:01.265: INFO: stdout: "\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms\naffinity-clusterip-m7cms"
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Received response from host: affinity-clusterip-m7cms
  Dec  2 13:02:01.265: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:02:01.269: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip in namespace services-580, will wait for the garbage collector to delete the pods @ 12/02/23 13:02:01.287
  Dec  2 13:02:01.347: INFO: Deleting ReplicationController affinity-clusterip took: 6.694183ms
  Dec  2 13:02:01.448: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.371308ms
  E1202 13:02:02.111630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:03.112656      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:04.112764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-580" for this suite. @ 12/02/23 13:02:04.568
• [9.833 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:69
  STEP: Creating a kubernetes client @ 12/02/23 13:02:04.576
  Dec  2 13:02:04.576: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:02:04.577
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:04.593
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:04.595
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:02:04.597
  E1202 13:02:05.112868      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:06.113100      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:07.113227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:08.114059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:02:08.617
  Dec  2 13:02:08.620: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-0378c369-03d1-4a2c-9a28-57b10df4df54 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:02:08.627
  Dec  2 13:02:08.646: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-8715" for this suite. @ 12/02/23 13:02:08.65
• [4.079 seconds]
------------------------------
SS
------------------------------
[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:46
  STEP: Creating a kubernetes client @ 12/02/23 13:02:08.655
  Dec  2 13:02:08.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:02:08.656
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:08.674
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:08.676
  STEP: Creating secret with name secret-test-9b4f779b-ff04-4080-a60f-6d9235c7e4b9 @ 12/02/23 13:02:08.678
  STEP: Creating a pod to test consume secrets @ 12/02/23 13:02:08.688
  E1202 13:02:09.114150      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:10.114245      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:02:10.704
  Dec  2 13:02:10.707: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-secrets-1ef7ab8c-7408-4375-9d09-aefaa77e7da9 container secret-env-test: <nil>
  STEP: delete the pod @ 12/02/23 13:02:10.713
  Dec  2 13:02:10.728: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-7568" for this suite. @ 12/02/23 13:02:10.733
• [2.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
test/e2e/node/security_context.go:129
  STEP: Creating a kubernetes client @ 12/02/23 13:02:10.744
  Dec  2 13:02:10.744: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename security-context @ 12/02/23 13:02:10.744
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:10.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:10.766
  STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser @ 12/02/23 13:02:10.768
  E1202 13:02:11.114522      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:12.114579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:02:12.791
  Dec  2 13:02:12.794: INFO: Trying to get logs from node ip-172-31-1-50 pod security-context-214e6897-d433-4593-840c-5f2b5d1428bc container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:02:12.799
  Dec  2 13:02:12.819: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-9757" for this suite. @ 12/02/23 13:02:12.823
• [2.084 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:194
  STEP: Creating a kubernetes client @ 12/02/23 13:02:12.828
  Dec  2 13:02:12.828: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:02:12.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:12.845
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:12.847
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:02:12.85
  E1202 13:02:13.114652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:14.114752      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:15.115291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:16.115379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:02:16.871
  Dec  2 13:02:16.874: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-71872814-683f-4544-bb43-66445b25cf5a container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:02:16.882
  Dec  2 13:02:16.902: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1403" for this suite. @ 12/02/23 13:02:16.905
• [4.083 seconds]
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:131
  STEP: Creating a kubernetes client @ 12/02/23 13:02:16.911
  Dec  2 13:02:16.911: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:02:16.912
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:16.928
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:16.93
  STEP: Creating the pod @ 12/02/23 13:02:16.933
  E1202 13:02:17.115466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:18.115546      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:19.116235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:02:19.474: INFO: Successfully updated pod "labelsupdate9659fd3a-949a-4295-b02f-7eed41fa9004"
  E1202 13:02:20.116930      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:21.117166      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:02:21.489: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2259" for this suite. @ 12/02/23 13:02:21.493
• [4.593 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:252
  STEP: Creating a kubernetes client @ 12/02/23 13:02:21.505
  Dec  2 13:02:21.505: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename namespaces @ 12/02/23 13:02:21.505
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:21.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:21.527
  STEP: Creating a test namespace @ 12/02/23 13:02:21.53
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:21.548
  STEP: Creating a service in the namespace @ 12/02/23 13:02:21.55
  STEP: Deleting the namespace @ 12/02/23 13:02:21.56
  STEP: Waiting for the namespace to be removed. @ 12/02/23 13:02:21.568
  E1202 13:02:22.118036      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:23.119125      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:24.120011      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:25.120106      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:26.121186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:27.121809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 12/02/23 13:02:27.573
  STEP: Verifying there is no service in the namespace @ 12/02/23 13:02:27.589
  Dec  2 13:02:27.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-9879" for this suite. @ 12/02/23 13:02:27.596
  STEP: Destroying namespace "nsdeletetest-3136" for this suite. @ 12/02/23 13:02:27.602
  Dec  2 13:02:27.605: INFO: Namespace nsdeletetest-3136 was already deleted
  STEP: Destroying namespace "nsdeletetest-7623" for this suite. @ 12/02/23 13:02:27.605
• [6.105 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates should delete a collection of pod templates [Conformance]
test/e2e/common/node/podtemplates.go:122
  STEP: Creating a kubernetes client @ 12/02/23 13:02:27.611
  Dec  2 13:02:27.611: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename podtemplate @ 12/02/23 13:02:27.611
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:27.626
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:27.628
  STEP: Create set of pod templates @ 12/02/23 13:02:27.63
  Dec  2 13:02:27.639: INFO: created test-podtemplate-1
  Dec  2 13:02:27.644: INFO: created test-podtemplate-2
  Dec  2 13:02:27.650: INFO: created test-podtemplate-3
  STEP: get a list of pod templates with a label in the current namespace @ 12/02/23 13:02:27.65
  STEP: delete collection of pod templates @ 12/02/23 13:02:27.653
  Dec  2 13:02:27.653: INFO: requesting DeleteCollection of pod templates
  STEP: check that the list of pod templates matches the requested quantity @ 12/02/23 13:02:27.669
  Dec  2 13:02:27.669: INFO: requesting list of pod templates to confirm quantity
  Dec  2 13:02:27.672: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-8526" for this suite. @ 12/02/23 13:02:27.675
• [0.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]
test/e2e/apimachinery/watch.go:142
  STEP: Creating a kubernetes client @ 12/02/23 13:02:27.683
  Dec  2 13:02:27.683: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename watch @ 12/02/23 13:02:27.684
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:27.699
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:27.704
  STEP: creating a new configmap @ 12/02/23 13:02:27.707
  STEP: modifying the configmap once @ 12/02/23 13:02:27.711
  STEP: modifying the configmap a second time @ 12/02/23 13:02:27.719
  STEP: deleting the configmap @ 12/02/23 13:02:27.728
  STEP: creating a watch on configmaps from the resource version returned by the first update @ 12/02/23 13:02:27.733
  STEP: Expecting to observe notifications for all changes to the configmap after the first update @ 12/02/23 13:02:27.734
  Dec  2 13:02:27.734: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8524  e61964d9-9181-43ea-93a5-2491c099ef5e 22976 0 2023-12-02 13:02:27 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-02 13:02:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:02:27.734: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8524  e61964d9-9181-43ea-93a5-2491c099ef5e 22977 0 2023-12-02 13:02:27 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2023-12-02 13:02:27 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:02:27.734: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-8524" for this suite. @ 12/02/23 13:02:27.738
• [0.061 seconds]
------------------------------
SS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:52
  STEP: Creating a kubernetes client @ 12/02/23 13:02:27.744
  Dec  2 13:02:27.744: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubelet-test @ 12/02/23 13:02:27.745
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:27.762
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:27.764
  E1202 13:02:28.121899      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:29.122057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:02:29.796: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-5083" for this suite. @ 12/02/23 13:02:29.799
• [2.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:217
  STEP: Creating a kubernetes client @ 12/02/23 13:02:29.807
  Dec  2 13:02:29.807: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:02:29.808
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:29.823
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:29.825
  STEP: Creating a pod to test emptydir 0777 on node default medium @ 12/02/23 13:02:29.828
  E1202 13:02:30.122189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:31.122263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:32.122651      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:33.123287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:02:33.85
  Dec  2 13:02:33.853: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-52232aa3-a312-4b3f-88e7-073c0f93ac3d container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:02:33.861
  Dec  2 13:02:33.877: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4012" for this suite. @ 12/02/23 13:02:33.881
• [4.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
test/e2e/scheduling/predicates.go:705
  STEP: Creating a kubernetes client @ 12/02/23 13:02:33.887
  Dec  2 13:02:33.887: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-pred @ 12/02/23 13:02:33.888
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:02:33.904
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:02:33.907
  Dec  2 13:02:33.909: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  2 13:02:33.916: INFO: Waiting for terminating namespaces to be deleted...
  Dec  2 13:02:33.919: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-1-50 before test
  Dec  2 13:02:33.925: INFO: nginx-ingress-controller-kubernetes-worker-bl8w7 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:04:04 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.925: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:02:33.925: INFO: calico-node-lzsm2 from kube-system started at 2023-12-02 12:03:38 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.925: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:02:33.925: INFO: busybox-scheduling-d3b895cb-30a3-4da7-985a-869ef8441911 from kubelet-test-5083 started at 2023-12-02 13:02:27 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.925: INFO: 	Container busybox-scheduling-d3b895cb-30a3-4da7-985a-869ef8441911 ready: true, restart count 0
  Dec  2 13:02:33.925: INFO: sonobuoy from sonobuoy started at 2023-12-02 12:07:42 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.925: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  2 13:02:33.925: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-28gq4 from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:02:33.925: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:02:33.925: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 13:02:33.925: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-74-39 before test
  Dec  2 13:02:33.930: INFO: nginx-ingress-controller-kubernetes-worker-p5kqq from ingress-nginx-kubernetes-worker started at 2023-12-02 12:05:07 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.930: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:02:33.930: INFO: calico-node-jvhbz from kube-system started at 2023-12-02 12:04:51 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.930: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:02:33.930: INFO: sonobuoy-e2e-job-e9309236a19947ce from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:02:33.931: INFO: 	Container e2e ready: true, restart count 0
  Dec  2 13:02:33.931: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:02:33.931: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-fz89t from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:02:33.931: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:02:33.931: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 13:02:33.931: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-89-192 before test
  Dec  2 13:02:33.936: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-5sm95 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.936: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  2 13:02:33.936: INFO: nginx-ingress-controller-kubernetes-worker-g5cfp from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.936: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:02:33.936: INFO: calico-node-ql9q7 from kube-system started at 2023-12-02 12:01:42 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.936: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: coredns-59cfb5bf46-4zw4x from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.937: INFO: 	Container coredns ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: kube-state-metrics-78c475f58b-9brf7 from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.937: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: metrics-server-v0.6.3-69d7fbfdf8-q6h8s from kube-system started at 2023-12-02 12:02:20 +0000 UTC (2 container statuses recorded)
  Dec  2 13:02:33.937: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: dashboard-metrics-scraper-5dd7cb5fc-srsz2 from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.937: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: kubernetes-dashboard-7b899cb9d9-vfzmg from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:02:33.937: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-ldh7p from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:02:33.937: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:02:33.937: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/02/23 13:02:33.937
  E1202 13:02:34.123373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:35.123630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/02/23 13:02:35.956
  STEP: Trying to apply a random label on the found node. @ 12/02/23 13:02:35.973
  STEP: verifying the node has the label kubernetes.io/e2e-6deb68e2-3f1d-4480-9d90-86baacfcb39a 95 @ 12/02/23 13:02:35.982
  STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled @ 12/02/23 13:02:35.987
  E1202 13:02:36.124501      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:37.124766      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.74.39 on the node which pod4 resides and expect not scheduled @ 12/02/23 13:02:38
  E1202 13:02:38.125259      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:39.125293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:40.125678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:41.125788      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:42.126124      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:43.126240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:44.127013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:45.127105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:46.128101      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:47.128292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:48.128369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:49.128473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:50.128848      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:51.128928      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:52.129348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:53.129412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:54.130464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:55.130571      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:56.131397      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:57.131477      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:58.131944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:02:59.132924      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:00.133544      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:01.134467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:02.135190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:03.135361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:04.135578      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:05.135753      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:06.135933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:07.136927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:08.137389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:09.138076      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:10.139072      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:11.139747      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:12.140151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:13.140251      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:14.140542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:15.140639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:16.141659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:17.141749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:18.142614      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:19.142699      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:20.143336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:21.143387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:22.143686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:23.143744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:24.144115      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:25.144279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:26.144772      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:27.145493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:28.146299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:29.147290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:30.147816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:31.147923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:32.148289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:33.148405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:34.148837      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:35.149129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:36.149302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:37.149558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:38.149593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:39.149702      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:40.150303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:41.151290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:42.151964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:43.152109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:44.153527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:45.153602      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:46.154479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:47.155289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:48.155478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:49.155601      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:50.156330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:51.156770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:52.156927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:53.157707      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:54.157880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:55.158779      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:56.159163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:57.159280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:58.159475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:03:59.159572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:00.159718      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:01.160043      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:02.160231      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:03.161229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:04.161413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:05.162241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:06.163300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:07.163391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:08.163478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:09.163674      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:10.163709      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:11.164208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:12.164287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:13.164615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:14.164796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:15.164885      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:16.165502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:17.166238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:18.166363      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:19.166396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:20.167285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:21.168057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:22.168144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:23.168689      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:24.168792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:25.169223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:26.169593      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:27.170256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:28.170347      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:29.171268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:30.171439      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:31.172447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:32.172536      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:33.172642      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:34.173206      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:35.173308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:36.173374      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:37.173655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:38.173748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:39.174268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:40.174350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:41.174827      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:42.175299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:43.175386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:44.175469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:45.175572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:46.175650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:47.175750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:48.175852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:49.175932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:50.176066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:51.176852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:52.176965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:53.177199      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:54.177276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:55.177377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:56.177764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:57.178238      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:58.178363      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:04:59.178470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:00.178550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:01.179493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:02.179581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:03.180591      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:04.180770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:05.180858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:06.180931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:07.181939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:08.182135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:09.182809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:10.182903      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:11.183305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:12.183388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:13.184412      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:14.184477      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:15.184562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:16.184610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:17.184787      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:18.185853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:19.186690      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:20.187025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:21.187119      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:22.187194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:23.187243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:24.187332      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:25.187422      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:26.187594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:27.187648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:28.187835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:29.187949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:30.188019      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:31.188502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:32.188603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:33.188697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:34.188935      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:35.189417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:36.189522      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:37.190452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:38.190519      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:39.190710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:40.190789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:41.190881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:42.191395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:43.191506      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:44.191720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:45.192591      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:46.192912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:47.193416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:48.193508      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:49.193578      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:50.193804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:51.194214      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:52.194256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:53.194380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:54.194545      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:55.195092      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:56.195181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:57.195927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:58.196015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:05:59.196303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:00.196452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:01.197390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:02.197540      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:03.198345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:04.199279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:05.199388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:06.199464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:07.199798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:08.199879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:09.199970      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:10.200105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:11.200203      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:12.200292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:13.203552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:14.204366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:15.205229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:16.205322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:17.206208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:18.207287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:19.207730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:20.207891      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:21.208450      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:22.209387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:23.211380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:24.211464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:25.212379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:26.212465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:27.213276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:28.213368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:29.213638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:30.213798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:31.214211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:32.215278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:33.215895      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:34.215953      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:35.216619      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:36.216710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:37.217227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:38.217403      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:39.217490      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:40.217660      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:41.218225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:42.219280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:43.219312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:44.220003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:45.220073      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:46.220173      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:47.220249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:48.220398      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:49.221005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:50.221211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:51.221883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:52.222077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:53.222300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:54.222392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:55.223275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:56.224251      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:57.225147      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:58.225413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:06:59.225999      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:00.226191      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:01.226221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:02.227278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:03.227374      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:04.227539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:05.227654      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:06.228379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:07.229053      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:08.229514      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:09.230482      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:10.231292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:11.231327      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:12.231405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:13.231931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:14.232109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:15.232322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:16.232417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:17.232511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:18.232597      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:19.233193      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:20.233348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:21.233719      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:22.234364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:23.234575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:24.235305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:25.235582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:26.236236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:27.236322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:28.237418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:29.237823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:30.238620      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:31.239278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:32.240101      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:33.240876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:34.240980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:35.241480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:36.241960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:37.242220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-6deb68e2-3f1d-4480-9d90-86baacfcb39a off the node ip-172-31-74-39 @ 12/02/23 13:07:38.008
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-6deb68e2-3f1d-4480-9d90-86baacfcb39a @ 12/02/23 13:07:38.019
  Dec  2 13:07:38.024: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-8256" for this suite. @ 12/02/23 13:07:38.028
• [304.150 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:69
  STEP: Creating a kubernetes client @ 12/02/23 13:07:38.038
  Dec  2 13:07:38.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 13:07:38.039
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:07:38.058
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:07:38.06
  Dec  2 13:07:38.064: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:07:38.242321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:39.243317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with known and required properties @ 12/02/23 13:07:39.293
  Dec  2 13:07:39.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 create -f -'
  E1202 13:07:40.243562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:41.243660      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:07:41.654: INFO: stderr: ""
  Dec  2 13:07:41.654: INFO: stdout: "e2e-test-crd-publish-openapi-2657-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec  2 13:07:41.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 delete e2e-test-crd-publish-openapi-2657-crds test-foo'
  Dec  2 13:07:41.723: INFO: stderr: ""
  Dec  2 13:07:41.723: INFO: stdout: "e2e-test-crd-publish-openapi-2657-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  Dec  2 13:07:41.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 apply -f -'
  Dec  2 13:07:42.049: INFO: stderr: ""
  Dec  2 13:07:42.049: INFO: stdout: "e2e-test-crd-publish-openapi-2657-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
  Dec  2 13:07:42.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 delete e2e-test-crd-publish-openapi-2657-crds test-foo'
  Dec  2 13:07:42.105: INFO: stderr: ""
  Dec  2 13:07:42.105: INFO: stdout: "e2e-test-crd-publish-openapi-2657-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
  STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values @ 12/02/23 13:07:42.105
  Dec  2 13:07:42.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 create -f -'
  Dec  2 13:07:42.207: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema @ 12/02/23 13:07:42.207
  Dec  2 13:07:42.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 create -f -'
  E1202 13:07:42.244512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:07:42.310: INFO: rc: 1
  Dec  2 13:07:42.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 apply -f -'
  Dec  2 13:07:42.424: INFO: rc: 1
  STEP: kubectl validation (kubectl create and apply) rejects request without required properties @ 12/02/23 13:07:42.424
  Dec  2 13:07:42.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 create -f -'
  Dec  2 13:07:42.537: INFO: rc: 1
  Dec  2 13:07:42.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 --namespace=crd-publish-openapi-5659 apply -f -'
  Dec  2 13:07:42.649: INFO: rc: 1
  STEP: kubectl explain works to explain CR properties @ 12/02/23 13:07:42.649
  Dec  2 13:07:42.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 explain e2e-test-crd-publish-openapi-2657-crds'
  Dec  2 13:07:42.753: INFO: stderr: ""
  Dec  2 13:07:42.753: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2657-crd\nVERSION:    v1\n\nDESCRIPTION:\n    Foo CRD for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Foo\n\n  status\t<Object>\n    Status of Foo\n\n\n"
  STEP: kubectl explain works to explain CR properties recursively @ 12/02/23 13:07:42.753
  Dec  2 13:07:42.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 explain e2e-test-crd-publish-openapi-2657-crds.metadata'
  Dec  2 13:07:42.859: INFO: stderr: ""
  Dec  2 13:07:42.859: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2657-crd\nVERSION:    v1\n\nFIELD: metadata <ObjectMeta>\n\nDESCRIPTION:\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n    ObjectMeta is metadata that all persisted resources must have, which\n    includes all objects users must create.\n    \nFIELDS:\n  annotations\t<map[string]string>\n    Annotations is an unstructured key value map stored with a resource that may\n    be set by external tools to store and retrieve arbitrary metadata. They are\n    not queryable and should be preserved when modifying objects. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations\n\n  creationTimestamp\t<string>\n    CreationTimestamp is a timestamp representing the server time when this\n    object was created. It is not guaranteed to be set in happens-before order\n    across separate operations. Clients may not set this value. It is\n    represented in RFC3339 form and is in UTC.\n    \n    Populated by the system. Read-only. Null for lists. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  deletionGracePeriodSeconds\t<integer>\n    Number of seconds allowed for this object to gracefully terminate before it\n    will be removed from the system. Only set when deletionTimestamp is also\n    set. May only be shortened. Read-only.\n\n  deletionTimestamp\t<string>\n    DeletionTimestamp is RFC 3339 date and time at which this resource will be\n    deleted. This field is set by the server when a graceful deletion is\n    requested by the user, and is not directly settable by a client. The\n    resource is expected to be deleted (no longer visible from resource lists,\n    and not reachable by name) after the time in this field, once the finalizers\n    list is empty. As long as the finalizers list contains items, deletion is\n    blocked. Once the deletionTimestamp is set, this value may not be unset or\n    be set further into the future, although it may be shortened or the resource\n    may be deleted prior to this time. For example, a user may request that a\n    pod is deleted in 30 seconds. The Kubelet will react by sending a graceful\n    termination signal to the containers in the pod. After that 30 seconds, the\n    Kubelet will send a hard termination signal (SIGKILL) to the container and\n    after cleanup, remove the pod from the API. In the presence of network\n    partitions, this object may still exist after this timestamp, until an\n    administrator or automated process can determine the resource is fully\n    terminated. If not set, graceful deletion of the object has not been\n    requested.\n    \n    Populated by the system when a graceful deletion is requested. Read-only.\n    More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  finalizers\t<[]string>\n    Must be empty before the object is deleted from the registry. Each entry is\n    an identifier for the responsible component that will remove the entry from\n    the list. If the deletionTimestamp of the object is non-nil, entries in this\n    list can only be removed. Finalizers may be processed and removed in any\n    order.  Order is NOT enforced because it introduces significant risk of\n    stuck finalizers. finalizers is a shared field, any actor with permission\n    can reorder it. If the finalizer list is processed in order, then this can\n    lead to a situation in which the component responsible for the first\n    finalizer in the list is waiting for a signal (field value, external system,\n    or other) produced by a component responsible for a finalizer later in the\n    list, resulting in a deadlock. Without enforced ordering finalizers are free\n    to order amongst themselves and are not vulnerable to ordering changes in\n    the list.\n\n  generateName\t<string>\n    GenerateName is an optional prefix, used by the server, to generate a unique\n    name ONLY IF the Name field has not been provided. If this field is used,\n    the name returned to the client will be different than the name passed. This\n    value will also be combined with a unique suffix. The provided value has the\n    same validation rules as the Name field, and may be truncated by the length\n    of the suffix required to make the value unique on the server.\n    \n    If this field is specified and the generated name exists, the server will\n    return a 409.\n    \n    Applied only if Name is not specified. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n  generation\t<integer>\n    A sequence number representing a specific generation of the desired state.\n    Populated by the system. Read-only.\n\n  labels\t<map[string]string>\n    Map of string keys and values that can be used to organize and categorize\n    (scope and select) objects. May match selectors of replication controllers\n    and services. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/labels\n\n  managedFields\t<[]ManagedFieldsEntry>\n    ManagedFields maps workflow-id and version to the set of fields that are\n    managed by that workflow. This is mostly for internal housekeeping, and\n    users typically shouldn't need to set or understand this field. A workflow\n    can be the user's name, a controller's name, or the name of a specific apply\n    path like \"ci-cd\". The set of fields is always in the version that the\n    workflow used when modifying the object.\n\n  name\t<string>\n    Name must be unique within a namespace. Is required when creating resources,\n    although some resources may allow a client to request the generation of an\n    appropriate name automatically. Name is primarily intended for creation\n    idempotence and configuration definition. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names\n\n  namespace\t<string>\n    Namespace defines the space within which each name must be unique. An empty\n    namespace is equivalent to the \"default\" namespace, but \"default\" is the\n    canonical representation. Not all objects are required to be scoped to a\n    namespace - the value of this field for those objects will be empty.\n    \n    Must be a DNS_LABEL. Cannot be updated. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces\n\n  ownerReferences\t<[]OwnerReference>\n    List of objects depended by this object. If ALL objects in the list have\n    been deleted, this object will be garbage collected. If this object is\n    managed by a controller, then an entry in this list will point to this\n    controller, with the controller field set to true. There cannot be more than\n    one managing controller.\n\n  resourceVersion\t<string>\n    An opaque value that represents the internal version of this object that can\n    be used by clients to determine when objects have changed. May be used for\n    optimistic concurrency, change detection, and the watch operation on a\n    resource or set of resources. Clients must treat these values as opaque and\n    passed unmodified back to the server. They may only be valid for a\n    particular resource or set of resources.\n    \n    Populated by the system. Read-only. Value must be treated as opaque by\n    clients and . More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n  selfLink\t<string>\n    Deprecated: selfLink is a legacy read-only field that is no longer populated\n    by the system.\n\n  uid\t<string>\n    UID is the unique in time and space value for this object. It is typically\n    generated by the server on successful creation of a resource and is not\n    allowed to change on PUT operations.\n    \n    Populated by the system. Read-only. More info:\n    https://kubernetes.io/docs/concepts/overview/working-with-objects/names#uids\n\n\n"
  Dec  2 13:07:42.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 explain e2e-test-crd-publish-openapi-2657-crds.spec'
  Dec  2 13:07:42.965: INFO: stderr: ""
  Dec  2 13:07:42.965: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2657-crd\nVERSION:    v1\n\nFIELD: spec <Object>\n\nDESCRIPTION:\n    Specification of Foo\n    \nFIELDS:\n  bars\t<[]Object>\n    List of Bars and their specs.\n\n\n"
  Dec  2 13:07:42.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 explain e2e-test-crd-publish-openapi-2657-crds.spec.bars'
  Dec  2 13:07:43.067: INFO: stderr: ""
  Dec  2 13:07:43.067: INFO: stdout: "GROUP:      crd-publish-openapi-test-foo.example.com\nKIND:       e2e-test-crd-publish-openapi-2657-crd\nVERSION:    v1\n\nFIELD: bars <[]Object>\n\nDESCRIPTION:\n    List of Bars and their specs.\n    \nFIELDS:\n  age\t<string>\n    Age of Bar.\n\n  bazs\t<[]string>\n    List of Bazs.\n\n  feeling\t<string>\n    Whether Bar is feeling great.\n\n  name\t<string> -required-\n    Name of Bar.\n\n\n"
  STEP: kubectl explain works to return error when explain is called on property that doesn't exist @ 12/02/23 13:07:43.067
  Dec  2 13:07:43.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-5659 explain e2e-test-crd-publish-openapi-2657-crds.spec.bars2'
  Dec  2 13:07:43.227: INFO: rc: 1
  E1202 13:07:43.244557      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:44.244760      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:07:44.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-5659" for this suite. @ 12/02/23 13:07:44.494
• [6.467 seconds]
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
test/e2e/network/proxy.go:286
  STEP: Creating a kubernetes client @ 12/02/23 13:07:44.505
  Dec  2 13:07:44.505: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename proxy @ 12/02/23 13:07:44.506
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:07:44.524
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:07:44.528
  Dec  2 13:07:44.532: INFO: Creating pod...
  E1202 13:07:45.245373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:46.246136      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:07:46.550: INFO: Creating service...
  Dec  2 13:07:46.560: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/pods/agnhost/proxy/some/path/with/DELETE
  Dec  2 13:07:46.566: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  2 13:07:46.566: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/pods/agnhost/proxy/some/path/with/GET
  Dec  2 13:07:46.570: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec  2 13:07:46.570: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/pods/agnhost/proxy/some/path/with/HEAD
  Dec  2 13:07:46.573: INFO: http.Client request:HEAD | StatusCode:200
  Dec  2 13:07:46.573: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/pods/agnhost/proxy/some/path/with/OPTIONS
  Dec  2 13:07:46.576: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  2 13:07:46.576: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/pods/agnhost/proxy/some/path/with/PATCH
  Dec  2 13:07:46.579: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  2 13:07:46.579: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/pods/agnhost/proxy/some/path/with/POST
  Dec  2 13:07:46.582: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  2 13:07:46.582: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/pods/agnhost/proxy/some/path/with/PUT
  Dec  2 13:07:46.586: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  2 13:07:46.586: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/services/test-service/proxy/some/path/with/DELETE
  Dec  2 13:07:46.591: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
  Dec  2 13:07:46.591: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/services/test-service/proxy/some/path/with/GET
  Dec  2 13:07:46.594: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
  Dec  2 13:07:46.594: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/services/test-service/proxy/some/path/with/HEAD
  Dec  2 13:07:46.600: INFO: http.Client request:HEAD | StatusCode:200
  Dec  2 13:07:46.600: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/services/test-service/proxy/some/path/with/OPTIONS
  Dec  2 13:07:46.604: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
  Dec  2 13:07:46.605: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/services/test-service/proxy/some/path/with/PATCH
  Dec  2 13:07:46.609: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
  Dec  2 13:07:46.609: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/services/test-service/proxy/some/path/with/POST
  Dec  2 13:07:46.615: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
  Dec  2 13:07:46.615: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-5268/services/test-service/proxy/some/path/with/PUT
  Dec  2 13:07:46.619: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
  Dec  2 13:07:46.619: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "proxy-5268" for this suite. @ 12/02/23 13:07:46.623
• [2.125 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-network] Services should complete a service status lifecycle [Conformance]
test/e2e/network/service.go:3326
  STEP: Creating a kubernetes client @ 12/02/23 13:07:46.63
  Dec  2 13:07:46.630: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:07:46.631
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:07:46.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:07:46.65
  STEP: creating a Service @ 12/02/23 13:07:46.66
  STEP: watching for the Service to be added @ 12/02/23 13:07:46.668
  Dec  2 13:07:46.670: INFO: Found Service test-service-4b8b6 in namespace services-3 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
  Dec  2 13:07:46.670: INFO: Service test-service-4b8b6 created
  STEP: Getting /status @ 12/02/23 13:07:46.67
  Dec  2 13:07:46.673: INFO: Service test-service-4b8b6 has LoadBalancer: {[]}
  STEP: patching the ServiceStatus @ 12/02/23 13:07:46.673
  STEP: watching for the Service to be patched @ 12/02/23 13:07:46.679
  Dec  2 13:07:46.680: INFO: observed Service test-service-4b8b6 in namespace services-3 with annotations: map[] & LoadBalancer: {[]}
  Dec  2 13:07:46.680: INFO: Found Service test-service-4b8b6 in namespace services-3 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
  Dec  2 13:07:46.680: INFO: Service test-service-4b8b6 has service status patched
  STEP: updating the ServiceStatus @ 12/02/23 13:07:46.68
  Dec  2 13:07:46.688: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Service to be updated @ 12/02/23 13:07:46.688
  Dec  2 13:07:46.689: INFO: Observed Service test-service-4b8b6 in namespace services-3 with annotations: map[] & Conditions: {[]}
  Dec  2 13:07:46.689: INFO: Observed event: &Service{ObjectMeta:{test-service-4b8b6  services-3  3b71401f-b4d7-4689-82ac-f09695b4fa7a 23810 0 2023-12-02 13:07:46 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2023-12-02 13:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2023-12-02 13:07:46 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.87,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.87],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
  Dec  2 13:07:46.689: INFO: Found Service test-service-4b8b6 in namespace services-3 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  2 13:07:46.689: INFO: Service test-service-4b8b6 has service status updated
  STEP: patching the service @ 12/02/23 13:07:46.689
  STEP: watching for the Service to be patched @ 12/02/23 13:07:46.699
  Dec  2 13:07:46.701: INFO: observed Service test-service-4b8b6 in namespace services-3 with labels: map[test-service-static:true]
  Dec  2 13:07:46.701: INFO: observed Service test-service-4b8b6 in namespace services-3 with labels: map[test-service-static:true]
  Dec  2 13:07:46.701: INFO: observed Service test-service-4b8b6 in namespace services-3 with labels: map[test-service-static:true]
  Dec  2 13:07:46.701: INFO: Found Service test-service-4b8b6 in namespace services-3 with labels: map[test-service:patched test-service-static:true]
  Dec  2 13:07:46.701: INFO: Service test-service-4b8b6 patched
  STEP: deleting the service @ 12/02/23 13:07:46.701
  STEP: watching for the Service to be deleted @ 12/02/23 13:07:46.711
  Dec  2 13:07:46.712: INFO: Observed event: ADDED
  Dec  2 13:07:46.712: INFO: Observed event: MODIFIED
  Dec  2 13:07:46.712: INFO: Observed event: MODIFIED
  Dec  2 13:07:46.712: INFO: Observed event: MODIFIED
  Dec  2 13:07:46.712: INFO: Found Service test-service-4b8b6 in namespace services-3 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
  Dec  2 13:07:46.712: INFO: Service test-service-4b8b6 deleted
  Dec  2 13:07:46.712: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-3" for this suite. @ 12/02/23 13:07:46.716
• [0.092 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:89
  STEP: Creating a kubernetes client @ 12/02/23 13:07:46.723
  Dec  2 13:07:46.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 13:07:46.724
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:07:46.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:07:46.74
  STEP: Creating configMap with name configmap-test-volume-map-b4a0795a-1984-4024-b638-ff258078249f @ 12/02/23 13:07:46.742
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:07:46.749
  E1202 13:07:47.246184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:48.246249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:49.246534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:50.247415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:07:50.771
  Dec  2 13:07:50.774: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-0d6015f8-57cd-4a38-bfa7-a720316e03a4 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 13:07:50.791
  Dec  2 13:07:50.808: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8927" for this suite. @ 12/02/23 13:07:50.811
• [4.094 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]
test/e2e/storage/subpath.go:105
  STEP: Creating a kubernetes client @ 12/02/23 13:07:50.817
  Dec  2 13:07:50.817: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename subpath @ 12/02/23 13:07:50.818
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:07:50.831
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:07:50.834
  STEP: Setting up data @ 12/02/23 13:07:50.836
  STEP: Creating pod pod-subpath-test-projected-pfxz @ 12/02/23 13:07:50.844
  STEP: Creating a pod to test atomic-volume-subpath @ 12/02/23 13:07:50.844
  E1202 13:07:51.248442      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:52.248621      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:53.248747      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:54.248819      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:55.249341      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:56.249435      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:57.249522      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:58.249613      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:07:59.250089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:00.250227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:01.251288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:02.251382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:03.251852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:04.251920      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:05.252627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:06.252726      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:07.253357      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:08.253520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:09.254239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:10.254346      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:11.254423      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:12.255300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:08:12.902
  Dec  2 13:08:12.906: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-subpath-test-projected-pfxz container test-container-subpath-projected-pfxz: <nil>
  STEP: delete the pod @ 12/02/23 13:08:12.922
  STEP: Deleting pod pod-subpath-test-projected-pfxz @ 12/02/23 13:08:12.939
  Dec  2 13:08:12.939: INFO: Deleting pod "pod-subpath-test-projected-pfxz" in namespace "subpath-9398"
  Dec  2 13:08:12.942: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9398" for this suite. @ 12/02/23 13:08:12.946
• [22.147 seconds]
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:647
  STEP: Creating a kubernetes client @ 12/02/23 13:08:12.964
  Dec  2 13:08:12.964: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svcaccounts @ 12/02/23 13:08:12.965
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:12.981
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:12.983
  STEP: creating a ServiceAccount @ 12/02/23 13:08:12.986
  STEP: watching for the ServiceAccount to be added @ 12/02/23 13:08:12.993
  STEP: patching the ServiceAccount @ 12/02/23 13:08:12.997
  STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) @ 12/02/23 13:08:13.002
  STEP: deleting the ServiceAccount @ 12/02/23 13:08:13.005
  Dec  2 13:08:13.019: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7781" for this suite. @ 12/02/23 13:08:13.023
• [0.067 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:236
  STEP: Creating a kubernetes client @ 12/02/23 13:08:13.032
  Dec  2 13:08:13.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:08:13.033
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:13.048
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:13.051
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:08:13.053
  E1202 13:08:13.256156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:14.256222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:15.256629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:16.256708      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:08:17.077
  Dec  2 13:08:17.080: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-5f21e300-a3d5-4b16-9edf-2f2d1ae8c771 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:08:17.087
  Dec  2 13:08:17.103: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5748" for this suite. @ 12/02/23 13:08:17.107
• [4.086 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]
test/e2e/network/dns.go:286
  STEP: Creating a kubernetes client @ 12/02/23 13:08:17.119
  Dec  2 13:08:17.119: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 13:08:17.12
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:17.137
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:17.139
  STEP: Creating a test headless service @ 12/02/23 13:08:17.141
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8907.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8907.svc.cluster.local;sleep 1; done
   @ 12/02/23 13:08:17.146
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8907.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8907.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8907.svc.cluster.local;sleep 1; done
   @ 12/02/23 13:08:17.146
  STEP: creating a pod to probe DNS @ 12/02/23 13:08:17.146
  STEP: submitting the pod to kubernetes @ 12/02/23 13:08:17.146
  E1202 13:08:17.257641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:18.257742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/02/23 13:08:19.187
  STEP: looking for the results for each expected name from probers @ 12/02/23 13:08:19.19
  Dec  2 13:08:19.194: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.197: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.200: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.204: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.207: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.209: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.213: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.216: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8907.svc.cluster.local from pod dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6: the server could not find the requested resource (get pods dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6)
  Dec  2 13:08:19.216: INFO: Lookups using dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8907.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8907.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8907.svc.cluster.local jessie_udp@dns-test-service-2.dns-8907.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8907.svc.cluster.local]

  Dec  2 13:08:19.221: INFO: Pod client logs for webserver: 
  Dec  2 13:08:19.228: INFO: Pod client logs for querier: 
  Dec  2 13:08:19.233: INFO: Pod client logs for jessie-querier: 
  E1202 13:08:19.258413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:20.259336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:21.259696      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:22.259751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:23.259960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:24.260829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:08:24.263: INFO: DNS probes using dns-8907/dns-test-2b5711c0-d492-4f35-9bdd-38567413d0e6 succeeded

  Dec  2 13:08:24.263: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:08:24.266
  STEP: deleting the test headless service @ 12/02/23 13:08:24.282
  STEP: Destroying namespace "dns-8907" for this suite. @ 12/02/23 13:08:24.294
• [7.183 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:137
  STEP: Creating a kubernetes client @ 12/02/23 13:08:24.302
  Dec  2 13:08:24.302: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:08:24.303
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:24.322
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:24.324
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/02/23 13:08:24.326
  E1202 13:08:25.261132      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:26.261171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:08:26.343
  Dec  2 13:08:26.346: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-98d9d7c0-cf3d-40d9-94fc-745b5a7a478c container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:08:26.353
  Dec  2 13:08:26.367: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-6623" for this suite. @ 12/02/23 13:08:26.371
• [2.075 seconds]
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]
test/e2e/apimachinery/webhook.go:238
  STEP: Creating a kubernetes client @ 12/02/23 13:08:26.377
  Dec  2 13:08:26.377: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:08:26.377
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:26.394
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:26.396
  STEP: Setting up server cert @ 12/02/23 13:08:26.419
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:08:26.773
  STEP: Deploying the webhook pod @ 12/02/23 13:08:26.781
  STEP: Wait for the deployment to be ready @ 12/02/23 13:08:26.792
  Dec  2 13:08:26.801: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:08:27.262027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:28.262239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:08:28.814
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:08:28.824
  E1202 13:08:29.263291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:08:29.824: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API @ 12/02/23 13:08:29.832
  STEP: create a namespace for the webhook @ 12/02/23 13:08:29.846
  STEP: create a configmap should be unconditionally rejected by the webhook @ 12/02/23 13:08:29.86
  Dec  2 13:08:29.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-6796" for this suite. @ 12/02/23 13:08:29.955
  STEP: Destroying namespace "webhook-markers-9554" for this suite. @ 12/02/23 13:08:29.963
  STEP: Destroying namespace "fail-closed-namespace-4727" for this suite. @ 12/02/23 13:08:29.97
• [3.598 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:194
  STEP: Creating a kubernetes client @ 12/02/23 13:08:29.976
  Dec  2 13:08:29.976: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 13:08:29.977
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:29.99
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:29.992
  Dec  2 13:08:29.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:08:30.263997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties @ 12/02/23 13:08:31.22
  Dec  2 13:08:31.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-684 --namespace=crd-publish-openapi-684 create -f -'
  E1202 13:08:31.264356      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:32.264423      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:33.264583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:08:33.524: INFO: stderr: ""
  Dec  2 13:08:33.525: INFO: stdout: "e2e-test-crd-publish-openapi-2618-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec  2 13:08:33.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-684 --namespace=crd-publish-openapi-684 delete e2e-test-crd-publish-openapi-2618-crds test-cr'
  Dec  2 13:08:33.583: INFO: stderr: ""
  Dec  2 13:08:33.583: INFO: stdout: "e2e-test-crd-publish-openapi-2618-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  Dec  2 13:08:33.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-684 --namespace=crd-publish-openapi-684 apply -f -'
  Dec  2 13:08:33.704: INFO: stderr: ""
  Dec  2 13:08:33.704: INFO: stdout: "e2e-test-crd-publish-openapi-2618-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
  Dec  2 13:08:33.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-684 --namespace=crd-publish-openapi-684 delete e2e-test-crd-publish-openapi-2618-crds test-cr'
  Dec  2 13:08:33.760: INFO: stderr: ""
  Dec  2 13:08:33.760: INFO: stdout: "e2e-test-crd-publish-openapi-2618-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
  STEP: kubectl explain works to explain CR @ 12/02/23 13:08:33.76
  Dec  2 13:08:33.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=crd-publish-openapi-684 explain e2e-test-crd-publish-openapi-2618-crds'
  Dec  2 13:08:34.091: INFO: stderr: ""
  Dec  2 13:08:34.091: INFO: stdout: "GROUP:      crd-publish-openapi-test-unknown-at-root.example.com\nKIND:       e2e-test-crd-publish-openapi-2618-crd\nVERSION:    v1\n\nDESCRIPTION:\n    preserve-unknown-properties at root for Testing\n    \nFIELDS:\n  apiVersion\t<string>\n    APIVersion defines the versioned schema of this representation of an object.\n    Servers should convert recognized schemas to the latest internal value, and\n    may reject unrecognized values. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n  kind\t<string>\n    Kind is a string value representing the REST resource this object\n    represents. Servers may infer this from the endpoint the client submits\n    requests to. Cannot be updated. In CamelCase. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n  metadata\t<ObjectMeta>\n    Standard object's metadata. More info:\n    https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n  spec\t<Object>\n    Specification of Waldo\n\n  status\t<Object>\n    Status of Waldo\n\n\n"
  E1202 13:08:34.265189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:35.265505      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:08:35.361: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-684" for this suite. @ 12/02/23 13:08:35.369
• [5.401 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should be updated [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:345
  STEP: Creating a kubernetes client @ 12/02/23 13:08:35.378
  Dec  2 13:08:35.378: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:08:35.378
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:35.395
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:35.398
  STEP: creating the pod @ 12/02/23 13:08:35.4
  STEP: submitting the pod to kubernetes @ 12/02/23 13:08:35.4
  E1202 13:08:36.266222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:37.266323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: verifying the pod is in kubernetes @ 12/02/23 13:08:37.416
  STEP: updating the pod @ 12/02/23 13:08:37.42
  Dec  2 13:08:37.931: INFO: Successfully updated pod "pod-update-665aab05-f4fc-4b48-951c-208d49a867f9"
  STEP: verifying the updated pod is in kubernetes @ 12/02/23 13:08:37.934
  Dec  2 13:08:37.937: INFO: Pod update OK
  Dec  2 13:08:37.937: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-9711" for this suite. @ 12/02/23 13:08:37.941
• [2.571 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:127
  STEP: Creating a kubernetes client @ 12/02/23 13:08:37.949
  Dec  2 13:08:37.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:08:37.95
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:37.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:37.968
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/02/23 13:08:37.97
  E1202 13:08:38.267089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:39.267179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:40.268057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:41.268255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:08:41.993
  Dec  2 13:08:41.996: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-1d122c09-f955-4001-99e7-6cb488106dee container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:08:42.002
  Dec  2 13:08:42.018: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-1185" for this suite. @ 12/02/23 13:08:42.022
• [4.079 seconds]
------------------------------
SS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:216
  STEP: Creating a kubernetes client @ 12/02/23 13:08:42.029
  Dec  2 13:08:42.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-runtime @ 12/02/23 13:08:42.029
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:42.045
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:42.048
  STEP: create the container @ 12/02/23 13:08:42.05
  W1202 13:08:42.061598      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Failed @ 12/02/23 13:08:42.061
  E1202 13:08:42.268873      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:43.269902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:44.270456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/02/23 13:08:45.081
  STEP: the container should be terminated @ 12/02/23 13:08:45.083
  STEP: the termination message should be set @ 12/02/23 13:08:45.083
  Dec  2 13:08:45.083: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
  STEP: delete the container @ 12/02/23 13:08:45.083
  Dec  2 13:08:45.095: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-2693" for this suite. @ 12/02/23 13:08:45.102
• [3.081 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]
test/e2e/scheduling/preemption.go:224
  STEP: Creating a kubernetes client @ 12/02/23 13:08:45.11
  Dec  2 13:08:45.110: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-preemption @ 12/02/23 13:08:45.11
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:08:45.129
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:08:45.132
  Dec  2 13:08:45.147: INFO: Waiting up to 1m0s for all nodes to be ready
  E1202 13:08:45.270888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:46.271926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:47.272528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:48.272628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:49.273241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:50.277043      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:51.277211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:52.277481      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:53.277705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:54.277784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:55.278279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:56.278323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:57.278778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:58.278858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:08:59.279250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:00.279429      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:01.279831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:02.280000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:03.281723      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:04.282210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:05.283198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:06.283605      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:07.284261      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:08.284326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:09.285093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:10.285187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:11.285292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:12.285367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:13.286007      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:14.287006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:15.287651      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:16.288305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:17.289002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:18.289176      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:19.290215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:20.290305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:21.290980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:22.291089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:23.292007      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:24.292161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:25.292704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:26.292799      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:27.293717      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:28.293866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:29.294349      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:30.294398      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:31.294689      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:32.294786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:33.295728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:34.295833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:35.296248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:36.296347      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:37.296874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:38.297117      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:39.297154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:40.297322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:41.298341      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:42.299281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:43.299407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:44.299565      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:09:45.166: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Create pods that use 4/5 of node resources. @ 12/02/23 13:09:45.169
  Dec  2 13:09:45.185: INFO: Created pod: pod0-0-sched-preemption-low-priority
  Dec  2 13:09:45.192: INFO: Created pod: pod0-1-sched-preemption-medium-priority
  Dec  2 13:09:45.229: INFO: Created pod: pod1-0-sched-preemption-medium-priority
  Dec  2 13:09:45.235: INFO: Created pod: pod1-1-sched-preemption-medium-priority
  Dec  2 13:09:45.253: INFO: Created pod: pod2-0-sched-preemption-medium-priority
  Dec  2 13:09:45.260: INFO: Created pod: pod2-1-sched-preemption-medium-priority
  STEP: Wait for pods to be scheduled. @ 12/02/23 13:09:45.26
  E1202 13:09:45.300478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:46.301069      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Run a critical pod that use same resources as that of a lower priority pod @ 12/02/23 13:09:47.281
  E1202 13:09:47.301619      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:48.301757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:49.301729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:09:49.336: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-3476" for this suite. @ 12/02/23 13:09:49.396
• [64.292 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:51
  STEP: Creating a kubernetes client @ 12/02/23 13:09:49.402
  Dec  2 13:09:49.402: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/02/23 13:09:49.403
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:09:49.417
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:09:49.419
  STEP: creating a target pod @ 12/02/23 13:09:49.423
  E1202 13:09:50.302821      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:51.303847      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 12/02/23 13:09:51.444
  E1202 13:09:52.303927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:53.303965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 12/02/23 13:09:53.466
  Dec  2 13:09:53.466: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8893 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:09:53.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:09:53.467: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:09:53.467: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-8893/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Dec  2 13:09:53.539: INFO: Exec stderr: ""
  Dec  2 13:09:53.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-8893" for this suite. @ 12/02/23 13:09:53.551
• [4.156 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]
test/e2e/apps/daemon_set.go:836
  STEP: Creating a kubernetes client @ 12/02/23 13:09:53.559
  Dec  2 13:09:53.559: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename daemonsets @ 12/02/23 13:09:53.559
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:09:53.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:09:53.581
  STEP: Creating simple DaemonSet "daemon-set" @ 12/02/23 13:09:53.606
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/02/23 13:09:53.614
  Dec  2 13:09:53.619: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:09:53.619: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:09:53.622: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 13:09:53.622: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:09:54.304147      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:09:54.628: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:09:54.628: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:09:54.633: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 13:09:54.633: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:09:55.304612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:09:55.629: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:09:55.629: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:09:55.632: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 13:09:55.632: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: listing all DaemonSets @ 12/02/23 13:09:55.635
  STEP: DeleteCollection of the DaemonSets @ 12/02/23 13:09:55.639
  STEP: Verify that ReplicaSets have been deleted @ 12/02/23 13:09:55.647
  Dec  2 13:09:55.657: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"24781"},"items":null}

  Dec  2 13:09:55.662: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"24781"},"items":[{"metadata":{"name":"daemon-set-d6pvv","generateName":"daemon-set-","namespace":"daemonsets-8221","uid":"bf80516f-e6a0-4bf9-8d31-77d77ee0ab18","resourceVersion":"24776","creationTimestamp":"2023-12-02T13:09:53Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c8aec278-984f-40da-b4c5-d993a379f72f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-02T13:09:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8aec278-984f-40da-b4c5-d993a379f72f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-02T13:09:55Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.21.223\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-hjfkt","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-hjfkt","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-1-50","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-1-50"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:53Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:55Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:55Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:53Z"}],"hostIP":"172.31.1.50","podIP":"192.168.21.223","podIPs":[{"ip":"192.168.21.223"}],"startTime":"2023-12-02T13:09:53Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-02T13:09:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://a22aad147c7a7369420f688c7237e1c50000f07091736000b7d3baeec690eaf1","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-hxbsq","generateName":"daemon-set-","namespace":"daemonsets-8221","uid":"9fa9d76e-d7e0-4032-8af6-5dcd16156d7f","resourceVersion":"24751","creationTimestamp":"2023-12-02T13:09:53Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c8aec278-984f-40da-b4c5-d993a379f72f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-02T13:09:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8aec278-984f-40da-b4c5-d993a379f72f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-02T13:09:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.95.162\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-j5jk4","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-j5jk4","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-89-192","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-89-192"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:53Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:54Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:54Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:53Z"}],"hostIP":"172.31.89.192","podIP":"192.168.95.162","podIPs":[{"ip":"192.168.95.162"}],"startTime":"2023-12-02T13:09:53Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-02T13:09:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://2e2bb712392a0bbf2cf858d55e3968c907ac696fefb0970768cdcc460cab9ca9","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-mcsrj","generateName":"daemon-set-","namespace":"daemonsets-8221","uid":"413f5f22-e184-4749-bc10-bff0b34cdd7c","resourceVersion":"24753","creationTimestamp":"2023-12-02T13:09:53Z","labels":{"controller-revision-hash":"58cb6b5b65","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c8aec278-984f-40da-b4c5-d993a379f72f","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2023-12-02T13:09:53Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c8aec278-984f-40da-b4c5-d993a379f72f\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2023-12-02T13:09:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.230.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-2g9qs","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-2g9qs","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-74-39","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-74-39"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:53Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:54Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:54Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2023-12-02T13:09:53Z"}],"hostIP":"172.31.74.39","podIP":"192.168.230.6","podIPs":[{"ip":"192.168.230.6"}],"startTime":"2023-12-02T13:09:53Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2023-12-02T13:09:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-4","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22","containerID":"containerd://7e847a8abe05ae1a6d6ff51af4150d75b2cb6c2d0cba77eee3635f147e3d0319","started":true}],"qosClass":"BestEffort"}}]}

  Dec  2 13:09:55.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-8221" for this suite. @ 12/02/23 13:09:55.683
• [2.132 seconds]
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]
test/e2e/apps/statefulset.go:901
  STEP: Creating a kubernetes client @ 12/02/23 13:09:55.692
  Dec  2 13:09:55.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 13:09:55.692
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:09:55.717
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:09:55.72
  STEP: Creating service test in namespace statefulset-4679 @ 12/02/23 13:09:55.724
  STEP: Creating statefulset ss in namespace statefulset-4679 @ 12/02/23 13:09:55.729
  Dec  2 13:09:55.745: INFO: Found 0 stateful pods, waiting for 1
  E1202 13:09:56.304778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:57.304945      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:58.305115      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:09:59.305210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:00.305291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:01.305561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:02.305742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:03.305834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:04.305936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:05.306140      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:05.750: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: getting scale subresource @ 12/02/23 13:10:05.755
  STEP: updating a scale subresource @ 12/02/23 13:10:05.759
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/02/23 13:10:05.764
  STEP: Patch a scale subresource @ 12/02/23 13:10:05.767
  STEP: verifying the statefulset Spec.Replicas was modified @ 12/02/23 13:10:05.777
  Dec  2 13:10:05.783: INFO: Deleting all statefulset in ns statefulset-4679
  Dec  2 13:10:05.786: INFO: Scaling statefulset ss to 0
  E1202 13:10:06.306293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:07.306462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:08.306502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:09.306586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:10.307310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:11.307581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:12.307745      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:13.307860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:14.307958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:15.308037      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:15.808: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 13:10:15.812: INFO: Deleting statefulset ss
  Dec  2 13:10:15.824: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-4679" for this suite. @ 12/02/23 13:10:15.828
• [20.143 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet Replace and Patch tests [Conformance]
test/e2e/apps/replica_set.go:154
  STEP: Creating a kubernetes client @ 12/02/23 13:10:15.836
  Dec  2 13:10:15.836: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replicaset @ 12/02/23 13:10:15.836
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:15.852
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:15.855
  Dec  2 13:10:15.868: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1202 13:10:16.308164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:17.308272      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:18.308795      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:19.308897      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:20.309006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:20.873: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/02/23 13:10:20.873
  STEP: Scaling up "test-rs" replicaset  @ 12/02/23 13:10:20.873
  Dec  2 13:10:20.882: INFO: Updating replica set "test-rs"
  STEP: patching the ReplicaSet @ 12/02/23 13:10:20.882
  Dec  2 13:10:20.893: INFO: observed ReplicaSet test-rs in namespace replicaset-3737 with ReadyReplicas 1, AvailableReplicas 1
  Dec  2 13:10:20.938: INFO: observed ReplicaSet test-rs in namespace replicaset-3737 with ReadyReplicas 1, AvailableReplicas 1
  Dec  2 13:10:20.965: INFO: observed ReplicaSet test-rs in namespace replicaset-3737 with ReadyReplicas 1, AvailableReplicas 1
  Dec  2 13:10:20.984: INFO: observed ReplicaSet test-rs in namespace replicaset-3737 with ReadyReplicas 1, AvailableReplicas 1
  E1202 13:10:21.310025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:21.870: INFO: observed ReplicaSet test-rs in namespace replicaset-3737 with ReadyReplicas 2, AvailableReplicas 2
  Dec  2 13:10:21.880: INFO: observed Replicaset test-rs in namespace replicaset-3737 with ReadyReplicas 3 found true
  Dec  2 13:10:21.880: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-3737" for this suite. @ 12/02/23 13:10:21.884
• [6.054 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] DNS should provide DNS for pods for Hostname [Conformance]
test/e2e/network/dns.go:244
  STEP: Creating a kubernetes client @ 12/02/23 13:10:21.891
  Dec  2 13:10:21.891: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 13:10:21.891
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:21.911
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:21.914
  STEP: Creating a test headless service @ 12/02/23 13:10:21.917
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5486.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5486.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
   @ 12/02/23 13:10:21.921
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5486.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5486.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
   @ 12/02/23 13:10:21.921
  STEP: creating a pod to probe DNS @ 12/02/23 13:10:21.921
  STEP: submitting the pod to kubernetes @ 12/02/23 13:10:21.921
  E1202 13:10:22.310166      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:23.310266      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/02/23 13:10:23.942
  STEP: looking for the results for each expected name from probers @ 12/02/23 13:10:23.946
  Dec  2 13:10:23.962: INFO: DNS probes using dns-5486/dns-test-1269c42f-981d-43d0-b1bf-c1ae126aa6e3 succeeded

  Dec  2 13:10:23.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:10:23.967
  STEP: deleting the test headless service @ 12/02/23 13:10:23.992
  STEP: Destroying namespace "dns-5486" for this suite. @ 12/02/23 13:10:24.011
• [2.130 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]
test/e2e/storage/csistoragecapacity.go:49
  STEP: Creating a kubernetes client @ 12/02/23 13:10:24.029
  Dec  2 13:10:24.029: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename csistoragecapacity @ 12/02/23 13:10:24.03
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:24.047
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:24.05
  STEP: getting /apis @ 12/02/23 13:10:24.054
  STEP: getting /apis/storage.k8s.io @ 12/02/23 13:10:24.057
  STEP: getting /apis/storage.k8s.io/v1 @ 12/02/23 13:10:24.058
  STEP: creating @ 12/02/23 13:10:24.059
  STEP: watching @ 12/02/23 13:10:24.073
  Dec  2 13:10:24.073: INFO: starting watch
  STEP: getting @ 12/02/23 13:10:24.081
  STEP: listing in namespace @ 12/02/23 13:10:24.084
  STEP: listing across namespaces @ 12/02/23 13:10:24.087
  STEP: patching @ 12/02/23 13:10:24.09
  STEP: updating @ 12/02/23 13:10:24.095
  Dec  2 13:10:24.100: INFO: waiting for watch events with expected annotations in namespace
  Dec  2 13:10:24.100: INFO: waiting for watch events with expected annotations across namespace
  STEP: deleting @ 12/02/23 13:10:24.1
  STEP: deleting a collection @ 12/02/23 13:10:24.111
  Dec  2 13:10:24.126: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csistoragecapacity-3197" for this suite. @ 12/02/23 13:10:24.13
• [0.108 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/secrets_volume.go:386
  STEP: Creating a kubernetes client @ 12/02/23 13:10:24.137
  Dec  2 13:10:24.137: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:10:24.137
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:24.153
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:24.156
  Dec  2 13:10:24.195: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4042" for this suite. @ 12/02/23 13:10:24.198
• [0.068 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]
test/e2e/network/proxy.go:101
  STEP: Creating a kubernetes client @ 12/02/23 13:10:24.207
  Dec  2 13:10:24.207: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename proxy @ 12/02/23 13:10:24.207
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:24.222
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:24.224
  STEP: starting an echo server on multiple ports @ 12/02/23 13:10:24.235
  STEP: creating replication controller proxy-service-ws628 in namespace proxy-5276 @ 12/02/23 13:10:24.236
  I1202 13:10:24.245507      18 runners.go:197] Created replication controller with name: proxy-service-ws628, namespace: proxy-5276, replica count: 1
  E1202 13:10:24.311259      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:10:25.296088      18 runners.go:197] proxy-service-ws628 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1202 13:10:25.311257      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:10:26.296833      18 runners.go:197] proxy-service-ws628 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 13:10:26.300: INFO: setup took 2.073777486s, starting test cases
  STEP: running 16 cases, 20 attempts per case, 320 total attempts @ 12/02/23 13:10:26.3
  Dec  2 13:10:26.305: INFO: (0) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 4.801673ms)
  Dec  2 13:10:26.306: INFO: (0) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 5.0995ms)
  Dec  2 13:10:26.307: INFO: (0) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 5.996875ms)
  Dec  2 13:10:26.307: INFO: (0) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.971054ms)
  Dec  2 13:10:26.309: INFO: (0) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 8.254382ms)
  Dec  2 13:10:26.311: INFO: (0) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 10.030085ms)
  E1202 13:10:26.311597      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:26.315: INFO: (0) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 14.624805ms)
  Dec  2 13:10:26.316: INFO: (0) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 15.445453ms)
  Dec  2 13:10:26.316: INFO: (0) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 15.507169ms)
  Dec  2 13:10:26.316: INFO: (0) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 15.325969ms)
  Dec  2 13:10:26.317: INFO: (0) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 15.700041ms)
  Dec  2 13:10:26.317: INFO: (0) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 15.767418ms)
  Dec  2 13:10:26.317: INFO: (0) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 16.204161ms)
  Dec  2 13:10:26.317: INFO: (0) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 15.944185ms)
  Dec  2 13:10:26.318: INFO: (0) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 16.932154ms)
  Dec  2 13:10:26.318: INFO: (0) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 17.041327ms)
  Dec  2 13:10:26.322: INFO: (1) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 3.270745ms)
  Dec  2 13:10:26.322: INFO: (1) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 3.952546ms)
  Dec  2 13:10:26.322: INFO: (1) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 4.359728ms)
  Dec  2 13:10:26.323: INFO: (1) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 4.611004ms)
  Dec  2 13:10:26.323: INFO: (1) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 5.002382ms)
  Dec  2 13:10:26.324: INFO: (1) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.589482ms)
  Dec  2 13:10:26.325: INFO: (1) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 6.590216ms)
  Dec  2 13:10:26.325: INFO: (1) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 6.549981ms)
  Dec  2 13:10:26.325: INFO: (1) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 6.534397ms)
  Dec  2 13:10:26.325: INFO: (1) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 7.119526ms)
  Dec  2 13:10:26.326: INFO: (1) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 8.245876ms)
  Dec  2 13:10:26.327: INFO: (1) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 8.455934ms)
  Dec  2 13:10:26.327: INFO: (1) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 8.631479ms)
  Dec  2 13:10:26.327: INFO: (1) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 8.545566ms)
  Dec  2 13:10:26.327: INFO: (1) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 9.110802ms)
  Dec  2 13:10:26.330: INFO: (1) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 11.881668ms)
  Dec  2 13:10:26.334: INFO: (2) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 3.539934ms)
  Dec  2 13:10:26.334: INFO: (2) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 4.140699ms)
  Dec  2 13:10:26.334: INFO: (2) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 4.152959ms)
  Dec  2 13:10:26.335: INFO: (2) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 4.523338ms)
  Dec  2 13:10:26.335: INFO: (2) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 4.714579ms)
  Dec  2 13:10:26.336: INFO: (2) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 5.313163ms)
  Dec  2 13:10:26.336: INFO: (2) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.592591ms)
  Dec  2 13:10:26.336: INFO: (2) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.934626ms)
  Dec  2 13:10:26.337: INFO: (2) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 6.438575ms)
  Dec  2 13:10:26.338: INFO: (2) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 7.211143ms)
  Dec  2 13:10:26.338: INFO: (2) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 7.557374ms)
  Dec  2 13:10:26.338: INFO: (2) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 7.96661ms)
  Dec  2 13:10:26.338: INFO: (2) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 7.784453ms)
  Dec  2 13:10:26.338: INFO: (2) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 8.173704ms)
  Dec  2 13:10:26.339: INFO: (2) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.793227ms)
  Dec  2 13:10:26.340: INFO: (2) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 9.4038ms)
  Dec  2 13:10:26.344: INFO: (3) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 4.304467ms)
  Dec  2 13:10:26.345: INFO: (3) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 5.048694ms)
  Dec  2 13:10:26.345: INFO: (3) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 4.801285ms)
  Dec  2 13:10:26.346: INFO: (3) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 5.321308ms)
  Dec  2 13:10:26.346: INFO: (3) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 6.196048ms)
  Dec  2 13:10:26.346: INFO: (3) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 6.079409ms)
  Dec  2 13:10:26.347: INFO: (3) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 7.217598ms)
  Dec  2 13:10:26.348: INFO: (3) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.564025ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 8.656753ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 8.721265ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 9.069951ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 9.01508ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 9.066ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 8.982195ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 9.1285ms)
  Dec  2 13:10:26.349: INFO: (3) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 9.237133ms)
  Dec  2 13:10:26.353: INFO: (4) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 3.727596ms)
  Dec  2 13:10:26.354: INFO: (4) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 4.240841ms)
  Dec  2 13:10:26.354: INFO: (4) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 4.329545ms)
  Dec  2 13:10:26.355: INFO: (4) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 4.763796ms)
  Dec  2 13:10:26.355: INFO: (4) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 4.870833ms)
  Dec  2 13:10:26.356: INFO: (4) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 6.020508ms)
  Dec  2 13:10:26.357: INFO: (4) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 6.741404ms)
  Dec  2 13:10:26.357: INFO: (4) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 7.211578ms)
  Dec  2 13:10:26.357: INFO: (4) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 7.033552ms)
  Dec  2 13:10:26.357: INFO: (4) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 6.931215ms)
  Dec  2 13:10:26.357: INFO: (4) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 7.285924ms)
  Dec  2 13:10:26.358: INFO: (4) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 7.861003ms)
  Dec  2 13:10:26.358: INFO: (4) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 7.876367ms)
  Dec  2 13:10:26.358: INFO: (4) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 8.005963ms)
  Dec  2 13:10:26.358: INFO: (4) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.335529ms)
  Dec  2 13:10:26.358: INFO: (4) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 8.631791ms)
  Dec  2 13:10:26.362: INFO: (5) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 3.314756ms)
  Dec  2 13:10:26.362: INFO: (5) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 3.181132ms)
  Dec  2 13:10:26.364: INFO: (5) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.42674ms)
  Dec  2 13:10:26.364: INFO: (5) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 5.648355ms)
  Dec  2 13:10:26.365: INFO: (5) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.514574ms)
  Dec  2 13:10:26.365: INFO: (5) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 5.862424ms)
  Dec  2 13:10:26.365: INFO: (5) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 6.081199ms)
  Dec  2 13:10:26.365: INFO: (5) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 6.680633ms)
  Dec  2 13:10:26.366: INFO: (5) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 7.018571ms)
  Dec  2 13:10:26.367: INFO: (5) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 7.631382ms)
  Dec  2 13:10:26.367: INFO: (5) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 7.716754ms)
  Dec  2 13:10:26.367: INFO: (5) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.127657ms)
  Dec  2 13:10:26.367: INFO: (5) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 8.000016ms)
  Dec  2 13:10:26.367: INFO: (5) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 7.91271ms)
  Dec  2 13:10:26.367: INFO: (5) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.294729ms)
  Dec  2 13:10:26.368: INFO: (5) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 8.819281ms)
  Dec  2 13:10:26.371: INFO: (6) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 3.635984ms)
  Dec  2 13:10:26.372: INFO: (6) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 4.162475ms)
  Dec  2 13:10:26.372: INFO: (6) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 4.660714ms)
  Dec  2 13:10:26.373: INFO: (6) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.258871ms)
  Dec  2 13:10:26.373: INFO: (6) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.356512ms)
  Dec  2 13:10:26.374: INFO: (6) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 5.796067ms)
  Dec  2 13:10:26.375: INFO: (6) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 6.636194ms)
  Dec  2 13:10:26.375: INFO: (6) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 7.214812ms)
  Dec  2 13:10:26.375: INFO: (6) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 7.666353ms)
  Dec  2 13:10:26.375: INFO: (6) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 7.367296ms)
  Dec  2 13:10:26.375: INFO: (6) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 7.595271ms)
  Dec  2 13:10:26.375: INFO: (6) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 7.713754ms)
  Dec  2 13:10:26.375: INFO: (6) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 7.585145ms)
  Dec  2 13:10:26.376: INFO: (6) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.383677ms)
  Dec  2 13:10:26.376: INFO: (6) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 8.432543ms)
  Dec  2 13:10:26.377: INFO: (6) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 8.769026ms)
  Dec  2 13:10:26.381: INFO: (7) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 4.521696ms)
  Dec  2 13:10:26.383: INFO: (7) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 5.731138ms)
  Dec  2 13:10:26.385: INFO: (7) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 8.146342ms)
  Dec  2 13:10:26.386: INFO: (7) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 8.634278ms)
  Dec  2 13:10:26.386: INFO: (7) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 8.573541ms)
  Dec  2 13:10:26.387: INFO: (7) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 9.910588ms)
  Dec  2 13:10:26.387: INFO: (7) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 10.084893ms)
  Dec  2 13:10:26.388: INFO: (7) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 10.778265ms)
  Dec  2 13:10:26.388: INFO: (7) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 10.960792ms)
  Dec  2 13:10:26.389: INFO: (7) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 11.946267ms)
  Dec  2 13:10:26.389: INFO: (7) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 12.321021ms)
  Dec  2 13:10:26.389: INFO: (7) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 12.009846ms)
  Dec  2 13:10:26.390: INFO: (7) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 12.563905ms)
  Dec  2 13:10:26.390: INFO: (7) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 12.549356ms)
  Dec  2 13:10:26.390: INFO: (7) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 12.954478ms)
  Dec  2 13:10:26.391: INFO: (7) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 13.575083ms)
  Dec  2 13:10:26.394: INFO: (8) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 3.484557ms)
  Dec  2 13:10:26.394: INFO: (8) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 3.591206ms)
  Dec  2 13:10:26.396: INFO: (8) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 5.163692ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 7.737473ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 7.529726ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 7.867447ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 7.706459ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 7.664001ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 7.647109ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 7.938384ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 7.859597ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 7.982586ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 8.163998ms)
  Dec  2 13:10:26.399: INFO: (8) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 8.095562ms)
  Dec  2 13:10:26.400: INFO: (8) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.665964ms)
  Dec  2 13:10:26.400: INFO: (8) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 9.067032ms)
  Dec  2 13:10:26.405: INFO: (9) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 4.499637ms)
  Dec  2 13:10:26.405: INFO: (9) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 4.982308ms)
  Dec  2 13:10:26.406: INFO: (9) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.393633ms)
  Dec  2 13:10:26.406: INFO: (9) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 5.484131ms)
  Dec  2 13:10:26.407: INFO: (9) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 6.183113ms)
  Dec  2 13:10:26.407: INFO: (9) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 6.358208ms)
  Dec  2 13:10:26.407: INFO: (9) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 7.087135ms)
  Dec  2 13:10:26.408: INFO: (9) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 7.768625ms)
  Dec  2 13:10:26.408: INFO: (9) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 7.916764ms)
  Dec  2 13:10:26.408: INFO: (9) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 7.830004ms)
  Dec  2 13:10:26.409: INFO: (9) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.057152ms)
  Dec  2 13:10:26.409: INFO: (9) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 8.014831ms)
  Dec  2 13:10:26.409: INFO: (9) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 9.063272ms)
  Dec  2 13:10:26.409: INFO: (9) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 9.146529ms)
  Dec  2 13:10:26.410: INFO: (9) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 9.278262ms)
  Dec  2 13:10:26.410: INFO: (9) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 9.580284ms)
  Dec  2 13:10:26.414: INFO: (10) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 4.207043ms)
  Dec  2 13:10:26.414: INFO: (10) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 4.348972ms)
  Dec  2 13:10:26.414: INFO: (10) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 4.246365ms)
  Dec  2 13:10:26.415: INFO: (10) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 4.81703ms)
  Dec  2 13:10:26.416: INFO: (10) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 5.645058ms)
  Dec  2 13:10:26.416: INFO: (10) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.781651ms)
  Dec  2 13:10:26.416: INFO: (10) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 5.975422ms)
  Dec  2 13:10:26.416: INFO: (10) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.962525ms)
  Dec  2 13:10:26.417: INFO: (10) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 6.541533ms)
  Dec  2 13:10:26.418: INFO: (10) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 7.472409ms)
  Dec  2 13:10:26.418: INFO: (10) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 7.558787ms)
  Dec  2 13:10:26.418: INFO: (10) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 7.738206ms)
  Dec  2 13:10:26.418: INFO: (10) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 7.883005ms)
  Dec  2 13:10:26.418: INFO: (10) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 8.516598ms)
  Dec  2 13:10:26.419: INFO: (10) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.269137ms)
  Dec  2 13:10:26.420: INFO: (10) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 9.835194ms)
  Dec  2 13:10:26.424: INFO: (11) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 3.198379ms)
  Dec  2 13:10:26.424: INFO: (11) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 3.608282ms)
  Dec  2 13:10:26.425: INFO: (11) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 4.633047ms)
  Dec  2 13:10:26.425: INFO: (11) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 4.603283ms)
  Dec  2 13:10:26.425: INFO: (11) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 4.44001ms)
  Dec  2 13:10:26.426: INFO: (11) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 5.423167ms)
  Dec  2 13:10:26.426: INFO: (11) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.346827ms)
  Dec  2 13:10:26.427: INFO: (11) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 6.184388ms)
  Dec  2 13:10:26.427: INFO: (11) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 6.433136ms)
  Dec  2 13:10:26.427: INFO: (11) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 6.732596ms)
  Dec  2 13:10:26.427: INFO: (11) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 6.485941ms)
  Dec  2 13:10:26.428: INFO: (11) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 7.65777ms)
  Dec  2 13:10:26.428: INFO: (11) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 7.744948ms)
  Dec  2 13:10:26.429: INFO: (11) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 8.2383ms)
  Dec  2 13:10:26.429: INFO: (11) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 8.308135ms)
  Dec  2 13:10:26.429: INFO: (11) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 8.848315ms)
  Dec  2 13:10:26.433: INFO: (12) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 3.539798ms)
  Dec  2 13:10:26.433: INFO: (12) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 3.732495ms)
  Dec  2 13:10:26.433: INFO: (12) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 3.933667ms)
  Dec  2 13:10:26.434: INFO: (12) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 4.340834ms)
  Dec  2 13:10:26.435: INFO: (12) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.103865ms)
  Dec  2 13:10:26.435: INFO: (12) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 4.967854ms)
  Dec  2 13:10:26.435: INFO: (12) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 5.572365ms)
  Dec  2 13:10:26.436: INFO: (12) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 6.695294ms)
  Dec  2 13:10:26.436: INFO: (12) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 6.417184ms)
  Dec  2 13:10:26.437: INFO: (12) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 6.975034ms)
  Dec  2 13:10:26.438: INFO: (12) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 8.209068ms)
  Dec  2 13:10:26.438: INFO: (12) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 8.236282ms)
  Dec  2 13:10:26.438: INFO: (12) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.914473ms)
  Dec  2 13:10:26.438: INFO: (12) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 8.721735ms)
  Dec  2 13:10:26.438: INFO: (12) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 8.79565ms)
  Dec  2 13:10:26.439: INFO: (12) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.701938ms)
  Dec  2 13:10:26.443: INFO: (13) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 3.729123ms)
  Dec  2 13:10:26.444: INFO: (13) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 4.411682ms)
  Dec  2 13:10:26.445: INFO: (13) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 5.276716ms)
  Dec  2 13:10:26.445: INFO: (13) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 6.082825ms)
  Dec  2 13:10:26.445: INFO: (13) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 4.259614ms)
  Dec  2 13:10:26.445: INFO: (13) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.569972ms)
  Dec  2 13:10:26.446: INFO: (13) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 5.751265ms)
  Dec  2 13:10:26.446: INFO: (13) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 5.074458ms)
  Dec  2 13:10:26.447: INFO: (13) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 8.731694ms)
  Dec  2 13:10:26.450: INFO: (13) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 11.432112ms)
  Dec  2 13:10:26.452: INFO: (13) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 11.211001ms)
  Dec  2 13:10:26.453: INFO: (13) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 13.132525ms)
  Dec  2 13:10:26.453: INFO: (13) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 13.402946ms)
  Dec  2 13:10:26.453: INFO: (13) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 12.367504ms)
  Dec  2 13:10:26.453: INFO: (13) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 14.497763ms)
  Dec  2 13:10:26.453: INFO: (13) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 14.296921ms)
  Dec  2 13:10:26.461: INFO: (14) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 6.708203ms)
  Dec  2 13:10:26.461: INFO: (14) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 6.690853ms)
  Dec  2 13:10:26.461: INFO: (14) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 7.530076ms)
  Dec  2 13:10:26.461: INFO: (14) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 7.527082ms)
  Dec  2 13:10:26.462: INFO: (14) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 7.50638ms)
  Dec  2 13:10:26.462: INFO: (14) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 7.601637ms)
  Dec  2 13:10:26.462: INFO: (14) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 7.724588ms)
  Dec  2 13:10:26.462: INFO: (14) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 7.824273ms)
  Dec  2 13:10:26.462: INFO: (14) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 7.926323ms)
  Dec  2 13:10:26.462: INFO: (14) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 7.991934ms)
  Dec  2 13:10:26.463: INFO: (14) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 8.214634ms)
  Dec  2 13:10:26.463: INFO: (14) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.770331ms)
  Dec  2 13:10:26.463: INFO: (14) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 9.10831ms)
  Dec  2 13:10:26.463: INFO: (14) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 8.772512ms)
  Dec  2 13:10:26.463: INFO: (14) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.920961ms)
  Dec  2 13:10:26.464: INFO: (14) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 9.335955ms)
  Dec  2 13:10:26.468: INFO: (15) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 3.52696ms)
  Dec  2 13:10:26.468: INFO: (15) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 3.850343ms)
  Dec  2 13:10:26.470: INFO: (15) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.724573ms)
  Dec  2 13:10:26.470: INFO: (15) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 5.64951ms)
  Dec  2 13:10:26.470: INFO: (15) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 6.191243ms)
  Dec  2 13:10:26.471: INFO: (15) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 6.660696ms)
  Dec  2 13:10:26.471: INFO: (15) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 6.350679ms)
  Dec  2 13:10:26.471: INFO: (15) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 6.753081ms)
  Dec  2 13:10:26.471: INFO: (15) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 6.619353ms)
  Dec  2 13:10:26.471: INFO: (15) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 6.558058ms)
  Dec  2 13:10:26.472: INFO: (15) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 7.560173ms)
  Dec  2 13:10:26.472: INFO: (15) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 7.71692ms)
  Dec  2 13:10:26.472: INFO: (15) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 8.152754ms)
  Dec  2 13:10:26.472: INFO: (15) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 7.758095ms)
  Dec  2 13:10:26.473: INFO: (15) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 8.411173ms)
  Dec  2 13:10:26.473: INFO: (15) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.576158ms)
  Dec  2 13:10:26.477: INFO: (16) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 3.912301ms)
  Dec  2 13:10:26.477: INFO: (16) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 4.244325ms)
  Dec  2 13:10:26.478: INFO: (16) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 4.882077ms)
  Dec  2 13:10:26.478: INFO: (16) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 4.895895ms)
  Dec  2 13:10:26.478: INFO: (16) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 4.964923ms)
  Dec  2 13:10:26.480: INFO: (16) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 6.6812ms)
  Dec  2 13:10:26.480: INFO: (16) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 6.786199ms)
  Dec  2 13:10:26.480: INFO: (16) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 6.741585ms)
  Dec  2 13:10:26.480: INFO: (16) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 7.33828ms)
  Dec  2 13:10:26.481: INFO: (16) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 7.387912ms)
  Dec  2 13:10:26.481: INFO: (16) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 7.533556ms)
  Dec  2 13:10:26.481: INFO: (16) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 8.075499ms)
  Dec  2 13:10:26.481: INFO: (16) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 7.861586ms)
  Dec  2 13:10:26.481: INFO: (16) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 8.023088ms)
  Dec  2 13:10:26.481: INFO: (16) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 8.396323ms)
  Dec  2 13:10:26.482: INFO: (16) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 9.244064ms)
  Dec  2 13:10:26.486: INFO: (17) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 3.269353ms)
  Dec  2 13:10:26.487: INFO: (17) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 4.396478ms)
  Dec  2 13:10:26.488: INFO: (17) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 5.120557ms)
  Dec  2 13:10:26.489: INFO: (17) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.920229ms)
  Dec  2 13:10:26.489: INFO: (17) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 6.425978ms)
  Dec  2 13:10:26.489: INFO: (17) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 6.584416ms)
  Dec  2 13:10:26.490: INFO: (17) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 6.754919ms)
  Dec  2 13:10:26.490: INFO: (17) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 6.656218ms)
  Dec  2 13:10:26.490: INFO: (17) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 7.110041ms)
  Dec  2 13:10:26.491: INFO: (17) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 8.204479ms)
  Dec  2 13:10:26.491: INFO: (17) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 8.013347ms)
  Dec  2 13:10:26.491: INFO: (17) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 8.327284ms)
  Dec  2 13:10:26.491: INFO: (17) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 8.04551ms)
  Dec  2 13:10:26.491: INFO: (17) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.3746ms)
  Dec  2 13:10:26.492: INFO: (17) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 9.076467ms)
  Dec  2 13:10:26.492: INFO: (17) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 9.305416ms)
  Dec  2 13:10:26.496: INFO: (18) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 3.456768ms)
  Dec  2 13:10:26.497: INFO: (18) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 4.339365ms)
  Dec  2 13:10:26.498: INFO: (18) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 5.86358ms)
  Dec  2 13:10:26.499: INFO: (18) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 5.874482ms)
  Dec  2 13:10:26.499: INFO: (18) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 5.813159ms)
  Dec  2 13:10:26.499: INFO: (18) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 6.510713ms)
  Dec  2 13:10:26.499: INFO: (18) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 6.488539ms)
  Dec  2 13:10:26.500: INFO: (18) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 7.603118ms)
  Dec  2 13:10:26.501: INFO: (18) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 8.150772ms)
  Dec  2 13:10:26.501: INFO: (18) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 8.35503ms)
  Dec  2 13:10:26.501: INFO: (18) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 8.763194ms)
  Dec  2 13:10:26.501: INFO: (18) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 8.805831ms)
  Dec  2 13:10:26.501: INFO: (18) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 8.663684ms)
  Dec  2 13:10:26.502: INFO: (18) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 9.205278ms)
  Dec  2 13:10:26.502: INFO: (18) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 9.36922ms)
  Dec  2 13:10:26.502: INFO: (18) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 9.439093ms)
  Dec  2 13:10:26.506: INFO: (19) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:462/proxy/: tls qux (200; 4.232111ms)
  Dec  2 13:10:26.507: INFO: (19) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:1080/proxy/rewriteme">test<... (200; 4.1865ms)
  Dec  2 13:10:26.507: INFO: (19) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:443/proxy/tlsrewritem... (200; 4.266176ms)
  Dec  2 13:10:26.508: INFO: (19) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:160/proxy/: foo (200; 5.540955ms)
  Dec  2 13:10:26.511: INFO: (19) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:1080/proxy/rewriteme">... (200; 7.945922ms)
  Dec  2 13:10:26.511: INFO: (19) /api/v1/namespaces/proxy-5276/pods/https:proxy-service-ws628-c4hjm:460/proxy/: tls baz (200; 8.607881ms)
  Dec  2 13:10:26.511: INFO: (19) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/: <a href="/api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm/proxy/rewriteme">test</a> (200; 8.632082ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:162/proxy/: bar (200; 9.20149ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/pods/http:proxy-service-ws628-c4hjm:162/proxy/: bar (200; 9.504877ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname2/proxy/: tls qux (200; 9.418344ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/pods/proxy-service-ws628-c4hjm:160/proxy/: foo (200; 9.551609ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname2/proxy/: bar (200; 10.153893ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname1/proxy/: foo (200; 9.879312ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/services/http:proxy-service-ws628:portname1/proxy/: foo (200; 9.997195ms)
  Dec  2 13:10:26.512: INFO: (19) /api/v1/namespaces/proxy-5276/services/proxy-service-ws628:portname2/proxy/: bar (200; 9.853814ms)
  Dec  2 13:10:26.513: INFO: (19) /api/v1/namespaces/proxy-5276/services/https:proxy-service-ws628:tlsportname1/proxy/: tls baz (200; 10.591478ms)
  Dec  2 13:10:26.513: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController proxy-service-ws628 in namespace proxy-5276, will wait for the garbage collector to delete the pods @ 12/02/23 13:10:26.516
  Dec  2 13:10:26.577: INFO: Deleting ReplicationController proxy-service-ws628 took: 7.129876ms
  Dec  2 13:10:26.677: INFO: Terminating ReplicationController proxy-service-ws628 pods took: 100.317565ms
  E1202 13:10:27.313729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:28.314486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:29.314828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "proxy-5276" for this suite. @ 12/02/23 13:10:29.478
• [5.279 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]
test/e2e/apps/deployment.go:150
  STEP: Creating a kubernetes client @ 12/02/23 13:10:29.486
  Dec  2 13:10:29.486: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 13:10:29.487
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:29.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:29.507
  Dec  2 13:10:29.510: INFO: Creating simple deployment test-new-deployment
  Dec  2 13:10:29.522: INFO: deployment "test-new-deployment" doesn't have the required revision set
  E1202 13:10:30.315418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:31.315902      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting scale subresource @ 12/02/23 13:10:31.535
  STEP: updating a scale subresource @ 12/02/23 13:10:31.538
  STEP: verifying the deployment Spec.Replicas was modified @ 12/02/23 13:10:31.544
  STEP: Patch a scale subresource @ 12/02/23 13:10:31.547
  Dec  2 13:10:31.560: INFO: Deployment "test-new-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=19) "test-new-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4803",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "44dd6500-593f-49be-9d49-9bedd223b04a",
      ResourceVersion: (string) (len=5) "25284",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119429,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)(<nil>),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=28) {
              00000000  7b 22 66 3a 73 70 65 63  22 3a 7b 22 66 3a 72 65  |{"f:spec":{"f:re|
              00000010  70 6c 69 63 61 73 22 3a  7b 7d 7d 7d              |plicas":{}}}|
            }
          }),
          Subresource: (string) (len=5) "scale"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119429,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=619) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |onds":{},"f:revi|
              00000060  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000070  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              00000090  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000a0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000b0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000c0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000d0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000e0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              000000f0  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000100  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000110  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000120  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000130  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000140  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000150  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000160  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000170  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000180  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000190  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001a0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001b0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001c0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001d0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001e0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000001f0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000200  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000210  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000220  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000230  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000240  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000250  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000260  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=514) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 70 64  |licas":{},"f:upd|
              000001f0  61 74 65 64 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |atedReplicas":{}|
              00000200  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(4),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119429,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=22) "NewReplicaSetAvailable",
          Message: (string) (len=72) "ReplicaSet \"test-new-deployment-557759b7c7\" has successfully progressed."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  2 13:10:31.567: INFO: New ReplicaSet "test-new-deployment-557759b7c7" of Deployment "test-new-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "test-new-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-4803",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "e131eba3-4db4-48df-8469-2042ca9df943",
      ResourceVersion: (string) (len=5) "25283",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119429,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=19) "test-new-deployment",
          UID: (types.UID) (len=36) "44dd6500-593f-49be-9d49-9bedd223b04a",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119431,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 34 34 64 64 36 35  30 30 2d 35 39 33 66 2d  |\"44dd6500-593f-|
              00000120  34 39 62 65 2d 39 64 34  39 2d 39 62 65 64 64 32  |49be-9d49-9bedd2|
              00000130  32 33 62 30 34 61 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |23b04a\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 13:10:31.573: INFO: Pod "test-new-deployment-557759b7c7-hzz2g" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-hzz2g",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4803",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f4c28c3c-ab98-4788-a974-88010e797109",
      ResourceVersion: (string) (len=5) "25287",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119431,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "e131eba3-4db4-48df-8469-2042ca9df943",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119431,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 31  33 31 65 62 61 33 2d 34  |d\":\"e131eba3-4|
              00000090  64 62 34 2d 34 38 64 66  2d 38 34 36 39 2d 32 30  |db4-48df-8469-20|
              000000a0  34 32 63 61 39 64 66 39  34 33 5c 22 7d 22 3a 7b  |42ca9df943\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fc4h2",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fc4h2",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119431,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:10:31.575: INFO: Pod "test-new-deployment-557759b7c7-pjjdj" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "test-new-deployment-557759b7c7-pjjdj",
      GenerateName: (string) (len=31) "test-new-deployment-557759b7c7-",
      Namespace: (string) (len=15) "deployment-4803",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "040f62b0-4f95-4d9a-9d27-2847176c45d3",
      ResourceVersion: (string) (len=5) "25276",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119429,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "test-new-deployment-557759b7c7",
          UID: (types.UID) (len=36) "e131eba3-4db4-48df-8469-2042ca9df943",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119429,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 65 31  33 31 65 62 61 33 2d 34  |d\":\"e131eba3-4|
              00000090  64 62 34 2d 34 38 64 66  2d 38 34 36 39 2d 32 30  |db4-48df-8469-20|
              000000a0  34 32 63 61 39 64 66 39  34 33 5c 22 7d 22 3a 7b  |42ca9df943\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 31 2e 32 34 36 5c 22  |192.168.21.246\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-bwmht",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-bwmht",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119429,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119430,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119429,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.246",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.246"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119429,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837119430,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://495a9ca1f917f1d60e028d560c7dc2545a38a8392e2a1870b45bf004ee0c7014",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:10:31.577: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-4803" for this suite. @ 12/02/23 13:10:31.585
• [2.106 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:168
  STEP: Creating a kubernetes client @ 12/02/23 13:10:31.595
  Dec  2 13:10:31.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename field-validation @ 12/02/23 13:10:31.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:31.614
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:31.616
  Dec  2 13:10:31.619: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:10:32.316740      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:33.316923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1202 13:10:34.163952      18 warnings.go:70] unknown field "alpha"
  W1202 13:10:34.163971      18 warnings.go:70] unknown field "beta"
  W1202 13:10:34.163975      18 warnings.go:70] unknown field "delta"
  W1202 13:10:34.163978      18 warnings.go:70] unknown field "epsilon"
  W1202 13:10:34.163981      18 warnings.go:70] unknown field "gamma"
  E1202 13:10:34.317990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:34.695: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-2821" for this suite. @ 12/02/23 13:10:34.711
• [3.123 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]
test/e2e/storage/csi_inline.go:157
  STEP: Creating a kubernetes client @ 12/02/23 13:10:34.719
  Dec  2 13:10:34.719: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/02/23 13:10:34.719
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:34.737
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:34.74
  STEP: Creating two CSIDrivers @ 12/02/23 13:10:34.742
  STEP: Getting "inline-driver-19bd5480-2b4c-4b6e-a886-1d30e99da660" & "inline-driver-c9b0b5e0-0447-4519-befd-404de7ddadc5" @ 12/02/23 13:10:34.759
  STEP: Patching the CSIDriver "inline-driver-c9b0b5e0-0447-4519-befd-404de7ddadc5" @ 12/02/23 13:10:34.765
  STEP: Updating the CSIDriver "inline-driver-c9b0b5e0-0447-4519-befd-404de7ddadc5" @ 12/02/23 13:10:34.77
  STEP: Listing all CSIDrivers with the labelSelector: "e2e-test=csiinlinevolumes-6695" @ 12/02/23 13:10:34.779
  STEP: Deleting CSIDriver "inline-driver-19bd5480-2b4c-4b6e-a886-1d30e99da660" @ 12/02/23 13:10:34.784
  STEP: Confirm deletion of CSIDriver "inline-driver-19bd5480-2b4c-4b6e-a886-1d30e99da660" @ 12/02/23 13:10:34.79
  STEP: Deleting CSIDriver "inline-driver-c9b0b5e0-0447-4519-befd-404de7ddadc5" via DeleteCollection @ 12/02/23 13:10:34.793
  STEP: Confirm deletion of CSIDriver "inline-driver-c9b0b5e0-0447-4519-befd-404de7ddadc5" @ 12/02/23 13:10:34.8
  Dec  2 13:10:34.803: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-6695" for this suite. @ 12/02/23 13:10:34.806
• [0.094 seconds]
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:57
  STEP: Creating a kubernetes client @ 12/02/23 13:10:34.813
  Dec  2 13:10:34.813: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:10:34.815
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:34.836
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:34.838
  STEP: Creating secret with name secret-test-eedc83a8-7157-41df-a230-3a18987ddd8c @ 12/02/23 13:10:34.841
  STEP: Creating a pod to test consume secrets @ 12/02/23 13:10:34.848
  E1202 13:10:35.318629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:36.318810      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:37.319283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:38.319386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:10:38.867
  Dec  2 13:10:38.870: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-secrets-e0c54bb2-6cd5-43e7-ba3a-13cad6b9d621 container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 13:10:38.876
  Dec  2 13:10:38.893: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-6432" for this suite. @ 12/02/23 13:10:38.896
• [4.089 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]
test/e2e/network/service.go:1533
  STEP: Creating a kubernetes client @ 12/02/23 13:10:38.902
  Dec  2 13:10:38.902: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:10:38.903
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:38.916
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:38.919
  STEP: creating a service nodeport-service with the type=NodePort in namespace services-5415 @ 12/02/23 13:10:38.921
  STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service @ 12/02/23 13:10:38.935
  STEP: creating service externalsvc in namespace services-5415 @ 12/02/23 13:10:38.935
  STEP: creating replication controller externalsvc in namespace services-5415 @ 12/02/23 13:10:38.948
  I1202 13:10:38.953219      18 runners.go:197] Created replication controller with name: externalsvc, namespace: services-5415, replica count: 2
  E1202 13:10:39.320117      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:40.321115      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:41.321224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:10:42.003564      18 runners.go:197] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  STEP: changing the NodePort service to type=ExternalName @ 12/02/23 13:10:42.007
  Dec  2 13:10:42.026: INFO: Creating new exec pod
  E1202 13:10:42.322025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:43.322320      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:44.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-5415 exec execpodlzsn2 -- /bin/sh -x -c nslookup nodeport-service.services-5415.svc.cluster.local'
  Dec  2 13:10:44.189: INFO: stderr: "+ nslookup nodeport-service.services-5415.svc.cluster.local\n"
  Dec  2 13:10:44.189: INFO: stdout: "Server:\t\t10.152.183.66\nAddress:\t10.152.183.66#53\n\nnodeport-service.services-5415.svc.cluster.local\tcanonical name = externalsvc.services-5415.svc.cluster.local.\nName:\texternalsvc.services-5415.svc.cluster.local\nAddress: 10.152.183.204\n\n"
  Dec  2 13:10:44.189: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting ReplicationController externalsvc in namespace services-5415, will wait for the garbage collector to delete the pods @ 12/02/23 13:10:44.193
  Dec  2 13:10:44.253: INFO: Deleting ReplicationController externalsvc took: 6.174167ms
  E1202 13:10:44.322554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:44.353: INFO: Terminating ReplicationController externalsvc pods took: 100.105289ms
  E1202 13:10:45.322630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:46.323044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:47.323661      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:47.470: INFO: Cleaning up the NodePort to ExternalName test service
  STEP: Destroying namespace "services-5415" for this suite. @ 12/02/23 13:10:47.482
• [8.587 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]
test/e2e/common/storage/configmap_volume.go:504
  STEP: Creating a kubernetes client @ 12/02/23 13:10:47.489
  Dec  2 13:10:47.489: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 13:10:47.49
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:47.506
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:47.509
  Dec  2 13:10:47.547: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-1335" for this suite. @ 12/02/23 13:10:47.551
• [0.068 seconds]
------------------------------
S
------------------------------
[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]
test/e2e/apimachinery/field_validation.go:622
  STEP: Creating a kubernetes client @ 12/02/23 13:10:47.558
  Dec  2 13:10:47.558: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename field-validation @ 12/02/23 13:10:47.558
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:47.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:47.575
  Dec  2 13:10:47.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:10:48.324129      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:49.324390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1202 13:10:50.122962      18 warnings.go:70] unknown field "alpha"
  W1202 13:10:50.122989      18 warnings.go:70] unknown field "beta"
  W1202 13:10:50.122994      18 warnings.go:70] unknown field "delta"
  W1202 13:10:50.123009      18 warnings.go:70] unknown field "epsilon"
  W1202 13:10:50.123013      18 warnings.go:70] unknown field "gamma"
  E1202 13:10:50.324828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:10:50.649: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-9686" for this suite. @ 12/02/23 13:10:50.664
• [3.112 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:54
  STEP: Creating a kubernetes client @ 12/02/23 13:10:50.67
  Dec  2 13:10:50.670: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:10:50.671
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:50.688
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:50.69
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:10:50.693
  E1202 13:10:51.324922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:52.325183      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:53.325278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:54.325984      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:10:54.716
  Dec  2 13:10:54.719: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-1a6cb763-b135-46b0-870d-c2080d6dfce0 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:10:54.725
  Dec  2 13:10:54.742: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-513" for this suite. @ 12/02/23 13:10:54.747
• [4.083 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2202
  STEP: Creating a kubernetes client @ 12/02/23 13:10:54.754
  Dec  2 13:10:54.754: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:10:54.754
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:10:54.772
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:10:54.774
  STEP: creating service in namespace services-3427 @ 12/02/23 13:10:54.777
  STEP: creating service affinity-nodeport in namespace services-3427 @ 12/02/23 13:10:54.777
  STEP: creating replication controller affinity-nodeport in namespace services-3427 @ 12/02/23 13:10:54.79
  I1202 13:10:54.799681      18 runners.go:197] Created replication controller with name: affinity-nodeport, namespace: services-3427, replica count: 3
  E1202 13:10:55.326823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:56.326913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:57.327001      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:10:57.851725      18 runners.go:197] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 13:10:57.862: INFO: Creating new exec pod
  E1202 13:10:58.327087      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:10:59.327182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:00.328106      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:00.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3427 exec execpod-affinityt57r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
  Dec  2 13:11:00.998: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
  Dec  2 13:11:00.998: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:11:00.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3427 exec execpod-affinityt57r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.148 80'
  Dec  2 13:11:01.121: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.148 80\nConnection to 10.152.183.148 80 port [tcp/http] succeeded!\n"
  Dec  2 13:11:01.121: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:11:01.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3427 exec execpod-affinityt57r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.1.50 30597'
  Dec  2 13:11:01.241: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.1.50 30597\nConnection to 172.31.1.50 30597 port [tcp/*] succeeded!\n"
  Dec  2 13:11:01.241: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:11:01.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3427 exec execpod-affinityt57r2 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.74.39 30597'
  E1202 13:11:01.329186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:01.366: INFO: stderr: "+ nc -v -t -w 2 172.31.74.39 30597\n+ echo hostName\nConnection to 172.31.74.39 30597 port [tcp/*] succeeded!\n"
  Dec  2 13:11:01.366: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:11:01.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3427 exec execpod-affinityt57r2 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.1.50:30597/ ; done'
  Dec  2 13:11:01.526: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:30597/\n"
  Dec  2 13:11:01.526: INFO: stdout: "\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr\naffinity-nodeport-swxpr"
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Received response from host: affinity-nodeport-swxpr
  Dec  2 13:11:01.526: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:11:01.531: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport in namespace services-3427, will wait for the garbage collector to delete the pods @ 12/02/23 13:11:01.545
  Dec  2 13:11:01.606: INFO: Deleting ReplicationController affinity-nodeport took: 6.525356ms
  Dec  2 13:11:01.707: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.414751ms
  E1202 13:11:02.329691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:03.330753      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:04.331683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-3427" for this suite. @ 12/02/23 13:11:04.53
• [9.786 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]
test/e2e/network/service.go:1455
  STEP: Creating a kubernetes client @ 12/02/23 13:11:04.539
  Dec  2 13:11:04.539: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:11:04.54
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:11:04.573
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:11:04.576
  STEP: creating a service externalname-service with the type=ExternalName in namespace services-3434 @ 12/02/23 13:11:04.578
  STEP: changing the ExternalName service to type=NodePort @ 12/02/23 13:11:04.583
  STEP: creating replication controller externalname-service in namespace services-3434 @ 12/02/23 13:11:04.602
  I1202 13:11:04.608902      18 runners.go:197] Created replication controller with name: externalname-service, namespace: services-3434, replica count: 2
  E1202 13:11:05.332443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:06.332480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:07.332674      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:11:07.660283      18 runners.go:197] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 13:11:07.660: INFO: Creating new exec pod
  E1202 13:11:08.332773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:09.332937      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:10.333731      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:10.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3434 exec execpodwxs2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
  Dec  2 13:11:10.811: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
  Dec  2 13:11:10.811: INFO: stdout: "externalname-service-42wcl"
  Dec  2 13:11:10.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3434 exec execpodwxs2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.156 80'
  Dec  2 13:11:10.928: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.156 80\nConnection to 10.152.183.156 80 port [tcp/http] succeeded!\n"
  Dec  2 13:11:10.928: INFO: stdout: ""
  E1202 13:11:11.334741      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:11.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3434 exec execpodwxs2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.156 80'
  Dec  2 13:11:12.057: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.156 80\nConnection to 10.152.183.156 80 port [tcp/http] succeeded!\n"
  Dec  2 13:11:12.057: INFO: stdout: ""
  E1202 13:11:12.335305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:12.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3434 exec execpodwxs2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.156 80'
  Dec  2 13:11:13.062: INFO: stderr: "+ nc -v -t -w 2 10.152.183.156 80\n+ echo hostName\nConnection to 10.152.183.156 80 port [tcp/http] succeeded!\n"
  Dec  2 13:11:13.062: INFO: stdout: "externalname-service-znkwn"
  Dec  2 13:11:13.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3434 exec execpodwxs2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.74.39 31431'
  Dec  2 13:11:13.190: INFO: stderr: "+ nc -v -t -w 2 172.31.74.39 31431\n+ echo hostName\nConnection to 172.31.74.39 31431 port [tcp/*] succeeded!\n"
  Dec  2 13:11:13.190: INFO: stdout: "externalname-service-42wcl"
  Dec  2 13:11:13.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-3434 exec execpodwxs2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.1.50 31431'
  Dec  2 13:11:13.330: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.1.50 31431\nConnection to 172.31.1.50 31431 port [tcp/*] succeeded!\n"
  Dec  2 13:11:13.330: INFO: stdout: "externalname-service-znkwn"
  Dec  2 13:11:13.330: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:11:13.334: INFO: Cleaning up the ExternalName to NodePort test service
  E1202 13:11:13.336163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-3434" for this suite. @ 12/02/23 13:11:13.352
• [8.819 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]
test/e2e/apps/deployment.go:185
  STEP: Creating a kubernetes client @ 12/02/23 13:11:13.359
  Dec  2 13:11:13.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 13:11:13.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:11:13.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:11:13.385
  STEP: creating a Deployment @ 12/02/23 13:11:13.392
  STEP: waiting for Deployment to be created @ 12/02/23 13:11:13.396
  STEP: waiting for all Replicas to be Ready @ 12/02/23 13:11:13.397
  Dec  2 13:11:13.398: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  2 13:11:13.398: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  2 13:11:13.412: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  2 13:11:13.412: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  2 13:11:13.431: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  2 13:11:13.431: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  2 13:11:13.457: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  Dec  2 13:11:13.457: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0 and labels map[test-deployment-static:true]
  E1202 13:11:14.336586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:14.479: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec  2 13:11:14.479: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1 and labels map[test-deployment-static:true]
  Dec  2 13:11:15.010: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2 and labels map[test-deployment-static:true]
  STEP: patching the Deployment @ 12/02/23 13:11:15.01
  Dec  2 13:11:15.017: INFO: observed event type ADDED
  STEP: waiting for Replicas to scale @ 12/02/23 13:11:15.017
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 0
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.019: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.030: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.030: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.044: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.044: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:15.067: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:15.067: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:15.086: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:15.086: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  E1202 13:11:15.337517      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:16.020: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:16.020: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:16.054: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  STEP: listing Deployments @ 12/02/23 13:11:16.054
  Dec  2 13:11:16.058: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
  STEP: updating the Deployment @ 12/02/23 13:11:16.058
  Dec  2 13:11:16.070: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  STEP: fetching the DeploymentStatus @ 12/02/23 13:11:16.07
  Dec  2 13:11:16.076: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  2 13:11:16.082: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  2 13:11:16.124: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  2 13:11:16.150: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  2 13:11:16.158: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
  E1202 13:11:16.337947      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:17.025: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  2 13:11:17.067: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  Dec  2 13:11:17.075: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
  E1202 13:11:17.338561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:18.339288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:18.499: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
  STEP: patching the DeploymentStatus @ 12/02/23 13:11:18.525
  STEP: fetching the DeploymentStatus @ 12/02/23 13:11:18.533
  Dec  2 13:11:18.540: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:18.540: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:18.540: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:18.541: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:18.541: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 1
  Dec  2 13:11:18.541: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:18.541: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:18.541: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 2
  Dec  2 13:11:18.541: INFO: observed Deployment test-deployment in namespace deployment-3442 with ReadyReplicas 3
  STEP: deleting the Deployment @ 12/02/23 13:11:18.541
  Dec  2 13:11:18.549: INFO: observed event type MODIFIED
  Dec  2 13:11:18.549: INFO: observed event type MODIFIED
  Dec  2 13:11:18.549: INFO: observed event type MODIFIED
  Dec  2 13:11:18.549: INFO: observed event type MODIFIED
  Dec  2 13:11:18.549: INFO: observed event type MODIFIED
  Dec  2 13:11:18.549: INFO: observed event type MODIFIED
  Dec  2 13:11:18.550: INFO: observed event type MODIFIED
  Dec  2 13:11:18.550: INFO: observed event type MODIFIED
  Dec  2 13:11:18.550: INFO: observed event type MODIFIED
  Dec  2 13:11:18.550: INFO: observed event type MODIFIED
  Dec  2 13:11:18.550: INFO: observed event type MODIFIED
  Dec  2 13:11:18.550: INFO: observed event type MODIFIED
  Dec  2 13:11:18.552: INFO: Log out all the ReplicaSets if there is no deployment created
  Dec  2 13:11:18.557: INFO: ReplicaSet "test-deployment-64fd565c98":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-64fd565c98",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3442",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c79a266c-4314-4d81-93c4-e215880fb6d6",
      ResourceVersion: (string) (len=5) "26105",
      Generation: (int64) 4,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119475,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "28c0ff21-a0bb-4e68-a113-ee15f98fe708",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 32 38 63 30  66 66 32 31 2d 61 30 62  |":\"28c0ff21-a0b|
              00000130  62 2d 34 65 36 38 2d 61  31 31 33 2d 65 65 31 35  |b-4e68-a113-ee15|
              00000140  66 39 38 66 65 37 30 38  5c 22 7d 22 3a 7b 7d 7d  |f98fe708\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=25) "registry.k8s.io/pause:3.9",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(2),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 4,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Dec  2 13:11:18.561: INFO: pod: "test-deployment-64fd565c98-ntx8n":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-64fd565c98-ntx8n",
      GenerateName: (string) (len=27) "test-deployment-64fd565c98-",
      Namespace: (string) (len=15) "deployment-3442",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4485c649-048e-461d-bc2c-44ebdb9d1101",
      ResourceVersion: (string) (len=5) "26098",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119475,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119480,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(2),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "64fd565c98",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=26) "test-deployment-64fd565c98",
          UID: (types.UID) (len=36) "c79a266c-4314-4d81-93c4-e215880fb6d6",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119475,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  63 37 39 61 32 36 36 63  |uid\":\"c79a266c|
              000000a0  2d 34 33 31 34 2d 34 64  38 31 2d 39 33 63 34 2d  |-4314-4d81-93c4-|
              000000b0  65 32 31 35 38 38 30 66  62 36 64 36 5c 22 7d 22  |e215880fb6d6\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119475,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 33 30 2e 31 33 5c 22  |192.168.230.13\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-sc2jk",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-sc2jk",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(2),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119475,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119475,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119475,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119475,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.230.13",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.230.13"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119475,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837119475,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=25) "registry.k8s.io/pause:3.9",
          ImageID: (string) (len=93) "registry.k8s.io/pause@sha256:7031c1b283388d2c2e09b57badb803c05ebed362dc88d84b480cc47f72a21097",
          ContainerID: (string) (len=77) "containerd://68f97cee979f3e72f88e6f7bb4f3722e18464bb7d4d1a650cca4d1ad5413686a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Dec  2 13:11:18.570: INFO: ReplicaSet "test-deployment-69d58987ff":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=26) "test-deployment-69d58987ff",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3442",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1145006a-70df-491b-8bc3-95e2955dba66",
      ResourceVersion: (string) (len=5) "25995",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119473,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "69d58987ff",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1",
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "28c0ff21-a0bb-4e68-a113-ee15f98fe708",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 32 38 63 30  66 66 32 31 2d 61 30 62  |":\"28c0ff21-a0b|
              00000130  62 2d 34 65 36 38 2d 61  31 31 33 2d 65 65 31 35  |b-4e68-a113-ee15|
              00000140  66 39 38 66 65 37 30 38  5c 22 7d 22 3a 7b 7d 7d  |f98fe708\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=56) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  6f 62 73 65 72 76 65 64  47 65 6e 65 72 61 74 69  |observedGenerati|
              00000020  6f 6e 22 3a 7b 7d 2c 22  66 3a 72 65 70 6c 69 63  |on":{},"f:replic|
              00000030  61 73 22 3a 7b 7d 7d 7d                           |as":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(0),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=10) "69d58987ff",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=22) "test-deployment-static": (string) (len=4) "true",
            (string) (len=17) "pod-template-hash": (string) (len=10) "69d58987ff"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=44) "registry.k8s.io/e2e-test-images/agnhost:2.45",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 0,
      FullyLabeledReplicas: (int32) 0,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 3,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Dec  2 13:11:18.580: INFO: ReplicaSet "test-deployment-79ff746c4":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=25) "test-deployment-79ff746c4",
      GenerateName: (string) "",
      Namespace: (string) (len=15) "deployment-3442",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d5f0e497-c58e-4f4c-b936-f00ad433df37",
      ResourceVersion: (string) (len=5) "26091",
      Generation: (int64) 2,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "2",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "3",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "3"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=15) "test-deployment",
          UID: (types.UID) (len=36) "28c0ff21-a0bb-4e68-a113-ee15f98fe708",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=827) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              000000d0  65 2d 68 61 73 68 22 3a  7b 7d 2c 22 66 3a 74 65  |e-hash":{},"f:te|
              000000e0  73 74 2d 64 65 70 6c 6f  79 6d 65 6e 74 2d 73 74  |st-deployment-st|
              000000f0  61 74 69 63 22 3a 7b 7d  7d 2c 22 66 3a 6f 77 6e  |atic":{}},"f:own|
              00000100  65 72 52 65 66 65 72 65  6e 63 65 73 22 3a 7b 22  |erReferences":{"|
              00000110  2e 22 3a 7b 7d 2c 22 6b  3a 7b 5c 22 75 69 64 5c  |.":{},"k:{\"uid\|
              00000120  22 3a 5c 22 32 38 63 30  66 66 32 31 2d 61 30 62  |":\"28c0ff21-a0b|
              00000130  62 2d 34 65 36 38 2d 61  31 31 33 2d 65 65 31 35  |b-4e68-a113-ee15|
              00000140  66 39 38 66 65 37 30 38  5c 22 7d 22 3a 7b 7d 7d  |f98fe708\"}":{}}|
              00000150  7d 2c 22 66 3a 73 70 65  63 22 3a 7b 22 66 3a 72  |},"f:spec":{"f:r|
              00000160  65 70 6c 69 63 61 73 22  3a 7b 7d 2c 22 66 3a 73  |eplicas":{},"f:s|
              00000170  65 6c 65 63 74 6f 72 22  3a 7b 7d 2c 22 66 3a 74  |elector":{},"f:t|
              00000180  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000190  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              000001a0  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 70 6f  |s":{".":{},"f:po|
              000001b0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001c0  3a 7b 7d 2c 22 66 3a 74  65 73 74 2d 64 65 70 6c  |:{},"f:test-depl|
              000001d0  6f 79 6d 65 6e 74 2d 73  74 61 74 69 63 22 3a 7b  |oyment-static":{|
              000001e0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000001f0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000200  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 74 65 73  |:{\"name\":\"tes|
              00000210  74 2d 64 65 70 6c 6f 79  6d 65 6e 74 5c 22 7d 22  |t-deployment\"}"|
              00000220  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000230  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000240  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000250  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              00000260  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              00000270  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              00000280  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000290  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000002a0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000002b0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              000002c0  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              000002d0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000002e0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000002f0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000300  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000310  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000320  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000330  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(2),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
          (string) (len=22) "test-deployment-static": (string) (len=4) "true"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
            (string) (len=22) "test-deployment-static": (string) (len=4) "true"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=15) "test-deployment",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(1),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 2,
      FullyLabeledReplicas: (int32) 2,
      ReadyReplicas: (int32) 2,
      AvailableReplicas: (int32) 2,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }


  Dec  2 13:11:18.590: INFO: pod: "test-deployment-79ff746c4-fn5bl":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-79ff746c4-fn5bl",
      GenerateName: (string) (len=26) "test-deployment-79ff746c4-",
      Namespace: (string) (len=15) "deployment-3442",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "c0f99416-0ee9-4a90-a6da-67ef5a8ff32b",
      ResourceVersion: (string) (len=5) "26117",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119479,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(1),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-79ff746c4",
          UID: (types.UID) (len=36) "d5f0e497-c58e-4f4c-b936-f00ad433df37",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 35 66 30 65 34 39 37  |uid\":\"d5f0e497|
              000000a0  2d 63 35 38 65 2d 34 66  34 63 2d 62 39 33 36 2d  |-c58e-4f4c-b936-|
              000000b0  66 30 30 61 64 34 33 33  64 66 33 37 5c 22 7d 22  |f00ad433df37\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=520) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 33 30 2e 38 5c 22 7d  |192.168.230.8\"}|
              000001e0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 70 22  |":{".":{},"f:ip"|
              000001f0  3a 7b 7d 7d 7d 2c 22 66  3a 73 74 61 72 74 54 69  |:{}}},"f:startTi|
              00000200  6d 65 22 3a 7b 7d 7d 7d                           |me":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-q59cc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-q59cc",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119476,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=13) "192.168.230.8",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=13) "192.168.230.8"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119476,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837119476,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://934df4d8885ee28ec069d0a658c5ab2e0c664bba27aefd692cfc96242df1b3f5",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Dec  2 13:11:18.601: INFO: pod: "test-deployment-79ff746c4-tbh8k":
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "test-deployment-79ff746c4-tbh8k",
      GenerateName: (string) (len=26) "test-deployment-79ff746c4-",
      Namespace: (string) (len=15) "deployment-3442",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "ab250374-f90b-498a-b282-da90f13101e2",
      ResourceVersion: (string) (len=5) "26118",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119479,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      DeletionGracePeriodSeconds: (*int64)(1),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "79ff746c4",
        (string) (len=22) "test-deployment-static": (string) (len=4) "true"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=25) "test-deployment-79ff746c4",
          UID: (types.UID) (len=36) "d5f0e497-c58e-4f4c-b936-f00ad433df37",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=565) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 70 6f 64 2d 74 65 6d  |.":{},"f:pod-tem|
              00000040  70 6c 61 74 65 2d 68 61  73 68 22 3a 7b 7d 2c 22  |plate-hash":{},"|
              00000050  66 3a 74 65 73 74 2d 64  65 70 6c 6f 79 6d 65 6e  |f:test-deploymen|
              00000060  74 2d 73 74 61 74 69 63  22 3a 7b 7d 7d 2c 22 66  |t-static":{}},"f|
              00000070  3a 6f 77 6e 65 72 52 65  66 65 72 65 6e 63 65 73  |:ownerReferences|
              00000080  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 6b 3a 7b 5c 22  |":{".":{},"k:{\"|
              00000090  75 69 64 5c 22 3a 5c 22  64 35 66 30 65 34 39 37  |uid\":\"d5f0e497|
              000000a0  2d 63 35 38 65 2d 34 66  34 63 2d 62 39 33 36 2d  |-c58e-4f4c-b936-|
              000000b0  66 30 30 61 64 34 33 33  64 66 33 37 5c 22 7d 22  |f00ad433df37\"}"|
              000000c0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000000d0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000000e0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 74  |"k:{\"name\":\"t|
              000000f0  65 73 74 2d 64 65 70 6c  6f 79 6d 65 6e 74 5c 22  |est-deployment\"|
              00000100  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000110  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000120  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000130  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000140  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000150  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000160  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000170  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000180  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000190  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              000001a0  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000001b0  3a 7b 7d 2c 22 66 3a 65  6e 61 62 6c 65 53 65 72  |:{},"f:enableSer|
              000001c0  76 69 63 65 4c 69 6e 6b  73 22 3a 7b 7d 2c 22 66  |viceLinks":{},"f|
              000001d0  3a 72 65 73 74 61 72 74  50 6f 6c 69 63 79 22 3a  |:restartPolicy":|
              000001e0  7b 7d 2c 22 66 3a 73 63  68 65 64 75 6c 65 72 4e  |{},"f:schedulerN|
              000001f0  61 6d 65 22 3a 7b 7d 2c  22 66 3a 73 65 63 75 72  |ame":{},"f:secur|
              00000200  69 74 79 43 6f 6e 74 65  78 74 22 3a 7b 7d 2c 22  |ityContext":{},"|
              00000210  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 47 72 61  |f:terminationGra|
              00000220  63 65 50 65 72 69 6f 64  53 65 63 6f 6e 64 73 22  |cePeriodSeconds"|
              00000230  3a 7b 7d 7d 7d                                    |:{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 31 2e 32 33 31 5c 22  |192.168.21.231\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-v5mkh",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=15) "test-deployment",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-v5mkh",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(1),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119478,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837119477,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.231",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.231"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837119477,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=15) "test-deployment",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837119477,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://0fa8fe4ae8db938ac6e6dd08de58c3475ceb4edc4d9b470f03a5547c3772b338",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }


  Dec  2 13:11:18.608: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-3442" for this suite. @ 12/02/23 13:11:18.613
• [5.260 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:89
  STEP: Creating a kubernetes client @ 12/02/23 13:11:18.62
  Dec  2 13:11:18.620: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename containers @ 12/02/23 13:11:18.621
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:11:18.647
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:11:18.662
  STEP: Creating a pod to test override all @ 12/02/23 13:11:18.665
  E1202 13:11:19.339387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:20.339477      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:21.339529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:22.339627      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:11:22.687
  Dec  2 13:11:22.690: INFO: Trying to get logs from node ip-172-31-1-50 pod client-containers-f62eb2c7-ba21-4bc9-b69e-00fe2d14f2c5 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 13:11:22.696
  Dec  2 13:11:22.713: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-1113" for this suite. @ 12/02/23 13:11:22.716
• [4.102 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]
test/e2e/apimachinery/webhook.go:285
  STEP: Creating a kubernetes client @ 12/02/23 13:11:22.723
  Dec  2 13:11:22.723: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:11:22.723
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:11:22.739
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:11:22.741
  STEP: Setting up server cert @ 12/02/23 13:11:22.764
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:11:22.912
  STEP: Deploying the webhook pod @ 12/02/23 13:11:22.92
  STEP: Wait for the deployment to be ready @ 12/02/23 13:11:22.931
  Dec  2 13:11:22.939: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:11:23.339695      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:24.339809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:11:24.949
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:11:24.964
  E1202 13:11:25.340115      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:25.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  2 13:11:25.971: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:11:26.340962      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9872-crds.webhook.example.com via the AdmissionRegistration API @ 12/02/23 13:11:26.479
  STEP: Creating a custom resource that should be mutated by the webhook @ 12/02/23 13:11:26.492
  E1202 13:11:27.341089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:28.341172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:11:28.516: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-9769" for this suite. @ 12/02/23 13:11:29.082
  STEP: Destroying namespace "webhook-markers-809" for this suite. @ 12/02/23 13:11:29.093
• [6.381 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
test/e2e/auth/service_accounts.go:529
  STEP: Creating a kubernetes client @ 12/02/23 13:11:29.105
  Dec  2 13:11:29.105: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svcaccounts @ 12/02/23 13:11:29.106
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:11:29.134
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:11:29.138
  Dec  2 13:11:29.161: INFO: created pod
  E1202 13:11:29.341486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:30.341669      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:31.342155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:32.342243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:11:33.174
  E1202 13:11:33.342684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:34.343302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:35.343385      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:36.344314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:37.344465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:38.344635      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:39.344726      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:40.345359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:41.346066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:42.346914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:43.347294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:44.347448      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:45.347545      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:46.347916      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:47.348965      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:48.349051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:49.349324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:50.349415      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:51.350208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:52.350294      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:53.351287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:54.351459      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:55.351518      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:56.351609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:57.351763      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:58.352005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:11:59.352166      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:00.353047      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:01.353350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:02.354210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:12:03.174: INFO: polling logs
  Dec  2 13:12:03.182: INFO: Pod logs: 
  I1202 13:11:29.833341       1 log.go:194] OK: Got token
  I1202 13:11:29.833488       1 log.go:194] validating with in-cluster discovery
  I1202 13:11:29.833794       1 log.go:194] OK: got issuer https://kubernetes.default.svc
  I1202 13:11:29.833820       1 log.go:194] Full, not-validated claims: 
  openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7458:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0004c06b0), NotBefore:(*jwt.NumericDate)(0xc0004c0798), IssuedAt:(*jwt.NumericDate)(0xc0004c06c0), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7458", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ca4072cb-e836-4a66-aff1-aa24a54b9a94"}}}
  I1202 13:11:29.842385       1 log.go:194] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
  I1202 13:11:29.847983       1 log.go:194] OK: Validated signature on JWT
  I1202 13:11:29.848074       1 log.go:194] OK: Got valid claims from token!
  I1202 13:11:29.848114       1 log.go:194] Full, validated claims: 
  &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-7458:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:(*jwt.NumericDate)(0xc0001758f8), NotBefore:(*jwt.NumericDate)(0xc000175920), IssuedAt:(*jwt.NumericDate)(0xc000175900), ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-7458", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"ca4072cb-e836-4a66-aff1-aa24a54b9a94"}}}

  Dec  2 13:12:03.182: INFO: completed pod
  Dec  2 13:12:03.189: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7458" for this suite. @ 12/02/23 13:12:03.193
• [34.094 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]
test/e2e/apps/statefulset.go:792
  STEP: Creating a kubernetes client @ 12/02/23 13:12:03.2
  Dec  2 13:12:03.200: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 13:12:03.201
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:03.221
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:03.224
  STEP: Creating service test in namespace statefulset-7983 @ 12/02/23 13:12:03.228
  STEP: Looking for a node to schedule stateful set and pod @ 12/02/23 13:12:03.235
  STEP: Creating pod with conflicting port in namespace statefulset-7983 @ 12/02/23 13:12:03.242
  STEP: Waiting until pod test-pod will start running in namespace statefulset-7983 @ 12/02/23 13:12:03.255
  E1202 13:12:03.354478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:04.354558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating statefulset with conflicting port in namespace statefulset-7983 @ 12/02/23 13:12:05.265
  STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7983 @ 12/02/23 13:12:05.27
  Dec  2 13:12:05.284: INFO: Observed stateful pod in namespace: statefulset-7983, name: ss-0, uid: c8f76880-589c-4c18-be83-276cf51e40ff, status phase: Pending. Waiting for statefulset controller to delete.
  Dec  2 13:12:05.302: INFO: Observed stateful pod in namespace: statefulset-7983, name: ss-0, uid: c8f76880-589c-4c18-be83-276cf51e40ff, status phase: Failed. Waiting for statefulset controller to delete.
  Dec  2 13:12:05.325: INFO: Observed stateful pod in namespace: statefulset-7983, name: ss-0, uid: c8f76880-589c-4c18-be83-276cf51e40ff, status phase: Failed. Waiting for statefulset controller to delete.
  Dec  2 13:12:05.328: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7983
  STEP: Removing pod with conflicting port in namespace statefulset-7983 @ 12/02/23 13:12:05.328
  E1202 13:12:05.355102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7983 and will be in running state @ 12/02/23 13:12:05.36
  E1202 13:12:06.355451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:07.355484      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:12:07.369: INFO: Deleting all statefulset in ns statefulset-7983
  Dec  2 13:12:07.372: INFO: Scaling statefulset ss to 0
  E1202 13:12:08.355569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:09.355792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:10.355880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:11.355960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:12.356048      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:13.356310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:14.357298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:15.357479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:16.357551      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:17.357710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:12:17.390: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 13:12:17.394: INFO: Deleting statefulset ss
  Dec  2 13:12:17.410: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-7983" for this suite. @ 12/02/23 13:12:17.414
• [14.221 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:89
  STEP: Creating a kubernetes client @ 12/02/23 13:12:17.421
  Dec  2 13:12:17.421: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:12:17.422
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:17.438
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:17.441
  STEP: Creating configMap with name projected-configmap-test-volume-map-9957d4c0-661f-4885-9610-979ac20780ed @ 12/02/23 13:12:17.444
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:12:17.448
  E1202 13:12:18.357817      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:19.357907      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:20.358236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:21.359285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:12:21.471
  Dec  2 13:12:21.474: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-configmaps-3ff3904f-4e6e-4572-a01d-550b1058cd47 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 13:12:21.481
  Dec  2 13:12:21.499: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-3441" for this suite. @ 12/02/23 13:12:21.503
• [4.090 seconds]
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:222
  STEP: Creating a kubernetes client @ 12/02/23 13:12:21.511
  Dec  2 13:12:21.511: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:12:21.512
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:21.523
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:21.525
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:12:21.528
  E1202 13:12:22.359384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:23.359488      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:24.359576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:25.359960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:12:25.545
  Dec  2 13:12:25.547: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-5c24c381-0844-4ea1-b89b-36e29144caac container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:12:25.554
  Dec  2 13:12:25.570: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6537" for this suite. @ 12/02/23 13:12:25.574
• [4.069 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:84
  STEP: Creating a kubernetes client @ 12/02/23 13:12:25.581
  Dec  2 13:12:25.582: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pod-network-test @ 12/02/23 13:12:25.582
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:25.599
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:25.602
  STEP: Performing setup for networking test in namespace pod-network-test-783 @ 12/02/23 13:12:25.604
  STEP: creating a selector @ 12/02/23 13:12:25.604
  STEP: Creating the service pods in kubernetes @ 12/02/23 13:12:25.604
  Dec  2 13:12:25.604: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1202 13:12:26.360924      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:27.361290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:28.361140      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:29.361197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:30.361530      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:31.361623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:32.361883      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:33.362330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:34.362421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:35.363284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:36.363916      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:37.364504      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:38.365577      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:39.365676      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:40.366070      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:41.366223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:42.367278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:43.367427      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:44.368083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:45.368172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:46.368991      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:47.369844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/02/23 13:12:47.695
  E1202 13:12:48.370239      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:49.370336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:12:49.711: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  2 13:12:49.711: INFO: Breadth first check of 192.168.21.221 on host 172.31.1.50...
  Dec  2 13:12:49.714: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.21.227:9080/dial?request=hostname&protocol=http&host=192.168.21.221&port=8083&tries=1'] Namespace:pod-network-test-783 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:12:49.714: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:12:49.715: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:12:49.715: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-783/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.21.227%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.21.221%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  2 13:12:49.774: INFO: Waiting for responses: map[]
  Dec  2 13:12:49.774: INFO: reached 192.168.21.221 after 0/1 tries
  Dec  2 13:12:49.774: INFO: Breadth first check of 192.168.230.36 on host 172.31.74.39...
  Dec  2 13:12:49.778: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.21.227:9080/dial?request=hostname&protocol=http&host=192.168.230.36&port=8083&tries=1'] Namespace:pod-network-test-783 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:12:49.778: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:12:49.779: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:12:49.779: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-783/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.21.227%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.230.36%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  2 13:12:49.846: INFO: Waiting for responses: map[]
  Dec  2 13:12:49.846: INFO: reached 192.168.230.36 after 0/1 tries
  Dec  2 13:12:49.846: INFO: Breadth first check of 192.168.95.161 on host 172.31.89.192...
  Dec  2 13:12:49.849: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.21.227:9080/dial?request=hostname&protocol=http&host=192.168.95.161&port=8083&tries=1'] Namespace:pod-network-test-783 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:12:49.849: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:12:49.850: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:12:49.850: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-783/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.21.227%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.95.161%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  2 13:12:49.918: INFO: Waiting for responses: map[]
  Dec  2 13:12:49.918: INFO: reached 192.168.95.161 after 0/1 tries
  Dec  2 13:12:49.918: INFO: Going to retry 0 out of 3 pods....
  Dec  2 13:12:49.918: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-783" for this suite. @ 12/02/23 13:12:49.922
• [24.347 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]
test/e2e/scheduling/limit_range.go:239
  STEP: Creating a kubernetes client @ 12/02/23 13:12:49.929
  Dec  2 13:12:49.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename limitrange @ 12/02/23 13:12:49.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:49.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:49.949
  STEP: Creating LimitRange "e2e-limitrange-8b7lt" in namespace "limitrange-7588" @ 12/02/23 13:12:49.951
  STEP: Creating another limitRange in another namespace @ 12/02/23 13:12:49.955
  Dec  2 13:12:49.969: INFO: Namespace "e2e-limitrange-8b7lt-5097" created
  Dec  2 13:12:49.969: INFO: Creating LimitRange "e2e-limitrange-8b7lt" in namespace "e2e-limitrange-8b7lt-5097"
  STEP: Listing all LimitRanges with label "e2e-test=e2e-limitrange-8b7lt" @ 12/02/23 13:12:49.973
  Dec  2 13:12:49.977: INFO: Found 2 limitRanges
  STEP: Patching LimitRange "e2e-limitrange-8b7lt" in "limitrange-7588" namespace @ 12/02/23 13:12:49.977
  Dec  2 13:12:49.982: INFO: LimitRange "e2e-limitrange-8b7lt" has been patched
  STEP: Delete LimitRange "e2e-limitrange-8b7lt" by Collection with labelSelector: "e2e-limitrange-8b7lt=patched" @ 12/02/23 13:12:49.982
  STEP: Confirm that the limitRange "e2e-limitrange-8b7lt" has been deleted @ 12/02/23 13:12:49.99
  Dec  2 13:12:49.990: INFO: Requesting list of LimitRange to confirm quantity
  Dec  2 13:12:49.992: INFO: Found 0 LimitRange with label "e2e-limitrange-8b7lt=patched"
  Dec  2 13:12:49.992: INFO: LimitRange "e2e-limitrange-8b7lt" has been deleted.
  STEP: Confirm that a single LimitRange still exists with label "e2e-test=e2e-limitrange-8b7lt" @ 12/02/23 13:12:49.992
  Dec  2 13:12:49.996: INFO: Found 1 limitRange
  Dec  2 13:12:49.996: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-7588" for this suite. @ 12/02/23 13:12:49.999
  STEP: Destroying namespace "e2e-limitrange-8b7lt-5097" for this suite. @ 12/02/23 13:12:50.005
• [0.081 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]
test/e2e/kubectl/kubectl.go:396
  STEP: Creating a kubernetes client @ 12/02/23 13:12:50.011
  Dec  2 13:12:50.011: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:12:50.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:50.029
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:50.031
  STEP: creating all guestbook components @ 12/02/23 13:12:50.034
  Dec  2 13:12:50.034: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-replica
    labels:
      app: agnhost
      role: replica
      tier: backend
  spec:
    ports:
    - port: 6379
    selector:
      app: agnhost
      role: replica
      tier: backend

  Dec  2 13:12:50.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 create -f -'
  E1202 13:12:50.371318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:12:50.386: INFO: stderr: ""
  Dec  2 13:12:50.386: INFO: stdout: "service/agnhost-replica created\n"
  Dec  2 13:12:50.386: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: agnhost-primary
    labels:
      app: agnhost
      role: primary
      tier: backend
  spec:
    ports:
    - port: 6379
      targetPort: 6379
    selector:
      app: agnhost
      role: primary
      tier: backend

  Dec  2 13:12:50.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 create -f -'
  Dec  2 13:12:50.552: INFO: stderr: ""
  Dec  2 13:12:50.552: INFO: stdout: "service/agnhost-primary created\n"
  Dec  2 13:12:50.552: INFO: apiVersion: v1
  kind: Service
  metadata:
    name: frontend
    labels:
      app: guestbook
      tier: frontend
  spec:
    # if your cluster supports it, uncomment the following to automatically create
    # an external load-balanced IP for the frontend service.
    # type: LoadBalancer
    ports:
    - port: 80
    selector:
      app: guestbook
      tier: frontend

  Dec  2 13:12:50.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 create -f -'
  Dec  2 13:12:50.710: INFO: stderr: ""
  Dec  2 13:12:50.710: INFO: stdout: "service/frontend created\n"
  Dec  2 13:12:50.710: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: frontend
  spec:
    replicas: 3
    selector:
      matchLabels:
        app: guestbook
        tier: frontend
    template:
      metadata:
        labels:
          app: guestbook
          tier: frontend
      spec:
        containers:
        - name: guestbook-frontend
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--backend-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 80

  Dec  2 13:12:50.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 create -f -'
  Dec  2 13:12:50.839: INFO: stderr: ""
  Dec  2 13:12:50.839: INFO: stdout: "deployment.apps/frontend created\n"
  Dec  2 13:12:50.839: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-primary
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: agnhost
        role: primary
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: primary
          tier: backend
      spec:
        containers:
        - name: primary
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec  2 13:12:50.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 create -f -'
  Dec  2 13:12:50.975: INFO: stderr: ""
  Dec  2 13:12:50.975: INFO: stdout: "deployment.apps/agnhost-primary created\n"
  Dec  2 13:12:50.975: INFO: apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: agnhost-replica
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: agnhost
        role: replica
        tier: backend
    template:
      metadata:
        labels:
          app: agnhost
          role: replica
          tier: backend
      spec:
        containers:
        - name: replica
          image: registry.k8s.io/e2e-test-images/agnhost:2.45
          args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          ports:
          - containerPort: 6379

  Dec  2 13:12:50.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 create -f -'
  Dec  2 13:12:51.104: INFO: stderr: ""
  Dec  2 13:12:51.104: INFO: stdout: "deployment.apps/agnhost-replica created\n"
  STEP: validating guestbook app @ 12/02/23 13:12:51.104
  Dec  2 13:12:51.104: INFO: Waiting for all frontend pods to be Running.
  E1202 13:12:51.372166      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:52.372542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:53.372643      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:54.372805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:55.374183      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:12:56.155: INFO: Waiting for frontend to serve content.
  Dec  2 13:12:56.164: INFO: Trying to add a new entry to the guestbook.
  Dec  2 13:12:56.179: INFO: Verifying that added entry can be retrieved.
  STEP: using delete to clean up resources @ 12/02/23 13:12:56.187
  Dec  2 13:12:56.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 delete --grace-period=0 --force -f -'
  Dec  2 13:12:56.258: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 13:12:56.258: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
  STEP: using delete to clean up resources @ 12/02/23 13:12:56.258
  Dec  2 13:12:56.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 delete --grace-period=0 --force -f -'
  Dec  2 13:12:56.327: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 13:12:56.327: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/02/23 13:12:56.327
  Dec  2 13:12:56.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 delete --grace-period=0 --force -f -'
  E1202 13:12:56.374599      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:12:56.391: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 13:12:56.391: INFO: stdout: "service \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/02/23 13:12:56.391
  Dec  2 13:12:56.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 delete --grace-period=0 --force -f -'
  Dec  2 13:12:56.450: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 13:12:56.450: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
  STEP: using delete to clean up resources @ 12/02/23 13:12:56.45
  Dec  2 13:12:56.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 delete --grace-period=0 --force -f -'
  Dec  2 13:12:56.521: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 13:12:56.521: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
  STEP: using delete to clean up resources @ 12/02/23 13:12:56.521
  Dec  2 13:12:56.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7365 delete --grace-period=0 --force -f -'
  Dec  2 13:12:56.600: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 13:12:56.600: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
  Dec  2 13:12:56.600: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7365" for this suite. @ 12/02/23 13:12:56.604
• [6.601 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]
test/e2e/storage/csi_inline.go:50
  STEP: Creating a kubernetes client @ 12/02/23 13:12:56.612
  Dec  2 13:12:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename csiinlinevolumes @ 12/02/23 13:12:56.613
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:56.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:56.685
  STEP: creating @ 12/02/23 13:12:56.689
  STEP: getting @ 12/02/23 13:12:56.706
  STEP: listing in namespace @ 12/02/23 13:12:56.711
  STEP: patching @ 12/02/23 13:12:56.715
  STEP: deleting @ 12/02/23 13:12:56.729
  Dec  2 13:12:56.740: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "csiinlinevolumes-5249" for this suite. @ 12/02/23 13:12:56.744
• [0.138 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:89
  STEP: Creating a kubernetes client @ 12/02/23 13:12:56.75
  Dec  2 13:12:56.750: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:12:56.751
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:12:56.773
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:12:56.777
  STEP: Creating secret with name secret-test-map-5c0e2707-6526-4551-8300-f244274fcbc2 @ 12/02/23 13:12:56.78
  STEP: Creating a pod to test consume secrets @ 12/02/23 13:12:56.784
  E1202 13:12:57.374773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:58.374854      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:12:59.375182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:00.375264      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:13:00.807
  Dec  2 13:13:00.811: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-secrets-0e53d3df-df01-4df8-b169-fead13b5381f container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 13:13:00.822
  Dec  2 13:13:00.839: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-1300" for this suite. @ 12/02/23 13:13:00.843
• [4.099 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]
test/e2e/common/node/kubelet.go:135
  STEP: Creating a kubernetes client @ 12/02/23 13:13:00.85
  Dec  2 13:13:00.850: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubelet-test @ 12/02/23 13:13:00.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:00.867
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:00.87
  Dec  2 13:13:00.897: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubelet-test-3033" for this suite. @ 12/02/23 13:13:00.901
• [0.059 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
test/e2e/common/storage/projected_combined.go:44
  STEP: Creating a kubernetes client @ 12/02/23 13:13:00.909
  Dec  2 13:13:00.909: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:13:00.91
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:00.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:00.928
  STEP: Creating configMap with name configmap-projected-all-test-volume-42751c5f-572f-4d4c-985c-d0b1e9e1e6ad @ 12/02/23 13:13:00.93
  STEP: Creating secret with name secret-projected-all-test-volume-d76ea822-6ad9-4853-8b87-e7c1662e77bb @ 12/02/23 13:13:00.935
  STEP: Creating a pod to test Check all projections for projected volume plugin @ 12/02/23 13:13:00.939
  E1202 13:13:01.375356      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:02.375433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:13:02.958
  Dec  2 13:13:02.961: INFO: Trying to get logs from node ip-172-31-1-50 pod projected-volume-5b7fd358-20ca-480c-87bb-5311e586b44c container projected-all-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 13:13:02.967
  Dec  2 13:13:02.983: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9313" for this suite. @ 12/02/23 13:13:02.987
• [2.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:76
  STEP: Creating a kubernetes client @ 12/02/23 13:13:02.994
  Dec  2 13:13:02.995: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 13:13:02.995
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:03.008
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:03.011
  STEP: Creating a pod to test substitution in container's command @ 12/02/23 13:13:03.013
  E1202 13:13:03.376425      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:04.376611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:05.377049      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:06.377655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:13:07.036
  Dec  2 13:13:07.041: INFO: Trying to get logs from node ip-172-31-1-50 pod var-expansion-5037e070-46fb-4cf7-8a98-cf9f2816c6a5 container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 13:13:07.048
  Dec  2 13:13:07.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-4804" for this suite. @ 12/02/23 13:13:07.069
• [4.082 seconds]
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:197
  STEP: Creating a kubernetes client @ 12/02/23 13:13:07.077
  Dec  2 13:13:07.077: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:13:07.078
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:07.093
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:07.096
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/02/23 13:13:07.098
  E1202 13:13:07.378220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:08.378248      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:09.378298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:10.379302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:13:11.119
  Dec  2 13:13:11.122: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-46fda550-25af-4665-8068-067ff12f59bc container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:13:11.128
  Dec  2 13:13:11.145: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-9641" for this suite. @ 12/02/23 13:13:11.148
• [4.076 seconds]
------------------------------
SSSS
------------------------------
[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
test/e2e/network/hostport.go:63
  STEP: Creating a kubernetes client @ 12/02/23 13:13:11.154
  Dec  2 13:13:11.154: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename hostport @ 12/02/23 13:13:11.154
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:11.187
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:11.19
  STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled @ 12/02/23 13:13:11.196
  E1202 13:13:11.379929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:12.380006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.89.192 on the node which pod1 resides and expect scheduled @ 12/02/23 13:13:13.212
  E1202 13:13:13.380255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:14.380356      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:15.381317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:16.381405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:17.381949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:18.382026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:19.382610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:20.383200      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:21.383287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:22.383444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:23.383526      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:24.383785      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.89.192 but use UDP protocol on the node which pod2 resides @ 12/02/23 13:13:25.244
  E1202 13:13:25.384328      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:26.384439      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:27.384949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:28.385045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 @ 12/02/23 13:13:29.273
  Dec  2 13:13:29.273: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.89.192 http://127.0.0.1:54323/hostname] Namespace:hostport-7463 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:13:29.273: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:13:29.274: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:13:29.274: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-7463/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.89.192+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.89.192, port: 54323 @ 12/02/23 13:13:29.357
  Dec  2 13:13:29.357: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.89.192:54323/hostname] Namespace:hostport-7463 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:13:29.357: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:13:29.358: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:13:29.358: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-7463/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.89.192%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E1202 13:13:29.385619      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.89.192, port: 54323 UDP @ 12/02/23 13:13:29.428
  Dec  2 13:13:29.428: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.89.192 54323] Namespace:hostport-7463 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:13:29.428: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:13:29.429: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:13:29.429: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-7463/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.89.192+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
  E1202 13:13:30.386223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:31.387293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:32.387490      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:33.387585      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:34.387661      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:13:34.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "hostport-7463" for this suite. @ 12/02/23 13:13:34.508
• [23.361 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:129
  STEP: Creating a kubernetes client @ 12/02/23 13:13:34.516
  Dec  2 13:13:34.516: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename runtimeclass @ 12/02/23 13:13:34.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:34.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:34.538
  E1202 13:13:35.388375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:36.388750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:13:36.559: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4241" for this suite. @ 12/02/23 13:13:36.569
• [2.062 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]
test/e2e/kubectl/kubectl.go:1641
  STEP: Creating a kubernetes client @ 12/02/23 13:13:36.578
  Dec  2 13:13:36.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:13:36.579
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:36.595
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:36.598
  STEP: creating Agnhost RC @ 12/02/23 13:13:36.6
  Dec  2 13:13:36.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7862 create -f -'
  Dec  2 13:13:36.765: INFO: stderr: ""
  Dec  2 13:13:36.765: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/02/23 13:13:36.765
  E1202 13:13:37.389579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:13:37.769: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:13:37.769: INFO: Found 0 / 1
  E1202 13:13:38.390559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:13:38.770: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:13:38.770: INFO: Found 1 / 1
  Dec  2 13:13:38.770: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  STEP: patching all pods @ 12/02/23 13:13:38.77
  Dec  2 13:13:38.773: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:13:38.773: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  2 13:13:38.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7862 patch pod agnhost-primary-z7msn -p {"metadata":{"annotations":{"x":"y"}}}'
  Dec  2 13:13:38.829: INFO: stderr: ""
  Dec  2 13:13:38.829: INFO: stdout: "pod/agnhost-primary-z7msn patched\n"
  STEP: checking annotations @ 12/02/23 13:13:38.829
  Dec  2 13:13:38.834: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:13:38.834: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  2 13:13:38.834: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7862" for this suite. @ 12/02/23 13:13:38.837
• [2.266 seconds]
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:95
  STEP: Creating a kubernetes client @ 12/02/23 13:13:38.844
  Dec  2 13:13:38.844: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pod-network-test @ 12/02/23 13:13:38.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:38.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:38.861
  STEP: Performing setup for networking test in namespace pod-network-test-4638 @ 12/02/23 13:13:38.864
  STEP: creating a selector @ 12/02/23 13:13:38.864
  STEP: Creating the service pods in kubernetes @ 12/02/23 13:13:38.864
  Dec  2 13:13:38.864: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1202 13:13:39.392041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:40.392197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:41.393286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:42.394350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:43.394466      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:44.395373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:45.395931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:46.396034      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:47.397035      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:48.397216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:49.397374      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:50.397552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/02/23 13:13:50.933
  E1202 13:13:51.397634      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:52.397803      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:13:52.947: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  2 13:13:52.947: INFO: Breadth first check of 192.168.21.220 on host 172.31.1.50...
  Dec  2 13:13:52.951: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.21.215:9080/dial?request=hostname&protocol=udp&host=192.168.21.220&port=8081&tries=1'] Namespace:pod-network-test-4638 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:13:52.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:13:52.952: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:13:52.952: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4638/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.21.215%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.21.220%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  2 13:13:53.021: INFO: Waiting for responses: map[]
  Dec  2 13:13:53.021: INFO: reached 192.168.21.220 after 0/1 tries
  Dec  2 13:13:53.021: INFO: Breadth first check of 192.168.230.20 on host 172.31.74.39...
  Dec  2 13:13:53.024: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.21.215:9080/dial?request=hostname&protocol=udp&host=192.168.230.20&port=8081&tries=1'] Namespace:pod-network-test-4638 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:13:53.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:13:53.025: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:13:53.025: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4638/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.21.215%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.230.20%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  2 13:13:53.097: INFO: Waiting for responses: map[]
  Dec  2 13:13:53.097: INFO: reached 192.168.230.20 after 0/1 tries
  Dec  2 13:13:53.097: INFO: Breadth first check of 192.168.95.175 on host 172.31.89.192...
  Dec  2 13:13:53.100: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.21.215:9080/dial?request=hostname&protocol=udp&host=192.168.95.175&port=8081&tries=1'] Namespace:pod-network-test-4638 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:13:53.101: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:13:53.101: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:13:53.101: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4638/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.21.215%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.95.175%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
  Dec  2 13:13:53.173: INFO: Waiting for responses: map[]
  Dec  2 13:13:53.173: INFO: reached 192.168.95.175 after 0/1 tries
  Dec  2 13:13:53.173: INFO: Going to retry 0 out of 3 pods....
  Dec  2 13:13:53.173: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-4638" for this suite. @ 12/02/23 13:13:53.177
• [14.339 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] PodTemplates should replace a pod template [Conformance]
test/e2e/common/node/podtemplates.go:176
  STEP: Creating a kubernetes client @ 12/02/23 13:13:53.184
  Dec  2 13:13:53.184: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename podtemplate @ 12/02/23 13:13:53.184
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:53.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:53.207
  STEP: Create a pod template @ 12/02/23 13:13:53.211
  STEP: Replace a pod template @ 12/02/23 13:13:53.218
  Dec  2 13:13:53.224: INFO: Found updated podtemplate annotation: "true"

  Dec  2 13:13:53.224: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "podtemplate-5167" for this suite. @ 12/02/23 13:13:53.227
• [0.049 seconds]
------------------------------
SS
------------------------------
[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:45
  STEP: Creating a kubernetes client @ 12/02/23 13:13:53.232
  Dec  2 13:13:53.232: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:13:53.233
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:53.249
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:53.254
  STEP: Creating a pod to test downward api env vars @ 12/02/23 13:13:53.256
  E1202 13:13:53.398849      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:54.398934      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:55.399676      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:56.400678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:13:57.277
  Dec  2 13:13:57.279: INFO: Trying to get logs from node ip-172-31-1-50 pod downward-api-385a2d20-81a5-4537-be6c-8c634caa1ca0 container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 13:13:57.287
  Dec  2 13:13:57.304: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-5990" for this suite. @ 12/02/23 13:13:57.307
• [4.080 seconds]
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]
test/e2e/scheduling/predicates.go:467
  STEP: Creating a kubernetes client @ 12/02/23 13:13:57.313
  Dec  2 13:13:57.313: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-pred @ 12/02/23 13:13:57.314
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:13:57.331
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:13:57.334
  Dec  2 13:13:57.338: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  2 13:13:57.347: INFO: Waiting for terminating namespaces to be deleted...
  Dec  2 13:13:57.352: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-1-50 before test
  Dec  2 13:13:57.360: INFO: nginx-ingress-controller-kubernetes-worker-bl8w7 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:04:04 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.360: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:13:57.360: INFO: calico-node-lzsm2 from kube-system started at 2023-12-02 12:03:38 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.360: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:13:57.360: INFO: netserver-0 from pod-network-test-4638 started at 2023-12-02 13:13:38 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.360: INFO: 	Container webserver ready: true, restart count 0
  Dec  2 13:13:57.360: INFO: test-container-pod from pod-network-test-4638 started at 2023-12-02 13:13:50 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.360: INFO: 	Container webserver ready: true, restart count 0
  Dec  2 13:13:57.360: INFO: sonobuoy from sonobuoy started at 2023-12-02 12:07:42 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.360: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  2 13:13:57.360: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-28gq4 from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:13:57.360: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:13:57.360: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 13:13:57.360: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-74-39 before test
  Dec  2 13:13:57.366: INFO: nginx-ingress-controller-kubernetes-worker-p5kqq from ingress-nginx-kubernetes-worker started at 2023-12-02 12:05:07 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.366: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:13:57.366: INFO: calico-node-jvhbz from kube-system started at 2023-12-02 12:04:51 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.366: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:13:57.367: INFO: netserver-1 from pod-network-test-4638 started at 2023-12-02 13:13:38 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.367: INFO: 	Container webserver ready: true, restart count 0
  Dec  2 13:13:57.367: INFO: sonobuoy-e2e-job-e9309236a19947ce from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:13:57.367: INFO: 	Container e2e ready: true, restart count 0
  Dec  2 13:13:57.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:13:57.367: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-fz89t from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:13:57.367: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:13:57.367: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 13:13:57.367: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-89-192 before test
  Dec  2 13:13:57.373: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-5sm95 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: nginx-ingress-controller-kubernetes-worker-g5cfp from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: calico-node-ql9q7 from kube-system started at 2023-12-02 12:01:42 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: coredns-59cfb5bf46-4zw4x from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container coredns ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: kube-state-metrics-78c475f58b-9brf7 from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: metrics-server-v0.6.3-69d7fbfdf8-q6h8s from kube-system started at 2023-12-02 12:02:20 +0000 UTC (2 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: dashboard-metrics-scraper-5dd7cb5fc-srsz2 from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: kubernetes-dashboard-7b899cb9d9-vfzmg from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: netserver-2 from pod-network-test-4638 started at 2023-12-02 13:13:38 +0000 UTC (1 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container webserver ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-ldh7p from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:13:57.373: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:13:57.373: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/02/23 13:13:57.373
  E1202 13:13:57.400866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:58.401006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:13:59.401180      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/02/23 13:13:59.401
  STEP: Trying to apply a random label on the found node. @ 12/02/23 13:13:59.412
  STEP: verifying the node has the label kubernetes.io/e2e-4327b6cf-da7e-4ed9-adf9-4290f5671f1c 42 @ 12/02/23 13:13:59.42
  STEP: Trying to relaunch the pod, now with labels. @ 12/02/23 13:13:59.423
  E1202 13:14:00.401595      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:01.401785      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label kubernetes.io/e2e-4327b6cf-da7e-4ed9-adf9-4290f5671f1c off the node ip-172-31-1-50 @ 12/02/23 13:14:01.441
  STEP: verifying the node doesn't have the label kubernetes.io/e2e-4327b6cf-da7e-4ed9-adf9-4290f5671f1c @ 12/02/23 13:14:01.451
  Dec  2 13:14:01.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-5515" for this suite. @ 12/02/23 13:14:01.458
• [4.152 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API should delete a collection of events [Conformance]
test/e2e/instrumentation/events.go:207
  STEP: Creating a kubernetes client @ 12/02/23 13:14:01.466
  Dec  2 13:14:01.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename events @ 12/02/23 13:14:01.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:01.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:01.484
  STEP: Create set of events @ 12/02/23 13:14:01.488
  STEP: get a list of Events with a label in the current namespace @ 12/02/23 13:14:01.506
  STEP: delete a list of events @ 12/02/23 13:14:01.51
  Dec  2 13:14:01.510: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/02/23 13:14:01.534
  Dec  2 13:14:01.536: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-943" for this suite. @ 12/02/23 13:14:01.539
• [0.080 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
test/e2e/network/service.go:2187
  STEP: Creating a kubernetes client @ 12/02/23 13:14:01.546
  Dec  2 13:14:01.546: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:14:01.547
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:01.562
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:01.564
  STEP: creating service in namespace services-5867 @ 12/02/23 13:14:01.566
  STEP: creating service affinity-clusterip-transition in namespace services-5867 @ 12/02/23 13:14:01.566
  STEP: creating replication controller affinity-clusterip-transition in namespace services-5867 @ 12/02/23 13:14:01.574
  I1202 13:14:01.582393      18 runners.go:197] Created replication controller with name: affinity-clusterip-transition, namespace: services-5867, replica count: 3
  E1202 13:14:02.402773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:03.402871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:04.403336      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:14:04.633757      18 runners.go:197] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 13:14:04.640: INFO: Creating new exec pod
  E1202 13:14:05.404223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:06.404346      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:07.405302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:07.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-5867 exec execpod-affinityk8mxk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
  Dec  2 13:14:07.782: INFO: stderr: "+ nc -v -t -w 2 affinity-clusterip-transition 80\n+ echo hostName\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
  Dec  2 13:14:07.782: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:14:07.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-5867 exec execpod-affinityk8mxk -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.126 80'
  Dec  2 13:14:07.889: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.126 80\nConnection to 10.152.183.126 80 port [tcp/http] succeeded!\n"
  Dec  2 13:14:07.889: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:14:07.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-5867 exec execpod-affinityk8mxk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.126:80/ ; done'
  Dec  2 13:14:08.080: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n"
  Dec  2 13:14:08.080: INFO: stdout: "\naffinity-clusterip-transition-79bx4\naffinity-clusterip-transition-79bx4\naffinity-clusterip-transition-79bx4\naffinity-clusterip-transition-pkv4x\naffinity-clusterip-transition-79bx4\naffinity-clusterip-transition-pkv4x\naffinity-clusterip-transition-pkv4x\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-pkv4x\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-79bx4\naffinity-clusterip-transition-79bx4\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-79bx4"
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-79bx4
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-79bx4
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-79bx4
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-pkv4x
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-79bx4
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-pkv4x
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-pkv4x
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-pkv4x
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-79bx4
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-79bx4
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.080: INFO: Received response from host: affinity-clusterip-transition-79bx4
  Dec  2 13:14:08.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-5867 exec execpod-affinityk8mxk -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.126:80/ ; done'
  Dec  2 13:14:08.262: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.126:80/\n"
  Dec  2 13:14:08.262: INFO: stdout: "\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56\naffinity-clusterip-transition-zfh56"
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Received response from host: affinity-clusterip-transition-zfh56
  Dec  2 13:14:08.262: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:14:08.266: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-5867, will wait for the garbage collector to delete the pods @ 12/02/23 13:14:08.278
  Dec  2 13:14:08.339: INFO: Deleting ReplicationController affinity-clusterip-transition took: 7.25774ms
  E1202 13:14:08.405859      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:08.441: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.605316ms
  E1202 13:14:09.406555      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:10.406824      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:11.407512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-5867" for this suite. @ 12/02/23 13:14:11.46
• [9.920 seconds]
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:168
  STEP: Creating a kubernetes client @ 12/02/23 13:14:11.466
  Dec  2 13:14:11.466: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/02/23 13:14:11.467
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:11.482
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:11.485
  STEP: create the container to handle the HTTPGet hook request. @ 12/02/23 13:14:11.49
  E1202 13:14:12.407626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:13.407718      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/02/23 13:14:13.512
  E1202 13:14:14.407896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:15.408200      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 12/02/23 13:14:15.53
  STEP: delete the pod with lifecycle hook @ 12/02/23 13:14:15.537
  E1202 13:14:16.408289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:17.408373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:17.549: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-6521" for this suite. @ 12/02/23 13:14:17.552
• [6.094 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:268
  STEP: Creating a kubernetes client @ 12/02/23 13:14:17.567
  Dec  2 13:14:17.567: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:14:17.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:17.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:17.589
  STEP: Creating a pod to test downward api env vars @ 12/02/23 13:14:17.591
  E1202 13:14:18.408606      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:19.408890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:14:19.611
  Dec  2 13:14:19.615: INFO: Trying to get logs from node ip-172-31-74-39 pod downward-api-949802c6-0d5c-4f3c-9941-c761f9edec2d container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 13:14:19.632
  Dec  2 13:14:19.650: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-186" for this suite. @ 12/02/23 13:14:19.654
• [2.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]
test/e2e/apimachinery/webhook.go:403
  STEP: Creating a kubernetes client @ 12/02/23 13:14:19.662
  Dec  2 13:14:19.662: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:14:19.663
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:19.679
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:19.681
  STEP: Setting up server cert @ 12/02/23 13:14:19.707
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:14:19.881
  STEP: Deploying the webhook pod @ 12/02/23 13:14:19.888
  STEP: Wait for the deployment to be ready @ 12/02/23 13:14:19.899
  Dec  2 13:14:19.905: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1202 13:14:20.410252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:21.410351      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:14:21.917
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:14:21.927
  E1202 13:14:22.410431      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:22.927: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Creating a validating webhook configuration @ 12/02/23 13:14:22.933
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/02/23 13:14:22.947
  STEP: Updating a validating webhook configuration's rules to not include the create operation @ 12/02/23 13:14:22.954
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/02/23 13:14:22.963
  STEP: Patching a validating webhook configuration's rules to include the create operation @ 12/02/23 13:14:22.992
  STEP: Creating a configMap that does not comply to the validation webhook rules @ 12/02/23 13:14:23.001
  Dec  2 13:14:23.009: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-7923" for this suite. @ 12/02/23 13:14:23.068
  STEP: Destroying namespace "webhook-markers-5011" for this suite. @ 12/02/23 13:14:23.078
• [3.421 seconds]
------------------------------
[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]
test/e2e/kubectl/kubectl.go:1342
  STEP: Creating a kubernetes client @ 12/02/23 13:14:23.083
  Dec  2 13:14:23.083: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:14:23.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:23.1
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:23.103
  Dec  2 13:14:23.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-2965 create -f -'
  Dec  2 13:14:23.291: INFO: stderr: ""
  Dec  2 13:14:23.291: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  Dec  2 13:14:23.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-2965 create -f -'
  E1202 13:14:23.410944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:23.463: INFO: stderr: ""
  Dec  2 13:14:23.463: INFO: stdout: "service/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/02/23 13:14:23.463
  E1202 13:14:24.410984      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:24.467: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:14:24.467: INFO: Found 0 / 1
  E1202 13:14:25.411992      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:25.467: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:14:25.467: INFO: Found 1 / 1
  Dec  2 13:14:25.467: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec  2 13:14:25.471: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:14:25.471: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  2 13:14:25.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-2965 describe pod agnhost-primary-wsv2z'
  Dec  2 13:14:25.528: INFO: stderr: ""
  Dec  2 13:14:25.528: INFO: stdout: "Name:             agnhost-primary-wsv2z\nNamespace:        kubectl-2965\nPriority:         0\nService Account:  default\nNode:             ip-172-31-1-50/172.31.1.50\nStart Time:       Sat, 02 Dec 2023 13:14:23 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.21.219\nIPs:\n  IP:           192.168.21.219\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://1294a2c7ca25cd91840b26e64f642cb3b5e39faa4165240e5d7dafb38e42f8ae\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.45\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:2c5b5b056076334e4cf431d964d102e44cbca8f1e6b16ac1e477a0ffbe6caac4\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 02 Dec 2023 13:14:23 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-ljtbq (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-ljtbq:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2965/agnhost-primary-wsv2z to ip-172-31-1-50\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.45\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    2s    kubelet            Started container agnhost-primary\n"
  Dec  2 13:14:25.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-2965 describe rc agnhost-primary'
  Dec  2 13:14:25.589: INFO: stderr: ""
  Dec  2 13:14:25.589: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2965\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.45\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-wsv2z\n"
  Dec  2 13:14:25.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-2965 describe service agnhost-primary'
  Dec  2 13:14:25.647: INFO: stderr: ""
  Dec  2 13:14:25.647: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2965\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.237\nIPs:               10.152.183.237\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.21.219:6379\nSession Affinity:  None\nEvents:            <none>\n"
  Dec  2 13:14:25.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-2965 describe node ip-172-31-1-50'
  Dec  2 13:14:25.718: INFO: stderr: ""
  Dec  2 13:14:25.718: INFO: stdout: "Name:               ip-172-31-1-50\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-1-50\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 02 Dec 2023 12:03:23 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-1-50\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 02 Dec 2023 13:14:15 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sat, 02 Dec 2023 12:03:48 +0000   Sat, 02 Dec 2023 12:03:48 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sat, 02 Dec 2023 13:13:46 +0000   Sat, 02 Dec 2023 12:03:23 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sat, 02 Dec 2023 13:13:46 +0000   Sat, 02 Dec 2023 12:03:23 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sat, 02 Dec 2023 13:13:46 +0000   Sat, 02 Dec 2023 12:03:23 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sat, 02 Dec 2023 13:13:46 +0000   Sat, 02 Dec 2023 12:04:03 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.1.50\n  Hostname:    ip-172-31-1-50\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16094884Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             15992484Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      ec2c1012a12baf86a27cd09e887d0edb\n  System UUID:                     ec2c1012-a12b-af86-a27c-d09e887d0edb\n  Boot ID:                         19a47c01-b893-42c9-bb81-08a67bf9d851\n  Kernel Version:                  6.2.0-1016-aws\n  OS Image:                        Ubuntu 22.04.3 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.6.8\n  Kubelet Version:                 v1.28.4\n  Kube-Proxy Version:              v1.28.4\nNon-terminated Pods:               (5 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-bl8w7           0 (0%)        0 (0%)      0 (0%)           0 (0%)         70m\n  kube-system                      calico-node-lzsm2                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         71m\n  kubectl-2965                     agnhost-primary-wsv2z                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\n  sonobuoy                         sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         66m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-28gq4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         66m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
  Dec  2 13:14:25.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-2965 describe namespace kubectl-2965'
  Dec  2 13:14:25.773: INFO: stderr: ""
  Dec  2 13:14:25.773: INFO: stdout: "Name:         kubectl-2965\nLabels:       e2e-framework=kubectl\n              e2e-run=68aca84b-8ec8-41fd-9bbb-f6cca6ab0a52\n              kubernetes.io/metadata.name=kubectl-2965\n              pod-security.kubernetes.io/audit=baseline\n              pod-security.kubernetes.io/enforce=baseline\n              pod-security.kubernetes.io/warn=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
  Dec  2 13:14:25.773: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-2965" for this suite. @ 12/02/23 13:14:25.776
• [2.700 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
test/e2e/common/node/expansion.go:155
  STEP: Creating a kubernetes client @ 12/02/23 13:14:25.783
  Dec  2 13:14:25.783: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 13:14:25.784
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:25.801
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:25.803
  E1202 13:14:26.412924      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:27.413857      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:27.822: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:14:27.826: INFO: Deleting pod "var-expansion-7aa3717b-1485-4cc3-a9b1-351c2995ea9d" in namespace "var-expansion-3729"
  Dec  2 13:14:27.834: INFO: Wait up to 5m0s for pod "var-expansion-7aa3717b-1485-4cc3-a9b1-351c2995ea9d" to be fully deleted
  E1202 13:14:28.414335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:29.415290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "var-expansion-3729" for this suite. @ 12/02/23 13:14:29.843
• [4.066 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:97
  STEP: Creating a kubernetes client @ 12/02/23 13:14:29.849
  Dec  2 13:14:29.850: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:14:29.85
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:29.866
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:29.869
  STEP: Creating a pod to test emptydir 0644 on tmpfs @ 12/02/23 13:14:29.871
  E1202 13:14:30.415607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:31.415701      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:32.415790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:33.415971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:14:33.894
  Dec  2 13:14:33.897: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-7feeb826-67b0-4e59-b02d-d1857e9f6e9e container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:14:33.903
  Dec  2 13:14:33.918: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-8648" for this suite. @ 12/02/23 13:14:33.922
• [4.078 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]
test/e2e/apps/disruption.go:141
  STEP: Creating a kubernetes client @ 12/02/23 13:14:33.928
  Dec  2 13:14:33.928: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename disruption @ 12/02/23 13:14:33.928
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:33.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:33.948
  STEP: Waiting for the pdb to be processed @ 12/02/23 13:14:33.955
  E1202 13:14:34.416685      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:35.417087      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for all pods to be running @ 12/02/23 13:14:35.983
  Dec  2 13:14:35.988: INFO: running pods: 0 < 3
  E1202 13:14:36.417932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:37.418137      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:14:37.997: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-3857" for this suite. @ 12/02/23 13:14:38.002
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:99
  STEP: Creating a kubernetes client @ 12/02/23 13:14:38.012
  Dec  2 13:14:38.012: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 13:14:38.013
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:38.031
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:38.034
  STEP: Creating configMap with name configmap-test-volume-map-ea4f4eb4-5a4f-4f56-8ea4-1e1834a5a98d @ 12/02/23 13:14:38.038
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:14:38.042
  E1202 13:14:38.418981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:39.419306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:40.419558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:41.420330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:14:42.067
  Dec  2 13:14:42.070: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-configmaps-a2a5d001-ae08-4ddc-83a5-808d7ed3af3b container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 13:14:42.076
  Dec  2 13:14:42.091: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5779" for this suite. @ 12/02/23 13:14:42.094
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]
test/e2e/kubectl/kubectl.go:1781
  STEP: Creating a kubernetes client @ 12/02/23 13:14:42.1
  Dec  2 13:14:42.100: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:14:42.101
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:42.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:42.116
  STEP: starting the proxy server @ 12/02/23 13:14:42.119
  Dec  2 13:14:42.119: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7496 proxy -p 0 --disable-filter'
  STEP: curling proxy /api/ output @ 12/02/23 13:14:42.154
  Dec  2 13:14:42.161: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7496" for this suite. @ 12/02/23 13:14:42.166
• [0.073 seconds]
------------------------------
S
------------------------------
[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:68
  STEP: Creating a kubernetes client @ 12/02/23 13:14:42.173
  Dec  2 13:14:42.173: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:14:42.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:42.19
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:42.193
  STEP: Creating secret with name secret-test-0ba3df42-8c06-49aa-beb3-fe818b1467e1 @ 12/02/23 13:14:42.195
  STEP: Creating a pod to test consume secrets @ 12/02/23 13:14:42.2
  E1202 13:14:42.420428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:43.420556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:44.421364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:45.422361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:14:46.221
  Dec  2 13:14:46.224: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-secrets-2584c49d-133a-446e-8cbd-ec959b10516e container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 13:14:46.23
  Dec  2 13:14:46.247: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-2690" for this suite. @ 12/02/23 13:14:46.255
• [4.089 seconds]
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]
test/e2e/scheduling/predicates.go:332
  STEP: Creating a kubernetes client @ 12/02/23 13:14:46.262
  Dec  2 13:14:46.262: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-pred @ 12/02/23 13:14:46.263
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:46.28
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:46.283
  Dec  2 13:14:46.286: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
  Dec  2 13:14:46.294: INFO: Waiting for terminating namespaces to be deleted...
  Dec  2 13:14:46.297: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-1-50 before test
  Dec  2 13:14:46.304: INFO: nginx-ingress-controller-kubernetes-worker-bl8w7 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:04:04 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.304: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:14:46.304: INFO: calico-node-lzsm2 from kube-system started at 2023-12-02 12:03:38 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.304: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:14:46.304: INFO: sonobuoy from sonobuoy started at 2023-12-02 12:07:42 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.304: INFO: 	Container kube-sonobuoy ready: true, restart count 0
  Dec  2 13:14:46.304: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-28gq4 from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:14:46.304: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:14:46.304: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 13:14:46.304: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-74-39 before test
  Dec  2 13:14:46.310: INFO: nginx-ingress-controller-kubernetes-worker-p5kqq from ingress-nginx-kubernetes-worker started at 2023-12-02 12:05:07 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.310: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:14:46.310: INFO: calico-node-jvhbz from kube-system started at 2023-12-02 12:04:51 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.310: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:14:46.310: INFO: sonobuoy-e2e-job-e9309236a19947ce from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:14:46.310: INFO: 	Container e2e ready: true, restart count 0
  Dec  2 13:14:46.310: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:14:46.310: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-fz89t from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:14:46.310: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:14:46.310: INFO: 	Container systemd-logs ready: true, restart count 0
  Dec  2 13:14:46.310: INFO: 
  Logging pods the apiserver thinks is on node ip-172-31-89-192 before test
  Dec  2 13:14:46.316: INFO: default-http-backend-kubernetes-worker-5c79cc75ff-5sm95 from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: nginx-ingress-controller-kubernetes-worker-g5cfp from ingress-nginx-kubernetes-worker started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: calico-node-ql9q7 from kube-system started at 2023-12-02 12:01:42 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container calico-node ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: coredns-59cfb5bf46-4zw4x from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container coredns ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: kube-state-metrics-78c475f58b-9brf7 from kube-system started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container kube-state-metrics ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: metrics-server-v0.6.3-69d7fbfdf8-q6h8s from kube-system started at 2023-12-02 12:02:20 +0000 UTC (2 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container metrics-server ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: 	Container metrics-server-nanny ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: dashboard-metrics-scraper-5dd7cb5fc-srsz2 from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: kubernetes-dashboard-7b899cb9d9-vfzmg from kubernetes-dashboard started at 2023-12-02 12:02:20 +0000 UTC (1 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-ldh7p from sonobuoy started at 2023-12-02 12:07:44 +0000 UTC (2 container statuses recorded)
  Dec  2 13:14:46.316: INFO: 	Container sonobuoy-worker ready: true, restart count 0
  Dec  2 13:14:46.316: INFO: 	Container systemd-logs ready: true, restart count 0
  STEP: verifying the node has the label node ip-172-31-1-50 @ 12/02/23 13:14:46.335
  STEP: verifying the node has the label node ip-172-31-74-39 @ 12/02/23 13:14:46.346
  STEP: verifying the node has the label node ip-172-31-89-192 @ 12/02/23 13:14:46.372
  Dec  2 13:14:46.384: INFO: Pod default-http-backend-kubernetes-worker-5c79cc75ff-5sm95 requesting resource cpu=10m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod nginx-ingress-controller-kubernetes-worker-bl8w7 requesting resource cpu=0m on Node ip-172-31-1-50
  Dec  2 13:14:46.384: INFO: Pod nginx-ingress-controller-kubernetes-worker-g5cfp requesting resource cpu=0m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod nginx-ingress-controller-kubernetes-worker-p5kqq requesting resource cpu=0m on Node ip-172-31-74-39
  Dec  2 13:14:46.384: INFO: Pod calico-node-jvhbz requesting resource cpu=250m on Node ip-172-31-74-39
  Dec  2 13:14:46.384: INFO: Pod calico-node-lzsm2 requesting resource cpu=250m on Node ip-172-31-1-50
  Dec  2 13:14:46.384: INFO: Pod calico-node-ql9q7 requesting resource cpu=250m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod coredns-59cfb5bf46-4zw4x requesting resource cpu=100m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod kube-state-metrics-78c475f58b-9brf7 requesting resource cpu=0m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod metrics-server-v0.6.3-69d7fbfdf8-q6h8s requesting resource cpu=5m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod dashboard-metrics-scraper-5dd7cb5fc-srsz2 requesting resource cpu=0m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod kubernetes-dashboard-7b899cb9d9-vfzmg requesting resource cpu=0m on Node ip-172-31-89-192
  Dec  2 13:14:46.384: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-1-50
  Dec  2 13:14:46.385: INFO: Pod sonobuoy-e2e-job-e9309236a19947ce requesting resource cpu=0m on Node ip-172-31-74-39
  Dec  2 13:14:46.385: INFO: Pod sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-28gq4 requesting resource cpu=0m on Node ip-172-31-1-50
  Dec  2 13:14:46.385: INFO: Pod sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-fz89t requesting resource cpu=0m on Node ip-172-31-74-39
  Dec  2 13:14:46.385: INFO: Pod sonobuoy-systemd-logs-daemon-set-005dbe13b8ee4940-ldh7p requesting resource cpu=0m on Node ip-172-31-89-192
  STEP: Starting Pods to consume most of the cluster CPU. @ 12/02/23 13:14:46.385
  Dec  2 13:14:46.385: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-74-39
  Dec  2 13:14:46.393: INFO: Creating a pod which consumes cpu=1144m on Node ip-172-31-89-192
  Dec  2 13:14:46.401: INFO: Creating a pod which consumes cpu=1225m on Node ip-172-31-1-50
  E1202 13:14:46.423044      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:47.423613      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:48.423949      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating another pod that requires unavailable amount of CPU. @ 12/02/23 13:14:48.424
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-27c2194a-3cad-441e-84b0-3ef02b4da1b3.179d060cd5a1f351], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2789/filler-pod-27c2194a-3cad-441e-84b0-3ef02b4da1b3 to ip-172-31-89-192] @ 12/02/23 13:14:48.427
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-27c2194a-3cad-441e-84b0-3ef02b4da1b3.179d060cf7bf191a], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/02/23 13:14:48.427
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-27c2194a-3cad-441e-84b0-3ef02b4da1b3.179d060cf8f9a79d], Reason = [Created], Message = [Created container filler-pod-27c2194a-3cad-441e-84b0-3ef02b4da1b3] @ 12/02/23 13:14:48.427
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-27c2194a-3cad-441e-84b0-3ef02b4da1b3.179d060cfe07bd78], Reason = [Started], Message = [Started container filler-pod-27c2194a-3cad-441e-84b0-3ef02b4da1b3] @ 12/02/23 13:14:48.427
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-74fafa0b-1da7-4a58-bd38-952ab4a95fef.179d060cd53defa3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2789/filler-pod-74fafa0b-1da7-4a58-bd38-952ab4a95fef to ip-172-31-74-39] @ 12/02/23 13:14:48.427
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-74fafa0b-1da7-4a58-bd38-952ab4a95fef.179d060cf97fa4c2], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/02/23 13:14:48.427
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-74fafa0b-1da7-4a58-bd38-952ab4a95fef.179d060cfa574f6c], Reason = [Created], Message = [Created container filler-pod-74fafa0b-1da7-4a58-bd38-952ab4a95fef] @ 12/02/23 13:14:48.428
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-74fafa0b-1da7-4a58-bd38-952ab4a95fef.179d060cfe8eedd4], Reason = [Started], Message = [Started container filler-pod-74fafa0b-1da7-4a58-bd38-952ab4a95fef] @ 12/02/23 13:14:48.428
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ea96d6c3-0611-4805-9399-1e8843092227.179d060cd6246057], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2789/filler-pod-ea96d6c3-0611-4805-9399-1e8843092227 to ip-172-31-1-50] @ 12/02/23 13:14:48.428
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ea96d6c3-0611-4805-9399-1e8843092227.179d060cf83e8014], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.9" already present on machine] @ 12/02/23 13:14:48.428
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ea96d6c3-0611-4805-9399-1e8843092227.179d060cf94745cf], Reason = [Created], Message = [Created container filler-pod-ea96d6c3-0611-4805-9399-1e8843092227] @ 12/02/23 13:14:48.428
  STEP: Considering event: 
  Type = [Normal], Name = [filler-pod-ea96d6c3-0611-4805-9399-1e8843092227.179d060cfe912572], Reason = [Started], Message = [Started container filler-pod-ea96d6c3-0611-4805-9399-1e8843092227] @ 12/02/23 13:14:48.428
  STEP: Considering event: 
  Type = [Warning], Name = [additional-pod.179d060d4e549985], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod..] @ 12/02/23 13:14:48.439
  E1202 13:14:49.424095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: removing the label node off the node ip-172-31-89-192 @ 12/02/23 13:14:49.439
  STEP: verifying the node doesn't have the label node @ 12/02/23 13:14:49.45
  STEP: removing the label node off the node ip-172-31-1-50 @ 12/02/23 13:14:49.454
  STEP: verifying the node doesn't have the label node @ 12/02/23 13:14:49.465
  STEP: removing the label node off the node ip-172-31-74-39 @ 12/02/23 13:14:49.468
  STEP: verifying the node doesn't have the label node @ 12/02/23 13:14:49.491
  Dec  2 13:14:49.495: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-pred-2789" for this suite. @ 12/02/23 13:14:49.501
• [3.245 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:174
  STEP: Creating a kubernetes client @ 12/02/23 13:14:49.51
  Dec  2 13:14:49.510: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:14:49.511
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:14:49.527
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:14:49.53
  STEP: Creating configMap with name cm-test-opt-del-02d18945-d98b-48ef-a8c7-b75181d89c3c @ 12/02/23 13:14:49.536
  STEP: Creating configMap with name cm-test-opt-upd-2f71158f-7817-4742-aeb2-b74c1992ef16 @ 12/02/23 13:14:49.542
  STEP: Creating the pod @ 12/02/23 13:14:49.549
  E1202 13:14:50.424503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:51.424582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting configmap cm-test-opt-del-02d18945-d98b-48ef-a8c7-b75181d89c3c @ 12/02/23 13:14:51.592
  STEP: Updating configmap cm-test-opt-upd-2f71158f-7817-4742-aeb2-b74c1992ef16 @ 12/02/23 13:14:51.598
  STEP: Creating configMap with name cm-test-opt-create-685a1adb-76b6-487d-99b8-ec46359f5eef @ 12/02/23 13:14:51.604
  STEP: waiting to observe update in volume @ 12/02/23 13:14:51.609
  E1202 13:14:52.425560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:53.426388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:54.427293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:55.427828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:56.428810      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:57.428980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:58.429075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:14:59.429272      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:00.429564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:01.429663      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:02.429750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:03.429862      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:04.429954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:05.430541      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:06.430628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:07.430755      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:08.430785      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:09.430870      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:10.431557      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:11.431758      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:12.431845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:13.432104      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:14.432143      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:15.432170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:16.432308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:17.432392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:18.432491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:19.432558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:20.433572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:21.433747      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:22.433917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:23.434247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:24.434322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:25.435220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:26.436247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:27.436438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:28.437144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:29.437236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:30.438149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:31.438312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:32.438390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:33.438483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:34.438582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:35.439289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:36.439359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:37.439550      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:38.439638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:39.439810      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:40.440026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:41.440220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:42.441055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:43.441251      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:44.441528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:45.442211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:46.442316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:47.442342      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:48.443287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:49.443389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:50.443742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:51.443852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:52.444804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:53.444876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:54.445754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:55.446700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:56.446929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:57.447181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:58.447474      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:15:59.448177      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:00.449158      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:01.449423      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:02.450125      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:03.451071      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:04.451287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:05.452143      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:06.452217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:07.452398      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:08.452785      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:09.453322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:10.454289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:11.454565      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:12.455255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:13.455350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:14.455438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:15.456221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:16:15.954: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5211" for this suite. @ 12/02/23 13:16:15.958
• [86.454 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]
test/e2e/apps/cronjob.go:70
  STEP: Creating a kubernetes client @ 12/02/23 13:16:15.967
  Dec  2 13:16:15.967: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename cronjob @ 12/02/23 13:16:15.967
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:16:15.985
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:16:15.987
  STEP: Creating a cronjob @ 12/02/23 13:16:15.989
  STEP: Ensuring more than one job is running at a time @ 12/02/23 13:16:15.996
  E1202 13:16:16.457040      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:17.457120      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:18.457210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:19.457536      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:20.458000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:21.458185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:22.458233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:23.458586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:24.459297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:25.459729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:26.460491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:27.460644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:28.460732      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:29.460819      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:30.461103      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:31.461258      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:32.462119      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:33.462219      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:34.462306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:35.462604      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:36.463274      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:37.463432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:38.464237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:39.464465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:40.464673      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:41.465614      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:42.466126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:43.466227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:44.466858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:45.467223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:46.468185      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:47.468280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:48.468362      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:49.468461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:50.468496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:51.468646      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:52.469058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:53.469252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:54.470006      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:55.470202      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:56.471213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:57.471610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:58.472402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:16:59.472562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:00.472899      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:01.473574      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:02.474364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:03.475289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:04.475377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:05.475615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:06.476205      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:07.476300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:08.476898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:09.476993      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:10.477321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:11.477408      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:12.477499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:13.478391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:14.479285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:15.479329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:16.479530      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:17.480362      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:18.481102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:19.481182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:20.482061      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:21.482222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:22.482318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:23.482373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:24.483283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:25.483491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:26.483594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:27.483674      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:28.483766      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:29.484206      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:30.484583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:31.485340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:32.485433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:33.486055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:34.486221      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:35.486511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:36.487134      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:37.487295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:38.487764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:39.487859      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:40.488312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:41.488477      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:42.489039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:43.489197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:44.489885      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:45.490626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:46.491174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:47.491613      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:48.492433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:49.492526      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:50.493365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:51.494276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:52.495278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:53.495622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:54.496016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:55.496277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:56.496576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:57.496774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:58.497122      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:17:59.497214      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:00.497569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:01.497678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring at least two running jobs exists by listing jobs explicitly @ 12/02/23 13:18:02
  STEP: Removing cronjob @ 12/02/23 13:18:02.003
  Dec  2 13:18:02.010: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-9819" for this suite. @ 12/02/23 13:18:02.013
• [106.053 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]
test/e2e/common/node/secrets.go:140
  STEP: Creating a kubernetes client @ 12/02/23 13:18:02.02
  Dec  2 13:18:02.020: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:18:02.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:02.046
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:02.048
  STEP: Creating projection with secret that has name secret-emptykey-test-cea87395-387e-40ff-b305-49de2dc11e76 @ 12/02/23 13:18:02.051
  Dec  2 13:18:02.052: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-9897" for this suite. @ 12/02/23 13:18:02.059
• [0.048 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:176
  STEP: Creating a kubernetes client @ 12/02/23 13:18:02.068
  Dec  2 13:18:02.068: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-webhook @ 12/02/23 13:18:02.068
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:02.084
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:02.086
  STEP: Setting up server cert @ 12/02/23 13:18:02.088
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/02/23 13:18:02.36
  STEP: Deploying the custom resource conversion webhook pod @ 12/02/23 13:18:02.369
  STEP: Wait for the deployment to be ready @ 12/02/23 13:18:02.38
  Dec  2 13:18:02.388: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E1202 13:18:02.498683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:03.498872      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:18:04.398
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:18:04.407
  E1202 13:18:04.499388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:05.407: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  2 13:18:05.415: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:18:05.500212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:06.500756      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:07.501071      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 12/02/23 13:18:07.979
  STEP: Create a v2 custom resource @ 12/02/23 13:18:07.995
  STEP: List CRs in v1 @ 12/02/23 13:18:08.035
  STEP: List CRs in v2 @ 12/02/23 13:18:08.039
  Dec  2 13:18:08.043: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1202 13:18:08.501684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-8347" for this suite. @ 12/02/23 13:18:08.599
• [6.540 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]
test/e2e/apimachinery/watch.go:191
  STEP: Creating a kubernetes client @ 12/02/23 13:18:08.611
  Dec  2 13:18:08.612: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename watch @ 12/02/23 13:18:08.613
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:08.632
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:08.635
  STEP: creating a watch on configmaps @ 12/02/23 13:18:08.637
  STEP: creating a new configmap @ 12/02/23 13:18:08.641
  STEP: modifying the configmap once @ 12/02/23 13:18:08.645
  STEP: closing the watch once it receives two notifications @ 12/02/23 13:18:08.653
  Dec  2 13:18:08.653: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9948  306b7d88-7b86-4dc3-963a-e2d165547f75 29230 0 2023-12-02 13:18:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-02 13:18:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:18:08.654: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9948  306b7d88-7b86-4dc3-963a-e2d165547f75 29231 0 2023-12-02 13:18:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-02 13:18:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time, while the watch is closed @ 12/02/23 13:18:08.654
  STEP: creating a new watch on configmaps from the last resource version observed by the first watch @ 12/02/23 13:18:08.662
  STEP: deleting the configmap @ 12/02/23 13:18:08.664
  STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed @ 12/02/23 13:18:08.67
  Dec  2 13:18:08.670: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9948  306b7d88-7b86-4dc3-963a-e2d165547f75 29232 0 2023-12-02 13:18:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-02 13:18:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:18:08.670: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9948  306b7d88-7b86-4dc3-963a-e2d165547f75 29233 0 2023-12-02 13:18:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2023-12-02 13:18:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:18:08.670: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-9948" for this suite. @ 12/02/23 13:18:08.674
• [0.069 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:276
  STEP: Creating a kubernetes client @ 12/02/23 13:18:08.681
  Dec  2 13:18:08.681: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 13:18:08.681
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:08.701
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:08.704
  STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation @ 12/02/23 13:18:08.706
  Dec  2 13:18:08.707: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:18:09.502586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:10.180: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:18:10.503061      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:11.503086      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:12.503194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:13.503736      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:14.504562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:15.505524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:15.607: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-1457" for this suite. @ 12/02/23 13:18:15.62
• [6.950 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:222
  STEP: Creating a kubernetes client @ 12/02/23 13:18:15.632
  Dec  2 13:18:15.632: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:18:15.633
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:15.654
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:15.657
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:18:15.661
  E1202 13:18:16.505632      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:17.505733      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:18.505828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:19.505937      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:18:19.687
  Dec  2 13:18:19.691: INFO: Trying to get logs from node ip-172-31-74-39 pod downwardapi-volume-6fab1de1-28b4-47f8-b120-f6640bb5f58d container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:18:19.709
  Dec  2 13:18:19.723: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9872" for this suite. @ 12/02/23 13:18:19.727
• [4.102 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]
test/e2e/apps/controller_revision.go:124
  STEP: Creating a kubernetes client @ 12/02/23 13:18:19.735
  Dec  2 13:18:19.735: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename controllerrevisions @ 12/02/23 13:18:19.736
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:19.763
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:19.766
  STEP: Creating DaemonSet "e2e-4x8bl-daemon-set" @ 12/02/23 13:18:19.787
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/02/23 13:18:19.791
  Dec  2 13:18:19.799: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:19.800: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:19.803: INFO: Number of nodes with available pods controlled by daemonset e2e-4x8bl-daemon-set: 0
  Dec  2 13:18:19.803: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:18:20.506600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:20.808: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:20.808: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:20.812: INFO: Number of nodes with available pods controlled by daemonset e2e-4x8bl-daemon-set: 2
  Dec  2 13:18:20.812: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:18:21.507000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:21.807: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:21.807: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:21.811: INFO: Number of nodes with available pods controlled by daemonset e2e-4x8bl-daemon-set: 3
  Dec  2 13:18:21.811: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-4x8bl-daemon-set
  STEP: Confirm DaemonSet "e2e-4x8bl-daemon-set" successfully created with "daemonset-name=e2e-4x8bl-daemon-set" label @ 12/02/23 13:18:21.815
  STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-4x8bl-daemon-set" @ 12/02/23 13:18:21.821
  Dec  2 13:18:21.824: INFO: Located ControllerRevision: "e2e-4x8bl-daemon-set-6889b85cf7"
  STEP: Patching ControllerRevision "e2e-4x8bl-daemon-set-6889b85cf7" @ 12/02/23 13:18:21.826
  Dec  2 13:18:21.834: INFO: e2e-4x8bl-daemon-set-6889b85cf7 has been patched
  STEP: Create a new ControllerRevision @ 12/02/23 13:18:21.834
  Dec  2 13:18:21.840: INFO: Created ControllerRevision: e2e-4x8bl-daemon-set-6546d45c
  STEP: Confirm that there are two ControllerRevisions @ 12/02/23 13:18:21.84
  Dec  2 13:18:21.840: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  2 13:18:21.843: INFO: Found 2 ControllerRevisions
  STEP: Deleting ControllerRevision "e2e-4x8bl-daemon-set-6889b85cf7" @ 12/02/23 13:18:21.843
  STEP: Confirm that there is only one ControllerRevision @ 12/02/23 13:18:21.851
  Dec  2 13:18:21.851: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  2 13:18:21.854: INFO: Found 1 ControllerRevisions
  STEP: Updating ControllerRevision "e2e-4x8bl-daemon-set-6546d45c" @ 12/02/23 13:18:21.858
  Dec  2 13:18:21.866: INFO: e2e-4x8bl-daemon-set-6546d45c has been updated
  STEP: Generate another ControllerRevision by patching the Daemonset @ 12/02/23 13:18:21.866
  W1202 13:18:21.873823      18 warnings.go:70] unknown field "updateStrategy"
  STEP: Confirm that there are two ControllerRevisions @ 12/02/23 13:18:21.873
  Dec  2 13:18:21.873: INFO: Requesting list of ControllerRevisions to confirm quantity
  E1202 13:18:22.507299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:22.878: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  2 13:18:22.881: INFO: Found 2 ControllerRevisions
  STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-4x8bl-daemon-set-6546d45c=updated" @ 12/02/23 13:18:22.881
  STEP: Confirm that there is only one ControllerRevision @ 12/02/23 13:18:22.891
  Dec  2 13:18:22.891: INFO: Requesting list of ControllerRevisions to confirm quantity
  Dec  2 13:18:22.895: INFO: Found 1 ControllerRevisions
  Dec  2 13:18:22.899: INFO: ControllerRevision "e2e-4x8bl-daemon-set-77dd4b8876" has revision 3
  STEP: Deleting DaemonSet "e2e-4x8bl-daemon-set" @ 12/02/23 13:18:22.901
  STEP: deleting DaemonSet.extensions e2e-4x8bl-daemon-set in namespace controllerrevisions-6547, will wait for the garbage collector to delete the pods @ 12/02/23 13:18:22.901
  Dec  2 13:18:22.962: INFO: Deleting DaemonSet.extensions e2e-4x8bl-daemon-set took: 6.761482ms
  Dec  2 13:18:23.063: INFO: Terminating DaemonSet.extensions e2e-4x8bl-daemon-set pods took: 100.72922ms
  E1202 13:18:23.508153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:24.508609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:24.868: INFO: Number of nodes with available pods controlled by daemonset e2e-4x8bl-daemon-set: 0
  Dec  2 13:18:24.868: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-4x8bl-daemon-set
  Dec  2 13:18:24.870: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29449"},"items":null}

  Dec  2 13:18:24.873: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29449"},"items":null}

  Dec  2 13:18:24.887: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "controllerrevisions-6547" for this suite. @ 12/02/23 13:18:24.891
• [5.161 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
test/e2e/apps/daemon_set.go:385
  STEP: Creating a kubernetes client @ 12/02/23 13:18:24.898
  Dec  2 13:18:24.898: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename daemonsets @ 12/02/23 13:18:24.898
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:24.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:24.915
  Dec  2 13:18:24.935: INFO: Creating simple daemon set daemon-set
  STEP: Check that daemon pods launch on every node of the cluster. @ 12/02/23 13:18:24.942
  Dec  2 13:18:24.948: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:24.948: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:24.952: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 13:18:24.952: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:18:25.509016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:25.957: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:25.957: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:25.960: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
  Dec  2 13:18:25.960: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:18:26.509545      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:26.957: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:26.957: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:26.961: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 13:18:26.961: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Update daemon pods image. @ 12/02/23 13:18:26.973
  STEP: Check that daemon pods images are updated. @ 12/02/23 13:18:26.986
  Dec  2 13:18:26.990: INFO: Wrong image for pod: daemon-set-9mk2q. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  2 13:18:26.990: INFO: Wrong image for pod: daemon-set-smnvb. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  2 13:18:26.990: INFO: Wrong image for pod: daemon-set-wbx9b. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  2 13:18:26.994: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:26.994: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1202 13:18:27.509650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:27.999: INFO: Pod daemon-set-5c5q5 is not available
  Dec  2 13:18:27.999: INFO: Wrong image for pod: daemon-set-smnvb. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  2 13:18:27.999: INFO: Wrong image for pod: daemon-set-wbx9b. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  2 13:18:28.002: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:28.002: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1202 13:18:28.509744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:28.997: INFO: Pod daemon-set-hf8fj is not available
  Dec  2 13:18:28.997: INFO: Wrong image for pod: daemon-set-smnvb. Expected: registry.k8s.io/e2e-test-images/agnhost:2.45, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-4.
  Dec  2 13:18:29.001: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:29.001: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1202 13:18:29.510538      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:30.001: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:30.002: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1202 13:18:30.511161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:31.000: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:31.000: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Check that daemon pods are still running on every node of the cluster. @ 12/02/23 13:18:31
  Dec  2 13:18:31.004: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:31.004: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:18:31.008: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 13:18:31.008: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  STEP: Deleting DaemonSet "daemon-set" @ 12/02/23 13:18:31.025
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6732, will wait for the garbage collector to delete the pods @ 12/02/23 13:18:31.025
  Dec  2 13:18:31.086: INFO: Deleting DaemonSet.extensions daemon-set took: 7.661276ms
  Dec  2 13:18:31.187: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.439032ms
  E1202 13:18:31.511446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:32.511531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:32.891: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 13:18:32.891: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  2 13:18:32.893: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"29668"},"items":null}

  Dec  2 13:18:32.897: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"29668"},"items":null}

  Dec  2 13:18:32.909: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-6732" for this suite. @ 12/02/23 13:18:32.913
• [8.022 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]
test/e2e/common/node/expansion.go:115
  STEP: Creating a kubernetes client @ 12/02/23 13:18:32.921
  Dec  2 13:18:32.921: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 13:18:32.922
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:32.937
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:32.939
  STEP: Creating a pod to test substitution in volume subpath @ 12/02/23 13:18:32.942
  E1202 13:18:33.511623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:34.511713      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:35.512539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:36.512712      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:18:36.96
  Dec  2 13:18:36.963: INFO: Trying to get logs from node ip-172-31-1-50 pod var-expansion-ecf6a000-bca2-4a91-8f7b-10703564be3b container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 13:18:36.981
  Dec  2 13:18:36.995: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-6951" for this suite. @ 12/02/23 13:18:36.999
• [4.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]
test/e2e/apimachinery/webhook.go:315
  STEP: Creating a kubernetes client @ 12/02/23 13:18:37.011
  Dec  2 13:18:37.011: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:18:37.011
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:37.026
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:37.029
  STEP: Setting up server cert @ 12/02/23 13:18:37.063
  E1202 13:18:37.513638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:18:37.562
  STEP: Deploying the webhook pod @ 12/02/23 13:18:37.567
  STEP: Wait for the deployment to be ready @ 12/02/23 13:18:37.579
  Dec  2 13:18:37.588: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:18:38.514005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:39.514252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:18:39.598
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:18:39.609
  E1202 13:18:40.514358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:18:40.609: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  2 13:18:40.617: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5594-crds.webhook.example.com via the AdmissionRegistration API @ 12/02/23 13:18:41.128
  STEP: Creating a custom resource while v1 is storage version @ 12/02/23 13:18:41.142
  E1202 13:18:41.514429      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:42.514529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Patching Custom Resource Definition to set v2 as storage @ 12/02/23 13:18:43.183
  STEP: Patching the custom resource while v2 is storage version @ 12/02/23 13:18:43.196
  Dec  2 13:18:43.204: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1202 13:18:43.515109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "webhook-1651" for this suite. @ 12/02/23 13:18:43.777
  STEP: Destroying namespace "webhook-markers-7111" for this suite. @ 12/02/23 13:18:43.784
• [6.779 seconds]
------------------------------
[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]
test/e2e/kubectl/kubectl.go:1806
  STEP: Creating a kubernetes client @ 12/02/23 13:18:43.79
  Dec  2 13:18:43.790: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:18:43.79
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:43.807
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:43.81
  STEP: Starting the proxy @ 12/02/23 13:18:43.812
  Dec  2 13:18:43.813: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-9706 proxy --unix-socket=/tmp/kubectl-proxy-unix671869206/test'
  STEP: retrieving proxy /api/ output @ 12/02/23 13:18:43.847
  Dec  2 13:18:43.847: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-9706" for this suite. @ 12/02/23 13:18:43.851
• [0.067 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]
test/e2e/network/dns.go:117
  STEP: Creating a kubernetes client @ 12/02/23 13:18:43.857
  Dec  2 13:18:43.857: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 13:18:43.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:43.872
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:43.875
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8994.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8994.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
   @ 12/02/23 13:18:43.877
  STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8994.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8994.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
   @ 12/02/23 13:18:43.877
  STEP: creating a pod to probe /etc/hosts @ 12/02/23 13:18:43.877
  STEP: submitting the pod to kubernetes @ 12/02/23 13:18:43.877
  E1202 13:18:44.515978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:45.516267      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/02/23 13:18:45.894
  STEP: looking for the results for each expected name from probers @ 12/02/23 13:18:45.897
  Dec  2 13:18:45.914: INFO: DNS probes using dns-8994/dns-test-7627b6fc-491d-4aeb-80c8-6eb96958ae77 succeeded

  Dec  2 13:18:45.914: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:18:45.917
  STEP: Destroying namespace "dns-8994" for this suite. @ 12/02/23 13:18:45.933
• [2.082 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:107
  STEP: Creating a kubernetes client @ 12/02/23 13:18:45.94
  Dec  2 13:18:45.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 13:18:45.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:18:45.955
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:18:45.958
  E1202 13:18:46.516309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:47.517212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:48.517547      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:49.518208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:50.518618      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:51.519260      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:52.519350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:53.519823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:54.519830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:55.520135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:56.520226      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:57.520273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:58.520896      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:18:59.521691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:00.522531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:01.522620      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:02.523300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:03.523391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:04.523478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:05.524306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:06.525196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:07.525339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:08.526213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:09.527198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:10.527427      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:11.528409      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:12.528950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:13.529458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:14.529787      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:15.530319      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:16.531066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:17.531153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:18.532082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:19.532176      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:20.533074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:21.533936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:22.534540      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:23.534641      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:24.535179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:25.535261      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:26.535305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:27.536053      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:28.536737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:29.537683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:30.538403      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:31.538491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:32.538586      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:33.539299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:34.539994      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:35.540545      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:36.540629      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:37.540711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:38.540819      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:39.541723      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:40.542181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:41.542677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:42.542731      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:43.543250      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:44.543312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:45.544077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:19:45.974: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-7105" for this suite. @ 12/02/23 13:19:45.978
• [60.044 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version should find the server version [Conformance]
test/e2e/apimachinery/server_version.go:40
  STEP: Creating a kubernetes client @ 12/02/23 13:19:45.985
  Dec  2 13:19:45.985: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename server-version @ 12/02/23 13:19:45.986
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:19:46.003
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:19:46.006
  STEP: Request ServerVersion @ 12/02/23 13:19:46.009
  STEP: Confirm major version @ 12/02/23 13:19:46.01
  Dec  2 13:19:46.010: INFO: Major version: 1
  STEP: Confirm minor version @ 12/02/23 13:19:46.01
  Dec  2 13:19:46.010: INFO: cleanMinorVersion: 28
  Dec  2 13:19:46.010: INFO: Minor version: 28
  Dec  2 13:19:46.010: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "server-version-3302" for this suite. @ 12/02/23 13:19:46.014
• [0.035 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]
test/e2e/apimachinery/resource_quota.go:946
  STEP: Creating a kubernetes client @ 12/02/23 13:19:46.021
  Dec  2 13:19:46.021: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 13:19:46.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:19:46.033
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:19:46.036
  STEP: Creating a ResourceQuota @ 12/02/23 13:19:46.039
  STEP: Getting a ResourceQuota @ 12/02/23 13:19:46.043
  STEP: Listing all ResourceQuotas with LabelSelector @ 12/02/23 13:19:46.047
  STEP: Patching the ResourceQuota @ 12/02/23 13:19:46.05
  STEP: Deleting a Collection of ResourceQuotas @ 12/02/23 13:19:46.057
  STEP: Verifying the deleted ResourceQuota @ 12/02/23 13:19:46.066
  Dec  2 13:19:46.068: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1739" for this suite. @ 12/02/23 13:19:46.071
• [0.056 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:163
  STEP: Creating a kubernetes client @ 12/02/23 13:19:46.079
  Dec  2 13:19:46.079: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:19:46.079
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:19:46.109
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:19:46.112
  STEP: Creating the pod @ 12/02/23 13:19:46.115
  E1202 13:19:46.544172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:47.544241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:48.545305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:19:48.668: INFO: Successfully updated pod "annotationupdate2f035057-4457-4254-8f74-868418294146"
  E1202 13:19:49.545971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:50.546600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:19:50.684: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9316" for this suite. @ 12/02/23 13:19:50.687
• [4.615 seconds]
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:131
  STEP: Creating a kubernetes client @ 12/02/23 13:19:50.694
  Dec  2 13:19:50.694: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:19:50.694
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:19:50.711
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:19:50.713
  STEP: Creating the pod @ 12/02/23 13:19:50.716
  E1202 13:19:51.547407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:52.547595      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:19:53.258: INFO: Successfully updated pod "labelsupdate60a3904f-1be9-471c-95c3-272a2315172b"
  E1202 13:19:53.548277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:54.548378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:19:55.275: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-1970" for this suite. @ 12/02/23 13:19:55.279
• [4.592 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]
test/e2e/apimachinery/resource_quota.go:395
  STEP: Creating a kubernetes client @ 12/02/23 13:19:55.286
  Dec  2 13:19:55.286: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 13:19:55.287
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:19:55.3
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:19:55.303
  STEP: Counting existing ResourceQuota @ 12/02/23 13:19:55.305
  E1202 13:19:55.548411      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:56.549287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:57.550307      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:58.550810      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:19:59.551122      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/02/23 13:20:00.309
  STEP: Ensuring resource quota status is calculated @ 12/02/23 13:20:00.316
  E1202 13:20:00.551873      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:01.551954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ReplicationController @ 12/02/23 13:20:02.32
  STEP: Ensuring resource quota status captures replication controller creation @ 12/02/23 13:20:02.331
  E1202 13:20:02.552029      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:03.552804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ReplicationController @ 12/02/23 13:20:04.336
  STEP: Ensuring resource quota status released usage @ 12/02/23 13:20:04.341
  E1202 13:20:04.553224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:05.553300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:20:06.346: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-6161" for this suite. @ 12/02/23 13:20:06.351
• [11.072 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]
test/e2e/apimachinery/webhook.go:250
  STEP: Creating a kubernetes client @ 12/02/23 13:20:06.359
  Dec  2 13:20:06.359: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:20:06.36
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:06.374
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:06.377
  STEP: Setting up server cert @ 12/02/23 13:20:06.4
  E1202 13:20:06.553822      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:20:06.795
  STEP: Deploying the webhook pod @ 12/02/23 13:20:06.804
  STEP: Wait for the deployment to be ready @ 12/02/23 13:20:06.818
  Dec  2 13:20:06.826: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:20:07.553807      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:08.553900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:20:08.837
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:20:08.85
  E1202 13:20:09.553978      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:20:09.851: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating configmap webhook via the AdmissionRegistration API @ 12/02/23 13:20:09.859
  STEP: create a configmap that should be updated by the webhook @ 12/02/23 13:20:09.877
  Dec  2 13:20:09.891: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3719" for this suite. @ 12/02/23 13:20:09.973
  STEP: Destroying namespace "webhook-markers-8535" for this suite. @ 12/02/23 13:20:09.984
• [3.632 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]
test/e2e/apimachinery/watch.go:60
  STEP: Creating a kubernetes client @ 12/02/23 13:20:09.992
  Dec  2 13:20:09.992: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename watch @ 12/02/23 13:20:09.993
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:10.011
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:10.014
  STEP: creating a watch on configmaps with label A @ 12/02/23 13:20:10.018
  STEP: creating a watch on configmaps with label B @ 12/02/23 13:20:10.021
  STEP: creating a watch on configmaps with label A or B @ 12/02/23 13:20:10.022
  STEP: creating a configmap with label A and ensuring the correct watchers observe the notification @ 12/02/23 13:20:10.023
  Dec  2 13:20:10.028: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30312 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:20:10.028: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30312 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A and ensuring the correct watchers observe the notification @ 12/02/23 13:20:10.028
  Dec  2 13:20:10.039: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30313 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:20:10.039: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30313 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying configmap A again and ensuring the correct watchers observe the notification @ 12/02/23 13:20:10.04
  Dec  2 13:20:10.048: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30314 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:20:10.048: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30314 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: deleting configmap A and ensuring the correct watchers observe the notification @ 12/02/23 13:20:10.048
  Dec  2 13:20:10.054: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30315 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:20:10.054: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1974  47f77036-5175-4b86-a6f7-a83a55f1a224 30315 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: creating a configmap with label B and ensuring the correct watchers observe the notification @ 12/02/23 13:20:10.055
  Dec  2 13:20:10.061: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1974  7ee68c87-86b1-4f79-b2a3-897911956a92 30316 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:20:10.061: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1974  7ee68c87-86b1-4f79-b2a3-897911956a92 30316 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1202 13:20:10.554815      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:11.554914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:12.554988      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:13.555107      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:14.555425      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:15.555794      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:16.556499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:17.556568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:18.556743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:19.556909      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting configmap B and ensuring the correct watchers observe the notification @ 12/02/23 13:20:20.061
  Dec  2 13:20:20.069: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1974  7ee68c87-86b1-4f79-b2a3-897911956a92 30365 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:20:20.069: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1974  7ee68c87-86b1-4f79-b2a3-897911956a92 30365 0 2023-12-02 13:20:10 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2023-12-02 13:20:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  E1202 13:20:20.557242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:21.557332      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:22.557434      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:23.557580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:24.557754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:25.558720      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:26.558816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:27.559653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:28.559792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:29.559958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:20:30.070: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-1974" for this suite. @ 12/02/23 13:20:30.075
• [20.091 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]
test/e2e/apimachinery/resource_quota.go:887
  STEP: Creating a kubernetes client @ 12/02/23 13:20:30.084
  Dec  2 13:20:30.084: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 13:20:30.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:30.123
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:30.126
  STEP: Creating a ResourceQuota @ 12/02/23 13:20:30.128
  STEP: Getting a ResourceQuota @ 12/02/23 13:20:30.132
  STEP: Updating a ResourceQuota @ 12/02/23 13:20:30.137
  STEP: Verifying a ResourceQuota was modified @ 12/02/23 13:20:30.14
  STEP: Deleting a ResourceQuota @ 12/02/23 13:20:30.146
  STEP: Verifying the deleted ResourceQuota @ 12/02/23 13:20:30.157
  Dec  2 13:20:30.160: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9955" for this suite. @ 12/02/23 13:20:30.163
• [0.087 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:250
  STEP: Creating a kubernetes client @ 12/02/23 13:20:30.171
  Dec  2 13:20:30.171: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:20:30.172
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:30.182
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:30.184
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:20:30.187
  E1202 13:20:30.560421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:31.560513      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:32.560983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:33.561055      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:20:34.21
  Dec  2 13:20:34.214: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-f35e37a8-40f4-4b59-bf21-08d43982993f container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:20:34.221
  Dec  2 13:20:34.236: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9226" for this suite. @ 12/02/23 13:20:34.239
• [4.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]
test/e2e/apps/replica_set.go:165
  STEP: Creating a kubernetes client @ 12/02/23 13:20:34.247
  Dec  2 13:20:34.247: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replicaset @ 12/02/23 13:20:34.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:34.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:34.266
  STEP: Create a ReplicaSet @ 12/02/23 13:20:34.269
  STEP: Verify that the required pods have come up @ 12/02/23 13:20:34.273
  Dec  2 13:20:34.277: INFO: Pod name sample-pod: Found 0 pods out of 3
  E1202 13:20:34.561156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:35.562179      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:36.562252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:37.562341      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:38.563287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:20:39.284: INFO: Pod name sample-pod: Found 3 pods out of 3
  STEP: ensuring each pod is running @ 12/02/23 13:20:39.284
  Dec  2 13:20:39.289: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
  STEP: Listing all ReplicaSets @ 12/02/23 13:20:39.289
  STEP: DeleteCollection of the ReplicaSets @ 12/02/23 13:20:39.293
  STEP: After DeleteCollection verify that ReplicaSets have been deleted @ 12/02/23 13:20:39.301
  Dec  2 13:20:39.314: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4745" for this suite. @ 12/02/23 13:20:39.318
• [5.088 seconds]
------------------------------
[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]
test/e2e/common/node/ephemeral_containers.go:98
  STEP: Creating a kubernetes client @ 12/02/23 13:20:39.335
  Dec  2 13:20:39.335: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename ephemeral-containers-test @ 12/02/23 13:20:39.336
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:39.355
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:39.363
  STEP: creating a target pod @ 12/02/23 13:20:39.366
  E1202 13:20:39.563644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:40.563724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: adding an ephemeral container @ 12/02/23 13:20:41.399
  E1202 13:20:41.564168      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:42.564298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking pod container endpoints @ 12/02/23 13:20:43.413
  Dec  2 13:20:43.414: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-8351 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:20:43.414: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:20:43.414: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:20:43.414: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-8351/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
  Dec  2 13:20:43.486: INFO: Exec stderr: ""
  STEP: checking pod "ephemeral-containers-target-pod" has only one ephemeralcontainer @ 12/02/23 13:20:43.492
  STEP: adding another ephemeralcontainer to pod "ephemeral-containers-target-pod" @ 12/02/23 13:20:43.496
  STEP: checking pod "ephemeral-containers-target-pod" has only two ephemeralcontainers @ 12/02/23 13:20:43.507
  Dec  2 13:20:43.512: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ephemeral-containers-test-8351" for this suite. @ 12/02/23 13:20:43.516
• [4.187 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]
test/e2e/kubectl/kubectl.go:996
  STEP: Creating a kubernetes client @ 12/02/23 13:20:43.523
  Dec  2 13:20:43.523: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:20:43.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:43.538
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:43.541
  STEP: create deployment with httpd image @ 12/02/23 13:20:43.543
  Dec  2 13:20:43.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7072 create -f -'
  E1202 13:20:43.565000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:20:43.669: INFO: stderr: ""
  Dec  2 13:20:43.669: INFO: stdout: "deployment.apps/httpd-deployment created\n"
  STEP: verify diff finds difference between live and declared image @ 12/02/23 13:20:43.669
  Dec  2 13:20:43.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7072 diff -f -'
  Dec  2 13:20:43.779: INFO: rc: 1
  Dec  2 13:20:43.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7072 delete -f -'
  Dec  2 13:20:43.832: INFO: stderr: ""
  Dec  2 13:20:43.832: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
  Dec  2 13:20:43.832: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7072" for this suite. @ 12/02/23 13:20:43.836
• [0.321 seconds]
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:442
  STEP: Creating a kubernetes client @ 12/02/23 13:20:43.844
  Dec  2 13:20:43.844: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 13:20:43.844
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:43.859
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:43.862
  STEP: set up a multi version CRD @ 12/02/23 13:20:43.865
  Dec  2 13:20:43.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:20:44.565606      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:45.566375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:46.567170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: mark a version not serverd @ 12/02/23 13:20:47.063
  STEP: check the unserved version gets removed @ 12/02/23 13:20:47.079
  E1202 13:20:47.567801      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check the other version is not changed @ 12/02/23 13:20:47.99
  E1202 13:20:48.568182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:49.568878      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:50.569235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:20:50.598: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-7835" for this suite. @ 12/02/23 13:20:50.606
• [6.768 seconds]
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]
test/e2e/kubectl/kubectl.go:341
  STEP: Creating a kubernetes client @ 12/02/23 13:20:50.612
  Dec  2 13:20:50.612: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:20:50.613
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:50.637
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:50.639
  STEP: creating a replication controller @ 12/02/23 13:20:50.642
  Dec  2 13:20:50.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 create -f -'
  Dec  2 13:20:50.792: INFO: stderr: ""
  Dec  2 13:20:50.792: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
  STEP: waiting for all containers in name=update-demo pods to come up. @ 12/02/23 13:20:50.792
  Dec  2 13:20:50.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  2 13:20:50.849: INFO: stderr: ""
  Dec  2 13:20:50.849: INFO: stdout: "update-demo-nautilus-tkx49 update-demo-nautilus-x58qs "
  Dec  2 13:20:50.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods update-demo-nautilus-tkx49 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 13:20:50.898: INFO: stderr: ""
  Dec  2 13:20:50.898: INFO: stdout: ""
  Dec  2 13:20:50.898: INFO: update-demo-nautilus-tkx49 is created but not running
  E1202 13:20:51.569378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:52.569554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:53.569653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:54.569749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:55.570571      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:20:55.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
  Dec  2 13:20:55.950: INFO: stderr: ""
  Dec  2 13:20:55.950: INFO: stdout: "update-demo-nautilus-tkx49 update-demo-nautilus-x58qs "
  Dec  2 13:20:55.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods update-demo-nautilus-tkx49 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 13:20:56.001: INFO: stderr: ""
  Dec  2 13:20:56.001: INFO: stdout: "true"
  Dec  2 13:20:56.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods update-demo-nautilus-tkx49 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  2 13:20:56.053: INFO: stderr: ""
  Dec  2 13:20:56.053: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  2 13:20:56.053: INFO: validating pod update-demo-nautilus-tkx49
  Dec  2 13:20:56.059: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  2 13:20:56.059: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  2 13:20:56.059: INFO: update-demo-nautilus-tkx49 is verified up and running
  Dec  2 13:20:56.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods update-demo-nautilus-x58qs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
  Dec  2 13:20:56.108: INFO: stderr: ""
  Dec  2 13:20:56.108: INFO: stdout: "true"
  Dec  2 13:20:56.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods update-demo-nautilus-x58qs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
  Dec  2 13:20:56.158: INFO: stderr: ""
  Dec  2 13:20:56.158: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.7"
  Dec  2 13:20:56.158: INFO: validating pod update-demo-nautilus-x58qs
  Dec  2 13:20:56.163: INFO: got data: {
    "image": "nautilus.jpg"
  }

  Dec  2 13:20:56.163: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
  Dec  2 13:20:56.163: INFO: update-demo-nautilus-x58qs is verified up and running
  STEP: using delete to clean up resources @ 12/02/23 13:20:56.163
  Dec  2 13:20:56.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 delete --grace-period=0 --force -f -'
  Dec  2 13:20:56.217: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
  Dec  2 13:20:56.217: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
  Dec  2 13:20:56.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get rc,svc -l name=update-demo --no-headers'
  Dec  2 13:20:56.293: INFO: stderr: "No resources found in kubectl-4409 namespace.\n"
  Dec  2 13:20:56.293: INFO: stdout: ""
  Dec  2 13:20:56.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-4409 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
  Dec  2 13:20:56.387: INFO: stderr: ""
  Dec  2 13:20:56.387: INFO: stdout: ""
  Dec  2 13:20:56.387: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-4409" for this suite. @ 12/02/23 13:20:56.391
• [5.785 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets should patch a secret [Conformance]
test/e2e/common/node/secrets.go:154
  STEP: Creating a kubernetes client @ 12/02/23 13:20:56.398
  Dec  2 13:20:56.398: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:20:56.399
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:56.42
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:56.424
  STEP: creating a secret @ 12/02/23 13:20:56.428
  STEP: listing secrets in all namespaces to ensure that there are more than zero @ 12/02/23 13:20:56.432
  STEP: patching the secret @ 12/02/23 13:20:56.435
  STEP: deleting the secret using a LabelSelector @ 12/02/23 13:20:56.447
  STEP: listing secrets in all namespaces, searching for label name and value in patch @ 12/02/23 13:20:56.454
  Dec  2 13:20:56.457: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-8654" for this suite. @ 12/02/23 13:20:56.461
• [0.072 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]
test/e2e/auth/service_accounts.go:808
  STEP: Creating a kubernetes client @ 12/02/23 13:20:56.471
  Dec  2 13:20:56.471: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svcaccounts @ 12/02/23 13:20:56.471
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:56.49
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:56.492
  STEP: Creating ServiceAccount "e2e-sa-8mnfv"  @ 12/02/23 13:20:56.537
  Dec  2 13:20:56.542: INFO: AutomountServiceAccountToken: false
  STEP: Updating ServiceAccount "e2e-sa-8mnfv"  @ 12/02/23 13:20:56.542
  Dec  2 13:20:56.551: INFO: AutomountServiceAccountToken: true
  Dec  2 13:20:56.551: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svcaccounts-7888" for this suite. @ 12/02/23 13:20:56.556
• [0.091 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:168
  STEP: Creating a kubernetes client @ 12/02/23 13:20:56.563
  Dec  2 13:20:56.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 13:20:56.563
  E1202 13:20:56.571544      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:20:56.582
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:20:56.586
  STEP: Creating pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322 @ 12/02/23 13:20:56.589
  E1202 13:20:57.571650      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:20:58.571735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 13:20:58.61
  Dec  2 13:20:58.614: INFO: Initial restart count of pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 is 0
  Dec  2 13:20:58.618: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:20:59.572048      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:00.572640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:00.622: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:01.572835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:02.573304      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:02.627: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:03.573384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:04.573455      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:04.631: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:05.573583      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:06.573672      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:06.637: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:07.574174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:08.574302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:08.641: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:09.575296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:10.575457      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:10.644: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:11.575552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:12.575725      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:12.650: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:13.576381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:14.576462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:14.655: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:15.576562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:16.576661      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:16.660: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  E1202 13:21:17.577365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:18.577461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:18.663: INFO: Get pod liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 in namespace container-probe-5322
  Dec  2 13:21:18.664: INFO: Restart count of pod container-probe-5322/liveness-e7bb0405-0ab8-4ecb-bae2-b89e2d828ed6 is now 1 (20.049506949s elapsed)
  Dec  2 13:21:18.664: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:21:18.667
  STEP: Destroying namespace "container-probe-5322" for this suite. @ 12/02/23 13:21:18.683
• [22.127 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:151
  STEP: Creating a kubernetes client @ 12/02/23 13:21:18.69
  Dec  2 13:21:18.690: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 13:21:18.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:21:18.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:21:18.712
  STEP: Creating pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107 @ 12/02/23 13:21:18.714
  E1202 13:21:19.577559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:20.577938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 13:21:20.73
  Dec  2 13:21:20.734: INFO: Initial restart count of pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a is 0
  Dec  2 13:21:20.736: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:21.578922      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:22.579025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:22.741: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:23.579109      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:24.579198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:24.746: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:25.579757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:26.580309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:26.751: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:27.581123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:28.581216      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:28.755: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:29.581626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:30.581634      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:30.759: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:31.582233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:32.582333      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:32.762: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:33.583256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:34.584041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:34.767: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:35.584357      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:36.584397      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:36.772: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:37.585408      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:38.585572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:38.776: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:39.586004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:40.586980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:40.781: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:41.587289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:42.587380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:42.785: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:43.587716      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:44.587791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:44.789: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:45.588361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:46.588542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:46.793: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:47.588633      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:48.588673      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:48.797: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:49.589019      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:50.589697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:50.801: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:51.589973      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:52.590164      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:52.805: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:53.590702      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:54.591289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:54.810: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:55.592171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:56.592268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:56.814: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:57.593190      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:21:58.593301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:21:58.820: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:21:59.593852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:00.593900      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:00.823: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:01.594233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:02.595301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:02.827: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:03.595740      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:04.595796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:04.832: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:05.596358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:06.596430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:06.836: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:07.596740      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:08.596840      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:08.841: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:09.596918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:10.597134      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:10.845: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:11.597750      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:12.597960      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:12.849: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:13.598232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:14.598318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:14.852: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:15.598651      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:16.599303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:16.857: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:17.599391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:18.599703      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:18.861: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:19.599805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:20.600103      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:20.865: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:21.600444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:22.601057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:22.871: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:23.602084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:24.602245      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:24.876: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:25.603309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:26.603394      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:26.880: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:27.604026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:28.604102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:28.885: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:29.604209      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:30.604353      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:30.889: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:31.605196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:32.605370      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:32.893: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:33.605821      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:34.605914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:34.899: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:35.606608      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:36.606706      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:36.904: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:37.607305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:38.607394      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:38.910: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:39.607889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:40.607936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:40.913: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:41.608507      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:42.608594      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:42.918: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:43.608691      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:44.608781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:44.922: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:45.609442      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:46.609682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:46.926: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:47.610644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:48.610739      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:48.931: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:49.610956      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:50.611326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:50.934: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:51.611300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:52.611377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:52.939: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:53.611768      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:54.612308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:54.943: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:55.613213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:56.613305      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:56.949: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:57.613420      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:22:58.613502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:22:58.953: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:22:59.614399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:00.615275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:00.957: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:01.616196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:02.616302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:02.962: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:03.616730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:04.616826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:04.965: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:05.617384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:06.617519      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:06.970: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:07.618008      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:08.618174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:08.974: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:09.618228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:10.619225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:10.979: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:11.619316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:12.619491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:12.983: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:13.619946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:14.620483      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:14.988: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:15.621417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:16.621662      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:16.992: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:17.622431      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:18.623389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:18.996: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:19.623673      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:20.624763      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:21.000: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:21.625206      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:22.625447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:23.004: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:23.625537      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:24.625625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:25.009: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:25.625653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:26.625826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:27.012: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:27.626220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:28.627279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:29.017: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:29.627373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:30.627702      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:31.022: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:31.627802      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:32.627888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:33.027: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:33.628074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:34.628165      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:35.031: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:35.628708      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:36.628855      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:37.035: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:37.629654      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:38.629737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:39.039: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:39.629828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:40.630775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:41.043: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:41.631001      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:42.631580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:43.047: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:43.632149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:44.632235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:45.051: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:45.632694      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:46.632792      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:47.056: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:47.633781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:48.633937      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:49.059: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:49.634225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:50.634556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:51.064: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:51.635041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:52.635315      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:53.069: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:53.635338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:54.635516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:55.073: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:55.636316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:56.636898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:57.079: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:57.636993      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:23:58.637149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:23:59.084: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:23:59.637754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:00.637898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:01.088: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:01.638600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:02.639273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:03.094: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:03.639367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:04.639528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:05.098: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:05.640249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:06.640400      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:07.103: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:07.640966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:08.641057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:09.109: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:09.641144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:10.641351      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:11.113: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:11.641898      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:12.642648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:13.117: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:13.643153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:14.643311      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:15.122: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:15.643826      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:16.643932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:17.127: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:17.644675      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:18.644764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:19.130: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:19.644852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:20.645058      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:21.134: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:21.645151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:22.645658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:23.138: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:23.646359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:24.646452      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:25.142: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:25.646661      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:26.646740      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:27.148: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:27.647279      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:28.647435      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:29.152: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:29.648138      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:30.648369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:31.156: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:31.649177      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:32.649330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:33.160: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:33.650366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:34.651278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:35.164: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:35.651369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:36.652213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:37.169: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:37.652321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:38.652473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:39.173: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:39.652963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:40.653856      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:41.176: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:41.654215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:42.655281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:43.181: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:43.655774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:44.655864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:45.184: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:45.656644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:46.656838      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:47.188: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:47.657556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:48.657621      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:49.192: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:49.658138      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:50.658480      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:51.196: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:51.659159      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:52.659378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:53.200: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:53.659486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:54.659637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:55.204: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:55.660421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:56.661366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:57.209: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:57.661461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:24:58.661555      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:24:59.214: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:24:59.662171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:00.662516      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:01.218: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:01.662711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:02.663290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:03.222: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:03.663344      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:04.663438      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:05.227: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:05.663665      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:06.664038      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:07.233: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:07.664816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:08.665622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:09.237: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:09.666295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:10.666404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:11.241: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:11.666730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:12.667283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:13.244: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:13.668318      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:14.668360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:15.249: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:15.668635      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:16.668812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:17.253: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:17.669150      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:18.669299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:19.258: INFO: Get pod busybox-bfe31f1e-728b-425b-a993-e1d9aa51806a in namespace container-probe-3107
  E1202 13:25:19.669876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:20.670773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:21.258: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:25:21.262
  STEP: Destroying namespace "container-probe-3107" for this suite. @ 12/02/23 13:25:21.289
• [242.607 seconds]
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:135
  STEP: Creating a kubernetes client @ 12/02/23 13:25:21.297
  Dec  2 13:25:21.297: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/02/23 13:25:21.297
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:21.312
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:21.317
  STEP: create the container to handle the HTTPGet hook request. @ 12/02/23 13:25:21.323
  E1202 13:25:21.671470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:22.671798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/02/23 13:25:23.343
  E1202 13:25:23.674455      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:24.675304      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check poststart hook @ 12/02/23 13:25:25.362
  STEP: delete the pod with lifecycle hook @ 12/02/23 13:25:25.379
  E1202 13:25:25.676328      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:26.676422      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:27.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-5032" for this suite. @ 12/02/23 13:25:27.399
• [6.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]
test/e2e/auth/certificates.go:200
  STEP: Creating a kubernetes client @ 12/02/23 13:25:27.407
  Dec  2 13:25:27.407: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename certificates @ 12/02/23 13:25:27.407
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:27.428
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:27.43
  E1202 13:25:27.677230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: getting /apis @ 12/02/23 13:25:27.834
  STEP: getting /apis/certificates.k8s.io @ 12/02/23 13:25:27.838
  STEP: getting /apis/certificates.k8s.io/v1 @ 12/02/23 13:25:27.839
  STEP: creating @ 12/02/23 13:25:27.839
  STEP: getting @ 12/02/23 13:25:27.856
  STEP: listing @ 12/02/23 13:25:27.858
  STEP: watching @ 12/02/23 13:25:27.862
  Dec  2 13:25:27.862: INFO: starting watch
  STEP: patching @ 12/02/23 13:25:27.863
  STEP: updating @ 12/02/23 13:25:27.868
  Dec  2 13:25:27.872: INFO: waiting for watch events with expected annotations
  Dec  2 13:25:27.872: INFO: saw patched and updated annotations
  STEP: getting /approval @ 12/02/23 13:25:27.872
  STEP: patching /approval @ 12/02/23 13:25:27.875
  STEP: updating /approval @ 12/02/23 13:25:27.881
  STEP: getting /status @ 12/02/23 13:25:27.885
  STEP: patching /status @ 12/02/23 13:25:27.889
  STEP: updating /status @ 12/02/23 13:25:27.895
  STEP: deleting @ 12/02/23 13:25:27.902
  STEP: deleting a collection @ 12/02/23 13:25:27.914
  Dec  2 13:25:27.930: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "certificates-1939" for this suite. @ 12/02/23 13:25:27.933
• [0.533 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:167
  STEP: Creating a kubernetes client @ 12/02/23 13:25:27.94
  Dec  2 13:25:27.940: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:25:27.941
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:27.957
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:27.959
  STEP: Creating a pod to test emptydir 0644 on node default medium @ 12/02/23 13:25:27.962
  E1202 13:25:28.677382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:29.677534      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:30.678082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:31.678231      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:25:31.983
  Dec  2 13:25:31.985: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-2cd617cb-dcac-4128-b6cb-c5ef8f478c1f container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:25:32.004
  Dec  2 13:25:32.021: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-4017" for this suite. @ 12/02/23 13:25:32.024
• [4.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]
test/e2e/apimachinery/field_validation.go:474
  STEP: Creating a kubernetes client @ 12/02/23 13:25:32.032
  Dec  2 13:25:32.032: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename field-validation @ 12/02/23 13:25:32.032
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:32.05
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:32.052
  Dec  2 13:25:32.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:25:32.678701      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:33.678872      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1202 13:25:34.602681      18 warnings.go:70] unknown field "alpha"
  W1202 13:25:34.602700      18 warnings.go:70] unknown field "beta"
  W1202 13:25:34.602703      18 warnings.go:70] unknown field "delta"
  W1202 13:25:34.602707      18 warnings.go:70] unknown field "epsilon"
  W1202 13:25:34.602710      18 warnings.go:70] unknown field "gamma"
  E1202 13:25:34.679889      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:35.133: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6746" for this suite. @ 12/02/23 13:25:35.148
• [3.124 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:459
  STEP: Creating a kubernetes client @ 12/02/23 13:25:35.157
  Dec  2 13:25:35.157: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename init-container @ 12/02/23 13:25:35.157
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:35.173
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:35.175
  STEP: creating the pod @ 12/02/23 13:25:35.177
  Dec  2 13:25:35.177: INFO: PodSpec: initContainers in spec.initContainers
  E1202 13:25:35.679951      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:36.680918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:37.681037      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:38.197: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-5910" for this suite. @ 12/02/23 13:25:38.202
• [3.053 seconds]
------------------------------
SSS
------------------------------
[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:45
  STEP: Creating a kubernetes client @ 12/02/23 13:25:38.21
  Dec  2 13:25:38.210: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 13:25:38.21
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:38.227
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:38.23
  STEP: Creating configMap configmap-2199/configmap-test-acfe3278-6838-4603-9adb-c863a9d9ad74 @ 12/02/23 13:25:38.233
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:25:38.239
  E1202 13:25:38.681198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:39.681486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:25:40.255
  Dec  2 13:25:40.258: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-9259fd60-983b-43c7-af6d-a4bff194c661 container env-test: <nil>
  STEP: delete the pod @ 12/02/23 13:25:40.263
  Dec  2 13:25:40.280: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-2199" for this suite. @ 12/02/23 13:25:40.283
• [2.079 seconds]
------------------------------
S
------------------------------
[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:445
  STEP: Creating a kubernetes client @ 12/02/23 13:25:40.289
  Dec  2 13:25:40.289: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:25:40.29
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:40.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:40.317
  E1202 13:25:40.682088      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:41.682231      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:42.682932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:43.683952      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:44.684425      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:45.685446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:25:46.369
  Dec  2 13:25:46.372: INFO: Trying to get logs from node ip-172-31-1-50 pod client-envvars-86f3d871-99e5-481b-aef8-50c02378a8fa container env3cont: <nil>
  STEP: delete the pod @ 12/02/23 13:25:46.379
  Dec  2 13:25:46.395: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7649" for this suite. @ 12/02/23 13:25:46.4
• [6.117 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob should support CronJob API operations [Conformance]
test/e2e/apps/cronjob.go:324
  STEP: Creating a kubernetes client @ 12/02/23 13:25:46.408
  Dec  2 13:25:46.408: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename cronjob @ 12/02/23 13:25:46.408
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:46.427
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:46.429
  STEP: Creating a cronjob @ 12/02/23 13:25:46.432
  STEP: creating @ 12/02/23 13:25:46.432
  STEP: getting @ 12/02/23 13:25:46.437
  STEP: listing @ 12/02/23 13:25:46.444
  STEP: watching @ 12/02/23 13:25:46.448
  Dec  2 13:25:46.448: INFO: starting watch
  STEP: cluster-wide listing @ 12/02/23 13:25:46.449
  STEP: cluster-wide watching @ 12/02/23 13:25:46.452
  Dec  2 13:25:46.452: INFO: starting watch
  STEP: patching @ 12/02/23 13:25:46.453
  STEP: updating @ 12/02/23 13:25:46.458
  Dec  2 13:25:46.468: INFO: waiting for watch events with expected annotations
  Dec  2 13:25:46.468: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/02/23 13:25:46.468
  STEP: updating /status @ 12/02/23 13:25:46.473
  STEP: get /status @ 12/02/23 13:25:46.48
  STEP: deleting @ 12/02/23 13:25:46.483
  STEP: deleting a collection @ 12/02/23 13:25:46.499
  Dec  2 13:25:46.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-8778" for this suite. @ 12/02/23 13:25:46.514
• [0.113 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
test/e2e/common/node/runtime.go:232
  STEP: Creating a kubernetes client @ 12/02/23 13:25:46.521
  Dec  2 13:25:46.521: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-runtime @ 12/02/23 13:25:46.522
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:46.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:46.542
  STEP: create the container @ 12/02/23 13:25:46.544
  W1202 13:25:46.552347      18 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
  STEP: wait for the container to reach Succeeded @ 12/02/23 13:25:46.552
  E1202 13:25:46.686243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:47.686541      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:48.687456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: get the container status @ 12/02/23 13:25:49.567
  STEP: the container should be terminated @ 12/02/23 13:25:49.57
  STEP: the termination message should be set @ 12/02/23 13:25:49.57
  Dec  2 13:25:49.570: INFO: Expected: &{} to match Container's Termination Message:  --
  STEP: delete the container @ 12/02/23 13:25:49.57
  Dec  2 13:25:49.585: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-runtime-6696" for this suite. @ 12/02/23 13:25:49.593
• [3.078 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]
test/e2e/apimachinery/webhook.go:119
  STEP: Creating a kubernetes client @ 12/02/23 13:25:49.6
  Dec  2 13:25:49.600: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:25:49.601
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:49.618
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:49.62
  STEP: Setting up server cert @ 12/02/23 13:25:49.644
  E1202 13:25:49.687749      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:25:49.908
  STEP: Deploying the webhook pod @ 12/02/23 13:25:49.916
  STEP: Wait for the deployment to be ready @ 12/02/23 13:25:49.928
  Dec  2 13:25:49.934: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:25:50.688796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:51.688882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:25:51.945
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:25:51.954
  E1202 13:25:52.689061      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:52.954: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: fetching the /apis discovery document @ 12/02/23 13:25:52.961
  STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document @ 12/02/23 13:25:52.962
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document @ 12/02/23 13:25:52.962
  STEP: fetching the /apis/admissionregistration.k8s.io discovery document @ 12/02/23 13:25:52.962
  STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document @ 12/02/23 13:25:52.963
  STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/02/23 13:25:52.963
  STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document @ 12/02/23 13:25:52.964
  Dec  2 13:25:52.964: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1857" for this suite. @ 12/02/23 13:25:53.007
  STEP: Destroying namespace "webhook-markers-5595" for this suite. @ 12/02/23 13:25:53.017
• [3.423 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:167
  STEP: Creating a kubernetes client @ 12/02/23 13:25:53.026
  Dec  2 13:25:53.026: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:25:53.026
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:53.043
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:53.045
  STEP: Creating a pod to test downward api env vars @ 12/02/23 13:25:53.048
  E1202 13:25:53.689086      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:54.690155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:55.691097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:56.691237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:25:57.072
  Dec  2 13:25:57.075: INFO: Trying to get logs from node ip-172-31-1-50 pod downward-api-cefb3476-34d4-4f56-9a2c-f787a83cbfc9 container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 13:25:57.081
  Dec  2 13:25:57.099: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6040" for this suite. @ 12/02/23 13:25:57.102
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:537
  STEP: Creating a kubernetes client @ 12/02/23 13:25:57.111
  Dec  2 13:25:57.111: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:25:57.112
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:57.131
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:57.133
  Dec  2 13:25:57.135: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: creating the pod @ 12/02/23 13:25:57.136
  STEP: submitting the pod to kubernetes @ 12/02/23 13:25:57.137
  E1202 13:25:57.691958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:25:58.692026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:25:59.235: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-8946" for this suite. @ 12/02/23 13:25:59.24
• [2.136 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should delete a collection of pods [Conformance]
test/e2e/common/node/pods.go:846
  STEP: Creating a kubernetes client @ 12/02/23 13:25:59.248
  Dec  2 13:25:59.248: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:25:59.248
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:25:59.264
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:25:59.267
  STEP: Create set of pods @ 12/02/23 13:25:59.271
  Dec  2 13:25:59.281: INFO: created test-pod-1
  Dec  2 13:25:59.287: INFO: created test-pod-2
  Dec  2 13:25:59.295: INFO: created test-pod-3
  STEP: waiting for all 3 pods to be running @ 12/02/23 13:25:59.295
  E1202 13:25:59.692149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:00.692549      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting for all pods to be deleted @ 12/02/23 13:26:01.345
  Dec  2 13:26:01.348: INFO: Pod quantity 3 is different from expected quantity 0
  E1202 13:26:01.693513      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:02.352: INFO: Pod quantity 2 is different from expected quantity 0
  E1202 13:26:02.694562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:03.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-4135" for this suite. @ 12/02/23 13:26:03.355
• [4.115 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]
test/e2e/common/node/pods.go:897
  STEP: Creating a kubernetes client @ 12/02/23 13:26:03.364
  Dec  2 13:26:03.364: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:26:03.365
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:26:03.379
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:26:03.381
  STEP: creating a Pod with a static label @ 12/02/23 13:26:03.395
  STEP: watching for Pod to be ready @ 12/02/23 13:26:03.404
  Dec  2 13:26:03.406: INFO: observed Pod pod-test in namespace pods-893 in phase Pending with labels: map[test-pod-static:true] & conditions []
  Dec  2 13:26:03.409: INFO: observed Pod pod-test in namespace pods-893 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:03 +0000 UTC  }]
  Dec  2 13:26:03.423: INFO: observed Pod pod-test in namespace pods-893 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:03 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:03 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:03 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:03 +0000 UTC  }]
  E1202 13:26:03.695288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:04.695352      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:05.104: INFO: Found Pod pod-test in namespace pods-893 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:03 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:05 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:05 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2023-12-02 13:26:03 +0000 UTC  }]
  STEP: patching the Pod with a new Label and updated data @ 12/02/23 13:26:05.107
  STEP: getting the Pod and ensuring that it's patched @ 12/02/23 13:26:05.125
  STEP: replacing the Pod's status Ready condition to False @ 12/02/23 13:26:05.129
  STEP: check the Pod again to ensure its Ready conditions are False @ 12/02/23 13:26:05.14
  STEP: deleting the Pod via a Collection with a LabelSelector @ 12/02/23 13:26:05.14
  STEP: watching for the Pod to be deleted @ 12/02/23 13:26:05.149
  Dec  2 13:26:05.151: INFO: observed event type MODIFIED
  E1202 13:26:05.695635      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:06.584: INFO: observed event type MODIFIED
  E1202 13:26:06.696575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:07.360: INFO: observed event type MODIFIED
  E1202 13:26:07.697215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:08.110: INFO: observed event type MODIFIED
  Dec  2 13:26:08.125: INFO: observed event type MODIFIED
  Dec  2 13:26:08.130: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-893" for this suite. @ 12/02/23 13:26:08.134
• [4.777 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
test/e2e/apimachinery/watch.go:257
  STEP: Creating a kubernetes client @ 12/02/23 13:26:08.142
  Dec  2 13:26:08.142: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename watch @ 12/02/23 13:26:08.142
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:26:08.159
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:26:08.161
  STEP: creating a watch on configmaps with a certain label @ 12/02/23 13:26:08.163
  STEP: creating a new configmap @ 12/02/23 13:26:08.164
  STEP: modifying the configmap once @ 12/02/23 13:26:08.172
  STEP: changing the label value of the configmap @ 12/02/23 13:26:08.178
  STEP: Expecting to observe a delete notification for the watched object @ 12/02/23 13:26:08.186
  Dec  2 13:26:08.186: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-580  56b10df7-9c6c-42c2-b2fa-eb987c2a0a91 32028 0 2023-12-02 13:26:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-02 13:26:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:26:08.187: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-580  56b10df7-9c6c-42c2-b2fa-eb987c2a0a91 32029 0 2023-12-02 13:26:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-02 13:26:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:26:08.187: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-580  56b10df7-9c6c-42c2-b2fa-eb987c2a0a91 32030 0 2023-12-02 13:26:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-02 13:26:08 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
  STEP: modifying the configmap a second time @ 12/02/23 13:26:08.187
  STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements @ 12/02/23 13:26:08.194
  E1202 13:26:08.697893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:09.697972      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:10.698959      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:11.699043      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:12.699146      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:13.699406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:14.699509      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:15.700464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:16.700554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:17.700713      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: changing the label value of the configmap back @ 12/02/23 13:26:18.195
  STEP: modifying the configmap a third time @ 12/02/23 13:26:18.206
  STEP: deleting the configmap @ 12/02/23 13:26:18.214
  STEP: Expecting to observe an add notification for the watched object when the label value was restored @ 12/02/23 13:26:18.22
  Dec  2 13:26:18.220: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-580  56b10df7-9c6c-42c2-b2fa-eb987c2a0a91 32083 0 2023-12-02 13:26:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-02 13:26:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:26:18.220: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-580  56b10df7-9c6c-42c2-b2fa-eb987c2a0a91 32084 0 2023-12-02 13:26:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-02 13:26:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:26:18.221: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-580  56b10df7-9c6c-42c2-b2fa-eb987c2a0a91 32085 0 2023-12-02 13:26:08 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2023-12-02 13:26:18 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
  Dec  2 13:26:18.221: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "watch-580" for this suite. @ 12/02/23 13:26:18.225
• [10.090 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should apply changes to a job status [Conformance]
test/e2e/apps/job.go:642
  STEP: Creating a kubernetes client @ 12/02/23 13:26:18.234
  Dec  2 13:26:18.234: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename job @ 12/02/23 13:26:18.235
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:26:18.254
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:26:18.256
  STEP: Creating a job @ 12/02/23 13:26:18.259
  STEP: Ensure pods equal to parallelism count is attached to the job @ 12/02/23 13:26:18.264
  E1202 13:26:18.701751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:19.701842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 12/02/23 13:26:20.267
  STEP: updating /status @ 12/02/23 13:26:20.275
  STEP: get /status @ 12/02/23 13:26:20.281
  Dec  2 13:26:20.288: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-5577" for this suite. @ 12/02/23 13:26:20.291
• [2.063 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:194
  STEP: Creating a kubernetes client @ 12/02/23 13:26:20.299
  Dec  2 13:26:20.299: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:26:20.299
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:26:20.317
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:26:20.32
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:26:20.322
  E1202 13:26:20.702721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:21.702794      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:22.703309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:23.703354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:26:24.349
  Dec  2 13:26:24.352: INFO: Trying to get logs from node ip-172-31-74-39 pod downwardapi-volume-092b4447-82c8-4fb2-8bb5-810a2fe0ffd5 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:26:24.358
  Dec  2 13:26:24.377: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9474" for this suite. @ 12/02/23 13:26:24.381
• [4.088 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:350
  STEP: Creating a kubernetes client @ 12/02/23 13:26:24.387
  Dec  2 13:26:24.387: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename field-validation @ 12/02/23 13:26:24.388
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:26:24.405
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:26:24.408
  Dec  2 13:26:24.410: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  W1202 13:26:24.411449      18 field_validation.go:423] props: &JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{spec: {  <nil>  object   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[cronSpec:{  <nil>  string   nil <nil> false <nil> false <nil> <nil> ^(\d+|\*)(/\d+)?(\s+(\d+|\*)(/\d+)?){4}$ <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} foo:{  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []} ports:{  <nil>  array   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] &JSONSchemaPropsOrArray{Schema:&JSONSchemaProps{ID:,Schema:,Ref:nil,Description:,Type:object,Format:,Title:,Default:nil,Maximum:nil,ExclusiveMaximum:false,Minimum:nil,ExclusiveMinimum:false,MaxLength:nil,MinLength:nil,Pattern:,MaxItems:nil,MinItems:nil,UniqueItems:false,MultipleOf:nil,Enum:[]JSON{},MaxProperties:nil,MinProperties:nil,Required:[containerPort protocol],Items:nil,AllOf:[]JSONSchemaProps{},OneOf:[]JSONSchemaProps{},AnyOf:[]JSONSchemaProps{},Not:nil,Properties:map[string]JSONSchemaProps{containerPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostIP: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},hostPort: {  <nil>  integer int32  nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},name: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},protocol: {  <nil>  string   nil <nil> false <nil> false <nil> <nil>  <nil> <nil> false <nil> [] <nil> <nil> [] nil [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},},JSONSchemas:[]JSONSchemaProps{},} [] [] [] nil map[] nil map[] map[] nil map[] nil nil false <nil> false false [containerPort protocol] 0xc0013c4410 <nil> []}] nil map[] map[] nil map[] nil nil false <nil> false false [] <nil> <nil> []},},AdditionalProperties:nil,PatternProperties:map[string]JSONSchemaProps{},Dependencies:JSONSchemaDependencies{},AdditionalItems:nil,Definitions:JSONSchemaDefinitions{},ExternalDocs:nil,Example:nil,Nullable:false,XPreserveUnknownFields:nil,XEmbeddedResource:false,XIntOrString:false,XListMapKeys:[],XListType:nil,XMapType:nil,XValidations:[]ValidationRule{},}
  E1202 13:26:24.703372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:25.703751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:26.703845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  W1202 13:26:26.974158      18 warnings.go:70] unknown field "alpha"
  W1202 13:26:26.974177      18 warnings.go:70] unknown field "beta"
  W1202 13:26:26.974181      18 warnings.go:70] unknown field "delta"
  W1202 13:26:26.974184      18 warnings.go:70] unknown field "epsilon"
  W1202 13:26:26.974188      18 warnings.go:70] unknown field "gamma"
  Dec  2 13:26:27.499: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-1953" for this suite. @ 12/02/23 13:26:27.514
• [3.133 seconds]
------------------------------
SSSS
------------------------------
[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:198
  STEP: Creating a kubernetes client @ 12/02/23 13:26:27.524
  Dec  2 13:26:27.524: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 13:26:27.525
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:26:27.54
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:26:27.542
  STEP: Creating pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836 @ 12/02/23 13:26:27.545
  E1202 13:26:27.704630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:28.704721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: checking the pod's current state and verifying that restartCount is present @ 12/02/23 13:26:29.561
  Dec  2 13:26:29.564: INFO: Initial restart count of pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd is 0
  Dec  2 13:26:29.567: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:29.704798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:30.704890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:31.571: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:31.705640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:32.705908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:33.574: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:33.706946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:34.707102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:35.578: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:35.707736      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:36.707837      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:37.583: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:37.708230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:38.708382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:39.586: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:39.708469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:40.708741      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:41.590: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:41.709015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:42.709091      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:43.594: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:43.709659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:44.709845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:45.598: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:45.710605      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:46.711290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:47.602: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:47.712131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:48.712314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:49.608: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  Dec  2 13:26:49.608: INFO: Restart count of pod container-probe-3836/liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd is now 1 (20.043780436s elapsed)
  E1202 13:26:49.712743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:50.712916      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:51.613: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:51.713169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:52.714015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:53.616: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:53.714885      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:54.715471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:55.620: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:55.715952      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:56.716040      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:57.629: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:57.716375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:26:58.716529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:26:59.634: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:26:59.716618      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:00.716818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:01.638: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:01.717834      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:02.718442      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:03.642: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:03.719217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:04.719375      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:05.646: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:05.719651      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:06.719797      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:07.650: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:07.720582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:08.720664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:09.655: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  Dec  2 13:27:09.655: INFO: Restart count of pod container-probe-3836/liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd is now 2 (40.090563042s elapsed)
  E1202 13:27:09.721518      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:10.721619      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:11.658: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:11.722072      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:12.722217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:13.662: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:13.722509      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:14.723286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:15.667: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:15.723293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:16.723592      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:17.671: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:17.724256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:18.724358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:19.674: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:19.724854      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:20.725052      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:21.679: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:21.725330      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:22.725431      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:23.682: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:23.725828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:24.725933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:25.687: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:25.726195      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:26.726293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:27.690: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:27.726437      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:28.726543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:29.695: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  Dec  2 13:27:29.695: INFO: Restart count of pod container-probe-3836/liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd is now 3 (1m0.131007021s elapsed)
  E1202 13:27:29.726966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:30.727974      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:31.699: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:31.728247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:32.728999      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:33.729462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:33.777: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:34.730233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:35.730309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:35.781: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:36.731288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:37.731386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:37.787: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:38.731473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:39.731639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:39.791: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:40.731777      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:41.731874      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:41.796: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:42.732307      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:43.732532      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:43.799: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:44.732640      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:45.733419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:45.803: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:46.733562      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:47.733737      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:47.808: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:48.734231      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:49.734293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:49.813: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  Dec  2 13:27:49.813: INFO: Restart count of pod container-probe-3836/liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd is now 4 (1m20.248427124s elapsed)
  E1202 13:27:50.734822      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:51.734931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:51.817: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:52.735240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:53.735605      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:53.821: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:54.735704      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:55.736782      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:55.825: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:56.736853      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:57.736945      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:57.829: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:27:58.737026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:27:59.737193      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:27:59.833: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:00.738025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:01.738208      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:01.837: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:02.738243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:03.739296      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:03.842: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:04.740301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:05.740439      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:05.846: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:06.740529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:07.740618      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:07.850: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:08.740714      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:09.740796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:09.854: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:10.741663      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:11.741770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:11.859: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:12.741855      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:13.741955      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:13.863: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:14.742233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:15.742309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:15.867: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:16.742482      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:17.742567      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:17.873: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:18.742986      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:19.743057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:19.877: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:20.743851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:21.743974      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:21.880: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:22.744301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:23.744394      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:23.884: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:24.744421      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:25.744604      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:25.889: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:26.744678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:27.745464      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:27.894: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:28.745964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:29.746051      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:29.898: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:30.746858      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:31.746976      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:31.901: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:32.747082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:33.747560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:33.905: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:34.747642      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:35.748556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:35.910: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:36.748643      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:37.749645      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:37.914: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:38.750070      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:39.750225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:39.918: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:40.751285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:41.751469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:41.922: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:42.752246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:43.752340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:43.926: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:44.752489      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:45.753474      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:45.931: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:46.754288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:47.754381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:47.937: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:48.754461      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:49.755440      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:49.941: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:50.755803      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:51.755697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:51.945: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:52.756182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:53.756539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:53.949: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:54.756625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:55.756715      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:55.954: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:56.757387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:57.757476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:57.958: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  E1202 13:28:58.758473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:28:59.759283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:28:59.962: INFO: Get pod liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd in namespace container-probe-3836
  Dec  2 13:28:59.962: INFO: Restart count of pod container-probe-3836/liveness-6d9de38f-4062-4b53-88b0-9ec743639cdd is now 5 (2m30.397863786s elapsed)
  Dec  2 13:28:59.962: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:28:59.965
  STEP: Destroying namespace "container-probe-3836" for this suite. @ 12/02/23 13:28:59.98
• [152.461 seconds]
------------------------------
SSS
------------------------------
[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
test/e2e/network/endpointslice.go:104
  STEP: Creating a kubernetes client @ 12/02/23 13:28:59.986
  Dec  2 13:28:59.986: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename endpointslice @ 12/02/23 13:28:59.987
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:29:00.004
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:29:00.007
  E1202 13:29:00.759856      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:01.759964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:29:02.053: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-3995" for this suite. @ 12/02/23 13:29:02.057
• [2.078 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]
test/e2e/apps/cronjob.go:161
  STEP: Creating a kubernetes client @ 12/02/23 13:29:02.065
  Dec  2 13:29:02.065: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename cronjob @ 12/02/23 13:29:02.065
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:29:02.083
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:29:02.085
  STEP: Creating a ReplaceConcurrent cronjob @ 12/02/23 13:29:02.098
  STEP: Ensuring a job is scheduled @ 12/02/23 13:29:02.104
  E1202 13:29:02.760057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:03.760151      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:04.760211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:05.760611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:06.760692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:07.760791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:08.760876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:09.760972      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:10.761831      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:11.761916      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:12.762231      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:13.763299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:14.763399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:15.763493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:16.763584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:17.763676      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:18.763769      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:19.763862      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:20.764580      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:21.764659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:22.764850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:23.765372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:24.765475      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:25.765507      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:26.765598      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:27.765841      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:28.766236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:29.766337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:30.766714      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:31.767299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:32.767388      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:33.767476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:34.768309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:35.768404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:36.768718      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:37.768899      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:38.768987      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:39.769089      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:40.769106      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:41.769212      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:42.769285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:43.769479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:44.769568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:45.769923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:46.770232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:47.771288      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:48.772358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:49.772531      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:50.772819      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:51.772910      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:52.773003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:53.773075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:54.773174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:55.773269      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:56.773360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:57.773866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:58.774232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:29:59.775295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:00.775579      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:01.775840      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Ensuring exactly one is scheduled @ 12/02/23 13:30:02.108
  STEP: Ensuring exactly one running job exists by listing jobs explicitly @ 12/02/23 13:30:02.112
  STEP: Ensuring the job is replaced with a new one @ 12/02/23 13:30:02.115
  E1202 13:30:02.776306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:03.776828      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:04.776908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:05.777815      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:06.777901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:07.778582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:08.779292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:09.779380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:10.779492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:11.779608      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:12.779688      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:13.779774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:14.779864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:15.780809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:16.781066      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:17.781156      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:18.781234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:19.781322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:20.781369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:21.781404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:22.781498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:23.781700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:24.781791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:25.782860      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:26.782946      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:27.783278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:28.783381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:29.783567      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:30.784252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:31.784373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:32.784932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:33.785313      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:34.785404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:35.785517      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:36.785607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:37.785770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:38.786433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:39.787314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:40.787803      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:41.788057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:42.788187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:43.788273      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:44.789230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:45.789309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:46.789765      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:47.789855      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:48.790906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:49.791301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:50.791630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:51.791503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:52.791789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:53.791954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:54.792264      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:55.793196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:56.793565      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:57.793656      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:58.794211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:30:59.795276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Removing cronjob @ 12/02/23 13:31:00.125
  Dec  2 13:31:00.136: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "cronjob-4355" for this suite. @ 12/02/23 13:31:00.145
• [118.088 seconds]
------------------------------
SSSSSS
------------------------------
[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
test/e2e/apps/job.go:430
  STEP: Creating a kubernetes client @ 12/02/23 13:31:00.153
  Dec  2 13:31:00.153: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename job @ 12/02/23 13:31:00.153
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:00.176
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:00.178
  STEP: Creating a job @ 12/02/23 13:31:00.183
  STEP: Ensuring job reaches completions @ 12/02/23 13:31:00.188
  E1202 13:31:00.796133      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:01.796170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:02.796249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:03.796310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:04.796706      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:05.796781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:06.797189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:07.797277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:08.797334      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:09.797512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:31:10.192: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-7113" for this suite. @ 12/02/23 13:31:10.195
• [10.049 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
test/e2e/common/storage/secrets_volume.go:99
  STEP: Creating a kubernetes client @ 12/02/23 13:31:10.203
  Dec  2 13:31:10.203: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:31:10.203
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:10.22
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:10.222
  STEP: Creating secret with name secret-test-30effe98-5b41-4675-b2de-b05a36e6dcbd @ 12/02/23 13:31:10.245
  STEP: Creating a pod to test consume secrets @ 12/02/23 13:31:10.25
  E1202 13:31:10.798428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:11.798609      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:12.798948      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:13.799034      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:31:14.271
  Dec  2 13:31:14.275: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-secrets-94e0969b-fd22-4e29-bd52-8b5c4a6bbf2a container secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 13:31:14.292
  Dec  2 13:31:14.307: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-5041" for this suite. @ 12/02/23 13:31:14.312
  STEP: Destroying namespace "secret-namespace-4453" for this suite. @ 12/02/23 13:31:14.318
• [4.121 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services should find a service from listing all namespaces [Conformance]
test/e2e/network/service.go:3117
  STEP: Creating a kubernetes client @ 12/02/23 13:31:14.325
  Dec  2 13:31:14.325: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:31:14.325
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:14.343
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:14.345
  STEP: fetching services @ 12/02/23 13:31:14.347
  Dec  2 13:31:14.352: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-915" for this suite. @ 12/02/23 13:31:14.355
• [0.036 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment deployment should support proportional scaling [Conformance]
test/e2e/apps/deployment.go:160
  STEP: Creating a kubernetes client @ 12/02/23 13:31:14.362
  Dec  2 13:31:14.362: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 13:31:14.363
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:14.382
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:14.384
  Dec  2 13:31:14.386: INFO: Creating deployment "webserver-deployment"
  Dec  2 13:31:14.391: INFO: Waiting for observed generation 1
  E1202 13:31:14.799681      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:15.799998      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:31:16.399: INFO: Waiting for all required pods to come up
  Dec  2 13:31:16.402: INFO: Pod name httpd: Found 10 pods out of 10
  STEP: ensuring each pod is running @ 12/02/23 13:31:16.402
  Dec  2 13:31:16.402: INFO: Waiting for deployment "webserver-deployment" to complete
  Dec  2 13:31:16.408: INFO: Updating deployment "webserver-deployment" with a non-existent image
  Dec  2 13:31:16.416: INFO: Updating deployment webserver-deployment
  Dec  2 13:31:16.416: INFO: Waiting for observed generation 2
  E1202 13:31:16.800721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:17.801768      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:31:18.422: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
  Dec  2 13:31:18.425: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
  Dec  2 13:31:18.428: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec  2 13:31:18.437: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
  Dec  2 13:31:18.437: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
  Dec  2 13:31:18.439: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
  Dec  2 13:31:18.445: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
  Dec  2 13:31:18.445: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
  Dec  2 13:31:18.455: INFO: Updating deployment webserver-deployment
  Dec  2 13:31:18.455: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
  Dec  2 13:31:18.460: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
  Dec  2 13:31:18.463: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
  Dec  2 13:31:18.482: INFO: Deployment "webserver-deployment":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=20) "webserver-deployment",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6e94230d-a293-44fc-aaaa-2fd6ea188cfd",
      ResourceVersion: (string) (len=5) "33385",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=1) {
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=541) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 22  2e 22 3a 7b 7d 2c 22 6b  |ions":{".":{},"k|
              00000090  3a 7b 5c 22 74 79 70 65  5c 22 3a 5c 22 41 76 61  |:{\"type\":\"Ava|
              000000a0  69 6c 61 62 6c 65 5c 22  7d 22 3a 7b 22 2e 22 3a  |ilable\"}":{".":|
              000000b0  7b 7d 2c 22 66 3a 6c 61  73 74 54 72 61 6e 73 69  |{},"f:lastTransi|
              000000c0  74 69 6f 6e 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |tionTime":{},"f:|
              000000d0  6c 61 73 74 55 70 64 61  74 65 54 69 6d 65 22 3a  |lastUpdateTime":|
              000000e0  7b 7d 2c 22 66 3a 6d 65  73 73 61 67 65 22 3a 7b  |{},"f:message":{|
              000000f0  7d 2c 22 66 3a 72 65 61  73 6f 6e 22 3a 7b 7d 2c  |},"f:reason":{},|
              00000100  22 66 3a 73 74 61 74 75  73 22 3a 7b 7d 2c 22 66  |"f:status":{},"f|
              00000110  3a 74 79 70 65 22 3a 7b  7d 7d 2c 22 6b 3a 7b 5c  |:type":{}},"k:{\|
              00000120  22 74 79 70 65 5c 22 3a  5c 22 50 72 6f 67 72 65  |"type\":\"Progre|
              00000130  73 73 69 6e 67 5c 22 7d  22 3a 7b 22 2e 22 3a 7b  |ssing\"}":{".":{|
              00000140  7d 2c 22 66 3a 6c 61 73  74 54 72 61 6e 73 69 74  |},"f:lastTransit|
              00000150  69 6f 6e 54 69 6d 65 22  3a 7b 7d 2c 22 66 3a 6c  |ionTime":{},"f:l|
              00000160  61 73 74 55 70 64 61 74  65 54 69 6d 65 22 3a 7b  |astUpdateTime":{|
              00000170  7d 2c 22 66 3a 6d 65 73  73 61 67 65 22 3a 7b 7d  |},"f:message":{}|
              00000180  2c 22 66 3a 72 65 61 73  6f 6e 22 3a 7b 7d 2c 22  |,"f:reason":{},"|
              00000190  66 3a 73 74 61 74 75 73  22 3a 7b 7d 2c 22 66 3a  |f:status":{},"f:|
              000001a0  74 79 70 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 6f 62  |type":{}}},"f:ob|
              000001b0  73 65 72 76 65 64 47 65  6e 65 72 61 74 69 6f 6e  |servedGeneration|
              000001c0  22 3a 7b 7d 2c 22 66 3a  72 65 61 64 79 52 65 70  |":{},"f:readyRep|
              000001d0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 72 65 70  |licas":{},"f:rep|
              000001e0  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 75 6e 61  |licas":{},"f:una|
              000001f0  76 61 69 6c 61 62 6c 65  52 65 70 6c 69 63 61 73  |vailableReplicas|
              00000200  22 3a 7b 7d 2c 22 66 3a  75 70 64 61 74 65 64 52  |":{},"f:updatedR|
              00000210  65 70 6c 69 63 61 73 22  3a 7b 7d 7d 7d           |eplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=635) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 7d 7d 2c  |},"f:name":{}}},|
              00000030  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 70 72 6f  |"f:spec":{"f:pro|
              00000040  67 72 65 73 73 44 65 61  64 6c 69 6e 65 53 65 63  |gressDeadlineSec|
              00000050  6f 6e 64 73 22 3a 7b 7d  2c 22 66 3a 72 65 70 6c  |onds":{},"f:repl|
              00000060  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 72 65 76 69  |icas":{},"f:revi|
              00000070  73 69 6f 6e 48 69 73 74  6f 72 79 4c 69 6d 69 74  |sionHistoryLimit|
              00000080  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000090  22 3a 7b 7d 2c 22 66 3a  73 74 72 61 74 65 67 79  |":{},"f:strategy|
              000000a0  22 3a 7b 22 66 3a 72 6f  6c 6c 69 6e 67 55 70 64  |":{"f:rollingUpd|
              000000b0  61 74 65 22 3a 7b 22 2e  22 3a 7b 7d 2c 22 66 3a  |ate":{".":{},"f:|
              000000c0  6d 61 78 53 75 72 67 65  22 3a 7b 7d 2c 22 66 3a  |maxSurge":{},"f:|
              000000d0  6d 61 78 55 6e 61 76 61  69 6c 61 62 6c 65 22 3a  |maxUnavailable":|
              000000e0  7b 7d 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |{}},"f:type":{}}|
              000000f0  2c 22 66 3a 74 65 6d 70  6c 61 74 65 22 3a 7b 22  |,"f:template":{"|
              00000100  66 3a 6d 65 74 61 64 61  74 61 22 3a 7b 22 66 3a  |f:metadata":{"f:|
              00000110  6c 61 62 65 6c 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |labels":{".":{},|
              00000120  22 66 3a 6e 61 6d 65 22  3a 7b 7d 7d 7d 2c 22 66  |"f:name":{}}},"f|
              00000130  3a 73 70 65 63 22 3a 7b  22 66 3a 63 6f 6e 74 61  |:spec":{"f:conta|
              00000140  69 6e 65 72 73 22 3a 7b  22 6b 3a 7b 5c 22 6e 61  |iners":{"k:{\"na|
              00000150  6d 65 5c 22 3a 5c 22 68  74 74 70 64 5c 22 7d 22  |me\":\"httpd\"}"|
              00000160  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 69 6d 61 67  |:{".":{},"f:imag|
              00000170  65 22 3a 7b 7d 2c 22 66  3a 69 6d 61 67 65 50 75  |e":{},"f:imagePu|
              00000180  6c 6c 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |llPolicy":{},"f:|
              00000190  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 72 65 73 6f  |name":{},"f:reso|
              000001a0  75 72 63 65 73 22 3a 7b  7d 2c 22 66 3a 73 65 63  |urces":{},"f:sec|
              000001b0  75 72 69 74 79 43 6f 6e  74 65 78 74 22 3a 7b 7d  |urityContext":{}|
              000001c0  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              000001d0  65 73 73 61 67 65 50 61  74 68 22 3a 7b 7d 2c 22  |essagePath":{},"|
              000001e0  66 3a 74 65 72 6d 69 6e  61 74 69 6f 6e 4d 65 73  |f:terminationMes|
              000001f0  73 61 67 65 50 6f 6c 69  63 79 22 3a 7b 7d 7d 7d  |sagePolicy":{}}}|
              00000200  2c 22 66 3a 64 6e 73 50  6f 6c 69 63 79 22 3a 7b  |,"f:dnsPolicy":{|
              00000210  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              00000220  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              00000230  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000270  6e 64 73 22 3a 7b 7d 7d  7d 7d 7d                 |nds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(30),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=1) {
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=1) {
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 2,
            StrVal: (string) ""
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 0,
            IntVal: (int32) 3,
            StrVal: (string) ""
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 2,
      Replicas: (int32) 13,
      UpdatedReplicas: (int32) 5,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      UnavailableReplicas: (int32) 5,
      Conditions: ([]v1.DeploymentCondition) (len=2) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=9) "Available",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=24) "MinimumReplicasAvailable",
          Message: (string) (len=36) "Deployment has minimum availability."
        },
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=11) "Progressing",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=17) "ReplicaSetUpdated",
          Message: (string) (len=59) "ReplicaSet \"webserver-deployment-9b4f5bf69\" is progressing."
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  2 13:31:18.487: INFO: New ReplicaSet "webserver-deployment-9b4f5bf69" of Deployment "webserver-deployment":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "406fda8f-23c1-45cc-8de8-f06c9832a1b5",
      ResourceVersion: (string) (len=5) "33389",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "2"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "6e94230d-a293-44fc-aaaa-2fd6ea188cfd",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=84) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  66 75 6c 6c 79 4c 61 62  65 6c 65 64 52 65 70 6c  |fullyLabeledRepl|
              00000020  69 63 61 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |icas":{},"f:obse|
              00000030  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              00000040  7b 7d 2c 22 66 3a 72 65  70 6c 69 63 61 73 22 3a  |{},"f:replicas":|
              00000050  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 65 39 34 32 33  30 64 2d 61 32 39 33 2d  |\"6e94230d-a293-|
              00000120  34 34 66 63 2d 61 61 61  61 2d 32 66 64 36 65 61  |44fc-aaaa-2fd6ea|
              00000130  31 38 38 63 66 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |188cfd\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(13),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
          (string) (len=4) "name": (string) (len=5) "httpd"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=13) "webserver:404",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 5,
      FullyLabeledReplicas: (int32) 5,
      ReadyReplicas: (int32) 0,
      AvailableReplicas: (int32) 0,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 13:31:18.489: INFO: All old ReplicaSets of Deployment "webserver-deployment":
  Dec  2 13:31:18.489: INFO: (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=31) "webserver-deployment-557759b7c7",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
      ResourceVersion: (string) (len=5) "33386",
      Generation: (int64) 3,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=2) "30",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=2) "33",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=20) "webserver-deployment",
          UID: (types.UID) (len=36) "6e94230d-a293-44fc-aaaa-2fd6ea188cfd",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=781) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 6e 61 6d  65 22 3a 7b 7d 2c 22 66  |},"f:name":{},"f|
              000000d0  3a 70 6f 64 2d 74 65 6d  70 6c 61 74 65 2d 68 61  |:pod-template-ha|
              000000e0  73 68 22 3a 7b 7d 7d 2c  22 66 3a 6f 77 6e 65 72  |sh":{}},"f:owner|
              000000f0  52 65 66 65 72 65 6e 63  65 73 22 3a 7b 22 2e 22  |References":{"."|
              00000100  3a 7b 7d 2c 22 6b 3a 7b  5c 22 75 69 64 5c 22 3a  |:{},"k:{\"uid\":|
              00000110  5c 22 36 65 39 34 32 33  30 64 2d 61 32 39 33 2d  |\"6e94230d-a293-|
              00000120  34 34 66 63 2d 61 61 61  61 2d 32 66 64 36 65 61  |44fc-aaaa-2fd6ea|
              00000130  31 38 38 63 66 64 5c 22  7d 22 3a 7b 7d 7d 7d 2c  |188cfd\"}":{}}},|
              00000140  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 72 65 70  |"f:spec":{"f:rep|
              00000150  6c 69 63 61 73 22 3a 7b  7d 2c 22 66 3a 73 65 6c  |licas":{},"f:sel|
              00000160  65 63 74 6f 72 22 3a 7b  7d 2c 22 66 3a 74 65 6d  |ector":{},"f:tem|
              00000170  70 6c 61 74 65 22 3a 7b  22 66 3a 6d 65 74 61 64  |plate":{"f:metad|
              00000180  61 74 61 22 3a 7b 22 66  3a 6c 61 62 65 6c 73 22  |ata":{"f:labels"|
              00000190  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6e 61 6d 65  |:{".":{},"f:name|
              000001a0  22 3a 7b 7d 2c 22 66 3a  70 6f 64 2d 74 65 6d 70  |":{},"f:pod-temp|
              000001b0  6c 61 74 65 2d 68 61 73  68 22 3a 7b 7d 7d 7d 2c  |late-hash":{}}},|
              000001c0  22 66 3a 73 70 65 63 22  3a 7b 22 66 3a 63 6f 6e  |"f:spec":{"f:con|
              000001d0  74 61 69 6e 65 72 73 22  3a 7b 22 6b 3a 7b 5c 22  |tainers":{"k:{\"|
              000001e0  6e 61 6d 65 5c 22 3a 5c  22 68 74 74 70 64 5c 22  |name\":\"httpd\"|
              000001f0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 6d  |}":{".":{},"f:im|
              00000200  61 67 65 22 3a 7b 7d 2c  22 66 3a 69 6d 61 67 65  |age":{},"f:image|
              00000210  50 75 6c 6c 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |PullPolicy":{},"|
              00000220  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 72 65  |f:name":{},"f:re|
              00000230  73 6f 75 72 63 65 73 22  3a 7b 7d 2c 22 66 3a 73  |sources":{},"f:s|
              00000240  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              00000250  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000260  6e 4d 65 73 73 61 67 65  50 61 74 68 22 3a 7b 7d  |nMessagePath":{}|
              00000270  2c 22 66 3a 74 65 72 6d  69 6e 61 74 69 6f 6e 4d  |,"f:terminationM|
              00000280  65 73 73 61 67 65 50 6f  6c 69 63 79 22 3a 7b 7d  |essagePolicy":{}|
              00000290  7d 7d 2c 22 66 3a 64 6e  73 50 6f 6c 69 63 79 22  |}},"f:dnsPolicy"|
              000002a0  3a 7b 7d 2c 22 66 3a 72  65 73 74 61 72 74 50 6f  |:{},"f:restartPo|
              000002b0  6c 69 63 79 22 3a 7b 7d  2c 22 66 3a 73 63 68 65  |licy":{},"f:sche|
              000002c0  64 75 6c 65 72 4e 61 6d  65 22 3a 7b 7d 2c 22 66  |dulerName":{},"f|
              000002d0  3a 73 65 63 75 72 69 74  79 43 6f 6e 74 65 78 74  |:securityContext|
              000002e0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              000002f0  69 6f 6e 47 72 61 63 65  50 65 72 69 6f 64 53 65  |ionGracePeriodSe|
              00000300  63 6f 6e 64 73 22 3a 7b  7d 7d 7d 7d 7d           |conds":{}}}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(20),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 8,
      FullyLabeledReplicas: (int32) 8,
      ReadyReplicas: (int32) 8,
      AvailableReplicas: (int32) 8,
      ObservedGeneration: (int64) 2,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 13:31:18.495: INFO: Pod "webserver-deployment-557759b7c7-2mnr6" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-2mnr6",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "7d4c1e33-15ec-4dda-bc42-722b99f898a7",
      ResourceVersion: (string) (len=5) "33399",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120678,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-lrnl4",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-lrnl4",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.496: INFO: Pod "webserver-deployment-557759b7c7-5c8pp" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-5c8pp",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "04205e5d-047b-41ee-844d-c853137e7b0f",
      ResourceVersion: (string) (len=5) "33390",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120678,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-f9x6n",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-f9x6n",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.501: INFO: Pod "webserver-deployment-557759b7c7-b6h52" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-b6h52",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f5155304-4d60-42ba-b4ac-c149314daf25",
      ResourceVersion: (string) (len=5) "33261",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  39 35 2e 31 38 32 5c 22  |192.168.95.182\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-c29n8",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-c29n8",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-89-192",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.89.192",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.95.182",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.95.182"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d17e91a65f3eeca742d42c00a7174eb19aad20375f49e51629b721c5dfb76f8a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.502: INFO: Pod "webserver-deployment-557759b7c7-d59xf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-d59xf",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "3620c6cf-0821-4ad3-a6d0-b23d2ee214ca",
      ResourceVersion: (string) (len=5) "33270",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 33 30 2e 35 36 5c 22  |192.168.230.56\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-gmkpt",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-gmkpt",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.230.56",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.230.56"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d62af7df577ca7db2f0fc7c1ae6140e9506bc638c21b48c1f5f0e63c8c80e451",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.504: INFO: Pod "webserver-deployment-557759b7c7-g7fl9" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-g7fl9",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "8a173191-f881-447e-b74a-c48f9eab26e9",
      ResourceVersion: (string) (len=5) "33273",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 33 30 2e 35 33 5c 22  |192.168.230.53\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-shwp7",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-shwp7",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.230.53",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.230.53"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b79d7201b5e6980af0edcd02d03b543c8788c085d4f341e92162b12c0166a0c7",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.505: INFO: Pod "webserver-deployment-557759b7c7-hs9kb" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-hs9kb",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "449fb240-6f4b-4088-8615-ec741e102945",
      ResourceVersion: (string) (len=5) "33264",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  39 35 2e 31 38 33 5c 22  |192.168.95.183\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-hlkh6",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-hlkh6",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-89-192",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.89.192",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.95.183",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.95.183"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://b3acf17e51b1f899fa482ed965fdddc0545a702aea72b9c0245e7e303bd61d11",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.506: INFO: Pod "webserver-deployment-557759b7c7-jvb79" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-jvb79",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6e015235-0360-400e-8567-0466e9dd2f85",
      ResourceVersion: (string) (len=5) "33254",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 31 2e 32 33 31 5c 22  |192.168.21.231\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-r4kkw",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-r4kkw",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.231",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.231"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://ef878f1791eb76665a8c54c074cbe68c55ecb2e8d77dfade96abe9fdbc543726",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.511: INFO: Pod "webserver-deployment-557759b7c7-kzvlh" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-kzvlh",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "32e0b9fb-b58b-434f-b879-76a4de518cf1",
      ResourceVersion: (string) (len=5) "33258",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  39 35 2e 31 38 34 5c 22  |192.168.95.184\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-d4vzq",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-d4vzq",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-89-192",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.89.192",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.95.184",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.95.184"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://d845fbc341b2cba62fc91f75b28770110a74f99ac675c8a336a535e9da3f3a5a",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.516: INFO: Pod "webserver-deployment-557759b7c7-rrjvc" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-rrjvc",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "949e909a-c480-4014-8e16-7cd7c4efdca3",
      ResourceVersion: (string) (len=5) "33393",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120678,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-xkn2p",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-xkn2p",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) "",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) <nil>,
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.521: INFO: Pod "webserver-deployment-557759b7c7-sgjnk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-sgjnk",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "20b98a56-e111-488d-8619-c0ecd4f06261",
      ResourceVersion: (string) (len=5) "33251",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 31 2e 32 34 30 5c 22  |192.168.21.240\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-rv65q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-rv65q",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.240",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.240"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f8f8b948a9f245620e5545014895a7fe411a86813f3b29138814f30eeca5a82b",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.524: INFO: Pod "webserver-deployment-557759b7c7-wfdsf" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=37) "webserver-deployment-557759b7c7-wfdsf",
      GenerateName: (string) (len=32) "webserver-deployment-557759b7c7-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "99b39a79-13d1-47e5-af2d-7a02a1317e23",
      ResourceVersion: (string) (len=5) "33248",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "557759b7c7"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=31) "webserver-deployment-557759b7c7",
          UID: (types.UID) (len=36) "4618c8ec-65a0-4135-9ef1-205c16e519b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 36  31 38 63 38 65 63 2d 36  |d\":\"4618c8ec-6|
              00000090  35 61 30 2d 34 31 33 35  2d 39 65 66 31 2d 32 30  |5a0-4135-9ef1-20|
              000000a0  35 63 31 36 65 35 31 39  62 35 5c 22 7d 22 3a 7b  |5c16e519b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 31 2e 32 34 32 5c 22  |192.168.21.242\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-29lwj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-29lwj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120675,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120674,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.242",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.242"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120674,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120675,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://f44e063dc997d8456b36b81a16833544c396610da243d5846ca2886d3ef71db0",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.525: INFO: Pod "webserver-deployment-9b4f5bf69-55n2t" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-55n2t",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "fbd80866-0ea3-4a30-a06e-c0132da27a24",
      ResourceVersion: (string) (len=5) "33397",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120678,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "406fda8f-23c1-45cc-8de8-f06c9832a1b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=1) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  36 66 64 61 38 66 2d 32  |d\":\"406fda8f-2|
              00000090  33 63 31 2d 34 35 63 63  2d 38 64 65 38 2d 66 30  |3c1-45cc-8de8-f0|
              000000a0  36 63 39 38 33 32 61 31  62 35 5c 22 7d 22 3a 7b  |6c9832a1b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-npr4q",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-npr4q",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-89-192",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=1) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) "",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) "",
      PodIPs: ([]v1.PodIP) <nil>,
      StartTime: (*v1.Time)(<nil>),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) <nil>,
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.526: INFO: Pod "webserver-deployment-9b4f5bf69-6zj2j" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-6zj2j",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f126a469-ad0f-49f5-b4f4-b2006478a1a4",
      ResourceVersion: (string) (len=5) "33374",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "406fda8f-23c1-45cc-8de8-f06c9832a1b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  36 66 64 61 38 66 2d 32  |d\":\"406fda8f-2|
              00000090  33 63 31 2d 34 35 63 63  2d 38 64 65 38 2d 66 30  |3c1-45cc-8de8-f0|
              000000a0  36 63 39 38 33 32 61 31  62 35 5c 22 7d 22 3a 7b  |6c9832a1b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120677,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=566) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 32 31 2e  32 34 33 5c 22 7d 22 3a  |.168.21.243\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000220  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000230  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-fwlpj",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-fwlpj",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.243",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.243"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.527: INFO: Pod "webserver-deployment-9b4f5bf69-bsvq5" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-bsvq5",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "1c130f2e-f372-484f-8321-95fa9d618eb4",
      ResourceVersion: (string) (len=5) "33383",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "406fda8f-23c1-45cc-8de8-f06c9832a1b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  36 66 64 61 38 66 2d 32  |d\":\"406fda8f-2|
              00000090  33 63 31 2d 34 35 63 63  2d 38 64 65 38 2d 66 30  |3c1-45cc-8de8-f0|
              000000a0  36 63 39 38 33 32 61 31  62 35 5c 22 7d 22 3a 7b  |6c9832a1b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=566) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 32 33 30  2e 35 35 5c 22 7d 22 3a  |.168.230.55\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000220  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000230  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-ttghn",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-ttghn",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.230.55",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.230.55"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.536: INFO: Pod "webserver-deployment-9b4f5bf69-l6569" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-l6569",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6cf75a38-86a6-4bbb-bd20-ef745924430b",
      ResourceVersion: (string) (len=5) "33380",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "406fda8f-23c1-45cc-8de8-f06c9832a1b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  36 66 64 61 38 66 2d 32  |d\":\"406fda8f-2|
              00000090  33 63 31 2d 34 35 63 63  2d 38 64 65 38 2d 66 30  |3c1-45cc-8de8-f0|
              000000a0  36 63 39 38 33 32 61 31  62 35 5c 22 7d 22 3a 7b  |6c9832a1b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=566) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 32 33 30  2e 35 37 5c 22 7d 22 3a  |.168.230.57\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000220  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000230  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-2hjnc",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-2hjnc",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.230.57",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.230.57"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.541: INFO: Pod "webserver-deployment-9b4f5bf69-ndm9c" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-ndm9c",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "6addb49f-527a-44cc-bd14-4b7247377e6c",
      ResourceVersion: (string) (len=5) "33378",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "406fda8f-23c1-45cc-8de8-f06c9832a1b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  36 66 64 61 38 66 2d 32  |d\":\"406fda8f-2|
              00000090  33 63 31 2d 34 35 63 63  2d 38 64 65 38 2d 66 30  |3c1-45cc-8de8-f0|
              000000a0  36 63 39 38 33 32 61 31  62 35 5c 22 7d 22 3a 7b  |6c9832a1b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120678,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=566) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 39 35 2e  31 38 35 5c 22 7d 22 3a  |.168.95.185\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000220  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000230  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-dstsm",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-dstsm",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=16) "ip-172-31-89-192",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=13) "172.31.89.192",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.95.185",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.95.185"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.542: INFO: Pod "webserver-deployment-9b4f5bf69-nt8ff" is not available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=36) "webserver-deployment-9b4f5bf69-nt8ff",
      GenerateName: (string) (len=31) "webserver-deployment-9b4f5bf69-",
      Namespace: (string) (len=14) "deployment-500",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "f2801f7c-1fc0-46a8-bc44-7215f103017b",
      ResourceVersion: (string) (len=5) "33372",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=9) "9b4f5bf69"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=30) "webserver-deployment-9b4f5bf69",
          UID: (types.UID) (len=36) "406fda8f-23c1-45cc-8de8-f06c9832a1b5",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=537) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |.":{},"f:name":{|
              00000040  7d 2c 22 66 3a 70 6f 64  2d 74 65 6d 70 6c 61 74  |},"f:pod-templat|
              00000050  65 2d 68 61 73 68 22 3a  7b 7d 7d 2c 22 66 3a 6f  |e-hash":{}},"f:o|
              00000060  77 6e 65 72 52 65 66 65  72 65 6e 63 65 73 22 3a  |wnerReferences":|
              00000070  7b 22 2e 22 3a 7b 7d 2c  22 6b 3a 7b 5c 22 75 69  |{".":{},"k:{\"ui|
              00000080  64 5c 22 3a 5c 22 34 30  36 66 64 61 38 66 2d 32  |d\":\"406fda8f-2|
              00000090  33 63 31 2d 34 35 63 63  2d 38 64 65 38 2d 66 30  |3c1-45cc-8de8-f0|
              000000a0  36 63 39 38 33 32 61 31  62 35 5c 22 7d 22 3a 7b  |6c9832a1b5\"}":{|
              000000b0  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              000000c0  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              000000d0  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              000000e0  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              000000f0  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000100  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              00000110  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              00000120  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              00000130  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              00000140  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              00000150  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              00000160  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000170  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000180  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000190  69 63 79 22 3a 7b 7d 2c  22 66 3a 65 6e 61 62 6c  |icy":{},"f:enabl|
              000001a0  65 53 65 72 76 69 63 65  4c 69 6e 6b 73 22 3a 7b  |eServiceLinks":{|
              000001b0  7d 2c 22 66 3a 72 65 73  74 61 72 74 50 6f 6c 69  |},"f:restartPoli|
              000001c0  63 79 22 3a 7b 7d 2c 22  66 3a 73 63 68 65 64 75  |cy":{},"f:schedu|
              000001d0  6c 65 72 4e 61 6d 65 22  3a 7b 7d 2c 22 66 3a 73  |lerName":{},"f:s|
              000001e0  65 63 75 72 69 74 79 43  6f 6e 74 65 78 74 22 3a  |ecurityContext":|
              000001f0  7b 7d 2c 22 66 3a 74 65  72 6d 69 6e 61 74 69 6f  |{},"f:terminatio|
              00000200  6e 47 72 61 63 65 50 65  72 69 6f 64 53 65 63 6f  |nGracePeriodSeco|
              00000210  6e 64 73 22 3a 7b 7d 7d  7d                       |nds":{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120677,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=566) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 6d 65 73 73 61 67  |me":{},"f:messag|
              00000080  65 22 3a 7b 7d 2c 22 66  3a 72 65 61 73 6f 6e 22  |e":{},"f:reason"|
              00000090  3a 7b 7d 2c 22 66 3a 73  74 61 74 75 73 22 3a 7b  |:{},"f:status":{|
              000000a0  7d 2c 22 66 3a 74 79 70  65 22 3a 7b 7d 7d 2c 22  |},"f:type":{}},"|
              000000b0  6b 3a 7b 5c 22 74 79 70  65 5c 22 3a 5c 22 49 6e  |k:{\"type\":\"In|
              000000c0  69 74 69 61 6c 69 7a 65  64 5c 22 7d 22 3a 7b 22  |itialized\"}":{"|
              000000d0  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 50 72 6f  |.":{},"f:lastPro|
              000000e0  62 65 54 69 6d 65 22 3a  7b 7d 2c 22 66 3a 6c 61  |beTime":{},"f:la|
              000000f0  73 74 54 72 61 6e 73 69  74 69 6f 6e 54 69 6d 65  |stTransitionTime|
              00000100  22 3a 7b 7d 2c 22 66 3a  73 74 61 74 75 73 22 3a  |":{},"f:status":|
              00000110  7b 7d 2c 22 66 3a 74 79  70 65 22 3a 7b 7d 7d 2c  |{},"f:type":{}},|
              00000120  22 6b 3a 7b 5c 22 74 79  70 65 5c 22 3a 5c 22 52  |"k:{\"type\":\"R|
              00000130  65 61 64 79 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |eady\"}":{".":{}|
              00000140  2c 22 66 3a 6c 61 73 74  50 72 6f 62 65 54 69 6d  |,"f:lastProbeTim|
              00000150  65 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |e":{},"f:lastTra|
              00000160  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000170  22 66 3a 6d 65 73 73 61  67 65 22 3a 7b 7d 2c 22  |"f:message":{},"|
              00000180  66 3a 72 65 61 73 6f 6e  22 3a 7b 7d 2c 22 66 3a  |f:reason":{},"f:|
              00000190  73 74 61 74 75 73 22 3a  7b 7d 2c 22 66 3a 74 79  |status":{},"f:ty|
              000001a0  70 65 22 3a 7b 7d 7d 7d  2c 22 66 3a 63 6f 6e 74  |pe":{}}},"f:cont|
              000001b0  61 69 6e 65 72 53 74 61  74 75 73 65 73 22 3a 7b  |ainerStatuses":{|
              000001c0  7d 2c 22 66 3a 68 6f 73  74 49 50 22 3a 7b 7d 2c  |},"f:hostIP":{},|
              000001d0  22 66 3a 70 6f 64 49 50  22 3a 7b 7d 2c 22 66 3a  |"f:podIP":{},"f:|
              000001e0  70 6f 64 49 50 73 22 3a  7b 22 2e 22 3a 7b 7d 2c  |podIPs":{".":{},|
              000001f0  22 6b 3a 7b 5c 22 69 70  5c 22 3a 5c 22 31 39 32  |"k:{\"ip\":\"192|
              00000200  2e 31 36 38 2e 32 31 2e  32 33 38 5c 22 7d 22 3a  |.168.21.238\"}":|
              00000210  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 69 70 22 3a 7b  |{".":{},"f:ip":{|
              00000220  7d 7d 7d 2c 22 66 3a 73  74 61 72 74 54 69 6d 65  |}}},"f:startTime|
              00000230  22 3a 7b 7d 7d 7d                                 |":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tpq8c",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=13) "webserver:404",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tpq8c",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=14) "ip-172-31-1-50",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Pending",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=5) "False",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) (len=18) "ContainersNotReady",
          Message: (string) (len=39) "containers with unready status: [httpd]"
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120676,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=11) "172.31.1.50",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.21.238",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.21.238"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120676,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)({
              Reason: (string) (len=12) "ErrImagePull",
              Message: (string) (len=262) "failed to pull and unpack image \"docker.io/library/webserver:404\": failed to resolve reference \"docker.io/library/webserver:404\": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed"
            }),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) false,
          RestartCount: (int32) 0,
          Image: (string) (len=13) "webserver:404",
          ImageID: (string) "",
          ContainerID: (string) "",
          Started: (*bool)(false),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:31:18.543: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-500" for this suite. @ 12/02/23 13:31:18.547
• [4.201 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]
test/e2e/common/node/expansion.go:95
  STEP: Creating a kubernetes client @ 12/02/23 13:31:18.564
  Dec  2 13:31:18.564: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 13:31:18.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:18.598
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:18.601
  STEP: Creating a pod to test substitution in container's args @ 12/02/23 13:31:18.603
  E1202 13:31:18.802189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:19.802242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:20.803299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:21.803432      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:31:22.63
  Dec  2 13:31:22.635: INFO: Trying to get logs from node ip-172-31-74-39 pod var-expansion-318139bc-04ca-4383-b670-52112c9af7d4 container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 13:31:22.642
  Dec  2 13:31:22.659: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9336" for this suite. @ 12/02/23 13:31:22.662
• [4.104 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]
test/e2e/common/storage/empty_dir.go:227
  STEP: Creating a kubernetes client @ 12/02/23 13:31:22.667
  Dec  2 13:31:22.667: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:31:22.668
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:22.683
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:22.685
  STEP: Creating Pod @ 12/02/23 13:31:22.688
  E1202 13:31:22.804287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:23.804418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Reading file content from the nginx-container @ 12/02/23 13:31:24.705
  Dec  2 13:31:24.705: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-2385 PodName:pod-sharedvolume-c43cee2b-ef03-436d-934b-bced5dca2e36 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:31:24.706: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:31:24.706: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:31:24.706: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-2385/pods/pod-sharedvolume-c43cee2b-ef03-436d-934b-bced5dca2e36/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
  Dec  2 13:31:24.803: INFO: Exec stderr: ""
  Dec  2 13:31:24.803: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1202 13:31:24.804404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "emptydir-2385" for this suite. @ 12/02/23 13:31:24.806
• [2.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]
test/e2e/storage/empty_dir_wrapper.go:67
  STEP: Creating a kubernetes client @ 12/02/23 13:31:24.816
  Dec  2 13:31:24.816: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir-wrapper @ 12/02/23 13:31:24.817
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:24.833
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:24.835
  E1202 13:31:25.805024      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:26.805107      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:31:26.865: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Cleaning up the secret @ 12/02/23 13:31:26.869
  STEP: Cleaning up the configmap @ 12/02/23 13:31:26.876
  STEP: Cleaning up the pod @ 12/02/23 13:31:26.882
  STEP: Destroying namespace "emptydir-wrapper-4478" for this suite. @ 12/02/23 13:31:26.894
• [2.087 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
test/e2e/scheduling/limit_range.go:61
  STEP: Creating a kubernetes client @ 12/02/23 13:31:26.903
  Dec  2 13:31:26.903: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename limitrange @ 12/02/23 13:31:26.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:26.918
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:26.921
  STEP: Creating a LimitRange @ 12/02/23 13:31:26.923
  STEP: Setting up watch @ 12/02/23 13:31:26.923
  STEP: Submitting a LimitRange @ 12/02/23 13:31:27.031
  STEP: Verifying LimitRange creation was observed @ 12/02/23 13:31:27.038
  STEP: Fetching the LimitRange to ensure it has proper values @ 12/02/23 13:31:27.038
  Dec  2 13:31:27.041: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec  2 13:31:27.041: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with no resource requirements @ 12/02/23 13:31:27.041
  STEP: Ensuring Pod has resource requirements applied from LimitRange @ 12/02/23 13:31:27.046
  Dec  2 13:31:27.049: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
  Dec  2 13:31:27.049: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Creating a Pod with partial resource requirements @ 12/02/23 13:31:27.049
  STEP: Ensuring Pod has merged resource requirements applied from LimitRange @ 12/02/23 13:31:27.056
  Dec  2 13:31:27.060: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
  Dec  2 13:31:27.060: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
  STEP: Failing to create a Pod with less than min resources @ 12/02/23 13:31:27.06
  STEP: Failing to create a Pod with more than max resources @ 12/02/23 13:31:27.062
  STEP: Updating a LimitRange @ 12/02/23 13:31:27.063
  STEP: Verifying LimitRange updating is effective @ 12/02/23 13:31:27.068
  E1202 13:31:27.805653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:28.805780      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Pod with less than former min resources @ 12/02/23 13:31:29.074
  STEP: Failing to create a Pod with more than max resources @ 12/02/23 13:31:29.08
  STEP: Deleting a LimitRange @ 12/02/23 13:31:29.082
  STEP: Verifying the LimitRange was deleted @ 12/02/23 13:31:29.089
  E1202 13:31:29.806230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:30.807281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:31.807435      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:32.807539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:33.807656      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:31:34.094: INFO: limitRange is already deleted
  STEP: Creating a Pod with more than former max resources @ 12/02/23 13:31:34.094
  Dec  2 13:31:34.101: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "limitrange-8651" for this suite. @ 12/02/23 13:31:34.105
• [7.209 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events should delete a collection of events [Conformance]
test/e2e/instrumentation/core_events.go:175
  STEP: Creating a kubernetes client @ 12/02/23 13:31:34.113
  Dec  2 13:31:34.113: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename events @ 12/02/23 13:31:34.114
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:34.132
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:34.134
  STEP: Create set of events @ 12/02/23 13:31:34.137
  Dec  2 13:31:34.154: INFO: created test-event-1
  Dec  2 13:31:34.158: INFO: created test-event-2
  Dec  2 13:31:34.162: INFO: created test-event-3
  STEP: get a list of Events with a label in the current namespace @ 12/02/23 13:31:34.162
  STEP: delete collection of events @ 12/02/23 13:31:34.166
  Dec  2 13:31:34.166: INFO: requesting DeleteCollection of events
  STEP: check that the list of events matches the requested quantity @ 12/02/23 13:31:34.19
  Dec  2 13:31:34.190: INFO: requesting list of events to confirm quantity
  Dec  2 13:31:34.194: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "events-1178" for this suite. @ 12/02/23 13:31:34.197
• [0.091 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]
test/e2e/apps/disruption.go:108
  STEP: Creating a kubernetes client @ 12/02/23 13:31:34.205
  Dec  2 13:31:34.205: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename disruption @ 12/02/23 13:31:34.206
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:34.223
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:34.226
  STEP: creating the pdb @ 12/02/23 13:31:34.228
  STEP: Waiting for the pdb to be processed @ 12/02/23 13:31:34.234
  E1202 13:31:34.807880      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:35.808845      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pdb @ 12/02/23 13:31:36.242
  STEP: Waiting for the pdb to be processed @ 12/02/23 13:31:36.251
  E1202 13:31:36.808936      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:37.809013      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching the pdb @ 12/02/23 13:31:38.259
  STEP: Waiting for the pdb to be processed @ 12/02/23 13:31:38.267
  E1202 13:31:38.810014      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:39.810121      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for the pdb to be deleted @ 12/02/23 13:31:40.28
  Dec  2 13:31:40.283: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-4910" for this suite. @ 12/02/23 13:31:40.287
• [6.089 seconds]
------------------------------
SSSS
------------------------------
[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:156
  STEP: Creating a kubernetes client @ 12/02/23 13:31:40.294
  Dec  2 13:31:40.294: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename runtimeclass @ 12/02/23 13:31:40.295
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:40.314
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:40.316
  STEP: Deleting RuntimeClass runtimeclass-4321-delete-me @ 12/02/23 13:31:40.322
  STEP: Waiting for the RuntimeClass to disappear @ 12/02/23 13:31:40.328
  Dec  2 13:31:40.337: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-4321" for this suite. @ 12/02/23 13:31:40.34
• [0.053 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
test/e2e/common/node/runtimeclass.go:104
  STEP: Creating a kubernetes client @ 12/02/23 13:31:40.348
  Dec  2 13:31:40.348: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename runtimeclass @ 12/02/23 13:31:40.348
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:40.365
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:40.367
  E1202 13:31:40.810804      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:41.811300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:31:42.393: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "runtimeclass-2989" for this suite. @ 12/02/23 13:31:42.404
• [2.064 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:117
  STEP: Creating a kubernetes client @ 12/02/23 13:31:42.413
  Dec  2 13:31:42.413: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:31:42.414
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:42.43
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:42.434
  STEP: Creating a pod to test emptydir 0777 on tmpfs @ 12/02/23 13:31:42.437
  E1202 13:31:42.811909      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:43.812788      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:44.812805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:45.812822      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:31:46.462
  Dec  2 13:31:46.466: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-00af29c9-d704-4d2f-a7a8-06617053b1f2 container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:31:46.487
  Dec  2 13:31:46.503: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-2084" for this suite. @ 12/02/23 13:31:46.508
• [4.103 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
test/e2e/common/storage/projected_configmap.go:375
  STEP: Creating a kubernetes client @ 12/02/23 13:31:46.517
  Dec  2 13:31:46.517: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:31:46.518
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:46.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:46.539
  STEP: Creating configMap with name projected-configmap-test-volume-af26b455-9005-4db6-a277-011e48587927 @ 12/02/23 13:31:46.544
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:31:46.549
  E1202 13:31:46.813468      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:47.814441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:48.815064      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:49.815155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:31:50.573
  Dec  2 13:31:50.576: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-projected-configmaps-721bf07a-7aa8-41d3-a67e-5c479c63a500 container projected-configmap-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 13:31:50.582
  Dec  2 13:31:50.599: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-8208" for this suite. @ 12/02/23 13:31:50.603
• [4.093 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]
test/e2e/kubectl/kubectl.go:830
  STEP: Creating a kubernetes client @ 12/02/23 13:31:50.612
  Dec  2 13:31:50.612: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:31:50.612
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:50.629
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:50.631
  STEP: validating api versions @ 12/02/23 13:31:50.633
  Dec  2 13:31:50.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1291 api-versions'
  Dec  2 13:31:50.679: INFO: stderr: ""
  Dec  2 13:31:50.679: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta2\nflowcontrol.apiserver.k8s.io/v1beta3\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nv1\n"
  Dec  2 13:31:50.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1291" for this suite. @ 12/02/23 13:31:50.682
• [0.078 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]
test/e2e/apimachinery/webhook.go:371
  STEP: Creating a kubernetes client @ 12/02/23 13:31:50.69
  Dec  2 13:31:50.690: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:31:50.691
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:31:50.706
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:31:50.708
  STEP: Setting up server cert @ 12/02/23 13:31:50.734
  E1202 13:31:50.815511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:31:51.029
  STEP: Deploying the webhook pod @ 12/02/23 13:31:51.038
  STEP: Wait for the deployment to be ready @ 12/02/23 13:31:51.049
  Dec  2 13:31:51.060: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:31:51.815604      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:52.815832      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:31:53.074
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:31:53.098
  E1202 13:31:53.815944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:31:54.098: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Setting timeout (1s) shorter than webhook latency (5s) @ 12/02/23 13:31:54.104
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/02/23 13:31:54.104
  STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) @ 12/02/23 13:31:54.123
  E1202 13:31:54.816355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore @ 12/02/23 13:31:55.137
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/02/23 13:31:55.137
  E1202 13:31:55.816394      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is longer than webhook latency @ 12/02/23 13:31:56.17
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/02/23 13:31:56.17
  E1202 13:31:56.816489      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:57.816582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:58.816742      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:31:59.816967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:00.817181      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Having no error when timeout is empty (defaulted to 10s in v1) @ 12/02/23 13:32:01.204
  STEP: Registering slow webhook via the AdmissionRegistration API @ 12/02/23 13:32:01.204
  E1202 13:32:01.818144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:02.818236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:03.818312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:04.818402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:05.818512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:06.235: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-3632" for this suite. @ 12/02/23 13:32:06.303
  STEP: Destroying namespace "webhook-markers-8937" for this suite. @ 12/02/23 13:32:06.309
• [15.627 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]
test/e2e/common/node/init_container.go:178
  STEP: Creating a kubernetes client @ 12/02/23 13:32:06.318
  Dec  2 13:32:06.318: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename init-container @ 12/02/23 13:32:06.318
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:06.334
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:06.336
  STEP: creating the pod @ 12/02/23 13:32:06.338
  Dec  2 13:32:06.338: INFO: PodSpec: initContainers in spec.initContainers
  E1202 13:32:06.819429      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:07.820114      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:08.821188      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:09.821906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:10.822948      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:10.884: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "init-container-8684" for this suite. @ 12/02/23 13:32:10.888
• [4.578 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]
test/e2e/apimachinery/webhook.go:221
  STEP: Creating a kubernetes client @ 12/02/23 13:32:10.896
  Dec  2 13:32:10.896: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:32:10.897
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:10.912
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:10.915
  STEP: Setting up server cert @ 12/02/23 13:32:10.939
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:32:11.307
  STEP: Deploying the webhook pod @ 12/02/23 13:32:11.312
  STEP: Wait for the deployment to be ready @ 12/02/23 13:32:11.324
  Dec  2 13:32:11.331: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:32:11.823130      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:12.823218      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:32:13.342
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:32:13.352
  E1202 13:32:13.823530      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:14.352: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  Dec  2 13:32:14.358: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:32:14.824395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Registering the custom resource webhook via the AdmissionRegistration API @ 12/02/23 13:32:14.869
  STEP: Creating a custom resource that should be denied by the webhook @ 12/02/23 13:32:14.882
  E1202 13:32:15.825271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:16.825381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a custom resource whose deletion would be denied by the webhook @ 12/02/23 13:32:16.903
  STEP: Updating the custom resource with disallowed data should be denied @ 12/02/23 13:32:16.909
  STEP: Deleting the custom resource should be denied @ 12/02/23 13:32:16.917
  STEP: Remove the offending key and value from the custom resource data @ 12/02/23 13:32:16.922
  STEP: Deleting the updated custom resource should be successful @ 12/02/23 13:32:16.934
  Dec  2 13:32:16.942: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-1021" for this suite. @ 12/02/23 13:32:17.506
  STEP: Destroying namespace "webhook-markers-7424" for this suite. @ 12/02/23 13:32:17.513
• [6.623 seconds]
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
test/e2e/common/node/containers.go:75
  STEP: Creating a kubernetes client @ 12/02/23 13:32:17.52
  Dec  2 13:32:17.520: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename containers @ 12/02/23 13:32:17.52
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:17.539
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:17.541
  STEP: Creating a pod to test override command @ 12/02/23 13:32:17.544
  E1202 13:32:17.826074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:18.826260      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:19.826808      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:20.827008      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:32:21.567
  Dec  2 13:32:21.570: INFO: Trying to get logs from node ip-172-31-1-50 pod client-containers-0554a7fe-6bcd-4e53-ae87-9760a4133082 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 13:32:21.576
  Dec  2 13:32:21.593: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "containers-4451" for this suite. @ 12/02/23 13:32:21.597
• [4.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]
test/e2e/kubectl/kubectl.go:1674
  STEP: Creating a kubernetes client @ 12/02/23 13:32:21.605
  Dec  2 13:32:21.605: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:32:21.606
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:21.625
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:21.628
  Dec  2 13:32:21.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-8122 version'
  Dec  2 13:32:21.672: INFO: stderr: ""
  Dec  2 13:32:21.672: INFO: stdout: "Client Version: v1.28.4\nKustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\nServer Version: v1.28.4\n"
  Dec  2 13:32:21.673: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-8122" for this suite. @ 12/02/23 13:32:21.677
• [0.079 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for services  [Conformance]
test/e2e/network/dns.go:137
  STEP: Creating a kubernetes client @ 12/02/23 13:32:21.685
  Dec  2 13:32:21.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 13:32:21.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:21.702
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:21.704
  STEP: Creating a test headless service @ 12/02/23 13:32:21.706
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8705.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8705.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8705.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8705.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 212.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.212_udp@PTR;check="$$(dig +tcp +noall +answer +search 212.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.212_tcp@PTR;sleep 1; done
   @ 12/02/23 13:32:21.725
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8705.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8705.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8705.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8705.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8705.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 212.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.212_udp@PTR;check="$$(dig +tcp +noall +answer +search 212.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.212_tcp@PTR;sleep 1; done
   @ 12/02/23 13:32:21.725
  STEP: creating a pod to probe DNS @ 12/02/23 13:32:21.726
  STEP: submitting the pod to kubernetes @ 12/02/23 13:32:21.726
  E1202 13:32:21.827414      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:22.828396      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/02/23 13:32:23.746
  STEP: looking for the results for each expected name from probers @ 12/02/23 13:32:23.75
  Dec  2 13:32:23.754: INFO: Unable to read wheezy_udp@dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.756: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.760: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.763: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.778: INFO: Unable to read jessie_udp@dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.780: INFO: Unable to read jessie_tcp@dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.783: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.787: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local from pod dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda: the server could not find the requested resource (get pods dns-test-456db5a8-65da-46e2-b826-0152fe30cfda)
  Dec  2 13:32:23.798: INFO: Lookups using dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda failed for: [wheezy_udp@dns-test-service.dns-8705.svc.cluster.local wheezy_tcp@dns-test-service.dns-8705.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local jessie_udp@dns-test-service.dns-8705.svc.cluster.local jessie_tcp@dns-test-service.dns-8705.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8705.svc.cluster.local]

  Dec  2 13:32:23.803: INFO: Pod client logs for webserver: 
  Dec  2 13:32:23.809: INFO: Pod client logs for querier: 
  Dec  2 13:32:23.815: INFO: Pod client logs for jessie-querier: 
  E1202 13:32:23.828648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:24.828774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:25.829724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:26.829811      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:27.829888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:28.829980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:28.863: INFO: DNS probes using dns-8705/dns-test-456db5a8-65da-46e2-b826-0152fe30cfda succeeded

  Dec  2 13:32:28.863: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:32:28.867
  STEP: deleting the test service @ 12/02/23 13:32:28.883
  STEP: deleting the test headless service @ 12/02/23 13:32:28.907
  STEP: Destroying namespace "dns-8705" for this suite. @ 12/02/23 13:32:28.919
• [7.242 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl logs logs should be able to retrieve and filter logs  [Conformance]
test/e2e/kubectl/logs.go:114
  STEP: Creating a kubernetes client @ 12/02/23 13:32:28.931
  Dec  2 13:32:28.931: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl-logs @ 12/02/23 13:32:28.932
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:28.947
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:28.95
  STEP: creating an pod @ 12/02/23 13:32:28.952
  Dec  2 13:32:28.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.45 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
  Dec  2 13:32:29.005: INFO: stderr: ""
  Dec  2 13:32:29.005: INFO: stdout: "pod/logs-generator created\n"
  STEP: Waiting for log generator to start. @ 12/02/23 13:32:29.005
  Dec  2 13:32:29.005: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
  E1202 13:32:29.830319      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:30.831291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:31.013: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
  STEP: checking for a matching strings @ 12/02/23 13:32:31.013
  Dec  2 13:32:31.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 logs logs-generator logs-generator'
  Dec  2 13:32:31.071: INFO: stderr: ""
  Dec  2 13:32:31.071: INFO: stdout: "I1202 13:32:29.665503       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/bkk 388\nI1202 13:32:29.865594       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/7pn 558\nI1202 13:32:30.066131       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/24c 553\nI1202 13:32:30.266420       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/vg7 578\nI1202 13:32:30.465651       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/ffb 455\nI1202 13:32:30.665939       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/95t 418\nI1202 13:32:30.866200       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/zhc 580\nI1202 13:32:31.066380       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/4jh9 385\n"
  STEP: limiting log lines @ 12/02/23 13:32:31.071
  Dec  2 13:32:31.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 logs logs-generator logs-generator --tail=1'
  Dec  2 13:32:31.126: INFO: stderr: ""
  Dec  2 13:32:31.126: INFO: stdout: "I1202 13:32:31.066380       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/4jh9 385\n"
  Dec  2 13:32:31.126: INFO: got output "I1202 13:32:31.066380       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/4jh9 385\n"
  STEP: limiting log bytes @ 12/02/23 13:32:31.126
  Dec  2 13:32:31.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 logs logs-generator logs-generator --limit-bytes=1'
  Dec  2 13:32:31.184: INFO: stderr: ""
  Dec  2 13:32:31.184: INFO: stdout: "I"
  Dec  2 13:32:31.184: INFO: got output "I"
  STEP: exposing timestamps @ 12/02/23 13:32:31.184
  Dec  2 13:32:31.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 logs logs-generator logs-generator --tail=1 --timestamps'
  Dec  2 13:32:31.239: INFO: stderr: ""
  Dec  2 13:32:31.239: INFO: stdout: "2023-12-02T13:32:31.066448664Z I1202 13:32:31.066380       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/4jh9 385\n"
  Dec  2 13:32:31.239: INFO: got output "2023-12-02T13:32:31.066448664Z I1202 13:32:31.066380       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/4jh9 385\n"
  STEP: restricting to a time range @ 12/02/23 13:32:31.239
  E1202 13:32:31.831785      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:32.831852      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:33.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 logs logs-generator logs-generator --since=1s'
  Dec  2 13:32:33.793: INFO: stderr: ""
  Dec  2 13:32:33.793: INFO: stdout: "I1202 13:32:32.865639       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/44tm 397\nI1202 13:32:33.065929       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/9mv 483\nI1202 13:32:33.266218       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/ncc 279\nI1202 13:32:33.466528       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/h5hv 329\nI1202 13:32:33.665799       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/ksq7 463\n"
  Dec  2 13:32:33.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 logs logs-generator logs-generator --since=24h'
  E1202 13:32:33.832456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:33.846: INFO: stderr: ""
  Dec  2 13:32:33.846: INFO: stdout: "I1202 13:32:29.665503       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/bkk 388\nI1202 13:32:29.865594       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/default/pods/7pn 558\nI1202 13:32:30.066131       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/24c 553\nI1202 13:32:30.266420       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/vg7 578\nI1202 13:32:30.465651       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/ffb 455\nI1202 13:32:30.665939       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/95t 418\nI1202 13:32:30.866200       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/zhc 580\nI1202 13:32:31.066380       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/4jh9 385\nI1202 13:32:31.265604       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/5g78 281\nI1202 13:32:31.465877       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/4cz 321\nI1202 13:32:31.666166       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/jvfn 281\nI1202 13:32:31.866306       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/7p8 533\nI1202 13:32:32.065542       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/269 231\nI1202 13:32:32.265840       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/whj 327\nI1202 13:32:32.466120       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/zcm7 365\nI1202 13:32:32.666409       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/7rv 436\nI1202 13:32:32.865639       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/44tm 397\nI1202 13:32:33.065929       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/9mv 483\nI1202 13:32:33.266218       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/ncc 279\nI1202 13:32:33.466528       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/h5hv 329\nI1202 13:32:33.665799       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/ksq7 463\n"
  Dec  2 13:32:33.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-logs-3565 delete pod logs-generator'
  Dec  2 13:32:34.807: INFO: stderr: ""
  Dec  2 13:32:34.807: INFO: stdout: "pod \"logs-generator\" deleted\n"
  Dec  2 13:32:34.807: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-logs-3565" for this suite. @ 12/02/23 13:32:34.81
• [5.885 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]
test/e2e/apps/disruption.go:164
  STEP: Creating a kubernetes client @ 12/02/23 13:32:34.817
  Dec  2 13:32:34.817: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename disruption @ 12/02/23 13:32:34.817
  E1202 13:32:34.832642      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:34.834
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:34.836
  STEP: Waiting for the pdb to be processed @ 12/02/23 13:32:34.844
  E1202 13:32:35.833097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:36.833169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Updating PodDisruptionBudget status @ 12/02/23 13:32:36.851
  STEP: Waiting for all pods to be running @ 12/02/23 13:32:36.858
  Dec  2 13:32:36.861: INFO: running pods: 0 < 1
  E1202 13:32:37.833382      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:38.833582      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: locating a running pod @ 12/02/23 13:32:38.865
  STEP: Waiting for the pdb to be processed @ 12/02/23 13:32:38.875
  STEP: Patching PodDisruptionBudget status @ 12/02/23 13:32:38.881
  STEP: Waiting for the pdb to be processed @ 12/02/23 13:32:38.89
  Dec  2 13:32:38.895: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "disruption-512" for this suite. @ 12/02/23 13:32:38.899
• [4.088 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]
test/e2e/apps/deployment.go:488
  STEP: Creating a kubernetes client @ 12/02/23 13:32:38.906
  Dec  2 13:32:38.906: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename deployment @ 12/02/23 13:32:38.906
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:38.926
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:38.928
  STEP: creating a Deployment @ 12/02/23 13:32:38.936
  Dec  2 13:32:38.936: INFO: Creating simple deployment test-deployment-pjtgb
  Dec  2 13:32:38.949: INFO: deployment "test-deployment-pjtgb" doesn't have the required revision set
  E1202 13:32:39.834258      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:40.834338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Getting /status @ 12/02/23 13:32:40.961
  Dec  2 13:32:40.964: INFO: Deployment test-deployment-pjtgb has Conditions: [{Available True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-pjtgb-5d576bd769" has successfully progressed.}]
  STEP: updating Deployment Status @ 12/02/23 13:32:40.964
  Dec  2 13:32:40.974: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 32, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 32, 40, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 32, 40, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 32, 38, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-pjtgb-5d576bd769\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the Deployment status to be updated @ 12/02/23 13:32:40.974
  Dec  2 13:32:40.976: INFO: Observed &Deployment event: ADDED
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-pjtgb-5d576bd769"}
  Dec  2 13:32:40.976: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-pjtgb-5d576bd769"}
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  2 13:32:40.976: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-pjtgb-5d576bd769" is progressing.}
  Dec  2 13:32:40.976: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-pjtgb-5d576bd769" has successfully progressed.}
  Dec  2 13:32:40.976: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  2 13:32:40.976: INFO: Observed Deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-pjtgb-5d576bd769" has successfully progressed.}
  Dec  2 13:32:40.976: INFO: Found Deployment test-deployment-pjtgb in namespace deployment-318 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  2 13:32:40.976: INFO: Deployment test-deployment-pjtgb has an updated status
  STEP: patching the Statefulset Status @ 12/02/23 13:32:40.976
  Dec  2 13:32:40.976: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec  2 13:32:40.982: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Deployment status to be patched @ 12/02/23 13:32:40.982
  Dec  2 13:32:40.984: INFO: Observed &Deployment event: ADDED
  Dec  2 13:32:40.984: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-pjtgb-5d576bd769"}
  Dec  2 13:32:40.984: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.984: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-pjtgb-5d576bd769"}
  Dec  2 13:32:40.984: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  2 13:32:40.984: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.984: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
  Dec  2 13:32:40.984: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:38 +0000 UTC 2023-12-02 13:32:38 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-pjtgb-5d576bd769" is progressing.}
  Dec  2 13:32:40.985: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.985: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  2 13:32:40.985: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-pjtgb-5d576bd769" has successfully progressed.}
  Dec  2 13:32:40.985: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.985: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:40 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
  Dec  2 13:32:40.985: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2023-12-02 13:32:40 +0000 UTC 2023-12-02 13:32:38 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-pjtgb-5d576bd769" has successfully progressed.}
  Dec  2 13:32:40.985: INFO: Observed deployment test-deployment-pjtgb in namespace deployment-318 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  2 13:32:40.985: INFO: Observed &Deployment event: MODIFIED
  Dec  2 13:32:40.985: INFO: Found deployment test-deployment-pjtgb in namespace deployment-318 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
  Dec  2 13:32:40.985: INFO: Deployment test-deployment-pjtgb has a patched status
  Dec  2 13:32:40.990: INFO: Deployment "test-deployment-pjtgb":
  (v1.Deployment) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=21) "test-deployment-pjtgb",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-318",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "9b30ed6f-e5dc-43e7-ab73-6c1e8ac2707f",
      ResourceVersion: (string) (len=5) "34637",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120758,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=2) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd"
      },
      Annotations: (map[string]string) (len=1) {
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) <nil>,
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=3) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120758,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=657) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              00000020  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              00000030  6e 61 6d 65 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |name":{}}},"f:sp|
              00000040  65 63 22 3a 7b 22 66 3a  70 72 6f 67 72 65 73 73  |ec":{"f:progress|
              00000050  44 65 61 64 6c 69 6e 65  53 65 63 6f 6e 64 73 22  |DeadlineSeconds"|
              00000060  3a 7b 7d 2c 22 66 3a 72  65 70 6c 69 63 61 73 22  |:{},"f:replicas"|
              00000070  3a 7b 7d 2c 22 66 3a 72  65 76 69 73 69 6f 6e 48  |:{},"f:revisionH|
              00000080  69 73 74 6f 72 79 4c 69  6d 69 74 22 3a 7b 7d 2c  |istoryLimit":{},|
              00000090  22 66 3a 73 65 6c 65 63  74 6f 72 22 3a 7b 7d 2c  |"f:selector":{},|
              000000a0  22 66 3a 73 74 72 61 74  65 67 79 22 3a 7b 22 66  |"f:strategy":{"f|
              000000b0  3a 72 6f 6c 6c 69 6e 67  55 70 64 61 74 65 22 3a  |:rollingUpdate":|
              000000c0  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6d 61 78 53 75  |{".":{},"f:maxSu|
              000000d0  72 67 65 22 3a 7b 7d 2c  22 66 3a 6d 61 78 55 6e  |rge":{},"f:maxUn|
              000000e0  61 76 61 69 6c 61 62 6c  65 22 3a 7b 7d 7d 2c 22  |available":{}},"|
              000000f0  66 3a 74 79 70 65 22 3a  7b 7d 7d 2c 22 66 3a 74  |f:type":{}},"f:t|
              00000100  65 6d 70 6c 61 74 65 22  3a 7b 22 66 3a 6d 65 74  |emplate":{"f:met|
              00000110  61 64 61 74 61 22 3a 7b  22 66 3a 6c 61 62 65 6c  |adata":{"f:label|
              00000120  73 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 65 32  |s":{".":{},"f:e2|
              00000130  65 22 3a 7b 7d 2c 22 66  3a 6e 61 6d 65 22 3a 7b  |e":{},"f:name":{|
              00000140  7d 7d 7d 2c 22 66 3a 73  70 65 63 22 3a 7b 22 66  |}}},"f:spec":{"f|
              00000150  3a 63 6f 6e 74 61 69 6e  65 72 73 22 3a 7b 22 6b  |:containers":{"k|
              00000160  3a 7b 5c 22 6e 61 6d 65  5c 22 3a 5c 22 68 74 74  |:{\"name\":\"htt|
              00000170  70 64 5c 22 7d 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |pd\"}":{".":{},"|
              00000180  66 3a 69 6d 61 67 65 22  3a 7b 7d 2c 22 66 3a 69  |f:image":{},"f:i|
              00000190  6d 61 67 65 50 75 6c 6c  50 6f 6c 69 63 79 22 3a  |magePullPolicy":|
              000001a0  7b 7d 2c 22 66 3a 6e 61  6d 65 22 3a 7b 7d 2c 22  |{},"f:name":{},"|
              000001b0  66 3a 72 65 73 6f 75 72  63 65 73 22 3a 7b 7d 2c  |f:resources":{},|
              000001c0  22 66 3a 73 65 63 75 72  69 74 79 43 6f 6e 74 65  |"f:securityConte|
              000001d0  78 74 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |xt":{},"f:termin|
              000001e0  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 61 74 68  |ationMessagePath|
              000001f0  22 3a 7b 7d 2c 22 66 3a  74 65 72 6d 69 6e 61 74  |":{},"f:terminat|
              00000200  69 6f 6e 4d 65 73 73 61  67 65 50 6f 6c 69 63 79  |ionMessagePolicy|
              00000210  22 3a 7b 7d 7d 7d 2c 22  66 3a 64 6e 73 50 6f 6c  |":{}}},"f:dnsPol|
              00000220  69 63 79 22 3a 7b 7d 2c  22 66 3a 72 65 73 74 61  |icy":{},"f:resta|
              00000230  72 74 50 6f 6c 69 63 79  22 3a 7b 7d 2c 22 66 3a  |rtPolicy":{},"f:|
              00000240  73 63 68 65 64 75 6c 65  72 4e 61 6d 65 22 3a 7b  |schedulerName":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 47  72 61 63 65 50 65 72 69  |inationGracePeri|
              00000280  6f 64 53 65 63 6f 6e 64  73 22 3a 7b 7d 7d 7d 7d  |odSeconds":{}}}}|
              00000290  7d                                                |}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=8) "e2e.test",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120760,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=147) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 53 74 61 74  |{\"type\":\"Stat|
              00000030  75 73 50 61 74 63 68 65  64 5c 22 7d 22 3a 7b 22  |usPatched\"}":{"|
              00000040  2e 22 3a 7b 7d 2c 22 66  3a 6c 61 73 74 54 72 61  |.":{},"f:lastTra|
              00000050  6e 73 69 74 69 6f 6e 54  69 6d 65 22 3a 7b 7d 2c  |nsitionTime":{},|
              00000060  22 66 3a 6c 61 73 74 55  70 64 61 74 65 54 69 6d  |"f:lastUpdateTim|
              00000070  65 22 3a 7b 7d 2c 22 66  3a 73 74 61 74 75 73 22  |e":{},"f:status"|
              00000080  3a 7b 7d 2c 22 66 3a 74  79 70 65 22 3a 7b 7d 7d  |:{},"f:type":{}}|
              00000090  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120760,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=224) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 72 65 76 69 73  69 6f 6e 22 3a 7b 7d 7d  |io/revision":{}}|
              00000050  7d 2c 22 66 3a 73 74 61  74 75 73 22 3a 7b 22 66  |},"f:status":{"f|
              00000060  3a 61 76 61 69 6c 61 62  6c 65 52 65 70 6c 69 63  |:availableReplic|
              00000070  61 73 22 3a 7b 7d 2c 22  66 3a 63 6f 6e 64 69 74  |as":{},"f:condit|
              00000080  69 6f 6e 73 22 3a 7b 7d  2c 22 66 3a 6f 62 73 65  |ions":{},"f:obse|
              00000090  72 76 65 64 47 65 6e 65  72 61 74 69 6f 6e 22 3a  |rvedGeneration":|
              000000a0  7b 7d 2c 22 66 3a 72 65  61 64 79 52 65 70 6c 69  |{},"f:readyRepli|
              000000b0  63 61 73 22 3a 7b 7d 2c  22 66 3a 72 65 70 6c 69  |cas":{},"f:repli|
              000000c0  63 61 73 22 3a 7b 7d 2c  22 66 3a 75 70 64 61 74  |cas":{},"f:updat|
              000000d0  65 64 52 65 70 6c 69 63  61 73 22 3a 7b 7d 7d 7d  |edReplicas":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.DeploymentSpec) {
      Replicas: (*int32)(1),
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=2) {
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=3) "e2e": (string) (len=7) "testing"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=2) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      },
      Strategy: (v1.DeploymentStrategy) {
        Type: (v1.DeploymentStrategyType) (len=13) "RollingUpdate",
        RollingUpdate: (*v1.RollingUpdateDeployment)({
          MaxUnavailable: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          }),
          MaxSurge: (*intstr.IntOrString)({
            Type: (intstr.Type) 1,
            IntVal: (int32) 0,
            StrVal: (string) (len=3) "25%"
          })
        })
      },
      MinReadySeconds: (int32) 0,
      RevisionHistoryLimit: (*int32)(10),
      Paused: (bool) false,
      ProgressDeadlineSeconds: (*int32)(600)
    },
    Status: (v1.DeploymentStatus) {
      ObservedGeneration: (int64) 1,
      Replicas: (int32) 1,
      UpdatedReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      UnavailableReplicas: (int32) 0,
      Conditions: ([]v1.DeploymentCondition) (len=1) {
        (v1.DeploymentCondition) {
          Type: (v1.DeploymentConditionType) (len=13) "StatusPatched",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastUpdateTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      CollisionCount: (*int32)(<nil>)
    }
  }


  Dec  2 13:32:40.997: INFO: New ReplicaSet "test-deployment-pjtgb-5d576bd769" of Deployment "test-deployment-pjtgb":
  (v1.ReplicaSet) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=32) "test-deployment-pjtgb-5d576bd769",
      GenerateName: (string) "",
      Namespace: (string) (len=14) "deployment-318",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "28755ec8-1230-4765-8c6d-8a28ca3f83e9",
      ResourceVersion: (string) (len=5) "34634",
      Generation: (int64) 1,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120758,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) (len=3) {
        (string) (len=41) "deployment.kubernetes.io/desired-replicas": (string) (len=1) "1",
        (string) (len=37) "deployment.kubernetes.io/max-replicas": (string) (len=1) "2",
        (string) (len=33) "deployment.kubernetes.io/revision": (string) (len=1) "1"
      },
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "Deployment",
          Name: (string) (len=21) "test-deployment-pjtgb",
          UID: (types.UID) (len=36) "9b30ed6f-e5dc-43e7-ab73-6c1e8ac2707f",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120758,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=803) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 61 6e 6e 6f 74 61  74 69 6f 6e 73 22 3a 7b  |f:annotations":{|
              00000020  22 2e 22 3a 7b 7d 2c 22  66 3a 64 65 70 6c 6f 79  |".":{},"f:deploy|
              00000030  6d 65 6e 74 2e 6b 75 62  65 72 6e 65 74 65 73 2e  |ment.kubernetes.|
              00000040  69 6f 2f 64 65 73 69 72  65 64 2d 72 65 70 6c 69  |io/desired-repli|
              00000050  63 61 73 22 3a 7b 7d 2c  22 66 3a 64 65 70 6c 6f  |cas":{},"f:deplo|
              00000060  79 6d 65 6e 74 2e 6b 75  62 65 72 6e 65 74 65 73  |yment.kubernetes|
              00000070  2e 69 6f 2f 6d 61 78 2d  72 65 70 6c 69 63 61 73  |.io/max-replicas|
              00000080  22 3a 7b 7d 2c 22 66 3a  64 65 70 6c 6f 79 6d 65  |":{},"f:deployme|
              00000090  6e 74 2e 6b 75 62 65 72  6e 65 74 65 73 2e 69 6f  |nt.kubernetes.io|
              000000a0  2f 72 65 76 69 73 69 6f  6e 22 3a 7b 7d 7d 2c 22  |/revision":{}},"|
              000000b0  66 3a 6c 61 62 65 6c 73  22 3a 7b 22 2e 22 3a 7b  |f:labels":{".":{|
              000000c0  7d 2c 22 66 3a 65 32 65  22 3a 7b 7d 2c 22 66 3a  |},"f:e2e":{},"f:|
              000000d0  6e 61 6d 65 22 3a 7b 7d  2c 22 66 3a 70 6f 64 2d  |name":{},"f:pod-|
              000000e0  74 65 6d 70 6c 61 74 65  2d 68 61 73 68 22 3a 7b  |template-hash":{|
              000000f0  7d 7d 2c 22 66 3a 6f 77  6e 65 72 52 65 66 65 72  |}},"f:ownerRefer|
              00000100  65 6e 63 65 73 22 3a 7b  22 2e 22 3a 7b 7d 2c 22  |ences":{".":{},"|
              00000110  6b 3a 7b 5c 22 75 69 64  5c 22 3a 5c 22 39 62 33  |k:{\"uid\":\"9b3|
              00000120  30 65 64 36 66 2d 65 35  64 63 2d 34 33 65 37 2d  |0ed6f-e5dc-43e7-|
              00000130  61 62 37 33 2d 36 63 31  65 38 61 63 32 37 30 37  |ab73-6c1e8ac2707|
              00000140  66 5c 22 7d 22 3a 7b 7d  7d 7d 2c 22 66 3a 73 70  |f\"}":{}}},"f:sp|
              00000150  65 63 22 3a 7b 22 66 3a  72 65 70 6c 69 63 61 73  |ec":{"f:replicas|
              00000160  22 3a 7b 7d 2c 22 66 3a  73 65 6c 65 63 74 6f 72  |":{},"f:selector|
              00000170  22 3a 7b 7d 2c 22 66 3a  74 65 6d 70 6c 61 74 65  |":{},"f:template|
              00000180  22 3a 7b 22 66 3a 6d 65  74 61 64 61 74 61 22 3a  |":{"f:metadata":|
              00000190  7b 22 66 3a 6c 61 62 65  6c 73 22 3a 7b 22 2e 22  |{"f:labels":{"."|
              000001a0  3a 7b 7d 2c 22 66 3a 65  32 65 22 3a 7b 7d 2c 22  |:{},"f:e2e":{},"|
              000001b0  66 3a 6e 61 6d 65 22 3a  7b 7d 2c 22 66 3a 70 6f  |f:name":{},"f:po|
              000001c0  64 2d 74 65 6d 70 6c 61  74 65 2d 68 61 73 68 22  |d-template-hash"|
              000001d0  3a 7b 7d 7d 7d 2c 22 66  3a 73 70 65 63 22 3a 7b  |:{}}},"f:spec":{|
              000001e0  22 66 3a 63 6f 6e 74 61  69 6e 65 72 73 22 3a 7b  |"f:containers":{|
              000001f0  22 6b 3a 7b 5c 22 6e 61  6d 65 5c 22 3a 5c 22 68  |"k:{\"name\":\"h|
              00000200  74 74 70 64 5c 22 7d 22  3a 7b 22 2e 22 3a 7b 7d  |ttpd\"}":{".":{}|
              00000210  2c 22 66 3a 69 6d 61 67  65 22 3a 7b 7d 2c 22 66  |,"f:image":{},"f|
              00000220  3a 69 6d 61 67 65 50 75  6c 6c 50 6f 6c 69 63 79  |:imagePullPolicy|
              00000230  22 3a 7b 7d 2c 22 66 3a  6e 61 6d 65 22 3a 7b 7d  |":{},"f:name":{}|
              00000240  2c 22 66 3a 72 65 73 6f  75 72 63 65 73 22 3a 7b  |,"f:resources":{|
              00000250  7d 2c 22 66 3a 73 65 63  75 72 69 74 79 43 6f 6e  |},"f:securityCon|
              00000260  74 65 78 74 22 3a 7b 7d  2c 22 66 3a 74 65 72 6d  |text":{},"f:term|
              00000270  69 6e 61 74 69 6f 6e 4d  65 73 73 61 67 65 50 61  |inationMessagePa|
              00000280  74 68 22 3a 7b 7d 2c 22  66 3a 74 65 72 6d 69 6e  |th":{},"f:termin|
              00000290  61 74 69 6f 6e 4d 65 73  73 61 67 65 50 6f 6c 69  |ationMessagePoli|
              000002a0  63 79 22 3a 7b 7d 7d 7d  2c 22 66 3a 64 6e 73 50  |cy":{}}},"f:dnsP|
              000002b0  6f 6c 69 63 79 22 3a 7b  7d 2c 22 66 3a 72 65 73  |olicy":{},"f:res|
              000002c0  74 61 72 74 50 6f 6c 69  63 79 22 3a 7b 7d 2c 22  |tartPolicy":{},"|
              000002d0  66 3a 73 63 68 65 64 75  6c 65 72 4e 61 6d 65 22  |f:schedulerName"|
              000002e0  3a 7b 7d 2c 22 66 3a 73  65 63 75 72 69 74 79 43  |:{},"f:securityC|
              000002f0  6f 6e 74 65 78 74 22 3a  7b 7d 2c 22 66 3a 74 65  |ontext":{},"f:te|
              00000300  72 6d 69 6e 61 74 69 6f  6e 47 72 61 63 65 50 65  |rminationGracePe|
              00000310  72 69 6f 64 53 65 63 6f  6e 64 73 22 3a 7b 7d 7d  |riodSeconds":{}}|
              00000320  7d 7d 7d                                          |}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=7) "apps/v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120760,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=130) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  61 76 61 69 6c 61 62 6c  65 52 65 70 6c 69 63 61  |availableReplica|
              00000020  73 22 3a 7b 7d 2c 22 66  3a 66 75 6c 6c 79 4c 61  |s":{},"f:fullyLa|
              00000030  62 65 6c 65 64 52 65 70  6c 69 63 61 73 22 3a 7b  |beledReplicas":{|
              00000040  7d 2c 22 66 3a 6f 62 73  65 72 76 65 64 47 65 6e  |},"f:observedGen|
              00000050  65 72 61 74 69 6f 6e 22  3a 7b 7d 2c 22 66 3a 72  |eration":{},"f:r|
              00000060  65 61 64 79 52 65 70 6c  69 63 61 73 22 3a 7b 7d  |eadyReplicas":{}|
              00000070  2c 22 66 3a 72 65 70 6c  69 63 61 73 22 3a 7b 7d  |,"f:replicas":{}|
              00000080  7d 7d                                             |}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.ReplicaSetSpec) {
      Replicas: (*int32)(1),
      MinReadySeconds: (int32) 0,
      Selector: (*v1.LabelSelector)({
        MatchLabels: (map[string]string) (len=3) {
          (string) (len=3) "e2e": (string) (len=7) "testing",
          (string) (len=4) "name": (string) (len=5) "httpd",
          (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
        },
        MatchExpressions: ([]v1.LabelSelectorRequirement) <nil>
      }),
      Template: (v1.PodTemplateSpec) {
        ObjectMeta: (v1.ObjectMeta) {
          Name: (string) "",
          GenerateName: (string) "",
          Namespace: (string) "",
          SelfLink: (string) "",
          UID: (types.UID) "",
          ResourceVersion: (string) "",
          Generation: (int64) 0,
          CreationTimestamp: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          DeletionTimestamp: (*v1.Time)(<nil>),
          DeletionGracePeriodSeconds: (*int64)(<nil>),
          Labels: (map[string]string) (len=3) {
            (string) (len=3) "e2e": (string) (len=7) "testing",
            (string) (len=4) "name": (string) (len=5) "httpd",
            (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
          },
          Annotations: (map[string]string) <nil>,
          OwnerReferences: ([]v1.OwnerReference) <nil>,
          Finalizers: ([]string) <nil>,
          ManagedFields: ([]v1.ManagedFieldsEntry) <nil>
        },
        Spec: (v1.PodSpec) {
          Volumes: ([]v1.Volume) <nil>,
          InitContainers: ([]v1.Container) <nil>,
          Containers: ([]v1.Container) (len=1) {
            (v1.Container) {
              Name: (string) (len=5) "httpd",
              Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
              Command: ([]string) <nil>,
              Args: ([]string) <nil>,
              WorkingDir: (string) "",
              Ports: ([]v1.ContainerPort) <nil>,
              EnvFrom: ([]v1.EnvFromSource) <nil>,
              Env: ([]v1.EnvVar) <nil>,
              Resources: (v1.ResourceRequirements) {
                Limits: (v1.ResourceList) <nil>,
                Requests: (v1.ResourceList) <nil>,
                Claims: ([]v1.ResourceClaim) <nil>
              },
              ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
              RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
              VolumeMounts: ([]v1.VolumeMount) <nil>,
              VolumeDevices: ([]v1.VolumeDevice) <nil>,
              LivenessProbe: (*v1.Probe)(<nil>),
              ReadinessProbe: (*v1.Probe)(<nil>),
              StartupProbe: (*v1.Probe)(<nil>),
              Lifecycle: (*v1.Lifecycle)(<nil>),
              TerminationMessagePath: (string) (len=20) "/dev/termination-log",
              TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
              ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
              SecurityContext: (*v1.SecurityContext)({
                Capabilities: (*v1.Capabilities)(<nil>),
                Privileged: (*bool)(<nil>),
                SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
                WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
                RunAsUser: (*int64)(<nil>),
                RunAsGroup: (*int64)(<nil>),
                RunAsNonRoot: (*bool)(<nil>),
                ReadOnlyRootFilesystem: (*bool)(<nil>),
                AllowPrivilegeEscalation: (*bool)(<nil>),
                ProcMount: (*v1.ProcMountType)(<nil>),
                SeccompProfile: (*v1.SeccompProfile)(<nil>)
              }),
              Stdin: (bool) false,
              StdinOnce: (bool) false,
              TTY: (bool) false
            }
          },
          EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
          RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
          TerminationGracePeriodSeconds: (*int64)(0),
          ActiveDeadlineSeconds: (*int64)(<nil>),
          DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
          NodeSelector: (map[string]string) <nil>,
          ServiceAccountName: (string) "",
          DeprecatedServiceAccount: (string) "",
          AutomountServiceAccountToken: (*bool)(<nil>),
          NodeName: (string) "",
          HostNetwork: (bool) false,
          HostPID: (bool) false,
          HostIPC: (bool) false,
          ShareProcessNamespace: (*bool)(<nil>),
          SecurityContext: (*v1.PodSecurityContext)({
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            SupplementalGroups: ([]int64) <nil>,
            FSGroup: (*int64)(<nil>),
            Sysctls: ([]v1.Sysctl) <nil>,
            FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
          Hostname: (string) "",
          Subdomain: (string) "",
          Affinity: (*v1.Affinity)(<nil>),
          SchedulerName: (string) (len=17) "default-scheduler",
          Tolerations: ([]v1.Toleration) <nil>,
          HostAliases: ([]v1.HostAlias) <nil>,
          PriorityClassName: (string) "",
          Priority: (*int32)(<nil>),
          DNSConfig: (*v1.PodDNSConfig)(<nil>),
          ReadinessGates: ([]v1.PodReadinessGate) <nil>,
          RuntimeClassName: (*string)(<nil>),
          EnableServiceLinks: (*bool)(<nil>),
          PreemptionPolicy: (*v1.PreemptionPolicy)(<nil>),
          Overhead: (v1.ResourceList) <nil>,
          TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
          SetHostnameAsFQDN: (*bool)(<nil>),
          OS: (*v1.PodOS)(<nil>),
          HostUsers: (*bool)(<nil>),
          SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
          ResourceClaims: ([]v1.PodResourceClaim) <nil>
        }
      }
    },
    Status: (v1.ReplicaSetStatus) {
      Replicas: (int32) 1,
      FullyLabeledReplicas: (int32) 1,
      ReadyReplicas: (int32) 1,
      AvailableReplicas: (int32) 1,
      ObservedGeneration: (int64) 1,
      Conditions: ([]v1.ReplicaSetCondition) <nil>
    }
  }

  Dec  2 13:32:41.004: INFO: Pod "test-deployment-pjtgb-5d576bd769-4rwpk" is available:
  (v1.Pod) {
    TypeMeta: (v1.TypeMeta) {
      Kind: (string) "",
      APIVersion: (string) ""
    },
    ObjectMeta: (v1.ObjectMeta) {
      Name: (string) (len=38) "test-deployment-pjtgb-5d576bd769-4rwpk",
      GenerateName: (string) (len=33) "test-deployment-pjtgb-5d576bd769-",
      Namespace: (string) (len=14) "deployment-318",
      SelfLink: (string) "",
      UID: (types.UID) (len=36) "d25e24fa-f7e1-4501-86cb-bb7f8fd6da5e",
      ResourceVersion: (string) (len=5) "34633",
      Generation: (int64) 0,
      CreationTimestamp: (v1.Time) {
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120758,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      },
      DeletionTimestamp: (*v1.Time)(<nil>),
      DeletionGracePeriodSeconds: (*int64)(<nil>),
      Labels: (map[string]string) (len=3) {
        (string) (len=3) "e2e": (string) (len=7) "testing",
        (string) (len=4) "name": (string) (len=5) "httpd",
        (string) (len=17) "pod-template-hash": (string) (len=10) "5d576bd769"
      },
      Annotations: (map[string]string) <nil>,
      OwnerReferences: ([]v1.OwnerReference) (len=1) {
        (v1.OwnerReference) {
          APIVersion: (string) (len=7) "apps/v1",
          Kind: (string) (len=10) "ReplicaSet",
          Name: (string) (len=32) "test-deployment-pjtgb-5d576bd769",
          UID: (types.UID) (len=36) "28755ec8-1230-4765-8c6d-8a28ca3f83e9",
          Controller: (*bool)(true),
          BlockOwnerDeletion: (*bool)(true)
        }
      },
      Finalizers: ([]string) <nil>,
      ManagedFields: ([]v1.ManagedFieldsEntry) (len=2) {
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=23) "kube-controller-manager",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120758,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=548) {
              00000000  7b 22 66 3a 6d 65 74 61  64 61 74 61 22 3a 7b 22  |{"f:metadata":{"|
              00000010  66 3a 67 65 6e 65 72 61  74 65 4e 61 6d 65 22 3a  |f:generateName":|
              00000020  7b 7d 2c 22 66 3a 6c 61  62 65 6c 73 22 3a 7b 22  |{},"f:labels":{"|
              00000030  2e 22 3a 7b 7d 2c 22 66  3a 65 32 65 22 3a 7b 7d  |.":{},"f:e2e":{}|
              00000040  2c 22 66 3a 6e 61 6d 65  22 3a 7b 7d 2c 22 66 3a  |,"f:name":{},"f:|
              00000050  70 6f 64 2d 74 65 6d 70  6c 61 74 65 2d 68 61 73  |pod-template-has|
              00000060  68 22 3a 7b 7d 7d 2c 22  66 3a 6f 77 6e 65 72 52  |h":{}},"f:ownerR|
              00000070  65 66 65 72 65 6e 63 65  73 22 3a 7b 22 2e 22 3a  |eferences":{".":|
              00000080  7b 7d 2c 22 6b 3a 7b 5c  22 75 69 64 5c 22 3a 5c  |{},"k:{\"uid\":\|
              00000090  22 32 38 37 35 35 65 63  38 2d 31 32 33 30 2d 34  |"28755ec8-1230-4|
              000000a0  37 36 35 2d 38 63 36 64  2d 38 61 32 38 63 61 33  |765-8c6d-8a28ca3|
              000000b0  66 38 33 65 39 5c 22 7d  22 3a 7b 7d 7d 7d 2c 22  |f83e9\"}":{}}},"|
              000000c0  66 3a 73 70 65 63 22 3a  7b 22 66 3a 63 6f 6e 74  |f:spec":{"f:cont|
              000000d0  61 69 6e 65 72 73 22 3a  7b 22 6b 3a 7b 5c 22 6e  |ainers":{"k:{\"n|
              000000e0  61 6d 65 5c 22 3a 5c 22  68 74 74 70 64 5c 22 7d  |ame\":\"httpd\"}|
              000000f0  22 3a 7b 22 2e 22 3a 7b  7d 2c 22 66 3a 69 6d 61  |":{".":{},"f:ima|
              00000100  67 65 22 3a 7b 7d 2c 22  66 3a 69 6d 61 67 65 50  |ge":{},"f:imageP|
              00000110  75 6c 6c 50 6f 6c 69 63  79 22 3a 7b 7d 2c 22 66  |ullPolicy":{},"f|
              00000120  3a 6e 61 6d 65 22 3a 7b  7d 2c 22 66 3a 72 65 73  |:name":{},"f:res|
              00000130  6f 75 72 63 65 73 22 3a  7b 7d 2c 22 66 3a 73 65  |ources":{},"f:se|
              00000140  63 75 72 69 74 79 43 6f  6e 74 65 78 74 22 3a 7b  |curityContext":{|
              00000150  7d 2c 22 66 3a 74 65 72  6d 69 6e 61 74 69 6f 6e  |},"f:termination|
              00000160  4d 65 73 73 61 67 65 50  61 74 68 22 3a 7b 7d 2c  |MessagePath":{},|
              00000170  22 66 3a 74 65 72 6d 69  6e 61 74 69 6f 6e 4d 65  |"f:terminationMe|
              00000180  73 73 61 67 65 50 6f 6c  69 63 79 22 3a 7b 7d 7d  |ssagePolicy":{}}|
              00000190  7d 2c 22 66 3a 64 6e 73  50 6f 6c 69 63 79 22 3a  |},"f:dnsPolicy":|
              000001a0  7b 7d 2c 22 66 3a 65 6e  61 62 6c 65 53 65 72 76  |{},"f:enableServ|
              000001b0  69 63 65 4c 69 6e 6b 73  22 3a 7b 7d 2c 22 66 3a  |iceLinks":{},"f:|
              000001c0  72 65 73 74 61 72 74 50  6f 6c 69 63 79 22 3a 7b  |restartPolicy":{|
              000001d0  7d 2c 22 66 3a 73 63 68  65 64 75 6c 65 72 4e 61  |},"f:schedulerNa|
              000001e0  6d 65 22 3a 7b 7d 2c 22  66 3a 73 65 63 75 72 69  |me":{},"f:securi|
              000001f0  74 79 43 6f 6e 74 65 78  74 22 3a 7b 7d 2c 22 66  |tyContext":{},"f|
              00000200  3a 74 65 72 6d 69 6e 61  74 69 6f 6e 47 72 61 63  |:terminationGrac|
              00000210  65 50 65 72 69 6f 64 53  65 63 6f 6e 64 73 22 3a  |ePeriodSeconds":|
              00000220  7b 7d 7d 7d                                       |{}}}|
            }
          }),
          Subresource: (string) ""
        },
        (v1.ManagedFieldsEntry) {
          Manager: (string) (len=7) "kubelet",
          Operation: (v1.ManagedFieldsOperationType) (len=6) "Update",
          APIVersion: (string) (len=2) "v1",
          Time: (*v1.Time)({
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120760,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          }),
          FieldsType: (string) (len=8) "FieldsV1",
          FieldsV1: (*v1.FieldsV1)({
            Raw: ([]uint8) (len=521) {
              00000000  7b 22 66 3a 73 74 61 74  75 73 22 3a 7b 22 66 3a  |{"f:status":{"f:|
              00000010  63 6f 6e 64 69 74 69 6f  6e 73 22 3a 7b 22 6b 3a  |conditions":{"k:|
              00000020  7b 5c 22 74 79 70 65 5c  22 3a 5c 22 43 6f 6e 74  |{\"type\":\"Cont|
              00000030  61 69 6e 65 72 73 52 65  61 64 79 5c 22 7d 22 3a  |ainersReady\"}":|
              00000040  7b 22 2e 22 3a 7b 7d 2c  22 66 3a 6c 61 73 74 50  |{".":{},"f:lastP|
              00000050  72 6f 62 65 54 69 6d 65  22 3a 7b 7d 2c 22 66 3a  |robeTime":{},"f:|
              00000060  6c 61 73 74 54 72 61 6e  73 69 74 69 6f 6e 54 69  |lastTransitionTi|
              00000070  6d 65 22 3a 7b 7d 2c 22  66 3a 73 74 61 74 75 73  |me":{},"f:status|
              00000080  22 3a 7b 7d 2c 22 66 3a  74 79 70 65 22 3a 7b 7d  |":{},"f:type":{}|
              00000090  7d 2c 22 6b 3a 7b 5c 22  74 79 70 65 5c 22 3a 5c  |},"k:{\"type\":\|
              000000a0  22 49 6e 69 74 69 61 6c  69 7a 65 64 5c 22 7d 22  |"Initialized\"}"|
              000000b0  3a 7b 22 2e 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |:{".":{},"f:last|
              000000c0  50 72 6f 62 65 54 69 6d  65 22 3a 7b 7d 2c 22 66  |ProbeTime":{},"f|
              000000d0  3a 6c 61 73 74 54 72 61  6e 73 69 74 69 6f 6e 54  |:lastTransitionT|
              000000e0  69 6d 65 22 3a 7b 7d 2c  22 66 3a 73 74 61 74 75  |ime":{},"f:statu|
              000000f0  73 22 3a 7b 7d 2c 22 66  3a 74 79 70 65 22 3a 7b  |s":{},"f:type":{|
              00000100  7d 7d 2c 22 6b 3a 7b 5c  22 74 79 70 65 5c 22 3a  |}},"k:{\"type\":|
              00000110  5c 22 52 65 61 64 79 5c  22 7d 22 3a 7b 22 2e 22  |\"Ready\"}":{"."|
              00000120  3a 7b 7d 2c 22 66 3a 6c  61 73 74 50 72 6f 62 65  |:{},"f:lastProbe|
              00000130  54 69 6d 65 22 3a 7b 7d  2c 22 66 3a 6c 61 73 74  |Time":{},"f:last|
              00000140  54 72 61 6e 73 69 74 69  6f 6e 54 69 6d 65 22 3a  |TransitionTime":|
              00000150  7b 7d 2c 22 66 3a 73 74  61 74 75 73 22 3a 7b 7d  |{},"f:status":{}|
              00000160  2c 22 66 3a 74 79 70 65  22 3a 7b 7d 7d 7d 2c 22  |,"f:type":{}}},"|
              00000170  66 3a 63 6f 6e 74 61 69  6e 65 72 53 74 61 74 75  |f:containerStatu|
              00000180  73 65 73 22 3a 7b 7d 2c  22 66 3a 68 6f 73 74 49  |ses":{},"f:hostI|
              00000190  50 22 3a 7b 7d 2c 22 66  3a 70 68 61 73 65 22 3a  |P":{},"f:phase":|
              000001a0  7b 7d 2c 22 66 3a 70 6f  64 49 50 22 3a 7b 7d 2c  |{},"f:podIP":{},|
              000001b0  22 66 3a 70 6f 64 49 50  73 22 3a 7b 22 2e 22 3a  |"f:podIPs":{".":|
              000001c0  7b 7d 2c 22 6b 3a 7b 5c  22 69 70 5c 22 3a 5c 22  |{},"k:{\"ip\":\"|
              000001d0  31 39 32 2e 31 36 38 2e  32 33 30 2e 36 30 5c 22  |192.168.230.60\"|
              000001e0  7d 22 3a 7b 22 2e 22 3a  7b 7d 2c 22 66 3a 69 70  |}":{".":{},"f:ip|
              000001f0  22 3a 7b 7d 7d 7d 2c 22  66 3a 73 74 61 72 74 54  |":{}}},"f:startT|
              00000200  69 6d 65 22 3a 7b 7d 7d  7d                       |ime":{}}}|
            }
          }),
          Subresource: (string) (len=6) "status"
        }
      }
    },
    Spec: (v1.PodSpec) {
      Volumes: ([]v1.Volume) (len=1) {
        (v1.Volume) {
          Name: (string) (len=21) "kube-api-access-tnlsr",
          VolumeSource: (v1.VolumeSource) {
            HostPath: (*v1.HostPathVolumeSource)(<nil>),
            EmptyDir: (*v1.EmptyDirVolumeSource)(<nil>),
            GCEPersistentDisk: (*v1.GCEPersistentDiskVolumeSource)(<nil>),
            AWSElasticBlockStore: (*v1.AWSElasticBlockStoreVolumeSource)(<nil>),
            GitRepo: (*v1.GitRepoVolumeSource)(<nil>),
            Secret: (*v1.SecretVolumeSource)(<nil>),
            NFS: (*v1.NFSVolumeSource)(<nil>),
            ISCSI: (*v1.ISCSIVolumeSource)(<nil>),
            Glusterfs: (*v1.GlusterfsVolumeSource)(<nil>),
            PersistentVolumeClaim: (*v1.PersistentVolumeClaimVolumeSource)(<nil>),
            RBD: (*v1.RBDVolumeSource)(<nil>),
            FlexVolume: (*v1.FlexVolumeSource)(<nil>),
            Cinder: (*v1.CinderVolumeSource)(<nil>),
            CephFS: (*v1.CephFSVolumeSource)(<nil>),
            Flocker: (*v1.FlockerVolumeSource)(<nil>),
            DownwardAPI: (*v1.DownwardAPIVolumeSource)(<nil>),
            FC: (*v1.FCVolumeSource)(<nil>),
            AzureFile: (*v1.AzureFileVolumeSource)(<nil>),
            ConfigMap: (*v1.ConfigMapVolumeSource)(<nil>),
            VsphereVolume: (*v1.VsphereVirtualDiskVolumeSource)(<nil>),
            Quobyte: (*v1.QuobyteVolumeSource)(<nil>),
            AzureDisk: (*v1.AzureDiskVolumeSource)(<nil>),
            PhotonPersistentDisk: (*v1.PhotonPersistentDiskVolumeSource)(<nil>),
            Projected: (*v1.ProjectedVolumeSource)({
              Sources: ([]v1.VolumeProjection) (len=3) {
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)({
                    Audience: (string) "",
                    ExpirationSeconds: (*int64)(3607),
                    Path: (string) (len=5) "token"
                  })
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)(<nil>),
                  ConfigMap: (*v1.ConfigMapProjection)({
                    LocalObjectReference: (v1.LocalObjectReference) {
                      Name: (string) (len=16) "kube-root-ca.crt"
                    },
                    Items: ([]v1.KeyToPath) (len=1) {
                      (v1.KeyToPath) {
                        Key: (string) (len=6) "ca.crt",
                        Path: (string) (len=6) "ca.crt",
                        Mode: (*int32)(<nil>)
                      }
                    },
                    Optional: (*bool)(<nil>)
                  }),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                },
                (v1.VolumeProjection) {
                  Secret: (*v1.SecretProjection)(<nil>),
                  DownwardAPI: (*v1.DownwardAPIProjection)({
                    Items: ([]v1.DownwardAPIVolumeFile) (len=1) {
                      (v1.DownwardAPIVolumeFile) {
                        Path: (string) (len=9) "namespace",
                        FieldRef: (*v1.ObjectFieldSelector)({
                          APIVersion: (string) (len=2) "v1",
                          FieldPath: (string) (len=18) "metadata.namespace"
                        }),
                        ResourceFieldRef: (*v1.ResourceFieldSelector)(<nil>),
                        Mode: (*int32)(<nil>)
                      }
                    }
                  }),
                  ConfigMap: (*v1.ConfigMapProjection)(<nil>),
                  ServiceAccountToken: (*v1.ServiceAccountTokenProjection)(<nil>)
                }
              },
              DefaultMode: (*int32)(420)
            }),
            PortworxVolume: (*v1.PortworxVolumeSource)(<nil>),
            ScaleIO: (*v1.ScaleIOVolumeSource)(<nil>),
            StorageOS: (*v1.StorageOSVolumeSource)(<nil>),
            CSI: (*v1.CSIVolumeSource)(<nil>),
            Ephemeral: (*v1.EphemeralVolumeSource)(<nil>)
          }
        }
      },
      InitContainers: ([]v1.Container) <nil>,
      Containers: ([]v1.Container) (len=1) {
        (v1.Container) {
          Name: (string) (len=5) "httpd",
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          Command: ([]string) <nil>,
          Args: ([]string) <nil>,
          WorkingDir: (string) "",
          Ports: ([]v1.ContainerPort) <nil>,
          EnvFrom: ([]v1.EnvFromSource) <nil>,
          Env: ([]v1.EnvVar) <nil>,
          Resources: (v1.ResourceRequirements) {
            Limits: (v1.ResourceList) <nil>,
            Requests: (v1.ResourceList) <nil>,
            Claims: ([]v1.ResourceClaim) <nil>
          },
          ResizePolicy: ([]v1.ContainerResizePolicy) <nil>,
          RestartPolicy: (*v1.ContainerRestartPolicy)(<nil>),
          VolumeMounts: ([]v1.VolumeMount) (len=1) {
            (v1.VolumeMount) {
              Name: (string) (len=21) "kube-api-access-tnlsr",
              ReadOnly: (bool) true,
              MountPath: (string) (len=45) "/var/run/secrets/kubernetes.io/serviceaccount",
              SubPath: (string) "",
              MountPropagation: (*v1.MountPropagationMode)(<nil>),
              SubPathExpr: (string) ""
            }
          },
          VolumeDevices: ([]v1.VolumeDevice) <nil>,
          LivenessProbe: (*v1.Probe)(<nil>),
          ReadinessProbe: (*v1.Probe)(<nil>),
          StartupProbe: (*v1.Probe)(<nil>),
          Lifecycle: (*v1.Lifecycle)(<nil>),
          TerminationMessagePath: (string) (len=20) "/dev/termination-log",
          TerminationMessagePolicy: (v1.TerminationMessagePolicy) (len=4) "File",
          ImagePullPolicy: (v1.PullPolicy) (len=12) "IfNotPresent",
          SecurityContext: (*v1.SecurityContext)({
            Capabilities: (*v1.Capabilities)(<nil>),
            Privileged: (*bool)(<nil>),
            SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
            WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
            RunAsUser: (*int64)(<nil>),
            RunAsGroup: (*int64)(<nil>),
            RunAsNonRoot: (*bool)(<nil>),
            ReadOnlyRootFilesystem: (*bool)(<nil>),
            AllowPrivilegeEscalation: (*bool)(<nil>),
            ProcMount: (*v1.ProcMountType)(<nil>),
            SeccompProfile: (*v1.SeccompProfile)(<nil>)
          }),
          Stdin: (bool) false,
          StdinOnce: (bool) false,
          TTY: (bool) false
        }
      },
      EphemeralContainers: ([]v1.EphemeralContainer) <nil>,
      RestartPolicy: (v1.RestartPolicy) (len=6) "Always",
      TerminationGracePeriodSeconds: (*int64)(0),
      ActiveDeadlineSeconds: (*int64)(<nil>),
      DNSPolicy: (v1.DNSPolicy) (len=12) "ClusterFirst",
      NodeSelector: (map[string]string) <nil>,
      ServiceAccountName: (string) (len=7) "default",
      DeprecatedServiceAccount: (string) (len=7) "default",
      AutomountServiceAccountToken: (*bool)(<nil>),
      NodeName: (string) (len=15) "ip-172-31-74-39",
      HostNetwork: (bool) false,
      HostPID: (bool) false,
      HostIPC: (bool) false,
      ShareProcessNamespace: (*bool)(<nil>),
      SecurityContext: (*v1.PodSecurityContext)({
        SELinuxOptions: (*v1.SELinuxOptions)(<nil>),
        WindowsOptions: (*v1.WindowsSecurityContextOptions)(<nil>),
        RunAsUser: (*int64)(<nil>),
        RunAsGroup: (*int64)(<nil>),
        RunAsNonRoot: (*bool)(<nil>),
        SupplementalGroups: ([]int64) <nil>,
        FSGroup: (*int64)(<nil>),
        Sysctls: ([]v1.Sysctl) <nil>,
        FSGroupChangePolicy: (*v1.PodFSGroupChangePolicy)(<nil>),
        SeccompProfile: (*v1.SeccompProfile)(<nil>)
      }),
      ImagePullSecrets: ([]v1.LocalObjectReference) <nil>,
      Hostname: (string) "",
      Subdomain: (string) "",
      Affinity: (*v1.Affinity)(<nil>),
      SchedulerName: (string) (len=17) "default-scheduler",
      Tolerations: ([]v1.Toleration) (len=2) {
        (v1.Toleration) {
          Key: (string) (len=28) "node.kubernetes.io/not-ready",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        },
        (v1.Toleration) {
          Key: (string) (len=30) "node.kubernetes.io/unreachable",
          Operator: (v1.TolerationOperator) (len=6) "Exists",
          Value: (string) "",
          Effect: (v1.TaintEffect) (len=9) "NoExecute",
          TolerationSeconds: (*int64)(300)
        }
      },
      HostAliases: ([]v1.HostAlias) <nil>,
      PriorityClassName: (string) "",
      Priority: (*int32)(0),
      DNSConfig: (*v1.PodDNSConfig)(<nil>),
      ReadinessGates: ([]v1.PodReadinessGate) <nil>,
      RuntimeClassName: (*string)(<nil>),
      EnableServiceLinks: (*bool)(true),
      PreemptionPolicy: (*v1.PreemptionPolicy)((len=20) "PreemptLowerPriority"),
      Overhead: (v1.ResourceList) <nil>,
      TopologySpreadConstraints: ([]v1.TopologySpreadConstraint) <nil>,
      SetHostnameAsFQDN: (*bool)(<nil>),
      OS: (*v1.PodOS)(<nil>),
      HostUsers: (*bool)(<nil>),
      SchedulingGates: ([]v1.PodSchedulingGate) <nil>,
      ResourceClaims: ([]v1.PodResourceClaim) <nil>
    },
    Status: (v1.PodStatus) {
      Phase: (v1.PodPhase) (len=7) "Running",
      Conditions: ([]v1.PodCondition) (len=4) {
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=11) "Initialized",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120758,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=5) "Ready",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120760,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=15) "ContainersReady",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120760,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        },
        (v1.PodCondition) {
          Type: (v1.PodConditionType) (len=12) "PodScheduled",
          Status: (v1.ConditionStatus) (len=4) "True",
          LastProbeTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 0,
              loc: (*time.Location)(<nil>)
            }
          },
          LastTransitionTime: (v1.Time) {
            Time: (time.Time) {
              wall: (uint64) 0,
              ext: (int64) 63837120758,
              loc: (*time.Location)({
                name: (string) (len=3) "UTC",
                zone: ([]time.zone) <nil>,
                tx: ([]time.zoneTrans) <nil>,
                extend: (string) "",
                cacheStart: (int64) 0,
                cacheEnd: (int64) 0,
                cacheZone: (*time.zone)(<nil>)
              })
            }
          },
          Reason: (string) "",
          Message: (string) ""
        }
      },
      Message: (string) "",
      Reason: (string) "",
      NominatedNodeName: (string) "",
      HostIP: (string) (len=12) "172.31.74.39",
      HostIPs: ([]v1.HostIP) <nil>,
      PodIP: (string) (len=14) "192.168.230.60",
      PodIPs: ([]v1.PodIP) (len=1) {
        (v1.PodIP) {
          IP: (string) (len=14) "192.168.230.60"
        }
      },
      StartTime: (*v1.Time)({
        Time: (time.Time) {
          wall: (uint64) 0,
          ext: (int64) 63837120758,
          loc: (*time.Location)({
            name: (string) (len=3) "UTC",
            zone: ([]time.zone) <nil>,
            tx: ([]time.zoneTrans) <nil>,
            extend: (string) "",
            cacheStart: (int64) 0,
            cacheEnd: (int64) 0,
            cacheZone: (*time.zone)(<nil>)
          })
        }
      }),
      InitContainerStatuses: ([]v1.ContainerStatus) <nil>,
      ContainerStatuses: ([]v1.ContainerStatus) (len=1) {
        (v1.ContainerStatus) {
          Name: (string) (len=5) "httpd",
          State: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)({
              StartedAt: (v1.Time) {
                Time: (time.Time) {
                  wall: (uint64) 0,
                  ext: (int64) 63837120759,
                  loc: (*time.Location)(<already shown>)
                }
              }
            }),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          LastTerminationState: (v1.ContainerState) {
            Waiting: (*v1.ContainerStateWaiting)(<nil>),
            Running: (*v1.ContainerStateRunning)(<nil>),
            Terminated: (*v1.ContainerStateTerminated)(<nil>)
          },
          Ready: (bool) true,
          RestartCount: (int32) 0,
          Image: (string) (len=46) "registry.k8s.io/e2e-test-images/httpd:2.4.38-4",
          ImageID: (string) (len=109) "registry.k8s.io/e2e-test-images/httpd@sha256:148b022f5c5da426fc2f3c14b5c0867e58ef05961510c84749ac1fddcb0fef22",
          ContainerID: (string) (len=77) "containerd://9cbf31ca595c9e34f372af131c8848b9ac6e978a51deb391ee65d03bd9f4cdf8",
          Started: (*bool)(true),
          AllocatedResources: (v1.ResourceList) <nil>,
          Resources: (*v1.ResourceRequirements)(<nil>)
        }
      },
      QOSClass: (v1.PodQOSClass) (len=10) "BestEffort",
      EphemeralContainerStatuses: ([]v1.ContainerStatus) <nil>,
      Resize: (v1.PodResizeStatus) "",
      ResourceClaimStatuses: ([]v1.PodResourceClaimStatus) <nil>
    }
  }

  Dec  2 13:32:41.005: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "deployment-318" for this suite. @ 12/02/23 13:32:41.008
• [2.109 seconds]
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
test/e2e/apimachinery/garbage_collector.go:713
  STEP: Creating a kubernetes client @ 12/02/23 13:32:41.016
  Dec  2 13:32:41.016: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename gc @ 12/02/23 13:32:41.017
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:41.036
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:41.038
  STEP: create the rc1 @ 12/02/23 13:32:41.061
  STEP: create the rc2 @ 12/02/23 13:32:41.071
  E1202 13:32:41.835392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:42.839963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:43.842355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:44.842447      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:45.842539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:46.845954      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well @ 12/02/23 13:32:47.101
  STEP: delete the rc simpletest-rc-to-be-deleted @ 12/02/23 13:32:47.827
  STEP: wait for the rc to be deleted @ 12/02/23 13:32:47.839
  E1202 13:32:47.865206      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:48.865315      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:49.865379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:50.865558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:51.865652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:52.852: INFO: 68 pods remaining
  Dec  2 13:32:52.852: INFO: 68 pods has nil DeletionTimestamp
  Dec  2 13:32:52.852: INFO: 
  E1202 13:32:52.865791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:53.866022      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:54.866263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:55.866345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:56.867359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/02/23 13:32:57.85
  W1202 13:32:57.855175      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  2 13:32:57.855: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  2 13:32:57.855: INFO: Deleting pod "simpletest-rc-to-be-deleted-25dgh" in namespace "gc-2609"
  E1202 13:32:57.867983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:32:57.926: INFO: Deleting pod "simpletest-rc-to-be-deleted-28m2k" in namespace "gc-2609"
  Dec  2 13:32:57.942: INFO: Deleting pod "simpletest-rc-to-be-deleted-2gc9z" in namespace "gc-2609"
  Dec  2 13:32:57.955: INFO: Deleting pod "simpletest-rc-to-be-deleted-2vdbj" in namespace "gc-2609"
  Dec  2 13:32:57.968: INFO: Deleting pod "simpletest-rc-to-be-deleted-44cck" in namespace "gc-2609"
  Dec  2 13:32:57.982: INFO: Deleting pod "simpletest-rc-to-be-deleted-47qj7" in namespace "gc-2609"
  Dec  2 13:32:57.995: INFO: Deleting pod "simpletest-rc-to-be-deleted-4gcrq" in namespace "gc-2609"
  Dec  2 13:32:58.016: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wt7m" in namespace "gc-2609"
  Dec  2 13:32:58.029: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wx4x" in namespace "gc-2609"
  Dec  2 13:32:58.043: INFO: Deleting pod "simpletest-rc-to-be-deleted-55wv5" in namespace "gc-2609"
  Dec  2 13:32:58.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-5sl8d" in namespace "gc-2609"
  Dec  2 13:32:58.078: INFO: Deleting pod "simpletest-rc-to-be-deleted-5t6lc" in namespace "gc-2609"
  Dec  2 13:32:58.091: INFO: Deleting pod "simpletest-rc-to-be-deleted-5xtxd" in namespace "gc-2609"
  Dec  2 13:32:58.104: INFO: Deleting pod "simpletest-rc-to-be-deleted-62nzs" in namespace "gc-2609"
  Dec  2 13:32:58.121: INFO: Deleting pod "simpletest-rc-to-be-deleted-6jnlz" in namespace "gc-2609"
  Dec  2 13:32:58.135: INFO: Deleting pod "simpletest-rc-to-be-deleted-749h6" in namespace "gc-2609"
  Dec  2 13:32:58.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-7swfg" in namespace "gc-2609"
  Dec  2 13:32:58.162: INFO: Deleting pod "simpletest-rc-to-be-deleted-7sx2z" in namespace "gc-2609"
  Dec  2 13:32:58.179: INFO: Deleting pod "simpletest-rc-to-be-deleted-8dpzv" in namespace "gc-2609"
  Dec  2 13:32:58.203: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ggmf" in namespace "gc-2609"
  Dec  2 13:32:58.212: INFO: Deleting pod "simpletest-rc-to-be-deleted-8kthl" in namespace "gc-2609"
  Dec  2 13:32:58.224: INFO: Deleting pod "simpletest-rc-to-be-deleted-8pkgp" in namespace "gc-2609"
  Dec  2 13:32:58.242: INFO: Deleting pod "simpletest-rc-to-be-deleted-8xtfq" in namespace "gc-2609"
  Dec  2 13:32:58.257: INFO: Deleting pod "simpletest-rc-to-be-deleted-8zf7z" in namespace "gc-2609"
  Dec  2 13:32:58.273: INFO: Deleting pod "simpletest-rc-to-be-deleted-96nfv" in namespace "gc-2609"
  Dec  2 13:32:58.285: INFO: Deleting pod "simpletest-rc-to-be-deleted-b2dlx" in namespace "gc-2609"
  Dec  2 13:32:58.298: INFO: Deleting pod "simpletest-rc-to-be-deleted-bd4nn" in namespace "gc-2609"
  Dec  2 13:32:58.309: INFO: Deleting pod "simpletest-rc-to-be-deleted-bnpcz" in namespace "gc-2609"
  Dec  2 13:32:58.324: INFO: Deleting pod "simpletest-rc-to-be-deleted-c64zt" in namespace "gc-2609"
  Dec  2 13:32:58.338: INFO: Deleting pod "simpletest-rc-to-be-deleted-cbdnm" in namespace "gc-2609"
  Dec  2 13:32:58.355: INFO: Deleting pod "simpletest-rc-to-be-deleted-crzjb" in namespace "gc-2609"
  Dec  2 13:32:58.367: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddbcd" in namespace "gc-2609"
  Dec  2 13:32:58.382: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddfmv" in namespace "gc-2609"
  Dec  2 13:32:58.398: INFO: Deleting pod "simpletest-rc-to-be-deleted-dl5dg" in namespace "gc-2609"
  Dec  2 13:32:58.412: INFO: Deleting pod "simpletest-rc-to-be-deleted-drwx7" in namespace "gc-2609"
  Dec  2 13:32:58.427: INFO: Deleting pod "simpletest-rc-to-be-deleted-dv4qs" in namespace "gc-2609"
  Dec  2 13:32:58.441: INFO: Deleting pod "simpletest-rc-to-be-deleted-f69vf" in namespace "gc-2609"
  Dec  2 13:32:58.453: INFO: Deleting pod "simpletest-rc-to-be-deleted-ff2sg" in namespace "gc-2609"
  Dec  2 13:32:58.478: INFO: Deleting pod "simpletest-rc-to-be-deleted-fjkfp" in namespace "gc-2609"
  Dec  2 13:32:58.505: INFO: Deleting pod "simpletest-rc-to-be-deleted-flgbp" in namespace "gc-2609"
  Dec  2 13:32:58.523: INFO: Deleting pod "simpletest-rc-to-be-deleted-fsmz4" in namespace "gc-2609"
  Dec  2 13:32:58.538: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5dgf" in namespace "gc-2609"
  Dec  2 13:32:58.553: INFO: Deleting pod "simpletest-rc-to-be-deleted-gd6ns" in namespace "gc-2609"
  Dec  2 13:32:58.574: INFO: Deleting pod "simpletest-rc-to-be-deleted-gdshv" in namespace "gc-2609"
  Dec  2 13:32:58.587: INFO: Deleting pod "simpletest-rc-to-be-deleted-gv5l4" in namespace "gc-2609"
  Dec  2 13:32:58.601: INFO: Deleting pod "simpletest-rc-to-be-deleted-gwhbb" in namespace "gc-2609"
  Dec  2 13:32:58.622: INFO: Deleting pod "simpletest-rc-to-be-deleted-hlbkv" in namespace "gc-2609"
  Dec  2 13:32:58.637: INFO: Deleting pod "simpletest-rc-to-be-deleted-hlzt4" in namespace "gc-2609"
  Dec  2 13:32:58.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-j7pff" in namespace "gc-2609"
  Dec  2 13:32:58.665: INFO: Deleting pod "simpletest-rc-to-be-deleted-jfnc4" in namespace "gc-2609"
  Dec  2 13:32:58.679: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2609" for this suite. @ 12/02/23 13:32:58.685
• [17.675 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/security_context.go:609
  STEP: Creating a kubernetes client @ 12/02/23 13:32:58.692
  Dec  2 13:32:58.692: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename security-context-test @ 12/02/23 13:32:58.693
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:32:58.709
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:32:58.711
  E1202 13:32:58.870655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:32:59.870859      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:00.871864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:01.872032      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:02.873071      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:03.873271      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:04.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "security-context-test-5233" for this suite. @ 12/02/23 13:33:04.82
• [6.135 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job should manage the lifecycle of a job [Conformance]
test/e2e/apps/job.go:713
  STEP: Creating a kubernetes client @ 12/02/23 13:33:04.829
  Dec  2 13:33:04.829: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename job @ 12/02/23 13:33:04.829
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:33:04.847
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:33:04.85
  STEP: Creating a suspended job @ 12/02/23 13:33:04.856
  STEP: Patching the Job @ 12/02/23 13:33:04.863
  E1202 13:33:04.874170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Watching for Job to be patched @ 12/02/23 13:33:04.878
  Dec  2 13:33:04.879: INFO: Event ADDED observed for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778] and annotations: map[]
  Dec  2 13:33:04.879: INFO: Event MODIFIED observed for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778] and annotations: map[]
  Dec  2 13:33:04.880: INFO: Event MODIFIED found for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[]
  STEP: Updating the job @ 12/02/23 13:33:04.88
  STEP: Watching for Job to be updated @ 12/02/23 13:33:04.888
  Dec  2 13:33:04.889: INFO: Event MODIFIED found for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[updated:true]
  Dec  2 13:33:04.889: INFO: Found Job annotations: map[string]string{"updated":"true"}
  STEP: Listing all Jobs with LabelSelector @ 12/02/23 13:33:04.889
  Dec  2 13:33:04.894: INFO: Job: e2e-m4778 as labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched]
  STEP: Waiting for job to complete @ 12/02/23 13:33:04.894
  E1202 13:33:05.874312      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:06.874500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:07.874757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:08.874833      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:09.874944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:10.875974      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:11.876083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:12.876172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Delete a job collection with a labelselector @ 12/02/23 13:33:12.897
  STEP: Watching for Job to be deleted @ 12/02/23 13:33:12.905
  Dec  2 13:33:12.907: INFO: Event MODIFIED observed for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[updated:true]
  Dec  2 13:33:12.907: INFO: Event MODIFIED observed for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[updated:true]
  Dec  2 13:33:12.907: INFO: Event MODIFIED observed for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[updated:true]
  Dec  2 13:33:12.907: INFO: Event MODIFIED observed for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[updated:true]
  Dec  2 13:33:12.907: INFO: Event MODIFIED observed for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[updated:true]
  Dec  2 13:33:12.907: INFO: Event DELETED found for Job e2e-m4778 in namespace job-8411 with labels: map[e2e-job-label:e2e-m4778 e2e-m4778:patched] and annotations: map[updated:true]
  STEP: Relist jobs to confirm deletion @ 12/02/23 13:33:12.907
  Dec  2 13:33:12.910: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "job-8411" for this suite. @ 12/02/23 13:33:12.913
• [8.096 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
test/e2e/apps/statefulset.go:640
  STEP: Creating a kubernetes client @ 12/02/23 13:33:12.925
  Dec  2 13:33:12.925: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 13:33:12.926
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:33:12.943
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:33:12.945
  STEP: Creating service test in namespace statefulset-5737 @ 12/02/23 13:33:12.947
  STEP: Initializing watcher for selector baz=blah,foo=bar @ 12/02/23 13:33:12.951
  STEP: Creating stateful set ss in namespace statefulset-5737 @ 12/02/23 13:33:12.954
  STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5737 @ 12/02/23 13:33:12.961
  Dec  2 13:33:12.965: INFO: Found 0 stateful pods, waiting for 1
  E1202 13:33:13.877184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:14.878197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:15.878240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:16.878323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:17.878418      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:18.879321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:19.879529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:20.879733      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:21.879823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:22.879917      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:22.970: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod @ 12/02/23 13:33:22.97
  Dec  2 13:33:22.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 13:33:23.092: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 13:33:23.092: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 13:33:23.092: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 13:33:23.096: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
  E1202 13:33:23.880690      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:24.880782      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:25.880966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:26.881065      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:27.881322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:28.881402      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:29.881493      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:30.881576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:31.882637      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:32.883276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:33.101: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 13:33:33.101: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  2 13:33:33.118: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999824s
  E1202 13:33:33.883856      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:34.123: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995794631s
  E1202 13:33:34.884184      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:35.128: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990469203s
  E1202 13:33:35.884776      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:36.131: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986884758s
  E1202 13:33:36.884919      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:37.138: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982693958s
  E1202 13:33:37.885106      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:38.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.976513963s
  E1202 13:33:38.885188      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:39.145: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.972413248s
  E1202 13:33:39.885467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:40.150: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.969195039s
  E1202 13:33:40.885564      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:41.154: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964027269s
  E1202 13:33:41.886071      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:42.158: INFO: Verifying statefulset ss doesn't scale past 1 for another 959.771096ms
  E1202 13:33:42.886236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5737 @ 12/02/23 13:33:43.159
  Dec  2 13:33:43.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  2 13:33:43.285: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  2 13:33:43.285: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 13:33:43.285: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  2 13:33:43.289: INFO: Found 1 stateful pods, waiting for 3
  E1202 13:33:43.887004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:44.887082      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:45.887174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:46.887265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:47.887348      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:48.887446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:49.887559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:50.887635      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:51.887728      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:52.887801      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:33:53.294: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 13:33:53.294: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
  Dec  2 13:33:53.294: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Verifying that stateful set ss was scaled up in order @ 12/02/23 13:33:53.294
  STEP: Scale down will halt with unhealthy stateful pod @ 12/02/23 13:33:53.295
  Dec  2 13:33:53.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 13:33:53.416: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 13:33:53.416: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 13:33:53.416: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 13:33:53.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 13:33:53.539: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 13:33:53.539: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 13:33:53.539: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 13:33:53.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
  Dec  2 13:33:53.666: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
  Dec  2 13:33:53.666: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
  Dec  2 13:33:53.666: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

  Dec  2 13:33:53.666: INFO: Waiting for statefulset status.readyReplicas updated to 0
  Dec  2 13:33:53.669: INFO: Waiting for statefulset status.readyReplicas to become 0, currently 3
  E1202 13:33:53.888112      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:54.888188      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:55.888405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:56.888511      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:57.888569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:58.888985      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:33:59.889844      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:00.889931      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:01.890096      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:02.890224      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:03.678: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 13:34:03.678: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 13:34:03.678: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
  Dec  2 13:34:03.692: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999868s
  E1202 13:34:03.890941      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:04.697: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996409312s
  E1202 13:34:04.891337      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:05.701: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.991894788s
  E1202 13:34:05.891428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:06.707: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987910047s
  E1202 13:34:06.891839      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:07.711: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981480811s
  E1202 13:34:07.892369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:08.715: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.977960895s
  E1202 13:34:08.893295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:09.719: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.974009574s
  E1202 13:34:09.894167      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:10.724: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968482342s
  E1202 13:34:10.894503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:11.728: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.96477503s
  E1202 13:34:11.894887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:12.732: INFO: Verifying statefulset ss doesn't scale past 3 for another 960.147261ms
  E1202 13:34:12.895836      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5737 @ 12/02/23 13:34:13.732
  Dec  2 13:34:13.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  2 13:34:13.844: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  2 13:34:13.844: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 13:34:13.844: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  2 13:34:13.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  E1202 13:34:13.896714      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:13.968: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  2 13:34:13.968: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 13:34:13.968: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  2 13:34:13.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=statefulset-5737 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
  Dec  2 13:34:14.107: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
  Dec  2 13:34:14.107: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
  Dec  2 13:34:14.107: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

  Dec  2 13:34:14.107: INFO: Scaling statefulset ss to 0
  E1202 13:34:14.896770      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:15.897912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:16.898607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:17.899105      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:18.899194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:19.899346      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:20.900223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:21.900302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:22.900872      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:23.901046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Verifying that stateful set ss was scaled down in reverse order @ 12/02/23 13:34:24.121
  Dec  2 13:34:24.121: INFO: Deleting all statefulset in ns statefulset-5737
  Dec  2 13:34:24.125: INFO: Scaling statefulset ss to 0
  Dec  2 13:34:24.133: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 13:34:24.137: INFO: Deleting statefulset ss
  Dec  2 13:34:24.149: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5737" for this suite. @ 12/02/23 13:34:24.153
• [71.238 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] PreStop should call prestop when killing a pod  [Conformance]
test/e2e/node/pre_stop.go:169
  STEP: Creating a kubernetes client @ 12/02/23 13:34:24.163
  Dec  2 13:34:24.163: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename prestop @ 12/02/23 13:34:24.164
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:34:24.193
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:34:24.195
  STEP: Creating server pod server in namespace prestop-6861 @ 12/02/23 13:34:24.198
  STEP: Waiting for pods to come up. @ 12/02/23 13:34:24.205
  E1202 13:34:24.901373      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:25.901626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating tester pod tester in namespace prestop-6861 @ 12/02/23 13:34:26.218
  E1202 13:34:26.901778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:27.901950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting pre-stop pod @ 12/02/23 13:34:28.231
  E1202 13:34:28.902971      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:29.903306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:30.903636      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:31.903730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:32.903815      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:33.245: INFO: Saw: {
  	"Hostname": "server",
  	"Sent": null,
  	"Received": {
  		"prestop": 1
  	},
  	"Errors": null,
  	"Log": [
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
  		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
  	],
  	"StillContactingPeers": true
  }
  Dec  2 13:34:33.245: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Deleting the server pod @ 12/02/23 13:34:33.249
  STEP: Destroying namespace "prestop-6861" for this suite. @ 12/02/23 13:34:33.273
• [9.117 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods should patch a pod status [Conformance]
test/e2e/common/node/pods.go:1084
  STEP: Creating a kubernetes client @ 12/02/23 13:34:33.281
  Dec  2 13:34:33.281: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:34:33.281
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:34:33.299
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:34:33.301
  STEP: Create a pod @ 12/02/23 13:34:33.303
  E1202 13:34:33.904002      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:34.904084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: patching /status @ 12/02/23 13:34:35.322
  Dec  2 13:34:35.330: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
  Dec  2 13:34:35.330: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-3179" for this suite. @ 12/02/23 13:34:35.334
• [2.060 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/secrets.go:95
  STEP: Creating a kubernetes client @ 12/02/23 13:34:35.341
  Dec  2 13:34:35.342: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename secrets @ 12/02/23 13:34:35.342
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:34:35.36
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:34:35.362
  STEP: creating secret secrets-4757/secret-test-2e4182d7-5248-4d93-8a23-18894e88c931 @ 12/02/23 13:34:35.364
  STEP: Creating a pod to test consume secrets @ 12/02/23 13:34:35.37
  E1202 13:34:35.904890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:36.904990      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:37.905291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:38.906154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:34:39.394
  Dec  2 13:34:39.397: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-configmaps-a7cbad56-160f-4f3f-8277-ec41ab763e2d container env-test: <nil>
  STEP: delete the pod @ 12/02/23 13:34:39.41
  Dec  2 13:34:39.427: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "secrets-4757" for this suite. @ 12/02/23 13:34:39.43
• [4.095 seconds]
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]
test/e2e/apps/statefulset.go:1030
  STEP: Creating a kubernetes client @ 12/02/23 13:34:39.436
  Dec  2 13:34:39.437: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename statefulset @ 12/02/23 13:34:39.437
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:34:39.454
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:34:39.456
  STEP: Creating service test in namespace statefulset-5782 @ 12/02/23 13:34:39.458
  STEP: Creating statefulset ss in namespace statefulset-5782 @ 12/02/23 13:34:39.465
  Dec  2 13:34:39.473: INFO: Found 0 stateful pods, waiting for 1
  E1202 13:34:39.906467      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:40.906546      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:41.907291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:42.907371      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:43.907561      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:44.907732      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:45.907805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:46.908653      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:47.908887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:48.909056      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:49.478: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
  STEP: Patch Statefulset to include a label @ 12/02/23 13:34:49.484
  STEP: Getting /status @ 12/02/23 13:34:49.494
  Dec  2 13:34:49.497: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
  STEP: updating the StatefulSet Status @ 12/02/23 13:34:49.497
  Dec  2 13:34:49.505: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the statefulset status to be updated @ 12/02/23 13:34:49.505
  Dec  2 13:34:49.507: INFO: Observed &StatefulSet event: ADDED
  Dec  2 13:34:49.507: INFO: Found Statefulset ss in namespace statefulset-5782 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  2 13:34:49.507: INFO: Statefulset ss has an updated status
  STEP: patching the Statefulset Status @ 12/02/23 13:34:49.507
  Dec  2 13:34:49.507: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec  2 13:34:49.514: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Statefulset status to be patched @ 12/02/23 13:34:49.514
  Dec  2 13:34:49.515: INFO: Observed &StatefulSet event: ADDED
  Dec  2 13:34:49.515: INFO: Observed Statefulset ss in namespace statefulset-5782 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  2 13:34:49.515: INFO: Observed &StatefulSet event: MODIFIED
  Dec  2 13:34:49.515: INFO: Found Statefulset ss in namespace statefulset-5782 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Dec  2 13:34:49.515: INFO: Deleting all statefulset in ns statefulset-5782
  Dec  2 13:34:49.519: INFO: Scaling statefulset ss to 0
  E1202 13:34:49.909498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:50.909774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:51.909974      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:52.910057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:53.910218      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:54.911286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:55.912204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:56.912378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:57.913361      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:34:58.914284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:34:59.535: INFO: Waiting for statefulset status.replicas updated to 0
  Dec  2 13:34:59.539: INFO: Deleting statefulset ss
  Dec  2 13:34:59.552: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "statefulset-5782" for this suite. @ 12/02/23 13:34:59.555
• [20.128 seconds]
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/network/networking.go:107
  STEP: Creating a kubernetes client @ 12/02/23 13:34:59.566
  Dec  2 13:34:59.566: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pod-network-test @ 12/02/23 13:34:59.567
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:34:59.587
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:34:59.589
  STEP: Performing setup for networking test in namespace pod-network-test-5933 @ 12/02/23 13:34:59.592
  STEP: creating a selector @ 12/02/23 13:34:59.592
  STEP: Creating the service pods in kubernetes @ 12/02/23 13:34:59.592
  Dec  2 13:34:59.592: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
  E1202 13:34:59.914812      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:00.914958      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:01.915284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:02.916229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:03.916523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:04.916702      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:05.916789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:06.916863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:07.917417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:08.917528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:09.918220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:10.918230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:11.919280      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:12.919380      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:13.920000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:14.920097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:15.921018      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:16.921114      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:17.921482      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:18.921639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:19.922697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:20.922776      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating test pods @ 12/02/23 13:35:21.684
  E1202 13:35:21.923091      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:22.923169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:23.710: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
  Dec  2 13:35:23.710: INFO: Going to poll 192.168.21.224 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec  2 13:35:23.712: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.21.224:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5933 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:35:23.712: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:35:23.713: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:35:23.713: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5933/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.21.224%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  2 13:35:23.789: INFO: Found all 1 expected endpoints: [netserver-0]
  Dec  2 13:35:23.789: INFO: Going to poll 192.168.230.19 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec  2 13:35:23.793: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.230.19:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5933 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:35:23.793: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:35:23.793: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:35:23.793: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5933/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.230.19%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  Dec  2 13:35:23.861: INFO: Found all 1 expected endpoints: [netserver-1]
  Dec  2 13:35:23.861: INFO: Going to poll 192.168.95.143 on port 8083 at least 0 times, with a maximum of 39 tries before failing
  Dec  2 13:35:23.865: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.95.143:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5933 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:35:23.865: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:35:23.865: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:35:23.866: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5933/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.95.143%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
  E1202 13:35:23.923970      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:23.935: INFO: Found all 1 expected endpoints: [netserver-2]
  Dec  2 13:35:23.936: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pod-network-test-5933" for this suite. @ 12/02/23 13:35:23.94
• [24.381 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]
test/e2e/apps/daemon_set.go:443
  STEP: Creating a kubernetes client @ 12/02/23 13:35:23.947
  Dec  2 13:35:23.947: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename daemonsets @ 12/02/23 13:35:23.948
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:35:23.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:35:23.974
  Dec  2 13:35:24.000: INFO: Create a RollingUpdate DaemonSet
  Dec  2 13:35:24.005: INFO: Check that daemon pods launch on every node of the cluster
  Dec  2 13:35:24.008: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:24.008: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:24.012: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 13:35:24.012: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:35:24.925004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:25.017: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:25.017: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:25.021: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
  Dec  2 13:35:25.021: INFO: Node ip-172-31-1-50 is running 0 daemon pod, expected 1
  E1202 13:35:25.925335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:26.017: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:26.017: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:26.021: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
  Dec  2 13:35:26.021: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
  Dec  2 13:35:26.021: INFO: Update the DaemonSet to trigger a rollout
  Dec  2 13:35:26.030: INFO: Updating DaemonSet daemon-set
  E1202 13:35:26.925419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:27.044: INFO: Roll back the DaemonSet before rollout is complete
  Dec  2 13:35:27.054: INFO: Updating DaemonSet daemon-set
  Dec  2 13:35:27.054: INFO: Make sure DaemonSet rollback is complete
  Dec  2 13:35:27.056: INFO: Wrong image for pod: daemon-set-8rvhh. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-4, got: foo:non-existent.
  Dec  2 13:35:27.056: INFO: Pod daemon-set-8rvhh is not available
  Dec  2 13:35:27.060: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:27.060: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1202 13:35:27.925967      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:28.068: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:28.068: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  E1202 13:35:28.926232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:29.066: INFO: Pod daemon-set-d8snm is not available
  Dec  2 13:35:29.069: INFO: DaemonSet pods can't tolerate node ip-172-31-12-62 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  Dec  2 13:35:29.069: INFO: DaemonSet pods can't tolerate node ip-172-31-22-152 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
  STEP: Deleting DaemonSet "daemon-set" @ 12/02/23 13:35:29.075
  STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4210, will wait for the garbage collector to delete the pods @ 12/02/23 13:35:29.075
  Dec  2 13:35:29.136: INFO: Deleting DaemonSet.extensions daemon-set took: 8.131982ms
  Dec  2 13:35:29.237: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.401918ms
  E1202 13:35:29.927103      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:30.927710      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:30.941: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
  Dec  2 13:35:30.941: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
  Dec  2 13:35:30.943: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38334"},"items":null}

  Dec  2 13:35:30.947: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38334"},"items":null}

  Dec  2 13:35:30.960: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "daemonsets-4210" for this suite. @ 12/02/23 13:35:30.965
• [7.024 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:58
  STEP: Creating a kubernetes client @ 12/02/23 13:35:30.972
  Dec  2 13:35:30.972: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/02/23 13:35:30.973
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:35:30.994
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:35:30.996
  Dec  2 13:35:30.998: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:35:31.927790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:32.023: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-9303" for this suite. @ 12/02/23 13:35:32.026
• [1.062 seconds]
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]
test/e2e/kubectl/kubectl.go:1481
  STEP: Creating a kubernetes client @ 12/02/23 13:35:32.034
  Dec  2 13:35:32.034: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:35:32.035
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:35:32.052
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:35:32.055
  STEP: creating Agnhost RC @ 12/02/23 13:35:32.057
  Dec  2 13:35:32.057: INFO: namespace kubectl-1846
  Dec  2 13:35:32.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1846 create -f -'
  Dec  2 13:35:32.203: INFO: stderr: ""
  Dec  2 13:35:32.203: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
  STEP: Waiting for Agnhost primary to start. @ 12/02/23 13:35:32.203
  E1202 13:35:32.927886      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:33.208: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:35:33.208: INFO: Found 0 / 1
  E1202 13:35:33.928026      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:34.207: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:35:34.207: INFO: Found 1 / 1
  Dec  2 13:35:34.207: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
  Dec  2 13:35:34.211: INFO: Selector matched 1 pods for map[app:agnhost]
  Dec  2 13:35:34.211: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
  Dec  2 13:35:34.211: INFO: wait on agnhost-primary startup in kubectl-1846 
  Dec  2 13:35:34.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1846 logs agnhost-primary-bj52q agnhost-primary'
  Dec  2 13:35:34.295: INFO: stderr: ""
  Dec  2 13:35:34.295: INFO: stdout: "Paused\n"
  STEP: exposing RC @ 12/02/23 13:35:34.295
  Dec  2 13:35:34.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1846 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
  Dec  2 13:35:34.387: INFO: stderr: ""
  Dec  2 13:35:34.387: INFO: stdout: "service/rm2 exposed\n"
  Dec  2 13:35:34.406: INFO: Service rm2 in namespace kubectl-1846 found.
  E1202 13:35:34.928076      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:35.928453      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: exposing service @ 12/02/23 13:35:36.413
  Dec  2 13:35:36.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-1846 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
  Dec  2 13:35:36.473: INFO: stderr: ""
  Dec  2 13:35:36.473: INFO: stdout: "service/rm3 exposed\n"
  Dec  2 13:35:36.477: INFO: Service rm3 in namespace kubectl-1846 found.
  E1202 13:35:36.928625      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:37.928702      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:35:38.485: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-1846" for this suite. @ 12/02/23 13:35:38.489
• [6.461 seconds]
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]
test/e2e/apimachinery/crd_watch.go:51
  STEP: Creating a kubernetes client @ 12/02/23 13:35:38.496
  Dec  2 13:35:38.496: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-watch @ 12/02/23 13:35:38.496
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:35:38.513
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:35:38.516
  Dec  2 13:35:38.518: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:35:38.928881      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:39.929701      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:40.929796      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating first CR  @ 12/02/23 13:35:41.059
  Dec  2 13:35:41.066: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-02T13:35:41Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-02T13:35:41Z]] name:name1 resourceVersion:38457 uid:5bb64627-b506-4e21-93e8-09520b48104d] num:map[num1:9223372036854775807 num2:1000000]]}
  E1202 13:35:41.929890      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:42.929973      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:43.930566      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:44.931285      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:45.931433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:46.931652      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:47.931748      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:48.931882      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:49.931969      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:50.933028      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating second CR @ 12/02/23 13:35:51.067
  Dec  2 13:35:51.073: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-02T13:35:51Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-02T13:35:51Z]] name:name2 resourceVersion:38506 uid:63f6315b-cc0c-4f53-aa26-36805dab9d20] num:map[num1:9223372036854775807 num2:1000000]]}
  E1202 13:35:51.933320      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:52.933387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:53.934194      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:54.934227      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:55.934487      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:56.934584      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:57.935401      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:58.935486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:35:59.935647      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:00.935745      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying first CR @ 12/02/23 13:36:01.074
  Dec  2 13:36:01.081: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-02T13:35:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-02T13:36:01Z]] name:name1 resourceVersion:38526 uid:5bb64627-b506-4e21-93e8-09520b48104d] num:map[num1:9223372036854775807 num2:1000000]]}
  E1202 13:36:01.935830      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:02.935920      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:03.936502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:04.937310      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:05.937399      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:06.937636      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:07.937798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:08.937933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:09.938004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:10.938211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Modifying second CR @ 12/02/23 13:36:11.082
  Dec  2 13:36:11.087: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-02T13:35:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-02T13:36:11Z]] name:name2 resourceVersion:38546 uid:63f6315b-cc0c-4f53-aa26-36805dab9d20] num:map[num1:9223372036854775807 num2:1000000]]}
  E1202 13:36:11.938888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:12.938982      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:13.939123      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:14.939187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:15.939552      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:16.939760      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:17.939818      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:18.940682      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:19.940843      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:20.940980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting first CR @ 12/02/23 13:36:21.088
  Dec  2 13:36:21.096: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-02T13:35:41Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-02T13:36:01Z]] name:name1 resourceVersion:38565 uid:5bb64627-b506-4e21-93e8-09520b48104d] num:map[num1:9223372036854775807 num2:1000000]]}
  E1202 13:36:21.942046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:22.942603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:23.942699      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:24.943379      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:25.943451      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:26.944430      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:27.944558      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:28.944869      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:29.945503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:30.945788      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting second CR @ 12/02/23 13:36:31.097
  Dec  2 13:36:31.107: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2023-12-02T13:35:51Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2023-12-02T13:36:11Z]] name:name2 resourceVersion:38585 uid:63f6315b-cc0c-4f53-aa26-36805dab9d20] num:map[num1:9223372036854775807 num2:1000000]]}
  E1202 13:36:31.946777      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:32.947291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:33.947528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:34.947997      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:35.949005      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:36.949169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:37.949254      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:38.949417      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:39.949574      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:40.950631      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:36:41.631: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-watch-9733" for this suite. @ 12/02/23 13:36:41.635
• [63.146 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]
test/e2e/apimachinery/webhook.go:210
  STEP: Creating a kubernetes client @ 12/02/23 13:36:41.644
  Dec  2 13:36:41.644: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:36:41.645
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:36:41.662
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:36:41.664
  STEP: Setting up server cert @ 12/02/23 13:36:41.691
  E1202 13:36:41.951039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:36:42.056
  STEP: Deploying the webhook pod @ 12/02/23 13:36:42.065
  STEP: Wait for the deployment to be ready @ 12/02/23 13:36:42.078
  Dec  2 13:36:42.083: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
  E1202 13:36:42.951290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:43.951465      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:36:44.096
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:36:44.105
  E1202 13:36:44.952469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:36:45.105: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the webhook via the AdmissionRegistration API @ 12/02/23 13:36:45.118
  STEP: create a pod @ 12/02/23 13:36:45.131
  E1202 13:36:45.952847      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:46.953689      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: 'kubectl attach' the pod, should be denied by the webhook @ 12/02/23 13:36:47.151
  Dec  2 13:36:47.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=webhook-645 attach --namespace=webhook-645 to-be-attached-pod -i -c=container1'
  Dec  2 13:36:47.208: INFO: rc: 1
  Dec  2 13:36:47.208: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-645" for this suite. @ 12/02/23 13:36:47.257
  STEP: Destroying namespace "webhook-markers-5734" for this suite. @ 12/02/23 13:36:47.264
• [5.628 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]
test/e2e/apimachinery/resource_quota.go:101
  STEP: Creating a kubernetes client @ 12/02/23 13:36:47.273
  Dec  2 13:36:47.273: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 13:36:47.273
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:36:47.289
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:36:47.292
  STEP: Counting existing ResourceQuota @ 12/02/23 13:36:47.294
  E1202 13:36:47.953905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:48.954246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:49.954306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:50.954398      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:51.955198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/02/23 13:36:52.298
  STEP: Ensuring resource quota status is calculated @ 12/02/23 13:36:52.302
  E1202 13:36:52.955287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:53.956015      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a Service @ 12/02/23 13:36:54.306
  STEP: Creating a NodePort Service @ 12/02/23 13:36:54.339
  STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota @ 12/02/23 13:36:54.36
  STEP: Ensuring resource quota status captures service creation @ 12/02/23 13:36:54.389
  E1202 13:36:54.956286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:55.956378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting Services @ 12/02/23 13:36:56.394
  STEP: Ensuring resource quota status released usage @ 12/02/23 13:36:56.428
  E1202 13:36:56.956463      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:36:57.956636      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:36:58.433: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-9457" for this suite. @ 12/02/23 13:36:58.436
• [11.171 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]
test/e2e/kubectl/kubectl.go:1027
  STEP: Creating a kubernetes client @ 12/02/23 13:36:58.444
  Dec  2 13:36:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename kubectl @ 12/02/23 13:36:58.445
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:36:58.461
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:36:58.463
  STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/02/23 13:36:58.465
  Dec  2 13:36:58.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7356 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-4 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
  Dec  2 13:36:58.516: INFO: stderr: ""
  Dec  2 13:36:58.516: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
  STEP: replace the image in the pod with server-side dry-run @ 12/02/23 13:36:58.516
  Dec  2 13:36:58.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7356 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-4"}]}} --dry-run=server'
  Dec  2 13:36:58.566: INFO: stderr: ""
  Dec  2 13:36:58.566: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
  STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-4 @ 12/02/23 13:36:58.566
  Dec  2 13:36:58.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=kubectl-7356 delete pods e2e-test-httpd-pod'
  E1202 13:36:58.957331      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:36:59.785: INFO: stderr: ""
  Dec  2 13:36:59.785: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
  Dec  2 13:36:59.785: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "kubectl-7356" for this suite. @ 12/02/23 13:36:59.789
• [1.352 seconds]
------------------------------
SS
------------------------------
[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]
test/e2e/apimachinery/field_validation.go:64
  STEP: Creating a kubernetes client @ 12/02/23 13:36:59.797
  Dec  2 13:36:59.797: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename field-validation @ 12/02/23 13:36:59.797
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:36:59.811
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:36:59.813
  STEP: apply creating a deployment @ 12/02/23 13:36:59.815
  Dec  2 13:36:59.817: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-6992" for this suite. @ 12/02/23 13:36:59.831
• [0.040 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]
test/e2e/apimachinery/namespace.go:243
  STEP: Creating a kubernetes client @ 12/02/23 13:36:59.838
  Dec  2 13:36:59.838: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename namespaces @ 12/02/23 13:36:59.839
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:36:59.855
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:36:59.857
  STEP: Creating a test namespace @ 12/02/23 13:36:59.859
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:36:59.873
  STEP: Creating a pod in the namespace @ 12/02/23 13:36:59.875
  STEP: Waiting for the pod to have running status @ 12/02/23 13:36:59.885
  E1202 13:36:59.957977      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:00.959062      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting the namespace @ 12/02/23 13:37:01.893
  STEP: Waiting for the namespace to be removed. @ 12/02/23 13:37:01.901
  E1202 13:37:01.959692      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:02.959964      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:03.960929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:04.961070      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:05.961598      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:06.962606      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:07.962887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:08.963108      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:09.963384      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:10.963581      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:11.964496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Recreating the namespace @ 12/02/23 13:37:12.904
  STEP: Verifying there are no pods in the namespace @ 12/02/23 13:37:12.923
  Dec  2 13:37:12.927: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "namespaces-1238" for this suite. @ 12/02/23 13:37:12.933
  STEP: Destroying namespace "nsdeletetest-8076" for this suite. @ 12/02/23 13:37:12.94
  Dec  2 13:37:12.943: INFO: Namespace nsdeletetest-8076 was already deleted
  STEP: Destroying namespace "nsdeletetest-8966" for this suite. @ 12/02/23 13:37:12.943
• [13.110 seconds]
------------------------------
SS
------------------------------
[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
test/e2e/common/storage/configmap_volume.go:74
  STEP: Creating a kubernetes client @ 12/02/23 13:37:12.949
  Dec  2 13:37:12.949: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 13:37:12.949
  E1202 13:37:12.964993      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:37:12.966
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:37:12.971
  STEP: Creating configMap with name configmap-test-volume-65c54683-6279-450a-b937-d5db06ab302b @ 12/02/23 13:37:12.973
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:37:12.978
  E1202 13:37:13.965913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:14.966084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:37:14.992
  Dec  2 13:37:14.996: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-6f0c10a9-c38a-4a80-befe-8f0b2ec825a3 container agnhost-container: <nil>
  STEP: delete the pod @ 12/02/23 13:37:15.012
  Dec  2 13:37:15.027: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-4247" for this suite. @ 12/02/23 13:37:15.031
• [2.089 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]
test/e2e/apimachinery/webhook.go:261
  STEP: Creating a kubernetes client @ 12/02/23 13:37:15.038
  Dec  2 13:37:15.038: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename webhook @ 12/02/23 13:37:15.039
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:37:15.061
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:37:15.064
  STEP: Setting up server cert @ 12/02/23 13:37:15.09
  STEP: Create role binding to let webhook read extension-apiserver-authentication @ 12/02/23 13:37:15.241
  STEP: Deploying the webhook pod @ 12/02/23 13:37:15.25
  STEP: Wait for the deployment to be ready @ 12/02/23 13:37:15.262
  Dec  2 13:37:15.270: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
  E1202 13:37:15.966951      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:16.967292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:37:17.28
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:37:17.292
  E1202 13:37:17.967939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:37:18.292: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
  STEP: Registering the mutating pod webhook via the AdmissionRegistration API @ 12/02/23 13:37:18.299
  STEP: create a pod that should be updated by the webhook @ 12/02/23 13:37:18.312
  Dec  2 13:37:18.325: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "webhook-2005" for this suite. @ 12/02/23 13:37:18.373
  STEP: Destroying namespace "webhook-markers-1391" for this suite. @ 12/02/23 13:37:18.381
• [3.352 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]
test/e2e/apimachinery/resource_quota.go:328
  STEP: Creating a kubernetes client @ 12/02/23 13:37:18.391
  Dec  2 13:37:18.391: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename resourcequota @ 12/02/23 13:37:18.391
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:37:18.407
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:37:18.41
  E1202 13:37:18.968875      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:19.969453      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:20.969639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:21.969724      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:22.970446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:23.971303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:24.971389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:25.972311      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:26.972488      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:27.972566      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:28.972660      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:29.972757      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:30.973126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:31.973229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:32.973401      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:33.974234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:34.975297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Counting existing ResourceQuota @ 12/02/23 13:37:35.416
  E1202 13:37:35.975404      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:36.976143      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:37.976242      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:38.976485      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:39.976912      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ResourceQuota @ 12/02/23 13:37:40.419
  STEP: Ensuring resource quota status is calculated @ 12/02/23 13:37:40.424
  E1202 13:37:40.977835      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:41.978003      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a ConfigMap @ 12/02/23 13:37:42.428
  STEP: Ensuring resource quota status captures configMap creation @ 12/02/23 13:37:42.439
  E1202 13:37:42.978234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:43.979289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deleting a ConfigMap @ 12/02/23 13:37:44.444
  STEP: Ensuring resource quota status released usage @ 12/02/23 13:37:44.45
  E1202 13:37:44.979374      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:45.979448      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:37:46.455: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "resourcequota-1771" for this suite. @ 12/02/23 13:37:46.459
• [28.074 seconds]
------------------------------
SSSSS
------------------------------
[sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]
test/e2e/network/ingressclass.go:266
  STEP: Creating a kubernetes client @ 12/02/23 13:37:46.465
  Dec  2 13:37:46.465: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename ingressclass @ 12/02/23 13:37:46.466
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:37:46.483
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:37:46.486
  STEP: getting /apis @ 12/02/23 13:37:46.488
  STEP: getting /apis/networking.k8s.io @ 12/02/23 13:37:46.491
  STEP: getting /apis/networking.k8s.iov1 @ 12/02/23 13:37:46.493
  STEP: creating @ 12/02/23 13:37:46.494
  STEP: getting @ 12/02/23 13:37:46.506
  STEP: listing @ 12/02/23 13:37:46.51
  STEP: watching @ 12/02/23 13:37:46.513
  Dec  2 13:37:46.513: INFO: starting watch
  STEP: patching @ 12/02/23 13:37:46.514
  STEP: updating @ 12/02/23 13:37:46.518
  Dec  2 13:37:46.523: INFO: waiting for watch events with expected annotations
  Dec  2 13:37:46.523: INFO: saw patched and updated annotations
  STEP: deleting @ 12/02/23 13:37:46.523
  STEP: deleting a collection @ 12/02/23 13:37:46.534
  Dec  2 13:37:46.550: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingressclass-945" for this suite. @ 12/02/23 13:37:46.553
• [0.095 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS should provide DNS for the cluster  [Conformance]
test/e2e/network/dns.go:50
  STEP: Creating a kubernetes client @ 12/02/23 13:37:46.563
  Dec  2 13:37:46.563: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 13:37:46.564
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:37:46.578
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:37:46.58
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/02/23 13:37:46.583
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
   @ 12/02/23 13:37:46.583
  STEP: creating a pod to probe DNS @ 12/02/23 13:37:46.583
  STEP: submitting the pod to kubernetes @ 12/02/23 13:37:46.583
  E1202 13:37:46.979509      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:47.979675      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/02/23 13:37:48.597
  STEP: looking for the results for each expected name from probers @ 12/02/23 13:37:48.6
  Dec  2 13:37:48.614: INFO: DNS probes using dns-9089/dns-test-0e9d1895-df8a-4f4c-b2bc-46414f67e84a succeeded

  Dec  2 13:37:48.614: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:37:48.618
  STEP: Destroying namespace "dns-9089" for this suite. @ 12/02/23 13:37:48.631
• [2.074 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
test/e2e/common/node/container_probe.go:71
  STEP: Creating a kubernetes client @ 12/02/23 13:37:48.639
  Dec  2 13:37:48.639: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-probe @ 12/02/23 13:37:48.64
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:37:48.657
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:37:48.66
  E1202 13:37:48.980518      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:49.981196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:50.981813      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:51.981980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:52.982686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:53.982788      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:54.983284      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:55.983678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:56.984549      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:57.984643      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:58.985097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:37:59.985171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:00.985732      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:01.985808      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:02.986291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:03.987323      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:04.987779      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:05.987950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:06.989016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:07.989283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:08.989371      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:09.989543      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:38:10.722: INFO: Container started at 2023-12-02 13:37:49 +0000 UTC, pod became ready at 2023-12-02 13:38:08 +0000 UTC
  Dec  2 13:38:10.722: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-probe-3358" for this suite. @ 12/02/23 13:38:10.725
• [22.098 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
test/e2e/network/service.go:2224
  STEP: Creating a kubernetes client @ 12/02/23 13:38:10.737
  Dec  2 13:38:10.737: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:38:10.738
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:38:10.755
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:38:10.757
  STEP: creating service in namespace services-2471 @ 12/02/23 13:38:10.76
  STEP: creating service affinity-nodeport-transition in namespace services-2471 @ 12/02/23 13:38:10.76
  STEP: creating replication controller affinity-nodeport-transition in namespace services-2471 @ 12/02/23 13:38:10.775
  I1202 13:38:10.788290      18 runners.go:197] Created replication controller with name: affinity-nodeport-transition, namespace: services-2471, replica count: 3
  E1202 13:38:10.990502      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:11.990980      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:12.991407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:38:13.839020      18 runners.go:197] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  Dec  2 13:38:13.848: INFO: Creating new exec pod
  E1202 13:38:13.992020      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:14.992101      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:15.992630      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:38:16.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2471 exec execpod-affinity6vxp4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
  E1202 13:38:16.993237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:38:16.994: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
  Dec  2 13:38:16.994: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:38:16.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2471 exec execpod-affinity6vxp4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.189 80'
  Dec  2 13:38:17.109: INFO: stderr: "+ nc -v -t -w 2 10.152.183.189 80\n+ echo hostName\nConnection to 10.152.183.189 80 port [tcp/http] succeeded!\n"
  Dec  2 13:38:17.109: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:38:17.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2471 exec execpod-affinity6vxp4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.1.50 32329'
  Dec  2 13:38:17.225: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.1.50 32329\nConnection to 172.31.1.50 32329 port [tcp/*] succeeded!\n"
  Dec  2 13:38:17.225: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:38:17.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2471 exec execpod-affinity6vxp4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.89.192 32329'
  Dec  2 13:38:17.341: INFO: stderr: "+ nc -v -t -w 2 172.31.89.192 32329\n+ echo hostName\nConnection to 172.31.89.192 32329 port [tcp/*] succeeded!\n"
  Dec  2 13:38:17.341: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:38:17.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2471 exec execpod-affinity6vxp4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.1.50:32329/ ; done'
  Dec  2 13:38:17.519: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n"
  Dec  2 13:38:17.519: INFO: stdout: "\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-mxrh4\naffinity-nodeport-transition-mxrh4\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-5nrbk\naffinity-nodeport-transition-mxrh4"
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-mxrh4
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-mxrh4
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-5nrbk
  Dec  2 13:38:17.519: INFO: Received response from host: affinity-nodeport-transition-mxrh4
  Dec  2 13:38:17.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2471 exec execpod-affinity6vxp4 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.1.50:32329/ ; done'
  Dec  2 13:38:17.704: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.1.50:32329/\n"
  Dec  2 13:38:17.704: INFO: stdout: "\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm\naffinity-nodeport-transition-2xxwm"
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.704: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.705: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.705: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.705: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.705: INFO: Received response from host: affinity-nodeport-transition-2xxwm
  Dec  2 13:38:17.705: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:38:17.710: INFO: Cleaning up the exec pod
  STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2471, will wait for the garbage collector to delete the pods @ 12/02/23 13:38:17.722
  Dec  2 13:38:17.784: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.151252ms
  Dec  2 13:38:17.885: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.075473ms
  E1202 13:38:17.993655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:18.994716      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:19.995756      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:20.996297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "services-2471" for this suite. @ 12/02/23 13:38:21.01
• [10.281 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]
test/e2e/apimachinery/table_conversion.go:154
  STEP: Creating a kubernetes client @ 12/02/23 13:38:21.019
  Dec  2 13:38:21.019: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename tables @ 12/02/23 13:38:21.02
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:38:21.037
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:38:21.04
  Dec  2 13:38:21.044: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "tables-9694" for this suite. @ 12/02/23 13:38:21.048
• [0.036 seconds]
------------------------------
SSSSS
------------------------------
[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]
test/e2e/apimachinery/field_validation.go:289
  STEP: Creating a kubernetes client @ 12/02/23 13:38:21.055
  Dec  2 13:38:21.055: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename field-validation @ 12/02/23 13:38:21.056
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:38:21.073
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:38:21.076
  Dec  2 13:38:21.078: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:38:21.997142      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:22.997419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:23.997574      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:38:24.150: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "field-validation-4264" for this suite. @ 12/02/23 13:38:24.166
• [3.117 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
test/e2e/network/dns.go:191
  STEP: Creating a kubernetes client @ 12/02/23 13:38:24.173
  Dec  2 13:38:24.173: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename dns @ 12/02/23 13:38:24.174
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:38:24.203
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:38:24.206
  STEP: Creating a test headless service @ 12/02/23 13:38:24.208
  STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9782 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9782;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9782 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9782;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9782.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9782.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9782.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9782.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9782.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9782.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9782.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9782.svc;check="$$(dig +notcp +noall +answer +search 159.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.159_udp@PTR;check="$$(dig +tcp +noall +answer +search 159.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.159_tcp@PTR;sleep 1; done
   @ 12/02/23 13:38:24.223
  STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9782 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9782;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9782 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9782;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9782.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9782.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9782.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9782.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9782.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9782.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9782.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9782.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9782.svc;check="$$(dig +notcp +noall +answer +search 159.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.159_udp@PTR;check="$$(dig +tcp +noall +answer +search 159.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.159_tcp@PTR;sleep 1; done
   @ 12/02/23 13:38:24.223
  STEP: creating a pod to probe DNS @ 12/02/23 13:38:24.223
  STEP: submitting the pod to kubernetes @ 12/02/23 13:38:24.223
  E1202 13:38:24.997614      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:25.997708      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: retrieving the pod @ 12/02/23 13:38:26.242
  STEP: looking for the results for each expected name from probers @ 12/02/23 13:38:26.247
  Dec  2 13:38:26.252: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.257: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.261: INFO: Unable to read wheezy_udp@dns-test-service.dns-9782 from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.266: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9782 from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.271: INFO: Unable to read wheezy_udp@dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.274: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.278: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.280: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.300: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.303: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.306: INFO: Unable to read jessie_udp@dns-test-service.dns-9782 from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.310: INFO: Unable to read jessie_tcp@dns-test-service.dns-9782 from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.313: INFO: Unable to read jessie_udp@dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.316: INFO: Unable to read jessie_tcp@dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.320: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.323: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9782.svc from pod dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff: the server could not find the requested resource (get pods dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff)
  Dec  2 13:38:26.336: INFO: Lookups using dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9782 wheezy_tcp@dns-test-service.dns-9782 wheezy_udp@dns-test-service.dns-9782.svc wheezy_tcp@dns-test-service.dns-9782.svc wheezy_udp@_http._tcp.dns-test-service.dns-9782.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9782.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9782 jessie_tcp@dns-test-service.dns-9782 jessie_udp@dns-test-service.dns-9782.svc jessie_tcp@dns-test-service.dns-9782.svc jessie_udp@_http._tcp.dns-test-service.dns-9782.svc jessie_tcp@_http._tcp.dns-test-service.dns-9782.svc]

  Dec  2 13:38:26.342: INFO: Pod client logs for webserver: 
  Dec  2 13:38:26.350: INFO: Pod client logs for querier: 
  Dec  2 13:38:26.356: INFO: Pod client logs for jessie-querier: 
  E1202 13:38:26.997988      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:27.998067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:28.998945      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:29.999039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:30.999084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:38:31.429: INFO: DNS probes using dns-9782/dns-test-c779bd79-0ff2-49d9-88e0-d68e6c722eff succeeded

  Dec  2 13:38:31.429: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: deleting the pod @ 12/02/23 13:38:31.432
  STEP: deleting the test service @ 12/02/23 13:38:31.447
  STEP: deleting the test headless service @ 12/02/23 13:38:31.464
  STEP: Destroying namespace "dns-9782" for this suite. @ 12/02/23 13:38:31.48
• [7.314 seconds]
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
test/e2e/common/node/expansion.go:228
  STEP: Creating a kubernetes client @ 12/02/23 13:38:31.488
  Dec  2 13:38:31.488: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename var-expansion @ 12/02/23 13:38:31.489
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:38:31.505
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:38:31.508
  STEP: creating the pod with failed condition @ 12/02/23 13:38:31.51
  E1202 13:38:32.000000      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:33.000093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:34.000458      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:35.000525      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:36.001161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:37.001255      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:38.002187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:39.002247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:40.002329      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:41.003281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:42.003378      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:43.003548      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:44.004263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:45.004290      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:46.005297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:47.005523      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:48.005842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:49.005702      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:50.006612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:51.006708      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:52.007278      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:53.007823      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:54.008317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:55.008405      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:56.009201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:57.009354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:58.009789      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:38:59.010211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:00.010998      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:01.011283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:02.011797      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:03.012800      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:04.012873      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:05.013025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:06.013385      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:07.013526      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:08.014319      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:09.015354      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:10.015486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:11.016249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:12.016317      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:13.016504      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:14.016735      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:15.016809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:16.017226      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:17.017929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:18.017984      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:19.018145      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:20.018758      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:21.018841      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:22.018926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:23.019046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:24.019774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:25.020046      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:26.020135      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:27.020228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:28.020906      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:29.021519      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:30.021607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:31.021894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:32.021982      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:33.022059      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:34.022790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:35.022901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:36.023939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:37.024030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:38.024866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:39.024952      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:40.025622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:41.025887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:42.026915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:43.027295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:44.027389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:45.028261      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:46.028927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:47.029017      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:48.029851      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:49.030030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:50.030234      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:51.031281      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:52.031686      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:53.031776      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:54.031877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:55.031963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:56.032355      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:57.032532      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:58.033306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:39:59.033481      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:00.033575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:01.034542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:02.034918      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:03.035302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:04.035392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:05.035486      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:06.036339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:07.036499      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:08.037139      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:09.037232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:10.037729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:11.037816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:12.038289      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:13.038357      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:14.038929      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:15.039126      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:16.039587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:17.039671      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:18.039754      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:19.039921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:20.040705      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:21.040791      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:22.041187      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:23.041365      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:24.042228      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:25.043291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:26.043391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:27.043569      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:28.043608      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:29.043778      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:30.043864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:31.044626      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: updating the pod @ 12/02/23 13:40:31.519
  Dec  2 13:40:32.030: INFO: Successfully updated pod "var-expansion-6bfa877b-2512-4abc-a742-19a71a4e0405"
  STEP: waiting for pod running @ 12/02/23 13:40:32.03
  E1202 13:40:32.045590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:33.045824      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 12/02/23 13:40:34.038
  Dec  2 13:40:34.038: INFO: Deleting pod "var-expansion-6bfa877b-2512-4abc-a742-19a71a4e0405" in namespace "var-expansion-9372"
  Dec  2 13:40:34.045: INFO: Wait up to 5m0s for pod "var-expansion-6bfa877b-2512-4abc-a742-19a71a4e0405" to be fully deleted
  E1202 13:40:34.046308      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:35.047283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:36.047367      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:37.047476      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:38.047658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:39.048554      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:40.048772      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:41.049648      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:42.049729      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:43.050246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:44.050335      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:45.050646      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:46.051283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:47.051395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:48.051732      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:49.051663      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:50.051659      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:51.052524      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:52.052613      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:53.053287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:54.053387      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:55.053603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:56.053938      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:57.054275      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:58.054345      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:40:59.054478      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:00.055406      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:01.055491      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:02.055739      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:03.056381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:04.056481      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:05.056730      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:06.056832      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:41:06.118: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "var-expansion-9372" for this suite. @ 12/02/23 13:41:06.123
• [154.642 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]
test/e2e/node/taints.go:290
  STEP: Creating a kubernetes client @ 12/02/23 13:41:06.13
  Dec  2 13:41:06.130: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename taint-single-pod @ 12/02/23 13:41:06.131
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:41:06.148
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:41:06.15
  Dec  2 13:41:06.152: INFO: Waiting up to 1m0s for all nodes to be ready
  E1202 13:41:07.057092      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:08.057162      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:09.057479      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:10.057575      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:11.058473      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:12.058570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:13.058829      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:14.058927      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:15.059482      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:16.059721      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:17.059809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:18.059981      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:19.060150      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:20.060222      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:21.060784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:22.060966      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:23.061169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:24.061256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:25.061350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:26.061494      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:27.062469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:28.063360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:29.063456      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:30.063546      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:31.064433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:32.064477      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:33.064877      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:34.065431      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:35.066163      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:36.066247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:37.067143      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:38.067182      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:39.067287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:40.067381      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:41.068083      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:42.068196      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:43.068484      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:44.068576      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:45.069198      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:46.069764      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:47.070241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:48.071293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:49.071391      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:50.071572      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:51.072302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:52.072300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:53.072344      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:54.072433      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:55.072628      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:56.072638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:57.073268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:58.073369      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:41:59.073471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:00.073568      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:01.074223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:02.074283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:03.075309      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:04.075631      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:05.075956      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:06.076022      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:42:06.181: INFO: Waiting for terminating namespaces to be deleted...
  Dec  2 13:42:06.189: INFO: Starting informer...
  STEP: Starting pod... @ 12/02/23 13:42:06.189
  Dec  2 13:42:06.403: INFO: Pod is running on ip-172-31-1-50. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/02/23 13:42:06.403
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/02/23 13:42:06.413
  STEP: Waiting short time to make sure Pod is queued for deletion @ 12/02/23 13:42:06.417
  Dec  2 13:42:06.418: INFO: Pod wasn't evicted. Proceeding
  Dec  2 13:42:06.418: INFO: Removing taint from Node
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/02/23 13:42:06.427
  STEP: Waiting some time to make sure that toleration time passed. @ 12/02/23 13:42:06.435
  E1202 13:42:07.076150      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:08.076232      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:09.076392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:10.076512      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:11.076794      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:12.076986      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:13.077469      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:14.077658      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:15.077821      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:16.077932      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:17.078067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:18.078225      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:19.078320      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:20.079282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:21.079377      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:22.079542      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:23.079842      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:24.079939      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:25.080111      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:26.080303      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:27.080395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:28.080786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:29.080871      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:30.081029      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:31.081122      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:32.081809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:33.081901      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:34.082056      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:35.082223      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:36.083282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:37.083444      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:38.084454      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:39.084549      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:40.085560      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:41.085646      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:42.085744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:43.085893      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:44.086328      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:45.087292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:46.087390      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:47.087474      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:48.087655      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:49.087847      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:50.088022      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:51.088102      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:52.088411      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:53.088498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:54.088663      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:55.089286      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:56.089664      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:57.089763      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:58.089863      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:42:59.090025      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:00.090200      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:01.090230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:02.091282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:03.091446      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:04.091879      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:05.092043      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:06.092850      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:07.093649      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:08.094471      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:09.095527      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:10.095603      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:11.095677      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:12.095768      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:13.095926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:14.096711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:15.096930      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:16.097021      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:17.097174      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:18.097339      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:19.097943      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:20.098027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:21.098162      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:43:21.435: INFO: Pod wasn't evicted. Test successful
  Dec  2 13:43:21.435: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "taint-single-pod-849" for this suite. @ 12/02/23 13:43:21.44
• [135.316 seconds]
------------------------------
[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:619
  STEP: Creating a kubernetes client @ 12/02/23 13:43:21.446
  Dec  2 13:43:21.446: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:43:21.447
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:43:21.464
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:43:21.467
  Dec  2 13:43:21.469: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: creating the pod @ 12/02/23 13:43:21.47
  STEP: submitting the pod to kubernetes @ 12/02/23 13:43:21.47
  E1202 13:43:22.098556      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:23.098646      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:43:23.511: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-7220" for this suite. @ 12/02/23 13:43:23.515
• [2.075 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]
test/e2e/apimachinery/custom_resource_definition.go:269
  STEP: Creating a kubernetes client @ 12/02/23 13:43:23.522
  Dec  2 13:43:23.522: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename custom-resource-definition @ 12/02/23 13:43:23.523
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:43:23.542
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:43:23.544
  Dec  2 13:43:23.547: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:43:24.099170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:25.099340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:26.100067      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:43:26.641: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "custom-resource-definition-2337" for this suite. @ 12/02/23 13:43:26.645
• [3.130 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:123
  STEP: Creating a kubernetes client @ 12/02/23 13:43:26.654
  Dec  2 13:43:26.654: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sysctl @ 12/02/23 13:43:26.654
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:43:26.671
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:43:26.673
  STEP: Creating a pod with one valid and two invalid sysctls @ 12/02/23 13:43:26.675
  Dec  2 13:43:26.680: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7831" for this suite. @ 12/02/23 13:43:26.684
• [0.044 seconds]
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/empty_dir.go:107
  STEP: Creating a kubernetes client @ 12/02/23 13:43:26.698
  Dec  2 13:43:26.698: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename emptydir @ 12/02/23 13:43:26.699
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:43:26.719
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:43:26.722
  STEP: Creating a pod to test emptydir 0666 on tmpfs @ 12/02/23 13:43:26.724
  E1202 13:43:27.101053      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:28.102144      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:29.102894      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:30.102994      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:43:30.74
  Dec  2 13:43:30.742: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-e0d8e14b-29a4-4b06-ac07-56b31e16a231 container test-container: <nil>
  STEP: delete the pod @ 12/02/23 13:43:30.761
  Dec  2 13:43:30.778: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "emptydir-7217" for this suite. @ 12/02/23 13:43:30.781
• [4.092 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]
test/e2e/scheduling/preemption.go:624
  STEP: Creating a kubernetes client @ 12/02/23 13:43:30.791
  Dec  2 13:43:30.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-preemption @ 12/02/23 13:43:30.791
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:43:30.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:43:30.816
  Dec  2 13:43:30.831: INFO: Waiting up to 1m0s for all nodes to be ready
  E1202 13:43:31.103585      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:32.103772      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:33.104744      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:34.104809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:35.104888      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:36.105719      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:37.105819      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:38.105914      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:39.106774      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:40.106865      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:41.107795      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:42.107950      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:43.108428      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:44.108643      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:45.109204      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:46.109300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:47.110293      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:48.110395      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:49.111084      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:50.111161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:51.112249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:52.112426      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:53.113441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:54.113607      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:55.114149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:56.114226      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:57.114790      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:58.115409      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:43:59.116030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:00.116116      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:01.116217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:02.116302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:03.117001      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:04.117172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:05.118049      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:06.118246      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:07.118419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:08.119277      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:09.119368      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:10.119462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:11.120217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:12.120386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:13.120462      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:14.120622      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:15.121039      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:16.121344      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:17.121822      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:18.122016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:19.122612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:20.122700      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:21.123610      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:22.124639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:23.125217      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:24.125760      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:25.125865      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:26.125944      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:27.126213      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:28.127287      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:29.128137      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:30.128298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:44:30.850: INFO: Waiting for terminating namespaces to be deleted...
  STEP: Creating a kubernetes client @ 12/02/23 13:44:30.853
  Dec  2 13:44:30.853: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sched-preemption-path @ 12/02/23 13:44:30.853
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:44:30.873
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:44:30.875
  STEP: Finding an available node @ 12/02/23 13:44:30.877
  STEP: Trying to launch a pod without a label to get a node which can launch it. @ 12/02/23 13:44:30.877
  E1202 13:44:31.128351      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:32.128419      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Explicitly delete pod here to free the resource it takes. @ 12/02/23 13:44:32.913
  Dec  2 13:44:32.926: INFO: found a healthy node: ip-172-31-1-50
  E1202 13:44:33.129342      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:34.130256      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:35.131113      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:36.131559      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:37.132389      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:38.132498      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:44:38.995: INFO: pods created so far: [1 1 1]
  Dec  2 13:44:38.995: INFO: length of pods created so far: 3
  E1202 13:44:39.132763      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:40.133153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:44:41.007: INFO: pods created so far: [2 2 1]
  E1202 13:44:41.133585      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:42.133697      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:43.133797      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:44.133926      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:45.134004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:46.134095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:47.134243      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:44:48.008: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  Dec  2 13:44:48.041: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sched-preemption-path-3644" for this suite. @ 12/02/23 13:44:48.079
  STEP: Destroying namespace "sched-preemption-7522" for this suite. @ 12/02/23 13:44:48.085
• [77.303 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/node/kubelet_etc_hosts.go:64
  STEP: Creating a kubernetes client @ 12/02/23 13:44:48.095
  Dec  2 13:44:48.095: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts @ 12/02/23 13:44:48.096
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:44:48.114
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:44:48.117
  STEP: Setting up the test @ 12/02/23 13:44:48.119
  STEP: Creating hostNetwork=false pod @ 12/02/23 13:44:48.119
  E1202 13:44:48.134501      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:49.135301      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:50.135722      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating hostNetwork=true pod @ 12/02/23 13:44:50.139
  E1202 13:44:51.135816      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:52.136030      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Running the test @ 12/02/23 13:44:52.154
  STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false @ 12/02/23 13:44:52.154
  Dec  2 13:44:52.154: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.154: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.154: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.155: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  2 13:44:52.227: INFO: Exec stderr: ""
  Dec  2 13:44:52.227: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.227: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.227: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.227: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  2 13:44:52.303: INFO: Exec stderr: ""
  Dec  2 13:44:52.303: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.303: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.304: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.304: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  2 13:44:52.367: INFO: Exec stderr: ""
  Dec  2 13:44:52.367: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.367: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.367: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.367: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  2 13:44:52.439: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount @ 12/02/23 13:44:52.439
  Dec  2 13:44:52.439: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.439: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.440: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.440: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec  2 13:44:52.507: INFO: Exec stderr: ""
  Dec  2 13:44:52.507: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.507: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.507: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.507: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
  Dec  2 13:44:52.583: INFO: Exec stderr: ""
  STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true @ 12/02/23 13:44:52.583
  Dec  2 13:44:52.583: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.583: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.584: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.584: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  2 13:44:52.655: INFO: Exec stderr: ""
  Dec  2 13:44:52.655: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.655: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.655: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.655: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
  Dec  2 13:44:52.718: INFO: Exec stderr: ""
  Dec  2 13:44:52.718: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.718: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.719: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.719: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  2 13:44:52.790: INFO: Exec stderr: ""
  Dec  2 13:44:52.790: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2400 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
  Dec  2 13:44:52.791: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  Dec  2 13:44:52.791: INFO: ExecWithOptions: Clientset creation
  Dec  2 13:44:52.791: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2400/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
  Dec  2 13:44:52.858: INFO: Exec stderr: ""
  Dec  2 13:44:52.858: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "e2e-kubelet-etc-hosts-2400" for this suite. @ 12/02/23 13:44:52.863
• [4.855 seconds]
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:321
  STEP: Creating a kubernetes client @ 12/02/23 13:44:52.951
  Dec  2 13:44:52.951: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename gc @ 12/02/23 13:44:52.951
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:44:52.97
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:44:52.972
  STEP: create the rc @ 12/02/23 13:44:52.975
  W1202 13:44:52.979988      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  E1202 13:44:53.136263      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:54.136371      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:55.136611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:56.136920      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:57.137074      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the rc @ 12/02/23 13:44:57.984
  STEP: wait for all pods to be garbage collected @ 12/02/23 13:44:57.991
  E1202 13:44:58.137197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:44:59.137410      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:00.137528      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:01.137809      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:02.137905      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/02/23 13:45:02.999
  W1202 13:45:03.005543      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  2 13:45:03.005: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  2 13:45:03.005: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-2498" for this suite. @ 12/02/23 13:45:03.008
• [10.070 seconds]
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency should not be very high  [Conformance]
test/e2e/network/service_latency.go:59
  STEP: Creating a kubernetes client @ 12/02/23 13:45:03.021
  Dec  2 13:45:03.021: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename svc-latency @ 12/02/23 13:45:03.022
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:45:03.038
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:45:03.04
  Dec  2 13:45:03.043: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: creating replication controller svc-latency-rc in namespace svc-latency-6824 @ 12/02/23 13:45:03.043
  I1202 13:45:03.047916      18 runners.go:197] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6824, replica count: 1
  E1202 13:45:03.138667      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:45:04.099242      18 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1202 13:45:04.139420      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  I1202 13:45:05.099396      18 runners.go:197] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
  E1202 13:45:05.139782      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:05.211: INFO: Created: latency-svc-4dzrh
  Dec  2 13:45:05.218: INFO: Got endpoints: latency-svc-4dzrh [18.972123ms]
  Dec  2 13:45:05.231: INFO: Created: latency-svc-tbch8
  Dec  2 13:45:05.238: INFO: Got endpoints: latency-svc-tbch8 [19.489463ms]
  Dec  2 13:45:05.240: INFO: Created: latency-svc-7l9bn
  Dec  2 13:45:05.248: INFO: Created: latency-svc-5jjm7
  Dec  2 13:45:05.248: INFO: Got endpoints: latency-svc-7l9bn [29.356534ms]
  Dec  2 13:45:05.251: INFO: Created: latency-svc-x72ft
  Dec  2 13:45:05.255: INFO: Got endpoints: latency-svc-5jjm7 [35.586766ms]
  Dec  2 13:45:05.260: INFO: Got endpoints: latency-svc-x72ft [40.773264ms]
  Dec  2 13:45:05.262: INFO: Created: latency-svc-czkz4
  Dec  2 13:45:05.269: INFO: Got endpoints: latency-svc-czkz4 [49.621835ms]
  Dec  2 13:45:05.269: INFO: Created: latency-svc-8jldl
  Dec  2 13:45:05.274: INFO: Got endpoints: latency-svc-8jldl [54.926882ms]
  Dec  2 13:45:05.275: INFO: Created: latency-svc-z8682
  Dec  2 13:45:05.302: INFO: Created: latency-svc-cpqpf
  Dec  2 13:45:05.303: INFO: Got endpoints: latency-svc-z8682 [84.112355ms]
  Dec  2 13:45:05.309: INFO: Got endpoints: latency-svc-cpqpf [89.98336ms]
  Dec  2 13:45:05.312: INFO: Created: latency-svc-bklm2
  Dec  2 13:45:05.319: INFO: Got endpoints: latency-svc-bklm2 [100.241141ms]
  Dec  2 13:45:05.319: INFO: Created: latency-svc-fk8t2
  Dec  2 13:45:05.324: INFO: Got endpoints: latency-svc-fk8t2 [105.528409ms]
  Dec  2 13:45:05.325: INFO: Created: latency-svc-jzjsb
  Dec  2 13:45:05.332: INFO: Got endpoints: latency-svc-jzjsb [113.192574ms]
  Dec  2 13:45:05.333: INFO: Created: latency-svc-sjh5d
  Dec  2 13:45:05.338: INFO: Created: latency-svc-khkm7
  Dec  2 13:45:05.339: INFO: Got endpoints: latency-svc-sjh5d [119.914604ms]
  Dec  2 13:45:05.342: INFO: Got endpoints: latency-svc-khkm7 [122.616393ms]
  Dec  2 13:45:05.343: INFO: Created: latency-svc-brtft
  Dec  2 13:45:05.348: INFO: Got endpoints: latency-svc-brtft [128.686254ms]
  Dec  2 13:45:05.351: INFO: Created: latency-svc-xd9z2
  Dec  2 13:45:05.356: INFO: Got endpoints: latency-svc-xd9z2 [137.24064ms]
  Dec  2 13:45:05.357: INFO: Created: latency-svc-dfvwm
  Dec  2 13:45:05.364: INFO: Created: latency-svc-9s7jc
  Dec  2 13:45:05.365: INFO: Got endpoints: latency-svc-dfvwm [126.664384ms]
  Dec  2 13:45:05.371: INFO: Got endpoints: latency-svc-9s7jc [122.931707ms]
  Dec  2 13:45:05.374: INFO: Created: latency-svc-rzxms
  Dec  2 13:45:05.377: INFO: Got endpoints: latency-svc-rzxms [121.967882ms]
  Dec  2 13:45:05.380: INFO: Created: latency-svc-pztsz
  Dec  2 13:45:05.385: INFO: Got endpoints: latency-svc-pztsz [124.498859ms]
  Dec  2 13:45:05.387: INFO: Created: latency-svc-plc2c
  Dec  2 13:45:05.393: INFO: Got endpoints: latency-svc-plc2c [123.737934ms]
  Dec  2 13:45:05.396: INFO: Created: latency-svc-vh8s9
  Dec  2 13:45:05.400: INFO: Created: latency-svc-5crm9
  Dec  2 13:45:05.401: INFO: Got endpoints: latency-svc-vh8s9 [126.853401ms]
  Dec  2 13:45:05.406: INFO: Got endpoints: latency-svc-5crm9 [102.606762ms]
  Dec  2 13:45:05.410: INFO: Created: latency-svc-g6nx9
  Dec  2 13:45:05.415: INFO: Created: latency-svc-595vq
  Dec  2 13:45:05.416: INFO: Got endpoints: latency-svc-g6nx9 [106.446923ms]
  Dec  2 13:45:05.421: INFO: Got endpoints: latency-svc-595vq [101.030376ms]
  Dec  2 13:45:05.423: INFO: Created: latency-svc-r8jvd
  Dec  2 13:45:05.428: INFO: Got endpoints: latency-svc-r8jvd [103.096151ms]
  Dec  2 13:45:05.428: INFO: Created: latency-svc-bmt9f
  Dec  2 13:45:05.438: INFO: Got endpoints: latency-svc-bmt9f [105.33565ms]
  Dec  2 13:45:05.438: INFO: Created: latency-svc-j5725
  Dec  2 13:45:05.443: INFO: Got endpoints: latency-svc-j5725 [103.639615ms]
  Dec  2 13:45:05.445: INFO: Created: latency-svc-tkdk4
  Dec  2 13:45:05.449: INFO: Got endpoints: latency-svc-tkdk4 [107.494436ms]
  Dec  2 13:45:05.451: INFO: Created: latency-svc-49dgh
  Dec  2 13:45:05.457: INFO: Got endpoints: latency-svc-49dgh [109.416777ms]
  Dec  2 13:45:05.460: INFO: Created: latency-svc-9n2tn
  Dec  2 13:45:05.465: INFO: Got endpoints: latency-svc-9n2tn [108.274574ms]
  Dec  2 13:45:05.467: INFO: Created: latency-svc-8swpz
  Dec  2 13:45:05.472: INFO: Created: latency-svc-jlprm
  Dec  2 13:45:05.473: INFO: Got endpoints: latency-svc-8swpz [107.587554ms]
  Dec  2 13:45:05.484: INFO: Got endpoints: latency-svc-jlprm [113.073232ms]
  Dec  2 13:45:05.486: INFO: Created: latency-svc-bs7p8
  Dec  2 13:45:05.486: INFO: Got endpoints: latency-svc-bs7p8 [108.737179ms]
  Dec  2 13:45:05.489: INFO: Created: latency-svc-gjp87
  Dec  2 13:45:05.495: INFO: Created: latency-svc-hb9xl
  Dec  2 13:45:05.497: INFO: Got endpoints: latency-svc-gjp87 [111.918192ms]
  Dec  2 13:45:05.502: INFO: Created: latency-svc-v5bs9
  Dec  2 13:45:05.508: INFO: Created: latency-svc-864vg
  Dec  2 13:45:05.515: INFO: Got endpoints: latency-svc-hb9xl [121.943588ms]
  Dec  2 13:45:05.516: INFO: Created: latency-svc-hdgsd
  Dec  2 13:45:05.523: INFO: Created: latency-svc-bk5g9
  Dec  2 13:45:05.529: INFO: Created: latency-svc-27jxr
  Dec  2 13:45:05.533: INFO: Created: latency-svc-bfqbl
  Dec  2 13:45:05.540: INFO: Created: latency-svc-w5gr7
  Dec  2 13:45:05.545: INFO: Created: latency-svc-684pz
  Dec  2 13:45:05.550: INFO: Created: latency-svc-cjw7f
  Dec  2 13:45:05.555: INFO: Created: latency-svc-6l9nw
  Dec  2 13:45:05.560: INFO: Created: latency-svc-zlm78
  Dec  2 13:45:05.564: INFO: Got endpoints: latency-svc-v5bs9 [163.274426ms]
  Dec  2 13:45:05.566: INFO: Created: latency-svc-vpnhj
  Dec  2 13:45:05.575: INFO: Created: latency-svc-7g77x
  Dec  2 13:45:05.578: INFO: Created: latency-svc-7gzqt
  Dec  2 13:45:05.582: INFO: Created: latency-svc-ndwwp
  Dec  2 13:45:05.590: INFO: Created: latency-svc-kqlzd
  Dec  2 13:45:05.615: INFO: Got endpoints: latency-svc-864vg [208.993276ms]
  Dec  2 13:45:05.625: INFO: Created: latency-svc-gszkq
  Dec  2 13:45:05.666: INFO: Got endpoints: latency-svc-hdgsd [250.212801ms]
  Dec  2 13:45:05.675: INFO: Created: latency-svc-wmllq
  Dec  2 13:45:05.716: INFO: Got endpoints: latency-svc-bk5g9 [295.084634ms]
  Dec  2 13:45:05.727: INFO: Created: latency-svc-rwpst
  Dec  2 13:45:05.766: INFO: Got endpoints: latency-svc-27jxr [338.383638ms]
  Dec  2 13:45:05.785: INFO: Created: latency-svc-mvtxp
  Dec  2 13:45:05.814: INFO: Got endpoints: latency-svc-bfqbl [376.1087ms]
  Dec  2 13:45:05.825: INFO: Created: latency-svc-kstt4
  Dec  2 13:45:05.865: INFO: Got endpoints: latency-svc-w5gr7 [421.915287ms]
  Dec  2 13:45:05.875: INFO: Created: latency-svc-tkf7g
  Dec  2 13:45:05.917: INFO: Got endpoints: latency-svc-684pz [467.541132ms]
  Dec  2 13:45:05.926: INFO: Created: latency-svc-kt79w
  Dec  2 13:45:05.964: INFO: Got endpoints: latency-svc-cjw7f [506.85761ms]
  Dec  2 13:45:05.975: INFO: Created: latency-svc-qcxxw
  Dec  2 13:45:06.015: INFO: Got endpoints: latency-svc-6l9nw [549.718404ms]
  Dec  2 13:45:06.025: INFO: Created: latency-svc-fc78p
  Dec  2 13:45:06.065: INFO: Got endpoints: latency-svc-zlm78 [592.609753ms]
  Dec  2 13:45:06.075: INFO: Created: latency-svc-c54pc
  Dec  2 13:45:06.115: INFO: Got endpoints: latency-svc-vpnhj [631.253066ms]
  Dec  2 13:45:06.126: INFO: Created: latency-svc-t2v7j
  E1202 13:45:06.140513      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:06.166: INFO: Got endpoints: latency-svc-7g77x [680.263627ms]
  Dec  2 13:45:06.176: INFO: Created: latency-svc-z6s69
  Dec  2 13:45:06.214: INFO: Got endpoints: latency-svc-7gzqt [717.485906ms]
  Dec  2 13:45:06.227: INFO: Created: latency-svc-kf2p8
  Dec  2 13:45:06.264: INFO: Got endpoints: latency-svc-ndwwp [749.361692ms]
  Dec  2 13:45:06.273: INFO: Created: latency-svc-x4fnd
  Dec  2 13:45:06.316: INFO: Got endpoints: latency-svc-kqlzd [751.50396ms]
  Dec  2 13:45:06.326: INFO: Created: latency-svc-jcrzr
  Dec  2 13:45:06.366: INFO: Got endpoints: latency-svc-gszkq [750.888809ms]
  Dec  2 13:45:06.376: INFO: Created: latency-svc-jdmx8
  Dec  2 13:45:06.415: INFO: Got endpoints: latency-svc-wmllq [749.251803ms]
  Dec  2 13:45:06.426: INFO: Created: latency-svc-fc8gf
  Dec  2 13:45:06.465: INFO: Got endpoints: latency-svc-rwpst [748.58508ms]
  Dec  2 13:45:06.475: INFO: Created: latency-svc-5jhvp
  Dec  2 13:45:06.515: INFO: Got endpoints: latency-svc-mvtxp [748.990989ms]
  Dec  2 13:45:06.525: INFO: Created: latency-svc-dlcqr
  Dec  2 13:45:06.566: INFO: Got endpoints: latency-svc-kstt4 [751.908181ms]
  Dec  2 13:45:06.576: INFO: Created: latency-svc-frstp
  Dec  2 13:45:06.615: INFO: Got endpoints: latency-svc-tkf7g [750.404933ms]
  Dec  2 13:45:06.626: INFO: Created: latency-svc-smlwz
  Dec  2 13:45:06.666: INFO: Got endpoints: latency-svc-kt79w [749.285097ms]
  Dec  2 13:45:06.676: INFO: Created: latency-svc-qq5g7
  Dec  2 13:45:06.719: INFO: Got endpoints: latency-svc-qcxxw [755.002532ms]
  Dec  2 13:45:06.730: INFO: Created: latency-svc-25x78
  Dec  2 13:45:06.764: INFO: Got endpoints: latency-svc-fc78p [749.2063ms]
  Dec  2 13:45:06.775: INFO: Created: latency-svc-rz98j
  Dec  2 13:45:06.816: INFO: Got endpoints: latency-svc-c54pc [750.022782ms]
  Dec  2 13:45:06.825: INFO: Created: latency-svc-wmcmg
  Dec  2 13:45:06.869: INFO: Got endpoints: latency-svc-t2v7j [753.139738ms]
  Dec  2 13:45:06.878: INFO: Created: latency-svc-q58qp
  Dec  2 13:45:06.914: INFO: Got endpoints: latency-svc-z6s69 [747.997408ms]
  Dec  2 13:45:06.927: INFO: Created: latency-svc-d87wb
  Dec  2 13:45:06.964: INFO: Got endpoints: latency-svc-kf2p8 [749.721303ms]
  Dec  2 13:45:06.975: INFO: Created: latency-svc-jsxcn
  Dec  2 13:45:07.014: INFO: Got endpoints: latency-svc-x4fnd [750.159186ms]
  Dec  2 13:45:07.024: INFO: Created: latency-svc-vlbrn
  Dec  2 13:45:07.066: INFO: Got endpoints: latency-svc-jcrzr [749.59028ms]
  Dec  2 13:45:07.076: INFO: Created: latency-svc-49vxq
  Dec  2 13:45:07.115: INFO: Got endpoints: latency-svc-jdmx8 [749.591639ms]
  Dec  2 13:45:07.125: INFO: Created: latency-svc-f6clp
  E1202 13:45:07.141358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:07.166: INFO: Got endpoints: latency-svc-fc8gf [750.420107ms]
  Dec  2 13:45:07.178: INFO: Created: latency-svc-gxl7h
  Dec  2 13:45:07.215: INFO: Got endpoints: latency-svc-5jhvp [750.087182ms]
  Dec  2 13:45:07.227: INFO: Created: latency-svc-dkwft
  Dec  2 13:45:07.264: INFO: Got endpoints: latency-svc-dlcqr [748.632919ms]
  Dec  2 13:45:07.274: INFO: Created: latency-svc-bxcvp
  Dec  2 13:45:07.316: INFO: Got endpoints: latency-svc-frstp [749.104905ms]
  Dec  2 13:45:07.325: INFO: Created: latency-svc-cpxb5
  Dec  2 13:45:07.366: INFO: Got endpoints: latency-svc-smlwz [750.543681ms]
  Dec  2 13:45:07.377: INFO: Created: latency-svc-l9fv7
  Dec  2 13:45:07.414: INFO: Got endpoints: latency-svc-qq5g7 [747.689286ms]
  Dec  2 13:45:07.424: INFO: Created: latency-svc-cphk4
  Dec  2 13:45:07.465: INFO: Got endpoints: latency-svc-25x78 [745.097561ms]
  Dec  2 13:45:07.475: INFO: Created: latency-svc-8thr8
  Dec  2 13:45:07.516: INFO: Got endpoints: latency-svc-rz98j [751.166911ms]
  Dec  2 13:45:07.528: INFO: Created: latency-svc-dfxjj
  Dec  2 13:45:07.567: INFO: Got endpoints: latency-svc-wmcmg [750.748235ms]
  Dec  2 13:45:07.576: INFO: Created: latency-svc-wlx25
  Dec  2 13:45:07.615: INFO: Got endpoints: latency-svc-q58qp [746.463689ms]
  Dec  2 13:45:07.624: INFO: Created: latency-svc-vnsr4
  Dec  2 13:45:07.664: INFO: Got endpoints: latency-svc-d87wb [749.838579ms]
  Dec  2 13:45:07.676: INFO: Created: latency-svc-tjmjm
  Dec  2 13:45:07.714: INFO: Got endpoints: latency-svc-jsxcn [749.843651ms]
  Dec  2 13:45:07.723: INFO: Created: latency-svc-pmm67
  Dec  2 13:45:07.766: INFO: Got endpoints: latency-svc-vlbrn [751.842383ms]
  Dec  2 13:45:07.775: INFO: Created: latency-svc-td9h4
  Dec  2 13:45:07.816: INFO: Got endpoints: latency-svc-49vxq [749.888091ms]
  Dec  2 13:45:07.826: INFO: Created: latency-svc-2fpz5
  Dec  2 13:45:07.866: INFO: Got endpoints: latency-svc-f6clp [750.250324ms]
  Dec  2 13:45:07.875: INFO: Created: latency-svc-qlz7w
  Dec  2 13:45:07.914: INFO: Got endpoints: latency-svc-gxl7h [748.160831ms]
  Dec  2 13:45:07.925: INFO: Created: latency-svc-5qwcf
  Dec  2 13:45:07.965: INFO: Got endpoints: latency-svc-dkwft [749.723023ms]
  Dec  2 13:45:07.974: INFO: Created: latency-svc-rmczs
  Dec  2 13:45:08.020: INFO: Got endpoints: latency-svc-bxcvp [755.895501ms]
  Dec  2 13:45:08.029: INFO: Created: latency-svc-4b99h
  Dec  2 13:45:08.066: INFO: Got endpoints: latency-svc-cpxb5 [750.276737ms]
  Dec  2 13:45:08.075: INFO: Created: latency-svc-kblbb
  Dec  2 13:45:08.116: INFO: Got endpoints: latency-svc-l9fv7 [749.547148ms]
  Dec  2 13:45:08.125: INFO: Created: latency-svc-2mqfq
  E1202 13:45:08.141606      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:08.164: INFO: Got endpoints: latency-svc-cphk4 [750.066429ms]
  Dec  2 13:45:08.174: INFO: Created: latency-svc-5q549
  Dec  2 13:45:08.216: INFO: Got endpoints: latency-svc-8thr8 [751.905945ms]
  Dec  2 13:45:08.227: INFO: Created: latency-svc-6zb66
  Dec  2 13:45:08.265: INFO: Got endpoints: latency-svc-dfxjj [748.642461ms]
  Dec  2 13:45:08.278: INFO: Created: latency-svc-b7hdx
  Dec  2 13:45:08.313: INFO: Got endpoints: latency-svc-wlx25 [746.353153ms]
  Dec  2 13:45:08.337: INFO: Created: latency-svc-6hshn
  Dec  2 13:45:08.364: INFO: Got endpoints: latency-svc-vnsr4 [748.822474ms]
  Dec  2 13:45:08.375: INFO: Created: latency-svc-4mbnw
  Dec  2 13:45:08.416: INFO: Got endpoints: latency-svc-tjmjm [751.507152ms]
  Dec  2 13:45:08.426: INFO: Created: latency-svc-mwhpp
  Dec  2 13:45:08.466: INFO: Got endpoints: latency-svc-pmm67 [751.489242ms]
  Dec  2 13:45:08.478: INFO: Created: latency-svc-x6ptg
  Dec  2 13:45:08.514: INFO: Got endpoints: latency-svc-td9h4 [747.727128ms]
  Dec  2 13:45:08.525: INFO: Created: latency-svc-pdl5n
  Dec  2 13:45:08.564: INFO: Got endpoints: latency-svc-2fpz5 [748.031605ms]
  Dec  2 13:45:08.576: INFO: Created: latency-svc-7d9b5
  Dec  2 13:45:08.614: INFO: Got endpoints: latency-svc-qlz7w [748.024582ms]
  Dec  2 13:45:08.624: INFO: Created: latency-svc-xb878
  Dec  2 13:45:08.665: INFO: Got endpoints: latency-svc-5qwcf [750.074657ms]
  Dec  2 13:45:08.692: INFO: Created: latency-svc-j976n
  Dec  2 13:45:08.715: INFO: Got endpoints: latency-svc-rmczs [750.271104ms]
  Dec  2 13:45:08.725: INFO: Created: latency-svc-d5vn8
  Dec  2 13:45:08.763: INFO: Got endpoints: latency-svc-4b99h [743.065235ms]
  Dec  2 13:45:08.773: INFO: Created: latency-svc-6gs6j
  Dec  2 13:45:08.814: INFO: Got endpoints: latency-svc-kblbb [747.460523ms]
  Dec  2 13:45:08.824: INFO: Created: latency-svc-kxq6c
  Dec  2 13:45:08.865: INFO: Got endpoints: latency-svc-2mqfq [748.90401ms]
  Dec  2 13:45:08.875: INFO: Created: latency-svc-pdvlk
  Dec  2 13:45:08.913: INFO: Got endpoints: latency-svc-5q549 [749.371516ms]
  Dec  2 13:45:08.923: INFO: Created: latency-svc-jsz6h
  Dec  2 13:45:08.965: INFO: Got endpoints: latency-svc-6zb66 [748.689347ms]
  Dec  2 13:45:08.975: INFO: Created: latency-svc-s6n7z
  Dec  2 13:45:09.016: INFO: Got endpoints: latency-svc-b7hdx [751.492011ms]
  Dec  2 13:45:09.026: INFO: Created: latency-svc-4k2s6
  Dec  2 13:45:09.066: INFO: Got endpoints: latency-svc-6hshn [752.571457ms]
  Dec  2 13:45:09.076: INFO: Created: latency-svc-rccqb
  Dec  2 13:45:09.120: INFO: Got endpoints: latency-svc-4mbnw [756.019677ms]
  Dec  2 13:45:09.130: INFO: Created: latency-svc-7kc74
  E1202 13:45:09.142620      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:09.164: INFO: Got endpoints: latency-svc-mwhpp [748.469858ms]
  Dec  2 13:45:09.176: INFO: Created: latency-svc-jbzff
  Dec  2 13:45:09.213: INFO: Got endpoints: latency-svc-x6ptg [747.226785ms]
  Dec  2 13:45:09.226: INFO: Created: latency-svc-4sm4z
  Dec  2 13:45:09.265: INFO: Got endpoints: latency-svc-pdl5n [750.387884ms]
  Dec  2 13:45:09.274: INFO: Created: latency-svc-gg5bj
  Dec  2 13:45:09.315: INFO: Got endpoints: latency-svc-7d9b5 [751.141762ms]
  Dec  2 13:45:09.325: INFO: Created: latency-svc-8jrk4
  Dec  2 13:45:09.366: INFO: Got endpoints: latency-svc-xb878 [751.618002ms]
  Dec  2 13:45:09.388: INFO: Created: latency-svc-k5q54
  Dec  2 13:45:09.414: INFO: Got endpoints: latency-svc-j976n [749.562768ms]
  Dec  2 13:45:09.425: INFO: Created: latency-svc-8j9sx
  Dec  2 13:45:09.464: INFO: Got endpoints: latency-svc-d5vn8 [748.59456ms]
  Dec  2 13:45:09.475: INFO: Created: latency-svc-wdzdh
  Dec  2 13:45:09.514: INFO: Got endpoints: latency-svc-6gs6j [750.98792ms]
  Dec  2 13:45:09.524: INFO: Created: latency-svc-5s77p
  Dec  2 13:45:09.566: INFO: Got endpoints: latency-svc-kxq6c [752.599005ms]
  Dec  2 13:45:09.576: INFO: Created: latency-svc-8pwfj
  Dec  2 13:45:09.616: INFO: Got endpoints: latency-svc-pdvlk [751.165652ms]
  Dec  2 13:45:09.626: INFO: Created: latency-svc-bbzkv
  Dec  2 13:45:09.664: INFO: Got endpoints: latency-svc-jsz6h [750.686059ms]
  Dec  2 13:45:09.677: INFO: Created: latency-svc-t4khc
  Dec  2 13:45:09.715: INFO: Got endpoints: latency-svc-s6n7z [749.338498ms]
  Dec  2 13:45:09.724: INFO: Created: latency-svc-d2s9z
  Dec  2 13:45:09.768: INFO: Got endpoints: latency-svc-4k2s6 [751.624224ms]
  Dec  2 13:45:09.778: INFO: Created: latency-svc-ckkmf
  Dec  2 13:45:09.816: INFO: Got endpoints: latency-svc-rccqb [750.683405ms]
  Dec  2 13:45:09.826: INFO: Created: latency-svc-q6plk
  Dec  2 13:45:09.865: INFO: Got endpoints: latency-svc-7kc74 [744.711857ms]
  Dec  2 13:45:09.876: INFO: Created: latency-svc-cs54z
  Dec  2 13:45:09.914: INFO: Got endpoints: latency-svc-jbzff [749.323009ms]
  Dec  2 13:45:09.926: INFO: Created: latency-svc-ldk5c
  Dec  2 13:45:09.964: INFO: Got endpoints: latency-svc-4sm4z [750.685758ms]
  Dec  2 13:45:09.974: INFO: Created: latency-svc-vjnws
  Dec  2 13:45:10.016: INFO: Got endpoints: latency-svc-gg5bj [751.101322ms]
  Dec  2 13:45:10.025: INFO: Created: latency-svc-zsqw7
  Dec  2 13:45:10.066: INFO: Got endpoints: latency-svc-8jrk4 [750.330352ms]
  Dec  2 13:45:10.076: INFO: Created: latency-svc-4j9lk
  Dec  2 13:45:10.115: INFO: Got endpoints: latency-svc-k5q54 [749.227244ms]
  Dec  2 13:45:10.128: INFO: Created: latency-svc-sfsfg
  E1202 13:45:10.142996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:10.163: INFO: Got endpoints: latency-svc-8j9sx [749.225543ms]
  Dec  2 13:45:10.173: INFO: Created: latency-svc-kx2mp
  Dec  2 13:45:10.216: INFO: Got endpoints: latency-svc-wdzdh [752.127759ms]
  Dec  2 13:45:10.228: INFO: Created: latency-svc-f9vnn
  Dec  2 13:45:10.265: INFO: Got endpoints: latency-svc-5s77p [751.061691ms]
  Dec  2 13:45:10.276: INFO: Created: latency-svc-nnltq
  Dec  2 13:45:10.315: INFO: Got endpoints: latency-svc-8pwfj [748.992161ms]
  Dec  2 13:45:10.325: INFO: Created: latency-svc-6s85n
  Dec  2 13:45:10.364: INFO: Got endpoints: latency-svc-bbzkv [748.26021ms]
  Dec  2 13:45:10.376: INFO: Created: latency-svc-pdh79
  Dec  2 13:45:10.414: INFO: Got endpoints: latency-svc-t4khc [750.100028ms]
  Dec  2 13:45:10.425: INFO: Created: latency-svc-tm9fn
  Dec  2 13:45:10.465: INFO: Got endpoints: latency-svc-d2s9z [750.880351ms]
  Dec  2 13:45:10.475: INFO: Created: latency-svc-dbr55
  Dec  2 13:45:10.518: INFO: Got endpoints: latency-svc-ckkmf [749.864115ms]
  Dec  2 13:45:10.527: INFO: Created: latency-svc-zrm6h
  Dec  2 13:45:10.564: INFO: Got endpoints: latency-svc-q6plk [747.867617ms]
  Dec  2 13:45:10.576: INFO: Created: latency-svc-d776h
  Dec  2 13:45:10.619: INFO: Got endpoints: latency-svc-cs54z [753.851667ms]
  Dec  2 13:45:10.635: INFO: Created: latency-svc-lrdwd
  Dec  2 13:45:10.664: INFO: Got endpoints: latency-svc-ldk5c [750.123645ms]
  Dec  2 13:45:10.674: INFO: Created: latency-svc-smxbk
  Dec  2 13:45:10.713: INFO: Got endpoints: latency-svc-vjnws [749.200684ms]
  Dec  2 13:45:10.725: INFO: Created: latency-svc-cdthh
  Dec  2 13:45:10.766: INFO: Got endpoints: latency-svc-zsqw7 [749.439762ms]
  Dec  2 13:45:10.775: INFO: Created: latency-svc-g8qws
  Dec  2 13:45:10.821: INFO: Got endpoints: latency-svc-4j9lk [755.147309ms]
  Dec  2 13:45:10.831: INFO: Created: latency-svc-jv2qd
  Dec  2 13:45:10.866: INFO: Got endpoints: latency-svc-sfsfg [750.853164ms]
  Dec  2 13:45:10.875: INFO: Created: latency-svc-nvxh2
  Dec  2 13:45:10.915: INFO: Got endpoints: latency-svc-kx2mp [751.07963ms]
  Dec  2 13:45:10.925: INFO: Created: latency-svc-4sj5j
  Dec  2 13:45:10.964: INFO: Got endpoints: latency-svc-f9vnn [747.423753ms]
  Dec  2 13:45:10.975: INFO: Created: latency-svc-vd2sc
  Dec  2 13:45:11.014: INFO: Got endpoints: latency-svc-nnltq [748.763498ms]
  Dec  2 13:45:11.025: INFO: Created: latency-svc-8jvms
  Dec  2 13:45:11.064: INFO: Got endpoints: latency-svc-6s85n [748.361244ms]
  Dec  2 13:45:11.073: INFO: Created: latency-svc-9vzlt
  Dec  2 13:45:11.115: INFO: Got endpoints: latency-svc-pdh79 [751.010707ms]
  Dec  2 13:45:11.125: INFO: Created: latency-svc-9b5hr
  E1202 13:45:11.143762      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:11.164: INFO: Got endpoints: latency-svc-tm9fn [749.880738ms]
  Dec  2 13:45:11.176: INFO: Created: latency-svc-dxk7s
  Dec  2 13:45:11.214: INFO: Got endpoints: latency-svc-dbr55 [748.377818ms]
  Dec  2 13:45:11.228: INFO: Created: latency-svc-wmr52
  Dec  2 13:45:11.266: INFO: Got endpoints: latency-svc-zrm6h [747.631434ms]
  Dec  2 13:45:11.275: INFO: Created: latency-svc-44gkk
  Dec  2 13:45:11.316: INFO: Got endpoints: latency-svc-d776h [751.165958ms]
  Dec  2 13:45:11.326: INFO: Created: latency-svc-k5x29
  Dec  2 13:45:11.366: INFO: Got endpoints: latency-svc-lrdwd [746.642069ms]
  Dec  2 13:45:11.377: INFO: Created: latency-svc-fg787
  Dec  2 13:45:11.414: INFO: Got endpoints: latency-svc-smxbk [749.855226ms]
  Dec  2 13:45:11.425: INFO: Created: latency-svc-j76m2
  Dec  2 13:45:11.467: INFO: Got endpoints: latency-svc-cdthh [753.377141ms]
  Dec  2 13:45:11.476: INFO: Created: latency-svc-9jvzk
  Dec  2 13:45:11.515: INFO: Got endpoints: latency-svc-g8qws [749.494425ms]
  Dec  2 13:45:11.524: INFO: Created: latency-svc-w6gqg
  Dec  2 13:45:11.566: INFO: Got endpoints: latency-svc-jv2qd [744.195406ms]
  Dec  2 13:45:11.576: INFO: Created: latency-svc-rgq2z
  Dec  2 13:45:11.614: INFO: Got endpoints: latency-svc-nvxh2 [747.681703ms]
  Dec  2 13:45:11.640: INFO: Created: latency-svc-64tns
  Dec  2 13:45:11.664: INFO: Got endpoints: latency-svc-4sj5j [749.668064ms]
  Dec  2 13:45:11.682: INFO: Created: latency-svc-zg2gb
  Dec  2 13:45:11.715: INFO: Got endpoints: latency-svc-vd2sc [750.352492ms]
  Dec  2 13:45:11.725: INFO: Created: latency-svc-r4cqt
  Dec  2 13:45:11.766: INFO: Got endpoints: latency-svc-8jvms [751.604616ms]
  Dec  2 13:45:11.775: INFO: Created: latency-svc-27rn7
  Dec  2 13:45:11.815: INFO: Got endpoints: latency-svc-9vzlt [750.910725ms]
  Dec  2 13:45:11.824: INFO: Created: latency-svc-jz8k4
  Dec  2 13:45:11.865: INFO: Got endpoints: latency-svc-9b5hr [750.121782ms]
  Dec  2 13:45:11.877: INFO: Created: latency-svc-56ttg
  Dec  2 13:45:11.914: INFO: Got endpoints: latency-svc-dxk7s [749.924945ms]
  Dec  2 13:45:11.924: INFO: Created: latency-svc-pr62t
  Dec  2 13:45:11.965: INFO: Got endpoints: latency-svc-wmr52 [751.269443ms]
  Dec  2 13:45:11.975: INFO: Created: latency-svc-pr786
  Dec  2 13:45:12.016: INFO: Got endpoints: latency-svc-44gkk [750.140467ms]
  Dec  2 13:45:12.030: INFO: Created: latency-svc-m88h2
  Dec  2 13:45:12.066: INFO: Got endpoints: latency-svc-k5x29 [750.27431ms]
  Dec  2 13:45:12.075: INFO: Created: latency-svc-6kpnh
  Dec  2 13:45:12.115: INFO: Got endpoints: latency-svc-fg787 [748.885277ms]
  Dec  2 13:45:12.125: INFO: Created: latency-svc-c2hqh
  E1202 13:45:12.144819      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:12.164: INFO: Got endpoints: latency-svc-j76m2 [750.171091ms]
  Dec  2 13:45:12.175: INFO: Created: latency-svc-59cxt
  Dec  2 13:45:12.216: INFO: Got endpoints: latency-svc-9jvzk [748.75763ms]
  Dec  2 13:45:12.226: INFO: Created: latency-svc-hvn7j
  Dec  2 13:45:12.268: INFO: Got endpoints: latency-svc-w6gqg [752.357655ms]
  Dec  2 13:45:12.277: INFO: Created: latency-svc-9kcvp
  Dec  2 13:45:12.316: INFO: Got endpoints: latency-svc-rgq2z [749.668014ms]
  Dec  2 13:45:12.326: INFO: Created: latency-svc-2v2fx
  Dec  2 13:45:12.366: INFO: Got endpoints: latency-svc-64tns [752.743194ms]
  Dec  2 13:45:12.378: INFO: Created: latency-svc-khwr7
  Dec  2 13:45:12.415: INFO: Got endpoints: latency-svc-zg2gb [750.904229ms]
  Dec  2 13:45:12.424: INFO: Created: latency-svc-qmxsx
  Dec  2 13:45:12.467: INFO: Got endpoints: latency-svc-r4cqt [752.411112ms]
  Dec  2 13:45:12.479: INFO: Created: latency-svc-6ql26
  Dec  2 13:45:12.515: INFO: Got endpoints: latency-svc-27rn7 [749.232209ms]
  Dec  2 13:45:12.525: INFO: Created: latency-svc-k7ls7
  Dec  2 13:45:12.565: INFO: Got endpoints: latency-svc-jz8k4 [750.273626ms]
  Dec  2 13:45:12.575: INFO: Created: latency-svc-72gvj
  Dec  2 13:45:12.614: INFO: Got endpoints: latency-svc-56ttg [748.488095ms]
  Dec  2 13:45:12.624: INFO: Created: latency-svc-msb64
  Dec  2 13:45:12.666: INFO: Got endpoints: latency-svc-pr62t [751.414173ms]
  Dec  2 13:45:12.675: INFO: Created: latency-svc-7ljpt
  Dec  2 13:45:12.715: INFO: Got endpoints: latency-svc-pr786 [749.937121ms]
  Dec  2 13:45:12.724: INFO: Created: latency-svc-dr5s5
  Dec  2 13:45:12.767: INFO: Got endpoints: latency-svc-m88h2 [751.427265ms]
  Dec  2 13:45:12.778: INFO: Created: latency-svc-wvnj9
  Dec  2 13:45:12.815: INFO: Got endpoints: latency-svc-6kpnh [748.867343ms]
  Dec  2 13:45:12.825: INFO: Created: latency-svc-f9jc6
  Dec  2 13:45:12.864: INFO: Got endpoints: latency-svc-c2hqh [749.185362ms]
  Dec  2 13:45:12.876: INFO: Created: latency-svc-695zf
  Dec  2 13:45:12.914: INFO: Got endpoints: latency-svc-59cxt [749.527574ms]
  Dec  2 13:45:12.924: INFO: Created: latency-svc-vbzv8
  Dec  2 13:45:12.965: INFO: Got endpoints: latency-svc-hvn7j [749.815675ms]
  Dec  2 13:45:12.975: INFO: Created: latency-svc-jq2ch
  Dec  2 13:45:13.016: INFO: Got endpoints: latency-svc-9kcvp [748.339801ms]
  Dec  2 13:45:13.025: INFO: Created: latency-svc-znrqj
  Dec  2 13:45:13.065: INFO: Got endpoints: latency-svc-2v2fx [749.494518ms]
  Dec  2 13:45:13.116: INFO: Got endpoints: latency-svc-khwr7 [749.594766ms]
  E1202 13:45:13.145501      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:13.164: INFO: Got endpoints: latency-svc-qmxsx [749.061667ms]
  Dec  2 13:45:13.214: INFO: Got endpoints: latency-svc-6ql26 [747.281484ms]
  Dec  2 13:45:13.264: INFO: Got endpoints: latency-svc-k7ls7 [748.474709ms]
  Dec  2 13:45:13.314: INFO: Got endpoints: latency-svc-72gvj [748.653282ms]
  Dec  2 13:45:13.366: INFO: Got endpoints: latency-svc-msb64 [751.674036ms]
  Dec  2 13:45:13.414: INFO: Got endpoints: latency-svc-7ljpt [747.999921ms]
  Dec  2 13:45:13.466: INFO: Got endpoints: latency-svc-dr5s5 [750.689332ms]
  Dec  2 13:45:13.516: INFO: Got endpoints: latency-svc-wvnj9 [748.277634ms]
  Dec  2 13:45:13.565: INFO: Got endpoints: latency-svc-f9jc6 [750.043107ms]
  Dec  2 13:45:13.616: INFO: Got endpoints: latency-svc-695zf [751.536387ms]
  Dec  2 13:45:13.666: INFO: Got endpoints: latency-svc-vbzv8 [751.502673ms]
  Dec  2 13:45:13.713: INFO: Got endpoints: latency-svc-jq2ch [747.420763ms]
  Dec  2 13:45:13.765: INFO: Got endpoints: latency-svc-znrqj [749.042453ms]
  Dec  2 13:45:13.765: INFO: Latencies: [19.489463ms 29.356534ms 35.586766ms 40.773264ms 49.621835ms 54.926882ms 84.112355ms 89.98336ms 100.241141ms 101.030376ms 102.606762ms 103.096151ms 103.639615ms 105.33565ms 105.528409ms 106.446923ms 107.494436ms 107.587554ms 108.274574ms 108.737179ms 109.416777ms 111.918192ms 113.073232ms 113.192574ms 119.914604ms 121.943588ms 121.967882ms 122.616393ms 122.931707ms 123.737934ms 124.498859ms 126.664384ms 126.853401ms 128.686254ms 137.24064ms 163.274426ms 208.993276ms 250.212801ms 295.084634ms 338.383638ms 376.1087ms 421.915287ms 467.541132ms 506.85761ms 549.718404ms 592.609753ms 631.253066ms 680.263627ms 717.485906ms 743.065235ms 744.195406ms 744.711857ms 745.097561ms 746.353153ms 746.463689ms 746.642069ms 747.226785ms 747.281484ms 747.420763ms 747.423753ms 747.460523ms 747.631434ms 747.681703ms 747.689286ms 747.727128ms 747.867617ms 747.997408ms 747.999921ms 748.024582ms 748.031605ms 748.160831ms 748.26021ms 748.277634ms 748.339801ms 748.361244ms 748.377818ms 748.469858ms 748.474709ms 748.488095ms 748.58508ms 748.59456ms 748.632919ms 748.642461ms 748.653282ms 748.689347ms 748.75763ms 748.763498ms 748.822474ms 748.867343ms 748.885277ms 748.90401ms 748.990989ms 748.992161ms 749.042453ms 749.061667ms 749.104905ms 749.185362ms 749.200684ms 749.2063ms 749.225543ms 749.227244ms 749.232209ms 749.251803ms 749.285097ms 749.323009ms 749.338498ms 749.361692ms 749.371516ms 749.439762ms 749.494425ms 749.494518ms 749.527574ms 749.547148ms 749.562768ms 749.59028ms 749.591639ms 749.594766ms 749.668014ms 749.668064ms 749.721303ms 749.723023ms 749.815675ms 749.838579ms 749.843651ms 749.855226ms 749.864115ms 749.880738ms 749.888091ms 749.924945ms 749.937121ms 750.022782ms 750.043107ms 750.066429ms 750.074657ms 750.087182ms 750.100028ms 750.121782ms 750.123645ms 750.140467ms 750.159186ms 750.171091ms 750.250324ms 750.271104ms 750.273626ms 750.27431ms 750.276737ms 750.330352ms 750.352492ms 750.387884ms 750.404933ms 750.420107ms 750.543681ms 750.683405ms 750.685758ms 750.686059ms 750.689332ms 750.748235ms 750.853164ms 750.880351ms 750.888809ms 750.904229ms 750.910725ms 750.98792ms 751.010707ms 751.061691ms 751.07963ms 751.101322ms 751.141762ms 751.165652ms 751.165958ms 751.166911ms 751.269443ms 751.414173ms 751.427265ms 751.489242ms 751.492011ms 751.502673ms 751.50396ms 751.507152ms 751.536387ms 751.604616ms 751.618002ms 751.624224ms 751.674036ms 751.842383ms 751.905945ms 751.908181ms 752.127759ms 752.357655ms 752.411112ms 752.571457ms 752.599005ms 752.743194ms 753.139738ms 753.377141ms 753.851667ms 755.002532ms 755.147309ms 755.895501ms 756.019677ms]
  Dec  2 13:45:13.765: INFO: 50 %ile: 749.227244ms
  Dec  2 13:45:13.765: INFO: 90 %ile: 751.604616ms
  Dec  2 13:45:13.765: INFO: 99 %ile: 755.895501ms
  Dec  2 13:45:13.765: INFO: Total sample count: 200
  Dec  2 13:45:13.765: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "svc-latency-6824" for this suite. @ 12/02/23 13:45:13.771
• [10.756 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]
test/e2e/common/storage/projected_secret.go:46
  STEP: Creating a kubernetes client @ 12/02/23 13:45:13.778
  Dec  2 13:45:13.778: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:45:13.779
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:45:13.794
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:45:13.796
  STEP: Creating projection with secret that has name projected-secret-test-447970ed-422f-4b47-880f-1771d5015546 @ 12/02/23 13:45:13.798
  STEP: Creating a pod to test consume secrets @ 12/02/23 13:45:13.804
  E1202 13:45:14.145683      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:15.145716      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:16.146230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:17.147306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:45:17.821
  Dec  2 13:45:17.824: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-projected-secrets-397b3319-fd8e-41a9-a8f4-37e123b940c2 container projected-secret-volume-test: <nil>
  STEP: delete the pod @ 12/02/23 13:45:17.837
  Dec  2 13:45:17.854: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-9283" for this suite. @ 12/02/23 13:45:17.857
• [4.086 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]
test/e2e/apps/rc.go:69
  STEP: Creating a kubernetes client @ 12/02/23 13:45:17.864
  Dec  2 13:45:17.864: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replication-controller @ 12/02/23 13:45:17.865
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:45:17.882
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:45:17.885
  STEP: Creating replication controller my-hostname-basic-b6f74a52-2f72-4d0d-8708-c4f6ca5443c9 @ 12/02/23 13:45:17.887
  Dec  2 13:45:17.895: INFO: Pod name my-hostname-basic-b6f74a52-2f72-4d0d-8708-c4f6ca5443c9: Found 0 pods out of 1
  E1202 13:45:18.147615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:19.147723      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:20.147798      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:21.147923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:22.147996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:22.901: INFO: Pod name my-hostname-basic-b6f74a52-2f72-4d0d-8708-c4f6ca5443c9: Found 1 pods out of 1
  Dec  2 13:45:22.901: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b6f74a52-2f72-4d0d-8708-c4f6ca5443c9" are running
  Dec  2 13:45:22.904: INFO: Pod "my-hostname-basic-b6f74a52-2f72-4d0d-8708-c4f6ca5443c9-dmgc7" is running and ready(conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 13:45:17 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 13:45:18 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 13:45:18 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2023-12-02 13:45:17 +0000 UTC Reason: Message:}])
  Dec  2 13:45:22.904: INFO: Trying to dial the pod
  STEP: trying to dial each unique pod @ 12/02/23 13:45:22.904
  Dec  2 13:45:22.916: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replication-controller-2594" for this suite. @ 12/02/23 13:45:22.919
• [5.063 seconds]
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]
test/e2e/apimachinery/crd_conversion_webhook.go:141
  STEP: Creating a kubernetes client @ 12/02/23 13:45:22.929
  Dec  2 13:45:22.929: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-webhook @ 12/02/23 13:45:22.93
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:45:22.946
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:45:22.948
  STEP: Setting up server cert @ 12/02/23 13:45:22.95
  E1202 13:45:23.152045      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication @ 12/02/23 13:45:23.432
  STEP: Deploying the custom resource conversion webhook pod @ 12/02/23 13:45:23.439
  STEP: Wait for the deployment to be ready @ 12/02/23 13:45:23.451
  Dec  2 13:45:23.458: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
  E1202 13:45:24.152122      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:25.152252      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Deploying the webhook service @ 12/02/23 13:45:25.468
  STEP: Verifying the service has paired with the endpoint @ 12/02/23 13:45:25.477
  E1202 13:45:26.152306      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:26.477: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  2 13:45:26.481: INFO: Unexpected error trying to get Endpoints for e2e-test-crd-conversion-webhook : endpoints "e2e-test-crd-conversion-webhook" not found
  E1202 13:45:27.152495      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:27.477: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  2 13:45:27.481: INFO: Unexpected error trying to get Endpoints for e2e-test-crd-conversion-webhook : endpoints "e2e-test-crd-conversion-webhook" not found
  E1202 13:45:28.152832      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:28.478: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  2 13:45:28.482: INFO: Unexpected error trying to get Endpoints for e2e-test-crd-conversion-webhook : endpoints "e2e-test-crd-conversion-webhook" not found
  E1202 13:45:29.153016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:29.478: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  2 13:45:29.481: INFO: Unexpected error trying to get Endpoints for e2e-test-crd-conversion-webhook : endpoints "e2e-test-crd-conversion-webhook" not found
  E1202 13:45:30.153283      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:30.477: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  2 13:45:30.481: INFO: Unexpected error trying to get Endpoints for e2e-test-crd-conversion-webhook : endpoints "e2e-test-crd-conversion-webhook" not found
  E1202 13:45:31.153570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:31.478: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
  Dec  2 13:45:31.485: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:45:32.154547      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:33.154623      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Creating a v1 custom resource @ 12/02/23 13:45:34.046
  STEP: v2 custom resource should be converted @ 12/02/23 13:45:34.05
  Dec  2 13:45:34.054: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  E1202 13:45:34.155027      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Destroying namespace "crd-webhook-6001" for this suite. @ 12/02/23 13:45:34.61
• [11.687 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:85
  STEP: Creating a kubernetes client @ 12/02/23 13:45:34.616
  Dec  2 13:45:34.616: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:45:34.616
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:45:34.636
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:45:34.639
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:45:34.641
  E1202 13:45:35.156034      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:36.156484      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:37.156589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:38.156678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:45:38.665
  Dec  2 13:45:38.669: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-997a4642-40e4-4eec-ac95-2e40d3a68cfe container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:45:38.68
  Dec  2 13:45:38.695: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-1386" for this suite. @ 12/02/23 13:45:38.698
• [4.088 seconds]
------------------------------
SSS
------------------------------
[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
test/e2e/apimachinery/aggregator.go:96
  STEP: Creating a kubernetes client @ 12/02/23 13:45:38.705
  Dec  2 13:45:38.705: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename aggregator @ 12/02/23 13:45:38.705
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:45:38.813
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:45:38.816
  Dec  2 13:45:38.818: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Registering the sample API server. @ 12/02/23 13:45:38.819
  Dec  2 13:45:39.118: INFO: Found ClusterRoles; assuming RBAC is enabled.
  Dec  2 13:45:39.144: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
  E1202 13:45:39.157638      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:40.157813      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:41.158265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:41.180: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:42.159340      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:43.159408      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:43.184: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:44.159492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:45.159669      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:45.184: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:46.159756      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:47.159933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:47.185: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:48.160876      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:49.160968      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:49.185: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:50.161052      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:51.161230      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:51.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:52.162197      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:53.162240      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:53.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:54.163299      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:55.163392      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:55.185: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:56.164262      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:57.164326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:57.184: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:45:58.164407      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:45:59.165314      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:45:59.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), LastTransitionTime:time.Date(2023, time.December, 2, 13, 45, 39, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-76f465f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
  E1202 13:46:00.165866      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:01.166140      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:46:01.302: INFO: Waited 109.570327ms for the sample-apiserver to be ready to handle requests.
  STEP: Read Status for v1alpha1.wardle.example.com @ 12/02/23 13:46:01.329
  STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' @ 12/02/23 13:46:01.332
  STEP: List APIServices @ 12/02/23 13:46:01.338
  Dec  2 13:46:01.343: INFO: Found v1alpha1.wardle.example.com in APIServiceList
  STEP: Adding a label to the APIService @ 12/02/23 13:46:01.343
  Dec  2 13:46:01.354: INFO: APIService labels: map[e2e-apiservice:patched]
  STEP: Updating APIService Status @ 12/02/23 13:46:01.354
  Dec  2 13:46:01.363: INFO: updatedStatus.Conditions: []v1.APIServiceCondition{v1.APIServiceCondition{Type:"Available", Status:"True", LastTransitionTime:time.Date(2023, time.December, 2, 13, 46, 1, 0, time.Local), Reason:"Passed", Message:"all checks passed"}, v1.APIServiceCondition{Type:"StatusUpdated", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: Confirm that v1alpha1.wardle.example.com /status was updated @ 12/02/23 13:46:01.363
  Dec  2 13:46:01.366: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {Available True 2023-12-02 13:46:01 +0000 UTC Passed all checks passed}
  Dec  2 13:46:01.366: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[e2e-apiservice:patched] & Condition: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  2 13:46:01.366: INFO: Found updated status condition for v1alpha1.wardle.example.com
  STEP: Replace APIService v1alpha1.wardle.example.com @ 12/02/23 13:46:01.366
  Dec  2 13:46:01.377: INFO: Found updated apiService label for "v1alpha1.wardle.example.com"
  STEP: Delete APIService "dynamic-flunder-61760936" @ 12/02/23 13:46:01.377
  STEP: Recreating test-flunder before removing endpoint via deleteCollection @ 12/02/23 13:46:01.384
  STEP: Read v1alpha1.wardle.example.com /status before patching it @ 12/02/23 13:46:01.391
  STEP: Patch APIService Status @ 12/02/23 13:46:01.394
  STEP: Confirm that v1alpha1.wardle.example.com /status was patched @ 12/02/23 13:46:01.4
  Dec  2 13:46:01.404: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {Available True 2023-12-02 13:46:01 +0000 UTC Passed all checks passed}
  Dec  2 13:46:01.404: INFO: Observed APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusUpdated True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  2 13:46:01.404: INFO: Found APIService v1alpha1.wardle.example.com with Labels: map[v1alpha1.wardle.example.com:updated] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC E2E Set by e2e test}
  Dec  2 13:46:01.404: INFO: Found patched status condition for v1alpha1.wardle.example.com
  STEP: APIService deleteCollection with labelSelector: "e2e-apiservice=patched" @ 12/02/23 13:46:01.404
  STEP: Confirm that the generated APIService has been deleted @ 12/02/23 13:46:01.407
  Dec  2 13:46:01.407: INFO: Requesting list of APIServices to confirm quantity
  Dec  2 13:46:01.411: INFO: Found 0 APIService with label "e2e-apiservice=patched"
  Dec  2 13:46:01.411: INFO: APIService v1alpha1.wardle.example.com has been deleted.
  Dec  2 13:46:01.480: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "aggregator-3729" for this suite. @ 12/02/23 13:46:01.508
• [22.810 seconds]
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]
test/e2e/common/node/downwardapi.go:91
  STEP: Creating a kubernetes client @ 12/02/23 13:46:01.515
  Dec  2 13:46:01.515: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:46:01.516
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:46:01.535
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:46:01.537
  STEP: Creating a pod to test downward api env vars @ 12/02/23 13:46:01.539
  E1202 13:46:02.167159      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:03.167321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:04.167416      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:05.167529      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:46:05.56
  Dec  2 13:46:05.564: INFO: Trying to get logs from node ip-172-31-1-50 pod downward-api-a66cf090-3e01-44ea-afa3-f80e5ddf6d34 container dapi-container: <nil>
  STEP: delete the pod @ 12/02/23 13:46:05.57
  Dec  2 13:46:05.585: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-6097" for this suite. @ 12/02/23 13:46:05.59
• [4.080 seconds]
------------------------------
S
------------------------------
[sig-network] Ingress API should support creating Ingress API operations [Conformance]
test/e2e/network/ingress.go:556
  STEP: Creating a kubernetes client @ 12/02/23 13:46:05.595
  Dec  2 13:46:05.595: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename ingress @ 12/02/23 13:46:05.596
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:46:05.612
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:46:05.614
  STEP: getting /apis @ 12/02/23 13:46:05.617
  STEP: getting /apis/networking.k8s.io @ 12/02/23 13:46:05.62
  STEP: getting /apis/networking.k8s.iov1 @ 12/02/23 13:46:05.621
  STEP: creating @ 12/02/23 13:46:05.622
  STEP: getting @ 12/02/23 13:46:05.64
  STEP: listing @ 12/02/23 13:46:05.645
  STEP: watching @ 12/02/23 13:46:05.648
  Dec  2 13:46:05.648: INFO: starting watch
  STEP: cluster-wide listing @ 12/02/23 13:46:05.649
  STEP: cluster-wide watching @ 12/02/23 13:46:05.652
  Dec  2 13:46:05.652: INFO: starting watch
  STEP: patching @ 12/02/23 13:46:05.653
  STEP: updating @ 12/02/23 13:46:05.659
  Dec  2 13:46:05.667: INFO: waiting for watch events with expected annotations
  Dec  2 13:46:05.667: INFO: saw patched and updated annotations
  STEP: patching /status @ 12/02/23 13:46:05.667
  STEP: updating /status @ 12/02/23 13:46:05.674
  STEP: get /status @ 12/02/23 13:46:05.683
  STEP: deleting @ 12/02/23 13:46:05.688
  STEP: deleting a collection @ 12/02/23 13:46:05.702
  Dec  2 13:46:05.720: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "ingress-6144" for this suite. @ 12/02/23 13:46:05.723
• [0.134 seconds]
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]
test/e2e/apimachinery/garbage_collector.go:479
  STEP: Creating a kubernetes client @ 12/02/23 13:46:05.73
  Dec  2 13:46:05.730: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename gc @ 12/02/23 13:46:05.73
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:46:05.744
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:46:05.747
  STEP: create the deployment @ 12/02/23 13:46:05.749
  W1202 13:46:05.754053      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/02/23 13:46:05.754
  STEP: delete the deployment @ 12/02/23 13:46:05.76
  STEP: wait for all rs to be garbage collected @ 12/02/23 13:46:05.772
  STEP: expected 0 rs, got 1 rs @ 12/02/23 13:46:05.777
  STEP: expected 0 pods, got 2 pods @ 12/02/23 13:46:05.782
  E1202 13:46:06.168131      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/02/23 13:46:06.297
  W1202 13:46:06.302524      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  2 13:46:06.302: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  2 13:46:06.302: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-3537" for this suite. @ 12/02/23 13:46:06.306
• [0.582 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]
test/e2e/apimachinery/crd_publish_openapi.go:357
  STEP: Creating a kubernetes client @ 12/02/23 13:46:06.312
  Dec  2 13:46:06.312: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename crd-publish-openapi @ 12/02/23 13:46:06.312
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:46:06.329
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:46:06.332
  STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation @ 12/02/23 13:46:06.334
  Dec  2 13:46:06.334: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:46:07.168740      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:46:07.639: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  E1202 13:46:08.169553      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:09.169763      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:10.169963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:11.170503      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:12.171172      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:46:12.840: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "crd-publish-openapi-9510" for this suite. @ 12/02/23 13:46:12.848
• [6.544 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
test/e2e/node/taints.go:450
  STEP: Creating a kubernetes client @ 12/02/23 13:46:12.857
  Dec  2 13:46:12.857: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename taint-multiple-pods @ 12/02/23 13:46:12.858
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:46:12.876
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:46:12.879
  Dec  2 13:46:12.881: INFO: Waiting up to 1m0s for all nodes to be ready
  E1202 13:46:13.171784      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:14.171963      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:15.172038      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:16.172525      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:17.173072      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:18.173169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:19.174229      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:20.174324      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:21.175085      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:22.175364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:23.176068      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:24.176249      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:25.176639      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:26.176908      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:27.176999      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:28.177210      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:29.178269      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:30.178358      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:31.179141      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:32.179220      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:33.179780      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:34.179868      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:35.180247      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:36.180773      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:37.181161      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:38.181253      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:39.181350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:40.181441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:41.181538      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:42.181612      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:43.181711      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:44.182372      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:45.183300      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:46.183684      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:47.184413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:48.184468      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:49.185149      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:50.185751      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:51.186617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:52.187282      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:53.187987      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:54.188078      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:55.188613      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:56.188933      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:57.188983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:58.189075      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:46:59.189775      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:00.190321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:01.190401      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:02.190492      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:03.190951      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:04.191291      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:05.191787      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:06.192155      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:07.192647      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:08.192743      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:09.192805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:10.192887      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:11.193500      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:12.193587      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:12.896: INFO: Waiting for terminating namespaces to be deleted...
  Dec  2 13:47:12.899: INFO: Starting informer...
  STEP: Starting pods... @ 12/02/23 13:47:12.899
  Dec  2 13:47:13.121: INFO: Pod1 is running on ip-172-31-1-50. Tainting Node
  E1202 13:47:13.193913      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:14.194974      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:15.195785      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:15.340: INFO: Pod2 is running on ip-172-31-1-50. Tainting Node
  STEP: Trying to apply a taint on the Node @ 12/02/23 13:47:15.34
  STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/02/23 13:47:15.349
  STEP: Waiting for Pod1 and Pod2 to be deleted @ 12/02/23 13:47:15.352
  E1202 13:47:16.196678      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:17.196766      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:18.196921      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:19.197093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:20.197258      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:20.850: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
  E1202 13:47:21.198211      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:22.199292      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:23.200322      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:24.200386      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:25.200533      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:26.200923      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:27.201001      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:28.201093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:29.201268      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:30.201360      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:31.201442      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:32.201601      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:33.202589      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:34.203298      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:35.204169      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:36.204496      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:37.204600      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:38.205171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:39.205265      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:40.205615      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:40.880: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
  Dec  2 13:47:40.880: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute @ 12/02/23 13:47:40.893
  STEP: Destroying namespace "taint-multiple-pods-2460" for this suite. @ 12/02/23 13:47:40.896
• [88.046 seconds]
------------------------------
SS
------------------------------
[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]
test/e2e/common/node/pods.go:227
  STEP: Creating a kubernetes client @ 12/02/23 13:47:40.903
  Dec  2 13:47:40.903: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename pods @ 12/02/23 13:47:40.904
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:47:40.925
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:47:40.928
  STEP: creating the pod @ 12/02/23 13:47:40.93
  STEP: setting up watch @ 12/02/23 13:47:40.93
  STEP: submitting the pod to kubernetes @ 12/02/23 13:47:41.037
  STEP: verifying the pod is in kubernetes @ 12/02/23 13:47:41.044
  STEP: verifying pod creation was observed @ 12/02/23 13:47:41.049
  E1202 13:47:41.205644      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:42.205693      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: deleting the pod gracefully @ 12/02/23 13:47:43.059
  STEP: verifying pod deletion was observed @ 12/02/23 13:47:43.066
  E1202 13:47:43.206171      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:43.895: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "pods-6462" for this suite. @ 12/02/23 13:47:43.899
• [3.002 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]
test/e2e/common/node/lifecycle_hook.go:152
  STEP: Creating a kubernetes client @ 12/02/23 13:47:43.909
  Dec  2 13:47:43.909: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename container-lifecycle-hook @ 12/02/23 13:47:43.909
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:47:43.929
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:47:43.933
  STEP: create the container to handle the HTTPGet hook request. @ 12/02/23 13:47:43.941
  E1202 13:47:44.206201      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:45.206233      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: create the pod with lifecycle hook @ 12/02/23 13:47:45.961
  E1202 13:47:46.207004      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:47.207096      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: delete the pod with lifecycle hook @ 12/02/23 13:47:47.979
  E1202 13:47:48.207872      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:49.208057      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: check prestop hook @ 12/02/23 13:47:49.993
  Dec  2 13:47:50.007: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "container-lifecycle-hook-1372" for this suite. @ 12/02/23 13:47:50.013
• [6.115 seconds]
------------------------------
[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]
test/e2e/network/endpointslice.go:68
  STEP: Creating a kubernetes client @ 12/02/23 13:47:50.024
  Dec  2 13:47:50.024: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename endpointslice @ 12/02/23 13:47:50.024
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:47:50.042
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:47:50.045
  Dec  2 13:47:50.064: INFO: Endpoints addresses: [172.31.12.62 172.31.22.152] , ports: [6443]
  Dec  2 13:47:50.064: INFO: EndpointSlices addresses: [172.31.12.62 172.31.22.152] , ports: [6443]
  Dec  2 13:47:50.064: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "endpointslice-9484" for this suite. @ 12/02/23 13:47:50.072
• [0.059 seconds]
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services should serve a basic endpoint from pods  [Conformance]
test/e2e/network/service.go:785
  STEP: Creating a kubernetes client @ 12/02/23 13:47:50.083
  Dec  2 13:47:50.083: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:47:50.084
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:47:50.107
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:47:50.11
  STEP: creating service endpoint-test2 in namespace services-2520 @ 12/02/23 13:47:50.112
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2520 to expose endpoints map[] @ 12/02/23 13:47:50.121
  Dec  2 13:47:50.129: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
  E1202 13:47:50.208975      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:51.138: INFO: successfully validated that service endpoint-test2 in namespace services-2520 exposes endpoints map[]
  STEP: Creating pod pod1 in namespace services-2520 @ 12/02/23 13:47:51.138
  E1202 13:47:51.209366      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:52.209441      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2520 to expose endpoints map[pod1:[80]] @ 12/02/23 13:47:53.156
  Dec  2 13:47:53.166: INFO: successfully validated that service endpoint-test2 in namespace services-2520 exposes endpoints map[pod1:[80]]
  STEP: Checking if the Service forwards traffic to pod1 @ 12/02/23 13:47:53.166
  Dec  2 13:47:53.166: INFO: Creating new exec pod
  E1202 13:47:53.211170      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:54.211443      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:55.212097      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:56.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2520 exec execpod2kpn5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  E1202 13:47:56.212590      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:56.294: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec  2 13:47:56.294: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:47:56.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2520 exec execpod2kpn5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.86 80'
  Dec  2 13:47:56.409: INFO: stderr: "+ nc -v -t -w 2 10.152.183.86 80\nConnection to 10.152.183.86 80 port [tcp/http] succeeded!\n+ echo hostName\n"
  Dec  2 13:47:56.409: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Creating pod pod2 in namespace services-2520 @ 12/02/23 13:47:56.409
  E1202 13:47:57.213522      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:47:58.213611      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2520 to expose endpoints map[pod1:[80] pod2:[80]] @ 12/02/23 13:47:58.423
  Dec  2 13:47:58.436: INFO: successfully validated that service endpoint-test2 in namespace services-2520 exposes endpoints map[pod1:[80] pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod1 and pod2 @ 12/02/23 13:47:58.436
  E1202 13:47:59.213722      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:47:59.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2520 exec execpod2kpn5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec  2 13:47:59.565: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec  2 13:47:59.565: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:47:59.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2520 exec execpod2kpn5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.86 80'
  Dec  2 13:47:59.676: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.86 80\nConnection to 10.152.183.86 80 port [tcp/http] succeeded!\n"
  Dec  2 13:47:59.676: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod1 in namespace services-2520 @ 12/02/23 13:47:59.676
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2520 to expose endpoints map[pod2:[80]] @ 12/02/23 13:47:59.692
  E1202 13:48:00.213805      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:48:00.714: INFO: successfully validated that service endpoint-test2 in namespace services-2520 exposes endpoints map[pod2:[80]]
  STEP: Checking if the Service forwards traffic to pod2 @ 12/02/23 13:48:00.714
  E1202 13:48:01.214539      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:48:01.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2520 exec execpod2kpn5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
  Dec  2 13:48:01.830: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
  Dec  2 13:48:01.830: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  Dec  2 13:48:01.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-1098306035 --namespace=services-2520 exec execpod2kpn5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.86 80'
  Dec  2 13:48:01.945: INFO: stderr: "+ nc -v -t -w 2 10.152.183.86 80\n+ echo hostName\nConnection to 10.152.183.86 80 port [tcp/http] succeeded!\n"
  Dec  2 13:48:01.945: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
  STEP: Deleting pod pod2 in namespace services-2520 @ 12/02/23 13:48:01.945
  STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2520 to expose endpoints map[] @ 12/02/23 13:48:01.963
  E1202 13:48:02.214930      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:48:02.981: INFO: successfully validated that service endpoint-test2 in namespace services-2520 exposes endpoints map[]
  Dec  2 13:48:02.981: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-2520" for this suite. @ 12/02/23 13:48:02.999
• [12.923 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
test/e2e/common/node/sysctl.go:77
  STEP: Creating a kubernetes client @ 12/02/23 13:48:03.007
  Dec  2 13:48:03.007: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename sysctl @ 12/02/23 13:48:03.008
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:03.025
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:03.027
  STEP: Creating a pod with the kernel.shm_rmid_forced sysctl @ 12/02/23 13:48:03.03
  STEP: Watching for error events or started pod @ 12/02/23 13:48:03.04
  E1202 13:48:03.215762      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:04.215873      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Waiting for pod completion @ 12/02/23 13:48:05.044
  E1202 13:48:05.216470      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:06.216570      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Checking that the pod succeeded @ 12/02/23 13:48:07.053
  STEP: Getting logs from the pod @ 12/02/23 13:48:07.053
  STEP: Checking that the sysctl is actually updated @ 12/02/23 13:48:07.06
  Dec  2 13:48:07.060: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "sysctl-7859" for this suite. @ 12/02/23 13:48:07.064
• [4.064 seconds]
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]
test/e2e/common/storage/downwardapi_volume.go:236
  STEP: Creating a kubernetes client @ 12/02/23 13:48:07.072
  Dec  2 13:48:07.072: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename downward-api @ 12/02/23 13:48:07.073
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:07.09
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:07.093
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:48:07.096
  E1202 13:48:07.216781      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:08.216864      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:48:09.113
  Dec  2 13:48:09.117: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-fea25465-2c1b-46f0-98b7-03e97f766b60 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:48:09.13
  Dec  2 13:48:09.146: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "downward-api-2032" for this suite. @ 12/02/23 13:48:09.15
• [2.084 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]
test/e2e/common/storage/projected_downwardapi.go:208
  STEP: Creating a kubernetes client @ 12/02/23 13:48:09.186
  Dec  2 13:48:09.186: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename projected @ 12/02/23 13:48:09.187
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:09.205
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:09.207
  STEP: Creating a pod to test downward API volume plugin @ 12/02/23 13:48:09.21
  E1202 13:48:09.217321      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:10.218095      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:11.218316      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:12.218359      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:13.219297      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:48:13.231
  Dec  2 13:48:13.234: INFO: Trying to get logs from node ip-172-31-1-50 pod downwardapi-volume-72e5ce9c-d5f1-4218-ba49-26ec1d4d5320 container client-container: <nil>
  STEP: delete the pod @ 12/02/23 13:48:13.24
  Dec  2 13:48:13.256: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "projected-5624" for this suite. @ 12/02/23 13:48:13.26
• [4.081 seconds]
------------------------------
S
------------------------------
[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]
test/e2e/apps/replica_set.go:176
  STEP: Creating a kubernetes client @ 12/02/23 13:48:13.267
  Dec  2 13:48:13.267: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename replicaset @ 12/02/23 13:48:13.269
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:13.286
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:13.288
  STEP: Create a Replicaset @ 12/02/23 13:48:13.294
  STEP: Verify that the required pods have come up. @ 12/02/23 13:48:13.299
  Dec  2 13:48:13.303: INFO: Pod name sample-pod: Found 0 pods out of 1
  E1202 13:48:14.219786      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:15.220338      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:16.220413      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:17.220541      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:18.221520      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  Dec  2 13:48:18.308: INFO: Pod name sample-pod: Found 1 pods out of 1
  STEP: ensuring each pod is running @ 12/02/23 13:48:18.308
  STEP: Getting /status @ 12/02/23 13:48:18.308
  Dec  2 13:48:18.313: INFO: Replicaset test-rs has Conditions: []
  STEP: updating the Replicaset Status @ 12/02/23 13:48:18.313
  Dec  2 13:48:18.327: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
  STEP: watching for the ReplicaSet status to be updated @ 12/02/23 13:48:18.327
  Dec  2 13:48:18.329: INFO: Observed &ReplicaSet event: ADDED
  Dec  2 13:48:18.329: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  2 13:48:18.329: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  2 13:48:18.330: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  2 13:48:18.330: INFO: Found replicaset test-rs in namespace replicaset-4004 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
  Dec  2 13:48:18.330: INFO: Replicaset test-rs has an updated status
  STEP: patching the Replicaset Status @ 12/02/23 13:48:18.33
  Dec  2 13:48:18.330: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
  Dec  2 13:48:18.337: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
  STEP: watching for the Replicaset status to be patched @ 12/02/23 13:48:18.337
  Dec  2 13:48:18.339: INFO: Observed &ReplicaSet event: ADDED
  Dec  2 13:48:18.339: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  2 13:48:18.339: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  2 13:48:18.339: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  2 13:48:18.339: INFO: Observed replicaset test-rs in namespace replicaset-4004 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
  Dec  2 13:48:18.339: INFO: Observed &ReplicaSet event: MODIFIED
  Dec  2 13:48:18.339: INFO: Found replicaset test-rs in namespace replicaset-4004 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
  Dec  2 13:48:18.339: INFO: Replicaset test-rs has a patched status
  Dec  2 13:48:18.339: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "replicaset-4004" for this suite. @ 12/02/23 13:48:18.344
• [5.085 seconds]
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
test/e2e/apimachinery/garbage_collector.go:538
  STEP: Creating a kubernetes client @ 12/02/23 13:48:18.352
  Dec  2 13:48:18.352: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename gc @ 12/02/23 13:48:18.353
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:18.37
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:18.372
  STEP: create the deployment @ 12/02/23 13:48:18.374
  W1202 13:48:18.380237      18 warnings.go:70] metadata.name: this is used in Pod names and hostnames, which can result in surprising behavior; a DNS label is recommended: [must not contain dots]
  STEP: Wait for the Deployment to create new ReplicaSet @ 12/02/23 13:48:18.38
  STEP: delete the deployment @ 12/02/23 13:48:18.891
  STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs @ 12/02/23 13:48:18.9
  E1202 13:48:19.222236      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Gathering metrics @ 12/02/23 13:48:19.423
  W1202 13:48:19.428601      18 metrics_grabber.go:152] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
  Dec  2 13:48:19.428: INFO: For apiserver_request_total:
  For apiserver_request_latency_seconds:
  For apiserver_init_events_total:
  For garbage_collector_attempt_to_delete_queue_latency:
  For garbage_collector_attempt_to_delete_work_duration:
  For garbage_collector_attempt_to_orphan_queue_latency:
  For garbage_collector_attempt_to_orphan_work_duration:
  For garbage_collector_dirty_processing_latency_microseconds:
  For garbage_collector_event_processing_latency_microseconds:
  For garbage_collector_graph_changes_queue_latency:
  For garbage_collector_graph_changes_work_duration:
  For garbage_collector_orphan_processing_latency_microseconds:
  For namespace_queue_latency:
  For namespace_queue_latency_sum:
  For namespace_queue_latency_count:
  For namespace_retries:
  For namespace_work_duration:
  For namespace_work_duration_sum:
  For namespace_work_duration_count:
  For function_duration_seconds:
  For errors_total:
  For evicted_pods_total:

  Dec  2 13:48:19.428: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "gc-4614" for this suite. @ 12/02/23 13:48:19.432
• [1.085 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]
test/e2e/storage/subpath.go:69
  STEP: Creating a kubernetes client @ 12/02/23 13:48:19.44
  Dec  2 13:48:19.440: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename subpath @ 12/02/23 13:48:19.441
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:19.458
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:19.46
  STEP: Setting up data @ 12/02/23 13:48:19.463
  STEP: Creating pod pod-subpath-test-configmap-sbs2 @ 12/02/23 13:48:19.472
  STEP: Creating a pod to test atomic-volume-subpath @ 12/02/23 13:48:19.472
  E1202 13:48:20.223154      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:21.223237      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:22.223344      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:23.223617      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:24.224093      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:25.224178      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:26.225016      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:27.225276      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:28.225350      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:29.225525      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:30.225983      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:31.226241      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:32.226326      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:33.227302      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:34.228153      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:35.228261      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:36.229094      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:37.229189      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:38.230041      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:39.230915      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:40.230996      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:41.231099      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:42.231186      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:43.231364      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:48:43.533
  Dec  2 13:48:43.536: INFO: Trying to get logs from node ip-172-31-74-39 pod pod-subpath-test-configmap-sbs2 container test-container-subpath-configmap-sbs2: <nil>
  STEP: delete the pod @ 12/02/23 13:48:43.547
  STEP: Deleting pod pod-subpath-test-configmap-sbs2 @ 12/02/23 13:48:43.564
  Dec  2 13:48:43.564: INFO: Deleting pod "pod-subpath-test-configmap-sbs2" in namespace "subpath-9868"
  Dec  2 13:48:43.567: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "subpath-9868" for this suite. @ 12/02/23 13:48:43.571
• [24.137 seconds]
------------------------------
SSS
------------------------------
[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]
test/e2e/common/node/configmap.go:93
  STEP: Creating a kubernetes client @ 12/02/23 13:48:43.578
  Dec  2 13:48:43.578: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 13:48:43.578
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:43.602
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:43.605
  STEP: Creating configMap configmap-8515/configmap-test-10f11e99-61e5-4edd-a095-4a6acd9456ae @ 12/02/23 13:48:43.607
  STEP: Creating a pod to test consume configMaps @ 12/02/23 13:48:43.611
  E1202 13:48:44.232215      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:45.232295      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:46.233077      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  E1202 13:48:47.233235      18 retrywatcher.go:129] "Watch failed" err="context canceled"
  STEP: Saw pod success @ 12/02/23 13:48:47.637
  Dec  2 13:48:47.640: INFO: Trying to get logs from node ip-172-31-1-50 pod pod-configmaps-f6f88fe4-3d31-495b-bc7b-672b6624027a container env-test: <nil>
  STEP: delete the pod @ 12/02/23 13:48:47.65
  Dec  2 13:48:47.667: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-8515" for this suite. @ 12/02/23 13:48:47.67
• [4.107 seconds]
------------------------------
SS
------------------------------
[sig-network] Services should delete a collection of services [Conformance]
test/e2e/network/service.go:3552
  STEP: Creating a kubernetes client @ 12/02/23 13:48:47.685
  Dec  2 13:48:47.685: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename services @ 12/02/23 13:48:47.686
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:47.738
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:47.74
  STEP: creating a collection of services @ 12/02/23 13:48:47.743
  Dec  2 13:48:47.743: INFO: Creating e2e-svc-a-m5vp7
  Dec  2 13:48:47.756: INFO: Creating e2e-svc-b-wnpxw
  Dec  2 13:48:47.768: INFO: Creating e2e-svc-c-krnrp
  STEP: deleting service collection @ 12/02/23 13:48:47.78
  Dec  2 13:48:47.813: INFO: Collection of services has been deleted
  Dec  2 13:48:47.813: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "services-8310" for this suite. @ 12/02/23 13:48:47.818
• [0.139 seconds]
------------------------------
[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]
test/e2e/common/node/configmap.go:138
  STEP: Creating a kubernetes client @ 12/02/23 13:48:47.825
  Dec  2 13:48:47.825: INFO: >>> kubeConfig: /tmp/kubeconfig-1098306035
  STEP: Building a namespace api object, basename configmap @ 12/02/23 13:48:47.825
  STEP: Waiting for a default service account to be provisioned in namespace @ 12/02/23 13:48:47.84
  STEP: Waiting for kube-root-ca.crt to be provisioned in namespace @ 12/02/23 13:48:47.842
  STEP: Creating configMap that has name configmap-test-emptyKey-b74a8047-40ea-4038-8934-615e3d325e20 @ 12/02/23 13:48:47.844
  Dec  2 13:48:47.846: INFO: Waiting up to 7m0s for all (but 0) nodes to be ready
  STEP: Destroying namespace "configmap-5364" for this suite. @ 12/02/23 13:48:47.85
• [0.033 seconds]
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:88
  Dec  2 13:48:47.859: INFO: Running AfterSuite actions on node 1
  Dec  2 13:48:47.859: INFO: Skipping dumping logs from cluster
[SynchronizedAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:157
[ReportAfterSuite] PASSED [0.000 seconds]
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:585
[ReportAfterSuite] PASSED [0.031 seconds]
------------------------------

Ran 380 of 7389 Specs in 6052.301 seconds
SUCCESS! -- 380 Passed | 0 Failed | 0 Pending | 7009 Skipped
PASS

Ginkgo ran 1 suite in 1h40m52.561039764s
Test Suite Passed
