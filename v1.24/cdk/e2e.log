I0702 11:53:39.604769      20 e2e.go:129] Starting e2e run "f4084c13-e4fd-49f1-97ce-b13d9ea6ead5" on Ginkgo node 1
{"msg":"Test Suite starting","total":356,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1656762819 - Will randomize all specs
Will run 356 of 6971 specs

Jul  2 11:53:41.639: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 11:53:41.640: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jul  2 11:53:41.652: INFO: Condition Ready of node ip-172-31-9-92 is false, but Node is tainted by NodeController with [{node.kubernetes.io/not-ready  NoSchedule 2022-07-02 11:53:38 +0000 UTC} {node.kubernetes.io/not-ready  NoExecute 2022-07-02 11:53:40 +0000 UTC}]. Failure
Jul  2 11:53:41.652: INFO: Unschedulable nodes= 1, maximum value for starting tests= 0
Jul  2 11:53:41.652: INFO: 	-> Node ip-172-31-9-92 [[[ Ready=false, Network(available)=false, Taints=[{node.kubernetes.io/not-ready  NoSchedule 2022-07-02 11:53:38 +0000 UTC} {node.kubernetes.io/not-ready  NoExecute 2022-07-02 11:53:40 +0000 UTC}], NonblockingTaints=juju.is/kubernetes-control-plane ]]]
Jul  2 11:53:41.652: INFO: ==== node wait: 4 out of 5 nodes are ready, max notReady allowed 0.  Need 1 more before starting.
Jul  2 11:54:11.662: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jul  2 11:54:11.681: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jul  2 11:54:11.681: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Jul  2 11:54:11.681: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jul  2 11:54:11.684: INFO: e2e test version: v1.24.2
Jul  2 11:54:11.686: INFO: kube-apiserver version: v1.24.2
Jul  2 11:54:11.686: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 11:54:11.690: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:54:11.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
W0702 11:54:11.717967      20 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
Jul  2 11:54:11.718: INFO: Found PodSecurityPolicies; testing pod creation to see if PodSecurityPolicy is enabled
Jul  2 11:54:11.732: INFO: PSP annotation exists on dry run pod: "privileged"; assuming PodSecurityPolicy is enabled
W0702 11:54:11.735029      20 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
W0702 11:54:11.741073      20 warnings.go:70] policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+
Jul  2 11:54:11.751: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8299
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8299
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8299
STEP: creating replication controller externalsvc in namespace services-8299
I0702 11:54:11.927463      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8299, replica count: 2
I0702 11:54:14.978338      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0702 11:54:17.978526      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Jul  2 11:54:18.007: INFO: Creating new exec pod
Jul  2 11:54:20.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8299 exec execpodd5kjk -- /bin/sh -x -c nslookup nodeport-service.services-8299.svc.cluster.local'
Jul  2 11:54:20.353: INFO: stderr: "+ nslookup nodeport-service.services-8299.svc.cluster.local\n"
Jul  2 11:54:20.353: INFO: stdout: "Server:\t\t10.152.183.155\nAddress:\t10.152.183.155#53\n\nnodeport-service.services-8299.svc.cluster.local\tcanonical name = externalsvc.services-8299.svc.cluster.local.\nName:\texternalsvc.services-8299.svc.cluster.local\nAddress: 10.152.183.41\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8299, will wait for the garbage collector to delete the pods
Jul  2 11:54:20.419: INFO: Deleting ReplicationController externalsvc took: 10.323367ms
Jul  2 11:54:20.520: INFO: Terminating ReplicationController externalsvc pods took: 100.891502ms
Jul  2 11:54:22.756: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 11:54:22.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8299" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:11.107 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":356,"completed":1,"skipped":27,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:54:22.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7057
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Pod
STEP: Reading file content from the nginx-container
Jul  2 11:54:24.966: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7057 PodName:pod-sharedvolume-6bee3527-cc53-452c-a621-13cfcfa468b4 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 11:54:24.966: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 11:54:24.967: INFO: ExecWithOptions: Clientset creation
Jul  2 11:54:24.967: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-7057/pods/pod-sharedvolume-6bee3527-cc53-452c-a621-13cfcfa468b4/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Jul  2 11:54:25.032: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 11:54:25.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7057" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":356,"completed":2,"skipped":37,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:54:25.048: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3335
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod test-webserver-4fe0d24e-3be3-4186-a5fb-fcab40c94e68 in namespace container-probe-3335
Jul  2 11:54:27.216: INFO: Started pod test-webserver-4fe0d24e-3be3-4186-a5fb-fcab40c94e68 in namespace container-probe-3335
STEP: checking the pod's current state and verifying that restartCount is present
Jul  2 11:54:27.219: INFO: Initial restart count of pod test-webserver-4fe0d24e-3be3-4186-a5fb-fcab40c94e68 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 11:58:28.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3335" for this suite.

• [SLOW TEST:243.133 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":3,"skipped":46,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:58:28.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7709
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  2 11:58:55.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7709" for this suite.

• [SLOW TEST:27.506 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":356,"completed":4,"skipped":58,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:58:55.688: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9720
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with projected pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-projected-l67p
STEP: Creating a pod to test atomic-volume-subpath
Jul  2 11:58:55.847: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-l67p" in namespace "subpath-9720" to be "Succeeded or Failed"
Jul  2 11:58:55.852: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Pending", Reason="", readiness=false. Elapsed: 4.704409ms
Jul  2 11:58:57.862: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 2.015484533s
Jul  2 11:58:59.869: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 4.022081525s
Jul  2 11:59:01.876: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 6.028973182s
Jul  2 11:59:03.882: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 8.034967912s
Jul  2 11:59:05.886: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 10.039156386s
Jul  2 11:59:07.891: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 12.044500945s
Jul  2 11:59:09.899: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 14.052446005s
Jul  2 11:59:11.907: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 16.060056302s
Jul  2 11:59:13.916: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 18.068844974s
Jul  2 11:59:15.922: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=true. Elapsed: 20.075435103s
Jul  2 11:59:17.929: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Running", Reason="", readiness=false. Elapsed: 22.082341157s
Jul  2 11:59:19.937: INFO: Pod "pod-subpath-test-projected-l67p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.090462068s
STEP: Saw pod success
Jul  2 11:59:19.937: INFO: Pod "pod-subpath-test-projected-l67p" satisfied condition "Succeeded or Failed"
Jul  2 11:59:19.942: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-subpath-test-projected-l67p container test-container-subpath-projected-l67p: <nil>
STEP: delete the pod
Jul  2 11:59:19.979: INFO: Waiting for pod pod-subpath-test-projected-l67p to disappear
Jul  2 11:59:19.982: INFO: Pod pod-subpath-test-projected-l67p no longer exists
STEP: Deleting pod pod-subpath-test-projected-l67p
Jul  2 11:59:19.982: INFO: Deleting pod "pod-subpath-test-projected-l67p" in namespace "subpath-9720"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  2 11:59:19.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9720" for this suite.

• [SLOW TEST:24.311 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","total":356,"completed":5,"skipped":66,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:59:19.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9755
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 11:59:20.473: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 11, 59, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 11, 59, 20, 0, time.Local), Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-68c7bd4684\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 11, 59, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 11, 59, 20, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 11:59:23.496: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 11:59:33.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9755" for this suite.
STEP: Destroying namespace "webhook-9755-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:13.819 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":356,"completed":6,"skipped":83,"failed":0}
SSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:59:33.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4679
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  2 11:59:33.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4679" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":356,"completed":7,"skipped":87,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:59:34.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename disruption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in disruption-9422
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Updating PodDisruptionBudget status
STEP: Waiting for all pods to be running
Jul  2 11:59:36.170: INFO: running pods: 0 < 1
STEP: locating a running pod
STEP: Waiting for the pdb to be processed
STEP: Patching PodDisruptionBudget status
STEP: Waiting for the pdb to be processed
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  2 11:59:38.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9422" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","total":356,"completed":8,"skipped":108,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:59:38.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9631
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Creating a NodePort Service
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota
STEP: Ensuring resource quota status captures service creation
STEP: Deleting Services
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 11:59:49.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9631" for this suite.

• [SLOW TEST:11.319 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":356,"completed":9,"skipped":114,"failed":0}
SSSSSSSS
------------------------------
[sig-node] RuntimeClass 
   should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:59:49.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename runtimeclass
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in runtimeclass-4047
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/node.k8s.io
STEP: getting /apis/node.k8s.io/v1
STEP: creating
STEP: watching
Jul  2 11:59:49.711: INFO: starting watch
STEP: getting
STEP: listing
STEP: patching
STEP: updating
Jul  2 11:59:49.740: INFO: waiting for watch events with expected annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  2 11:59:49.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4047" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","total":356,"completed":10,"skipped":122,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:59:49.790: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2207
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  2 11:59:49.943: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  2 11:59:51.952: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  2 11:59:51.968: INFO: The status of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  2 11:59:53.978: INFO: The status of Pod pod-with-prestop-exec-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Jul  2 11:59:53.992: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  2 11:59:53.995: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  2 11:59:55.996: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  2 11:59:56.000: INFO: Pod pod-with-prestop-exec-hook still exists
Jul  2 11:59:57.996: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jul  2 11:59:58.002: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  2 11:59:58.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2207" for this suite.

• [SLOW TEST:8.248 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":356,"completed":11,"skipped":138,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 11:59:58.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3326
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul  2 11:59:58.187: INFO: Waiting up to 5m0s for pod "pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf" in namespace "emptydir-3326" to be "Succeeded or Failed"
Jul  2 11:59:58.194: INFO: Pod "pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf": Phase="Pending", Reason="", readiness=false. Elapsed: 7.256462ms
Jul  2 12:00:00.204: INFO: Pod "pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01680457s
Jul  2 12:00:02.212: INFO: Pod "pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025395148s
STEP: Saw pod success
Jul  2 12:00:02.212: INFO: Pod "pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf" satisfied condition "Succeeded or Failed"
Jul  2 12:00:02.216: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf container test-container: <nil>
STEP: delete the pod
Jul  2 12:00:02.238: INFO: Waiting for pod pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf to disappear
Jul  2 12:00:02.243: INFO: Pod pod-9c526c4d-4b3a-456b-9a0f-096c9bb32fdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:00:02.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3326" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":12,"skipped":170,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:00:02.257: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-821
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:00:02.395: INFO: Creating pod...
Jul  2 12:00:04.415: INFO: Creating service...
Jul  2 12:00:04.430: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/pods/agnhost/proxy?method=DELETE
Jul  2 12:00:04.444: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  2 12:00:04.444: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/pods/agnhost/proxy?method=OPTIONS
Jul  2 12:00:04.454: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  2 12:00:04.454: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/pods/agnhost/proxy?method=PATCH
Jul  2 12:00:04.459: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  2 12:00:04.459: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/pods/agnhost/proxy?method=POST
Jul  2 12:00:04.465: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  2 12:00:04.465: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/pods/agnhost/proxy?method=PUT
Jul  2 12:00:04.472: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul  2 12:00:04.472: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/services/e2e-proxy-test-service/proxy?method=DELETE
Jul  2 12:00:04.480: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  2 12:00:04.480: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/services/e2e-proxy-test-service/proxy?method=OPTIONS
Jul  2 12:00:04.487: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  2 12:00:04.487: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/services/e2e-proxy-test-service/proxy?method=PATCH
Jul  2 12:00:04.496: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  2 12:00:04.496: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/services/e2e-proxy-test-service/proxy?method=POST
Jul  2 12:00:04.504: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  2 12:00:04.504: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/services/e2e-proxy-test-service/proxy?method=PUT
Jul  2 12:00:04.512: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul  2 12:00:04.512: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/pods/agnhost/proxy?method=GET
Jul  2 12:00:04.517: INFO: http.Client request:GET StatusCode:301
Jul  2 12:00:04.517: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/services/e2e-proxy-test-service/proxy?method=GET
Jul  2 12:00:04.522: INFO: http.Client request:GET StatusCode:301
Jul  2 12:00:04.522: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/pods/agnhost/proxy?method=HEAD
Jul  2 12:00:04.526: INFO: http.Client request:HEAD StatusCode:301
Jul  2 12:00:04.526: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-821/services/e2e-proxy-test-service/proxy?method=HEAD
Jul  2 12:00:04.535: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Jul  2 12:00:04.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-821" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","total":356,"completed":13,"skipped":194,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:00:04.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2820
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1574
[It] should update a single-container pod's image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  2 12:00:04.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2820 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jul  2 12:00:04.760: INFO: stderr: ""
Jul  2 12:00:04.760: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Jul  2 12:00:09.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2820 get pod e2e-test-httpd-pod -o json'
Jul  2 12:00:09.870: INFO: stderr: ""
Jul  2 12:00:09.870: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2022-07-02T12:00:04Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2820\",\n        \"resourceVersion\": \"3228\",\n        \"uid\": \"452e6863-c236-4d1b-98bf-7b1be15c25aa\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-tkcxc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-9-92\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-tkcxc\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-02T12:00:04Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-02T12:00:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-02T12:00:09Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-07-02T12:00:04Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://649216450326df839c1ab25d19f9d523454d640f7b0d4d9b08b9bf6ccd1b781a\",\n                \"image\": \"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-07-02T12:00:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.9.92\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.231.14\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.231.14\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-07-02T12:00:04Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jul  2 12:00:09.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2820 replace -f -'
Jul  2 12:00:10.636: INFO: stderr: ""
Jul  2 12:00:10.636: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/busybox:1.29-2
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1578
Jul  2 12:00:10.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2820 delete pods e2e-test-httpd-pod'
Jul  2 12:00:13.191: INFO: stderr: ""
Jul  2 12:00:13.191: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:00:13.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2820" for this suite.

• [SLOW TEST:8.657 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1571
    should update a single-container pod's image  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":356,"completed":14,"skipped":210,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:00:13.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1751
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  2 12:00:13.362: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:00:15.368: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:00:17.372: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:00:19.369: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  2 12:00:19.391: INFO: The status of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:00:21.397: INFO: The status of Pod pod-with-prestop-http-hook is Running (Ready = true)
STEP: delete the pod with lifecycle hook
Jul  2 12:00:21.411: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  2 12:00:21.416: INFO: Pod pod-with-prestop-http-hook still exists
Jul  2 12:00:23.417: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  2 12:00:23.425: INFO: Pod pod-with-prestop-http-hook still exists
Jul  2 12:00:25.417: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jul  2 12:00:25.427: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  2 12:00:25.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1751" for this suite.

• [SLOW TEST:12.255 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":356,"completed":15,"skipped":220,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:00:25.463: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9321
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-aac1b56b-9f4d-4cd2-a638-5269d4761454
STEP: Creating a pod to test consume secrets
Jul  2 12:00:25.616: INFO: Waiting up to 5m0s for pod "pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a" in namespace "secrets-9321" to be "Succeeded or Failed"
Jul  2 12:00:25.622: INFO: Pod "pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.456865ms
Jul  2 12:00:27.631: INFO: Pod "pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015080783s
Jul  2 12:00:29.640: INFO: Pod "pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023871614s
STEP: Saw pod success
Jul  2 12:00:29.640: INFO: Pod "pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a" satisfied condition "Succeeded or Failed"
Jul  2 12:00:29.644: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:00:29.668: INFO: Waiting for pod pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a to disappear
Jul  2 12:00:29.671: INFO: Pod pod-secrets-4e3b3b52-e27c-401d-9e17-cca388a6151a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:00:29.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9321" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":16,"skipped":234,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:00:29.687: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5236
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5236
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/framework/framework.go:652
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5236
STEP: Waiting until pod test-pod will start running in namespace statefulset-5236
STEP: Creating statefulset with conflicting port in namespace statefulset-5236
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5236
Jul  2 12:00:35.884: INFO: Observed stateful pod in namespace: statefulset-5236, name: ss-0, uid: 159bac10-79e6-4e09-ab2a-2625955c15fc, status phase: Pending. Waiting for statefulset controller to delete.
Jul  2 12:00:35.902: INFO: Observed stateful pod in namespace: statefulset-5236, name: ss-0, uid: 159bac10-79e6-4e09-ab2a-2625955c15fc, status phase: Failed. Waiting for statefulset controller to delete.
Jul  2 12:00:35.913: INFO: Observed stateful pod in namespace: statefulset-5236, name: ss-0, uid: 159bac10-79e6-4e09-ab2a-2625955c15fc, status phase: Failed. Waiting for statefulset controller to delete.
Jul  2 12:00:35.919: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5236
STEP: Removing pod with conflicting port in namespace statefulset-5236
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5236 and will be in running state
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 12:00:39.952: INFO: Deleting all statefulset in ns statefulset-5236
Jul  2 12:00:39.957: INFO: Scaling statefulset ss to 0
Jul  2 12:00:49.981: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:00:49.985: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 12:00:50.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5236" for this suite.

• [SLOW TEST:20.333 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":356,"completed":17,"skipped":247,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:00:50.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7713
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:00:50.153: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Jul  2 12:00:52.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7713 --namespace=crd-publish-openapi-7713 create -f -'
Jul  2 12:00:53.047: INFO: stderr: ""
Jul  2 12:00:53.047: INFO: stdout: "e2e-test-crd-publish-openapi-9401-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jul  2 12:00:53.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7713 --namespace=crd-publish-openapi-7713 delete e2e-test-crd-publish-openapi-9401-crds test-cr'
Jul  2 12:00:53.137: INFO: stderr: ""
Jul  2 12:00:53.137: INFO: stdout: "e2e-test-crd-publish-openapi-9401-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Jul  2 12:00:53.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7713 --namespace=crd-publish-openapi-7713 apply -f -'
Jul  2 12:00:53.564: INFO: stderr: ""
Jul  2 12:00:53.564: INFO: stdout: "e2e-test-crd-publish-openapi-9401-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jul  2 12:00:53.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7713 --namespace=crd-publish-openapi-7713 delete e2e-test-crd-publish-openapi-9401-crds test-cr'
Jul  2 12:00:53.628: INFO: stderr: ""
Jul  2 12:00:53.628: INFO: stdout: "e2e-test-crd-publish-openapi-9401-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jul  2 12:00:53.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7713 explain e2e-test-crd-publish-openapi-9401-crds'
Jul  2 12:00:53.778: INFO: stderr: ""
Jul  2 12:00:53.778: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9401-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:00:55.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7713" for this suite.

• [SLOW TEST:5.967 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":356,"completed":18,"skipped":251,"failed":0}
SSS
------------------------------
[sig-apps] ReplicaSet 
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:00:55.988: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1137
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota
Jul  2 12:00:56.132: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  2 12:01:01.139: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the replicaset Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  2 12:01:01.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1137" for this suite.

• [SLOW TEST:5.226 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","total":356,"completed":19,"skipped":254,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:01.213: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4457
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-8621ad16-b36d-4e02-9389-196bc05d8a07
STEP: Creating a pod to test consume secrets
Jul  2 12:01:01.374: INFO: Waiting up to 5m0s for pod "pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f" in namespace "secrets-4457" to be "Succeeded or Failed"
Jul  2 12:01:01.380: INFO: Pod "pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.487965ms
Jul  2 12:01:03.387: INFO: Pod "pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013483206s
Jul  2 12:01:05.397: INFO: Pod "pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023513369s
STEP: Saw pod success
Jul  2 12:01:05.397: INFO: Pod "pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f" satisfied condition "Succeeded or Failed"
Jul  2 12:01:05.401: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:01:05.426: INFO: Waiting for pod pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f to disappear
Jul  2 12:01:05.429: INFO: Pod pod-secrets-d433825f-9c1e-4e7c-b8e1-1ea7d589650f no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:01:05.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4457" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":20,"skipped":257,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:05.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2748
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-7eed391d-0ad1-49a5-ba40-fc04dc0bb89e
STEP: Creating a pod to test consume secrets
Jul  2 12:01:05.597: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525" in namespace "projected-2748" to be "Succeeded or Failed"
Jul  2 12:01:05.600: INFO: Pod "pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525": Phase="Pending", Reason="", readiness=false. Elapsed: 3.303791ms
Jul  2 12:01:07.609: INFO: Pod "pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011481998s
Jul  2 12:01:09.617: INFO: Pod "pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019680741s
STEP: Saw pod success
Jul  2 12:01:09.617: INFO: Pod "pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525" satisfied condition "Succeeded or Failed"
Jul  2 12:01:09.622: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:01:09.646: INFO: Waiting for pod pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525 to disappear
Jul  2 12:01:09.649: INFO: Pod pod-projected-secrets-0e8055ab-d3f1-4d6f-901d-f3535ae7b525 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  2 12:01:09.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2748" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":21,"skipped":297,"failed":0}
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:09.661: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3919
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with downward pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-downwardapi-dcml
STEP: Creating a pod to test atomic-volume-subpath
Jul  2 12:01:09.873: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dcml" in namespace "subpath-3919" to be "Succeeded or Failed"
Jul  2 12:01:09.879: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Pending", Reason="", readiness=false. Elapsed: 5.735963ms
Jul  2 12:01:11.887: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 2.01401471s
Jul  2 12:01:13.898: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 4.025101233s
Jul  2 12:01:15.904: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 6.031443487s
Jul  2 12:01:17.915: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 8.041480346s
Jul  2 12:01:19.920: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 10.047200823s
Jul  2 12:01:21.928: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 12.054886271s
Jul  2 12:01:23.938: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 14.065121518s
Jul  2 12:01:25.944: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 16.070516226s
Jul  2 12:01:27.954: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 18.081067378s
Jul  2 12:01:29.963: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=true. Elapsed: 20.090043288s
Jul  2 12:01:31.970: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Running", Reason="", readiness=false. Elapsed: 22.097286391s
Jul  2 12:01:33.978: INFO: Pod "pod-subpath-test-downwardapi-dcml": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.105325525s
STEP: Saw pod success
Jul  2 12:01:33.978: INFO: Pod "pod-subpath-test-downwardapi-dcml" satisfied condition "Succeeded or Failed"
Jul  2 12:01:33.982: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-subpath-test-downwardapi-dcml container test-container-subpath-downwardapi-dcml: <nil>
STEP: delete the pod
Jul  2 12:01:34.008: INFO: Waiting for pod pod-subpath-test-downwardapi-dcml to disappear
Jul  2 12:01:34.011: INFO: Pod pod-subpath-test-downwardapi-dcml no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-dcml
Jul  2 12:01:34.011: INFO: Deleting pod "pod-subpath-test-downwardapi-dcml" in namespace "subpath-3919"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  2 12:01:34.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3919" for this suite.

• [SLOW TEST:24.367 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","total":356,"completed":22,"skipped":298,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:34.028: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3945
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 12:01:45.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3945" for this suite.

• [SLOW TEST:11.207 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":356,"completed":23,"skipped":313,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version 
  should find the server version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:45.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename server-version
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in server-version-5302
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should find the server version [Conformance]
  test/e2e/framework/framework.go:652
STEP: Request ServerVersion
STEP: Confirm major version
Jul  2 12:01:45.373: INFO: Major version: 1
STEP: Confirm minor version
Jul  2 12:01:45.373: INFO: cleanMinorVersion: 24
Jul  2 12:01:45.373: INFO: Minor version: 24
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:188
Jul  2 12:01:45.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-5302" for this suite.
•{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","total":356,"completed":24,"skipped":356,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:45.385: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-74
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:01:45.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-74" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":356,"completed":25,"skipped":361,"failed":0}
S
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:45.537: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1133
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's args
Jul  2 12:01:45.680: INFO: Waiting up to 5m0s for pod "var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40" in namespace "var-expansion-1133" to be "Succeeded or Failed"
Jul  2 12:01:45.686: INFO: Pod "var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40": Phase="Pending", Reason="", readiness=false. Elapsed: 5.362747ms
Jul  2 12:01:47.696: INFO: Pod "var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015301314s
Jul  2 12:01:49.704: INFO: Pod "var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023557035s
STEP: Saw pod success
Jul  2 12:01:49.704: INFO: Pod "var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40" satisfied condition "Succeeded or Failed"
Jul  2 12:01:49.709: INFO: Trying to get logs from node ip-172-31-9-92 pod var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40 container dapi-container: <nil>
STEP: delete the pod
Jul  2 12:01:49.729: INFO: Waiting for pod var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40 to disappear
Jul  2 12:01:49.733: INFO: Pod var-expansion-e33b57d1-8ee1-43e6-9d47-626516787d40 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 12:01:49.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1133" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":356,"completed":26,"skipped":362,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:49.745: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6720
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  2 12:01:49.909: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:49.909: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:49.915: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 12:01:49.915: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:01:50.922: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:50.923: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:50.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 12:01:50.928: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:01:51.922: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:51.922: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:51.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:01:51.928: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:01:52.924: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:52.924: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:52.927: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:01:52.927: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:01:53.923: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:53.923: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:53.928: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:01:53.928: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:01:54.921: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:54.921: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:01:54.925: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 12:01:54.925: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets
STEP: DeleteCollection of the DaemonSets
STEP: Verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Jul  2 12:01:54.974: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4013"},"items":null}

Jul  2 12:01:54.978: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4014"},"items":[{"metadata":{"name":"daemon-set-g4n9r","generateName":"daemon-set-","namespace":"daemonsets-6720","uid":"b8be2cc1-10e4-4832-bb9e-5bcf0eb737d2","resourceVersion":"3990","creationTimestamp":"2022-07-02T12:01:49Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"kubernetes.io/psp":"e2e-test-privileged-psp"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0d0a6b6-6698-4127-8cff-1e4e1121e16c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-07-02T12:01:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0d0a6b6-6698-4127-8cff-1e4e1121e16c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-07-02T12:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.64.139\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-6mh8g","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-6mh8g","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-91-232","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-91-232"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:51Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:51Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:49Z"}],"hostIP":"172.31.91.232","podIP":"192.168.64.139","podIPs":[{"ip":"192.168.64.139"}],"startTime":"2022-07-02T12:01:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-07-02T12:01:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://c159a62a3db032e146352c916ecd94221f3c6648301f79aaa047bf04b4e2fa30","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-jhdvj","generateName":"daemon-set-","namespace":"daemonsets-6720","uid":"6e285397-27ce-42cb-b3b5-9a093f90a000","resourceVersion":"4004","creationTimestamp":"2022-07-02T12:01:49Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"kubernetes.io/psp":"e2e-test-privileged-psp"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0d0a6b6-6698-4127-8cff-1e4e1121e16c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-07-02T12:01:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0d0a6b6-6698-4127-8cff-1e4e1121e16c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-07-02T12:01:54Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.133\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xvb65","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xvb65","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-69-95","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-69-95"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:54Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:54Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:49Z"}],"hostIP":"172.31.69.95","podIP":"192.168.74.133","podIPs":[{"ip":"192.168.74.133"}],"startTime":"2022-07-02T12:01:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-07-02T12:01:54Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://d7cfebe36d3d2e4dc7ebafe85e49235cae75065e666c9c77bd993407d738513b","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-zgjws","generateName":"daemon-set-","namespace":"daemonsets-6720","uid":"a87924cf-4537-470c-87bf-e8eb4bc7dce1","resourceVersion":"3992","creationTimestamp":"2022-07-02T12:01:49Z","labels":{"controller-revision-hash":"6df8db488c","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"kubernetes.io/psp":"e2e-test-privileged-psp"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0d0a6b6-6698-4127-8cff-1e4e1121e16c","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-07-02T12:01:49Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0d0a6b6-6698-4127-8cff-1e4e1121e16c\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-07-02T12:01:51Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.21\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-97jfs","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-97jfs","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-9-92","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-9-92"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:49Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:51Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:51Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-07-02T12:01:49Z"}],"hostIP":"172.31.9.92","podIP":"192.168.231.21","podIPs":[{"ip":"192.168.231.21"}],"startTime":"2022-07-02T12:01:49Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-07-02T12:01:50Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/e2e-test-images/httpd:2.4.38-2","imageID":"k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://b3d310ca226ce18bc8f9d9ebed8afc441105160684df3385adecbf92a1518db2","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:01:55.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6720" for this suite.

• [SLOW TEST:5.270 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","total":356,"completed":27,"skipped":407,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:01:55.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5705
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:01:55.994: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:01:59.033: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:01:59.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:02:02.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5705" for this suite.
STEP: Destroying namespace "webhook-5705-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:7.261 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":356,"completed":28,"skipped":444,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:02.278: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6617
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:02:02.434: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e" in namespace "projected-6617" to be "Succeeded or Failed"
Jul  2 12:02:02.440: INFO: Pod "downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.655619ms
Jul  2 12:02:04.446: INFO: Pod "downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012063485s
Jul  2 12:02:06.451: INFO: Pod "downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017106624s
STEP: Saw pod success
Jul  2 12:02:06.451: INFO: Pod "downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e" satisfied condition "Succeeded or Failed"
Jul  2 12:02:06.456: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e container client-container: <nil>
STEP: delete the pod
Jul  2 12:02:06.477: INFO: Waiting for pod downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e to disappear
Jul  2 12:02:06.480: INFO: Pod downwardapi-volume-cbf8309d-defd-4cc5-ae7d-1353be23523e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:02:06.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6617" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":356,"completed":29,"skipped":514,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:06.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3481
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:02:06.988: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:02:10.017: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:02:10.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3481" for this suite.
STEP: Destroying namespace "webhook-3481-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":356,"completed":30,"skipped":523,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:10.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename runtimeclass
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in runtimeclass-1639
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  2 12:02:12.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1639" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","total":356,"completed":31,"skipped":555,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:12.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8302
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-3d9ef87f-ac1c-42d9-8bf9-7966caffa300
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:02:14.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8302" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":32,"skipped":572,"failed":0}
SSSSSSSS
------------------------------
[sig-architecture] Conformance Tests 
  should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:14.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename conformance-tests
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in conformance-tests-5710
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should have at least two untainted nodes [Conformance]
  test/e2e/framework/framework.go:652
STEP: Getting node addresses
Jul  2 12:02:14.905: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:188
Jul  2 12:02:14.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-5710" for this suite.
•{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","total":356,"completed":33,"skipped":580,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:14.924: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8456
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating Indexed job
STEP: Ensuring job reaches completions
STEP: Ensuring pods with index for job exist
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  2 12:02:27.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8456" for this suite.

• [SLOW TEST:12.167 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","total":356,"completed":34,"skipped":593,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:27.091: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9671
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:02:27.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9671" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","total":356,"completed":35,"skipped":627,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:27.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4961
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul  2 12:02:27.462: INFO: Waiting up to 5m0s for pod "pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177" in namespace "emptydir-4961" to be "Succeeded or Failed"
Jul  2 12:02:27.485: INFO: Pod "pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177": Phase="Pending", Reason="", readiness=false. Elapsed: 22.639649ms
Jul  2 12:02:29.495: INFO: Pod "pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033168979s
Jul  2 12:02:31.503: INFO: Pod "pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040580877s
STEP: Saw pod success
Jul  2 12:02:31.503: INFO: Pod "pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177" satisfied condition "Succeeded or Failed"
Jul  2 12:02:31.508: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177 container test-container: <nil>
STEP: delete the pod
Jul  2 12:02:31.534: INFO: Waiting for pod pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177 to disappear
Jul  2 12:02:31.538: INFO: Pod pod-d17f20a5-fdce-4b12-af9c-5d944e1f1177 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:02:31.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4961" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":36,"skipped":637,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:31.550: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5198
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Starting the proxy
Jul  2 12:02:31.691: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5198 proxy --unix-socket=/tmp/kubectl-proxy-unix1930672141/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:02:31.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5198" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":356,"completed":37,"skipped":640,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:31.741: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5431
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting a starting resourceVersion
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  2 12:02:34.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5431" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":356,"completed":38,"skipped":649,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:34.753: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4732
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating pod
Jul  2 12:02:34.932: INFO: The status of Pod pod-hostip-798914cf-9dc8-4bfb-8661-9603731973a8 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:02:36.949: INFO: The status of Pod pod-hostip-798914cf-9dc8-4bfb-8661-9603731973a8 is Running (Ready = true)
Jul  2 12:02:36.960: INFO: Pod pod-hostip-798914cf-9dc8-4bfb-8661-9603731973a8 has hostIP: 172.31.9.92
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:02:36.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4732" for this suite.
•{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","total":356,"completed":39,"skipped":695,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:36.977: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6324
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Jul  2 12:02:37.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:02:40.310: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:02:49.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6324" for this suite.

• [SLOW TEST:13.039 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":356,"completed":40,"skipped":762,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:50.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9315
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-cc5a0890-0aa6-4fca-b70b-e9dabbee7f1d
STEP: Creating a pod to test consume configMaps
Jul  2 12:02:50.173: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6" in namespace "projected-9315" to be "Succeeded or Failed"
Jul  2 12:02:50.176: INFO: Pod "pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.49158ms
Jul  2 12:02:52.183: INFO: Pod "pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010342035s
Jul  2 12:02:54.190: INFO: Pod "pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017774301s
STEP: Saw pod success
Jul  2 12:02:54.191: INFO: Pod "pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6" satisfied condition "Succeeded or Failed"
Jul  2 12:02:54.194: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:02:54.220: INFO: Waiting for pod pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6 to disappear
Jul  2 12:02:54.224: INFO: Pod pod-projected-configmaps-3a5a812b-8891-4090-b0b8-2ae9919230d6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 12:02:54.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9315" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":41,"skipped":784,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:54.238: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4838
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-map-bafc0abf-635a-4723-9378-4cc2533aa8fc
STEP: Creating a pod to test consume secrets
Jul  2 12:02:54.390: INFO: Waiting up to 5m0s for pod "pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628" in namespace "secrets-4838" to be "Succeeded or Failed"
Jul  2 12:02:54.394: INFO: Pod "pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628": Phase="Pending", Reason="", readiness=false. Elapsed: 3.706527ms
Jul  2 12:02:56.400: INFO: Pod "pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01062455s
Jul  2 12:02:58.410: INFO: Pod "pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020043348s
STEP: Saw pod success
Jul  2 12:02:58.410: INFO: Pod "pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628" satisfied condition "Succeeded or Failed"
Jul  2 12:02:58.415: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628 container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:02:58.437: INFO: Waiting for pod pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628 to disappear
Jul  2 12:02:58.440: INFO: Pod pod-secrets-faff1ee3-4a85-46b3-9004-20abc6e55628 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:02:58.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4838" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":42,"skipped":801,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:02:58.454: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-53
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 12:03:26.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-53" for this suite.

• [SLOW TEST:28.219 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":356,"completed":43,"skipped":812,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity 
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:03:26.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename csistoragecapacity
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in csistoragecapacity-3758
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/storage.k8s.io
STEP: getting /apis/storage.k8s.io/v1
STEP: creating
STEP: watching
Jul  2 12:03:26.836: INFO: starting watch
STEP: getting
STEP: listing in namespace
STEP: listing across namespaces
STEP: patching
STEP: updating
Jul  2 12:03:26.869: INFO: waiting for watch events with expected annotations in namespace
Jul  2 12:03:26.869: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:188
Jul  2 12:03:26.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-3758" for this suite.
•{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","total":356,"completed":44,"skipped":841,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:03:26.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8389
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-8389
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8389
STEP: creating replication controller externalsvc in namespace services-8389
I0702 12:03:27.108448      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-8389, replica count: 2
I0702 12:03:30.159950      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Jul  2 12:03:30.188: INFO: Creating new exec pod
Jul  2 12:03:32.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8389 exec execpodsqtkx -- /bin/sh -x -c nslookup clusterip-service.services-8389.svc.cluster.local'
Jul  2 12:03:32.414: INFO: stderr: "+ nslookup clusterip-service.services-8389.svc.cluster.local\n"
Jul  2 12:03:32.414: INFO: stdout: "Server:\t\t10.152.183.155\nAddress:\t10.152.183.155#53\n\nclusterip-service.services-8389.svc.cluster.local\tcanonical name = externalsvc.services-8389.svc.cluster.local.\nName:\texternalsvc.services-8389.svc.cluster.local\nAddress: 10.152.183.205\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8389, will wait for the garbage collector to delete the pods
Jul  2 12:03:32.478: INFO: Deleting ReplicationController externalsvc took: 8.304457ms
Jul  2 12:03:32.579: INFO: Terminating ReplicationController externalsvc pods took: 101.062997ms
Jul  2 12:03:34.816: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:03:34.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8389" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:7.927 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":356,"completed":45,"skipped":848,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:03:34.850: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-preemption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-preemption-8348
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  2 12:03:34.996: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  2 12:04:35.021: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Jul  2 12:04:35.050: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jul  2 12:04:35.059: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jul  2 12:04:35.080: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jul  2 12:04:35.091: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jul  2 12:04:35.109: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jul  2 12:04:35.122: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a critical pod that use same resources as that of a lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:04:51.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8348" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:76.449 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","total":356,"completed":46,"skipped":951,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:04:51.299: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3846
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating cluster-info
Jul  2 12:04:51.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-3846 cluster-info'
Jul  2 12:04:51.500: INFO: stderr: ""
Jul  2 12:04:51.500: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:04:51.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3846" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","total":356,"completed":47,"skipped":952,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:04:51.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1800
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  2 12:04:51.659: INFO: Waiting up to 5m0s for pod "downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f" in namespace "downward-api-1800" to be "Succeeded or Failed"
Jul  2 12:04:51.665: INFO: Pod "downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.567219ms
Jul  2 12:04:53.674: INFO: Pod "downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01434492s
Jul  2 12:04:55.681: INFO: Pod "downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021877667s
STEP: Saw pod success
Jul  2 12:04:55.681: INFO: Pod "downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f" satisfied condition "Succeeded or Failed"
Jul  2 12:04:55.686: INFO: Trying to get logs from node ip-172-31-69-95 pod downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f container dapi-container: <nil>
STEP: delete the pod
Jul  2 12:04:55.718: INFO: Waiting for pod downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f to disappear
Jul  2 12:04:55.723: INFO: Pod downward-api-6e95ca87-41d6-44d1-9023-d9dbec93281f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  2 12:04:55.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1800" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":356,"completed":48,"skipped":954,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:04:55.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8115
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7003
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5166
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:05:02.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8115" for this suite.
STEP: Destroying namespace "nsdeletetest-7003" for this suite.
Jul  2 12:05:02.172: INFO: Namespace nsdeletetest-7003 was already deleted
STEP: Destroying namespace "nsdeletetest-5166" for this suite.

• [SLOW TEST:6.445 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":356,"completed":49,"skipped":960,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:02.181: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3955
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:05:02.338: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jul  2 12:05:02.353: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:02.353: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:02.356: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 12:05:02.356: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:05:03.364: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:03.364: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:03.368: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 12:05:03.368: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:05:04.365: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:04.365: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:04.371: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 12:05:04.371: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jul  2 12:05:04.405: INFO: Wrong image for pod: daemon-set-g4txz. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:04.405: INFO: Wrong image for pod: daemon-set-j6v2t. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:04.405: INFO: Wrong image for pod: daemon-set-pl67p. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:04.410: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:04.410: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:05.417: INFO: Wrong image for pod: daemon-set-j6v2t. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:05.417: INFO: Wrong image for pod: daemon-set-pl67p. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:05.423: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:05.423: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:06.415: INFO: Wrong image for pod: daemon-set-j6v2t. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:06.415: INFO: Wrong image for pod: daemon-set-pl67p. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:06.422: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:06.422: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:07.419: INFO: Wrong image for pod: daemon-set-j6v2t. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:07.419: INFO: Pod daemon-set-lrdnk is not available
Jul  2 12:05:07.419: INFO: Wrong image for pod: daemon-set-pl67p. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:07.426: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:07.426: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:08.418: INFO: Wrong image for pod: daemon-set-j6v2t. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:08.424: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:08.424: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:09.418: INFO: Wrong image for pod: daemon-set-j6v2t. Expected: k8s.gcr.io/e2e-test-images/agnhost:2.39, got: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2.
Jul  2 12:05:09.418: INFO: Pod daemon-set-zzskd is not available
Jul  2 12:05:09.424: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:09.424: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:10.422: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:10.422: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:11.418: INFO: Pod daemon-set-rkd2c is not available
Jul  2 12:05:11.422: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:11.422: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Jul  2 12:05:11.427: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:11.427: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:11.431: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:05:11.431: INFO: Node ip-172-31-9-92 is running 0 daemon pod, expected 1
Jul  2 12:05:12.439: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:12.439: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:05:12.445: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 12:05:12.445: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3955, will wait for the garbage collector to delete the pods
Jul  2 12:05:12.528: INFO: Deleting DaemonSet.extensions daemon-set took: 9.124787ms
Jul  2 12:05:12.629: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.00641ms
Jul  2 12:05:14.840: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 12:05:14.840: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  2 12:05:14.844: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"5824"},"items":null}

Jul  2 12:05:14.847: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"5824"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:05:14.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3955" for this suite.

• [SLOW TEST:12.695 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":356,"completed":50,"skipped":1006,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:14.877: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4491
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-9272
STEP: Creating secret with name secret-test-27853026-f1fd-45e7-a82c-bef114a63670
STEP: Creating a pod to test consume secrets
Jul  2 12:05:15.168: INFO: Waiting up to 5m0s for pod "pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4" in namespace "secrets-4491" to be "Succeeded or Failed"
Jul  2 12:05:15.178: INFO: Pod "pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.557277ms
Jul  2 12:05:17.187: INFO: Pod "pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018843897s
Jul  2 12:05:19.193: INFO: Pod "pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025586211s
STEP: Saw pod success
Jul  2 12:05:19.193: INFO: Pod "pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4" satisfied condition "Succeeded or Failed"
Jul  2 12:05:19.199: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4 container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:05:19.232: INFO: Waiting for pod pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4 to disappear
Jul  2 12:05:19.237: INFO: Pod pod-secrets-6109b6b9-51a5-4622-a88f-0def5b5d06d4 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:05:19.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4491" for this suite.
STEP: Destroying namespace "secret-namespace-9272" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":356,"completed":51,"skipped":1023,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] HostPort 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:19.259: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename hostport
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostport-6151
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled
Jul  2 12:05:19.415: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:05:21.423: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.9.92 on the node which pod1 resides and expect scheduled
Jul  2 12:05:21.436: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:05:23.446: INFO: The status of Pod pod2 is Running (Ready = false)
Jul  2 12:05:25.442: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.9.92 but use UDP protocol on the node which pod2 resides
Jul  2 12:05:25.455: INFO: The status of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:05:27.463: INFO: The status of Pod pod3 is Running (Ready = true)
Jul  2 12:05:27.475: INFO: The status of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:05:29.485: INFO: The status of Pod e2e-host-exec is Running (Ready = true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323
Jul  2 12:05:29.489: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.9.92 http://127.0.0.1:54323/hostname] Namespace:hostport-6151 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:05:29.489: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:05:29.489: INFO: ExecWithOptions: Clientset creation
Jul  2 12:05:29.489: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-6151/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.9.92+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.9.92, port: 54323
Jul  2 12:05:29.576: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.9.92:54323/hostname] Namespace:hostport-6151 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:05:29.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:05:29.576: INFO: ExecWithOptions: Clientset creation
Jul  2 12:05:29.576: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-6151/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.9.92%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.9.92, port: 54323 UDP
Jul  2 12:05:29.662: INFO: ExecWithOptions {Command:[/bin/sh -c nc -vuz -w 5 172.31.9.92 54323] Namespace:hostport-6151 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:05:29.662: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:05:29.663: INFO: ExecWithOptions: Clientset creation
Jul  2 12:05:29.663: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-6151/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=nc+-vuz+-w+5+172.31.9.92+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:188
Jul  2 12:05:34.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-6151" for this suite.

• [SLOW TEST:15.485 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","total":356,"completed":52,"skipped":1033,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:34.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1019
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jul  2 12:05:34.894: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1019  2918cf3b-ad2d-44c9-b679-78b1347169df 6011 0 2022-07-02 12:05:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-02 12:05:34 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 12:05:34.894: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1019  2918cf3b-ad2d-44c9-b679-78b1347169df 6012 0 2022-07-02 12:05:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-02 12:05:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jul  2 12:05:34.915: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1019  2918cf3b-ad2d-44c9-b679-78b1347169df 6013 0 2022-07-02 12:05:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-02 12:05:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 12:05:34.915: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1019  2918cf3b-ad2d-44c9-b679-78b1347169df 6014 0 2022-07-02 12:05:34 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2022-07-02 12:05:34 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  2 12:05:34.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1019" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":356,"completed":53,"skipped":1043,"failed":0}
SSSSSS
------------------------------
[sig-apps] Deployment 
  should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:34.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4605
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
Jul  2 12:05:35.061: INFO: Creating simple deployment test-deployment-z2jpk
Jul  2 12:05:35.086: INFO: deployment "test-deployment-z2jpk" doesn't have the required revision set
STEP: Getting /status
Jul  2 12:05:37.112: INFO: Deployment test-deployment-z2jpk has Conditions: [{Available True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z2jpk-688c4d6789" has successfully progressed.}]
STEP: updating Deployment Status
Jul  2 12:05:37.122: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 5, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 5, 36, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 5, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 5, 35, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-z2jpk-688c4d6789\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated
Jul  2 12:05:37.124: INFO: Observed &Deployment event: ADDED
Jul  2 12:05:37.124: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z2jpk-688c4d6789"}
Jul  2 12:05:37.125: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.125: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z2jpk-688c4d6789"}
Jul  2 12:05:37.125: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  2 12:05:37.125: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.125: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  2 12:05:37.125: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-z2jpk-688c4d6789" is progressing.}
Jul  2 12:05:37.125: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.125: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  2 12:05:37.125: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z2jpk-688c4d6789" has successfully progressed.}
Jul  2 12:05:37.126: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.126: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  2 12:05:37.126: INFO: Observed Deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z2jpk-688c4d6789" has successfully progressed.}
Jul  2 12:05:37.126: INFO: Found Deployment test-deployment-z2jpk in namespace deployment-4605 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  2 12:05:37.126: INFO: Deployment test-deployment-z2jpk has an updated status
STEP: patching the Statefulset Status
Jul  2 12:05:37.126: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul  2 12:05:37.138: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched
Jul  2 12:05:37.141: INFO: Observed &Deployment event: ADDED
Jul  2 12:05:37.141: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z2jpk-688c4d6789"}
Jul  2 12:05:37.141: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.141: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-z2jpk-688c4d6789"}
Jul  2 12:05:37.141: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  2 12:05:37.142: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.142: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Jul  2 12:05:37.142: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:35 +0000 UTC 2022-07-02 12:05:35 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-z2jpk-688c4d6789" is progressing.}
Jul  2 12:05:37.142: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.142: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  2 12:05:37.142: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z2jpk-688c4d6789" has successfully progressed.}
Jul  2 12:05:37.142: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.142: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:36 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Jul  2 12:05:37.142: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-07-02 12:05:36 +0000 UTC 2022-07-02 12:05:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-z2jpk-688c4d6789" has successfully progressed.}
Jul  2 12:05:37.142: INFO: Observed deployment test-deployment-z2jpk in namespace deployment-4605 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  2 12:05:37.142: INFO: Observed &Deployment event: MODIFIED
Jul  2 12:05:37.142: INFO: Found deployment test-deployment-z2jpk in namespace deployment-4605 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Jul  2 12:05:37.142: INFO: Deployment test-deployment-z2jpk has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:05:37.148: INFO: Deployment "test-deployment-z2jpk":
&Deployment{ObjectMeta:{test-deployment-z2jpk  deployment-4605  1620c225-6187-4149-977d-aee4aaf940f5 6049 1 2022-07-02 12:05:35 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-07-02 12:05:35 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-07-02 12:05:37 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-07-02 12:05:37 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc000c5cad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-z2jpk-688c4d6789",LastUpdateTime:2022-07-02 12:05:37 +0000 UTC,LastTransitionTime:2022-07-02 12:05:37 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  2 12:05:37.152: INFO: New ReplicaSet "test-deployment-z2jpk-688c4d6789" of Deployment "test-deployment-z2jpk":
&ReplicaSet{ObjectMeta:{test-deployment-z2jpk-688c4d6789  deployment-4605  25076f92-e10d-4bf4-96b2-b1028b41cc57 6044 1 2022-07-02 12:05:35 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-z2jpk 1620c225-6187-4149-977d-aee4aaf940f5 0xc001123040 0xc001123041}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:05:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1620c225-6187-4149-977d-aee4aaf940f5\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:05:36 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 688c4d6789,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0011230e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:05:37.157: INFO: Pod "test-deployment-z2jpk-688c4d6789-csnxm" is available:
&Pod{ObjectMeta:{test-deployment-z2jpk-688c4d6789-csnxm test-deployment-z2jpk-688c4d6789- deployment-4605  bfe926ea-8fbb-4b5f-89d7-4b576bd579bf 6043 0 2022-07-02 12:05:35 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:688c4d6789] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-deployment-z2jpk-688c4d6789 25076f92-e10d-4bf4-96b2-b1028b41cc57 0xc0011234b7 0xc0011234b8}] []  [{kube-controller-manager Update v1 2022-07-02 12:05:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"25076f92-e10d-4bf4-96b2-b1028b41cc57\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:05:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.143\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-pwrgx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-pwrgx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:05:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:05:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:05:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.143,StartTime:2022-07-02 12:05:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:05:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://47f54ee124c8150ed75c227c2becc43824b3f311404e516a1b5d78ae5f73669c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.143,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:05:37.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4605" for this suite.
•{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","total":356,"completed":54,"skipped":1049,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:37.170: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9347
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-36dd8c76-cb45-4bd8-87c1-256be1051dba
STEP: Creating a pod to test consume configMaps
Jul  2 12:05:37.328: INFO: Waiting up to 5m0s for pod "pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e" in namespace "configmap-9347" to be "Succeeded or Failed"
Jul  2 12:05:37.333: INFO: Pod "pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.644149ms
Jul  2 12:05:39.339: INFO: Pod "pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010303485s
Jul  2 12:05:41.345: INFO: Pod "pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016558801s
STEP: Saw pod success
Jul  2 12:05:41.345: INFO: Pod "pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e" satisfied condition "Succeeded or Failed"
Jul  2 12:05:41.350: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:05:41.373: INFO: Waiting for pod pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e to disappear
Jul  2 12:05:41.378: INFO: Pod pod-configmaps-f783da6d-1bc9-4c44-afae-d8fe469c398e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:05:41.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9347" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":55,"skipped":1102,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:41.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-519
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-03ff9a82-535b-4af9-896b-1d6e0dafdb0d
STEP: Creating a pod to test consume configMaps
Jul  2 12:05:41.546: INFO: Waiting up to 5m0s for pod "pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc" in namespace "configmap-519" to be "Succeeded or Failed"
Jul  2 12:05:41.553: INFO: Pod "pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.11157ms
Jul  2 12:05:43.559: INFO: Pod "pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013205909s
Jul  2 12:05:45.568: INFO: Pod "pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02137015s
Jul  2 12:05:47.578: INFO: Pod "pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031474026s
STEP: Saw pod success
Jul  2 12:05:47.578: INFO: Pod "pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc" satisfied condition "Succeeded or Failed"
Jul  2 12:05:47.581: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:05:47.606: INFO: Waiting for pod pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc to disappear
Jul  2 12:05:47.609: INFO: Pod pod-configmaps-85b6a5ae-c435-45b2-8cd7-9b8de7c21bfc no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:05:47.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-519" for this suite.

• [SLOW TEST:6.232 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":56,"skipped":1128,"failed":0}
S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:47.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6519
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  2 12:05:47.769: INFO: Waiting up to 5m0s for pod "downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8" in namespace "downward-api-6519" to be "Succeeded or Failed"
Jul  2 12:05:47.772: INFO: Pod "downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320092ms
Jul  2 12:05:49.778: INFO: Pod "downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009028997s
Jul  2 12:05:51.785: INFO: Pod "downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016187432s
STEP: Saw pod success
Jul  2 12:05:51.785: INFO: Pod "downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8" satisfied condition "Succeeded or Failed"
Jul  2 12:05:51.791: INFO: Trying to get logs from node ip-172-31-9-92 pod downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8 container dapi-container: <nil>
STEP: delete the pod
Jul  2 12:05:51.811: INFO: Waiting for pod downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8 to disappear
Jul  2 12:05:51.816: INFO: Pod downward-api-ff6371e0-6261-406f-a4fa-e08556f914e8 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  2 12:05:51.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6519" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":356,"completed":57,"skipped":1129,"failed":0}
SSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:51.828: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6325
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  2 12:05:51.988: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:05:53.999: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  2 12:05:54.019: INFO: The status of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:05:56.024: INFO: The status of Pod pod-with-poststart-http-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul  2 12:05:56.048: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  2 12:05:56.051: INFO: Pod pod-with-poststart-http-hook still exists
Jul  2 12:05:58.051: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jul  2 12:05:58.058: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  2 12:05:58.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6325" for this suite.

• [SLOW TEST:6.243 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":356,"completed":58,"skipped":1132,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:05:58.072: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9890
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:05:58.460: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:06:01.487: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:06:01.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9890" for this suite.
STEP: Destroying namespace "webhook-9890-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":356,"completed":59,"skipped":1137,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:06:01.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-782
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Jul  2 12:06:01.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Jul  2 12:06:11.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:06:13.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:06:23.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-782" for this suite.

• [SLOW TEST:21.621 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":356,"completed":60,"skipped":1140,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:06:23.212: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5811
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a ReplicaSet
STEP: Verify that the required pods have come up
Jul  2 12:06:23.355: INFO: Pod name sample-pod: Found 0 pods out of 3
Jul  2 12:06:28.371: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running
Jul  2 12:06:28.375: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets
STEP: DeleteCollection of the ReplicaSets
STEP: After DeleteCollection verify that ReplicaSets have been deleted
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  2 12:06:28.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5811" for this suite.

• [SLOW TEST:5.201 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","total":356,"completed":61,"skipped":1152,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:06:28.414: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9958
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:06:28.570: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426" in namespace "downward-api-9958" to be "Succeeded or Failed"
Jul  2 12:06:28.576: INFO: Pod "downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426": Phase="Pending", Reason="", readiness=false. Elapsed: 5.464022ms
Jul  2 12:06:30.585: INFO: Pod "downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014107256s
Jul  2 12:06:32.593: INFO: Pod "downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022143761s
STEP: Saw pod success
Jul  2 12:06:32.593: INFO: Pod "downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426" satisfied condition "Succeeded or Failed"
Jul  2 12:06:32.600: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426 container client-container: <nil>
STEP: delete the pod
Jul  2 12:06:32.630: INFO: Waiting for pod downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426 to disappear
Jul  2 12:06:32.634: INFO: Pod downwardapi-volume-e787db9d-1634-463f-b3d0-3ef38ebc9426 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 12:06:32.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9958" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":62,"skipped":1162,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:06:32.645: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7922
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating an Endpoint
STEP: waiting for available Endpoint
STEP: listing all Endpoints
STEP: updating the Endpoint
STEP: fetching the Endpoint
STEP: patching the Endpoint
STEP: fetching the Endpoint
STEP: deleting the Endpoint by Collection
STEP: waiting for Endpoint deletion
STEP: fetching the Endpoint
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:06:32.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7922" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","total":356,"completed":63,"skipped":1182,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:06:32.842: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9894
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-9894
STEP: creating service affinity-nodeport in namespace services-9894
STEP: creating replication controller affinity-nodeport in namespace services-9894
I0702 12:06:33.002726      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-9894, replica count: 3
I0702 12:06:36.053799      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 12:06:36.074: INFO: Creating new exec pod
Jul  2 12:06:39.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9894 exec execpod-affinityppp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Jul  2 12:06:39.252: INFO: stderr: "+ + echonc hostName\n -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Jul  2 12:06:39.252: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:06:39.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9894 exec execpod-affinityppp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.36 80'
Jul  2 12:06:39.366: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.36 80\nConnection to 10.152.183.36 80 port [tcp/http] succeeded!\n"
Jul  2 12:06:39.366: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:06:39.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9894 exec execpod-affinityppp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.69.95 31254'
Jul  2 12:06:39.486: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.69.95 31254\nConnection to 172.31.69.95 31254 port [tcp/*] succeeded!\n"
Jul  2 12:06:39.486: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:06:39.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9894 exec execpod-affinityppp6r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.91.232 31254'
Jul  2 12:06:39.612: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.91.232 31254\nConnection to 172.31.91.232 31254 port [tcp/*] succeeded!\n"
Jul  2 12:06:39.612: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:06:39.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9894 exec execpod-affinityppp6r -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.69.95:31254/ ; done'
Jul  2 12:06:39.809: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:31254/\n"
Jul  2 12:06:39.809: INFO: stdout: "\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x\naffinity-nodeport-7px5x"
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Received response from host: affinity-nodeport-7px5x
Jul  2 12:06:39.809: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-9894, will wait for the garbage collector to delete the pods
Jul  2 12:06:39.893: INFO: Deleting ReplicationController affinity-nodeport took: 10.571184ms
Jul  2 12:06:39.993: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.322936ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:06:42.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9894" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.292 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":64,"skipped":1216,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:06:42.135: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4576
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac in namespace container-probe-4576
Jul  2 12:06:44.292: INFO: Started pod liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac in namespace container-probe-4576
STEP: checking the pod's current state and verifying that restartCount is present
Jul  2 12:06:44.296: INFO: Initial restart count of pod liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac is 0
Jul  2 12:07:04.390: INFO: Restart count of pod container-probe-4576/liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac is now 1 (20.093995203s elapsed)
Jul  2 12:07:24.471: INFO: Restart count of pod container-probe-4576/liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac is now 2 (40.174973195s elapsed)
Jul  2 12:07:44.578: INFO: Restart count of pod container-probe-4576/liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac is now 3 (1m0.281300581s elapsed)
Jul  2 12:08:04.667: INFO: Restart count of pod container-probe-4576/liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac is now 4 (1m20.370590572s elapsed)
Jul  2 12:09:16.987: INFO: Restart count of pod container-probe-4576/liveness-9959551c-2005-436c-80b0-e1ca72b0c7ac is now 5 (2m32.690498033s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 12:09:17.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4576" for this suite.

• [SLOW TEST:154.881 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":356,"completed":65,"skipped":1255,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:09:17.017: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8777
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:09:17.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382" in namespace "projected-8777" to be "Succeeded or Failed"
Jul  2 12:09:17.167: INFO: Pod "downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382": Phase="Pending", Reason="", readiness=false. Elapsed: 5.964022ms
Jul  2 12:09:19.175: INFO: Pod "downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01421967s
Jul  2 12:09:21.184: INFO: Pod "downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023337409s
STEP: Saw pod success
Jul  2 12:09:21.184: INFO: Pod "downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382" satisfied condition "Succeeded or Failed"
Jul  2 12:09:21.188: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382 container client-container: <nil>
STEP: delete the pod
Jul  2 12:09:21.214: INFO: Waiting for pod downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382 to disappear
Jul  2 12:09:21.217: INFO: Pod downwardapi-volume-4d21764d-4aab-444e-bbc0-cda9f85a8382 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:09:21.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8777" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":66,"skipped":1266,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:09:21.230: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8604
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul  2 12:09:21.373: INFO: Waiting up to 5m0s for pod "pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8" in namespace "emptydir-8604" to be "Succeeded or Failed"
Jul  2 12:09:21.376: INFO: Pod "pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.035408ms
Jul  2 12:09:23.384: INFO: Pod "pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011692273s
Jul  2 12:09:25.393: INFO: Pod "pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020114355s
STEP: Saw pod success
Jul  2 12:09:25.393: INFO: Pod "pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8" satisfied condition "Succeeded or Failed"
Jul  2 12:09:25.397: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8 container test-container: <nil>
STEP: delete the pod
Jul  2 12:09:25.419: INFO: Waiting for pod pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8 to disappear
Jul  2 12:09:25.423: INFO: Pod pod-d22cbbda-076c-4fe7-9d59-b7c2d09a4ee8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:09:25.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8604" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":67,"skipped":1268,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:09:25.436: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1557
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul  2 12:09:25.581: INFO: Waiting up to 5m0s for pod "pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977" in namespace "emptydir-1557" to be "Succeeded or Failed"
Jul  2 12:09:25.584: INFO: Pod "pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977": Phase="Pending", Reason="", readiness=false. Elapsed: 3.113336ms
Jul  2 12:09:27.593: INFO: Pod "pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011497755s
Jul  2 12:09:29.601: INFO: Pod "pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019620128s
STEP: Saw pod success
Jul  2 12:09:29.601: INFO: Pod "pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977" satisfied condition "Succeeded or Failed"
Jul  2 12:09:29.605: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977 container test-container: <nil>
STEP: delete the pod
Jul  2 12:09:29.629: INFO: Waiting for pod pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977 to disappear
Jul  2 12:09:29.632: INFO: Pod pod-f05fc9c9-0412-4c4c-ae79-15cb68a5f977 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:09:29.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1557" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":68,"skipped":1302,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:09:29.651: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7866
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on tmpfs
Jul  2 12:09:29.793: INFO: Waiting up to 5m0s for pod "pod-01cc764e-c085-4164-9f99-2b58644cb1df" in namespace "emptydir-7866" to be "Succeeded or Failed"
Jul  2 12:09:29.799: INFO: Pod "pod-01cc764e-c085-4164-9f99-2b58644cb1df": Phase="Pending", Reason="", readiness=false. Elapsed: 5.837766ms
Jul  2 12:09:31.808: INFO: Pod "pod-01cc764e-c085-4164-9f99-2b58644cb1df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015618368s
Jul  2 12:09:33.818: INFO: Pod "pod-01cc764e-c085-4164-9f99-2b58644cb1df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024729997s
STEP: Saw pod success
Jul  2 12:09:33.818: INFO: Pod "pod-01cc764e-c085-4164-9f99-2b58644cb1df" satisfied condition "Succeeded or Failed"
Jul  2 12:09:33.822: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-01cc764e-c085-4164-9f99-2b58644cb1df container test-container: <nil>
STEP: delete the pod
Jul  2 12:09:33.841: INFO: Waiting for pod pod-01cc764e-c085-4164-9f99-2b58644cb1df to disappear
Jul  2 12:09:33.845: INFO: Pod pod-01cc764e-c085-4164-9f99-2b58644cb1df no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:09:33.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7866" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":69,"skipped":1349,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:09:33.856: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-4730
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a job [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4730, will wait for the garbage collector to delete the pods
Jul  2 12:09:36.068: INFO: Deleting Job.batch foo took: 9.361273ms
Jul  2 12:09:36.169: INFO: Terminating Job.batch foo pods took: 100.727154ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  2 12:10:08.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4730" for this suite.

• [SLOW TEST:34.544 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":356,"completed":70,"skipped":1358,"failed":0}
S
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:10:08.400: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7129
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  2 12:10:08.533: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  2 12:10:14.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7129" for this suite.

• [SLOW TEST:5.905 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":356,"completed":71,"skipped":1359,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:10:14.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9848
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  2 12:10:14.465: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:14.466: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:14.469: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 12:10:14.469: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 12:10:15.478: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:15.478: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:15.481: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  2 12:10:15.481: INFO: Node ip-172-31-9-92 is running 0 daemon pod, expected 1
Jul  2 12:10:16.477: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:16.477: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:16.481: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 12:10:16.481: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jul  2 12:10:16.502: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:16.502: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:16.506: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:10:16.506: INFO: Node ip-172-31-9-92 is running 0 daemon pod, expected 1
Jul  2 12:10:17.512: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:17.512: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:17.517: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:10:17.517: INFO: Node ip-172-31-9-92 is running 0 daemon pod, expected 1
Jul  2 12:10:18.514: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:18.514: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:18.517: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:10:18.517: INFO: Node ip-172-31-9-92 is running 0 daemon pod, expected 1
Jul  2 12:10:19.513: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:19.513: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:19.518: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 12:10:19.518: INFO: Node ip-172-31-9-92 is running 0 daemon pod, expected 1
Jul  2 12:10:20.513: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:20.513: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 12:10:20.518: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 12:10:20.518: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9848, will wait for the garbage collector to delete the pods
Jul  2 12:10:20.584: INFO: Deleting DaemonSet.extensions daemon-set took: 7.797296ms
Jul  2 12:10:20.684: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.903622ms
Jul  2 12:10:23.394: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 12:10:23.394: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  2 12:10:23.398: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7640"},"items":null}

Jul  2 12:10:23.402: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7640"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:10:23.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9848" for this suite.

• [SLOW TEST:9.124 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":356,"completed":72,"skipped":1368,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:10:23.430: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6031
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should create and stop a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Jul  2 12:10:23.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 create -f -'
Jul  2 12:10:23.745: INFO: stderr: ""
Jul  2 12:10:23.745: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  2 12:10:23.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:10:23.808: INFO: stderr: ""
Jul  2 12:10:23.808: INFO: stdout: "update-demo-nautilus-mlt7g update-demo-nautilus-pjcs5 "
Jul  2 12:10:23.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods update-demo-nautilus-mlt7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:10:23.861: INFO: stderr: ""
Jul  2 12:10:23.861: INFO: stdout: ""
Jul  2 12:10:23.861: INFO: update-demo-nautilus-mlt7g is created but not running
Jul  2 12:10:28.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:10:28.944: INFO: stderr: ""
Jul  2 12:10:28.944: INFO: stdout: "update-demo-nautilus-mlt7g update-demo-nautilus-pjcs5 "
Jul  2 12:10:28.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods update-demo-nautilus-mlt7g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:10:28.999: INFO: stderr: ""
Jul  2 12:10:28.999: INFO: stdout: "true"
Jul  2 12:10:28.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods update-demo-nautilus-mlt7g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:10:29.051: INFO: stderr: ""
Jul  2 12:10:29.051: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:10:29.051: INFO: validating pod update-demo-nautilus-mlt7g
Jul  2 12:10:29.056: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:10:29.056: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:10:29.056: INFO: update-demo-nautilus-mlt7g is verified up and running
Jul  2 12:10:29.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods update-demo-nautilus-pjcs5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:10:29.114: INFO: stderr: ""
Jul  2 12:10:29.114: INFO: stdout: "true"
Jul  2 12:10:29.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods update-demo-nautilus-pjcs5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:10:29.169: INFO: stderr: ""
Jul  2 12:10:29.169: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:10:29.169: INFO: validating pod update-demo-nautilus-pjcs5
Jul  2 12:10:29.175: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:10:29.176: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:10:29.176: INFO: update-demo-nautilus-pjcs5 is verified up and running
STEP: using delete to clean up resources
Jul  2 12:10:29.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 delete --grace-period=0 --force -f -'
Jul  2 12:10:29.237: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:10:29.237: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul  2 12:10:29.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get rc,svc -l name=update-demo --no-headers'
Jul  2 12:10:29.297: INFO: stderr: "No resources found in kubectl-6031 namespace.\n"
Jul  2 12:10:29.297: INFO: stdout: ""
Jul  2 12:10:29.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-6031 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul  2 12:10:29.360: INFO: stderr: ""
Jul  2 12:10:29.360: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:10:29.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6031" for this suite.

• [SLOW TEST:5.943 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should create and stop a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":356,"completed":73,"skipped":1424,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:10:29.374: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2341
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  2 12:10:29.503: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  2 12:10:34.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2341" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":356,"completed":74,"skipped":1448,"failed":0}

------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:10:34.364: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2201
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create and stop a working application  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating all guestbook components
Jul  2 12:10:34.496: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Jul  2 12:10:34.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 create -f -'
Jul  2 12:10:34.975: INFO: stderr: ""
Jul  2 12:10:34.975: INFO: stdout: "service/agnhost-replica created\n"
Jul  2 12:10:34.975: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Jul  2 12:10:34.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 create -f -'
Jul  2 12:10:35.184: INFO: stderr: ""
Jul  2 12:10:35.184: INFO: stdout: "service/agnhost-primary created\n"
Jul  2 12:10:35.185: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jul  2 12:10:35.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 create -f -'
Jul  2 12:10:35.348: INFO: stderr: ""
Jul  2 12:10:35.348: INFO: stdout: "service/frontend created\n"
Jul  2 12:10:35.348: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Jul  2 12:10:35.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 create -f -'
Jul  2 12:10:35.503: INFO: stderr: ""
Jul  2 12:10:35.503: INFO: stdout: "deployment.apps/frontend created\n"
Jul  2 12:10:35.503: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul  2 12:10:35.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 create -f -'
Jul  2 12:10:35.684: INFO: stderr: ""
Jul  2 12:10:35.684: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Jul  2 12:10:35.684: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: k8s.gcr.io/e2e-test-images/agnhost:2.39
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jul  2 12:10:35.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 create -f -'
Jul  2 12:10:35.842: INFO: stderr: ""
Jul  2 12:10:35.842: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app
Jul  2 12:10:35.842: INFO: Waiting for all frontend pods to be Running.
Jul  2 12:10:40.893: INFO: Waiting for frontend to serve content.
Jul  2 12:10:40.905: INFO: Trying to add a new entry to the guestbook.
Jul  2 12:10:40.917: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jul  2 12:10:40.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 delete --grace-period=0 --force -f -'
Jul  2 12:10:41.022: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:10:41.022: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources
Jul  2 12:10:41.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 delete --grace-period=0 --force -f -'
Jul  2 12:10:41.119: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:10:41.119: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Jul  2 12:10:41.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 delete --grace-period=0 --force -f -'
Jul  2 12:10:41.193: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:10:41.193: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul  2 12:10:41.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 delete --grace-period=0 --force -f -'
Jul  2 12:10:41.256: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:10:41.256: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jul  2 12:10:41.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 delete --grace-period=0 --force -f -'
Jul  2 12:10:41.330: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:10:41.330: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources
Jul  2 12:10:41.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-2201 delete --grace-period=0 --force -f -'
Jul  2 12:10:41.418: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:10:41.418: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:10:41.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2201" for this suite.

• [SLOW TEST:7.066 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:340
    should create and stop a working application  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":356,"completed":75,"skipped":1448,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:10:41.429: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5073
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-1c02d9b8-a630-4254-ad70-d91f38636913
STEP: Creating a pod to test consume configMaps
Jul  2 12:10:41.583: INFO: Waiting up to 5m0s for pod "pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c" in namespace "configmap-5073" to be "Succeeded or Failed"
Jul  2 12:10:41.587: INFO: Pod "pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.789491ms
Jul  2 12:10:43.595: INFO: Pod "pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c": Phase="Running", Reason="", readiness=false. Elapsed: 2.012382685s
Jul  2 12:10:45.603: INFO: Pod "pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019851067s
STEP: Saw pod success
Jul  2 12:10:45.603: INFO: Pod "pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c" satisfied condition "Succeeded or Failed"
Jul  2 12:10:45.607: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:10:45.645: INFO: Waiting for pod pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c to disappear
Jul  2 12:10:45.649: INFO: Pod pod-configmaps-a178bf0a-30e9-449f-aee6-92eebd58486c no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:10:45.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5073" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":76,"skipped":1474,"failed":0}
SSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:10:45.660: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1191
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1191
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating stateful set ss in namespace statefulset-1191
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1191
Jul  2 12:10:45.811: INFO: Found 0 stateful pods, waiting for 1
Jul  2 12:10:55.818: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jul  2 12:10:55.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-1191 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:10:55.997: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:10:55.997: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:10:55.997: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:10:56.002: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul  2 12:11:06.016: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:11:06.016: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:11:06.037: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jul  2 12:11:06.037: INFO: ss-0  ip-172-31-9-92  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:10:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:10:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:10:56 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:10:45 +0000 UTC  }]
Jul  2 12:11:06.037: INFO: 
Jul  2 12:11:06.037: INFO: StatefulSet ss has not reached scale 3, at 1
Jul  2 12:11:07.045: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99470296s
Jul  2 12:11:08.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988227955s
Jul  2 12:11:09.059: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981374409s
Jul  2 12:11:10.068: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.972981228s
Jul  2 12:11:11.074: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.96467504s
Jul  2 12:11:12.082: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.958382899s
Jul  2 12:11:13.089: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.950659843s
Jul  2 12:11:14.095: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.943720948s
Jul  2 12:11:15.104: INFO: Verifying statefulset ss doesn't scale past 3 for another 936.40385ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1191
Jul  2 12:11:16.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-1191 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:11:16.254: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  2 12:11:16.255: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:11:16.255: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  2 12:11:16.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-1191 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:11:16.393: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul  2 12:11:16.393: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:11:16.393: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  2 12:11:16.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-1191 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:11:16.550: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jul  2 12:11:16.550: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:11:16.550: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  2 12:11:16.554: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Jul  2 12:11:26.571: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:11:26.571: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:11:26.571: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jul  2 12:11:26.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-1191 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:11:26.711: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:11:26.711: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:11:26.711: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:11:26.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-1191 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:11:26.862: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:11:26.862: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:11:26.862: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:11:26.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-1191 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:11:26.998: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:11:26.998: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:11:26.998: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:11:26.998: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:11:27.003: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul  2 12:11:37.022: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:11:37.022: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:11:37.022: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:11:37.036: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul  2 12:11:37.036: INFO: ss-0  ip-172-31-9-92    Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:10:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:10:45 +0000 UTC  }]
Jul  2 12:11:37.036: INFO: ss-1  ip-172-31-69-95   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:06 +0000 UTC  }]
Jul  2 12:11:37.036: INFO: ss-2  ip-172-31-91-232  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:06 +0000 UTC  }]
Jul  2 12:11:37.036: INFO: 
Jul  2 12:11:37.036: INFO: StatefulSet ss has not reached scale 0, at 3
Jul  2 12:11:38.043: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Jul  2 12:11:38.043: INFO: ss-2  ip-172-31-91-232  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:27 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:11:06 +0000 UTC  }]
Jul  2 12:11:38.043: INFO: 
Jul  2 12:11:38.043: INFO: StatefulSet ss has not reached scale 0, at 1
Jul  2 12:11:39.049: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.988925335s
Jul  2 12:11:40.057: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.982079678s
Jul  2 12:11:41.063: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.974907077s
Jul  2 12:11:42.069: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.968863771s
Jul  2 12:11:43.076: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.962597613s
Jul  2 12:11:44.082: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.955793993s
Jul  2 12:11:45.090: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.948638331s
Jul  2 12:11:46.097: INFO: Verifying statefulset ss doesn't scale past 0 for another 941.415361ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1191
Jul  2 12:11:47.103: INFO: Scaling statefulset ss to 0
Jul  2 12:11:47.122: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 12:11:47.125: INFO: Deleting all statefulset in ns statefulset-1191
Jul  2 12:11:47.129: INFO: Scaling statefulset ss to 0
Jul  2 12:11:47.139: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:11:47.142: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 12:11:47.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1191" for this suite.

• [SLOW TEST:61.507 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":356,"completed":77,"skipped":1479,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:11:47.168: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8215
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jul  2 12:11:47.319: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8215  f76e3aeb-eba0-4842-9ba8-fa5c368f24e0 8424 0 2022-07-02 12:11:47 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-02 12:11:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 12:11:47.319: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8215  f76e3aeb-eba0-4842-9ba8-fa5c368f24e0 8425 0 2022-07-02 12:11:47 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-02 12:11:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 12:11:47.319: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8215  f76e3aeb-eba0-4842-9ba8-fa5c368f24e0 8426 0 2022-07-02 12:11:47 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-02 12:11:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jul  2 12:11:57.363: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8215  f76e3aeb-eba0-4842-9ba8-fa5c368f24e0 8483 0 2022-07-02 12:11:47 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-02 12:11:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 12:11:57.364: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8215  f76e3aeb-eba0-4842-9ba8-fa5c368f24e0 8484 0 2022-07-02 12:11:47 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-02 12:11:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 12:11:57.364: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8215  f76e3aeb-eba0-4842-9ba8-fa5c368f24e0 8485 0 2022-07-02 12:11:47 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2022-07-02 12:11:47 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  2 12:11:57.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8215" for this suite.

• [SLOW TEST:10.208 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":356,"completed":78,"skipped":1491,"failed":0}
S
------------------------------
[sig-network] EndpointSlice 
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:11:57.376: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename endpointslice
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in endpointslice-1138
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
STEP: referencing a single matching pod
STEP: referencing matching pods with named port
STEP: creating empty Endpoints and EndpointSlices for no matching Pods
STEP: recreating EndpointSlices after they've been deleted
Jul  2 12:12:17.667: INFO: EndpointSlice for Service endpointslice-1138/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  2 12:12:27.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1138" for this suite.

• [SLOW TEST:30.332 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","total":356,"completed":79,"skipped":1492,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:12:27.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6902
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-85ec0dd4-bd7f-4dea-90d2-9f355b484af8
STEP: Creating a pod to test consume secrets
Jul  2 12:12:27.863: INFO: Waiting up to 5m0s for pod "pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e" in namespace "secrets-6902" to be "Succeeded or Failed"
Jul  2 12:12:27.867: INFO: Pod "pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.874181ms
Jul  2 12:12:29.875: INFO: Pod "pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011778951s
Jul  2 12:12:31.884: INFO: Pod "pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020589521s
STEP: Saw pod success
Jul  2 12:12:31.884: INFO: Pod "pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e" satisfied condition "Succeeded or Failed"
Jul  2 12:12:31.888: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:12:31.919: INFO: Waiting for pod pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e to disappear
Jul  2 12:12:31.922: INFO: Pod pod-secrets-ee7e70da-8356-4500-913e-83e2cfa4687e no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:12:31.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6902" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":80,"skipped":1531,"failed":0}
S
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:12:31.933: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4898
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in volume subpath
Jul  2 12:12:32.080: INFO: Waiting up to 5m0s for pod "var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d" in namespace "var-expansion-4898" to be "Succeeded or Failed"
Jul  2 12:12:32.084: INFO: Pod "var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.261659ms
Jul  2 12:12:34.092: INFO: Pod "var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012437524s
Jul  2 12:12:36.101: INFO: Pod "var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021548938s
STEP: Saw pod success
Jul  2 12:12:36.101: INFO: Pod "var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d" satisfied condition "Succeeded or Failed"
Jul  2 12:12:36.105: INFO: Trying to get logs from node ip-172-31-9-92 pod var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d container dapi-container: <nil>
STEP: delete the pod
Jul  2 12:12:36.131: INFO: Waiting for pod var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d to disappear
Jul  2 12:12:36.134: INFO: Pod var-expansion-294093ed-006d-486a-b4d1-8dbd6791c63d no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 12:12:36.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4898" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","total":356,"completed":81,"skipped":1532,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:12:36.146: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9929
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:12:38.306: INFO: Deleting pod "var-expansion-c8905da4-8f92-4098-9cf5-951466472afe" in namespace "var-expansion-9929"
Jul  2 12:12:38.316: INFO: Wait up to 5m0s for pod "var-expansion-c8905da4-8f92-4098-9cf5-951466472afe" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 12:12:40.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9929" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","total":356,"completed":82,"skipped":1545,"failed":0}
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:12:40.342: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7599
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-43226327-eede-48e4-9604-987212ef26b7
STEP: Creating a pod to test consume secrets
Jul  2 12:12:40.497: INFO: Waiting up to 5m0s for pod "pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc" in namespace "secrets-7599" to be "Succeeded or Failed"
Jul  2 12:12:40.500: INFO: Pod "pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.120274ms
Jul  2 12:12:42.512: INFO: Pod "pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014672152s
Jul  2 12:12:44.524: INFO: Pod "pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026720748s
STEP: Saw pod success
Jul  2 12:12:44.524: INFO: Pod "pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc" satisfied condition "Succeeded or Failed"
Jul  2 12:12:44.528: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:12:44.556: INFO: Waiting for pod pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc to disappear
Jul  2 12:12:44.560: INFO: Pod pod-secrets-40796d3e-457d-48bb-b9bd-4eb2b68b78dc no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:12:44.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7599" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":83,"skipped":1549,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:12:44.574: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4610
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:12:45.006: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:12:48.047: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:12:48.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4610" for this suite.
STEP: Destroying namespace "webhook-4610-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":356,"completed":84,"skipped":1621,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:12:48.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4618
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:12:48.349: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jul  2 12:12:53.363: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  2 12:12:53.363: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jul  2 12:12:55.372: INFO: Creating deployment "test-rollover-deployment"
Jul  2 12:12:55.393: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jul  2 12:12:57.406: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jul  2 12:12:57.414: INFO: Ensure that both replica sets have 1 created replica
Jul  2 12:12:57.423: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jul  2 12:12:57.439: INFO: Updating deployment test-rollover-deployment
Jul  2 12:12:57.439: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jul  2 12:12:59.455: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jul  2 12:12:59.463: INFO: Make sure deployment "test-rollover-deployment" is complete
Jul  2 12:12:59.471: INFO: all replica sets need to contain the pod-template-hash label
Jul  2 12:12:59.471: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:13:01.482: INFO: all replica sets need to contain the pod-template-hash label
Jul  2 12:13:01.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:13:03.484: INFO: all replica sets need to contain the pod-template-hash label
Jul  2 12:13:03.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:13:05.485: INFO: all replica sets need to contain the pod-template-hash label
Jul  2 12:13:05.485: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:13:07.484: INFO: all replica sets need to contain the pod-template-hash label
Jul  2 12:13:07.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 12, 58, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 12, 55, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-779c67f4f8\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:13:09.484: INFO: 
Jul  2 12:13:09.484: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:13:09.496: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4618  ce2488af-cd0d-4ece-80d6-7df283cdc813 9045 2 2022-07-02 12:12:55 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-07-02 12:12:57 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:13:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003108dd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-07-02 12:12:55 +0000 UTC,LastTransitionTime:2022-07-02 12:12:55 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-779c67f4f8" has successfully progressed.,LastUpdateTime:2022-07-02 12:13:08 +0000 UTC,LastTransitionTime:2022-07-02 12:12:55 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  2 12:13:09.500: INFO: New ReplicaSet "test-rollover-deployment-779c67f4f8" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-779c67f4f8  deployment-4618  a90b09c6-f27a-4102-b79a-92f3048bbb29 9035 2 2022-07-02 12:12:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ce2488af-cd0d-4ece-80d6-7df283cdc813 0xc001123397 0xc001123398}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:12:57 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce2488af-cd0d-4ece-80d6-7df283cdc813\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:13:08 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 779c67f4f8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001123478 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:13:09.500: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jul  2 12:13:09.500: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4618  ad5df29c-64c5-48ad-92bb-b296501494b2 9044 2 2022-07-02 12:12:48 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ce2488af-cd0d-4ece-80d6-7df283cdc813 0xc001123277 0xc001123278}] []  [{e2e.test Update apps/v1 2022-07-02 12:12:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:13:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce2488af-cd0d-4ece-80d6-7df283cdc813\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:13:08 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001123338 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:13:09.500: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-87f8f6dcf  deployment-4618  237a9fd3-9fcc-402d-afcf-2c52b159999b 8998 2 2022-07-02 12:12:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ce2488af-cd0d-4ece-80d6-7df283cdc813 0xc0011234d0 0xc0011234d1}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:12:55 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce2488af-cd0d-4ece-80d6-7df283cdc813\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:12:57 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 87f8f6dcf,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:87f8f6dcf] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001123578 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:13:09.503: INFO: Pod "test-rollover-deployment-779c67f4f8-tgk49" is available:
&Pod{ObjectMeta:{test-rollover-deployment-779c67f4f8-tgk49 test-rollover-deployment-779c67f4f8- deployment-4618  1898ddad-ae8e-47f5-a0ea-5b954824a425 9014 0 2022-07-02 12:12:57 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:779c67f4f8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-779c67f4f8 a90b09c6-f27a-4102-b79a-92f3048bbb29 0xc001123b07 0xc001123b08}] []  [{kube-controller-manager Update v1 2022-07-02 12:12:57 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a90b09c6-f27a-4102-b79a-92f3048bbb29\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:12:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.9\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lzb9z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lzb9z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:12:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:12:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:12:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:12:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.9,StartTime:2022-07-02 12:12:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:12:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://45406ba06de036a9ee7dc5b8fce57f2f738d3c6531cd41bd1206fc9399db0e3a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.9,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:13:09.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4618" for this suite.

• [SLOW TEST:21.338 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":356,"completed":85,"skipped":1648,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:13:09.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8411
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-8411
STEP: creating service affinity-clusterip-transition in namespace services-8411
STEP: creating replication controller affinity-clusterip-transition in namespace services-8411
I0702 12:13:09.671475      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-8411, replica count: 3
I0702 12:13:12.721890      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 12:13:12.735: INFO: Creating new exec pod
Jul  2 12:13:15.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8411 exec execpod-affinitydnfq8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Jul  2 12:13:15.904: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Jul  2 12:13:15.904: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:13:15.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8411 exec execpod-affinitydnfq8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.32 80'
Jul  2 12:13:16.029: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.32 80\nConnection to 10.152.183.32 80 port [tcp/http] succeeded!\n"
Jul  2 12:13:16.029: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:13:16.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8411 exec execpod-affinitydnfq8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.32:80/ ; done'
Jul  2 12:13:16.283: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n"
Jul  2 12:13:16.283: INFO: stdout: "\naffinity-clusterip-transition-76892\naffinity-clusterip-transition-76892\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-76892\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-76892\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-s97h7\naffinity-clusterip-transition-x4ccl"
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-76892
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-76892
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-76892
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-76892
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-s97h7
Jul  2 12:13:16.283: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8411 exec execpod-affinitydnfq8 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.32:80/ ; done'
Jul  2 12:13:16.496: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n"
Jul  2 12:13:16.496: INFO: stdout: "\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl\naffinity-clusterip-transition-x4ccl"
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Received response from host: affinity-clusterip-transition-x4ccl
Jul  2 12:13:16.496: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-8411, will wait for the garbage collector to delete the pods
Jul  2 12:13:16.576: INFO: Deleting ReplicationController affinity-clusterip-transition took: 7.877547ms
Jul  2 12:13:16.677: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 101.101403ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:13:18.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8411" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.294 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":86,"skipped":1651,"failed":0}
SSSSSS
------------------------------
[sig-node] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:13:18.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6387
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:13:18.957: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  2 12:13:18.970: INFO: The status of Pod pod-logs-websocket-347c4e7c-ea85-4870-a605-1baf6e17ea5b is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:13:20.976: INFO: The status of Pod pod-logs-websocket-347c4e7c-ea85-4870-a605-1baf6e17ea5b is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:13:20.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6387" for this suite.
•{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":356,"completed":87,"skipped":1657,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:13:21.010: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-7914
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:13:21.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Creating first CR 
Jul  2 12:13:23.707: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-02T12:13:23Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-02T12:13:23Z]] name:name1 resourceVersion:9268 uid:7eb1289a-9d36-4755-9d32-29425474bce5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Jul  2 12:13:33.724: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-02T12:13:33Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-02T12:13:33Z]] name:name2 resourceVersion:9328 uid:c7b86cba-6133-4c51-8e3e-21b1397a5e60] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Jul  2 12:13:43.738: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-02T12:13:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-02T12:13:43Z]] name:name1 resourceVersion:9348 uid:7eb1289a-9d36-4755-9d32-29425474bce5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Jul  2 12:13:53.753: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-02T12:13:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-02T12:13:53Z]] name:name2 resourceVersion:9367 uid:c7b86cba-6133-4c51-8e3e-21b1397a5e60] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Jul  2 12:14:03.769: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-02T12:13:23Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-02T12:13:43Z]] name:name1 resourceVersion:9391 uid:7eb1289a-9d36-4755-9d32-29425474bce5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Jul  2 12:14:13.785: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-07-02T12:13:33Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-07-02T12:13:53Z]] name:name2 resourceVersion:9412 uid:c7b86cba-6133-4c51-8e3e-21b1397a5e60] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:14:24.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7914" for this suite.

• [SLOW TEST:63.307 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":356,"completed":88,"skipped":1693,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:14:24.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-981
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override arguments
Jul  2 12:14:24.482: INFO: Waiting up to 5m0s for pod "client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482" in namespace "containers-981" to be "Succeeded or Failed"
Jul  2 12:14:24.487: INFO: Pod "client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482": Phase="Pending", Reason="", readiness=false. Elapsed: 4.413773ms
Jul  2 12:14:26.495: INFO: Pod "client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01324597s
Jul  2 12:14:28.505: INFO: Pod "client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022557211s
STEP: Saw pod success
Jul  2 12:14:28.505: INFO: Pod "client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482" satisfied condition "Succeeded or Failed"
Jul  2 12:14:28.510: INFO: Trying to get logs from node ip-172-31-9-92 pod client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:14:28.538: INFO: Waiting for pod client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482 to disappear
Jul  2 12:14:28.542: INFO: Pod client-containers-0b7e0a7c-3544-4ea2-8235-ba1122234482 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  2 12:14:28.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-981" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","total":356,"completed":89,"skipped":1718,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:14:28.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4532
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  2 12:14:28.702: INFO: The status of Pod pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:14:30.710: INFO: The status of Pod pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8 is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul  2 12:14:31.241: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8"
Jul  2 12:14:31.241: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8" in namespace "pods-4532" to be "terminated due to deadline exceeded"
Jul  2 12:14:31.249: INFO: Pod "pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8": Phase="Running", Reason="", readiness=true. Elapsed: 8.356395ms
Jul  2 12:14:33.257: INFO: Pod "pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8": Phase="Running", Reason="", readiness=true. Elapsed: 2.01642066s
Jul  2 12:14:35.267: INFO: Pod "pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.025970877s
Jul  2 12:14:35.267: INFO: Pod "pod-update-activedeadlineseconds-c0e3d22e-7c0b-4b5a-b2a2-05527dadd1f8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:14:35.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4532" for this suite.

• [SLOW TEST:6.726 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":356,"completed":90,"skipped":1732,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:14:35.280: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5785
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Jul  2 12:14:35.414: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:14:47.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5785" for this suite.

• [SLOW TEST:12.547 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":356,"completed":91,"skipped":1734,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:14:47.828: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6397
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service endpoint-test2 in namespace services-6397
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6397 to expose endpoints map[]
Jul  2 12:14:47.980: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Jul  2 12:14:48.997: INFO: successfully validated that service endpoint-test2 in namespace services-6397 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-6397
Jul  2 12:14:49.013: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:14:51.021: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6397 to expose endpoints map[pod1:[80]]
Jul  2 12:14:51.038: INFO: successfully validated that service endpoint-test2 in namespace services-6397 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1
Jul  2 12:14:51.038: INFO: Creating new exec pod
Jul  2 12:14:54.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-6397 exec execpodnxz26 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul  2 12:14:54.214: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul  2 12:14:54.214: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:14:54.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-6397 exec execpodnxz26 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.66 80'
Jul  2 12:14:54.316: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.66 80\nConnection to 10.152.183.66 80 port [tcp/http] succeeded!\n"
Jul  2 12:14:54.316: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-6397
Jul  2 12:14:54.331: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:14:56.338: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6397 to expose endpoints map[pod1:[80] pod2:[80]]
Jul  2 12:14:56.363: INFO: successfully validated that service endpoint-test2 in namespace services-6397 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2
Jul  2 12:14:57.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-6397 exec execpodnxz26 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul  2 12:14:57.521: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul  2 12:14:57.521: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:14:57.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-6397 exec execpodnxz26 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.66 80'
Jul  2 12:14:57.638: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 10.152.183.66 80\nConnection to 10.152.183.66 80 port [tcp/http] succeeded!\n"
Jul  2 12:14:57.638: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-6397
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6397 to expose endpoints map[pod2:[80]]
Jul  2 12:14:57.686: INFO: successfully validated that service endpoint-test2 in namespace services-6397 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2
Jul  2 12:14:58.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-6397 exec execpodnxz26 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Jul  2 12:14:58.847: INFO: stderr: "+ + ncecho hostName\n -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Jul  2 12:14:58.847: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:14:58.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-6397 exec execpodnxz26 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.66 80'
Jul  2 12:14:58.970: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.66 80\nConnection to 10.152.183.66 80 port [tcp/http] succeeded!\n"
Jul  2 12:14:58.970: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-6397
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6397 to expose endpoints map[]
Jul  2 12:14:59.003: INFO: successfully validated that service endpoint-test2 in namespace services-6397 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:14:59.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6397" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:11.216 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":356,"completed":92,"skipped":1756,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:14:59.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9464
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9464
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-9464
I0702 12:14:59.225099      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-9464, replica count: 2
I0702 12:15:02.276463      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 12:15:02.276: INFO: Creating new exec pod
Jul  2 12:15:05.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9464 exec execpod6pr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul  2 12:15:05.445: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul  2 12:15:05.445: INFO: stdout: "externalname-service-g6spq"
Jul  2 12:15:05.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9464 exec execpod6pr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.181 80'
Jul  2 12:15:05.582: INFO: stderr: "+ nc -v -t -w 2 10.152.183.181 80\n+ echo hostName\nConnection to 10.152.183.181 80 port [tcp/http] succeeded!\n"
Jul  2 12:15:05.582: INFO: stdout: "externalname-service-t8g4r"
Jul  2 12:15:05.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9464 exec execpod6pr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.9.92 31843'
Jul  2 12:15:05.705: INFO: stderr: "+ + echo hostNamenc\n -v -t -w 2 172.31.9.92 31843\nConnection to 172.31.9.92 31843 port [tcp/*] succeeded!\n"
Jul  2 12:15:05.705: INFO: stdout: "externalname-service-t8g4r"
Jul  2 12:15:05.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-9464 exec execpod6pr2s -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.69.95 31843'
Jul  2 12:15:05.836: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.69.95 31843\nConnection to 172.31.69.95 31843 port [tcp/*] succeeded!\n"
Jul  2 12:15:05.836: INFO: stdout: "externalname-service-g6spq"
Jul  2 12:15:05.836: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:15:05.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9464" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:6.861 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":356,"completed":93,"skipped":1790,"failed":0}
S
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:15:05.905: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5840
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  2 12:15:10.085: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  2 12:15:10.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5840" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":94,"skipped":1791,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:15:10.116: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7831
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 12:15:23.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7831" for this suite.

• [SLOW TEST:13.252 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":356,"completed":95,"skipped":1795,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] 
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:15:23.368: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-preemption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-preemption-6021
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  2 12:15:23.524: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  2 12:16:23.551: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create pods that use 4/5 of node resources.
Jul  2 12:16:23.576: INFO: Created pod: pod0-0-sched-preemption-low-priority
Jul  2 12:16:23.588: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Jul  2 12:16:23.619: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Jul  2 12:16:23.625: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Jul  2 12:16:23.648: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Jul  2 12:16:23.655: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled.
STEP: Run a high priority pod that has same requirements as that of lower priority pod
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:16:31.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6021" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:68.432 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","total":356,"completed":96,"skipped":1823,"failed":0}
S
------------------------------
[sig-apps] DisruptionController 
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:16:31.800: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename disruption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in disruption-954
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pdb that targets all three pods in a test replica set
STEP: Waiting for the pdb to be processed
STEP: First trying to evict a pod which shouldn't be evictable
STEP: Waiting for all pods to be running
Jul  2 12:16:31.959: INFO: pods: 0 < 3
STEP: locating a running pod
STEP: Updating the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
STEP: Waiting for the pdb to observed all healthy pods
STEP: Patching the pdb to disallow a pod to be evicted
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
STEP: locating a running pod
STEP: Deleting the pdb to allow a pod to be evicted
STEP: Waiting for the pdb to be deleted
STEP: Trying to evict the same pod we tried earlier which should now be evictable
STEP: Waiting for all pods to be running
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  2 12:16:38.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-954" for this suite.

• [SLOW TEST:6.345 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","total":356,"completed":97,"skipped":1824,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:16:38.145: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8007
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  2 12:16:48.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8007" for this suite.

• [SLOW TEST:10.170 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":356,"completed":98,"skipped":1872,"failed":0}
SSS
------------------------------
[sig-node] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:16:48.316: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5293
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:16:48.468: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:16:50.475: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:16:52.476: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:16:54.477: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:16:56.476: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:16:58.475: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:17:00.475: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:17:02.475: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:17:04.477: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:17:06.478: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:17:08.477: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = false)
Jul  2 12:17:10.478: INFO: The status of Pod test-webserver-51bb05f9-ec2a-49be-94c2-5c0f16d524c5 is Running (Ready = true)
Jul  2 12:17:10.486: INFO: Container started at 2022-07-02 12:16:49 +0000 UTC, pod became ready at 2022-07-02 12:17:08 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 12:17:10.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5293" for this suite.

• [SLOW TEST:22.183 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":356,"completed":99,"skipped":1875,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:10.500: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3103
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:17:10.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f" in namespace "projected-3103" to be "Succeeded or Failed"
Jul  2 12:17:10.650: INFO: Pod "downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.522326ms
Jul  2 12:17:12.653: INFO: Pod "downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008384133s
Jul  2 12:17:14.664: INFO: Pod "downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018784828s
STEP: Saw pod success
Jul  2 12:17:14.664: INFO: Pod "downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f" satisfied condition "Succeeded or Failed"
Jul  2 12:17:14.667: INFO: Trying to get logs from node ip-172-31-69-95 pod downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f container client-container: <nil>
STEP: delete the pod
Jul  2 12:17:14.706: INFO: Waiting for pod downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f to disappear
Jul  2 12:17:14.709: INFO: Pod downwardapi-volume-5f83f721-1e0f-43ec-8e65-9bc1a340030f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:17:14.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3103" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":100,"skipped":1884,"failed":0}
SSSSSS
------------------------------
[sig-node] Lease 
  lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:14.724: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-9297
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] lease API should be available [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:188
Jul  2 12:17:14.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-9297" for this suite.
•{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","total":356,"completed":101,"skipped":1890,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:14.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5645
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-5645
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  2 12:17:15.083: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  2 12:17:15.121: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:17:17.131: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:17:19.129: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:17:21.127: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:17:23.128: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:17:25.134: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:17:27.132: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  2 12:17:27.142: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  2 12:17:27.150: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  2 12:17:29.197: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  2 12:17:29.197: INFO: Going to poll 192.168.74.170 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul  2 12:17:29.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.74.170:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5645 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:17:29.201: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:17:29.202: INFO: ExecWithOptions: Clientset creation
Jul  2 12:17:29.202: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5645/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.74.170%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  2 12:17:29.302: INFO: Found all 1 expected endpoints: [netserver-0]
Jul  2 12:17:29.302: INFO: Going to poll 192.168.231.25 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul  2 12:17:29.306: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.231.25:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5645 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:17:29.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:17:29.306: INFO: ExecWithOptions: Clientset creation
Jul  2 12:17:29.306: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5645/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.231.25%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  2 12:17:29.408: INFO: Found all 1 expected endpoints: [netserver-1]
Jul  2 12:17:29.408: INFO: Going to poll 192.168.64.153 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Jul  2 12:17:29.413: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.64.153:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5645 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:17:29.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:17:29.414: INFO: ExecWithOptions: Clientset creation
Jul  2 12:17:29.414: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-5645/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.64.153%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  2 12:17:29.479: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  2 12:17:29.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5645" for this suite.

• [SLOW TEST:14.542 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":102,"skipped":1901,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:29.495: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6490
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  2 12:17:33.677: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  2 12:17:33.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6490" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":103,"skipped":1949,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:33.710: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-249
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:17:33.856: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  2 12:17:38.865: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Scaling up "test-rs" replicaset 
Jul  2 12:17:38.879: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet
Jul  2 12:17:38.931: INFO: observed ReplicaSet test-rs in namespace replicaset-249 with ReadyReplicas 1, AvailableReplicas 1
Jul  2 12:17:38.957: INFO: observed ReplicaSet test-rs in namespace replicaset-249 with ReadyReplicas 1, AvailableReplicas 1
Jul  2 12:17:38.975: INFO: observed ReplicaSet test-rs in namespace replicaset-249 with ReadyReplicas 1, AvailableReplicas 1
Jul  2 12:17:40.116: INFO: observed ReplicaSet test-rs in namespace replicaset-249 with ReadyReplicas 2, AvailableReplicas 2
Jul  2 12:17:40.820: INFO: observed Replicaset test-rs in namespace replicaset-249 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  2 12:17:40.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-249" for this suite.

• [SLOW TEST:7.125 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","total":356,"completed":104,"skipped":1959,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:40.836: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6425
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:17:40.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:17:44.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6425" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":356,"completed":105,"skipped":1996,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:44.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2137
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Pod with a static label
STEP: watching for Pod to be ready
Jul  2 12:17:44.505: INFO: observed Pod pod-test in namespace pods-2137 in phase Pending with labels: map[test-pod-static:true] & conditions []
Jul  2 12:17:44.506: INFO: observed Pod pod-test in namespace pods-2137 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:44 +0000 UTC  }]
Jul  2 12:17:44.526: INFO: observed Pod pod-test in namespace pods-2137 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:44 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:44 +0000 UTC  }]
Jul  2 12:17:46.168: INFO: Found Pod pod-test in namespace pods-2137 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:17:44 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data
STEP: getting the Pod and ensuring that it's patched
STEP: replacing the Pod's status Ready condition to False
STEP: check the Pod again to ensure its Ready conditions are False
STEP: deleting the Pod via a Collection with a LabelSelector
STEP: watching for the Pod to be deleted
Jul  2 12:17:46.251: INFO: observed event type MODIFIED
Jul  2 12:17:48.160: INFO: observed event type MODIFIED
Jul  2 12:17:49.165: INFO: observed event type MODIFIED
Jul  2 12:17:49.178: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:17:49.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2137" for this suite.
•{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","total":356,"completed":106,"skipped":2007,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:49.208: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-3934
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing all events in all namespaces
STEP: patching the test event
STEP: fetching the test event
STEP: deleting the test event
STEP: listing all events in all namespaces
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Jul  2 12:17:49.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3934" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":107,"skipped":2039,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:49.422: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9090
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:17:49.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:17:50.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9090" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":356,"completed":108,"skipped":2048,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:50.116: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5961
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul  2 12:17:50.262: INFO: Waiting up to 5m0s for pod "pod-a38f2469-5636-4d7d-8888-78898591cc76" in namespace "emptydir-5961" to be "Succeeded or Failed"
Jul  2 12:17:50.267: INFO: Pod "pod-a38f2469-5636-4d7d-8888-78898591cc76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.746017ms
Jul  2 12:17:52.275: INFO: Pod "pod-a38f2469-5636-4d7d-8888-78898591cc76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012906901s
Jul  2 12:17:54.283: INFO: Pod "pod-a38f2469-5636-4d7d-8888-78898591cc76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020489197s
STEP: Saw pod success
Jul  2 12:17:54.283: INFO: Pod "pod-a38f2469-5636-4d7d-8888-78898591cc76" satisfied condition "Succeeded or Failed"
Jul  2 12:17:54.288: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-a38f2469-5636-4d7d-8888-78898591cc76 container test-container: <nil>
STEP: delete the pod
Jul  2 12:17:54.309: INFO: Waiting for pod pod-a38f2469-5636-4d7d-8888-78898591cc76 to disappear
Jul  2 12:17:54.315: INFO: Pod pod-a38f2469-5636-4d7d-8888-78898591cc76 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:17:54.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5961" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":109,"skipped":2073,"failed":0}
SSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:17:54.327: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4078
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-70eabc70-5c50-4055-96f2-66525b5e3098 in namespace container-probe-4078
Jul  2 12:17:56.489: INFO: Started pod busybox-70eabc70-5c50-4055-96f2-66525b5e3098 in namespace container-probe-4078
STEP: checking the pod's current state and verifying that restartCount is present
Jul  2 12:17:56.494: INFO: Initial restart count of pod busybox-70eabc70-5c50-4055-96f2-66525b5e3098 is 0
Jul  2 12:18:46.693: INFO: Restart count of pod container-probe-4078/busybox-70eabc70-5c50-4055-96f2-66525b5e3098 is now 1 (50.198733649s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 12:18:46.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4078" for this suite.

• [SLOW TEST:52.394 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":110,"skipped":2077,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:18:46.721: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4834
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod busybox-cec2c561-1175-40a8-a98b-30754e06bab8 in namespace container-probe-4834
Jul  2 12:18:48.880: INFO: Started pod busybox-cec2c561-1175-40a8-a98b-30754e06bab8 in namespace container-probe-4834
STEP: checking the pod's current state and verifying that restartCount is present
Jul  2 12:18:48.886: INFO: Initial restart count of pod busybox-cec2c561-1175-40a8-a98b-30754e06bab8 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 12:22:49.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4834" for this suite.

• [SLOW TEST:243.083 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":356,"completed":111,"skipped":2089,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:22:49.805: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-470
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-7b964915-cc9b-4529-b781-cc17465498a2
STEP: Creating secret with name s-test-opt-upd-ed699ed9-2bb1-4cb6-82cd-689fe0600083
STEP: Creating the pod
Jul  2 12:22:50.016: INFO: The status of Pod pod-projected-secrets-4a87a3de-f849-4749-a2fc-b7f30f057e79 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:22:52.028: INFO: The status of Pod pod-projected-secrets-4a87a3de-f849-4749-a2fc-b7f30f057e79 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:22:54.028: INFO: The status of Pod pod-projected-secrets-4a87a3de-f849-4749-a2fc-b7f30f057e79 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-7b964915-cc9b-4529-b781-cc17465498a2
STEP: Updating secret s-test-opt-upd-ed699ed9-2bb1-4cb6-82cd-689fe0600083
STEP: Creating secret with name s-test-opt-create-c226773e-9808-4ef4-af4c-64dec9486c00
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  2 12:24:06.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-470" for this suite.

• [SLOW TEST:76.697 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":112,"skipped":2107,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:24:06.502: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9317
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:24:06.660: INFO: The status of Pod busybox-scheduling-2ef23871-d56e-4bf1-91d0-5ea8897d8739 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:24:08.666: INFO: The status of Pod busybox-scheduling-2ef23871-d56e-4bf1-91d0-5ea8897d8739 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  2 12:24:08.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9317" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":356,"completed":113,"skipped":2134,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:24:08.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5636
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-59xbz in namespace proxy-5636
I0702 12:24:08.871591      20 runners.go:193] Created replication controller with name: proxy-service-59xbz, namespace: proxy-5636, replica count: 1
I0702 12:24:09.922847      20 runners.go:193] proxy-service-59xbz Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0702 12:24:10.923878      20 runners.go:193] proxy-service-59xbz Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 12:24:10.930: INFO: setup took 2.0855676s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jul  2 12:24:10.938: INFO: (0) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 7.593777ms)
Jul  2 12:24:10.941: INFO: (0) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 10.329256ms)
Jul  2 12:24:10.941: INFO: (0) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 9.865331ms)
Jul  2 12:24:10.944: INFO: (0) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 12.580315ms)
Jul  2 12:24:10.948: INFO: (0) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 17.20496ms)
Jul  2 12:24:10.948: INFO: (0) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 16.991916ms)
Jul  2 12:24:10.948: INFO: (0) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 17.433899ms)
Jul  2 12:24:10.948: INFO: (0) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 17.996466ms)
Jul  2 12:24:10.949: INFO: (0) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 17.600181ms)
Jul  2 12:24:10.949: INFO: (0) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 17.713407ms)
Jul  2 12:24:10.948: INFO: (0) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 17.741676ms)
Jul  2 12:24:10.949: INFO: (0) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 18.859551ms)
Jul  2 12:24:10.950: INFO: (0) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 18.489498ms)
Jul  2 12:24:10.950: INFO: (0) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 18.945253ms)
Jul  2 12:24:10.950: INFO: (0) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 19.308104ms)
Jul  2 12:24:10.950: INFO: (0) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 19.554021ms)
Jul  2 12:24:10.958: INFO: (1) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 7.165314ms)
Jul  2 12:24:10.959: INFO: (1) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 8.238067ms)
Jul  2 12:24:10.959: INFO: (1) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 8.508855ms)
Jul  2 12:24:10.959: INFO: (1) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 8.384384ms)
Jul  2 12:24:10.959: INFO: (1) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 8.104466ms)
Jul  2 12:24:10.961: INFO: (1) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 9.98845ms)
Jul  2 12:24:10.961: INFO: (1) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 9.778859ms)
Jul  2 12:24:10.961: INFO: (1) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 10.221271ms)
Jul  2 12:24:10.962: INFO: (1) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 11.837615ms)
Jul  2 12:24:10.962: INFO: (1) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 11.739199ms)
Jul  2 12:24:10.963: INFO: (1) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 12.600424ms)
Jul  2 12:24:10.963: INFO: (1) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 11.790135ms)
Jul  2 12:24:10.963: INFO: (1) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 12.104498ms)
Jul  2 12:24:10.963: INFO: (1) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 12.814775ms)
Jul  2 12:24:10.964: INFO: (1) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 12.869402ms)
Jul  2 12:24:10.964: INFO: (1) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 13.200669ms)
Jul  2 12:24:10.970: INFO: (2) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 5.518296ms)
Jul  2 12:24:10.971: INFO: (2) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 6.698934ms)
Jul  2 12:24:10.971: INFO: (2) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 6.980056ms)
Jul  2 12:24:10.972: INFO: (2) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 8.189272ms)
Jul  2 12:24:10.973: INFO: (2) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 8.170489ms)
Jul  2 12:24:10.974: INFO: (2) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 9.439884ms)
Jul  2 12:24:10.976: INFO: (2) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 11.560447ms)
Jul  2 12:24:10.976: INFO: (2) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 11.475363ms)
Jul  2 12:24:10.976: INFO: (2) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 11.745633ms)
Jul  2 12:24:10.976: INFO: (2) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 11.367051ms)
Jul  2 12:24:10.976: INFO: (2) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 12.118259ms)
Jul  2 12:24:10.977: INFO: (2) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 12.152606ms)
Jul  2 12:24:10.979: INFO: (2) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 14.472534ms)
Jul  2 12:24:10.979: INFO: (2) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 14.566287ms)
Jul  2 12:24:10.979: INFO: (2) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 14.549345ms)
Jul  2 12:24:10.980: INFO: (2) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 15.800891ms)
Jul  2 12:24:10.999: INFO: (3) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 19.196921ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 18.746223ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 18.49407ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 18.5521ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 19.16488ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 19.089547ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 18.77082ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 18.557948ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 18.896904ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 19.308535ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 18.67839ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 19.071052ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 18.770698ms)
Jul  2 12:24:11.000: INFO: (3) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 18.867919ms)
Jul  2 12:24:11.001: INFO: (3) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 19.822397ms)
Jul  2 12:24:11.002: INFO: (3) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 21.353459ms)
Jul  2 12:24:11.011: INFO: (4) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 8.926102ms)
Jul  2 12:24:11.012: INFO: (4) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 9.442444ms)
Jul  2 12:24:11.014: INFO: (4) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 10.829203ms)
Jul  2 12:24:11.015: INFO: (4) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 12.286101ms)
Jul  2 12:24:11.018: INFO: (4) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 14.889777ms)
Jul  2 12:24:11.018: INFO: (4) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 15.497711ms)
Jul  2 12:24:11.018: INFO: (4) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 15.672328ms)
Jul  2 12:24:11.018: INFO: (4) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 15.682939ms)
Jul  2 12:24:11.018: INFO: (4) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 15.071272ms)
Jul  2 12:24:11.018: INFO: (4) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 16.044409ms)
Jul  2 12:24:11.019: INFO: (4) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 16.00436ms)
Jul  2 12:24:11.019: INFO: (4) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 17.041148ms)
Jul  2 12:24:11.020: INFO: (4) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 17.278814ms)
Jul  2 12:24:11.020: INFO: (4) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 17.4339ms)
Jul  2 12:24:11.020: INFO: (4) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 18.315314ms)
Jul  2 12:24:11.022: INFO: (4) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 18.784879ms)
Jul  2 12:24:11.036: INFO: (5) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 14.068865ms)
Jul  2 12:24:11.036: INFO: (5) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 14.387145ms)
Jul  2 12:24:11.037: INFO: (5) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 14.587883ms)
Jul  2 12:24:11.038: INFO: (5) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 15.981073ms)
Jul  2 12:24:11.038: INFO: (5) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 15.967897ms)
Jul  2 12:24:11.039: INFO: (5) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 16.870059ms)
Jul  2 12:24:11.040: INFO: (5) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 18.598691ms)
Jul  2 12:24:11.040: INFO: (5) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 18.387363ms)
Jul  2 12:24:11.041: INFO: (5) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 18.889872ms)
Jul  2 12:24:11.041: INFO: (5) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 19.012973ms)
Jul  2 12:24:11.042: INFO: (5) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 20.494267ms)
Jul  2 12:24:11.042: INFO: (5) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 19.913839ms)
Jul  2 12:24:11.043: INFO: (5) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 20.366112ms)
Jul  2 12:24:11.043: INFO: (5) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 20.153112ms)
Jul  2 12:24:11.044: INFO: (5) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 21.303452ms)
Jul  2 12:24:11.044: INFO: (5) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 21.498033ms)
Jul  2 12:24:11.051: INFO: (6) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 7.364216ms)
Jul  2 12:24:11.052: INFO: (6) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 7.915795ms)
Jul  2 12:24:11.054: INFO: (6) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 9.26848ms)
Jul  2 12:24:11.055: INFO: (6) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 10.19043ms)
Jul  2 12:24:11.055: INFO: (6) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 10.465623ms)
Jul  2 12:24:11.056: INFO: (6) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 11.635141ms)
Jul  2 12:24:11.057: INFO: (6) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 12.475438ms)
Jul  2 12:24:11.057: INFO: (6) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 12.610695ms)
Jul  2 12:24:11.058: INFO: (6) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 13.145691ms)
Jul  2 12:24:11.058: INFO: (6) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 13.684384ms)
Jul  2 12:24:11.059: INFO: (6) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 14.484519ms)
Jul  2 12:24:11.060: INFO: (6) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 15.470844ms)
Jul  2 12:24:11.060: INFO: (6) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 15.568732ms)
Jul  2 12:24:11.061: INFO: (6) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 16.078687ms)
Jul  2 12:24:11.061: INFO: (6) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 16.888927ms)
Jul  2 12:24:11.062: INFO: (6) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 17.709679ms)
Jul  2 12:24:11.070: INFO: (7) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 7.391307ms)
Jul  2 12:24:11.071: INFO: (7) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 8.134624ms)
Jul  2 12:24:11.071: INFO: (7) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 8.445609ms)
Jul  2 12:24:11.072: INFO: (7) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 9.205736ms)
Jul  2 12:24:11.072: INFO: (7) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 9.591814ms)
Jul  2 12:24:11.073: INFO: (7) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 10.390684ms)
Jul  2 12:24:11.075: INFO: (7) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 12.937173ms)
Jul  2 12:24:11.075: INFO: (7) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 12.792737ms)
Jul  2 12:24:11.076: INFO: (7) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 13.000481ms)
Jul  2 12:24:11.077: INFO: (7) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 13.868039ms)
Jul  2 12:24:11.077: INFO: (7) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 14.043944ms)
Jul  2 12:24:11.078: INFO: (7) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 15.067297ms)
Jul  2 12:24:11.079: INFO: (7) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 15.714651ms)
Jul  2 12:24:11.079: INFO: (7) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 15.768719ms)
Jul  2 12:24:11.079: INFO: (7) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 16.122427ms)
Jul  2 12:24:11.080: INFO: (7) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 16.667974ms)
Jul  2 12:24:11.087: INFO: (8) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 7.533656ms)
Jul  2 12:24:11.088: INFO: (8) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 8.27489ms)
Jul  2 12:24:11.088: INFO: (8) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 8.622831ms)
Jul  2 12:24:11.089: INFO: (8) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 9.356421ms)
Jul  2 12:24:11.090: INFO: (8) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 10.285715ms)
Jul  2 12:24:11.091: INFO: (8) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 11.344164ms)
Jul  2 12:24:11.092: INFO: (8) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 12.39997ms)
Jul  2 12:24:11.093: INFO: (8) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 13.339058ms)
Jul  2 12:24:11.094: INFO: (8) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 13.949639ms)
Jul  2 12:24:11.094: INFO: (8) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 14.253719ms)
Jul  2 12:24:11.094: INFO: (8) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 14.438645ms)
Jul  2 12:24:11.095: INFO: (8) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 14.940939ms)
Jul  2 12:24:11.095: INFO: (8) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 15.09629ms)
Jul  2 12:24:11.096: INFO: (8) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 15.855334ms)
Jul  2 12:24:11.097: INFO: (8) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 16.851494ms)
Jul  2 12:24:11.097: INFO: (8) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 17.122468ms)
Jul  2 12:24:11.105: INFO: (9) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 7.833606ms)
Jul  2 12:24:11.106: INFO: (9) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 8.313991ms)
Jul  2 12:24:11.107: INFO: (9) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 9.400843ms)
Jul  2 12:24:11.107: INFO: (9) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 9.843882ms)
Jul  2 12:24:11.108: INFO: (9) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 10.866509ms)
Jul  2 12:24:11.109: INFO: (9) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 10.956388ms)
Jul  2 12:24:11.111: INFO: (9) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 13.547768ms)
Jul  2 12:24:11.111: INFO: (9) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 13.81517ms)
Jul  2 12:24:11.111: INFO: (9) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 13.48541ms)
Jul  2 12:24:11.112: INFO: (9) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 14.758241ms)
Jul  2 12:24:11.112: INFO: (9) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 14.752127ms)
Jul  2 12:24:11.113: INFO: (9) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 15.449907ms)
Jul  2 12:24:11.114: INFO: (9) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 15.970573ms)
Jul  2 12:24:11.114: INFO: (9) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 16.674229ms)
Jul  2 12:24:11.114: INFO: (9) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 16.652174ms)
Jul  2 12:24:11.115: INFO: (9) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 17.207208ms)
Jul  2 12:24:11.122: INFO: (10) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 6.614408ms)
Jul  2 12:24:11.124: INFO: (10) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 8.459155ms)
Jul  2 12:24:11.125: INFO: (10) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 9.256333ms)
Jul  2 12:24:11.126: INFO: (10) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 10.275719ms)
Jul  2 12:24:11.127: INFO: (10) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 11.843349ms)
Jul  2 12:24:11.127: INFO: (10) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 11.700884ms)
Jul  2 12:24:11.129: INFO: (10) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 13.406007ms)
Jul  2 12:24:11.129: INFO: (10) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 12.871434ms)
Jul  2 12:24:11.129: INFO: (10) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 13.393573ms)
Jul  2 12:24:11.130: INFO: (10) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 14.468213ms)
Jul  2 12:24:11.130: INFO: (10) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 14.669862ms)
Jul  2 12:24:11.131: INFO: (10) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 15.460793ms)
Jul  2 12:24:11.131: INFO: (10) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 15.887009ms)
Jul  2 12:24:11.131: INFO: (10) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 16.134928ms)
Jul  2 12:24:11.132: INFO: (10) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 16.194728ms)
Jul  2 12:24:11.132: INFO: (10) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 16.667125ms)
Jul  2 12:24:11.139: INFO: (11) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 6.930024ms)
Jul  2 12:24:11.142: INFO: (11) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 9.353333ms)
Jul  2 12:24:11.142: INFO: (11) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 9.512183ms)
Jul  2 12:24:11.142: INFO: (11) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 9.789355ms)
Jul  2 12:24:11.143: INFO: (11) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 10.360391ms)
Jul  2 12:24:11.143: INFO: (11) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 10.817428ms)
Jul  2 12:24:11.144: INFO: (11) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 10.645745ms)
Jul  2 12:24:11.144: INFO: (11) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 11.32554ms)
Jul  2 12:24:11.146: INFO: (11) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 12.831806ms)
Jul  2 12:24:11.146: INFO: (11) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 12.776651ms)
Jul  2 12:24:11.146: INFO: (11) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 13.390364ms)
Jul  2 12:24:11.146: INFO: (11) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 13.855023ms)
Jul  2 12:24:11.147: INFO: (11) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 13.934781ms)
Jul  2 12:24:11.147: INFO: (11) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 14.48833ms)
Jul  2 12:24:11.148: INFO: (11) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 15.358647ms)
Jul  2 12:24:11.149: INFO: (11) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 16.415495ms)
Jul  2 12:24:11.154: INFO: (12) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 4.229804ms)
Jul  2 12:24:11.156: INFO: (12) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 6.168295ms)
Jul  2 12:24:11.156: INFO: (12) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 6.362104ms)
Jul  2 12:24:11.156: INFO: (12) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 6.062405ms)
Jul  2 12:24:11.157: INFO: (12) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 6.776639ms)
Jul  2 12:24:11.157: INFO: (12) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 7.549063ms)
Jul  2 12:24:11.158: INFO: (12) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 7.729189ms)
Jul  2 12:24:11.158: INFO: (12) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 8.363058ms)
Jul  2 12:24:11.160: INFO: (12) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 9.981332ms)
Jul  2 12:24:11.160: INFO: (12) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 9.876059ms)
Jul  2 12:24:11.160: INFO: (12) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 10.744102ms)
Jul  2 12:24:11.161: INFO: (12) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 10.834305ms)
Jul  2 12:24:11.161: INFO: (12) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 11.133203ms)
Jul  2 12:24:11.162: INFO: (12) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 12.333489ms)
Jul  2 12:24:11.162: INFO: (12) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 12.028062ms)
Jul  2 12:24:11.162: INFO: (12) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 12.334797ms)
Jul  2 12:24:11.168: INFO: (13) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 5.726718ms)
Jul  2 12:24:11.168: INFO: (13) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 5.8333ms)
Jul  2 12:24:11.169: INFO: (13) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 6.547188ms)
Jul  2 12:24:11.170: INFO: (13) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 7.261191ms)
Jul  2 12:24:11.170: INFO: (13) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 7.490141ms)
Jul  2 12:24:11.170: INFO: (13) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 7.754323ms)
Jul  2 12:24:11.171: INFO: (13) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 8.311666ms)
Jul  2 12:24:11.171: INFO: (13) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 8.719719ms)
Jul  2 12:24:11.173: INFO: (13) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 10.03625ms)
Jul  2 12:24:11.173: INFO: (13) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 10.441078ms)
Jul  2 12:24:11.173: INFO: (13) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 10.192173ms)
Jul  2 12:24:11.173: INFO: (13) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 10.175498ms)
Jul  2 12:24:11.175: INFO: (13) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 11.942887ms)
Jul  2 12:24:11.175: INFO: (13) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 12.268624ms)
Jul  2 12:24:11.175: INFO: (13) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 12.356387ms)
Jul  2 12:24:11.175: INFO: (13) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 12.417793ms)
Jul  2 12:24:11.181: INFO: (14) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 5.061628ms)
Jul  2 12:24:11.183: INFO: (14) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 6.417051ms)
Jul  2 12:24:11.183: INFO: (14) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 7.232416ms)
Jul  2 12:24:11.185: INFO: (14) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 9.70101ms)
Jul  2 12:24:11.186: INFO: (14) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 10.109534ms)
Jul  2 12:24:11.186: INFO: (14) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 10.145912ms)
Jul  2 12:24:11.186: INFO: (14) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 11.063749ms)
Jul  2 12:24:11.187: INFO: (14) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 11.017663ms)
Jul  2 12:24:11.188: INFO: (14) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 11.974393ms)
Jul  2 12:24:11.188: INFO: (14) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 11.891952ms)
Jul  2 12:24:11.188: INFO: (14) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 12.107305ms)
Jul  2 12:24:11.188: INFO: (14) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 11.965475ms)
Jul  2 12:24:11.189: INFO: (14) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 12.493311ms)
Jul  2 12:24:11.189: INFO: (14) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 12.687879ms)
Jul  2 12:24:11.189: INFO: (14) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 13.053875ms)
Jul  2 12:24:11.190: INFO: (14) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 13.412524ms)
Jul  2 12:24:11.194: INFO: (15) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 4.139468ms)
Jul  2 12:24:11.196: INFO: (15) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 6.322505ms)
Jul  2 12:24:11.197: INFO: (15) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 7.367424ms)
Jul  2 12:24:11.197: INFO: (15) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 6.875092ms)
Jul  2 12:24:11.197: INFO: (15) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 6.975188ms)
Jul  2 12:24:11.197: INFO: (15) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 7.803134ms)
Jul  2 12:24:11.199: INFO: (15) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 9.227808ms)
Jul  2 12:24:11.199: INFO: (15) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 9.489917ms)
Jul  2 12:24:11.199: INFO: (15) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 9.357335ms)
Jul  2 12:24:11.200: INFO: (15) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 9.955667ms)
Jul  2 12:24:11.200: INFO: (15) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 9.84448ms)
Jul  2 12:24:11.201: INFO: (15) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 11.009202ms)
Jul  2 12:24:11.202: INFO: (15) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 11.840322ms)
Jul  2 12:24:11.202: INFO: (15) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 11.476543ms)
Jul  2 12:24:11.202: INFO: (15) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 12.184497ms)
Jul  2 12:24:11.203: INFO: (15) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 13.317173ms)
Jul  2 12:24:11.209: INFO: (16) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 5.40449ms)
Jul  2 12:24:11.210: INFO: (16) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 5.786396ms)
Jul  2 12:24:11.210: INFO: (16) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 6.760609ms)
Jul  2 12:24:11.211: INFO: (16) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 7.339057ms)
Jul  2 12:24:11.211: INFO: (16) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 7.736118ms)
Jul  2 12:24:11.212: INFO: (16) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 8.756706ms)
Jul  2 12:24:11.213: INFO: (16) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 9.01774ms)
Jul  2 12:24:11.213: INFO: (16) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 9.692526ms)
Jul  2 12:24:11.214: INFO: (16) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 10.510919ms)
Jul  2 12:24:11.214: INFO: (16) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 10.622021ms)
Jul  2 12:24:11.215: INFO: (16) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 10.849185ms)
Jul  2 12:24:11.215: INFO: (16) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 11.607965ms)
Jul  2 12:24:11.216: INFO: (16) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 12.041702ms)
Jul  2 12:24:11.216: INFO: (16) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 12.611888ms)
Jul  2 12:24:11.216: INFO: (16) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 12.617329ms)
Jul  2 12:24:11.218: INFO: (16) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 13.780191ms)
Jul  2 12:24:11.223: INFO: (17) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 4.861648ms)
Jul  2 12:24:11.224: INFO: (17) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 5.828551ms)
Jul  2 12:24:11.224: INFO: (17) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 5.935962ms)
Jul  2 12:24:11.225: INFO: (17) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 6.301352ms)
Jul  2 12:24:11.225: INFO: (17) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 6.924919ms)
Jul  2 12:24:11.225: INFO: (17) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 7.562665ms)
Jul  2 12:24:11.226: INFO: (17) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 8.022234ms)
Jul  2 12:24:11.228: INFO: (17) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 9.459521ms)
Jul  2 12:24:11.228: INFO: (17) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 9.574318ms)
Jul  2 12:24:11.228: INFO: (17) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 9.565703ms)
Jul  2 12:24:11.228: INFO: (17) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 9.931932ms)
Jul  2 12:24:11.232: INFO: (17) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 13.36477ms)
Jul  2 12:24:11.233: INFO: (17) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 14.700991ms)
Jul  2 12:24:11.234: INFO: (17) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 15.314267ms)
Jul  2 12:24:11.235: INFO: (17) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 16.697165ms)
Jul  2 12:24:11.236: INFO: (17) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 17.271342ms)
Jul  2 12:24:11.241: INFO: (18) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 5.173648ms)
Jul  2 12:24:11.243: INFO: (18) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 5.919304ms)
Jul  2 12:24:11.243: INFO: (18) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 6.92766ms)
Jul  2 12:24:11.243: INFO: (18) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 7.248236ms)
Jul  2 12:24:11.246: INFO: (18) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 9.109626ms)
Jul  2 12:24:11.246: INFO: (18) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 9.414088ms)
Jul  2 12:24:11.246: INFO: (18) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 9.766049ms)
Jul  2 12:24:11.246: INFO: (18) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 9.287635ms)
Jul  2 12:24:11.246: INFO: (18) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 10.065097ms)
Jul  2 12:24:11.246: INFO: (18) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 9.717604ms)
Jul  2 12:24:11.247: INFO: (18) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 10.97789ms)
Jul  2 12:24:11.249: INFO: (18) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 12.349959ms)
Jul  2 12:24:11.250: INFO: (18) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 14.045081ms)
Jul  2 12:24:11.250: INFO: (18) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 13.773119ms)
Jul  2 12:24:11.251: INFO: (18) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 14.366263ms)
Jul  2 12:24:11.251: INFO: (18) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 15.095881ms)
Jul  2 12:24:11.258: INFO: (19) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 6.380589ms)
Jul  2 12:24:11.258: INFO: (19) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">... (200; 6.551505ms)
Jul  2 12:24:11.259: INFO: (19) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 7.726624ms)
Jul  2 12:24:11.259: INFO: (19) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:160/proxy/: foo (200; 7.748298ms)
Jul  2 12:24:11.259: INFO: (19) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl:1080/proxy/rewriteme">test<... (200; 7.874897ms)
Jul  2 12:24:11.260: INFO: (19) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:462/proxy/: tls qux (200; 8.458039ms)
Jul  2 12:24:11.261: INFO: (19) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:460/proxy/: tls baz (200; 9.292414ms)
Jul  2 12:24:11.261: INFO: (19) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname2/proxy/: bar (200; 9.926062ms)
Jul  2 12:24:11.262: INFO: (19) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname1/proxy/: tls baz (200; 10.331764ms)
Jul  2 12:24:11.262: INFO: (19) /api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/https:proxy-service-59xbz-t6zxl:443/proxy/tlsrewritem... (200; 10.388036ms)
Jul  2 12:24:11.263: INFO: (19) /api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/: <a href="/api/v1/namespaces/proxy-5636/pods/proxy-service-59xbz-t6zxl/proxy/rewriteme">test</a> (200; 11.080287ms)
Jul  2 12:24:11.263: INFO: (19) /api/v1/namespaces/proxy-5636/pods/http:proxy-service-59xbz-t6zxl:162/proxy/: bar (200; 11.250091ms)
Jul  2 12:24:11.263: INFO: (19) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname1/proxy/: foo (200; 12.108465ms)
Jul  2 12:24:11.264: INFO: (19) /api/v1/namespaces/proxy-5636/services/http:proxy-service-59xbz:portname1/proxy/: foo (200; 12.348876ms)
Jul  2 12:24:11.265: INFO: (19) /api/v1/namespaces/proxy-5636/services/proxy-service-59xbz:portname2/proxy/: bar (200; 13.493287ms)
Jul  2 12:24:11.265: INFO: (19) /api/v1/namespaces/proxy-5636/services/https:proxy-service-59xbz:tlsportname2/proxy/: tls qux (200; 13.80737ms)
STEP: deleting ReplicationController proxy-service-59xbz in namespace proxy-5636, will wait for the garbage collector to delete the pods
Jul  2 12:24:11.331: INFO: Deleting ReplicationController proxy-service-59xbz took: 9.402055ms
Jul  2 12:24:11.432: INFO: Terminating ReplicationController proxy-service-59xbz pods took: 100.81791ms
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Jul  2 12:24:13.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5636" for this suite.

• [SLOW TEST:5.136 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":356,"completed":114,"skipped":2157,"failed":0}
SSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints 
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:24:13.849: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-preemption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-preemption-4337
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  2 12:24:14.000: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  2 12:25:14.024: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:14.029: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-preemption-path-6596
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:25:14.184: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: Value: Forbidden: may not be changed in an update.
Jul  2 12:25:14.189: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: Value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:188
Jul  2 12:25:14.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-6596" for this suite.
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:25:14.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4337" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:60.448 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","total":356,"completed":115,"skipped":2161,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:14.298: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6122
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:25:14.427: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:25:20.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6122" for this suite.

• [SLOW TEST:6.436 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":356,"completed":116,"skipped":2164,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:20.734: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6453
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:25:20.870: INFO: Creating deployment "webserver-deployment"
Jul  2 12:25:20.877: INFO: Waiting for observed generation 1
Jul  2 12:25:22.894: INFO: Waiting for all required pods to come up
Jul  2 12:25:22.900: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Jul  2 12:25:24.915: INFO: Waiting for deployment "webserver-deployment" to complete
Jul  2 12:25:24.922: INFO: Updating deployment "webserver-deployment" with a non-existent image
Jul  2 12:25:24.937: INFO: Updating deployment webserver-deployment
Jul  2 12:25:24.937: INFO: Waiting for observed generation 2
Jul  2 12:25:26.947: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jul  2 12:25:26.951: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jul  2 12:25:26.956: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jul  2 12:25:26.969: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jul  2 12:25:26.969: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jul  2 12:25:26.972: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jul  2 12:25:26.981: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Jul  2 12:25:26.981: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Jul  2 12:25:26.991: INFO: Updating deployment webserver-deployment
Jul  2 12:25:26.991: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Jul  2 12:25:27.002: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jul  2 12:25:27.011: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:25:27.042: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6453  4d8123db-7f16-4b03-86e5-8392da9e3ef2 12614 3 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:25:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037068e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-57ccb67bb8" is progressing.,LastUpdateTime:2022-07-02 12:25:25 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-07-02 12:25:27 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Jul  2 12:25:27.064: INFO: New ReplicaSet "webserver-deployment-57ccb67bb8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-57ccb67bb8  deployment-6453  ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 12611 3 2022-07-02 12:25:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 4d8123db-7f16-4b03-86e5-8392da9e3ef2 0xc004211ed7 0xc004211ed8}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:25:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4d8123db-7f16-4b03-86e5-8392da9e3ef2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:25:24 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 57ccb67bb8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004211f78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:25:27.064: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Jul  2 12:25:27.064: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-55df494869  deployment-6453  83c6970e-c5eb-43be-8453-b0a5763d6826 12610 3 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 4d8123db-7f16-4b03-86e5-8392da9e3ef2 0xc004211de7 0xc004211de8}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4d8123db-7f16-4b03-86e5-8392da9e3ef2\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004211e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:25:27.081: INFO: Pod "webserver-deployment-55df494869-2lh6g" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-2lh6g webserver-deployment-55df494869- deployment-6453  6670b8d5-ea07-4031-9420-2802f568939b 12637 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cc427 0xc0036cc428}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q4qzn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q4qzn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:,StartTime:2022-07-02 12:25:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.081: INFO: Pod "webserver-deployment-55df494869-46s4f" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-46s4f webserver-deployment-55df494869- deployment-6453  eb25faca-7493-4dd6-aef3-55f19f57643b 12480 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cc5f7 0xc0036cc5f8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.180\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sklcd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sklcd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.180,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4bd77cba8e74f84b0bd7a6cd1a9cbfced33430b9666bc9256e556ef2a1c3f7e8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.180,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.081: INFO: Pod "webserver-deployment-55df494869-4ngkt" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-4ngkt webserver-deployment-55df494869- deployment-6453  494eeff6-4d91-4218-b0dd-6864135c3bb5 12461 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cc7e7 0xc0036cc7e8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.64.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-f5vht,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-f5vht,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-91-232,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.91.232,PodIP:192.168.64.155,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://ade66d159a5e9b7e0aac353fa4cc8a84524c9c49add06607f5137d104f61d105,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.64.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.082: INFO: Pod "webserver-deployment-55df494869-7qnwx" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-7qnwx webserver-deployment-55df494869- deployment-6453  29d23fdf-5e30-4b7a-830e-99485c186fbf 12644 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cc9e7 0xc0036cc9e8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mqfsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mqfsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.082: INFO: Pod "webserver-deployment-55df494869-cptwt" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-cptwt webserver-deployment-55df494869- deployment-6453  02c443ce-2466-4bf2-ba51-a787958e2f85 12477 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036ccb50 0xc0036ccb51}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.32\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-68tm4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-68tm4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.32,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://804d6ee6ae9a8e23a5aebd3897c350963d1395d076a2e72edbcb53116726ebbf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.082: INFO: Pod "webserver-deployment-55df494869-gpdmh" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-gpdmh webserver-deployment-55df494869- deployment-6453  49ee3462-556e-43cb-a25d-899e592b52eb 12474 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036ccd37 0xc0036ccd38}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.31\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m2rtf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m2rtf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.31,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5465396962037e90a6d3818e72d45e4a523ddc9759266bd7f61a884e662fed01,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.31,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.082: INFO: Pod "webserver-deployment-55df494869-kmz56" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-kmz56 webserver-deployment-55df494869- deployment-6453  9378bd62-84e9-4dee-8a38-3ffc583b5689 12643 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036ccf27 0xc0036ccf28}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-m8zwp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-m8zwp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-91-232,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.082: INFO: Pod "webserver-deployment-55df494869-mlwmz" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-mlwmz webserver-deployment-55df494869- deployment-6453  716e213c-1f7c-4503-8aac-e901889f4e31 12486 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cd0a0 0xc0036cd0a1}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.179\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8rm7z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8rm7z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.179,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://62524f119fecc0a89251d9ed66e8cadc64e742a3349981faa86ff65606840afe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.179,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.082: INFO: Pod "webserver-deployment-55df494869-rjqc8" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-rjqc8 webserver-deployment-55df494869- deployment-6453  7f786235-28f8-47d6-a046-f9b41ce8dee2 12635 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cd287 0xc0036cd288}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t67c5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t67c5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-55df494869-s5pj7" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-s5pj7 webserver-deployment-55df494869- deployment-6453  a0e63f29-0aef-448a-91f2-c6aea9fb2a7a 12465 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cd3c7 0xc0036cd3c8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.64.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sz4pl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sz4pl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-91-232,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.91.232,PodIP:192.168.64.156,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a3d306e1294430967aefdc4122836d8c5f6afd588eb47a45c0e736318bd7894d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.64.156,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-55df494869-sfhj5" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-sfhj5 webserver-deployment-55df494869- deployment-6453  35a2b877-744d-4d23-9197-c1ea1763f9b3 12630 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cd5b7 0xc0036cd5b8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8d29b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8d29b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:,StartTime:2022-07-02 12:25:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-55df494869-v8dlw" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-v8dlw webserver-deployment-55df494869- deployment-6453  c3229f14-e3ca-42c3-a0b9-0e4c21b5411f 12636 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cd787 0xc0036cd788}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vhg76,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vhg76,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-55df494869-xb5w8" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-xb5w8 webserver-deployment-55df494869- deployment-6453  8f3a71ad-ba2b-4c37-94ed-a8e4874ae6f5 12483 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cd8c7 0xc0036cd8c8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.181\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9nvsv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9nvsv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.181,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://2430c75f723ab15c77abe748a6cc3be47f81cba42642a757446ead3439fb52a0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-55df494869-z6j2t" is not available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-z6j2t webserver-deployment-55df494869- deployment-6453  c2271e8d-11f4-41d4-a972-5c74993fd2cf 12627 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cdab7 0xc0036cdab8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cnbkl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cnbkl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-55df494869-zs4gm" is available:
&Pod{ObjectMeta:{webserver-deployment-55df494869-zs4gm webserver-deployment-55df494869- deployment-6453  c3def246-e5fd-4e0a-9816-78f4f2f5762d 12468 0 2022-07-02 12:25:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-55df494869 83c6970e-c5eb-43be-8453-b0a5763d6826 0xc0036cdc20 0xc0036cdc21}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"83c6970e-c5eb-43be-8453-b0a5763d6826\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:22 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.64.157\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6lj5m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6lj5m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-91-232,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.91.232,PodIP:192.168.64.157,StartTime:2022-07-02 12:25:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:25:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://de64c6d98287b2f2a2a3d4cf7682de1670e50ab96863d6736025f8056906ce40,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.64.157,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-57ccb67bb8-562v9" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-562v9 webserver-deployment-57ccb67bb8- deployment-6453  c6d77d2b-f06e-4870-82e8-e23509c1c4b3 12596 0 2022-07-02 12:25:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0036cde17 0xc0036cde18}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.64.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rs8qg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rs8qg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-91-232,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.91.232,PodIP:192.168.64.158,StartTime:2022-07-02 12:25:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.64.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.083: INFO: Pod "webserver-deployment-57ccb67bb8-6k9j7" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-6k9j7 webserver-deployment-57ccb67bb8- deployment-6453  38400d46-f0a3-44d2-993b-e27b6151ea13 12603 0 2022-07-02 12:25:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039ea047 0xc0039ea048}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.33\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-brs8q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-brs8q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.33,StartTime:2022-07-02 12:25:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.084: INFO: Pod "webserver-deployment-57ccb67bb8-6lfp8" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-6lfp8 webserver-deployment-57ccb67bb8- deployment-6453  6268b60c-5940-4b4c-8646-a40066f8541a 12641 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039ea260 0xc0039ea261}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dkplz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dkplz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.084: INFO: Pod "webserver-deployment-57ccb67bb8-b8h48" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-b8h48 webserver-deployment-57ccb67bb8- deployment-6453  a243a943-6488-4289-ae7f-916fcac61ace 12642 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039ea3a7 0xc0039ea3a8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xk4m5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xk4m5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-91-232,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.91.232,PodIP:,StartTime:2022-07-02 12:25:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.084: INFO: Pod "webserver-deployment-57ccb67bb8-dfsdx" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-dfsdx webserver-deployment-57ccb67bb8- deployment-6453  e52728c5-66d2-46f2-a45a-76bb9f525b2c 12638 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039ea597 0xc0039ea598}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gwvwm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gwvwm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.084: INFO: Pod "webserver-deployment-57ccb67bb8-drkft" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-drkft webserver-deployment-57ccb67bb8- deployment-6453  7b011e89-4c27-4d1b-a1e0-a73bc2ffd1a2 12600 0 2022-07-02 12:25:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039ea6e7 0xc0039ea6e8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.34\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6lhr4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6lhr4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.34,StartTime:2022-07-02 12:25:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.084: INFO: Pod "webserver-deployment-57ccb67bb8-ktkrj" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-ktkrj webserver-deployment-57ccb67bb8- deployment-6453  39b0bc26-a369-46d1-9e6f-133acf44225a 12639 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039ea900 0xc0039ea901}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ts8g8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ts8g8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.084: INFO: Pod "webserver-deployment-57ccb67bb8-llvjp" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-llvjp webserver-deployment-57ccb67bb8- deployment-6453  98632351-e155-4839-89c1-16e4df8303ce 12631 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039eaa47 0xc0039eaa48}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c69b8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c69b8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.085: INFO: Pod "webserver-deployment-57ccb67bb8-n47q2" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-n47q2 webserver-deployment-57ccb67bb8- deployment-6453  24785099-79b6-434a-8f8b-a22b2c5fe3d7 12628 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039eabc0 0xc0039eabc1}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-p2m6l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-p2m6l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.085: INFO: Pod "webserver-deployment-57ccb67bb8-tqq6m" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-tqq6m webserver-deployment-57ccb67bb8- deployment-6453  47f5507d-3a32-44ad-879f-14bc00fa4033 12640 0 2022-07-02 12:25:27 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039ead30 0xc0039ead31}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q42lq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q42lq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.085: INFO: Pod "webserver-deployment-57ccb67bb8-vg9x9" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-vg9x9 webserver-deployment-57ccb67bb8- deployment-6453  10a60241-c571-46ca-84d8-f11527edef13 12580 0 2022-07-02 12:25:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039eae77 0xc0039eae78}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.182\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mw8v9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mw8v9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.182,StartTime:2022-07-02 12:25:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:25:27.085: INFO: Pod "webserver-deployment-57ccb67bb8-zsbkt" is not available:
&Pod{ObjectMeta:{webserver-deployment-57ccb67bb8-zsbkt webserver-deployment-57ccb67bb8- deployment-6453  6de94ab3-32aa-46a2-a059-60eaba11cb33 12606 0 2022-07-02 12:25:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:57ccb67bb8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-57ccb67bb8 ea748440-a4d1-44fb-8c6c-3ef4253e9c7b 0xc0039eb0b7 0xc0039eb0b8}] []  [{kube-controller-manager Update v1 2022-07-02 12:25:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ea748440-a4d1-44fb-8c6c-3ef4253e9c7b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:25:26 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.183\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ldsgt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ldsgt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:25:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.183,StartTime:2022-07-02 12:25:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:25:27.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6453" for this suite.

• [SLOW TEST:6.396 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":356,"completed":117,"skipped":2198,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:27.131: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5848
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  2 12:25:27.298: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  2 12:25:31.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5848" for this suite.
•{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":356,"completed":118,"skipped":2227,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:31.898: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7825
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:25:33.054: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jul  2 12:25:35.071: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 12, 25, 33, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 25, 33, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 25, 33, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 25, 33, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:25:38.094: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Jul  2 12:25:40.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=webhook-7825 attach --namespace=webhook-7825 to-be-attached-pod -i -c=container1'
Jul  2 12:25:40.207: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:25:40.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7825" for this suite.
STEP: Destroying namespace "webhook-7825-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:8.398 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":356,"completed":119,"skipped":2230,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:40.296: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2577
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pods
Jul  2 12:25:40.448: INFO: created test-pod-1
Jul  2 12:25:40.456: INFO: created test-pod-2
Jul  2 12:25:40.464: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running
Jul  2 12:25:40.464: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-2577' to be running and ready
Jul  2 12:25:40.479: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul  2 12:25:40.479: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul  2 12:25:40.479: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Jul  2 12:25:40.479: INFO: 0 / 3 pods in namespace 'pods-2577' are running and ready (0 seconds elapsed)
Jul  2 12:25:40.479: INFO: expected 0 pod replicas in namespace 'pods-2577', 0 are Running and Ready.
Jul  2 12:25:40.479: INFO: POD         NODE            PHASE    GRACE  CONDITIONS
Jul  2 12:25:40.479: INFO: test-pod-1  ip-172-31-9-92  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:25:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:25:40 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:25:40 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:25:40 +0000 UTC  }]
Jul  2 12:25:40.479: INFO: test-pod-2  ip-172-31-9-92  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:25:40 +0000 UTC  }]
Jul  2 12:25:40.479: INFO: test-pod-3  ip-172-31-9-92  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-07-02 12:25:40 +0000 UTC  }]
Jul  2 12:25:40.479: INFO: 
Jul  2 12:25:42.495: INFO: 3 / 3 pods in namespace 'pods-2577' are running and ready (2 seconds elapsed)
Jul  2 12:25:42.495: INFO: expected 0 pod replicas in namespace 'pods-2577', 0 are Running and Ready.
STEP: waiting for all pods to be deleted
Jul  2 12:25:42.527: INFO: Pod quantity 3 is different from expected quantity 0
Jul  2 12:25:43.534: INFO: Pod quantity 3 is different from expected quantity 0
Jul  2 12:25:44.534: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:25:45.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2577" for this suite.

• [SLOW TEST:5.255 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","total":356,"completed":120,"skipped":2247,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:45.552: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8212
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:25:45.744: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb" in namespace "downward-api-8212" to be "Succeeded or Failed"
Jul  2 12:25:45.749: INFO: Pod "downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.814828ms
Jul  2 12:25:47.757: INFO: Pod "downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013098935s
Jul  2 12:25:49.767: INFO: Pod "downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023778931s
Jul  2 12:25:51.775: INFO: Pod "downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.03143198s
STEP: Saw pod success
Jul  2 12:25:51.775: INFO: Pod "downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb" satisfied condition "Succeeded or Failed"
Jul  2 12:25:51.779: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb container client-container: <nil>
STEP: delete the pod
Jul  2 12:25:51.808: INFO: Waiting for pod downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb to disappear
Jul  2 12:25:51.813: INFO: Pod downwardapi-volume-9b79dcd8-ef2f-4c65-9e1b-9b26ba0a73eb no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 12:25:51.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8212" for this suite.

• [SLOW TEST:6.274 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":121,"skipped":2291,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:25:51.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2253
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-88tm
STEP: Creating a pod to test atomic-volume-subpath
Jul  2 12:25:51.983: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-88tm" in namespace "subpath-2253" to be "Succeeded or Failed"
Jul  2 12:25:51.987: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Pending", Reason="", readiness=false. Elapsed: 4.757506ms
Jul  2 12:25:54.003: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 2.020570681s
Jul  2 12:25:56.009: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 4.026489992s
Jul  2 12:25:58.015: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 6.03271496s
Jul  2 12:26:00.023: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 8.040651155s
Jul  2 12:26:02.030: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 10.047442211s
Jul  2 12:26:04.037: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 12.054476179s
Jul  2 12:26:06.044: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 14.061421471s
Jul  2 12:26:08.050: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 16.067064561s
Jul  2 12:26:10.057: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 18.074267842s
Jul  2 12:26:12.066: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=true. Elapsed: 20.083370173s
Jul  2 12:26:14.072: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Running", Reason="", readiness=false. Elapsed: 22.089679339s
Jul  2 12:26:16.078: INFO: Pod "pod-subpath-test-configmap-88tm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.095374921s
STEP: Saw pod success
Jul  2 12:26:16.078: INFO: Pod "pod-subpath-test-configmap-88tm" satisfied condition "Succeeded or Failed"
Jul  2 12:26:16.083: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-subpath-test-configmap-88tm container test-container-subpath-configmap-88tm: <nil>
STEP: delete the pod
Jul  2 12:26:16.105: INFO: Waiting for pod pod-subpath-test-configmap-88tm to disappear
Jul  2 12:26:16.108: INFO: Pod pod-subpath-test-configmap-88tm no longer exists
STEP: Deleting pod pod-subpath-test-configmap-88tm
Jul  2 12:26:16.108: INFO: Deleting pod "pod-subpath-test-configmap-88tm" in namespace "subpath-2253"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  2 12:26:16.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2253" for this suite.

• [SLOW TEST:24.297 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","total":356,"completed":122,"skipped":2328,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:26:16.124: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2275
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:26:16.318: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689" in namespace "projected-2275" to be "Succeeded or Failed"
Jul  2 12:26:16.325: INFO: Pod "downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689": Phase="Pending", Reason="", readiness=false. Elapsed: 6.84783ms
Jul  2 12:26:18.334: INFO: Pod "downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016030862s
Jul  2 12:26:20.344: INFO: Pod "downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025960832s
STEP: Saw pod success
Jul  2 12:26:20.344: INFO: Pod "downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689" satisfied condition "Succeeded or Failed"
Jul  2 12:26:20.348: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689 container client-container: <nil>
STEP: delete the pod
Jul  2 12:26:20.374: INFO: Waiting for pod downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689 to disappear
Jul  2 12:26:20.377: INFO: Pod downwardapi-volume-e4e0edb1-a479-462a-896c-9ddf5b344689 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:26:20.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2275" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":123,"skipped":2341,"failed":0}
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:26:20.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3246
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-72707895-80c9-40b1-b133-98d3d6869ad4
STEP: Creating a pod to test consume configMaps
Jul  2 12:26:20.538: INFO: Waiting up to 5m0s for pod "pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33" in namespace "configmap-3246" to be "Succeeded or Failed"
Jul  2 12:26:20.543: INFO: Pod "pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33": Phase="Pending", Reason="", readiness=false. Elapsed: 5.580407ms
Jul  2 12:26:22.550: INFO: Pod "pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012358359s
Jul  2 12:26:24.559: INFO: Pod "pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021070296s
STEP: Saw pod success
Jul  2 12:26:24.559: INFO: Pod "pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33" satisfied condition "Succeeded or Failed"
Jul  2 12:26:24.564: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:26:24.586: INFO: Waiting for pod pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33 to disappear
Jul  2 12:26:24.589: INFO: Pod pod-configmaps-09aec31f-8094-428c-b718-d7d71f484e33 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:26:24.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3246" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":124,"skipped":2345,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:26:24.602: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1774
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1774
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Jul  2 12:26:24.760: INFO: Found 0 stateful pods, waiting for 3
Jul  2 12:26:34.771: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:26:34.771: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:26:34.771: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Jul  2 12:26:34.806: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jul  2 12:26:44.855: INFO: Updating stateful set ss2
Jul  2 12:26:44.864: INFO: Waiting for Pod statefulset-1774/ss2-2 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
STEP: Restoring Pods to the correct revision when they are deleted
Jul  2 12:26:54.933: INFO: Found 2 stateful pods, waiting for 3
Jul  2 12:27:04.944: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:27:04.944: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:27:04.944: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jul  2 12:27:04.976: INFO: Updating stateful set ss2
Jul  2 12:27:04.986: INFO: Waiting for Pod statefulset-1774/ss2-1 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
Jul  2 12:27:15.025: INFO: Updating stateful set ss2
Jul  2 12:27:15.038: INFO: Waiting for StatefulSet statefulset-1774/ss2 to complete update
Jul  2 12:27:15.038: INFO: Waiting for Pod statefulset-1774/ss2-0 to have revision ss2-5f8764d585 update revision ss2-57bbdd95cb
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 12:27:25.057: INFO: Deleting all statefulset in ns statefulset-1774
Jul  2 12:27:25.060: INFO: Scaling statefulset ss2 to 0
Jul  2 12:27:35.087: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:27:35.092: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 12:27:35.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1774" for this suite.

• [SLOW TEST:70.530 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":356,"completed":125,"skipped":2352,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:27:35.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8942
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name projected-secret-test-7cdb3566-fd50-4df7-bc28-19b475d937dd
STEP: Creating a pod to test consume secrets
Jul  2 12:27:35.280: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011" in namespace "projected-8942" to be "Succeeded or Failed"
Jul  2 12:27:35.286: INFO: Pod "pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011": Phase="Pending", Reason="", readiness=false. Elapsed: 5.585939ms
Jul  2 12:27:37.291: INFO: Pod "pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011375564s
Jul  2 12:27:39.297: INFO: Pod "pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016865851s
STEP: Saw pod success
Jul  2 12:27:39.297: INFO: Pod "pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011" satisfied condition "Succeeded or Failed"
Jul  2 12:27:39.302: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011 container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:27:39.324: INFO: Waiting for pod pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011 to disappear
Jul  2 12:27:39.328: INFO: Pod pod-projected-secrets-9cf18343-32e9-4d28-adb6-5f82cf85d011 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  2 12:27:39.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8942" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":356,"completed":126,"skipped":2368,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:27:39.339: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2111
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jul  2 12:27:39.516: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2111  98a86970-de5b-41e9-96b1-6cad796e7c7f 13925 0 2022-07-02 12:27:39 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-07-02 12:27:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 12:27:39.517: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2111  98a86970-de5b-41e9-96b1-6cad796e7c7f 13926 0 2022-07-02 12:27:39 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2022-07-02 12:27:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  2 12:27:39.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2111" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":356,"completed":127,"skipped":2405,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:27:39.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-526
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:27:47.709: INFO: DNS probes using dns-526/dns-test-91f37f69-40ea-4c6d-b8c3-3ee8e264f811 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 12:27:47.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-526" for this suite.

• [SLOW TEST:8.208 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":356,"completed":128,"skipped":2413,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:27:47.737: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5442
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0702 12:27:48.542324      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul  2 12:27:48.542: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  2 12:27:48.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5442" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":356,"completed":129,"skipped":2426,"failed":0}
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:27:48.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-252
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-252
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  2 12:27:48.690: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  2 12:27:48.732: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:27:50.738: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:27:52.745: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:27:54.739: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:27:56.742: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:27:58.741: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:28:00.739: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  2 12:28:00.747: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  2 12:28:00.755: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  2 12:28:02.787: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  2 12:28:02.787: INFO: Breadth first check of 192.168.74.189 on host 172.31.69.95...
Jul  2 12:28:02.790: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.231.50:9080/dial?request=hostname&protocol=http&host=192.168.74.189&port=8083&tries=1'] Namespace:pod-network-test-252 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:28:02.790: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:28:02.791: INFO: ExecWithOptions: Clientset creation
Jul  2 12:28:02.791: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-252/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.231.50%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.74.189%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  2 12:28:02.883: INFO: Waiting for responses: map[]
Jul  2 12:28:02.883: INFO: reached 192.168.74.189 after 0/1 tries
Jul  2 12:28:02.883: INFO: Breadth first check of 192.168.231.49 on host 172.31.9.92...
Jul  2 12:28:02.888: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.231.50:9080/dial?request=hostname&protocol=http&host=192.168.231.49&port=8083&tries=1'] Namespace:pod-network-test-252 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:28:02.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:28:02.889: INFO: ExecWithOptions: Clientset creation
Jul  2 12:28:02.889: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-252/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.231.50%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.231.49%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  2 12:28:02.986: INFO: Waiting for responses: map[]
Jul  2 12:28:02.986: INFO: reached 192.168.231.49 after 0/1 tries
Jul  2 12:28:02.986: INFO: Breadth first check of 192.168.64.162 on host 172.31.91.232...
Jul  2 12:28:02.992: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.231.50:9080/dial?request=hostname&protocol=http&host=192.168.64.162&port=8083&tries=1'] Namespace:pod-network-test-252 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:28:02.992: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:28:02.992: INFO: ExecWithOptions: Clientset creation
Jul  2 12:28:02.992: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-252/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.231.50%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.64.162%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  2 12:28:03.058: INFO: Waiting for responses: map[]
Jul  2 12:28:03.058: INFO: reached 192.168.64.162 after 0/1 tries
Jul  2 12:28:03.058: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  2 12:28:03.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-252" for this suite.

• [SLOW TEST:14.517 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":356,"completed":130,"skipped":2428,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:28:03.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5632
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  2 12:28:03.225: INFO: The status of Pod annotationupdate4ac86376-5e1d-44a5-a50a-fdf343a3452c is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:28:05.238: INFO: The status of Pod annotationupdate4ac86376-5e1d-44a5-a50a-fdf343a3452c is Running (Ready = true)
Jul  2 12:28:05.778: INFO: Successfully updated pod "annotationupdate4ac86376-5e1d-44a5-a50a-fdf343a3452c"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:28:09.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5632" for this suite.

• [SLOW TEST:6.747 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":131,"skipped":2472,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:28:09.821: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6716
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-4547435d-be82-448e-8c6a-1ab7b1143e47
STEP: Creating a pod to test consume configMaps
Jul  2 12:28:09.971: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657" in namespace "projected-6716" to be "Succeeded or Failed"
Jul  2 12:28:09.975: INFO: Pod "pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657": Phase="Pending", Reason="", readiness=false. Elapsed: 3.514229ms
Jul  2 12:28:11.983: INFO: Pod "pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011644786s
Jul  2 12:28:13.989: INFO: Pod "pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018074692s
STEP: Saw pod success
Jul  2 12:28:13.989: INFO: Pod "pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657" satisfied condition "Succeeded or Failed"
Jul  2 12:28:13.995: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jul  2 12:28:14.016: INFO: Waiting for pod pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657 to disappear
Jul  2 12:28:14.021: INFO: Pod pod-projected-configmaps-9b736ff4-1395-4f4c-b8b3-3ee086841657 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 12:28:14.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6716" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":132,"skipped":2496,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:28:14.033: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5734
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1412
STEP: creating an pod
Jul  2 12:28:14.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 run logs-generator --image=k8s.gcr.io/e2e-test-images/agnhost:2.39 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Jul  2 12:28:14.255: INFO: stderr: ""
Jul  2 12:28:14.255: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for log generator to start.
Jul  2 12:28:14.255: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Jul  2 12:28:14.255: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-5734" to be "running and ready, or succeeded"
Jul  2 12:28:14.260: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.49947ms
Jul  2 12:28:16.267: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.012365732s
Jul  2 12:28:16.267: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Jul  2 12:28:16.267: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Jul  2 12:28:16.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 logs logs-generator logs-generator'
Jul  2 12:28:16.333: INFO: stderr: ""
Jul  2 12:28:16.333: INFO: stdout: "I0702 12:28:15.080893       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/9rks 494\nI0702 12:28:15.280987       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/wqps 487\nI0702 12:28:15.481903       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/7ds 486\nI0702 12:28:15.681189       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/44z 218\nI0702 12:28:15.881481       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/fgk 531\nI0702 12:28:16.081768       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/6dph 301\nI0702 12:28:16.280965       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/zhg 531\n"
STEP: limiting log lines
Jul  2 12:28:16.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 logs logs-generator logs-generator --tail=1'
Jul  2 12:28:16.395: INFO: stderr: ""
Jul  2 12:28:16.395: INFO: stdout: "I0702 12:28:16.280965       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/zhg 531\n"
Jul  2 12:28:16.395: INFO: got output "I0702 12:28:16.280965       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/zhg 531\n"
STEP: limiting log bytes
Jul  2 12:28:16.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 logs logs-generator logs-generator --limit-bytes=1'
Jul  2 12:28:16.482: INFO: stderr: ""
Jul  2 12:28:16.482: INFO: stdout: "I"
Jul  2 12:28:16.482: INFO: got output "I"
STEP: exposing timestamps
Jul  2 12:28:16.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 logs logs-generator logs-generator --tail=1 --timestamps'
Jul  2 12:28:16.544: INFO: stderr: ""
Jul  2 12:28:16.544: INFO: stdout: "2022-07-02T12:28:16.481479749Z I0702 12:28:16.481290       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/qkx 453\n"
Jul  2 12:28:16.544: INFO: got output "2022-07-02T12:28:16.481479749Z I0702 12:28:16.481290       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/qkx 453\n"
STEP: restricting to a time range
Jul  2 12:28:19.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 logs logs-generator logs-generator --since=1s'
Jul  2 12:28:19.114: INFO: stderr: ""
Jul  2 12:28:19.114: INFO: stdout: "I0702 12:28:18.281804       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/76k4 251\nI0702 12:28:18.480988       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/t8r 246\nI0702 12:28:18.681267       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/cllv 414\nI0702 12:28:18.881556       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/8td 334\nI0702 12:28:19.081845       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/klm7 204\n"
Jul  2 12:28:19.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 logs logs-generator logs-generator --since=24h'
Jul  2 12:28:19.183: INFO: stderr: ""
Jul  2 12:28:19.183: INFO: stdout: "I0702 12:28:15.080893       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/9rks 494\nI0702 12:28:15.280987       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/wqps 487\nI0702 12:28:15.481903       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/7ds 486\nI0702 12:28:15.681189       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/44z 218\nI0702 12:28:15.881481       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/fgk 531\nI0702 12:28:16.081768       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/6dph 301\nI0702 12:28:16.280965       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/zhg 531\nI0702 12:28:16.481290       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/qkx 453\nI0702 12:28:16.681561       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/p2f9 539\nI0702 12:28:16.881847       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/pnp 246\nI0702 12:28:17.081075       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/vkpn 421\nI0702 12:28:17.281361       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/wq88 425\nI0702 12:28:17.481652       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/ldfq 361\nI0702 12:28:17.681939       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/4r27 533\nI0702 12:28:17.881226       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/8n74 596\nI0702 12:28:18.081515       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/lsln 471\nI0702 12:28:18.281804       1 logs_generator.go:76] 16 POST /api/v1/namespaces/kube-system/pods/76k4 251\nI0702 12:28:18.480988       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/t8r 246\nI0702 12:28:18.681267       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/cllv 414\nI0702 12:28:18.881556       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/8td 334\nI0702 12:28:19.081845       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/klm7 204\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1417
Jul  2 12:28:19.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5734 delete pod logs-generator'
Jul  2 12:28:20.221: INFO: stderr: ""
Jul  2 12:28:20.221: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:28:20.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5734" for this suite.

• [SLOW TEST:6.204 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1409
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":356,"completed":133,"skipped":2509,"failed":0}
SSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin] 
  should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:28:20.237: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename certificates
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in certificates-8399
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CSR API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/certificates.k8s.io
STEP: getting /apis/certificates.k8s.io/v1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  2 12:28:21.091: INFO: starting watch
STEP: patching
STEP: updating
Jul  2 12:28:21.106: INFO: waiting for watch events with expected annotations
Jul  2 12:28:21.106: INFO: saw patched and updated annotations
STEP: getting /approval
STEP: patching /approval
STEP: updating /approval
STEP: getting /status
STEP: patching /status
STEP: updating /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:28:21.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-8399" for this suite.
•{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","total":356,"completed":134,"skipped":2516,"failed":0}

------------------------------
[sig-storage] ConfigMap 
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:28:21.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9356
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:28:21.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9356" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","total":356,"completed":135,"skipped":2516,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:28:21.386: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8949
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-7b37aca6-96d7-4102-a60f-4ac0d72ae9b6
STEP: Creating a pod to test consume configMaps
Jul  2 12:28:21.542: INFO: Waiting up to 5m0s for pod "pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba" in namespace "configmap-8949" to be "Succeeded or Failed"
Jul  2 12:28:21.546: INFO: Pod "pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.36841ms
Jul  2 12:28:23.552: INFO: Pod "pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010024455s
Jul  2 12:28:25.559: INFO: Pod "pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017280588s
STEP: Saw pod success
Jul  2 12:28:25.559: INFO: Pod "pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba" satisfied condition "Succeeded or Failed"
Jul  2 12:28:25.564: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:28:25.586: INFO: Waiting for pod pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba to disappear
Jul  2 12:28:25.590: INFO: Pod pod-configmaps-fc29e108-0b26-44a1-ad98-76311f494bba no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:28:25.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8949" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":136,"skipped":2527,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:28:25.601: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2353
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-2353
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a new StatefulSet
Jul  2 12:28:25.759: INFO: Found 0 stateful pods, waiting for 3
Jul  2 12:28:35.765: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:28:35.765: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:28:35.765: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:28:35.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-2353 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:28:35.975: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:28:35.975: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:28:35.975: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 to k8s.gcr.io/e2e-test-images/httpd:2.4.39-2
Jul  2 12:28:46.030: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jul  2 12:28:56.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-2353 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:28:56.215: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  2 12:28:56.215: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:28:56.215: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Jul  2 12:29:06.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-2353 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:29:06.414: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:29:06.414: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:29:06.414: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:29:16.460: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jul  2 12:29:26.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-2353 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:29:26.638: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  2 12:29:26.638: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:29:26.638: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 12:29:36.696: INFO: Deleting all statefulset in ns statefulset-2353
Jul  2 12:29:36.703: INFO: Scaling statefulset ss2 to 0
Jul  2 12:29:46.726: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:29:46.730: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 12:29:46.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2353" for this suite.

• [SLOW TEST:81.177 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":356,"completed":137,"skipped":2537,"failed":0}
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:29:46.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sysctl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sysctl-8194
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl
STEP: Watching for error events or started pod
STEP: Waiting for pod completion
STEP: Checking that the pod succeeded
STEP: Getting logs from the pod
STEP: Checking that the sysctl is actually updated
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  2 12:29:50.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8194" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":138,"skipped":2537,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:29:50.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-936
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:29:51.103: INFO: Creating ReplicaSet my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1
Jul  2 12:29:51.116: INFO: Pod name my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1: Found 0 pods out of 1
Jul  2 12:29:56.123: INFO: Pod name my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1: Found 1 pods out of 1
Jul  2 12:29:56.123: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1" is running
Jul  2 12:29:56.128: INFO: Pod "my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1-7sn4m" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:29:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:29:52 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:29:52 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:29:51 +0000 UTC Reason: Message:}])
Jul  2 12:29:56.128: INFO: Trying to dial the pod
Jul  2 12:30:01.145: INFO: Controller my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1: Got expected result from replica 1 [my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1-7sn4m]: "my-hostname-basic-7c118110-4374-4c73-959e-39ece65cdaf1-7sn4m", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  2 12:30:01.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-936" for this suite.

• [SLOW TEST:10.187 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":139,"skipped":2541,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:30:01.158: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3688
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:30:01.682: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:30:04.717: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:30:16.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3688" for this suite.
STEP: Destroying namespace "webhook-3688-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:15.812 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":356,"completed":140,"skipped":2546,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:30:16.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8310
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:30:17.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6" in namespace "downward-api-8310" to be "Succeeded or Failed"
Jul  2 12:30:17.142: INFO: Pod "downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.237804ms
Jul  2 12:30:19.147: INFO: Pod "downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010487382s
Jul  2 12:30:21.153: INFO: Pod "downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016659976s
STEP: Saw pod success
Jul  2 12:30:21.153: INFO: Pod "downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6" satisfied condition "Succeeded or Failed"
Jul  2 12:30:21.158: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6 container client-container: <nil>
STEP: delete the pod
Jul  2 12:30:21.183: INFO: Waiting for pod downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6 to disappear
Jul  2 12:30:21.188: INFO: Pod downwardapi-volume-1b7de580-aa5f-4db9-aae9-7197ecc1c8c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 12:30:21.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8310" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":141,"skipped":2557,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:30:21.210: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1402
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-ee18c507-d3eb-4631-bada-180ad6e95e8a
STEP: Creating a pod to test consume secrets
Jul  2 12:30:21.370: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705" in namespace "projected-1402" to be "Succeeded or Failed"
Jul  2 12:30:21.375: INFO: Pod "pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705": Phase="Pending", Reason="", readiness=false. Elapsed: 4.951094ms
Jul  2 12:30:23.380: INFO: Pod "pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00961266s
Jul  2 12:30:25.389: INFO: Pod "pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018545831s
STEP: Saw pod success
Jul  2 12:30:25.389: INFO: Pod "pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705" satisfied condition "Succeeded or Failed"
Jul  2 12:30:25.394: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:30:25.425: INFO: Waiting for pod pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705 to disappear
Jul  2 12:30:25.429: INFO: Pod pod-projected-secrets-fca3faf5-f99d-46ed-b923-feecbf8fb705 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  2 12:30:25.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1402" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":142,"skipped":2580,"failed":0}
SSSSS
------------------------------
[sig-node] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:30:25.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5769
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:30:25.591: INFO: The status of Pod server-envvars-4cf80cbc-6827-4686-ad7c-3523438ea6a3 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:30:27.598: INFO: The status of Pod server-envvars-4cf80cbc-6827-4686-ad7c-3523438ea6a3 is Running (Ready = true)
Jul  2 12:30:27.628: INFO: Waiting up to 5m0s for pod "client-envvars-664716a5-db60-485a-bea1-61c73d151da6" in namespace "pods-5769" to be "Succeeded or Failed"
Jul  2 12:30:27.637: INFO: Pod "client-envvars-664716a5-db60-485a-bea1-61c73d151da6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.801605ms
Jul  2 12:30:29.645: INFO: Pod "client-envvars-664716a5-db60-485a-bea1-61c73d151da6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016918946s
Jul  2 12:30:31.652: INFO: Pod "client-envvars-664716a5-db60-485a-bea1-61c73d151da6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02395379s
STEP: Saw pod success
Jul  2 12:30:31.652: INFO: Pod "client-envvars-664716a5-db60-485a-bea1-61c73d151da6" satisfied condition "Succeeded or Failed"
Jul  2 12:30:31.656: INFO: Trying to get logs from node ip-172-31-69-95 pod client-envvars-664716a5-db60-485a-bea1-61c73d151da6 container env3cont: <nil>
STEP: delete the pod
Jul  2 12:30:31.688: INFO: Waiting for pod client-envvars-664716a5-db60-485a-bea1-61c73d151da6 to disappear
Jul  2 12:30:31.694: INFO: Pod client-envvars-664716a5-db60-485a-bea1-61c73d151da6 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:30:31.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5769" for this suite.

• [SLOW TEST:6.261 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":356,"completed":143,"skipped":2585,"failed":0}
SS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:30:31.705: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-2067
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Jul  2 12:30:31.839: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  2 12:31:31.857: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:31:31.863: INFO: Starting informer...
STEP: Starting pod...
Jul  2 12:31:32.083: INFO: Pod is running on ip-172-31-9-92. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Jul  2 12:31:32.100: INFO: Pod wasn't evicted. Proceeding
Jul  2 12:31:32.100: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Jul  2 12:32:47.121: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:32:47.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-2067" for this suite.

• [SLOW TEST:135.433 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":356,"completed":144,"skipped":2587,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:32:47.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4418
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on node default medium
Jul  2 12:32:47.280: INFO: Waiting up to 5m0s for pod "pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b" in namespace "emptydir-4418" to be "Succeeded or Failed"
Jul  2 12:32:47.286: INFO: Pod "pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.285306ms
Jul  2 12:32:49.293: INFO: Pod "pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012956295s
Jul  2 12:32:51.300: INFO: Pod "pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020268409s
STEP: Saw pod success
Jul  2 12:32:51.300: INFO: Pod "pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b" satisfied condition "Succeeded or Failed"
Jul  2 12:32:51.306: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b container test-container: <nil>
STEP: delete the pod
Jul  2 12:32:51.334: INFO: Waiting for pod pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b to disappear
Jul  2 12:32:51.338: INFO: Pod pod-69ddb2d2-17e1-4ba7-9387-9419accc4b9b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:32:51.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4418" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":145,"skipped":2588,"failed":0}

------------------------------
[sig-network] EndpointSliceMirroring 
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:32:51.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename endpointslicemirroring
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in endpointslicemirroring-2405
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/framework/framework.go:652
STEP: mirroring a new custom Endpoint
Jul  2 12:32:51.569: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint
STEP: mirroring deletion of a custom Endpoint
Jul  2 12:32:53.611: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:188
Jul  2 12:32:55.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-2405" for this suite.
•{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","total":356,"completed":146,"skipped":2588,"failed":0}
S
------------------------------
[sig-auth] ServiceAccounts 
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:32:55.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9433
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:32:55.783: INFO: created pod
Jul  2 12:32:55.783: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-9433" to be "Succeeded or Failed"
Jul  2 12:32:55.790: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.364171ms
Jul  2 12:32:57.796: INFO: Pod "oidc-discovery-validator": Phase="Running", Reason="", readiness=false. Elapsed: 2.012862534s
Jul  2 12:32:59.803: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019904384s
STEP: Saw pod success
Jul  2 12:32:59.803: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Jul  2 12:33:29.803: INFO: polling logs
Jul  2 12:33:29.828: INFO: Pod logs: 
I0702 12:32:56.599513       1 log.go:195] OK: Got token
I0702 12:32:56.599539       1 log.go:195] validating with in-cluster discovery
I0702 12:32:56.599966       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I0702 12:32:56.599993       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-9433:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1656765775, NotBefore:1656765175, IssuedAt:1656765175, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9433", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"89c98f08-d704-48f5-adc6-0da87b5a49f6"}}}
I0702 12:32:56.613203       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I0702 12:32:56.618914       1 log.go:195] OK: Validated signature on JWT
I0702 12:32:56.619029       1 log.go:195] OK: Got valid claims from token!
I0702 12:32:56.619054       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-9433:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1656765775, NotBefore:1656765175, IssuedAt:1656765175, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-9433", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"89c98f08-d704-48f5-adc6-0da87b5a49f6"}}}

Jul  2 12:33:29.828: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  2 12:33:29.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9433" for this suite.

• [SLOW TEST:34.221 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","total":356,"completed":147,"skipped":2589,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Ingress API 
  should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:29.853: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename ingress
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in ingress-5129
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support creating Ingress API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  2 12:33:30.046: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Jul  2 12:33:30.051: INFO: starting watch
STEP: patching
STEP: updating
Jul  2 12:33:30.077: INFO: waiting for watch events with expected annotations
Jul  2 12:33:30.077: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:188
Jul  2 12:33:30.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-5129" for this suite.
•{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","total":356,"completed":148,"skipped":2600,"failed":0}
SSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:30.182: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename endpointslice
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in endpointslice-9565
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/discovery.k8s.io
STEP: getting /apis/discovery.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  2 12:33:30.353: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Jul  2 12:33:30.358: INFO: starting watch
STEP: patching
STEP: updating
Jul  2 12:33:30.375: INFO: waiting for watch events with expected annotations
Jul  2 12:33:30.375: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  2 12:33:30.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9565" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","total":356,"completed":149,"skipped":2608,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:30.427: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-303
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:33:30.854: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:33:33.892: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:33:34.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-303" for this suite.
STEP: Destroying namespace "webhook-303-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":356,"completed":150,"skipped":2633,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:34.226: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2492
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption-release is created
Jul  2 12:33:34.388: INFO: The status of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:33:36.395: INFO: The status of Pod pod-adoption-release is Running (Ready = true)
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jul  2 12:33:37.419: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  2 12:33:38.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2492" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":356,"completed":151,"skipped":2648,"failed":0}
SSSSSS
------------------------------
[sig-node] Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:38.461: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7134
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  2 12:33:40.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7134" for this suite.
•{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":356,"completed":152,"skipped":2654,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:40.646: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5654
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-9502f1c7-e99f-4278-8f4d-029efe40ca7a
STEP: Creating a pod to test consume secrets
Jul  2 12:33:40.798: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3" in namespace "projected-5654" to be "Succeeded or Failed"
Jul  2 12:33:40.805: INFO: Pod "pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.15648ms
Jul  2 12:33:42.812: INFO: Pod "pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013802413s
Jul  2 12:33:44.819: INFO: Pod "pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020727466s
STEP: Saw pod success
Jul  2 12:33:44.819: INFO: Pod "pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3" satisfied condition "Succeeded or Failed"
Jul  2 12:33:44.824: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  2 12:33:44.845: INFO: Waiting for pod pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3 to disappear
Jul  2 12:33:44.849: INFO: Pod pod-projected-secrets-4f96b9bc-2e85-4304-9123-1fb31da6aec3 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  2 12:33:44.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5654" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":153,"skipped":2668,"failed":0}
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:44.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-864
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-864
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  2 12:33:45.003: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  2 12:33:45.046: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:33:47.055: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:33:49.053: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:33:51.053: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:33:53.053: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:33:55.052: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 12:33:57.052: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  2 12:33:57.062: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  2 12:33:57.070: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  2 12:33:59.099: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  2 12:33:59.099: INFO: Breadth first check of 192.168.74.135 on host 172.31.69.95...
Jul  2 12:33:59.104: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.231.8:9080/dial?request=hostname&protocol=udp&host=192.168.74.135&port=8081&tries=1'] Namespace:pod-network-test-864 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:33:59.104: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:33:59.104: INFO: ExecWithOptions: Clientset creation
Jul  2 12:33:59.104: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-864/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.231.8%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.74.135%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  2 12:33:59.193: INFO: Waiting for responses: map[]
Jul  2 12:33:59.193: INFO: reached 192.168.74.135 after 0/1 tries
Jul  2 12:33:59.193: INFO: Breadth first check of 192.168.231.5 on host 172.31.9.92...
Jul  2 12:33:59.197: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.231.8:9080/dial?request=hostname&protocol=udp&host=192.168.231.5&port=8081&tries=1'] Namespace:pod-network-test-864 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:33:59.197: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:33:59.198: INFO: ExecWithOptions: Clientset creation
Jul  2 12:33:59.198: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-864/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.231.8%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.231.5%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  2 12:33:59.264: INFO: Waiting for responses: map[]
Jul  2 12:33:59.264: INFO: reached 192.168.231.5 after 0/1 tries
Jul  2 12:33:59.264: INFO: Breadth first check of 192.168.64.166 on host 172.31.91.232...
Jul  2 12:33:59.269: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.231.8:9080/dial?request=hostname&protocol=udp&host=192.168.64.166&port=8081&tries=1'] Namespace:pod-network-test-864 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:33:59.269: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:33:59.270: INFO: ExecWithOptions: Clientset creation
Jul  2 12:33:59.270: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-864/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.231.8%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.64.166%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Jul  2 12:33:59.341: INFO: Waiting for responses: map[]
Jul  2 12:33:59.341: INFO: reached 192.168.64.166 after 0/1 tries
Jul  2 12:33:59.341: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  2 12:33:59.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-864" for this suite.

• [SLOW TEST:14.493 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":356,"completed":154,"skipped":2670,"failed":0}
SSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:59.357: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4884
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:188
Jul  2 12:33:59.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4884" for this suite.
•{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":356,"completed":155,"skipped":2677,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:33:59.526: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3001
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-map-b96736f0-73ae-4681-9b6d-bf08d77fd9ae
STEP: Creating a pod to test consume configMaps
Jul  2 12:33:59.670: INFO: Waiting up to 5m0s for pod "pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170" in namespace "configmap-3001" to be "Succeeded or Failed"
Jul  2 12:33:59.678: INFO: Pod "pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170": Phase="Pending", Reason="", readiness=false. Elapsed: 8.932059ms
Jul  2 12:34:01.686: INFO: Pod "pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016311478s
Jul  2 12:34:03.696: INFO: Pod "pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026274551s
STEP: Saw pod success
Jul  2 12:34:03.696: INFO: Pod "pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170" satisfied condition "Succeeded or Failed"
Jul  2 12:34:03.699: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:34:03.726: INFO: Waiting for pod pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170 to disappear
Jul  2 12:34:03.730: INFO: Pod pod-configmaps-127d0998-1735-46aa-8f2d-443d302c0170 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:34:03.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3001" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":156,"skipped":2691,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:03.743: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6209
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir volume type on node default medium
Jul  2 12:34:03.953: INFO: Waiting up to 5m0s for pod "pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb" in namespace "emptydir-6209" to be "Succeeded or Failed"
Jul  2 12:34:03.956: INFO: Pod "pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.659924ms
Jul  2 12:34:05.964: INFO: Pod "pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011533656s
Jul  2 12:34:07.972: INFO: Pod "pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019262348s
STEP: Saw pod success
Jul  2 12:34:07.972: INFO: Pod "pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb" satisfied condition "Succeeded or Failed"
Jul  2 12:34:07.978: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb container test-container: <nil>
STEP: delete the pod
Jul  2 12:34:08.004: INFO: Waiting for pod pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb to disappear
Jul  2 12:34:08.009: INFO: Pod pod-20556e40-ca0e-445f-a73f-cf11fdba0ebb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:34:08.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6209" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":157,"skipped":2696,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:08.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3883
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Deployment
STEP: waiting for Deployment to be created
STEP: waiting for all Replicas to be Ready
Jul  2 12:34:08.186: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:08.186: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:08.197: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:08.197: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:08.231: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:08.231: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:08.256: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:08.256: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Jul  2 12:34:09.799: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jul  2 12:34:09.799: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Jul  2 12:34:09.813: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment
Jul  2 12:34:09.834: INFO: observed event type ADDED
STEP: waiting for Replicas to scale
Jul  2 12:34:09.836: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.836: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.836: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 0
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.837: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.846: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.847: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.875: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.875: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:09.939: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:09.939: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:09.969: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:09.970: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:10.846: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:10.846: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:10.874: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
STEP: listing Deployments
Jul  2 12:34:10.885: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment
Jul  2 12:34:10.902: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
STEP: fetching the DeploymentStatus
Jul  2 12:34:10.917: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:10.917: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:10.947: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:10.989: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:11.004: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:11.818: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:11.836: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:11.873: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:11.928: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Jul  2 12:34:12.825: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus
STEP: fetching the DeploymentStatus
Jul  2 12:34:12.955: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 1
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 3
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 2
Jul  2 12:34:12.956: INFO: observed Deployment test-deployment in namespace deployment-3883 with ReadyReplicas 3
STEP: deleting the Deployment
Jul  2 12:34:12.983: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
Jul  2 12:34:12.984: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:34:13.020: INFO: Log out all the ReplicaSets if there is no deployment created
Jul  2 12:34:13.031: INFO: ReplicaSet "test-deployment-6b48c869b6":
&ReplicaSet{ObjectMeta:{test-deployment-6b48c869b6  deployment-3883  2c896150-8012-4440-87ce-fb593455e36f 16655 3 2022-07-02 12:34:08 +0000 UTC <nil> <nil> map[pod-template-hash:6b48c869b6 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 7fa44b28-b7f5-4fc1-a4c1-367dc4555f59 0xc0039ea7a7 0xc0039ea7a8}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:34:08 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7fa44b28-b7f5-4fc1-a4c1-367dc4555f59\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:34:10 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 6b48c869b6,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:6b48c869b6 test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039ea830 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Jul  2 12:34:13.045: INFO: ReplicaSet "test-deployment-74c6dd549b":
&ReplicaSet{ObjectMeta:{test-deployment-74c6dd549b  deployment-3883  b37836fc-d7a7-4802-ae4e-9a1cde13d745 16734 2 2022-07-02 12:34:10 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 7fa44b28-b7f5-4fc1-a4c1-367dc4555f59 0xc0039ea897 0xc0039ea898}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:34:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7fa44b28-b7f5-4fc1-a4c1-367dc4555f59\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:34:11 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 74c6dd549b,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039ea920 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Jul  2 12:34:13.052: INFO: pod: "test-deployment-74c6dd549b-8fpl9":
&Pod{ObjectMeta:{test-deployment-74c6dd549b-8fpl9 test-deployment-74c6dd549b- deployment-3883  3d784559-0707-45bb-be17-ac7ff9debbf9 16732 0 2022-07-02 12:34:11 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-deployment-74c6dd549b b37836fc-d7a7-4802-ae4e-9a1cde13d745 0xc0039eacc7 0xc0039eacc8}] []  [{kube-controller-manager Update v1 2022-07-02 12:34:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b37836fc-d7a7-4802-ae4e-9a1cde13d745\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:34:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-b6dqt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-b6dqt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.11,StartTime:2022-07-02 12:34:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:34:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3e091c18c87c39a4fd7335557683889520a15a8c5edf1543fb00d69acfa45abd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul  2 12:34:13.052: INFO: pod: "test-deployment-74c6dd549b-m92wh":
&Pod{ObjectMeta:{test-deployment-74c6dd549b-m92wh test-deployment-74c6dd549b- deployment-3883  f1b1d633-6054-4593-a290-156a2778d2e9 16695 0 2022-07-02 12:34:10 +0000 UTC <nil> <nil> map[pod-template-hash:74c6dd549b test-deployment-static:true] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-deployment-74c6dd549b b37836fc-d7a7-4802-ae4e-9a1cde13d745 0xc0039eaeb7 0xc0039eaeb8}] []  [{kube-controller-manager Update v1 2022-07-02 12:34:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b37836fc-d7a7-4802-ae4e-9a1cde13d745\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:34:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.137\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6l2cl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6l2cl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.137,StartTime:2022-07-02 12:34:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:34:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://3fd214fe904ba969ea24dde3525bdc2244ff7f592dbd3622ddf632309f7b9574,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.137,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul  2 12:34:13.052: INFO: ReplicaSet "test-deployment-84b949bdfc":
&ReplicaSet{ObjectMeta:{test-deployment-84b949bdfc  deployment-3883  1385875e-0649-4389-87cd-ed02b18e076b 16747 4 2022-07-02 12:34:09 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-deployment 7fa44b28-b7f5-4fc1-a4c1-367dc4555f59 0xc0039ea987 0xc0039ea988}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:34:09 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7fa44b28-b7f5-4fc1-a4c1-367dc4555f59\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:34:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 84b949bdfc,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:84b949bdfc test-deployment-static:true] map[] [] []  []} {[] [] [{test-deployment k8s.gcr.io/pause:3.7 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039eaa10 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:4,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

Jul  2 12:34:13.063: INFO: pod: "test-deployment-84b949bdfc-7mt9p":
&Pod{ObjectMeta:{test-deployment-84b949bdfc-7mt9p test-deployment-84b949bdfc- deployment-3883  6bc3f7ee-bb3c-425e-b009-0e7afdbb5794 16702 0 2022-07-02 12:34:09 +0000 UTC 2022-07-02 12:34:12 +0000 UTC 0xc004211b38 map[pod-template-hash:84b949bdfc test-deployment-static:true] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-deployment-84b949bdfc 1385875e-0649-4389-87cd-ed02b18e076b 0xc004211b67 0xc004211b68}] []  [{kube-controller-manager Update v1 2022-07-02 12:34:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1385875e-0649-4389-87cd-ed02b18e076b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:34:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.140\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gk4ft,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.7,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gk4ft,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.140,StartTime:2022-07-02 12:34:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:34:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.7,ImageID:k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c,ContainerID:containerd://1059089206545965facddf60329acf46aff252ad957176fc59a7bdf663c2cd9e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.140,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Jul  2 12:34:13.064: INFO: pod: "test-deployment-84b949bdfc-nfx69":
&Pod{ObjectMeta:{test-deployment-84b949bdfc-nfx69 test-deployment-84b949bdfc- deployment-3883  c3c5b6b0-d7c6-428d-aa52-ab27e78ad0da 16741 0 2022-07-02 12:34:10 +0000 UTC 2022-07-02 12:34:13 +0000 UTC 0xc004211d30 map[pod-template-hash:84b949bdfc test-deployment-static:true] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-deployment-84b949bdfc 1385875e-0649-4389-87cd-ed02b18e076b 0xc004211d67 0xc004211d68}] []  [{kube-controller-manager Update v1 2022-07-02 12:34:10 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"1385875e-0649-4389-87cd-ed02b18e076b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:34:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.10\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-28xt8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:k8s.gcr.io/pause:3.7,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-28xt8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.10,StartTime:2022-07-02 12:34:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:34:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/pause:3.7,ImageID:k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c,ContainerID:containerd://b5a2d800b30aa9c99b0678e8ea7d32a6aa8aa2a23ccb0f38c05d0fb5d1242581,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.10,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:34:13.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3883" for this suite.

• [SLOW TEST:5.064 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","total":356,"completed":158,"skipped":2703,"failed":0}
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:13.088: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8302
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:34:13.254: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jul  2 12:34:18.261: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  2 12:34:18.261: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:34:20.312: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8302  ce8ff030-a702-4727-957e-a7d81442274e 16910 1 2022-07-02 12:34:18 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2022-07-02 12:34:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:34:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039a1a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-07-02 12:34:18 +0000 UTC,LastTransitionTime:2022-07-02 12:34:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-6755c7b765" has successfully progressed.,LastUpdateTime:2022-07-02 12:34:19 +0000 UTC,LastTransitionTime:2022-07-02 12:34:18 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  2 12:34:20.316: INFO: New ReplicaSet "test-cleanup-deployment-6755c7b765" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-6755c7b765  deployment-8302  bc4609dc-1796-4fed-9b77-74b0a8a196c8 16900 1 2022-07-02 12:34:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment ce8ff030-a702-4727-957e-a7d81442274e 0xc0039a1e07 0xc0039a1e08}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:34:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ce8ff030-a702-4727-957e-a7d81442274e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:34:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 6755c7b765,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0039a1eb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:34:20.320: INFO: Pod "test-cleanup-deployment-6755c7b765-zfkpf" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-6755c7b765-zfkpf test-cleanup-deployment-6755c7b765- deployment-8302  1b9d2b14-9f9e-47da-b8ef-b269dbdaaa72 16899 0 2022-07-02 12:34:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:6755c7b765] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-6755c7b765 bc4609dc-1796-4fed-9b77-74b0a8a196c8 0xc001024587 0xc001024588}] []  [{kube-controller-manager Update v1 2022-07-02 12:34:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"bc4609dc-1796-4fed-9b77-74b0a8a196c8\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:34:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.12\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x5222,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x5222,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:34:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.12,StartTime:2022-07-02 12:34:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:34:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://93a73de3f18b8df43794c393e86034aff43cb2288fe723c1993ae3144498a090,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.12,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:34:20.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8302" for this suite.

• [SLOW TEST:7.245 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":356,"completed":159,"skipped":2703,"failed":0}
SSSSSSS
------------------------------
[sig-instrumentation] Events API 
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:20.333: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1326
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
STEP: listing events with field selection filtering on source
STEP: listing events with field selection filtering on reportingController
STEP: getting the test event
STEP: patching the test event
STEP: getting the test event
STEP: updating the test event
STEP: getting the test event
STEP: deleting the test event
STEP: listing events in all namespaces
STEP: listing events in test namespace
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Jul  2 12:34:20.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1326" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","total":356,"completed":160,"skipped":2710,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:20.569: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3060
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 12:34:27.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3060" for this suite.

• [SLOW TEST:7.164 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":356,"completed":161,"skipped":2742,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:27.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7116
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:34:27.880: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99" in namespace "projected-7116" to be "Succeeded or Failed"
Jul  2 12:34:27.883: INFO: Pod "downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99": Phase="Pending", Reason="", readiness=false. Elapsed: 3.496866ms
Jul  2 12:34:29.891: INFO: Pod "downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011040032s
Jul  2 12:34:31.899: INFO: Pod "downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019622797s
STEP: Saw pod success
Jul  2 12:34:31.899: INFO: Pod "downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99" satisfied condition "Succeeded or Failed"
Jul  2 12:34:31.903: INFO: Trying to get logs from node ip-172-31-69-95 pod downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99 container client-container: <nil>
STEP: delete the pod
Jul  2 12:34:31.928: INFO: Waiting for pod downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99 to disappear
Jul  2 12:34:31.931: INFO: Pod downwardapi-volume-0477bcd8-a867-4492-be1d-64df4c2ced99 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:34:31.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7116" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":356,"completed":162,"skipped":2779,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces 
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:31.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename disruption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in disruption-4673
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:32.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename disruption-2
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in disruption-2-1790
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be processed
STEP: listing a collection of PDBs across all namespaces
STEP: listing a collection of PDBs in namespace disruption-4673
STEP: deleting a collection of PDBs
STEP: Waiting for the PDB collection to be deleted
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:188
Jul  2 12:34:38.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-1790" for this suite.
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  2 12:34:38.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4673" for this suite.

• [SLOW TEST:6.376 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","total":356,"completed":163,"skipped":2799,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:38.321: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1972
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-cafaa85d-ad07-4b93-9a21-9f8b178be9fd
STEP: Creating configMap with name cm-test-opt-upd-cf74fa6a-be46-47f3-bd56-4d6f0c3fb1c0
STEP: Creating the pod
Jul  2 12:34:38.492: INFO: The status of Pod pod-projected-configmaps-8e9352e1-ad48-4e4f-a992-05deb10aacd3 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:34:40.500: INFO: The status of Pod pod-projected-configmaps-8e9352e1-ad48-4e4f-a992-05deb10aacd3 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-cafaa85d-ad07-4b93-9a21-9f8b178be9fd
STEP: Updating configmap cm-test-opt-upd-cf74fa6a-be46-47f3-bd56-4d6f0c3fb1c0
STEP: Creating configMap with name cm-test-opt-create-39ee196a-84a4-447c-bc80-8b630a64eb0a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 12:34:42.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1972" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":164,"skipped":2809,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:42.602: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7601
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  2 12:34:42.737: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  2 12:34:42.747: INFO: Waiting for terminating namespaces to be deleted...
Jul  2 12:34:42.752: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-69-95 before test
Jul  2 12:34:42.759: INFO: nginx-ingress-controller-kubernetes-worker-7hv6n from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:21 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.759: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 12:34:42.759: INFO: pod-projected-configmaps-8e9352e1-ad48-4e4f-a992-05deb10aacd3 from projected-1972 started at 2022-07-02 12:34:38 +0000 UTC (3 container statuses recorded)
Jul  2 12:34:42.759: INFO: 	Container createcm-volume-test ready: true, restart count 0
Jul  2 12:34:42.759: INFO: 	Container delcm-volume-test ready: true, restart count 0
Jul  2 12:34:42.759: INFO: 	Container updcm-volume-test ready: true, restart count 0
Jul  2 12:34:42.759: INFO: sonobuoy-e2e-job-6916416ad43a4efe from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:34:42.759: INFO: 	Container e2e ready: true, restart count 0
Jul  2 12:34:42.759: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:34:42.759: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-z6zqf from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:34:42.759: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:34:42.759: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 12:34:42.759: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-9-92 before test
Jul  2 12:34:42.767: INFO: nginx-ingress-controller-kubernetes-worker-prprf from ingress-nginx-kubernetes-worker started at 2022-07-02 12:31:43 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.767: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 12:34:42.767: INFO: pod-qos-class-b309bfb6-2bc4-4891-bcee-c60ae498600f from pods-4884 started at 2022-07-02 12:33:59 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.767: INFO: 	Container agnhost ready: false, restart count 0
Jul  2 12:34:42.767: INFO: sonobuoy from sonobuoy started at 2022-07-02 11:53:23 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.767: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  2 12:34:42.767: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-x2r94 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:34:42.767: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:34:42.767: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 12:34:42.767: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-91-232 before test
Jul  2 12:34:42.777: INFO: default-http-backend-kubernetes-worker-6c59687bf6-gqrng from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 1
Jul  2 12:34:42.777: INFO: nginx-ingress-controller-kubernetes-worker-xvwtz from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 12:34:42.777: INFO: calico-kube-controllers-7f4ccc6cf4-qt6b5 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  2 12:34:42.777: INFO: coredns-86c98bfcdb-tftgb from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container coredns ready: true, restart count 0
Jul  2 12:34:42.777: INFO: kube-state-metrics-5cdbfd47b4-xkmd6 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jul  2 12:34:42.777: INFO: metrics-server-v0.5.2-6bfd958b56-2pqsv from kube-system started at 2022-07-02 11:49:20 +0000 UTC (2 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container metrics-server ready: true, restart count 0
Jul  2 12:34:42.777: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jul  2 12:34:42.777: INFO: dashboard-metrics-scraper-8669b59d4f-ftfm8 from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Jul  2 12:34:42.777: INFO: kubernetes-dashboard-585fc6bc87-ls4qj from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jul  2 12:34:42.777: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-4w8j4 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:34:42.777: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:34:42.777: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-7e0b5cb1-0329-42af-9d92-6fabc75238e8 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-7e0b5cb1-0329-42af-9d92-6fabc75238e8 off the node ip-172-31-9-92
STEP: verifying the node doesn't have the label kubernetes.io/e2e-7e0b5cb1-0329-42af-9d92-6fabc75238e8
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:34:46.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7601" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":356,"completed":165,"skipped":2825,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:46.902: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5969
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  2 12:34:47.055: INFO: The status of Pod labelsupdate68fc2aae-318a-4839-ba6c-cb4294ac4b70 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:34:49.061: INFO: The status of Pod labelsupdate68fc2aae-318a-4839-ba6c-cb4294ac4b70 is Running (Ready = true)
Jul  2 12:34:49.591: INFO: Successfully updated pod "labelsupdate68fc2aae-318a-4839-ba6c-cb4294ac4b70"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:34:53.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5969" for this suite.

• [SLOW TEST:6.739 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":166,"skipped":2834,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:34:53.641: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9875
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9875
[It] should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-9875
Jul  2 12:34:53.795: INFO: Found 0 stateful pods, waiting for 1
Jul  2 12:35:03.808: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
STEP: Patch a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 12:35:03.852: INFO: Deleting all statefulset in ns statefulset-9875
Jul  2 12:35:03.858: INFO: Scaling statefulset ss to 0
Jul  2 12:35:13.909: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:35:13.912: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 12:35:13.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9875" for this suite.

• [SLOW TEST:20.311 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":356,"completed":167,"skipped":2836,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:13.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5743
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should create services for rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Jul  2 12:35:14.101: INFO: namespace kubectl-5743
Jul  2 12:35:14.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5743 create -f -'
Jul  2 12:35:14.292: INFO: stderr: ""
Jul  2 12:35:14.292: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Jul  2 12:35:15.300: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 12:35:15.300: INFO: Found 0 / 1
Jul  2 12:35:16.299: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 12:35:16.299: INFO: Found 1 / 1
Jul  2 12:35:16.299: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul  2 12:35:16.305: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 12:35:16.305: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul  2 12:35:16.305: INFO: wait on agnhost-primary startup in kubectl-5743 
Jul  2 12:35:16.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5743 logs agnhost-primary-nbdbs agnhost-primary'
Jul  2 12:35:16.367: INFO: stderr: ""
Jul  2 12:35:16.367: INFO: stdout: "Paused\n"
STEP: exposing RC
Jul  2 12:35:16.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5743 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Jul  2 12:35:16.441: INFO: stderr: ""
Jul  2 12:35:16.441: INFO: stdout: "service/rm2 exposed\n"
Jul  2 12:35:16.453: INFO: Service rm2 in namespace kubectl-5743 found.
STEP: exposing service
Jul  2 12:35:18.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5743 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Jul  2 12:35:18.545: INFO: stderr: ""
Jul  2 12:35:18.545: INFO: stdout: "service/rm3 exposed\n"
Jul  2 12:35:18.553: INFO: Service rm3 in namespace kubectl-5743 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:35:20.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5743" for this suite.

• [SLOW TEST:6.626 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1249
    should create services for rc  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":356,"completed":168,"skipped":2874,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:20.580: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6594
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override command
Jul  2 12:35:20.777: INFO: Waiting up to 5m0s for pod "client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8" in namespace "containers-6594" to be "Succeeded or Failed"
Jul  2 12:35:20.781: INFO: Pod "client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03116ms
Jul  2 12:35:22.790: INFO: Pod "client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012716431s
Jul  2 12:35:24.799: INFO: Pod "client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021940505s
STEP: Saw pod success
Jul  2 12:35:24.799: INFO: Pod "client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8" satisfied condition "Succeeded or Failed"
Jul  2 12:35:24.804: INFO: Trying to get logs from node ip-172-31-9-92 pod client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:35:24.826: INFO: Waiting for pod client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8 to disappear
Jul  2 12:35:24.829: INFO: Pod client-containers-004c6c4b-ba52-474b-b2f2-ef5f736a64f8 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  2 12:35:24.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6594" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","total":356,"completed":169,"skipped":2921,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:24.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1950
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:35:25.540: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:35:28.579: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:35:28.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1950" for this suite.
STEP: Destroying namespace "webhook-1950-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":356,"completed":170,"skipped":2933,"failed":0}
SSSS
------------------------------
[sig-instrumentation] Events API 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:28.746: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-9309
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
STEP: get a list of Events with a label in the current namespace
STEP: delete a list of events
Jul  2 12:35:28.913: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:188
Jul  2 12:35:28.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9309" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","total":356,"completed":171,"skipped":2937,"failed":0}
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:28.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8563
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap that has name configmap-test-emptyKey-5b381b92-ac30-4d42-9e85-81b6e21a35e3
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:35:29.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8563" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":356,"completed":172,"skipped":2942,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:29.107: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4394
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating Agnhost RC
Jul  2 12:35:29.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-4394 create -f -'
Jul  2 12:35:29.417: INFO: stderr: ""
Jul  2 12:35:29.417: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Jul  2 12:35:30.426: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 12:35:30.426: INFO: Found 0 / 1
Jul  2 12:35:31.424: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 12:35:31.424: INFO: Found 1 / 1
Jul  2 12:35:31.424: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jul  2 12:35:31.428: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 12:35:31.428: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul  2 12:35:31.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-4394 patch pod agnhost-primary-bj8xv -p {"metadata":{"annotations":{"x":"y"}}}'
Jul  2 12:35:31.493: INFO: stderr: ""
Jul  2 12:35:31.493: INFO: stdout: "pod/agnhost-primary-bj8xv patched\n"
STEP: checking annotations
Jul  2 12:35:31.496: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 12:35:31.496: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:35:31.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4394" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":356,"completed":173,"skipped":2960,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff 
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:31.510: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4945
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/framework/framework.go:652
STEP: create deployment with httpd image
Jul  2 12:35:31.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-4945 create -f -'
Jul  2 12:35:31.821: INFO: stderr: ""
Jul  2 12:35:31.821: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image
Jul  2 12:35:31.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-4945 diff -f -'
Jul  2 12:35:31.997: INFO: rc: 1
Jul  2 12:35:31.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-4945 delete -f -'
Jul  2 12:35:32.071: INFO: stderr: ""
Jul  2 12:35:32.071: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:35:32.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4945" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","total":356,"completed":174,"skipped":2966,"failed":0}
SSSS
------------------------------
[sig-apps] ReplicaSet 
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:32.089: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1930
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a Replicaset
STEP: Verify that the required pods have come up.
Jul  2 12:35:32.236: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  2 12:35:37.243: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
STEP: Getting /status
Jul  2 12:35:37.247: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status
Jul  2 12:35:37.258: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated
Jul  2 12:35:37.260: INFO: Observed &ReplicaSet event: ADDED
Jul  2 12:35:37.260: INFO: Observed &ReplicaSet event: MODIFIED
Jul  2 12:35:37.261: INFO: Observed &ReplicaSet event: MODIFIED
Jul  2 12:35:37.261: INFO: Observed &ReplicaSet event: MODIFIED
Jul  2 12:35:37.261: INFO: Found replicaset test-rs in namespace replicaset-1930 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  2 12:35:37.261: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status
Jul  2 12:35:37.261: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul  2 12:35:37.268: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched
Jul  2 12:35:37.270: INFO: Observed &ReplicaSet event: ADDED
Jul  2 12:35:37.270: INFO: Observed &ReplicaSet event: MODIFIED
Jul  2 12:35:37.270: INFO: Observed &ReplicaSet event: MODIFIED
Jul  2 12:35:37.270: INFO: Observed &ReplicaSet event: MODIFIED
Jul  2 12:35:37.270: INFO: Observed replicaset test-rs in namespace replicaset-1930 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  2 12:35:37.271: INFO: Observed &ReplicaSet event: MODIFIED
Jul  2 12:35:37.271: INFO: Found replicaset test-rs in namespace replicaset-1930 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Jul  2 12:35:37.271: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:188
Jul  2 12:35:37.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1930" for this suite.

• [SLOW TEST:5.195 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","total":356,"completed":175,"skipped":2970,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:37.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1625
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jul  2 12:35:37.424: INFO: Waiting up to 5m0s for pod "pod-5f6206a3-d2ac-433e-b97e-4181609cac7e" in namespace "emptydir-1625" to be "Succeeded or Failed"
Jul  2 12:35:37.428: INFO: Pod "pod-5f6206a3-d2ac-433e-b97e-4181609cac7e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.5054ms
Jul  2 12:35:39.433: INFO: Pod "pod-5f6206a3-d2ac-433e-b97e-4181609cac7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009676286s
Jul  2 12:35:41.440: INFO: Pod "pod-5f6206a3-d2ac-433e-b97e-4181609cac7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015881368s
STEP: Saw pod success
Jul  2 12:35:41.440: INFO: Pod "pod-5f6206a3-d2ac-433e-b97e-4181609cac7e" satisfied condition "Succeeded or Failed"
Jul  2 12:35:41.444: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-5f6206a3-d2ac-433e-b97e-4181609cac7e container test-container: <nil>
STEP: delete the pod
Jul  2 12:35:41.467: INFO: Waiting for pod pod-5f6206a3-d2ac-433e-b97e-4181609cac7e to disappear
Jul  2 12:35:41.470: INFO: Pod pod-5f6206a3-d2ac-433e-b97e-4181609cac7e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:35:41.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1625" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":176,"skipped":2971,"failed":0}

------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:35:41.484: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4693
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4693
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4693
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4693
Jul  2 12:35:41.643: INFO: Found 0 stateful pods, waiting for 1
Jul  2 12:35:51.650: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jul  2 12:35:51.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:35:51.804: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:35:51.804: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:35:51.804: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:35:51.808: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jul  2 12:36:01.816: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:36:01.816: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:36:01.835: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999778s
Jul  2 12:36:02.843: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996361675s
Jul  2 12:36:03.851: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988134319s
Jul  2 12:36:04.859: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.979909229s
Jul  2 12:36:05.864: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.972277412s
Jul  2 12:36:06.871: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.96683079s
Jul  2 12:36:07.877: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.9592627s
Jul  2 12:36:08.884: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.954414827s
Jul  2 12:36:09.891: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.946736466s
Jul  2 12:36:10.898: INFO: Verifying statefulset ss doesn't scale past 1 for another 939.682537ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4693
Jul  2 12:36:11.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:36:12.050: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  2 12:36:12.050: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:36:12.050: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  2 12:36:12.056: INFO: Found 1 stateful pods, waiting for 3
Jul  2 12:36:22.066: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:36:22.066: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:36:22.066: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jul  2 12:36:22.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:36:22.226: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:36:22.226: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:36:22.226: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:36:22.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:36:22.389: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:36:22.389: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:36:22.389: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:36:22.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jul  2 12:36:22.528: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jul  2 12:36:22.528: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jul  2 12:36:22.528: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jul  2 12:36:22.528: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:36:22.534: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jul  2 12:36:32.545: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:36:32.545: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:36:32.545: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jul  2 12:36:32.561: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999776s
Jul  2 12:36:33.570: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994912694s
Jul  2 12:36:34.577: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985888894s
Jul  2 12:36:35.585: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.978959017s
Jul  2 12:36:36.592: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969896722s
Jul  2 12:36:37.599: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.963158419s
Jul  2 12:36:38.605: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.956744912s
Jul  2 12:36:39.613: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.95030651s
Jul  2 12:36:40.621: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941897579s
Jul  2 12:36:41.627: INFO: Verifying statefulset ss doesn't scale past 3 for another 934.803011ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4693
Jul  2 12:36:42.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:36:42.772: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  2 12:36:42.772: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:36:42.772: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  2 12:36:42.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:36:42.892: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  2 12:36:42.892: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:36:42.892: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  2 12:36:42.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=statefulset-4693 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jul  2 12:36:43.040: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jul  2 12:36:43.041: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jul  2 12:36:43.041: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jul  2 12:36:43.041: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 12:36:53.062: INFO: Deleting all statefulset in ns statefulset-4693
Jul  2 12:36:53.067: INFO: Scaling statefulset ss to 0
Jul  2 12:36:53.082: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 12:36:53.086: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 12:36:53.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4693" for this suite.

• [SLOW TEST:71.646 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":356,"completed":177,"skipped":2971,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:36:53.130: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9567
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:36:53.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83" in namespace "projected-9567" to be "Succeeded or Failed"
Jul  2 12:36:53.290: INFO: Pod "downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83": Phase="Pending", Reason="", readiness=false. Elapsed: 5.715562ms
Jul  2 12:36:55.299: INFO: Pod "downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015622267s
Jul  2 12:36:57.304: INFO: Pod "downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020548449s
STEP: Saw pod success
Jul  2 12:36:57.304: INFO: Pod "downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83" satisfied condition "Succeeded or Failed"
Jul  2 12:36:57.309: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83 container client-container: <nil>
STEP: delete the pod
Jul  2 12:36:57.335: INFO: Waiting for pod downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83 to disappear
Jul  2 12:36:57.338: INFO: Pod downwardapi-volume-c8002cba-e33f-4897-8b57-929aeb8e5e83 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:36:57.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9567" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":178,"skipped":2973,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:36:57.352: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-9478
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:36:57.831: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:37:00.859: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:37:00.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:37:04.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9478" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:6.811 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":356,"completed":179,"skipped":2992,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:37:04.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename cronjob
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in cronjob-1572
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a suspended cronjob
STEP: Ensuring no jobs are scheduled
STEP: Ensuring no job exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  2 12:42:04.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1572" for this suite.

• [SLOW TEST:300.232 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","total":356,"completed":180,"skipped":3013,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:42:04.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7681
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-4e7d9a5e-0dee-48c1-8698-da4ef913518d
STEP: Creating a pod to test consume configMaps
Jul  2 12:42:04.548: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c" in namespace "projected-7681" to be "Succeeded or Failed"
Jul  2 12:42:04.552: INFO: Pod "pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.382315ms
Jul  2 12:42:06.559: INFO: Pod "pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011118456s
Jul  2 12:42:08.565: INFO: Pod "pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016904127s
STEP: Saw pod success
Jul  2 12:42:08.565: INFO: Pod "pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c" satisfied condition "Succeeded or Failed"
Jul  2 12:42:08.570: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:42:08.608: INFO: Waiting for pod pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c to disappear
Jul  2 12:42:08.611: INFO: Pod pod-projected-configmaps-90782c8d-21b1-4144-93b7-db4ef56cd82c no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 12:42:08.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7681" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":356,"completed":181,"skipped":3016,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:42:08.625: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5184
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:297
[It] should scale a replication controller  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a replication controller
Jul  2 12:42:08.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 create -f -'
Jul  2 12:42:08.933: INFO: stderr: ""
Jul  2 12:42:08.933: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  2 12:42:08.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:42:09.001: INFO: stderr: ""
Jul  2 12:42:09.001: INFO: stdout: "update-demo-nautilus-62x5h update-demo-nautilus-l5q4c "
Jul  2 12:42:09.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:09.055: INFO: stderr: ""
Jul  2 12:42:09.055: INFO: stdout: ""
Jul  2 12:42:09.055: INFO: update-demo-nautilus-62x5h is created but not running
Jul  2 12:42:14.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:42:14.119: INFO: stderr: ""
Jul  2 12:42:14.119: INFO: stdout: "update-demo-nautilus-62x5h update-demo-nautilus-l5q4c "
Jul  2 12:42:14.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:14.176: INFO: stderr: ""
Jul  2 12:42:14.176: INFO: stdout: "true"
Jul  2 12:42:14.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:42:14.232: INFO: stderr: ""
Jul  2 12:42:14.232: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:42:14.232: INFO: validating pod update-demo-nautilus-62x5h
Jul  2 12:42:14.240: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:42:14.240: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:42:14.240: INFO: update-demo-nautilus-62x5h is verified up and running
Jul  2 12:42:14.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-l5q4c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:14.295: INFO: stderr: ""
Jul  2 12:42:14.295: INFO: stdout: "true"
Jul  2 12:42:14.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-l5q4c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:42:14.349: INFO: stderr: ""
Jul  2 12:42:14.349: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:42:14.349: INFO: validating pod update-demo-nautilus-l5q4c
Jul  2 12:42:14.355: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:42:14.355: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:42:14.355: INFO: update-demo-nautilus-l5q4c is verified up and running
STEP: scaling down the replication controller
Jul  2 12:42:14.356: INFO: scanned /root for discovery docs: <nil>
Jul  2 12:42:14.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Jul  2 12:42:15.441: INFO: stderr: ""
Jul  2 12:42:15.441: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  2 12:42:15.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:42:15.500: INFO: stderr: ""
Jul  2 12:42:15.500: INFO: stdout: "update-demo-nautilus-62x5h update-demo-nautilus-l5q4c "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jul  2 12:42:20.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:42:20.590: INFO: stderr: ""
Jul  2 12:42:20.591: INFO: stdout: "update-demo-nautilus-62x5h "
Jul  2 12:42:20.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:20.653: INFO: stderr: ""
Jul  2 12:42:20.653: INFO: stdout: "true"
Jul  2 12:42:20.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:42:20.709: INFO: stderr: ""
Jul  2 12:42:20.709: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:42:20.709: INFO: validating pod update-demo-nautilus-62x5h
Jul  2 12:42:20.715: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:42:20.715: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:42:20.715: INFO: update-demo-nautilus-62x5h is verified up and running
STEP: scaling up the replication controller
Jul  2 12:42:20.716: INFO: scanned /root for discovery docs: <nil>
Jul  2 12:42:20.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Jul  2 12:42:21.794: INFO: stderr: ""
Jul  2 12:42:21.794: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jul  2 12:42:21.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:42:21.852: INFO: stderr: ""
Jul  2 12:42:21.852: INFO: stdout: "update-demo-nautilus-62x5h update-demo-nautilus-swt9n "
Jul  2 12:42:21.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:21.908: INFO: stderr: ""
Jul  2 12:42:21.908: INFO: stdout: "true"
Jul  2 12:42:21.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:42:21.962: INFO: stderr: ""
Jul  2 12:42:21.962: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:42:21.962: INFO: validating pod update-demo-nautilus-62x5h
Jul  2 12:42:21.968: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:42:21.968: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:42:21.968: INFO: update-demo-nautilus-62x5h is verified up and running
Jul  2 12:42:21.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-swt9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:22.028: INFO: stderr: ""
Jul  2 12:42:22.028: INFO: stdout: ""
Jul  2 12:42:22.028: INFO: update-demo-nautilus-swt9n is created but not running
Jul  2 12:42:27.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Jul  2 12:42:27.094: INFO: stderr: ""
Jul  2 12:42:27.094: INFO: stdout: "update-demo-nautilus-62x5h update-demo-nautilus-swt9n "
Jul  2 12:42:27.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:27.149: INFO: stderr: ""
Jul  2 12:42:27.149: INFO: stdout: "true"
Jul  2 12:42:27.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-62x5h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:42:27.206: INFO: stderr: ""
Jul  2 12:42:27.206: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:42:27.206: INFO: validating pod update-demo-nautilus-62x5h
Jul  2 12:42:27.213: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:42:27.213: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:42:27.213: INFO: update-demo-nautilus-62x5h is verified up and running
Jul  2 12:42:27.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-swt9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Jul  2 12:42:27.274: INFO: stderr: ""
Jul  2 12:42:27.274: INFO: stdout: "true"
Jul  2 12:42:27.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods update-demo-nautilus-swt9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Jul  2 12:42:27.331: INFO: stderr: ""
Jul  2 12:42:27.331: INFO: stdout: "k8s.gcr.io/e2e-test-images/nautilus:1.5"
Jul  2 12:42:27.331: INFO: validating pod update-demo-nautilus-swt9n
Jul  2 12:42:27.338: INFO: got data: {
  "image": "nautilus.jpg"
}

Jul  2 12:42:27.338: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jul  2 12:42:27.338: INFO: update-demo-nautilus-swt9n is verified up and running
STEP: using delete to clean up resources
Jul  2 12:42:27.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 delete --grace-period=0 --force -f -'
Jul  2 12:42:27.410: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:42:27.410: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jul  2 12:42:27.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get rc,svc -l name=update-demo --no-headers'
Jul  2 12:42:27.488: INFO: stderr: "No resources found in kubectl-5184 namespace.\n"
Jul  2 12:42:27.488: INFO: stdout: ""
Jul  2 12:42:27.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5184 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul  2 12:42:27.578: INFO: stderr: ""
Jul  2 12:42:27.578: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:42:27.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5184" for this suite.

• [SLOW TEST:18.966 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:295
    should scale a replication controller  [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":356,"completed":182,"skipped":3017,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:42:27.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8657
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8657.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8657.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8657.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8657.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:42:29.785: INFO: DNS probes using dns-test-d9877491-c6bb-4d17-b67e-f2ed74b4c88d succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8657.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8657.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8657.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8657.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:42:31.847: INFO: File wheezy_udp@dns-test-service-3.dns-8657.svc.cluster.local from pod  dns-8657/dns-test-8cfff46c-90bf-4233-802f-c95389a5fb93 contains 'foo.example.com.
' instead of 'bar.example.com.'
Jul  2 12:42:31.852: INFO: File jessie_udp@dns-test-service-3.dns-8657.svc.cluster.local from pod  dns-8657/dns-test-8cfff46c-90bf-4233-802f-c95389a5fb93 contains 'foo.example.com.
' instead of 'bar.example.com.'
Jul  2 12:42:31.852: INFO: Lookups using dns-8657/dns-test-8cfff46c-90bf-4233-802f-c95389a5fb93 failed for: [wheezy_udp@dns-test-service-3.dns-8657.svc.cluster.local jessie_udp@dns-test-service-3.dns-8657.svc.cluster.local]

Jul  2 12:42:36.865: INFO: DNS probes using dns-test-8cfff46c-90bf-4233-802f-c95389a5fb93 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8657.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8657.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8657.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8657.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:42:38.956: INFO: DNS probes using dns-test-eb577eb0-1c7e-4fab-a4cd-5f74f245faa8 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 12:42:38.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8657" for this suite.

• [SLOW TEST:11.413 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":356,"completed":183,"skipped":3035,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:42:39.006: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5943
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating replication controller my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283
Jul  2 12:42:39.149: INFO: Pod name my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283: Found 0 pods out of 1
Jul  2 12:42:44.162: INFO: Pod name my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283: Found 1 pods out of 1
Jul  2 12:42:44.162: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283" are running
Jul  2 12:42:44.167: INFO: Pod "my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283-jhwvl" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:42:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:42:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:42:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-07-02 12:42:39 +0000 UTC Reason: Message:}])
Jul  2 12:42:44.167: INFO: Trying to dial the pod
Jul  2 12:42:49.187: INFO: Controller my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283: Got expected result from replica 1 [my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283-jhwvl]: "my-hostname-basic-36eed784-f8a8-42a3-a812-018405d35283-jhwvl", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  2 12:42:49.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5943" for this suite.

• [SLOW TEST:10.194 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":356,"completed":184,"skipped":3055,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:42:49.200: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5263
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:42:49.329: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Jul  2 12:42:51.380: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  2 12:42:51.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5263" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":356,"completed":185,"skipped":3064,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:42:51.402: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-31
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:42:53.556: INFO: Deleting pod "var-expansion-d9301210-2119-4b01-864e-659f8ad666e2" in namespace "var-expansion-31"
Jul  2 12:42:53.566: INFO: Wait up to 5m0s for pod "var-expansion-d9301210-2119-4b01-864e-659f8ad666e2" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 12:42:55.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-31" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","total":356,"completed":186,"skipped":3072,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:42:55.590: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6327
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-6dc0a9a0-5bcc-400e-aa18-8256b1a81954 in namespace container-probe-6327
Jul  2 12:42:57.749: INFO: Started pod liveness-6dc0a9a0-5bcc-400e-aa18-8256b1a81954 in namespace container-probe-6327
STEP: checking the pod's current state and verifying that restartCount is present
Jul  2 12:42:57.754: INFO: Initial restart count of pod liveness-6dc0a9a0-5bcc-400e-aa18-8256b1a81954 is 0
Jul  2 12:43:17.845: INFO: Restart count of pod container-probe-6327/liveness-6dc0a9a0-5bcc-400e-aa18-8256b1a81954 is now 1 (20.091292944s elapsed)
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 12:43:17.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6327" for this suite.

• [SLOW TEST:22.297 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":356,"completed":187,"skipped":3095,"failed":0}
SSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:43:17.887: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-444
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod with failed condition
STEP: updating the pod
Jul  2 12:45:18.578: INFO: Successfully updated pod "var-expansion-0aaa0c46-4ea4-4137-8bef-1bbad475856a"
STEP: waiting for pod running
STEP: deleting the pod gracefully
Jul  2 12:45:20.591: INFO: Deleting pod "var-expansion-0aaa0c46-4ea4-4137-8bef-1bbad475856a" in namespace "var-expansion-444"
Jul  2 12:45:20.603: INFO: Wait up to 5m0s for pod "var-expansion-0aaa0c46-4ea4-4137-8bef-1bbad475856a" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 12:45:52.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-444" for this suite.

• [SLOW TEST:154.740 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","total":356,"completed":188,"skipped":3102,"failed":0}
SSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:45:52.627: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7839
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:45:52.772: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-7c0522f4-5c42-4d36-977c-90746e47287a" in namespace "security-context-test-7839" to be "Succeeded or Failed"
Jul  2 12:45:52.777: INFO: Pod "busybox-privileged-false-7c0522f4-5c42-4d36-977c-90746e47287a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.718812ms
Jul  2 12:45:54.786: INFO: Pod "busybox-privileged-false-7c0522f4-5c42-4d36-977c-90746e47287a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013837615s
Jul  2 12:45:56.792: INFO: Pod "busybox-privileged-false-7c0522f4-5c42-4d36-977c-90746e47287a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019985055s
Jul  2 12:45:56.792: INFO: Pod "busybox-privileged-false-7c0522f4-5c42-4d36-977c-90746e47287a" satisfied condition "Succeeded or Failed"
Jul  2 12:45:56.808: INFO: Got logs for pod "busybox-privileged-false-7c0522f4-5c42-4d36-977c-90746e47287a": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  2 12:45:56.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7839" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":189,"skipped":3108,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:45:56.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5415
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ReplicationController
STEP: waiting for RC to be added
STEP: waiting for available Replicas
STEP: patching ReplicationController
STEP: waiting for RC to be modified
STEP: patching ReplicationController status
STEP: waiting for RC to be modified
STEP: waiting for available Replicas
STEP: fetching ReplicationController status
STEP: patching ReplicationController scale
STEP: waiting for RC to be modified
STEP: waiting for ReplicationController's scale to be the max amount
STEP: fetching ReplicationController; ensuring that it's patched
STEP: updating ReplicationController status
STEP: waiting for RC to be modified
STEP: listing all ReplicationControllers
STEP: checking that ReplicationController has expected values
STEP: deleting ReplicationControllers by collection
STEP: waiting for ReplicationController to have a DELETED watchEvent
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  2 12:45:59.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5415" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","total":356,"completed":190,"skipped":3116,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:45:59.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename runtimeclass
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in runtimeclass-2094
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Deleting RuntimeClass runtimeclass-2094-delete-me
STEP: Waiting for the RuntimeClass to disappear
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  2 12:45:59.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2094" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":191,"skipped":3127,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:45:59.222: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2309
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  2 12:45:59.368: INFO: The status of Pod labelsupdate6397c270-1246-4b45-a704-91d38703f4b3 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:46:01.374: INFO: The status of Pod labelsupdate6397c270-1246-4b45-a704-91d38703f4b3 is Running (Ready = true)
Jul  2 12:46:01.904: INFO: Successfully updated pod "labelsupdate6397c270-1246-4b45-a704-91d38703f4b3"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 12:46:03.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2309" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":356,"completed":192,"skipped":3137,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:46:03.940: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4612
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4612.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4612.svc.cluster.local;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4612.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4612.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4612.svc.cluster.local;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:46:06.133: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.139: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.143: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.148: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.154: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.158: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.163: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.169: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4612.svc.cluster.local from pod dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb: the server could not find the requested resource (get pods dns-test-32e366bd-d478-4673-8493-3f73b0a787cb)
Jul  2 12:46:06.169: INFO: Lookups using dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4612.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4612.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4612.svc.cluster.local jessie_udp@dns-test-service-2.dns-4612.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4612.svc.cluster.local]

Jul  2 12:46:11.210: INFO: DNS probes using dns-4612/dns-test-32e366bd-d478-4673-8493-3f73b0a787cb succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 12:46:11.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4612" for this suite.

• [SLOW TEST:7.336 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":356,"completed":193,"skipped":3140,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:46:11.277: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1566
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Jul  2 12:46:11.409: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:46:13.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:46:22.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1566" for this suite.

• [SLOW TEST:11.520 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":356,"completed":194,"skipped":3201,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:46:22.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7953
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:46:22.929: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jul  2 12:46:22.942: INFO: Pod name sample-pod: Found 0 pods out of 1
Jul  2 12:46:27.954: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jul  2 12:46:27.954: INFO: Creating deployment "test-rolling-update-deployment"
Jul  2 12:46:27.961: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jul  2 12:46:27.975: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jul  2 12:46:29.985: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jul  2 12:46:29.990: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:46:30.003: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7953  116bd73c-8458-4cfb-89f4-321109a5abe7 20293 1 2022-07-02 12:46:27 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2022-07-02 12:46:27 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0036299f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-07-02 12:46:27 +0000 UTC,LastTransitionTime:2022-07-02 12:46:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67c8f74c6c" has successfully progressed.,LastUpdateTime:2022-07-02 12:46:29 +0000 UTC,LastTransitionTime:2022-07-02 12:46:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  2 12:46:30.008: INFO: New ReplicaSet "test-rolling-update-deployment-67c8f74c6c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c  deployment-7953  111a2719-1ebf-4324-b387-d7f6e4bc1c44 20283 1 2022-07-02 12:46:27 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 116bd73c-8458-4cfb-89f4-321109a5abe7 0xc00365a007 0xc00365a008}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:46:27 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"116bd73c-8458-4cfb-89f4-321109a5abe7\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:46:28 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67c8f74c6c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00365a0d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:46:30.008: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jul  2 12:46:30.008: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7953  132b94ed-2ff5-42ad-98a9-8ebaf690c3cd 20292 2 2022-07-02 12:46:22 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 116bd73c-8458-4cfb-89f4-321109a5abe7 0xc003629e97 0xc003629e98}] []  [{e2e.test Update apps/v1 2022-07-02 12:46:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:46:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"116bd73c-8458-4cfb-89f4-321109a5abe7\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:46:29 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003629f68 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:46:30.013: INFO: Pod "test-rolling-update-deployment-67c8f74c6c-qb6d4" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67c8f74c6c-qb6d4 test-rolling-update-deployment-67c8f74c6c- deployment-7953  0633f4e2-239a-42e0-8d4b-1ce306963d53 20282 0 2022-07-02 12:46:27 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67c8f74c6c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-67c8f74c6c 111a2719-1ebf-4324-b387-d7f6e4bc1c44 0xc00365a527 0xc00365a528}] []  [{kube-controller-manager Update v1 2022-07-02 12:46:27 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"111a2719-1ebf-4324-b387-d7f6e4bc1c44\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:46:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.231.40\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rmtnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rmtnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:46:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:46:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:46:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:192.168.231.40,StartTime:2022-07-02 12:46:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:46:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,ImageID:k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e,ContainerID:containerd://bc3ecbb8d24eb2b7780702ec4fc158a9df80d419f3d5c9446d1a4ebe2cfe5b5b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.231.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:46:30.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7953" for this suite.

• [SLOW TEST:7.228 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":195,"skipped":3237,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:46:30.025: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4866
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4866
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:46:30.178: INFO: Found 0 stateful pods, waiting for 1
Jul  2 12:46:40.183: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet
Jul  2 12:46:40.216: INFO: Found 1 stateful pods, waiting for 2
Jul  2 12:46:50.227: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jul  2 12:46:50.227: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets
STEP: Delete all of the StatefulSets
STEP: Verify that StatefulSets have been deleted
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 12:46:50.263: INFO: Deleting all statefulset in ns statefulset-4866
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 12:46:50.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4866" for this suite.

• [SLOW TEST:20.266 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","total":356,"completed":196,"skipped":3245,"failed":0}
S
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:46:50.291: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7379
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7379.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7379.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7379.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7379.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:46:52.495: INFO: DNS probes using dns-7379/dns-test-db92b9b9-5780-49f9-a9ed-b0f1d956dfc3 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 12:46:52.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7379" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","total":356,"completed":197,"skipped":3246,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:46:52.549: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1945
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:46:52.689: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc" in namespace "projected-1945" to be "Succeeded or Failed"
Jul  2 12:46:52.695: INFO: Pod "downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.434777ms
Jul  2 12:46:54.701: INFO: Pod "downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01242986s
Jul  2 12:46:56.709: INFO: Pod "downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020357364s
STEP: Saw pod success
Jul  2 12:46:56.709: INFO: Pod "downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc" satisfied condition "Succeeded or Failed"
Jul  2 12:46:56.715: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc container client-container: <nil>
STEP: delete the pod
Jul  2 12:46:56.736: INFO: Waiting for pod downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc to disappear
Jul  2 12:46:56.740: INFO: Pod downwardapi-volume-20fa9c86-b0d8-4421-823b-30d9783313fc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 12:46:56.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1945" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":356,"completed":198,"skipped":3317,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:46:56.755: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-9863
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Jul  2 12:46:56.887: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  2 12:47:56.905: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:47:56.911: INFO: Starting informer...
STEP: Starting pods...
Jul  2 12:47:57.139: INFO: Pod1 is running on ip-172-31-9-92. Tainting Node
Jul  2 12:47:59.364: INFO: Pod2 is running on ip-172-31-9-92. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Jul  2 12:48:05.161: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Jul  2 12:48:25.186: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:48:25.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9863" for this suite.

• [SLOW TEST:88.475 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":356,"completed":199,"skipped":3349,"failed":0}
SSSSSS
------------------------------
[sig-network] IngressClass API 
   should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:25.230: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename ingressclass
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in ingressclass-9290
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:188
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: getting /apis
STEP: getting /apis/networking.k8s.io
STEP: getting /apis/networking.k8s.iov1
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  2 12:48:25.397: INFO: starting watch
STEP: patching
STEP: updating
Jul  2 12:48:25.409: INFO: waiting for watch events with expected annotations
Jul  2 12:48:25.409: INFO: saw patched and updated annotations
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:188
Jul  2 12:48:25.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-9290" for this suite.
•{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","total":356,"completed":200,"skipped":3355,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:25.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5796
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jul  2 12:48:25.600: INFO: Pod name pod-release: Found 0 pods out of 1
Jul  2 12:48:30.609: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  2 12:48:30.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5796" for this suite.

• [SLOW TEST:5.213 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":356,"completed":201,"skipped":3399,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:30.673: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9222
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:48:30.853: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"05730db7-f159-4f6e-9643-ec48e058b841", Controller:(*bool)(0xc003067ba6), BlockOwnerDeletion:(*bool)(0xc003067ba7)}}
Jul  2 12:48:30.862: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"215566ab-1bf6-4701-937d-cb055ccb7adc", Controller:(*bool)(0xc003067e1e), BlockOwnerDeletion:(*bool)(0xc003067e1f)}}
Jul  2 12:48:30.871: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"86c80b58-783b-4fc4-aed6-645ee0005aff", Controller:(*bool)(0xc003568086), BlockOwnerDeletion:(*bool)(0xc003568087)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  2 12:48:35.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9222" for this suite.

• [SLOW TEST:5.226 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":356,"completed":202,"skipped":3419,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:35.900: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3233
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:48:36.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties
Jul  2 12:48:38.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 create -f -'
Jul  2 12:48:38.968: INFO: stderr: ""
Jul  2 12:48:38.968: INFO: stdout: "e2e-test-crd-publish-openapi-8346-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jul  2 12:48:38.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 delete e2e-test-crd-publish-openapi-8346-crds test-foo'
Jul  2 12:48:39.031: INFO: stderr: ""
Jul  2 12:48:39.031: INFO: stdout: "e2e-test-crd-publish-openapi-8346-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Jul  2 12:48:39.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 apply -f -'
Jul  2 12:48:39.216: INFO: stderr: ""
Jul  2 12:48:39.216: INFO: stdout: "e2e-test-crd-publish-openapi-8346-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jul  2 12:48:39.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 delete e2e-test-crd-publish-openapi-8346-crds test-foo'
Jul  2 12:48:39.288: INFO: stderr: ""
Jul  2 12:48:39.288: INFO: stdout: "e2e-test-crd-publish-openapi-8346-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values
Jul  2 12:48:39.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 create -f -'
Jul  2 12:48:39.435: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Jul  2 12:48:39.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 create -f -'
Jul  2 12:48:40.068: INFO: rc: 1
Jul  2 12:48:40.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 apply -f -'
Jul  2 12:48:40.228: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties
Jul  2 12:48:40.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 create -f -'
Jul  2 12:48:40.374: INFO: rc: 1
Jul  2 12:48:40.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 --namespace=crd-publish-openapi-3233 apply -f -'
Jul  2 12:48:40.521: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Jul  2 12:48:40.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 explain e2e-test-crd-publish-openapi-8346-crds'
Jul  2 12:48:40.672: INFO: stderr: ""
Jul  2 12:48:40.672: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8346-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Jul  2 12:48:40.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 explain e2e-test-crd-publish-openapi-8346-crds.metadata'
Jul  2 12:48:40.820: INFO: stderr: ""
Jul  2 12:48:40.820: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8346-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     Deprecated: ClusterName is a legacy field that was always cleared by the\n     system and never used; it will be removed completely in 1.25.\n\n     The name in the go struct is changed to help clients detect accidental use.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Jul  2 12:48:40.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 explain e2e-test-crd-publish-openapi-8346-crds.spec'
Jul  2 12:48:40.971: INFO: stderr: ""
Jul  2 12:48:40.971: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8346-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Jul  2 12:48:40.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 explain e2e-test-crd-publish-openapi-8346-crds.spec.bars'
Jul  2 12:48:41.140: INFO: stderr: ""
Jul  2 12:48:41.140: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-8346-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Jul  2 12:48:41.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3233 explain e2e-test-crd-publish-openapi-8346-crds.spec.bars2'
Jul  2 12:48:41.306: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:48:43.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3233" for this suite.

• [SLOW TEST:7.909 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":356,"completed":203,"skipped":3475,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:43.810: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5095
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:48:43.953: INFO: Got root ca configmap in namespace "svcaccounts-5095"
Jul  2 12:48:43.960: INFO: Deleted root ca configmap in namespace "svcaccounts-5095"
STEP: waiting for a new root ca configmap created
Jul  2 12:48:44.466: INFO: Recreated root ca configmap in namespace "svcaccounts-5095"
Jul  2 12:48:44.471: INFO: Updated root ca configmap in namespace "svcaccounts-5095"
STEP: waiting for the root ca configmap reconciled
Jul  2 12:48:44.978: INFO: Reconciled root ca configmap in namespace "svcaccounts-5095"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  2 12:48:44.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5095" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","total":356,"completed":204,"skipped":3485,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:44.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7104
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:48:45.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  2 12:48:45.139: INFO: The status of Pod pod-exec-websocket-6d9c9a66-45b2-4093-937f-0ce2c521257d is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:48:47.147: INFO: The status of Pod pod-exec-websocket-6d9c9a66-45b2-4093-937f-0ce2c521257d is Running (Ready = true)
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:48:47.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7104" for this suite.
•{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":356,"completed":205,"skipped":3499,"failed":0}

------------------------------
[sig-apps] Deployment 
  Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:47.250: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6290
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:48:47.382: INFO: Creating simple deployment test-new-deployment
Jul  2 12:48:47.394: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the deployment Spec.Replicas was modified
STEP: Patch a scale subresource
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:48:49.449: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-6290  de56edf7-14c9-423d-9cea-cfbe735bc516 21124 3 2022-07-02 12:48:47 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-07-02 12:48:47 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:48:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00551c158 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-07-02 12:48:49 +0000 UTC,LastTransitionTime:2022-07-02 12:48:49 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-55df494869" has successfully progressed.,LastUpdateTime:2022-07-02 12:48:49 +0000 UTC,LastTransitionTime:2022-07-02 12:48:47 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jul  2 12:48:49.453: INFO: New ReplicaSet "test-new-deployment-55df494869" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-55df494869  deployment-6290  ff03b609-d88c-47db-a23d-021420280455 21123 2 2022-07-02 12:48:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment de56edf7-14c9-423d-9cea-cfbe735bc516 0xc00551c667 0xc00551c668}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:48:47 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"de56edf7-14c9-423d-9cea-cfbe735bc516\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:48:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 55df494869,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00551c708 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:48:49.459: INFO: Pod "test-new-deployment-55df494869-h4648" is available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-h4648 test-new-deployment-55df494869- deployment-6290  1ddc79b2-ce41-4d59-95ee-752ee95879e0 21117 0 2022-07-02 12:48:47 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-new-deployment-55df494869 ff03b609-d88c-47db-a23d-021420280455 0xc005462057 0xc005462058}] []  [{kube-controller-manager Update v1 2022-07-02 12:48:47 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff03b609-d88c-47db-a23d-021420280455\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:48:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.74.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mdhm9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mdhm9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-69-95,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:48:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:48:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:48:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:48:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.69.95,PodIP:192.168.74.154,StartTime:2022-07-02 12:48:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-07-02 12:48:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:k8s.gcr.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8c6e3264e2ee7e4b2f450fbfd0e68d30d6b4110c9fc17d33d0d6093c92f39869,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.74.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 12:48:49.459: INFO: Pod "test-new-deployment-55df494869-sznfh" is not available:
&Pod{ObjectMeta:{test-new-deployment-55df494869-sznfh test-new-deployment-55df494869- deployment-6290  986b9f38-1b87-43bc-98f6-d6fac457376e 21125 0 2022-07-02 12:48:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:55df494869] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-new-deployment-55df494869 ff03b609-d88c-47db-a23d-021420280455 0xc005462247 0xc005462248}] []  [{kube-controller-manager Update v1 2022-07-02 12:48:49 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ff03b609-d88c-47db-a23d-021420280455\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ljlhr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ljlhr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:48:49.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6290" for this suite.
•{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","total":356,"completed":206,"skipped":3499,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:49.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-889
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/framework/framework.go:652
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-889.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-889.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-889.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-889.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:48:51.666: INFO: DNS probes using dns-889/dns-test-09c035d9-9827-4b76-bff0-b477c2b6b1f1 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 12:48:51.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-889" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","total":356,"completed":207,"skipped":3515,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:51.701: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2643
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a secret [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:48:51.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2643" for this suite.
•{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","total":356,"completed":208,"skipped":3526,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance] 
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:51.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sysctl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sysctl-2126
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with one valid and two invalid sysctls
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  2 12:48:52.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-2126" for this suite.
•{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","total":356,"completed":209,"skipped":3566,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:48:52.026: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3840
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 12:49:08.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3840" for this suite.

• [SLOW TEST:16.281 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":356,"completed":210,"skipped":3582,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] version v1
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:49:08.308: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3561
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:49:08.438: INFO: Creating pod...
Jul  2 12:49:10.460: INFO: Creating service...
Jul  2 12:49:10.472: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/pods/agnhost/proxy/some/path/with/DELETE
Jul  2 12:49:10.478: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  2 12:49:10.478: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/pods/agnhost/proxy/some/path/with/GET
Jul  2 12:49:10.484: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jul  2 12:49:10.484: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/pods/agnhost/proxy/some/path/with/HEAD
Jul  2 12:49:10.489: INFO: http.Client request:HEAD | StatusCode:200
Jul  2 12:49:10.489: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/pods/agnhost/proxy/some/path/with/OPTIONS
Jul  2 12:49:10.494: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  2 12:49:10.494: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/pods/agnhost/proxy/some/path/with/PATCH
Jul  2 12:49:10.498: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  2 12:49:10.499: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/pods/agnhost/proxy/some/path/with/POST
Jul  2 12:49:10.502: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  2 12:49:10.502: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/pods/agnhost/proxy/some/path/with/PUT
Jul  2 12:49:10.507: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Jul  2 12:49:10.507: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/services/test-service/proxy/some/path/with/DELETE
Jul  2 12:49:10.515: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Jul  2 12:49:10.515: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/services/test-service/proxy/some/path/with/GET
Jul  2 12:49:10.521: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Jul  2 12:49:10.521: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/services/test-service/proxy/some/path/with/HEAD
Jul  2 12:49:10.528: INFO: http.Client request:HEAD | StatusCode:200
Jul  2 12:49:10.528: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/services/test-service/proxy/some/path/with/OPTIONS
Jul  2 12:49:10.536: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Jul  2 12:49:10.536: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/services/test-service/proxy/some/path/with/PATCH
Jul  2 12:49:10.543: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Jul  2 12:49:10.543: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/services/test-service/proxy/some/path/with/POST
Jul  2 12:49:10.549: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Jul  2 12:49:10.550: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-3561/services/test-service/proxy/some/path/with/PUT
Jul  2 12:49:10.557: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:188
Jul  2 12:49:10.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3561" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","total":356,"completed":211,"skipped":3612,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:49:10.570: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1434
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  2 12:49:10.717: INFO: Waiting up to 5m0s for pod "downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6" in namespace "downward-api-1434" to be "Succeeded or Failed"
Jul  2 12:49:10.721: INFO: Pod "downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.693501ms
Jul  2 12:49:12.730: INFO: Pod "downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012744097s
Jul  2 12:49:14.740: INFO: Pod "downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022934626s
STEP: Saw pod success
Jul  2 12:49:14.741: INFO: Pod "downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6" satisfied condition "Succeeded or Failed"
Jul  2 12:49:14.745: INFO: Trying to get logs from node ip-172-31-69-95 pod downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6 container dapi-container: <nil>
STEP: delete the pod
Jul  2 12:49:14.775: INFO: Waiting for pod downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6 to disappear
Jul  2 12:49:14.779: INFO: Pod downward-api-9fda6a5a-e450-466d-a231-20a0d27438b6 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  2 12:49:14.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1434" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":356,"completed":212,"skipped":3621,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:49:14.791: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3351
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name s-test-opt-del-aa7fb959-60f8-4c05-9d9b-488a53caf332
STEP: Creating secret with name s-test-opt-upd-456944bd-2e31-4fb4-8992-a9b698e28d1b
STEP: Creating the pod
Jul  2 12:49:15.002: INFO: The status of Pod pod-secrets-0bcc2f7d-ab32-4792-937c-2c8961772a14 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:49:17.010: INFO: The status of Pod pod-secrets-0bcc2f7d-ab32-4792-937c-2c8961772a14 is Running (Ready = true)
STEP: Deleting secret s-test-opt-del-aa7fb959-60f8-4c05-9d9b-488a53caf332
STEP: Updating secret s-test-opt-upd-456944bd-2e31-4fb4-8992-a9b698e28d1b
STEP: Creating secret with name s-test-opt-create-9e5b23e9-62ff-4c60-9e4a-c5eaa105e3f0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:49:19.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3351" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":213,"skipped":3667,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:49:19.097: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-7423
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:188
Jul  2 12:49:19.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7423" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":356,"completed":214,"skipped":3689,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events 
  should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:49:19.247: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2213
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of events [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of events
Jul  2 12:49:19.383: INFO: created test-event-1
Jul  2 12:49:19.387: INFO: created test-event-2
Jul  2 12:49:19.391: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace
STEP: delete collection of events
Jul  2 12:49:19.395: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity
Jul  2 12:49:19.422: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:188
Jul  2 12:49:19.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2213" for this suite.
•{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","total":356,"completed":215,"skipped":3712,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:49:19.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8035
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-8035
Jul  2 12:49:19.589: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:49:21.597: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Jul  2 12:49:21.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jul  2 12:49:21.748: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jul  2 12:49:21.748: INFO: stdout: "iptables"
Jul  2 12:49:21.748: INFO: proxyMode: iptables
Jul  2 12:49:21.765: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jul  2 12:49:21.769: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-8035
STEP: creating replication controller affinity-nodeport-timeout in namespace services-8035
I0702 12:49:21.794251      20 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-8035, replica count: 3
I0702 12:49:24.845127      20 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 12:49:24.862: INFO: Creating new exec pod
Jul  2 12:49:27.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Jul  2 12:49:28.034: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Jul  2 12:49:28.034: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:49:28.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.36 80'
Jul  2 12:49:28.171: INFO: stderr: "+ nc -v -t -w 2 10.152.183.36 80\n+ echo hostName\nConnection to 10.152.183.36 80 port [tcp/http] succeeded!\n"
Jul  2 12:49:28.171: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:49:28.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.69.95 32523'
Jul  2 12:49:28.283: INFO: stderr: "+ nc -v -t -w 2 172.31.69.95 32523\n+ echo hostName\nConnection to 172.31.69.95 32523 port [tcp/*] succeeded!\n"
Jul  2 12:49:28.283: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:49:28.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.91.232 32523'
Jul  2 12:49:28.397: INFO: stderr: "+ nc -v -t -w 2 172.31.91.232 32523\n+ echo hostName\nConnection to 172.31.91.232 32523 port [tcp/*] succeeded!\n"
Jul  2 12:49:28.397: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:49:28.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.69.95:32523/ ; done'
Jul  2 12:49:28.593: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n"
Jul  2 12:49:28.593: INFO: stdout: "\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn\naffinity-nodeport-timeout-z27hn"
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Received response from host: affinity-nodeport-timeout-z27hn
Jul  2 12:49:28.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.69.95:32523/'
Jul  2 12:49:28.720: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n"
Jul  2 12:49:28.720: INFO: stdout: "affinity-nodeport-timeout-z27hn"
Jul  2 12:49:48.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.69.95:32523/'
Jul  2 12:49:48.867: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n"
Jul  2 12:49:48.867: INFO: stdout: "affinity-nodeport-timeout-z27hn"
Jul  2 12:50:08.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8035 exec execpod-affinityxv8sd -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.69.95:32523/'
Jul  2 12:50:09.018: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.69.95:32523/\n"
Jul  2 12:50:09.018: INFO: stdout: "affinity-nodeport-timeout-ql25p"
Jul  2 12:50:09.018: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-8035, will wait for the garbage collector to delete the pods
Jul  2 12:50:09.108: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 7.541355ms
Jul  2 12:50:09.209: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.442924ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:50:11.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8035" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:52.012 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":216,"skipped":3768,"failed":0}
SS
------------------------------
[sig-apps] CronJob 
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:50:11.450: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename cronjob
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in cronjob-9875
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ReplaceConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring the job is replaced with a new one
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  2 12:52:01.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9875" for this suite.

• [SLOW TEST:110.181 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","total":356,"completed":217,"skipped":3770,"failed":0}
[sig-node] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:01.631: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8747
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating secret secrets-8747/secret-test-c484e945-ba30-48ac-9843-a741ba1436d7
STEP: Creating a pod to test consume secrets
Jul  2 12:52:01.777: INFO: Waiting up to 5m0s for pod "pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be" in namespace "secrets-8747" to be "Succeeded or Failed"
Jul  2 12:52:01.780: INFO: Pod "pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be": Phase="Pending", Reason="", readiness=false. Elapsed: 3.02687ms
Jul  2 12:52:03.788: INFO: Pod "pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010841609s
Jul  2 12:52:05.799: INFO: Pod "pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022049047s
STEP: Saw pod success
Jul  2 12:52:05.799: INFO: Pod "pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be" satisfied condition "Succeeded or Failed"
Jul  2 12:52:05.803: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be container env-test: <nil>
STEP: delete the pod
Jul  2 12:52:05.829: INFO: Waiting for pod pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be to disappear
Jul  2 12:52:05.832: INFO: Pod pod-configmaps-be024f19-3e9f-4bfc-b1d3-29503d33e6be no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  2 12:52:05.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8747" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":218,"skipped":3770,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:05.843: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1571
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 12:52:22.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1571" for this suite.

• [SLOW TEST:16.230 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":356,"completed":219,"skipped":3773,"failed":0}
SSS
------------------------------
[sig-node] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:22.074: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1449
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test substitution in container's command
Jul  2 12:52:22.243: INFO: Waiting up to 5m0s for pod "var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277" in namespace "var-expansion-1449" to be "Succeeded or Failed"
Jul  2 12:52:22.248: INFO: Pod "var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277": Phase="Pending", Reason="", readiness=false. Elapsed: 5.156564ms
Jul  2 12:52:24.257: INFO: Pod "var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014195538s
Jul  2 12:52:26.263: INFO: Pod "var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020204959s
STEP: Saw pod success
Jul  2 12:52:26.263: INFO: Pod "var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277" satisfied condition "Succeeded or Failed"
Jul  2 12:52:26.267: INFO: Trying to get logs from node ip-172-31-9-92 pod var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277 container dapi-container: <nil>
STEP: delete the pod
Jul  2 12:52:26.291: INFO: Waiting for pod var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277 to disappear
Jul  2 12:52:26.294: INFO: Pod var-expansion-f61ec14c-96a2-4b0a-b584-72be9767f277 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 12:52:26.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1449" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":356,"completed":220,"skipped":3776,"failed":0}
SSSSS
------------------------------
[sig-node] Security Context 
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:26.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename security-context
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-4471
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Jul  2 12:52:26.447: INFO: Waiting up to 5m0s for pod "security-context-84986c20-7c67-495a-81ad-965f236b14bb" in namespace "security-context-4471" to be "Succeeded or Failed"
Jul  2 12:52:26.454: INFO: Pod "security-context-84986c20-7c67-495a-81ad-965f236b14bb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.157076ms
Jul  2 12:52:28.463: INFO: Pod "security-context-84986c20-7c67-495a-81ad-965f236b14bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015188347s
Jul  2 12:52:30.472: INFO: Pod "security-context-84986c20-7c67-495a-81ad-965f236b14bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024384921s
STEP: Saw pod success
Jul  2 12:52:30.472: INFO: Pod "security-context-84986c20-7c67-495a-81ad-965f236b14bb" satisfied condition "Succeeded or Failed"
Jul  2 12:52:30.475: INFO: Trying to get logs from node ip-172-31-9-92 pod security-context-84986c20-7c67-495a-81ad-965f236b14bb container test-container: <nil>
STEP: delete the pod
Jul  2 12:52:30.501: INFO: Waiting for pod security-context-84986c20-7c67-495a-81ad-965f236b14bb to disappear
Jul  2 12:52:30.504: INFO: Pod security-context-84986c20-7c67-495a-81ad-965f236b14bb no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  2 12:52:30.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4471" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":221,"skipped":3781,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:30.520: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3617
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 60.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.60_udp@PTR;check="$$(dig +tcp +noall +answer +search 60.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.60_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3617.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3617.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3617.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3617.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 60.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.60_udp@PTR;check="$$(dig +tcp +noall +answer +search 60.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.60_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 12:52:32.715: INFO: Unable to read wheezy_udp@dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.718: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.722: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.727: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.746: INFO: Unable to read jessie_udp@dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.751: INFO: Unable to read jessie_tcp@dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.754: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.758: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local from pod dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1: the server could not find the requested resource (get pods dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1)
Jul  2 12:52:32.774: INFO: Lookups using dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1 failed for: [wheezy_udp@dns-test-service.dns-3617.svc.cluster.local wheezy_tcp@dns-test-service.dns-3617.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local jessie_udp@dns-test-service.dns-3617.svc.cluster.local jessie_tcp@dns-test-service.dns-3617.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3617.svc.cluster.local]

Jul  2 12:52:37.842: INFO: DNS probes using dns-3617/dns-test-da73d752-0b40-4261-9b98-790c1c3a67a1 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 12:52:37.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3617" for this suite.

• [SLOW TEST:7.393 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":356,"completed":222,"skipped":3789,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:37.914: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1240
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-1240
STEP: creating service affinity-nodeport-transition in namespace services-1240
STEP: creating replication controller affinity-nodeport-transition in namespace services-1240
I0702 12:52:38.102268      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-1240, replica count: 3
I0702 12:52:41.153735      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 12:52:41.171: INFO: Creating new exec pod
Jul  2 12:52:44.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-1240 exec execpod-affinityzhmnb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Jul  2 12:52:44.342: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Jul  2 12:52:44.342: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:52:44.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-1240 exec execpod-affinityzhmnb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.33 80'
Jul  2 12:52:44.476: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.33 80\nConnection to 10.152.183.33 80 port [tcp/http] succeeded!\n"
Jul  2 12:52:44.476: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:52:44.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-1240 exec execpod-affinityzhmnb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.9.92 30960'
Jul  2 12:52:44.593: INFO: stderr: "+ nc -v -t -w 2 172.31.9.92 30960\n+ echo hostName\nConnection to 172.31.9.92 30960 port [tcp/*] succeeded!\n"
Jul  2 12:52:44.593: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:52:44.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-1240 exec execpod-affinityzhmnb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.91.232 30960'
Jul  2 12:52:44.725: INFO: stderr: "+ + echonc -v hostName\n -t -w 2 172.31.91.232 30960\nConnection to 172.31.91.232 30960 port [tcp/*] succeeded!\n"
Jul  2 12:52:44.726: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 12:52:44.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-1240 exec execpod-affinityzhmnb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.69.95:30960/ ; done'
Jul  2 12:52:44.963: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n"
Jul  2 12:52:44.964: INFO: stdout: "\naffinity-nodeport-transition-v9757\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-v9757\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-t7grr\naffinity-nodeport-transition-t7grr\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-v9757\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-v9757\naffinity-nodeport-transition-v9757\naffinity-nodeport-transition-v9757\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-v9757\naffinity-nodeport-transition-v9757"
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-t7grr
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-t7grr
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.964: INFO: Received response from host: affinity-nodeport-transition-v9757
Jul  2 12:52:44.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-1240 exec execpod-affinityzhmnb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.69.95:30960/ ; done'
Jul  2 12:52:45.190: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.69.95:30960/\n"
Jul  2 12:52:45.190: INFO: stdout: "\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r\naffinity-nodeport-transition-m5l6r"
Jul  2 12:52:45.190: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.190: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.190: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.190: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Received response from host: affinity-nodeport-transition-m5l6r
Jul  2 12:52:45.191: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-1240, will wait for the garbage collector to delete the pods
Jul  2 12:52:45.266: INFO: Deleting ReplicationController affinity-nodeport-transition took: 7.751096ms
Jul  2 12:52:45.368: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.125985ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:52:47.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1240" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:9.793 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","total":356,"completed":223,"skipped":3811,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:47.707: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4157
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4157
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-4157
I0702 12:52:47.875513      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-4157, replica count: 2
Jul  2 12:52:50.926: INFO: Creating new exec pod
I0702 12:52:50.926496      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 12:52:53.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-4157 exec execpodvdvzm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Jul  2 12:52:54.091: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jul  2 12:52:54.091: INFO: stdout: "externalname-service-86gtx"
Jul  2 12:52:54.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-4157 exec execpodvdvzm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.30 80'
Jul  2 12:52:54.218: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.30 80\nConnection to 10.152.183.30 80 port [tcp/http] succeeded!\n"
Jul  2 12:52:54.218: INFO: stdout: "externalname-service-86gtx"
Jul  2 12:52:54.218: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:52:54.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4157" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:6.551 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":356,"completed":224,"skipped":3818,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:54.259: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8027
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jul  2 12:52:54.402: INFO: Waiting up to 5m0s for pod "pod-0e662bda-78e6-4cbb-a79b-d19a181b273c" in namespace "emptydir-8027" to be "Succeeded or Failed"
Jul  2 12:52:54.406: INFO: Pod "pod-0e662bda-78e6-4cbb-a79b-d19a181b273c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05355ms
Jul  2 12:52:56.414: INFO: Pod "pod-0e662bda-78e6-4cbb-a79b-d19a181b273c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011813142s
Jul  2 12:52:58.423: INFO: Pod "pod-0e662bda-78e6-4cbb-a79b-d19a181b273c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021020124s
STEP: Saw pod success
Jul  2 12:52:58.423: INFO: Pod "pod-0e662bda-78e6-4cbb-a79b-d19a181b273c" satisfied condition "Succeeded or Failed"
Jul  2 12:52:58.427: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-0e662bda-78e6-4cbb-a79b-d19a181b273c container test-container: <nil>
STEP: delete the pod
Jul  2 12:52:58.447: INFO: Waiting for pod pod-0e662bda-78e6-4cbb-a79b-d19a181b273c to disappear
Jul  2 12:52:58.450: INFO: Pod pod-0e662bda-78e6-4cbb-a79b-d19a181b273c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 12:52:58.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8027" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":225,"skipped":3821,"failed":0}

------------------------------
[sig-node] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:52:58.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7588
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod liveness-266f31b4-5b54-4ced-a39c-f9ba8dd957c3 in namespace container-probe-7588
Jul  2 12:53:00.628: INFO: Started pod liveness-266f31b4-5b54-4ced-a39c-f9ba8dd957c3 in namespace container-probe-7588
STEP: checking the pod's current state and verifying that restartCount is present
Jul  2 12:53:00.632: INFO: Initial restart count of pod liveness-266f31b4-5b54-4ced-a39c-f9ba8dd957c3 is 0
STEP: deleting the pod
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 12:57:01.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7588" for this suite.

• [SLOW TEST:243.220 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":356,"completed":226,"skipped":3821,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:01.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4673
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Jul  2 12:57:07.884: INFO: 80 pods remaining
Jul  2 12:57:07.884: INFO: 80 pods has nil DeletionTimestamp
Jul  2 12:57:07.884: INFO: 
Jul  2 12:57:08.879: INFO: 71 pods remaining
Jul  2 12:57:08.879: INFO: 71 pods has nil DeletionTimestamp
Jul  2 12:57:08.879: INFO: 
Jul  2 12:57:09.875: INFO: 60 pods remaining
Jul  2 12:57:09.875: INFO: 60 pods has nil DeletionTimestamp
Jul  2 12:57:09.875: INFO: 
Jul  2 12:57:10.875: INFO: 40 pods remaining
Jul  2 12:57:10.875: INFO: 40 pods has nil DeletionTimestamp
Jul  2 12:57:10.875: INFO: 
Jul  2 12:57:11.878: INFO: 31 pods remaining
Jul  2 12:57:11.878: INFO: 31 pods has nil DeletionTimestamp
Jul  2 12:57:11.878: INFO: 
Jul  2 12:57:12.877: INFO: 20 pods remaining
Jul  2 12:57:12.877: INFO: 20 pods has nil DeletionTimestamp
Jul  2 12:57:12.877: INFO: 
STEP: Gathering metrics
Jul  2 12:57:13.876: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0702 12:57:13.876878      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  2 12:57:13.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4673" for this suite.

• [SLOW TEST:12.198 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":356,"completed":227,"skipped":3851,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:13.889: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8566
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 12:57:14.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8566" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":356,"completed":228,"skipped":3881,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:14.116: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3943
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:57:14.259: INFO: Waiting up to 5m0s for pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb" in namespace "security-context-test-3943" to be "Succeeded or Failed"
Jul  2 12:57:14.263: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.838036ms
Jul  2 12:57:16.271: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01231953s
Jul  2 12:57:18.277: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017911402s
Jul  2 12:57:20.287: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028278702s
Jul  2 12:57:22.295: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.035851066s
Jul  2 12:57:24.302: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.043652412s
Jul  2 12:57:26.311: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.05201955s
Jul  2 12:57:26.311: INFO: Pod "busybox-user-65534-45e75ea6-9556-41ed-abed-bb52043a35cb" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  2 12:57:26.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3943" for this suite.

• [SLOW TEST:12.208 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:52
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":229,"skipped":3896,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:26.326: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1071
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:57:26.456: INFO: Creating deployment "test-recreate-deployment"
Jul  2 12:57:26.461: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jul  2 12:57:26.471: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jul  2 12:57:28.479: INFO: Waiting deployment "test-recreate-deployment" to complete
Jul  2 12:57:28.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 12, 57, 26, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 57, 26, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 57, 26, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 57, 26, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-845d658455\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:57:30.496: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jul  2 12:57:30.506: INFO: Updating deployment test-recreate-deployment
Jul  2 12:57:30.506: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Jul  2 12:57:30.615: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1071  4a072502-6706-4800-85b8-e6e3524d3345 24928 2 2022-07-02 12:57:26 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003fd44f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-07-02 12:57:30 +0000 UTC,LastTransitionTime:2022-07-02 12:57:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-cd8586fc7" is progressing.,LastUpdateTime:2022-07-02 12:57:30 +0000 UTC,LastTransitionTime:2022-07-02 12:57:26 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Jul  2 12:57:30.619: INFO: New ReplicaSet "test-recreate-deployment-cd8586fc7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-cd8586fc7  deployment-1071  3d83ae20-3060-4403-b178-93255a9bdd2b 24927 1 2022-07-02 12:57:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 4a072502-6706-4800-85b8-e6e3524d3345 0xc00411ab40 0xc00411ab41}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a072502-6706-4800-85b8-e6e3524d3345\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: cd8586fc7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[] [] []  []} {[] [] [{httpd k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00411abd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:57:30.619: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jul  2 12:57:30.619: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-845d658455  deployment-1071  d02321b3-ba98-4110-82bb-ec4f4e4ea4ab 24916 2 2022-07-02 12:57:26 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 4a072502-6706-4800-85b8-e6e3524d3345 0xc00411aa27 0xc00411aa28}] []  [{kube-controller-manager Update apps/v1 2022-07-02 12:57:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a072502-6706-4800-85b8-e6e3524d3345\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 845d658455,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:845d658455] map[] [] []  []} {[] [] [{agnhost k8s.gcr.io/e2e-test-images/agnhost:2.39 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00411aad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jul  2 12:57:30.623: INFO: Pod "test-recreate-deployment-cd8586fc7-7vvl9" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-cd8586fc7-7vvl9 test-recreate-deployment-cd8586fc7- deployment-1071  31fe4d84-33ce-4fcb-88d4-87da39dd58e4 24926 0 2022-07-02 12:57:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:cd8586fc7] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-cd8586fc7 3d83ae20-3060-4403-b178-93255a9bdd2b 0xc00411b120 0xc00411b121}] []  [{kube-controller-manager Update v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3d83ae20-3060-4403-b178-93255a9bdd2b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zdh5t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zdh5t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-9-92,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:57:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:57:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:57:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-07-02 12:57:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.9.92,PodIP:,StartTime:2022-07-02 12:57:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:k8s.gcr.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:188
Jul  2 12:57:30.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1071" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":356,"completed":230,"skipped":4012,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:30.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2998
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Service
STEP: watching for the Service to be added
Jul  2 12:57:30.784: INFO: Found Service test-service-4gk2t in namespace services-2998 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Jul  2 12:57:30.784: INFO: Service test-service-4gk2t created
STEP: Getting /status
Jul  2 12:57:30.790: INFO: Service test-service-4gk2t has LoadBalancer: {[]}
STEP: patching the ServiceStatus
STEP: watching for the Service to be patched
Jul  2 12:57:30.798: INFO: observed Service test-service-4gk2t in namespace services-2998 with annotations: map[] & LoadBalancer: {[]}
Jul  2 12:57:30.798: INFO: Found Service test-service-4gk2t in namespace services-2998 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Jul  2 12:57:30.798: INFO: Service test-service-4gk2t has service status patched
STEP: updating the ServiceStatus
Jul  2 12:57:30.808: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated
Jul  2 12:57:30.810: INFO: Observed Service test-service-4gk2t in namespace services-2998 with annotations: map[] & Conditions: {[]}
Jul  2 12:57:30.810: INFO: Observed event: &Service{ObjectMeta:{test-service-4gk2t  services-2998  bb52e6ae-e6dc-4571-8396-674fa9bb72fa 24938 0 2022-07-02 12:57:30 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] []  [{e2e.test Update v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-07-02 12:57:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.162,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.162],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Jul  2 12:57:30.810: INFO: Found Service test-service-4gk2t in namespace services-2998 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  2 12:57:30.810: INFO: Service test-service-4gk2t has service status updated
STEP: patching the service
STEP: watching for the Service to be patched
Jul  2 12:57:30.823: INFO: observed Service test-service-4gk2t in namespace services-2998 with labels: map[test-service-static:true]
Jul  2 12:57:30.823: INFO: observed Service test-service-4gk2t in namespace services-2998 with labels: map[test-service-static:true]
Jul  2 12:57:30.823: INFO: observed Service test-service-4gk2t in namespace services-2998 with labels: map[test-service-static:true]
Jul  2 12:57:30.823: INFO: Found Service test-service-4gk2t in namespace services-2998 with labels: map[test-service:patched test-service-static:true]
Jul  2 12:57:30.824: INFO: Service test-service-4gk2t patched
STEP: deleting the service
STEP: watching for the Service to be deleted
Jul  2 12:57:30.843: INFO: Observed event: ADDED
Jul  2 12:57:30.843: INFO: Observed event: MODIFIED
Jul  2 12:57:30.843: INFO: Observed event: MODIFIED
Jul  2 12:57:30.844: INFO: Observed event: MODIFIED
Jul  2 12:57:30.844: INFO: Found Service test-service-4gk2t in namespace services-2998 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Jul  2 12:57:30.844: INFO: Service test-service-4gk2t deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:57:30.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2998" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","total":356,"completed":231,"skipped":4024,"failed":0}
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:30.858: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4609
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with secret pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-secret-rhdt
STEP: Creating a pod to test atomic-volume-subpath
Jul  2 12:57:31.010: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rhdt" in namespace "subpath-4609" to be "Succeeded or Failed"
Jul  2 12:57:31.013: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.07536ms
Jul  2 12:57:33.020: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 2.010117866s
Jul  2 12:57:35.029: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 4.019091142s
Jul  2 12:57:37.040: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 6.029569954s
Jul  2 12:57:39.047: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 8.037146897s
Jul  2 12:57:41.056: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 10.045408488s
Jul  2 12:57:43.067: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 12.057083003s
Jul  2 12:57:45.076: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 14.066113535s
Jul  2 12:57:47.085: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 16.07453844s
Jul  2 12:57:49.092: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 18.081739839s
Jul  2 12:57:51.103: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=true. Elapsed: 20.093240281s
Jul  2 12:57:53.112: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Running", Reason="", readiness=false. Elapsed: 22.101452156s
Jul  2 12:57:55.118: INFO: Pod "pod-subpath-test-secret-rhdt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.107761464s
STEP: Saw pod success
Jul  2 12:57:55.118: INFO: Pod "pod-subpath-test-secret-rhdt" satisfied condition "Succeeded or Failed"
Jul  2 12:57:55.122: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-subpath-test-secret-rhdt container test-container-subpath-secret-rhdt: <nil>
STEP: delete the pod
Jul  2 12:57:55.153: INFO: Waiting for pod pod-subpath-test-secret-rhdt to disappear
Jul  2 12:57:55.156: INFO: Pod pod-subpath-test-secret-rhdt no longer exists
STEP: Deleting pod pod-subpath-test-secret-rhdt
Jul  2 12:57:55.156: INFO: Deleting pod "pod-subpath-test-secret-rhdt" in namespace "subpath-4609"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  2 12:57:55.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4609" for this suite.

• [SLOW TEST:24.314 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","total":356,"completed":232,"skipped":4029,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:55.173: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1169
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-a02d2f42-fe75-46a9-9dde-c7ba2d74b2a3
STEP: Creating a pod to test consume configMaps
Jul  2 12:57:55.323: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720" in namespace "projected-1169" to be "Succeeded or Failed"
Jul  2 12:57:55.326: INFO: Pod "pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720": Phase="Pending", Reason="", readiness=false. Elapsed: 3.449404ms
Jul  2 12:57:57.335: INFO: Pod "pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012070825s
Jul  2 12:57:59.346: INFO: Pod "pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023598563s
STEP: Saw pod success
Jul  2 12:57:59.346: INFO: Pod "pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720" satisfied condition "Succeeded or Failed"
Jul  2 12:57:59.350: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:57:59.380: INFO: Waiting for pod pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720 to disappear
Jul  2 12:57:59.383: INFO: Pod pod-projected-configmaps-569ac9df-17c3-4bed-9d34-ac17c6db5720 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 12:57:59.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1169" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":233,"skipped":4033,"failed":0}
S
------------------------------
[sig-node] Pods 
  should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:57:59.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2347
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: submitting the pod to kubernetes
Jul  2 12:57:59.551: INFO: The status of Pod pod-update-38285bbf-18c7-4142-b1cf-0b03b90da5fd is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:58:01.559: INFO: The status of Pod pod-update-38285bbf-18c7-4142-b1cf-0b03b90da5fd is Running (Ready = true)
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jul  2 12:58:02.082: INFO: Successfully updated pod "pod-update-38285bbf-18c7-4142-b1cf-0b03b90da5fd"
STEP: verifying the updated pod is in kubernetes
Jul  2 12:58:02.091: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 12:58:02.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2347" for this suite.
•{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","total":356,"completed":234,"skipped":4034,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] CronJob 
  should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:02.103: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename cronjob
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in cronjob-7888
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support CronJob API operations [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: creating
STEP: getting
STEP: listing
STEP: watching
Jul  2 12:58:02.252: INFO: starting watch
STEP: cluster-wide listing
STEP: cluster-wide watching
Jul  2 12:58:02.255: INFO: starting watch
STEP: patching
STEP: updating
Jul  2 12:58:02.271: INFO: waiting for watch events with expected annotations
Jul  2 12:58:02.272: INFO: saw patched and updated annotations
STEP: patching /status
STEP: updating /status
STEP: get /status
STEP: deleting
STEP: deleting a collection
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  2 12:58:02.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-7888" for this suite.
•{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","total":356,"completed":235,"skipped":4042,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:02.330: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-145
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:58:02.472: INFO: The status of Pod busybox-host-aliases8f35ca08-5782-4424-99e3-00522dca54a7 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:58:04.481: INFO: The status of Pod busybox-host-aliases8f35ca08-5782-4424-99e3-00522dca54a7 is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  2 12:58:04.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-145" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":236,"skipped":4052,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:04.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5664
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ConfigMap
STEP: fetching the ConfigMap
STEP: patching the ConfigMap
STEP: listing all ConfigMaps in all namespaces with a label selector
STEP: deleting the ConfigMap by collection with a label selector
STEP: listing all ConfigMaps in test namespace
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:58:04.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5664" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","total":356,"completed":237,"skipped":4061,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:04.696: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3370
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  2 12:58:04.831: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  2 12:58:04.840: INFO: Waiting for terminating namespaces to be deleted...
Jul  2 12:58:04.843: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-69-95 before test
Jul  2 12:58:04.849: INFO: nginx-ingress-controller-kubernetes-worker-7hv6n from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:21 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.849: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 12:58:04.849: INFO: busybox-host-aliases8f35ca08-5782-4424-99e3-00522dca54a7 from kubelet-test-145 started at 2022-07-02 12:58:02 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.849: INFO: 	Container busybox-host-aliases8f35ca08-5782-4424-99e3-00522dca54a7 ready: true, restart count 0
Jul  2 12:58:04.849: INFO: sonobuoy-e2e-job-6916416ad43a4efe from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:58:04.849: INFO: 	Container e2e ready: true, restart count 0
Jul  2 12:58:04.849: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:58:04.849: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-z6zqf from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:58:04.849: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:58:04.849: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 12:58:04.849: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-9-92 before test
Jul  2 12:58:04.855: INFO: nginx-ingress-controller-kubernetes-worker-j6wk6 from ingress-nginx-kubernetes-worker started at 2022-07-02 12:48:25 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.855: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 12:58:04.855: INFO: pod-update-38285bbf-18c7-4142-b1cf-0b03b90da5fd from pods-2347 started at 2022-07-02 12:57:59 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.855: INFO: 	Container nginx ready: true, restart count 0
Jul  2 12:58:04.855: INFO: sonobuoy from sonobuoy started at 2022-07-02 11:53:23 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.855: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  2 12:58:04.855: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-x2r94 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:58:04.855: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:58:04.855: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 12:58:04.855: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-91-232 before test
Jul  2 12:58:04.861: INFO: default-http-backend-kubernetes-worker-6c59687bf6-gqrng from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 1
Jul  2 12:58:04.861: INFO: nginx-ingress-controller-kubernetes-worker-xvwtz from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 12:58:04.861: INFO: calico-kube-controllers-7f4ccc6cf4-qt6b5 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  2 12:58:04.861: INFO: coredns-86c98bfcdb-tftgb from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container coredns ready: true, restart count 0
Jul  2 12:58:04.861: INFO: kube-state-metrics-5cdbfd47b4-xkmd6 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jul  2 12:58:04.861: INFO: metrics-server-v0.5.2-6bfd958b56-2pqsv from kube-system started at 2022-07-02 11:49:20 +0000 UTC (2 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container metrics-server ready: true, restart count 0
Jul  2 12:58:04.861: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jul  2 12:58:04.861: INFO: dashboard-metrics-scraper-8669b59d4f-ftfm8 from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Jul  2 12:58:04.861: INFO: kubernetes-dashboard-585fc6bc87-ls4qj from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jul  2 12:58:04.861: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-4w8j4 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 12:58:04.861: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 12:58:04.861: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/framework/framework.go:652
STEP: verifying the node has the label node ip-172-31-69-95
STEP: verifying the node has the label node ip-172-31-9-92
STEP: verifying the node has the label node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod default-http-backend-kubernetes-worker-6c59687bf6-gqrng requesting resource cpu=10m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod nginx-ingress-controller-kubernetes-worker-7hv6n requesting resource cpu=0m on Node ip-172-31-69-95
Jul  2 12:58:04.914: INFO: Pod nginx-ingress-controller-kubernetes-worker-j6wk6 requesting resource cpu=0m on Node ip-172-31-9-92
Jul  2 12:58:04.914: INFO: Pod nginx-ingress-controller-kubernetes-worker-xvwtz requesting resource cpu=0m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod calico-kube-controllers-7f4ccc6cf4-qt6b5 requesting resource cpu=0m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod coredns-86c98bfcdb-tftgb requesting resource cpu=100m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod kube-state-metrics-5cdbfd47b4-xkmd6 requesting resource cpu=0m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod metrics-server-v0.5.2-6bfd958b56-2pqsv requesting resource cpu=5m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod busybox-host-aliases8f35ca08-5782-4424-99e3-00522dca54a7 requesting resource cpu=0m on Node ip-172-31-69-95
Jul  2 12:58:04.914: INFO: Pod dashboard-metrics-scraper-8669b59d4f-ftfm8 requesting resource cpu=0m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod kubernetes-dashboard-585fc6bc87-ls4qj requesting resource cpu=0m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod pod-update-38285bbf-18c7-4142-b1cf-0b03b90da5fd requesting resource cpu=0m on Node ip-172-31-9-92
Jul  2 12:58:04.914: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-9-92
Jul  2 12:58:04.914: INFO: Pod sonobuoy-e2e-job-6916416ad43a4efe requesting resource cpu=0m on Node ip-172-31-69-95
Jul  2 12:58:04.914: INFO: Pod sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-4w8j4 requesting resource cpu=0m on Node ip-172-31-91-232
Jul  2 12:58:04.914: INFO: Pod sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-x2r94 requesting resource cpu=0m on Node ip-172-31-9-92
Jul  2 12:58:04.914: INFO: Pod sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-z6zqf requesting resource cpu=0m on Node ip-172-31-69-95
STEP: Starting Pods to consume most of the cluster CPU.
Jul  2 12:58:04.914: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-69-95
Jul  2 12:58:04.922: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-9-92
Jul  2 12:58:04.930: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-91-232
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40fb6dbb-61d6-48a2-ad18-f3dd664fc3b4.16fe0485a35f07ce], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3370/filler-pod-40fb6dbb-61d6-48a2-ad18-f3dd664fc3b4 to ip-172-31-9-92]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40fb6dbb-61d6-48a2-ad18-f3dd664fc3b4.16fe0485cc0569cd], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40fb6dbb-61d6-48a2-ad18-f3dd664fc3b4.16fe0485d0e369c3], Reason = [Created], Message = [Created container filler-pod-40fb6dbb-61d6-48a2-ad18-f3dd664fc3b4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40fb6dbb-61d6-48a2-ad18-f3dd664fc3b4.16fe0485d60051c9], Reason = [Started], Message = [Started container filler-pod-40fb6dbb-61d6-48a2-ad18-f3dd664fc3b4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-982d3ed2-2f2c-46cf-b41d-5de39032ce1a.16fe0485a2ff435c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3370/filler-pod-982d3ed2-2f2c-46cf-b41d-5de39032ce1a to ip-172-31-69-95]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-982d3ed2-2f2c-46cf-b41d-5de39032ce1a.16fe0485caae1305], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-982d3ed2-2f2c-46cf-b41d-5de39032ce1a.16fe0485ce96231d], Reason = [Created], Message = [Created container filler-pod-982d3ed2-2f2c-46cf-b41d-5de39032ce1a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-982d3ed2-2f2c-46cf-b41d-5de39032ce1a.16fe0485d3aa0f1e], Reason = [Started], Message = [Started container filler-pod-982d3ed2-2f2c-46cf-b41d-5de39032ce1a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf2c214-82d3-4967-8cda-609197bfe54b.16fe0485a3f2a896], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3370/filler-pod-daf2c214-82d3-4967-8cda-609197bfe54b to ip-172-31-91-232]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf2c214-82d3-4967-8cda-609197bfe54b.16fe0485cd42dbb0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.7" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf2c214-82d3-4967-8cda-609197bfe54b.16fe0485d0f9ad13], Reason = [Created], Message = [Created container filler-pod-daf2c214-82d3-4967-8cda-609197bfe54b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-daf2c214-82d3-4967-8cda-609197bfe54b.16fe0485d49d3219], Reason = [Started], Message = [Started container filler-pod-daf2c214-82d3-4967-8cda-609197bfe54b]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16fe04861cf36103], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {juju.is/kubernetes-control-plane: true}, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.]
STEP: removing the label node off the node ip-172-31-69-95
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-9-92
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-172-31-91-232
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  2 12:58:08.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3370" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":356,"completed":238,"skipped":4081,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:08.059: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1650
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1334
STEP: creating the pod
Jul  2 12:58:08.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 create -f -'
Jul  2 12:58:08.365: INFO: stderr: ""
Jul  2 12:58:08.365: INFO: stdout: "pod/pause created\n"
Jul  2 12:58:08.365: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jul  2 12:58:08.365: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1650" to be "running and ready"
Jul  2 12:58:08.370: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.627079ms
Jul  2 12:58:10.377: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.011819043s
Jul  2 12:58:10.377: INFO: Pod "pause" satisfied condition "running and ready"
Jul  2 12:58:10.377: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/framework/framework.go:652
STEP: adding the label testing-label with value testing-label-value to a pod
Jul  2 12:58:10.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 label pods pause testing-label=testing-label-value'
Jul  2 12:58:10.448: INFO: stderr: ""
Jul  2 12:58:10.448: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jul  2 12:58:10.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 get pod pause -L testing-label'
Jul  2 12:58:10.501: INFO: stderr: ""
Jul  2 12:58:10.501: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jul  2 12:58:10.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 label pods pause testing-label-'
Jul  2 12:58:10.569: INFO: stderr: ""
Jul  2 12:58:10.569: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jul  2 12:58:10.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 get pod pause -L testing-label'
Jul  2 12:58:10.638: INFO: stderr: ""
Jul  2 12:58:10.638: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1340
STEP: using delete to clean up resources
Jul  2 12:58:10.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 delete --grace-period=0 --force -f -'
Jul  2 12:58:10.709: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jul  2 12:58:10.709: INFO: stdout: "pod \"pause\" force deleted\n"
Jul  2 12:58:10.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 get rc,svc -l name=pause --no-headers'
Jul  2 12:58:10.769: INFO: stderr: "No resources found in kubectl-1650 namespace.\n"
Jul  2 12:58:10.770: INFO: stdout: ""
Jul  2 12:58:10.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1650 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jul  2 12:58:10.822: INFO: stderr: ""
Jul  2 12:58:10.822: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:58:10.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1650" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":356,"completed":239,"skipped":4120,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:10.833: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7096
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-7096/configmap-test-bb1670fb-b22d-4fbb-969d-015e4873dcdf
STEP: Creating a pod to test consume configMaps
Jul  2 12:58:10.979: INFO: Waiting up to 5m0s for pod "pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3" in namespace "configmap-7096" to be "Succeeded or Failed"
Jul  2 12:58:10.983: INFO: Pod "pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1398ms
Jul  2 12:58:12.992: INFO: Pod "pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012805683s
Jul  2 12:58:15.000: INFO: Pod "pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020712769s
STEP: Saw pod success
Jul  2 12:58:15.000: INFO: Pod "pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3" satisfied condition "Succeeded or Failed"
Jul  2 12:58:15.004: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3 container env-test: <nil>
STEP: delete the pod
Jul  2 12:58:15.024: INFO: Waiting for pod pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3 to disappear
Jul  2 12:58:15.027: INFO: Pod pod-configmaps-a478edc8-1c58-4040-a708-7dc6d304e4e3 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 12:58:15.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7096" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":356,"completed":240,"skipped":4148,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run 
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:15.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7834
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  2 12:58:15.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-7834 run e2e-test-httpd-pod --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Jul  2 12:58:15.238: INFO: stderr: ""
Jul  2 12:58:15.238: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run
Jul  2 12:58:15.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-7834 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "k8s.gcr.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Jul  2 12:58:15.670: INFO: stderr: ""
Jul  2 12:58:15.670: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  2 12:58:15.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-7834 delete pods e2e-test-httpd-pod'
Jul  2 12:58:17.381: INFO: stderr: ""
Jul  2 12:58:17.381: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:58:17.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7834" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","total":356,"completed":241,"skipped":4157,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:17.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-2763
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jul  2 12:58:17.911: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 12:58:20.938: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:58:20.944: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 12:58:24.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2763" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139

• [SLOW TEST:6.745 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":356,"completed":242,"skipped":4174,"failed":0}
SSSS
------------------------------
[sig-node] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:24.142: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-2308
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
Jul  2 12:58:24.358: INFO: The status of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:58:26.367: INFO: The status of Pod test-pod is Running (Ready = true)
STEP: Creating hostNetwork=true pod
Jul  2 12:58:26.383: INFO: The status of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Jul  2 12:58:28.388: INFO: The status of Pod test-host-network-pod is Running (Ready = true)
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jul  2 12:58:28.391: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.391: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.392: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.392: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  2 12:58:28.494: INFO: Exec stderr: ""
Jul  2 12:58:28.494: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.494: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.495: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.495: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  2 12:58:28.576: INFO: Exec stderr: ""
Jul  2 12:58:28.576: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.576: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.577: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.577: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  2 12:58:28.634: INFO: Exec stderr: ""
Jul  2 12:58:28.635: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.635: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.635: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.635: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  2 12:58:28.716: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jul  2 12:58:28.716: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.716: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.717: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.717: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jul  2 12:58:28.768: INFO: Exec stderr: ""
Jul  2 12:58:28.768: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.769: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.769: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Jul  2 12:58:28.840: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jul  2 12:58:28.840: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.840: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.840: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  2 12:58:28.923: INFO: Exec stderr: ""
Jul  2 12:58:28.923: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:28.923: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:28.923: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:28.923: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Jul  2 12:58:29.010: INFO: Exec stderr: ""
Jul  2 12:58:29.010: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:29.010: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:29.011: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:29.011: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  2 12:58:29.081: INFO: Exec stderr: ""
Jul  2 12:58:29.081: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2308 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 12:58:29.081: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 12:58:29.081: INFO: ExecWithOptions: Clientset creation
Jul  2 12:58:29.081: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2308/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Jul  2 12:58:29.157: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:188
Jul  2 12:58:29.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2308" for this suite.

• [SLOW TEST:5.030 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":243,"skipped":4178,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:29.172: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-8246
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:79
Jul  2 12:58:29.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the sample API server.
Jul  2 12:58:29.460: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jul  2 12:58:31.512: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:58:33.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:58:35.520: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:58:37.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 12, 58, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-d9646c97b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 12:58:42.350: INFO: Waited 2.815973617s for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}'
STEP: List APIServices
Jul  2 12:58:42.428: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:69
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:188
Jul  2 12:58:42.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8246" for this suite.

• [SLOW TEST:13.769 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":356,"completed":244,"skipped":4182,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:42.942: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3981
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check is all data is printed  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 12:58:43.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-3981 version'
Jul  2 12:58:43.144: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Jul  2 12:58:43.144: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.2\", GitCommit:\"f66044f4361b9f1f96f0053dd46cb7dce5e990a8\", GitTreeState:\"clean\", BuildDate:\"2022-06-15T14:22:29Z\", GoVersion:\"go1.18.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.4\nServer Version: version.Info{Major:\"1\", Minor:\"24\", GitVersion:\"v1.24.2\", GitCommit:\"f66044f4361b9f1f96f0053dd46cb7dce5e990a8\", GitTreeState:\"clean\", BuildDate:\"2022-06-17T21:59:56Z\", GoVersion:\"go1.18.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 12:58:43.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3981" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":356,"completed":245,"skipped":4209,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:43.160: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-979
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a collection of services
Jul  2 12:58:43.297: INFO: Creating e2e-svc-a-g267s
Jul  2 12:58:43.312: INFO: Creating e2e-svc-b-r24kw
Jul  2 12:58:43.326: INFO: Creating e2e-svc-c-bvzhm
STEP: deleting service collection
Jul  2 12:58:43.382: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 12:58:43.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-979" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","total":356,"completed":246,"skipped":4226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:58:43.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3381
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Jul  2 12:59:23.626: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0702 12:59:23.626036      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul  2 12:59:23.626: INFO: Deleting pod "simpletest.rc-24b8t" in namespace "gc-3381"
Jul  2 12:59:23.645: INFO: Deleting pod "simpletest.rc-24v8p" in namespace "gc-3381"
Jul  2 12:59:23.665: INFO: Deleting pod "simpletest.rc-2mznz" in namespace "gc-3381"
Jul  2 12:59:23.689: INFO: Deleting pod "simpletest.rc-2vnqm" in namespace "gc-3381"
Jul  2 12:59:23.709: INFO: Deleting pod "simpletest.rc-2wds9" in namespace "gc-3381"
Jul  2 12:59:23.732: INFO: Deleting pod "simpletest.rc-2wswn" in namespace "gc-3381"
Jul  2 12:59:23.747: INFO: Deleting pod "simpletest.rc-2zh9j" in namespace "gc-3381"
Jul  2 12:59:23.765: INFO: Deleting pod "simpletest.rc-49p79" in namespace "gc-3381"
Jul  2 12:59:23.777: INFO: Deleting pod "simpletest.rc-4sqwj" in namespace "gc-3381"
Jul  2 12:59:23.834: INFO: Deleting pod "simpletest.rc-4xnvs" in namespace "gc-3381"
Jul  2 12:59:23.852: INFO: Deleting pod "simpletest.rc-5dck6" in namespace "gc-3381"
Jul  2 12:59:23.873: INFO: Deleting pod "simpletest.rc-5nj2k" in namespace "gc-3381"
Jul  2 12:59:23.888: INFO: Deleting pod "simpletest.rc-5p2fs" in namespace "gc-3381"
Jul  2 12:59:23.909: INFO: Deleting pod "simpletest.rc-62c9v" in namespace "gc-3381"
Jul  2 12:59:23.924: INFO: Deleting pod "simpletest.rc-69bs9" in namespace "gc-3381"
Jul  2 12:59:23.940: INFO: Deleting pod "simpletest.rc-6b5fw" in namespace "gc-3381"
Jul  2 12:59:23.952: INFO: Deleting pod "simpletest.rc-6cmhv" in namespace "gc-3381"
Jul  2 12:59:23.968: INFO: Deleting pod "simpletest.rc-6ddsc" in namespace "gc-3381"
Jul  2 12:59:23.987: INFO: Deleting pod "simpletest.rc-6wzp7" in namespace "gc-3381"
Jul  2 12:59:24.000: INFO: Deleting pod "simpletest.rc-772dn" in namespace "gc-3381"
Jul  2 12:59:24.016: INFO: Deleting pod "simpletest.rc-7dct4" in namespace "gc-3381"
Jul  2 12:59:24.028: INFO: Deleting pod "simpletest.rc-7hrbb" in namespace "gc-3381"
Jul  2 12:59:24.043: INFO: Deleting pod "simpletest.rc-8n2l8" in namespace "gc-3381"
Jul  2 12:59:24.054: INFO: Deleting pod "simpletest.rc-8nfw9" in namespace "gc-3381"
Jul  2 12:59:24.070: INFO: Deleting pod "simpletest.rc-8p4d6" in namespace "gc-3381"
Jul  2 12:59:24.083: INFO: Deleting pod "simpletest.rc-9gn52" in namespace "gc-3381"
Jul  2 12:59:24.098: INFO: Deleting pod "simpletest.rc-9kjmr" in namespace "gc-3381"
Jul  2 12:59:24.115: INFO: Deleting pod "simpletest.rc-bb68x" in namespace "gc-3381"
Jul  2 12:59:24.126: INFO: Deleting pod "simpletest.rc-blqp5" in namespace "gc-3381"
Jul  2 12:59:24.144: INFO: Deleting pod "simpletest.rc-bq9jr" in namespace "gc-3381"
Jul  2 12:59:24.161: INFO: Deleting pod "simpletest.rc-c4nr6" in namespace "gc-3381"
Jul  2 12:59:24.175: INFO: Deleting pod "simpletest.rc-c9ff4" in namespace "gc-3381"
Jul  2 12:59:24.191: INFO: Deleting pod "simpletest.rc-cc87j" in namespace "gc-3381"
Jul  2 12:59:24.203: INFO: Deleting pod "simpletest.rc-cr8zb" in namespace "gc-3381"
Jul  2 12:59:24.215: INFO: Deleting pod "simpletest.rc-cw7pg" in namespace "gc-3381"
Jul  2 12:59:24.230: INFO: Deleting pod "simpletest.rc-dl5l4" in namespace "gc-3381"
Jul  2 12:59:24.244: INFO: Deleting pod "simpletest.rc-dz6wf" in namespace "gc-3381"
Jul  2 12:59:24.261: INFO: Deleting pod "simpletest.rc-f7p7h" in namespace "gc-3381"
Jul  2 12:59:24.272: INFO: Deleting pod "simpletest.rc-ffc6c" in namespace "gc-3381"
Jul  2 12:59:24.284: INFO: Deleting pod "simpletest.rc-fgwzl" in namespace "gc-3381"
Jul  2 12:59:24.300: INFO: Deleting pod "simpletest.rc-fw94z" in namespace "gc-3381"
Jul  2 12:59:24.314: INFO: Deleting pod "simpletest.rc-ggbsr" in namespace "gc-3381"
Jul  2 12:59:24.326: INFO: Deleting pod "simpletest.rc-gjjvp" in namespace "gc-3381"
Jul  2 12:59:24.338: INFO: Deleting pod "simpletest.rc-gtshj" in namespace "gc-3381"
Jul  2 12:59:24.350: INFO: Deleting pod "simpletest.rc-h6t6j" in namespace "gc-3381"
Jul  2 12:59:24.360: INFO: Deleting pod "simpletest.rc-h9q2h" in namespace "gc-3381"
Jul  2 12:59:24.377: INFO: Deleting pod "simpletest.rc-hc42t" in namespace "gc-3381"
Jul  2 12:59:24.389: INFO: Deleting pod "simpletest.rc-hkvmx" in namespace "gc-3381"
Jul  2 12:59:24.401: INFO: Deleting pod "simpletest.rc-hqwlf" in namespace "gc-3381"
Jul  2 12:59:24.418: INFO: Deleting pod "simpletest.rc-hsgvq" in namespace "gc-3381"
Jul  2 12:59:24.429: INFO: Deleting pod "simpletest.rc-jdztp" in namespace "gc-3381"
Jul  2 12:59:24.443: INFO: Deleting pod "simpletest.rc-jhjjz" in namespace "gc-3381"
Jul  2 12:59:24.454: INFO: Deleting pod "simpletest.rc-kbjvr" in namespace "gc-3381"
Jul  2 12:59:24.466: INFO: Deleting pod "simpletest.rc-kn2sc" in namespace "gc-3381"
Jul  2 12:59:24.480: INFO: Deleting pod "simpletest.rc-l7hqm" in namespace "gc-3381"
Jul  2 12:59:24.495: INFO: Deleting pod "simpletest.rc-l8t8r" in namespace "gc-3381"
Jul  2 12:59:24.508: INFO: Deleting pod "simpletest.rc-ljmv8" in namespace "gc-3381"
Jul  2 12:59:24.524: INFO: Deleting pod "simpletest.rc-lm9v5" in namespace "gc-3381"
Jul  2 12:59:24.535: INFO: Deleting pod "simpletest.rc-lpw98" in namespace "gc-3381"
Jul  2 12:59:24.545: INFO: Deleting pod "simpletest.rc-m5bm9" in namespace "gc-3381"
Jul  2 12:59:24.557: INFO: Deleting pod "simpletest.rc-m772d" in namespace "gc-3381"
Jul  2 12:59:24.570: INFO: Deleting pod "simpletest.rc-mb8f8" in namespace "gc-3381"
Jul  2 12:59:24.585: INFO: Deleting pod "simpletest.rc-ngdcr" in namespace "gc-3381"
Jul  2 12:59:24.601: INFO: Deleting pod "simpletest.rc-nmcnj" in namespace "gc-3381"
Jul  2 12:59:24.612: INFO: Deleting pod "simpletest.rc-ntbx5" in namespace "gc-3381"
Jul  2 12:59:24.624: INFO: Deleting pod "simpletest.rc-p7gbl" in namespace "gc-3381"
Jul  2 12:59:24.636: INFO: Deleting pod "simpletest.rc-pb8bh" in namespace "gc-3381"
Jul  2 12:59:24.648: INFO: Deleting pod "simpletest.rc-pbslh" in namespace "gc-3381"
Jul  2 12:59:24.660: INFO: Deleting pod "simpletest.rc-pbtlk" in namespace "gc-3381"
Jul  2 12:59:24.671: INFO: Deleting pod "simpletest.rc-pjjxz" in namespace "gc-3381"
Jul  2 12:59:24.702: INFO: Deleting pod "simpletest.rc-pmdl5" in namespace "gc-3381"
Jul  2 12:59:24.751: INFO: Deleting pod "simpletest.rc-qcq7l" in namespace "gc-3381"
Jul  2 12:59:24.804: INFO: Deleting pod "simpletest.rc-qqw7g" in namespace "gc-3381"
Jul  2 12:59:24.852: INFO: Deleting pod "simpletest.rc-r8mkg" in namespace "gc-3381"
Jul  2 12:59:24.903: INFO: Deleting pod "simpletest.rc-s6jjw" in namespace "gc-3381"
Jul  2 12:59:24.952: INFO: Deleting pod "simpletest.rc-s8krw" in namespace "gc-3381"
Jul  2 12:59:25.006: INFO: Deleting pod "simpletest.rc-sfhnm" in namespace "gc-3381"
Jul  2 12:59:25.051: INFO: Deleting pod "simpletest.rc-tf4hf" in namespace "gc-3381"
Jul  2 12:59:25.103: INFO: Deleting pod "simpletest.rc-tmsf5" in namespace "gc-3381"
Jul  2 12:59:25.151: INFO: Deleting pod "simpletest.rc-v2qc9" in namespace "gc-3381"
Jul  2 12:59:25.204: INFO: Deleting pod "simpletest.rc-v4hkd" in namespace "gc-3381"
Jul  2 12:59:25.256: INFO: Deleting pod "simpletest.rc-v4sgz" in namespace "gc-3381"
Jul  2 12:59:25.305: INFO: Deleting pod "simpletest.rc-vdpxp" in namespace "gc-3381"
Jul  2 12:59:25.352: INFO: Deleting pod "simpletest.rc-vdz6p" in namespace "gc-3381"
Jul  2 12:59:25.408: INFO: Deleting pod "simpletest.rc-vfh7h" in namespace "gc-3381"
Jul  2 12:59:25.455: INFO: Deleting pod "simpletest.rc-vgw5h" in namespace "gc-3381"
Jul  2 12:59:25.504: INFO: Deleting pod "simpletest.rc-vmgzs" in namespace "gc-3381"
Jul  2 12:59:25.555: INFO: Deleting pod "simpletest.rc-vscr8" in namespace "gc-3381"
Jul  2 12:59:25.601: INFO: Deleting pod "simpletest.rc-vwqmw" in namespace "gc-3381"
Jul  2 12:59:25.652: INFO: Deleting pod "simpletest.rc-w7n9w" in namespace "gc-3381"
Jul  2 12:59:25.702: INFO: Deleting pod "simpletest.rc-wbq8h" in namespace "gc-3381"
Jul  2 12:59:25.756: INFO: Deleting pod "simpletest.rc-wf6c2" in namespace "gc-3381"
Jul  2 12:59:25.802: INFO: Deleting pod "simpletest.rc-wq989" in namespace "gc-3381"
Jul  2 12:59:25.853: INFO: Deleting pod "simpletest.rc-wtdjb" in namespace "gc-3381"
Jul  2 12:59:25.904: INFO: Deleting pod "simpletest.rc-xc7f2" in namespace "gc-3381"
Jul  2 12:59:25.954: INFO: Deleting pod "simpletest.rc-xdzqt" in namespace "gc-3381"
Jul  2 12:59:26.003: INFO: Deleting pod "simpletest.rc-xjhh2" in namespace "gc-3381"
Jul  2 12:59:26.055: INFO: Deleting pod "simpletest.rc-xr288" in namespace "gc-3381"
Jul  2 12:59:26.107: INFO: Deleting pod "simpletest.rc-zbfrs" in namespace "gc-3381"
Jul  2 12:59:26.150: INFO: Deleting pod "simpletest.rc-zxj2w" in namespace "gc-3381"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  2 12:59:26.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3381" for this suite.

• [SLOW TEST:42.901 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":356,"completed":247,"skipped":4249,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:59:26.297: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3367
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:59:26.441: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68" in namespace "downward-api-3367" to be "Succeeded or Failed"
Jul  2 12:59:26.445: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.970467ms
Jul  2 12:59:28.455: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014010803s
Jul  2 12:59:30.470: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028985229s
Jul  2 12:59:32.478: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036796259s
Jul  2 12:59:34.486: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68": Phase="Pending", Reason="", readiness=false. Elapsed: 8.044704326s
Jul  2 12:59:36.494: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68": Phase="Pending", Reason="", readiness=false. Elapsed: 10.052550778s
Jul  2 12:59:38.499: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.058039801s
STEP: Saw pod success
Jul  2 12:59:38.499: INFO: Pod "downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68" satisfied condition "Succeeded or Failed"
Jul  2 12:59:38.504: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68 container client-container: <nil>
STEP: delete the pod
Jul  2 12:59:38.524: INFO: Waiting for pod downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68 to disappear
Jul  2 12:59:38.527: INFO: Pod downwardapi-volume-ff73b2c7-ed4e-47d5-806a-5bcb4577de68 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 12:59:38.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3367" for this suite.

• [SLOW TEST:12.241 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":248,"skipped":4256,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:59:38.538: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6621
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 12:59:38.677: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab" in namespace "downward-api-6621" to be "Succeeded or Failed"
Jul  2 12:59:38.680: INFO: Pod "downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab": Phase="Pending", Reason="", readiness=false. Elapsed: 3.074993ms
Jul  2 12:59:40.688: INFO: Pod "downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01136428s
Jul  2 12:59:42.697: INFO: Pod "downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019499411s
STEP: Saw pod success
Jul  2 12:59:42.697: INFO: Pod "downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab" satisfied condition "Succeeded or Failed"
Jul  2 12:59:42.700: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab container client-container: <nil>
STEP: delete the pod
Jul  2 12:59:42.732: INFO: Waiting for pod downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab to disappear
Jul  2 12:59:42.735: INFO: Pod downwardapi-volume-7c18e03f-df36-4038-bd7d-c5fe3484d5ab no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 12:59:42.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6621" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":356,"completed":249,"skipped":4257,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:59:42.748: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6121
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount projected service account token [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test service account token: 
Jul  2 12:59:42.893: INFO: Waiting up to 5m0s for pod "test-pod-5979234f-d446-47a0-b3be-7e3906767b8c" in namespace "svcaccounts-6121" to be "Succeeded or Failed"
Jul  2 12:59:42.897: INFO: Pod "test-pod-5979234f-d446-47a0-b3be-7e3906767b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.392223ms
Jul  2 12:59:44.907: INFO: Pod "test-pod-5979234f-d446-47a0-b3be-7e3906767b8c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013491483s
Jul  2 12:59:46.915: INFO: Pod "test-pod-5979234f-d446-47a0-b3be-7e3906767b8c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021189367s
STEP: Saw pod success
Jul  2 12:59:46.915: INFO: Pod "test-pod-5979234f-d446-47a0-b3be-7e3906767b8c" satisfied condition "Succeeded or Failed"
Jul  2 12:59:46.919: INFO: Trying to get logs from node ip-172-31-9-92 pod test-pod-5979234f-d446-47a0-b3be-7e3906767b8c container agnhost-container: <nil>
STEP: delete the pod
Jul  2 12:59:46.938: INFO: Waiting for pod test-pod-5979234f-d446-47a0-b3be-7e3906767b8c to disappear
Jul  2 12:59:46.944: INFO: Pod test-pod-5979234f-d446-47a0-b3be-7e3906767b8c no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  2 12:59:46.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6121" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","total":356,"completed":250,"skipped":4361,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob 
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 12:59:46.960: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename cronjob
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in cronjob-769
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a cronjob
STEP: Ensuring more than one job is running at a time
STEP: Ensuring at least two running jobs exists by listing jobs explicitly
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  2 13:01:01.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-769" for this suite.

• [SLOW TEST:74.177 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","total":356,"completed":251,"skipped":4376,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:01:01.138: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4185
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
Jul  2 13:01:11.697: INFO: 70 pods remaining
Jul  2 13:01:11.698: INFO: 70 pods has nil DeletionTimestamp
Jul  2 13:01:11.698: INFO: 
STEP: Gathering metrics
W0702 13:01:16.710811      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul  2 13:01:16.710: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Jul  2 13:01:16.710: INFO: Deleting pod "simpletest-rc-to-be-deleted-228v6" in namespace "gc-4185"
Jul  2 13:01:16.725: INFO: Deleting pod "simpletest-rc-to-be-deleted-2wssc" in namespace "gc-4185"
Jul  2 13:01:16.743: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fzfr" in namespace "gc-4185"
Jul  2 13:01:16.759: INFO: Deleting pod "simpletest-rc-to-be-deleted-4p44z" in namespace "gc-4185"
Jul  2 13:01:16.770: INFO: Deleting pod "simpletest-rc-to-be-deleted-5c2c8" in namespace "gc-4185"
Jul  2 13:01:16.787: INFO: Deleting pod "simpletest-rc-to-be-deleted-5l4b4" in namespace "gc-4185"
Jul  2 13:01:16.801: INFO: Deleting pod "simpletest-rc-to-be-deleted-65p74" in namespace "gc-4185"
Jul  2 13:01:16.815: INFO: Deleting pod "simpletest-rc-to-be-deleted-69vt7" in namespace "gc-4185"
Jul  2 13:01:16.827: INFO: Deleting pod "simpletest-rc-to-be-deleted-69x9p" in namespace "gc-4185"
Jul  2 13:01:16.844: INFO: Deleting pod "simpletest-rc-to-be-deleted-6mrzr" in namespace "gc-4185"
Jul  2 13:01:16.860: INFO: Deleting pod "simpletest-rc-to-be-deleted-6n7kv" in namespace "gc-4185"
Jul  2 13:01:16.875: INFO: Deleting pod "simpletest-rc-to-be-deleted-7chdp" in namespace "gc-4185"
Jul  2 13:01:16.891: INFO: Deleting pod "simpletest-rc-to-be-deleted-7vfm7" in namespace "gc-4185"
Jul  2 13:01:16.906: INFO: Deleting pod "simpletest-rc-to-be-deleted-9cvn9" in namespace "gc-4185"
Jul  2 13:01:16.918: INFO: Deleting pod "simpletest-rc-to-be-deleted-9dg7p" in namespace "gc-4185"
Jul  2 13:01:16.932: INFO: Deleting pod "simpletest-rc-to-be-deleted-9k6dr" in namespace "gc-4185"
Jul  2 13:01:16.947: INFO: Deleting pod "simpletest-rc-to-be-deleted-9plh9" in namespace "gc-4185"
Jul  2 13:01:16.958: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rssq" in namespace "gc-4185"
Jul  2 13:01:16.973: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rv8s" in namespace "gc-4185"
Jul  2 13:01:16.986: INFO: Deleting pod "simpletest-rc-to-be-deleted-bjmm9" in namespace "gc-4185"
Jul  2 13:01:16.997: INFO: Deleting pod "simpletest-rc-to-be-deleted-c8q24" in namespace "gc-4185"
Jul  2 13:01:17.009: INFO: Deleting pod "simpletest-rc-to-be-deleted-cd9t6" in namespace "gc-4185"
Jul  2 13:01:17.022: INFO: Deleting pod "simpletest-rc-to-be-deleted-chj48" in namespace "gc-4185"
Jul  2 13:01:17.034: INFO: Deleting pod "simpletest-rc-to-be-deleted-chsbs" in namespace "gc-4185"
Jul  2 13:01:17.053: INFO: Deleting pod "simpletest-rc-to-be-deleted-cxfdl" in namespace "gc-4185"
Jul  2 13:01:17.070: INFO: Deleting pod "simpletest-rc-to-be-deleted-cz2c7" in namespace "gc-4185"
Jul  2 13:01:17.084: INFO: Deleting pod "simpletest-rc-to-be-deleted-dcvzn" in namespace "gc-4185"
Jul  2 13:01:17.097: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnj96" in namespace "gc-4185"
Jul  2 13:01:17.117: INFO: Deleting pod "simpletest-rc-to-be-deleted-dwpfj" in namespace "gc-4185"
Jul  2 13:01:17.135: INFO: Deleting pod "simpletest-rc-to-be-deleted-dzvd4" in namespace "gc-4185"
Jul  2 13:01:17.147: INFO: Deleting pod "simpletest-rc-to-be-deleted-f2gzv" in namespace "gc-4185"
Jul  2 13:01:17.159: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5vpt" in namespace "gc-4185"
Jul  2 13:01:17.171: INFO: Deleting pod "simpletest-rc-to-be-deleted-f9xj8" in namespace "gc-4185"
Jul  2 13:01:17.185: INFO: Deleting pod "simpletest-rc-to-be-deleted-fbfqh" in namespace "gc-4185"
Jul  2 13:01:17.197: INFO: Deleting pod "simpletest-rc-to-be-deleted-ffchf" in namespace "gc-4185"
Jul  2 13:01:17.210: INFO: Deleting pod "simpletest-rc-to-be-deleted-fq6cl" in namespace "gc-4185"
Jul  2 13:01:17.222: INFO: Deleting pod "simpletest-rc-to-be-deleted-fz2bj" in namespace "gc-4185"
Jul  2 13:01:17.232: INFO: Deleting pod "simpletest-rc-to-be-deleted-g5x48" in namespace "gc-4185"
Jul  2 13:01:17.245: INFO: Deleting pod "simpletest-rc-to-be-deleted-g6278" in namespace "gc-4185"
Jul  2 13:01:17.260: INFO: Deleting pod "simpletest-rc-to-be-deleted-g7zp7" in namespace "gc-4185"
Jul  2 13:01:17.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8kfv" in namespace "gc-4185"
Jul  2 13:01:17.303: INFO: Deleting pod "simpletest-rc-to-be-deleted-g8lsm" in namespace "gc-4185"
Jul  2 13:01:17.318: INFO: Deleting pod "simpletest-rc-to-be-deleted-g9bjv" in namespace "gc-4185"
Jul  2 13:01:17.338: INFO: Deleting pod "simpletest-rc-to-be-deleted-gv4td" in namespace "gc-4185"
Jul  2 13:01:17.352: INFO: Deleting pod "simpletest-rc-to-be-deleted-gz4mn" in namespace "gc-4185"
Jul  2 13:01:17.364: INFO: Deleting pod "simpletest-rc-to-be-deleted-h8qhk" in namespace "gc-4185"
Jul  2 13:01:17.377: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjfkl" in namespace "gc-4185"
Jul  2 13:01:17.389: INFO: Deleting pod "simpletest-rc-to-be-deleted-hjqpf" in namespace "gc-4185"
Jul  2 13:01:17.401: INFO: Deleting pod "simpletest-rc-to-be-deleted-j85q2" in namespace "gc-4185"
Jul  2 13:01:17.415: INFO: Deleting pod "simpletest-rc-to-be-deleted-jbdnc" in namespace "gc-4185"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  2 13:01:17.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4185" for this suite.

• [SLOW TEST:16.300 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":356,"completed":252,"skipped":4407,"failed":0}
[sig-node] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:01:17.438: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9720
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name secret-emptykey-test-bcff478c-881b-4e4c-96a0-ad4551d2e307
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  2 13:01:17.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9720" for this suite.
•{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","total":356,"completed":253,"skipped":4407,"failed":0}

------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:01:17.587: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6766
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:01:18.354: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jul  2 13:01:20.367: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 13:01:22.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jul  2 13:01:24.374: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 1, 18, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:01:27.389: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:01:27.395: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1532-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:01:30.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6766" for this suite.
STEP: Destroying namespace "webhook-6766-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:12.965 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":356,"completed":254,"skipped":4407,"failed":0}
SSSSSSS
------------------------------
[sig-apps] CronJob 
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:01:30.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename cronjob
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in cronjob-4100
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ForbidConcurrent cronjob
STEP: Ensuring a job is scheduled
STEP: Ensuring exactly one is scheduled
STEP: Ensuring exactly one running job exists by listing jobs explicitly
STEP: Ensuring no more jobs are scheduled
STEP: Removing cronjob
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:188
Jul  2 13:07:00.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-4100" for this suite.

• [SLOW TEST:330.201 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","total":356,"completed":255,"skipped":4414,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:00.755: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5074
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:07:00.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5074 create -f -'
Jul  2 13:07:01.051: INFO: stderr: ""
Jul  2 13:07:01.051: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Jul  2 13:07:01.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5074 create -f -'
Jul  2 13:07:01.817: INFO: stderr: ""
Jul  2 13:07:01.817: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start.
Jul  2 13:07:02.825: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 13:07:02.825: INFO: Found 1 / 1
Jul  2 13:07:02.825: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jul  2 13:07:02.829: INFO: Selector matched 1 pods for map[app:agnhost]
Jul  2 13:07:02.829: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jul  2 13:07:02.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5074 describe pod agnhost-primary-ck9q9'
Jul  2 13:07:02.897: INFO: stderr: ""
Jul  2 13:07:02.897: INFO: stdout: "Name:         agnhost-primary-ck9q9\nNamespace:    kubectl-5074\nPriority:     0\nNode:         ip-172-31-9-92/172.31.9.92\nStart Time:   Sat, 02 Jul 2022 13:07:01 +0000\nLabels:       app=agnhost\n              role=primary\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           192.168.231.42\nIPs:\n  IP:           192.168.231.42\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://d708b371587083cdc76b86c270ce2e3a3ca1b4a1f64facb7bdf5d53db75c9fdc\n    Image:          k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Image ID:       k8s.gcr.io/e2e-test-images/agnhost@sha256:7e8bdd271312fd25fc5ff5a8f04727be84044eb3d7d8d03611972a6752e2e11e\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 02 Jul 2022 13:07:01 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vs6fc (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-vs6fc:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-5074/agnhost-primary-ck9q9 to ip-172-31-9-92\n  Normal  Pulled     1s    kubelet            Container image \"k8s.gcr.io/e2e-test-images/agnhost:2.39\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Jul  2 13:07:02.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5074 describe rc agnhost-primary'
Jul  2 13:07:02.978: INFO: stderr: ""
Jul  2 13:07:02.978: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-5074\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        k8s.gcr.io/e2e-test-images/agnhost:2.39\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-ck9q9\n"
Jul  2 13:07:02.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5074 describe service agnhost-primary'
Jul  2 13:07:03.047: INFO: stderr: ""
Jul  2 13:07:03.047: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-5074\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.218\nIPs:               10.152.183.218\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.231.42:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jul  2 13:07:03.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5074 describe node ip-172-31-41-146'
Jul  2 13:07:03.130: INFO: stderr: ""
Jul  2 13:07:03.130: INFO: stdout: "Name:               ip-172-31-41-146\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-control-plane\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-41-146\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 02 Jul 2022 11:48:16 +0000\nTaints:             juju.is/kubernetes-control-plane=true:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-41-146\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 02 Jul 2022 13:06:53 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 02 Jul 2022 13:05:51 +0000   Sat, 02 Jul 2022 11:48:16 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 02 Jul 2022 13:05:51 +0000   Sat, 02 Jul 2022 11:48:16 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 02 Jul 2022 13:05:51 +0000   Sat, 02 Jul 2022 11:48:16 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 02 Jul 2022 13:05:51 +0000   Sat, 02 Jul 2022 11:48:26 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.41.146\n  Hostname:    ip-172-31-41-146\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16080744Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7925680Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14820013646\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7823280Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec270b7a80e79071314f273e13e00922\n  System UUID:                ec270b7a-80e7-9071-314f-273e13e00922\n  Boot ID:                    e7901d75-1506-46c4-99ac-6ef79fd5b816\n  Kernel Version:             5.13.0-1031-aws\n  OS Image:                   Ubuntu 20.04.4 LTS\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.5.9\n  Kubelet Version:            v1.24.2\n  Kube-Proxy Version:         v1.24.2\nNon-terminated Pods:          (1 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-7bhl4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         73m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\n  hugepages-1Gi      0 (0%)    0 (0%)\n  hugepages-2Mi      0 (0%)    0 (0%)\nEvents:              <none>\n"
Jul  2 13:07:03.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-5074 describe namespace kubectl-5074'
Jul  2 13:07:03.197: INFO: stderr: ""
Jul  2 13:07:03.197: INFO: stdout: "Name:         kubectl-5074\nLabels:       e2e-framework=kubectl\n              e2e-run=f4084c13-e4fd-49f1-97ce-b13d9ea6ead5\n              kubernetes.io/metadata.name=kubectl-5074\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 13:07:03.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5074" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":356,"completed":256,"skipped":4528,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:03.209: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2009
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 13:07:03.353: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2" in namespace "downward-api-2009" to be "Succeeded or Failed"
Jul  2 13:07:03.357: INFO: Pod "downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.992073ms
Jul  2 13:07:05.365: INFO: Pod "downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012121134s
Jul  2 13:07:07.374: INFO: Pod "downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020448978s
STEP: Saw pod success
Jul  2 13:07:07.374: INFO: Pod "downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2" satisfied condition "Succeeded or Failed"
Jul  2 13:07:07.378: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2 container client-container: <nil>
STEP: delete the pod
Jul  2 13:07:07.413: INFO: Waiting for pod downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2 to disappear
Jul  2 13:07:07.417: INFO: Pod downwardapi-volume-b9f04240-cc9a-4ba1-a8ba-732338ed22b2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 13:07:07.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2009" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":257,"skipped":4530,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:07.430: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3233
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:07:07.900: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:07:10.927: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:07:10.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4956-crds.webhook.example.com via the AdmissionRegistration API
Jul  2 13:07:11.464: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:07:14.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3233" for this suite.
STEP: Destroying namespace "webhook-3233-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.876 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":356,"completed":258,"skipped":4567,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:14.306: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1366
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/framework/framework.go:652
STEP: validating api versions
Jul  2 13:07:14.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-1366 api-versions'
Jul  2 13:07:14.531: INFO: stderr: ""
Jul  2 13:07:14.531: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1\nevents.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\nnode.k8s.io/v1beta1\npolicy/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 13:07:14.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1366" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":356,"completed":259,"skipped":4576,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:14.546: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9592
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0702 13:07:15.732249      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Jul  2 13:07:15.732: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  2 13:07:15.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9592" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":356,"completed":260,"skipped":4581,"failed":0}
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:15.744: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3728
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a ServiceAccount
STEP: watching for the ServiceAccount to be added
STEP: patching the ServiceAccount
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector)
STEP: deleting the ServiceAccount
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  2 13:07:15.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3728" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","total":356,"completed":261,"skipped":4584,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:15.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4980
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[It] should support proxy with --port 0  [Conformance]
  test/e2e/framework/framework.go:652
STEP: starting the proxy server
Jul  2 13:07:16.051: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-4980 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 13:07:16.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4980" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":356,"completed":262,"skipped":4602,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:16.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1407
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not conflict [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:07:16.291: INFO: The status of Pod pod-secrets-6b74a7aa-5449-4eec-8503-15973cdfa81e is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:07:18.300: INFO: The status of Pod pod-secrets-6b74a7aa-5449-4eec-8503-15973cdfa81e is Running (Ready = true)
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Jul  2 13:07:18.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1407" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":356,"completed":263,"skipped":4610,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:18.343: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8920
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:07:18.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8920" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":356,"completed":264,"skipped":4624,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:18.487: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3680
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:07:18.982: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:07:22.016: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:07:22.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3680" for this suite.
STEP: Destroying namespace "webhook-3680-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":356,"completed":265,"skipped":4627,"failed":0}
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:22.169: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9722
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  2 13:07:22.312: INFO: Waiting up to 5m0s for pod "downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889" in namespace "downward-api-9722" to be "Succeeded or Failed"
Jul  2 13:07:22.316: INFO: Pod "downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889": Phase="Pending", Reason="", readiness=false. Elapsed: 3.433981ms
Jul  2 13:07:24.324: INFO: Pod "downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012223995s
Jul  2 13:07:26.333: INFO: Pod "downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021286089s
STEP: Saw pod success
Jul  2 13:07:26.333: INFO: Pod "downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889" satisfied condition "Succeeded or Failed"
Jul  2 13:07:26.337: INFO: Trying to get logs from node ip-172-31-9-92 pod downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889 container dapi-container: <nil>
STEP: delete the pod
Jul  2 13:07:26.368: INFO: Waiting for pod downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889 to disappear
Jul  2 13:07:26.372: INFO: Pod downward-api-8a885fec-11b7-436c-bb8f-c7aa3f8e2889 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  2 13:07:26.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9722" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":356,"completed":266,"skipped":4629,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:26.384: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-426
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  2 13:07:26.561: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:07:26.561: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:07:26.565: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:07:26.566: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 13:07:27.573: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:07:27.573: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:07:27.577: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:07:27.577: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 13:07:28.572: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:07:28.572: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:07:28.577: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 13:07:28.577: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status
Jul  2 13:07:28.585: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status
Jul  2 13:07:28.595: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated
Jul  2 13:07:28.596: INFO: Observed &DaemonSet event: ADDED
Jul  2 13:07:28.597: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.597: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.597: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.597: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.597: INFO: Found daemon set daemon-set in namespace daemonsets-426 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  2 13:07:28.597: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status
STEP: watching for the daemon set status to be patched
Jul  2 13:07:28.606: INFO: Observed &DaemonSet event: ADDED
Jul  2 13:07:28.606: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.606: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.607: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.607: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.607: INFO: Observed daemon set daemon-set in namespace daemonsets-426 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Jul  2 13:07:28.607: INFO: Observed &DaemonSet event: MODIFIED
Jul  2 13:07:28.607: INFO: Found daemon set daemon-set in namespace daemonsets-426 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Jul  2 13:07:28.607: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-426, will wait for the garbage collector to delete the pods
Jul  2 13:07:28.673: INFO: Deleting DaemonSet.extensions daemon-set took: 8.331494ms
Jul  2 13:07:28.774: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.846734ms
Jul  2 13:07:31.480: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:07:31.480: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  2 13:07:31.483: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"31967"},"items":null}

Jul  2 13:07:31.487: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"31967"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:07:31.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-426" for this suite.

• [SLOW TEST:5.133 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","total":356,"completed":267,"skipped":4632,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath 
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:07:31.518: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-preemption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-preemption-3221
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Jul  2 13:07:31.667: INFO: Waiting up to 1m0s for all nodes to be ready
Jul  2 13:08:31.685: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:08:31.689: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-preemption-path
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-preemption-path-6517
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
Jul  2 13:08:33.867: INFO: found a healthy node: ip-172-31-9-92
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:08:47.978: INFO: pods created so far: [1 1 1]
Jul  2 13:08:47.979: INFO: length of pods created so far: 3
Jul  2 13:08:50.002: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:188
Jul  2 13:08:57.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-6517" for this suite.
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:08:57.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3221" for this suite.
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80

• [SLOW TEST:85.590 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","total":356,"completed":268,"skipped":4693,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:08:57.109: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-82
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/framework/framework.go:652
STEP: fetching services
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 13:08:57.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-82" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":356,"completed":269,"skipped":4737,"failed":0}
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:08:57.261: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9715
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: reading a file in the container
Jul  2 13:08:59.418: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9715 pod-service-account-79575298-a051-4811-81d3-cb751b520caa -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jul  2 13:08:59.569: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9715 pod-service-account-79575298-a051-4811-81d3-cb751b520caa -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jul  2 13:08:59.711: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-9715 pod-service-account-79575298-a051-4811-81d3-cb751b520caa -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Jul  2 13:08:59.831: INFO: Got root ca configmap in namespace "svcaccounts-9715"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  2 13:08:59.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9715" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":356,"completed":270,"skipped":4741,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:08:59.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9649
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating the pod
Jul  2 13:08:59.990: INFO: The status of Pod annotationupdate8a2a0c92-6136-41e0-b667-59cc6c22a0a2 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:09:01.997: INFO: The status of Pod annotationupdate8a2a0c92-6136-41e0-b667-59cc6c22a0a2 is Running (Ready = true)
Jul  2 13:09:02.529: INFO: Successfully updated pod "annotationupdate8a2a0c92-6136-41e0-b667-59cc6c22a0a2"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 13:09:06.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9649" for this suite.

• [SLOW TEST:6.732 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":356,"completed":271,"skipped":4743,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:06.577: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename disruption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in disruption-1521
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/framework/framework.go:652
STEP: Waiting for the pdb to be processed
STEP: Waiting for all pods to be running
Jul  2 13:09:08.753: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  2 13:09:10.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1521" for this suite.
•{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","total":356,"completed":272,"skipped":4770,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:10.778: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3670
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-volume-21e494db-7524-4c8e-aafb-99cc5781c3a9
STEP: Creating a pod to test consume configMaps
Jul  2 13:09:10.930: INFO: Waiting up to 5m0s for pod "pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f" in namespace "configmap-3670" to be "Succeeded or Failed"
Jul  2 13:09:10.934: INFO: Pod "pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.455454ms
Jul  2 13:09:12.940: INFO: Pod "pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010100949s
Jul  2 13:09:14.947: INFO: Pod "pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017190777s
STEP: Saw pod success
Jul  2 13:09:14.947: INFO: Pod "pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f" satisfied condition "Succeeded or Failed"
Jul  2 13:09:14.951: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f container configmap-volume-test: <nil>
STEP: delete the pod
Jul  2 13:09:15.038: INFO: Waiting for pod pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f to disappear
Jul  2 13:09:15.042: INFO: Pod pod-configmaps-d57262c6-ab02-4334-9818-9ef173bb881f no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 13:09:15.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3670" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":356,"completed":273,"skipped":4781,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:15.054: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-977
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-map-23fc978c-ff07-4db3-9feb-e0a3078f805e
STEP: Creating a pod to test consume secrets
Jul  2 13:09:15.199: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d" in namespace "projected-977" to be "Succeeded or Failed"
Jul  2 13:09:15.204: INFO: Pod "pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.868178ms
Jul  2 13:09:17.210: INFO: Pod "pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01024094s
Jul  2 13:09:19.218: INFO: Pod "pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019131861s
STEP: Saw pod success
Jul  2 13:09:19.218: INFO: Pod "pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d" satisfied condition "Succeeded or Failed"
Jul  2 13:09:19.223: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  2 13:09:19.245: INFO: Waiting for pod pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d to disappear
Jul  2 13:09:19.249: INFO: Pod pod-projected-secrets-d7dc6529-07b5-4328-b5ad-b63da205090d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  2 13:09:19.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-977" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":274,"skipped":4839,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:19.260: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-708
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Jul  2 13:09:29.437: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0702 13:09:29.437102      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:188
Jul  2 13:09:29.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-708" for this suite.

• [SLOW TEST:10.194 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":356,"completed":275,"skipped":4861,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:29.454: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4725
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name cm-test-opt-del-c7fff1de-8712-455d-8b74-ab5700d8f261
STEP: Creating configMap with name cm-test-opt-upd-fb26df7a-e26c-44f7-8684-b9aba2b8a2d2
STEP: Creating the pod
Jul  2 13:09:29.621: INFO: The status of Pod pod-configmaps-e940fc2e-a998-489a-a630-64b9bd88c7d3 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:09:31.630: INFO: The status of Pod pod-configmaps-e940fc2e-a998-489a-a630-64b9bd88c7d3 is Running (Ready = true)
STEP: Deleting configmap cm-test-opt-del-c7fff1de-8712-455d-8b74-ab5700d8f261
STEP: Updating configmap cm-test-opt-upd-fb26df7a-e26c-44f7-8684-b9aba2b8a2d2
STEP: Creating configMap with name cm-test-opt-create-cefef696-1a33-4e93-a5b4-9260772d128f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 13:09:35.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4725" for this suite.

• [SLOW TEST:6.278 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":276,"skipped":4925,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:35.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3713
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 13:09:35.877: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915" in namespace "downward-api-3713" to be "Succeeded or Failed"
Jul  2 13:09:35.880: INFO: Pod "downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915": Phase="Pending", Reason="", readiness=false. Elapsed: 2.976266ms
Jul  2 13:09:37.888: INFO: Pod "downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010715805s
Jul  2 13:09:39.898: INFO: Pod "downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020253094s
STEP: Saw pod success
Jul  2 13:09:39.898: INFO: Pod "downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915" satisfied condition "Succeeded or Failed"
Jul  2 13:09:39.901: INFO: Trying to get logs from node ip-172-31-69-95 pod downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915 container client-container: <nil>
STEP: delete the pod
Jul  2 13:09:39.936: INFO: Waiting for pod downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915 to disappear
Jul  2 13:09:39.939: INFO: Pod downwardapi-volume-6fb2c834-1617-4d34-96f7-db4160c2a915 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 13:09:39.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3713" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":356,"completed":277,"skipped":4986,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:39.951: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4789
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:09:40.104: INFO: created pod pod-service-account-defaultsa
Jul  2 13:09:40.104: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jul  2 13:09:40.113: INFO: created pod pod-service-account-mountsa
Jul  2 13:09:40.113: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jul  2 13:09:40.119: INFO: created pod pod-service-account-nomountsa
Jul  2 13:09:40.119: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jul  2 13:09:40.127: INFO: created pod pod-service-account-defaultsa-mountspec
Jul  2 13:09:40.127: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jul  2 13:09:40.132: INFO: created pod pod-service-account-mountsa-mountspec
Jul  2 13:09:40.132: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jul  2 13:09:40.141: INFO: created pod pod-service-account-nomountsa-mountspec
Jul  2 13:09:40.141: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jul  2 13:09:40.148: INFO: created pod pod-service-account-defaultsa-nomountspec
Jul  2 13:09:40.148: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jul  2 13:09:40.155: INFO: created pod pod-service-account-mountsa-nomountspec
Jul  2 13:09:40.155: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jul  2 13:09:40.163: INFO: created pod pod-service-account-nomountsa-nomountspec
Jul  2 13:09:40.163: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:188
Jul  2 13:09:40.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4789" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":356,"completed":278,"skipped":4999,"failed":0}
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:40.180: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5441
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward api env vars
Jul  2 13:09:40.325: INFO: Waiting up to 5m0s for pod "downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06" in namespace "downward-api-5441" to be "Succeeded or Failed"
Jul  2 13:09:40.330: INFO: Pod "downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06": Phase="Pending", Reason="", readiness=false. Elapsed: 4.537263ms
Jul  2 13:09:42.335: INFO: Pod "downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01000163s
Jul  2 13:09:44.344: INFO: Pod "downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018770368s
STEP: Saw pod success
Jul  2 13:09:44.344: INFO: Pod "downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06" satisfied condition "Succeeded or Failed"
Jul  2 13:09:44.348: INFO: Trying to get logs from node ip-172-31-69-95 pod downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06 container dapi-container: <nil>
STEP: delete the pod
Jul  2 13:09:44.368: INFO: Waiting for pod downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06 to disappear
Jul  2 13:09:44.373: INFO: Pod downward-api-45b46bc3-9eec-422a-bb09-c095f396cd06 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:188
Jul  2 13:09:44.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5441" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":356,"completed":279,"skipped":5005,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:09:44.391: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1921
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
Jul  2 13:09:44.524: INFO: PodSpec: initContainers in spec.initContainers
Jul  2 13:10:24.685: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6a47a40e-dc3c-4616-9dd9-a7bcb0b2f991", GenerateName:"", Namespace:"init-container-1921", SelfLink:"", UID:"a45cb3b2-b39a-43d8-a0cd-d8b0c9cc48c1", ResourceVersion:"33140", Generation:0, CreationTimestamp:time.Date(2022, time.July, 2, 13, 9, 44, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"524394737"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ZZZ_DeprecatedClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.July, 2, 13, 9, 44, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002902b10), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.July, 2, 13, 9, 45, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc002902b40), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-bcwf5", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc004ef9c00), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-bcwf5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-bcwf5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.7", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-bcwf5", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0052036a0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-9-92", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00187a700), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005203730)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005203750)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc005203758), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00520375c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000718190), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 2, 13, 9, 44, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 2, 13, 9, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 2, 13, 9, 44, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.July, 2, 13, 9, 44, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.9.92", PodIP:"192.168.231.63", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.231.63"}}, StartTime:time.Date(2022, time.July, 2, 13, 9, 44, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00187a7e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00187a850)}, Ready:false, RestartCount:3, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"k8s.gcr.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://457babfdfb6b29508bb300ee600f706e99dbb91dda5e6034e6e788bc67cd1ab8", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004ef9c80), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004ef9c60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.7", ImageID:"", ContainerID:"", Started:(*bool)(0xc0052037df)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:188
Jul  2 13:10:24.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1921" for this suite.

• [SLOW TEST:40.311 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":356,"completed":280,"skipped":5020,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates 
  should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:10:24.703: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename podtemplate
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in podtemplate-3321
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should replace a pod template [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create a pod template
STEP: Replace a pod template
Jul  2 13:10:24.857: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Jul  2 13:10:24.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-3321" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","total":356,"completed":281,"skipped":5059,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:10:24.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5402
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul  2 13:10:25.010: INFO: Waiting up to 5m0s for pod "pod-dd3779db-1291-4994-9d07-444de5e607f3" in namespace "emptydir-5402" to be "Succeeded or Failed"
Jul  2 13:10:25.016: INFO: Pod "pod-dd3779db-1291-4994-9d07-444de5e607f3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.028815ms
Jul  2 13:10:27.023: INFO: Pod "pod-dd3779db-1291-4994-9d07-444de5e607f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013867684s
Jul  2 13:10:29.034: INFO: Pod "pod-dd3779db-1291-4994-9d07-444de5e607f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024552565s
STEP: Saw pod success
Jul  2 13:10:29.034: INFO: Pod "pod-dd3779db-1291-4994-9d07-444de5e607f3" satisfied condition "Succeeded or Failed"
Jul  2 13:10:29.038: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-dd3779db-1291-4994-9d07-444de5e607f3 container test-container: <nil>
STEP: delete the pod
Jul  2 13:10:29.059: INFO: Waiting for pod pod-dd3779db-1291-4994-9d07-444de5e607f3 to disappear
Jul  2 13:10:29.062: INFO: Pod pod-dd3779db-1291-4994-9d07-444de5e607f3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 13:10:29.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5402" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":282,"skipped":5081,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:10:29.073: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6210
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:10:29.234: INFO: Create a RollingUpdate DaemonSet
Jul  2 13:10:29.238: INFO: Check that daemon pods launch on every node of the cluster
Jul  2 13:10:29.242: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:29.242: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:29.248: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:10:29.248: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 13:10:30.256: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:30.256: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:30.260: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  2 13:10:30.260: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 13:10:31.255: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:31.255: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:31.259: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 13:10:31.259: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Jul  2 13:10:31.259: INFO: Update the DaemonSet to trigger a rollout
Jul  2 13:10:31.269: INFO: Updating DaemonSet daemon-set
Jul  2 13:10:33.289: INFO: Roll back the DaemonSet before rollout is complete
Jul  2 13:10:33.297: INFO: Updating DaemonSet daemon-set
Jul  2 13:10:33.297: INFO: Make sure DaemonSet rollback is complete
Jul  2 13:10:33.302: INFO: Wrong image for pod: daemon-set-pqstl. Expected: k8s.gcr.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Jul  2 13:10:33.302: INFO: Pod daemon-set-pqstl is not available
Jul  2 13:10:33.307: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:33.307: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:34.318: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:34.318: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:35.313: INFO: Pod daemon-set-chtpw is not available
Jul  2 13:10:35.317: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:10:35.317: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6210, will wait for the garbage collector to delete the pods
Jul  2 13:10:35.387: INFO: Deleting DaemonSet.extensions daemon-set took: 8.303828ms
Jul  2 13:10:35.487: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.627785ms
Jul  2 13:10:37.295: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:10:37.295: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  2 13:10:37.298: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33363"},"items":null}

Jul  2 13:10:37.302: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33363"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:10:37.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6210" for this suite.

• [SLOW TEST:8.256 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":356,"completed":283,"skipped":5082,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:10:37.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7173
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-test-upd-84437386-a7af-4fae-979d-ee76252a2b9d
STEP: Creating the pod
Jul  2 13:10:37.482: INFO: The status of Pod pod-configmaps-2645b9b6-35b2-4325-890c-8eff97ce073c is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:10:39.491: INFO: The status of Pod pod-configmaps-2645b9b6-35b2-4325-890c-8eff97ce073c is Running (Ready = true)
STEP: Updating configmap configmap-test-upd-84437386-a7af-4fae-979d-ee76252a2b9d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 13:10:41.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7173" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":284,"skipped":5145,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:10:41.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9902
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  2 13:10:45.726: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  2 13:10:45.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9902" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":356,"completed":285,"skipped":5163,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:10:45.752: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9181
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test override all
Jul  2 13:10:45.893: INFO: Waiting up to 5m0s for pod "client-containers-92284d08-b4a7-4250-b4eb-df339044624a" in namespace "containers-9181" to be "Succeeded or Failed"
Jul  2 13:10:45.896: INFO: Pod "client-containers-92284d08-b4a7-4250-b4eb-df339044624a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.129723ms
Jul  2 13:10:47.905: INFO: Pod "client-containers-92284d08-b4a7-4250-b4eb-df339044624a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011535491s
Jul  2 13:10:49.913: INFO: Pod "client-containers-92284d08-b4a7-4250-b4eb-df339044624a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019922049s
STEP: Saw pod success
Jul  2 13:10:49.913: INFO: Pod "client-containers-92284d08-b4a7-4250-b4eb-df339044624a" satisfied condition "Succeeded or Failed"
Jul  2 13:10:49.917: INFO: Trying to get logs from node ip-172-31-9-92 pod client-containers-92284d08-b4a7-4250-b4eb-df339044624a container agnhost-container: <nil>
STEP: delete the pod
Jul  2 13:10:49.937: INFO: Waiting for pod client-containers-92284d08-b4a7-4250-b4eb-df339044624a to disappear
Jul  2 13:10:49.944: INFO: Pod client-containers-92284d08-b4a7-4250-b4eb-df339044624a no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:188
Jul  2 13:10:49.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9181" for this suite.
•{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":356,"completed":286,"skipped":5188,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:10:49.959: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5104
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: waiting for pod running
STEP: creating a file in subpath
Jul  2 13:10:52.116: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-5104 PodName:var-expansion-e6ed711a-a1b9-4296-b9a7-de77d6753606 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 13:10:52.116: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 13:10:52.116: INFO: ExecWithOptions: Clientset creation
Jul  2 13:10:52.116: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5104/pods/var-expansion-e6ed711a-a1b9-4296-b9a7-de77d6753606/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path
Jul  2 13:10:52.207: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-5104 PodName:var-expansion-e6ed711a-a1b9-4296-b9a7-de77d6753606 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 13:10:52.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 13:10:52.208: INFO: ExecWithOptions: Clientset creation
Jul  2 13:10:52.208: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-5104/pods/var-expansion-e6ed711a-a1b9-4296-b9a7-de77d6753606/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value
Jul  2 13:10:52.806: INFO: Successfully updated pod "var-expansion-e6ed711a-a1b9-4296-b9a7-de77d6753606"
STEP: waiting for annotated pod running
STEP: deleting the pod gracefully
Jul  2 13:10:52.809: INFO: Deleting pod "var-expansion-e6ed711a-a1b9-4296-b9a7-de77d6753606" in namespace "var-expansion-5104"
Jul  2 13:10:52.817: INFO: Wait up to 5m0s for pod "var-expansion-e6ed711a-a1b9-4296-b9a7-de77d6753606" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 13:11:26.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5104" for this suite.

• [SLOW TEST:36.883 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","total":356,"completed":287,"skipped":5210,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:11:26.842: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3141
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:245
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1540
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/framework/framework.go:652
STEP: running the image k8s.gcr.io/e2e-test-images/httpd:2.4.38-2
Jul  2 13:11:26.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-3141 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=k8s.gcr.io/e2e-test-images/httpd:2.4.38-2'
Jul  2 13:11:27.044: INFO: stderr: ""
Jul  2 13:11:27.044: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1544
Jul  2 13:11:27.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=kubectl-3141 delete pods e2e-test-httpd-pod'
Jul  2 13:11:29.848: INFO: stderr: ""
Jul  2 13:11:29.848: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:188
Jul  2 13:11:29.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3141" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":356,"completed":288,"skipped":5212,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:11:29.867: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-356
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-e129ac4c-36a5-4806-8374-35102780554a
STEP: Creating a pod to test consume configMaps
Jul  2 13:11:30.014: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20" in namespace "projected-356" to be "Succeeded or Failed"
Jul  2 13:11:30.018: INFO: Pod "pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20": Phase="Pending", Reason="", readiness=false. Elapsed: 3.638006ms
Jul  2 13:11:32.025: INFO: Pod "pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011362172s
Jul  2 13:11:34.033: INFO: Pod "pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018817369s
STEP: Saw pod success
Jul  2 13:11:34.033: INFO: Pod "pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20" satisfied condition "Succeeded or Failed"
Jul  2 13:11:34.036: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 13:11:34.061: INFO: Waiting for pod pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20 to disappear
Jul  2 13:11:34.064: INFO: Pod pod-projected-configmaps-d8391cbe-bb77-4d92-8a56-160036ed1d20 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 13:11:34.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-356" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":356,"completed":289,"skipped":5261,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:11:34.076: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-130
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-e1a74e24-0f94-418c-b714-cdeb015eb995
STEP: Creating a pod to test consume secrets
Jul  2 13:11:34.237: INFO: Waiting up to 5m0s for pod "pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a" in namespace "secrets-130" to be "Succeeded or Failed"
Jul  2 13:11:34.243: INFO: Pod "pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.62715ms
Jul  2 13:11:36.252: INFO: Pod "pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014512292s
Jul  2 13:11:38.261: INFO: Pod "pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024024542s
STEP: Saw pod success
Jul  2 13:11:38.261: INFO: Pod "pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a" satisfied condition "Succeeded or Failed"
Jul  2 13:11:38.265: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a container secret-env-test: <nil>
STEP: delete the pod
Jul  2 13:11:38.287: INFO: Waiting for pod pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a to disappear
Jul  2 13:11:38.290: INFO: Pod pod-secrets-b0ae0b37-b4b7-48d2-bc44-4b1e3c00026a no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:188
Jul  2 13:11:38.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-130" for this suite.
•{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":356,"completed":290,"skipped":5277,"failed":0}
SSSSSS
------------------------------
[sig-node] PodTemplates 
  should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:11:38.302: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename podtemplate
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in podtemplate-7808
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should delete a collection of pod templates [Conformance]
  test/e2e/framework/framework.go:652
STEP: Create set of pod templates
Jul  2 13:11:38.440: INFO: created test-podtemplate-1
Jul  2 13:11:38.445: INFO: created test-podtemplate-2
Jul  2 13:11:38.451: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace
STEP: delete collection of pod templates
Jul  2 13:11:38.454: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity
Jul  2 13:11:38.475: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Jul  2 13:11:38.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-7808" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","total":356,"completed":291,"skipped":5283,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:11:38.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename endpointslice
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in endpointslice-9924
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  2 13:11:42.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-9924" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","total":356,"completed":292,"skipped":5301,"failed":0}
SS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:11:42.705: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1247
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:11:42.850: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-0cb4f40f-630b-46a7-ba38-b866b76214e0" in namespace "security-context-test-1247" to be "Succeeded or Failed"
Jul  2 13:11:42.856: INFO: Pod "alpine-nnp-false-0cb4f40f-630b-46a7-ba38-b866b76214e0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.33527ms
Jul  2 13:11:44.866: INFO: Pod "alpine-nnp-false-0cb4f40f-630b-46a7-ba38-b866b76214e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015517559s
Jul  2 13:11:46.873: INFO: Pod "alpine-nnp-false-0cb4f40f-630b-46a7-ba38-b866b76214e0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02248911s
Jul  2 13:11:48.881: INFO: Pod "alpine-nnp-false-0cb4f40f-630b-46a7-ba38-b866b76214e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.031287956s
Jul  2 13:11:48.881: INFO: Pod "alpine-nnp-false-0cb4f40f-630b-46a7-ba38-b866b76214e0" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  2 13:11:48.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1247" for this suite.

• [SLOW TEST:6.200 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:298
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":293,"skipped":5303,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:11:48.905: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1708
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2166
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6089
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:12:02.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1708" for this suite.
STEP: Destroying namespace "nsdeletetest-2166" for this suite.
Jul  2 13:12:02.356: INFO: Namespace nsdeletetest-2166 was already deleted
STEP: Destroying namespace "nsdeletetest-6089" for this suite.

• [SLOW TEST:13.459 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":356,"completed":294,"skipped":5326,"failed":0}
SSS
------------------------------
[sig-network] Services 
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:12:02.364: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5938
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-5938
Jul  2 13:12:02.514: INFO: The status of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:12:04.522: INFO: The status of Pod kube-proxy-mode-detector is Running (Ready = true)
Jul  2 13:12:04.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Jul  2 13:12:04.673: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Jul  2 13:12:04.673: INFO: stdout: "iptables"
Jul  2 13:12:04.673: INFO: proxyMode: iptables
Jul  2 13:12:04.687: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Jul  2 13:12:04.691: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-5938
STEP: creating replication controller affinity-clusterip-timeout in namespace services-5938
I0702 13:12:04.713602      20 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-5938, replica count: 3
I0702 13:12:07.764123      20 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 13:12:07.776: INFO: Creating new exec pod
Jul  2 13:12:10.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec execpod-affinity25wxm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Jul  2 13:12:10.927: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Jul  2 13:12:10.928: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 13:12:10.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec execpod-affinity25wxm -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.32 80'
Jul  2 13:12:11.072: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.32 80\nConnection to 10.152.183.32 80 port [tcp/http] succeeded!\n"
Jul  2 13:12:11.072: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 13:12:11.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec execpod-affinity25wxm -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.32:80/ ; done'
Jul  2 13:12:11.234: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n"
Jul  2 13:12:11.234: INFO: stdout: "\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r\naffinity-clusterip-timeout-45f2r"
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Received response from host: affinity-clusterip-timeout-45f2r
Jul  2 13:12:11.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec execpod-affinity25wxm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.32:80/'
Jul  2 13:12:11.372: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n"
Jul  2 13:12:11.372: INFO: stdout: "affinity-clusterip-timeout-45f2r"
Jul  2 13:12:31.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec execpod-affinity25wxm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.32:80/'
Jul  2 13:12:31.523: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n"
Jul  2 13:12:31.523: INFO: stdout: "affinity-clusterip-timeout-45f2r"
Jul  2 13:12:51.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec execpod-affinity25wxm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.32:80/'
Jul  2 13:12:51.675: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n"
Jul  2 13:12:51.675: INFO: stdout: "affinity-clusterip-timeout-45f2r"
Jul  2 13:13:11.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-5938 exec execpod-affinity25wxm -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.32:80/'
Jul  2 13:13:11.829: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.32:80/\n"
Jul  2 13:13:11.829: INFO: stdout: "affinity-clusterip-timeout-qbjpv"
Jul  2 13:13:11.829: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-5938, will wait for the garbage collector to delete the pods
Jul  2 13:13:11.913: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 7.760551ms
Jul  2 13:13:12.014: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.093837ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 13:13:14.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5938" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:71.784 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":295,"skipped":5329,"failed":0}
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:13:14.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7710
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jul  2 13:13:14.307: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:14.307: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:14.311: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:13:14.311: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 13:13:15.318: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:15.318: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:15.323: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:13:15.323: INFO: Node ip-172-31-69-95 is running 0 daemon pod, expected 1
Jul  2 13:13:16.318: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:16.318: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:16.322: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 13:13:16.322: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jul  2 13:13:16.343: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:16.343: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:16.348: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 13:13:16.348: INFO: Node ip-172-31-91-232 is running 0 daemon pod, expected 1
Jul  2 13:13:17.354: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:17.354: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:17.358: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Jul  2 13:13:17.358: INFO: Node ip-172-31-91-232 is running 0 daemon pod, expected 1
Jul  2 13:13:18.355: INFO: DaemonSet pods can't tolerate node ip-172-31-41-146 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:18.355: INFO: DaemonSet pods can't tolerate node ip-172-31-75-221 with taints [{Key:juju.is/kubernetes-control-plane Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Jul  2 13:13:18.359: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Jul  2 13:13:18.359: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7710, will wait for the garbage collector to delete the pods
Jul  2 13:13:18.429: INFO: Deleting DaemonSet.extensions daemon-set took: 8.348467ms
Jul  2 13:13:18.529: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.322349ms
Jul  2 13:13:20.637: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:13:20.637: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  2 13:13:20.640: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"34387"},"items":null}

Jul  2 13:13:20.645: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"34387"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:13:20.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7710" for this suite.

• [SLOW TEST:6.524 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":356,"completed":296,"skipped":5334,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:13:20.673: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4969
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 13:13:31.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4969" for this suite.

• [SLOW TEST:11.211 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":356,"completed":297,"skipped":5337,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Job 
  should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:13:31.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1801
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should apply changes to a job status [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensure pods equal to paralellism count is attached to the job
STEP: patching /status
STEP: updating /status
STEP: get /status
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  2 13:13:36.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1801" for this suite.
•{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","total":356,"completed":298,"skipped":5345,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:13:36.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8780
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0666 on node default medium
Jul  2 13:13:36.216: INFO: Waiting up to 5m0s for pod "pod-18311f4d-5314-4a99-ba43-fa156d63d8fb" in namespace "emptydir-8780" to be "Succeeded or Failed"
Jul  2 13:13:36.221: INFO: Pod "pod-18311f4d-5314-4a99-ba43-fa156d63d8fb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.497397ms
Jul  2 13:13:38.229: INFO: Pod "pod-18311f4d-5314-4a99-ba43-fa156d63d8fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013453619s
Jul  2 13:13:40.237: INFO: Pod "pod-18311f4d-5314-4a99-ba43-fa156d63d8fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020880153s
STEP: Saw pod success
Jul  2 13:13:40.237: INFO: Pod "pod-18311f4d-5314-4a99-ba43-fa156d63d8fb" satisfied condition "Succeeded or Failed"
Jul  2 13:13:40.241: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-18311f4d-5314-4a99-ba43-fa156d63d8fb container test-container: <nil>
STEP: delete the pod
Jul  2 13:13:40.269: INFO: Waiting for pod pod-18311f4d-5314-4a99-ba43-fa156d63d8fb to disappear
Jul  2 13:13:40.273: INFO: Pod pod-18311f4d-5314-4a99-ba43-fa156d63d8fb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 13:13:40.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8780" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":299,"skipped":5369,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] 
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:13:40.284: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1886
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1886
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating statefulset ss in namespace statefulset-1886
Jul  2 13:13:40.434: INFO: Found 0 stateful pods, waiting for 1
Jul  2 13:13:50.450: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label
STEP: Getting /status
Jul  2 13:13:50.473: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status
Jul  2 13:13:50.483: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated
Jul  2 13:13:50.484: INFO: Observed &StatefulSet event: ADDED
Jul  2 13:13:50.484: INFO: Found Statefulset ss in namespace statefulset-1886 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  2 13:13:50.484: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status
Jul  2 13:13:50.484: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Jul  2 13:13:50.491: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched
Jul  2 13:13:50.493: INFO: Observed &StatefulSet event: ADDED
Jul  2 13:13:50.493: INFO: Observed Statefulset ss in namespace statefulset-1886 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Jul  2 13:13:50.493: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Jul  2 13:13:50.493: INFO: Deleting all statefulset in ns statefulset-1886
Jul  2 13:13:50.496: INFO: Scaling statefulset ss to 0
Jul  2 13:14:00.527: INFO: Waiting for statefulset status.replicas updated to 0
Jul  2 13:14:00.530: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:188
Jul  2 13:14:00.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1886" for this suite.

• [SLOW TEST:20.274 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","total":356,"completed":300,"skipped":5429,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:14:00.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-699
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating pod pod-subpath-test-configmap-q9sp
STEP: Creating a pod to test atomic-volume-subpath
Jul  2 13:14:00.711: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-q9sp" in namespace "subpath-699" to be "Succeeded or Failed"
Jul  2 13:14:00.720: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Pending", Reason="", readiness=false. Elapsed: 9.115525ms
Jul  2 13:14:02.729: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 2.018240962s
Jul  2 13:14:04.736: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 4.025269545s
Jul  2 13:14:06.745: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 6.034358432s
Jul  2 13:14:08.754: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 8.043359904s
Jul  2 13:14:10.763: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 10.052494679s
Jul  2 13:14:12.772: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 12.060841617s
Jul  2 13:14:14.780: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 14.069141024s
Jul  2 13:14:16.788: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 16.076863606s
Jul  2 13:14:18.795: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 18.084393064s
Jul  2 13:14:20.806: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=true. Elapsed: 20.094836236s
Jul  2 13:14:22.818: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Running", Reason="", readiness=false. Elapsed: 22.107339401s
Jul  2 13:14:24.826: INFO: Pod "pod-subpath-test-configmap-q9sp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.115219859s
STEP: Saw pod success
Jul  2 13:14:24.826: INFO: Pod "pod-subpath-test-configmap-q9sp" satisfied condition "Succeeded or Failed"
Jul  2 13:14:24.830: INFO: Trying to get logs from node ip-172-31-69-95 pod pod-subpath-test-configmap-q9sp container test-container-subpath-configmap-q9sp: <nil>
STEP: delete the pod
Jul  2 13:14:24.852: INFO: Waiting for pod pod-subpath-test-configmap-q9sp to disappear
Jul  2 13:14:24.857: INFO: Pod pod-subpath-test-configmap-q9sp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-q9sp
Jul  2 13:14:24.857: INFO: Deleting pod "pod-subpath-test-configmap-q9sp" in namespace "subpath-699"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:188
Jul  2 13:14:24.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-699" for this suite.

• [SLOW TEST:24.313 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","total":356,"completed":301,"skipped":5446,"failed":0}
S
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:14:24.872: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename limitrange
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in limitrange-1047
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Jul  2 13:14:25.008: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Jul  2 13:14:25.018: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jul  2 13:14:25.018: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Jul  2 13:14:25.027: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jul  2 13:14:25.027: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Jul  2 13:14:25.038: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Jul  2 13:14:25.038: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Jul  2 13:14:32.087: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:188
Jul  2 13:14:32.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-1047" for this suite.

• [SLOW TEST:7.246 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":356,"completed":302,"skipped":5447,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:14:32.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4945
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a Namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nspatchtest-02fffd6a-a05e-474a-8a19-e218dfe31a95-3061
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:14:32.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4945" for this suite.
STEP: Destroying namespace "nspatchtest-02fffd6a-a05e-474a-8a19-e218dfe31a95-3061" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":356,"completed":303,"skipped":5483,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:14:32.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4504
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:61
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:188
Jul  2 13:15:32.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4504" for this suite.

• [SLOW TEST:60.164 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":356,"completed":304,"skipped":5509,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:15:32.568: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2245
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service in namespace services-2245
STEP: creating service affinity-clusterip in namespace services-2245
STEP: creating replication controller affinity-clusterip in namespace services-2245
I0702 13:15:32.725440      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-2245, replica count: 3
I0702 13:15:35.775875      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 13:15:35.787: INFO: Creating new exec pod
Jul  2 13:15:38.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-2245 exec execpod-affinitybvrdg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Jul  2 13:15:38.937: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Jul  2 13:15:38.937: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 13:15:38.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-2245 exec execpod-affinitybvrdg -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.74 80'
Jul  2 13:15:39.049: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.74 80\nConnection to 10.152.183.74 80 port [tcp/http] succeeded!\n"
Jul  2 13:15:39.049: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 13:15:39.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-2245 exec execpod-affinitybvrdg -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.74:80/ ; done'
Jul  2 13:15:39.219: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.74:80/\n"
Jul  2 13:15:39.219: INFO: stdout: "\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m\naffinity-clusterip-7bs6m"
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.219: INFO: Received response from host: affinity-clusterip-7bs6m
Jul  2 13:15:39.220: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-2245, will wait for the garbage collector to delete the pods
Jul  2 13:15:39.302: INFO: Deleting ReplicationController affinity-clusterip took: 7.683965ms
Jul  2 13:15:39.403: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.870814ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 13:15:41.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2245" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:8.770 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","total":356,"completed":305,"skipped":5517,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:15:41.338: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8601
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service multi-endpoint-test in namespace services-8601
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8601 to expose endpoints map[]
Jul  2 13:15:41.486: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Jul  2 13:15:42.497: INFO: successfully validated that service multi-endpoint-test in namespace services-8601 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-8601
Jul  2 13:15:42.511: INFO: The status of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:15:44.517: INFO: The status of Pod pod1 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8601 to expose endpoints map[pod1:[100]]
Jul  2 13:15:44.532: INFO: successfully validated that service multi-endpoint-test in namespace services-8601 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-8601
Jul  2 13:15:44.545: INFO: The status of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:15:46.553: INFO: The status of Pod pod2 is Running (Ready = true)
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8601 to expose endpoints map[pod1:[100] pod2:[101]]
Jul  2 13:15:46.573: INFO: successfully validated that service multi-endpoint-test in namespace services-8601 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods
Jul  2 13:15:46.573: INFO: Creating new exec pod
Jul  2 13:15:49.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8601 exec execpodpz9qb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Jul  2 13:15:49.763: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Jul  2 13:15:49.763: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 13:15:49.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8601 exec execpodpz9qb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.86 80'
Jul  2 13:15:49.901: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.86 80\nConnection to 10.152.183.86 80 port [tcp/http] succeeded!\n"
Jul  2 13:15:49.901: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 13:15:49.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8601 exec execpodpz9qb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Jul  2 13:15:50.019: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 81\n+ echo hostName\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Jul  2 13:15:50.019: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Jul  2 13:15:50.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8601 exec execpodpz9qb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.86 81'
Jul  2 13:15:50.143: INFO: stderr: "+ nc -v -t -w 2 10.152.183.86 81\n+ echo hostName\nConnection to 10.152.183.86 81 port [tcp/*] succeeded!\n"
Jul  2 13:15:50.143: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-8601
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8601 to expose endpoints map[pod2:[101]]
Jul  2 13:15:50.182: INFO: successfully validated that service multi-endpoint-test in namespace services-8601 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-8601
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8601 to expose endpoints map[]
Jul  2 13:15:50.207: INFO: successfully validated that service multi-endpoint-test in namespace services-8601 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 13:15:50.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8601" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:8.902 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":356,"completed":306,"skipped":5527,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery 
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:15:50.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename discovery
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in discovery-8703
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:15:51.206: INFO: Checking APIGroup: apiregistration.k8s.io
Jul  2 13:15:51.207: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Jul  2 13:15:51.207: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Jul  2 13:15:51.207: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Jul  2 13:15:51.207: INFO: Checking APIGroup: apps
Jul  2 13:15:51.208: INFO: PreferredVersion.GroupVersion: apps/v1
Jul  2 13:15:51.208: INFO: Versions found [{apps/v1 v1}]
Jul  2 13:15:51.208: INFO: apps/v1 matches apps/v1
Jul  2 13:15:51.208: INFO: Checking APIGroup: events.k8s.io
Jul  2 13:15:51.209: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Jul  2 13:15:51.209: INFO: Versions found [{events.k8s.io/v1 v1} {events.k8s.io/v1beta1 v1beta1}]
Jul  2 13:15:51.209: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Jul  2 13:15:51.209: INFO: Checking APIGroup: authentication.k8s.io
Jul  2 13:15:51.209: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Jul  2 13:15:51.209: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Jul  2 13:15:51.209: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Jul  2 13:15:51.209: INFO: Checking APIGroup: authorization.k8s.io
Jul  2 13:15:51.210: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Jul  2 13:15:51.210: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Jul  2 13:15:51.210: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Jul  2 13:15:51.210: INFO: Checking APIGroup: autoscaling
Jul  2 13:15:51.211: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Jul  2 13:15:51.211: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta1 v2beta1} {autoscaling/v2beta2 v2beta2}]
Jul  2 13:15:51.211: INFO: autoscaling/v2 matches autoscaling/v2
Jul  2 13:15:51.211: INFO: Checking APIGroup: batch
Jul  2 13:15:51.211: INFO: PreferredVersion.GroupVersion: batch/v1
Jul  2 13:15:51.212: INFO: Versions found [{batch/v1 v1} {batch/v1beta1 v1beta1}]
Jul  2 13:15:51.212: INFO: batch/v1 matches batch/v1
Jul  2 13:15:51.212: INFO: Checking APIGroup: certificates.k8s.io
Jul  2 13:15:51.212: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Jul  2 13:15:51.212: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Jul  2 13:15:51.212: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Jul  2 13:15:51.212: INFO: Checking APIGroup: networking.k8s.io
Jul  2 13:15:51.213: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Jul  2 13:15:51.213: INFO: Versions found [{networking.k8s.io/v1 v1}]
Jul  2 13:15:51.213: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Jul  2 13:15:51.213: INFO: Checking APIGroup: policy
Jul  2 13:15:51.214: INFO: PreferredVersion.GroupVersion: policy/v1
Jul  2 13:15:51.214: INFO: Versions found [{policy/v1 v1} {policy/v1beta1 v1beta1}]
Jul  2 13:15:51.214: INFO: policy/v1 matches policy/v1
Jul  2 13:15:51.214: INFO: Checking APIGroup: rbac.authorization.k8s.io
Jul  2 13:15:51.214: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Jul  2 13:15:51.214: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Jul  2 13:15:51.214: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Jul  2 13:15:51.214: INFO: Checking APIGroup: storage.k8s.io
Jul  2 13:15:51.215: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Jul  2 13:15:51.215: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Jul  2 13:15:51.215: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Jul  2 13:15:51.215: INFO: Checking APIGroup: admissionregistration.k8s.io
Jul  2 13:15:51.216: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Jul  2 13:15:51.216: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Jul  2 13:15:51.216: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Jul  2 13:15:51.216: INFO: Checking APIGroup: apiextensions.k8s.io
Jul  2 13:15:51.216: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Jul  2 13:15:51.216: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Jul  2 13:15:51.216: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Jul  2 13:15:51.216: INFO: Checking APIGroup: scheduling.k8s.io
Jul  2 13:15:51.217: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Jul  2 13:15:51.217: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Jul  2 13:15:51.217: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Jul  2 13:15:51.217: INFO: Checking APIGroup: coordination.k8s.io
Jul  2 13:15:51.218: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Jul  2 13:15:51.218: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Jul  2 13:15:51.218: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Jul  2 13:15:51.218: INFO: Checking APIGroup: node.k8s.io
Jul  2 13:15:51.219: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Jul  2 13:15:51.219: INFO: Versions found [{node.k8s.io/v1 v1} {node.k8s.io/v1beta1 v1beta1}]
Jul  2 13:15:51.219: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Jul  2 13:15:51.219: INFO: Checking APIGroup: discovery.k8s.io
Jul  2 13:15:51.219: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Jul  2 13:15:51.219: INFO: Versions found [{discovery.k8s.io/v1 v1} {discovery.k8s.io/v1beta1 v1beta1}]
Jul  2 13:15:51.220: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Jul  2 13:15:51.220: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Jul  2 13:15:51.220: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Jul  2 13:15:51.220: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Jul  2 13:15:51.220: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Jul  2 13:15:51.220: INFO: Checking APIGroup: metrics.k8s.io
Jul  2 13:15:51.221: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Jul  2 13:15:51.221: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Jul  2 13:15:51.221: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:188
Jul  2 13:15:51.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-8703" for this suite.
•{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","total":356,"completed":307,"skipped":5539,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:15:51.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4336
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:84
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  2 13:15:55.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4336" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":356,"completed":308,"skipped":5549,"failed":0}
SSSSSS
------------------------------
[sig-node] PodTemplates 
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:15:55.404: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename podtemplate
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in podtemplate-6362
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:188
Jul  2 13:15:55.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-6362" for this suite.
•{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","total":356,"completed":309,"skipped":5555,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:15:55.581: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6982
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Jul  2 13:15:58.248: INFO: Successfully updated pod "adopt-release-2qz5t"
STEP: Checking that the Job readopts the Pod
Jul  2 13:15:58.248: INFO: Waiting up to 15m0s for pod "adopt-release-2qz5t" in namespace "job-6982" to be "adopted"
Jul  2 13:15:58.252: INFO: Pod "adopt-release-2qz5t": Phase="Running", Reason="", readiness=true. Elapsed: 4.190851ms
Jul  2 13:16:00.260: INFO: Pod "adopt-release-2qz5t": Phase="Running", Reason="", readiness=true. Elapsed: 2.012294572s
Jul  2 13:16:00.260: INFO: Pod "adopt-release-2qz5t" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Jul  2 13:16:00.778: INFO: Successfully updated pod "adopt-release-2qz5t"
STEP: Checking that the Job releases the Pod
Jul  2 13:16:00.778: INFO: Waiting up to 15m0s for pod "adopt-release-2qz5t" in namespace "job-6982" to be "released"
Jul  2 13:16:00.781: INFO: Pod "adopt-release-2qz5t": Phase="Running", Reason="", readiness=true. Elapsed: 3.187911ms
Jul  2 13:16:02.790: INFO: Pod "adopt-release-2qz5t": Phase="Running", Reason="", readiness=true. Elapsed: 2.011815597s
Jul  2 13:16:02.790: INFO: Pod "adopt-release-2qz5t" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:188
Jul  2 13:16:02.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6982" for this suite.

• [SLOW TEST:7.221 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":356,"completed":310,"skipped":5563,"failed":0}
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:02.802: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1136
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-42a2f4f5-1b72-43a4-a569-ff3f62462c57
STEP: Creating a pod to test consume configMaps
Jul  2 13:16:02.952: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35" in namespace "projected-1136" to be "Succeeded or Failed"
Jul  2 13:16:02.955: INFO: Pod "pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35": Phase="Pending", Reason="", readiness=false. Elapsed: 3.087488ms
Jul  2 13:16:04.962: INFO: Pod "pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010420538s
Jul  2 13:16:06.971: INFO: Pod "pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018663568s
STEP: Saw pod success
Jul  2 13:16:06.971: INFO: Pod "pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35" satisfied condition "Succeeded or Failed"
Jul  2 13:16:06.975: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 13:16:07.008: INFO: Waiting for pod pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35 to disappear
Jul  2 13:16:07.012: INFO: Pod pod-projected-configmaps-81c8f22c-3502-4825-80f2-1e3214105d35 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 13:16:07.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1136" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":356,"completed":311,"skipped":5565,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:07.024: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6136
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating secret with name secret-test-4fe4e7df-b920-4573-9728-618e76201b01
STEP: Creating a pod to test consume secrets
Jul  2 13:16:07.174: INFO: Waiting up to 5m0s for pod "pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8" in namespace "secrets-6136" to be "Succeeded or Failed"
Jul  2 13:16:07.177: INFO: Pod "pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.155952ms
Jul  2 13:16:09.187: INFO: Pod "pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013198553s
Jul  2 13:16:11.195: INFO: Pod "pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021040728s
STEP: Saw pod success
Jul  2 13:16:11.195: INFO: Pod "pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8" satisfied condition "Succeeded or Failed"
Jul  2 13:16:11.200: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8 container secret-volume-test: <nil>
STEP: delete the pod
Jul  2 13:16:11.219: INFO: Waiting for pod pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8 to disappear
Jul  2 13:16:11.228: INFO: Pod pod-secrets-b6422d19-88a7-44c3-8141-7ed707a34fb8 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:188
Jul  2 13:16:11.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6136" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":356,"completed":312,"skipped":5626,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container 
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:11.239: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4496
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jul  2 13:16:15.415: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:188
Jul  2 13:16:15.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4496" for this suite.
•{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":356,"completed":313,"skipped":5635,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:15.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6433
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Jul  2 13:16:15.588: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6433  c2f75c18-7434-4c63-b696-1d88f2acdbab 35582 0 2022-07-02 13:16:15 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  [{e2e.test Update v1 2022-07-02 13:16:15 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hcstx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:k8s.gcr.io/e2e-test-images/agnhost:2.39,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hcstx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jul  2 13:16:15.591: INFO: The status of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:16:17.600: INFO: The status of Pod test-dns-nameservers is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Jul  2 13:16:17.600: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6433 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 13:16:17.600: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 13:16:17.601: INFO: ExecWithOptions: Clientset creation
Jul  2 13:16:17.601: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-6433/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod...
Jul  2 13:16:17.703: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6433 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 13:16:17.703: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 13:16:17.704: INFO: ExecWithOptions: Clientset creation
Jul  2 13:16:17.704: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-6433/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  2 13:16:17.799: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 13:16:17.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6433" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":356,"completed":314,"skipped":5652,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:17.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2530
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:40
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:16:17.975: INFO: The status of Pod busybox-readonly-fsf658559c-b8d3-4508-bd49-ffee93cf224d is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:16:19.985: INFO: The status of Pod busybox-readonly-fsf658559c-b8d3-4508-bd49-ffee93cf224d is Running (Ready = true)
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:188
Jul  2 13:16:20.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2530" for this suite.
•{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":315,"skipped":5681,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:20.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2805
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:16:20.151: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:16:21.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2805" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":356,"completed":316,"skipped":5739,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:21.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2754
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:188
Jul  2 13:16:37.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2754" for this suite.

• [SLOW TEST:16.292 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":356,"completed":317,"skipped":5769,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:37.486: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6327
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with secret that has name projected-secret-test-ee27e8b3-e4ec-4f69-9f98-00e2f3159aa3
STEP: Creating a pod to test consume secrets
Jul  2 13:16:37.637: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3" in namespace "projected-6327" to be "Succeeded or Failed"
Jul  2 13:16:37.641: INFO: Pod "pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.900023ms
Jul  2 13:16:39.650: INFO: Pod "pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013140232s
Jul  2 13:16:41.659: INFO: Pod "pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021728369s
STEP: Saw pod success
Jul  2 13:16:41.659: INFO: Pod "pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3" satisfied condition "Succeeded or Failed"
Jul  2 13:16:41.663: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jul  2 13:16:41.686: INFO: Waiting for pod pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3 to disappear
Jul  2 13:16:41.690: INFO: Pod pod-projected-secrets-aaaf30fa-ae1c-4836-b630-9bde727b46a3 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:188
Jul  2 13:16:41.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6327" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":318,"skipped":5781,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:41.708: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3877
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:16:42.523: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:16:45.550: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:16:45.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3877" for this suite.
STEP: Destroying namespace "webhook-3877-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":356,"completed":319,"skipped":5792,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:45.684: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6588
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:191
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jul  2 13:16:45.825: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying pod deletion was observed
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:188
Jul  2 13:16:50.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6588" for this suite.
•{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","total":356,"completed":320,"skipped":5850,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:50.447: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9945
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on node default medium
Jul  2 13:16:50.589: INFO: Waiting up to 5m0s for pod "pod-f99d277f-dc10-488b-833b-2e41ee1c32ed" in namespace "emptydir-9945" to be "Succeeded or Failed"
Jul  2 13:16:50.593: INFO: Pod "pod-f99d277f-dc10-488b-833b-2e41ee1c32ed": Phase="Pending", Reason="", readiness=false. Elapsed: 3.07362ms
Jul  2 13:16:52.602: INFO: Pod "pod-f99d277f-dc10-488b-833b-2e41ee1c32ed": Phase="Running", Reason="", readiness=false. Elapsed: 2.012751883s
Jul  2 13:16:54.607: INFO: Pod "pod-f99d277f-dc10-488b-833b-2e41ee1c32ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017970566s
STEP: Saw pod success
Jul  2 13:16:54.607: INFO: Pod "pod-f99d277f-dc10-488b-833b-2e41ee1c32ed" satisfied condition "Succeeded or Failed"
Jul  2 13:16:54.611: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-f99d277f-dc10-488b-833b-2e41ee1c32ed container test-container: <nil>
STEP: delete the pod
Jul  2 13:16:54.635: INFO: Waiting for pod pod-f99d277f-dc10-488b-833b-2e41ee1c32ed to disappear
Jul  2 13:16:54.638: INFO: Pod pod-f99d277f-dc10-488b-833b-2e41ee1c32ed no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 13:16:54.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9945" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":321,"skipped":5878,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:54.651: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1191
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 13:16:54.794: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351" in namespace "downward-api-1191" to be "Succeeded or Failed"
Jul  2 13:16:54.799: INFO: Pod "downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351": Phase="Pending", Reason="", readiness=false. Elapsed: 4.286155ms
Jul  2 13:16:56.807: INFO: Pod "downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012883751s
Jul  2 13:16:58.815: INFO: Pod "downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020972138s
STEP: Saw pod success
Jul  2 13:16:58.815: INFO: Pod "downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351" satisfied condition "Succeeded or Failed"
Jul  2 13:16:58.820: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351 container client-container: <nil>
STEP: delete the pod
Jul  2 13:16:58.840: INFO: Waiting for pod downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351 to disappear
Jul  2 13:16:58.844: INFO: Pod downwardapi-volume-19a1dec0-c7de-4d6f-9611-e09e77dd2351 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 13:16:58.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1191" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":322,"skipped":5890,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:16:58.855: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6497
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jul  2 13:16:59.000: INFO: Waiting up to 5m0s for pod "pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec" in namespace "emptydir-6497" to be "Succeeded or Failed"
Jul  2 13:16:59.003: INFO: Pod "pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.185252ms
Jul  2 13:17:01.011: INFO: Pod "pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011433533s
Jul  2 13:17:03.019: INFO: Pod "pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019940149s
STEP: Saw pod success
Jul  2 13:17:03.020: INFO: Pod "pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec" satisfied condition "Succeeded or Failed"
Jul  2 13:17:03.023: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec container test-container: <nil>
STEP: delete the pod
Jul  2 13:17:03.047: INFO: Waiting for pod pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec to disappear
Jul  2 13:17:03.051: INFO: Pod pod-17dd9556-e72f-44e4-98e2-c786a7dfcdec no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:188
Jul  2 13:17:03.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6497" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":323,"skipped":5926,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:17:03.063: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2308
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap configmap-2308/configmap-test-744beb17-4499-4fe6-8fee-efa8bd55946d
STEP: Creating a pod to test consume configMaps
Jul  2 13:17:03.210: INFO: Waiting up to 5m0s for pod "pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c" in namespace "configmap-2308" to be "Succeeded or Failed"
Jul  2 13:17:03.216: INFO: Pod "pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.590085ms
Jul  2 13:17:05.224: INFO: Pod "pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014235651s
Jul  2 13:17:07.233: INFO: Pod "pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023140753s
STEP: Saw pod success
Jul  2 13:17:07.233: INFO: Pod "pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c" satisfied condition "Succeeded or Failed"
Jul  2 13:17:07.238: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c container env-test: <nil>
STEP: delete the pod
Jul  2 13:17:07.261: INFO: Waiting for pod pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c to disappear
Jul  2 13:17:07.264: INFO: Pod pod-configmaps-b83eef58-eec8-46d7-ae0c-d6d72f6ea39c no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:188
Jul  2 13:17:07.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2308" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":356,"completed":324,"skipped":5990,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:17:07.276: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-642
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 13:17:07.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8" in namespace "projected-642" to be "Succeeded or Failed"
Jul  2 13:17:07.427: INFO: Pod "downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885549ms
Jul  2 13:17:09.437: INFO: Pod "downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013866847s
Jul  2 13:17:11.445: INFO: Pod "downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021502251s
STEP: Saw pod success
Jul  2 13:17:11.445: INFO: Pod "downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8" satisfied condition "Succeeded or Failed"
Jul  2 13:17:11.449: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8 container client-container: <nil>
STEP: delete the pod
Jul  2 13:17:11.473: INFO: Waiting for pod downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8 to disappear
Jul  2 13:17:11.476: INFO: Pod downwardapi-volume-499ce7c9-fae7-4df7-b137-b2a96b7bd7b8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 13:17:11.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-642" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":356,"completed":325,"skipped":6020,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:17:11.488: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8799
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Performing setup for networking test in namespace pod-network-test-8799
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jul  2 13:17:11.622: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jul  2 13:17:11.660: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:17:13.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:15.668: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:17.671: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:19.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:21.668: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:23.675: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:25.667: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:27.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:29.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:31.669: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jul  2 13:17:33.670: INFO: The status of Pod netserver-0 is Running (Ready = true)
Jul  2 13:17:33.678: INFO: The status of Pod netserver-1 is Running (Ready = true)
Jul  2 13:17:33.685: INFO: The status of Pod netserver-2 is Running (Ready = true)
STEP: Creating test pods
Jul  2 13:17:35.727: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Jul  2 13:17:35.728: INFO: Going to poll 192.168.74.154 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul  2 13:17:35.731: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.74.154 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8799 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 13:17:35.731: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 13:17:35.731: INFO: ExecWithOptions: Clientset creation
Jul  2 13:17:35.732: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8799/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.74.154+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  2 13:17:36.823: INFO: Found all 1 expected endpoints: [netserver-0]
Jul  2 13:17:36.823: INFO: Going to poll 192.168.231.37 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul  2 13:17:36.832: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.231.37 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8799 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 13:17:36.832: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 13:17:36.832: INFO: ExecWithOptions: Clientset creation
Jul  2 13:17:36.833: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8799/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.231.37+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  2 13:17:37.946: INFO: Found all 1 expected endpoints: [netserver-1]
Jul  2 13:17:37.946: INFO: Going to poll 192.168.64.159 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Jul  2 13:17:37.952: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.64.159 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8799 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Jul  2 13:17:37.952: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
Jul  2 13:17:37.953: INFO: ExecWithOptions: Clientset creation
Jul  2 13:17:37.953: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8799/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.64.159+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Jul  2 13:17:39.043: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:188
Jul  2 13:17:39.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8799" for this suite.

• [SLOW TEST:27.574 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":326,"skipped":6031,"failed":0}
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:17:39.062: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-790
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jul  2 13:17:39.206: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36310 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 13:17:39.206: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36310 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jul  2 13:17:39.214: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36311 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 13:17:39.214: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36311 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jul  2 13:17:39.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36312 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 13:17:39.223: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36312 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jul  2 13:17:39.231: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36313 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 13:17:39.231: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-790  cef1e17d-7cab-4070-a7ab-a325535eb2cc 36313 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jul  2 13:17:39.235: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-790  513496cf-5b79-49df-b7af-80a1fe21fa1c 36314 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 13:17:39.236: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-790  513496cf-5b79-49df-b7af-80a1fe21fa1c 36314 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jul  2 13:17:49.258: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-790  513496cf-5b79-49df-b7af-80a1fe21fa1c 36388 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jul  2 13:17:49.258: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-790  513496cf-5b79-49df-b7af-80a1fe21fa1c 36388 0 2022-07-02 13:17:39 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2022-07-02 13:17:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:188
Jul  2 13:17:59.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-790" for this suite.

• [SLOW TEST:20.224 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":356,"completed":327,"skipped":6031,"failed":0}
SSSSSS
------------------------------
[sig-node] RuntimeClass 
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:17:59.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename runtimeclass
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in runtimeclass-9915
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  2 13:17:59.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9915" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","total":356,"completed":328,"skipped":6037,"failed":0}
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:17:59.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8375
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name projected-configmap-test-volume-map-0bd5457d-3bca-43a6-838e-73c69ac1e97b
STEP: Creating a pod to test consume configMaps
Jul  2 13:17:59.591: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7" in namespace "projected-8375" to be "Succeeded or Failed"
Jul  2 13:17:59.594: INFO: Pod "pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.934594ms
Jul  2 13:18:01.602: INFO: Pod "pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011693483s
Jul  2 13:18:03.610: INFO: Pod "pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019296701s
STEP: Saw pod success
Jul  2 13:18:03.610: INFO: Pod "pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7" satisfied condition "Succeeded or Failed"
Jul  2 13:18:03.614: INFO: Trying to get logs from node ip-172-31-9-92 pod pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7 container agnhost-container: <nil>
STEP: delete the pod
Jul  2 13:18:03.637: INFO: Waiting for pod pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7 to disappear
Jul  2 13:18:03.641: INFO: Pod pod-projected-configmaps-0b75a918-d581-46dd-bbd8-ced6e47ed2c7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 13:18:03.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8375" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":329,"skipped":6038,"failed":0}
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:18:03.653: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4014
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:18:03.808: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jul  2 13:18:03.818: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:03.818: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched.
Jul  2 13:18:03.837: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:03.837: INFO: Node ip-172-31-91-232 is running 0 daemon pod, expected 1
Jul  2 13:18:04.842: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:04.842: INFO: Node ip-172-31-91-232 is running 0 daemon pod, expected 1
Jul  2 13:18:05.845: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  2 13:18:05.845: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jul  2 13:18:05.865: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  2 13:18:05.865: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Jul  2 13:18:06.872: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:06.872: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jul  2 13:18:06.887: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:06.887: INFO: Node ip-172-31-91-232 is running 0 daemon pod, expected 1
Jul  2 13:18:07.894: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:07.894: INFO: Node ip-172-31-91-232 is running 0 daemon pod, expected 1
Jul  2 13:18:08.894: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:08.894: INFO: Node ip-172-31-91-232 is running 0 daemon pod, expected 1
Jul  2 13:18:09.894: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Jul  2 13:18:09.894: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4014, will wait for the garbage collector to delete the pods
Jul  2 13:18:09.964: INFO: Deleting DaemonSet.extensions daemon-set took: 8.037119ms
Jul  2 13:18:10.064: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.451179ms
Jul  2 13:18:12.173: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Jul  2 13:18:12.173: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Jul  2 13:18:12.177: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"36558"},"items":null}

Jul  2 13:18:12.181: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"36558"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:18:12.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4014" for this suite.

• [SLOW TEST:8.653 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":356,"completed":330,"skipped":6039,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:18:12.307: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7079
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test env composition
Jul  2 13:18:12.449: INFO: Waiting up to 5m0s for pod "var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68" in namespace "var-expansion-7079" to be "Succeeded or Failed"
Jul  2 13:18:12.452: INFO: Pod "var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68": Phase="Pending", Reason="", readiness=false. Elapsed: 3.016915ms
Jul  2 13:18:14.459: INFO: Pod "var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010186802s
Jul  2 13:18:16.468: INFO: Pod "var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019276421s
STEP: Saw pod success
Jul  2 13:18:16.468: INFO: Pod "var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68" satisfied condition "Succeeded or Failed"
Jul  2 13:18:16.471: INFO: Trying to get logs from node ip-172-31-9-92 pod var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68 container dapi-container: <nil>
STEP: delete the pod
Jul  2 13:18:16.496: INFO: Waiting for pod var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68 to disappear
Jul  2 13:18:16.499: INFO: Pod var-expansion-d760a5d6-3117-4056-b532-d21eaa7bfd68 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:188
Jul  2 13:18:16.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7079" for this suite.
•{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":356,"completed":331,"skipped":6101,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:18:16.511: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2380
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:18:17.142: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:18:20.172: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Jul  2 13:18:20.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:18:20.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2380" for this suite.
STEP: Destroying namespace "webhook-2380-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":356,"completed":332,"skipped":6105,"failed":0}
SSSSSSS
------------------------------
[sig-node] Security Context 
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:18:20.273: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename security-context
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-8476
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser
Jul  2 13:18:20.415: INFO: Waiting up to 5m0s for pod "security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53" in namespace "security-context-8476" to be "Succeeded or Failed"
Jul  2 13:18:20.419: INFO: Pod "security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53": Phase="Pending", Reason="", readiness=false. Elapsed: 3.990942ms
Jul  2 13:18:22.428: INFO: Pod "security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013383292s
Jul  2 13:18:24.440: INFO: Pod "security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02490965s
STEP: Saw pod success
Jul  2 13:18:24.440: INFO: Pod "security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53" satisfied condition "Succeeded or Failed"
Jul  2 13:18:24.444: INFO: Trying to get logs from node ip-172-31-9-92 pod security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53 container test-container: <nil>
STEP: delete the pod
Jul  2 13:18:24.471: INFO: Waiting for pod security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53 to disappear
Jul  2 13:18:24.475: INFO: Pod security-context-7eb35799-dd50-4415-a223-eaaa1c11fb53 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  2 13:18:24.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-8476" for this suite.
•{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","total":356,"completed":333,"skipped":6112,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:18:24.490: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7478
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jul  2 13:18:24.952: INFO: Pod name wrapped-volume-race-dd54ab1c-d4a2-452a-a4f5-8a3b33714d38: Found 1 pods out of 5
Jul  2 13:18:29.967: INFO: Pod name wrapped-volume-race-dd54ab1c-d4a2-452a-a4f5-8a3b33714d38: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dd54ab1c-d4a2-452a-a4f5-8a3b33714d38 in namespace emptydir-wrapper-7478, will wait for the garbage collector to delete the pods
Jul  2 13:18:40.070: INFO: Deleting ReplicationController wrapped-volume-race-dd54ab1c-d4a2-452a-a4f5-8a3b33714d38 took: 10.576628ms
Jul  2 13:18:40.171: INFO: Terminating ReplicationController wrapped-volume-race-dd54ab1c-d4a2-452a-a4f5-8a3b33714d38 pods took: 100.388669ms
STEP: Creating RC which spawns configmap-volume pods
Jul  2 13:18:43.801: INFO: Pod name wrapped-volume-race-ee661010-f43a-4353-9fb3-854034b72595: Found 0 pods out of 5
Jul  2 13:18:48.816: INFO: Pod name wrapped-volume-race-ee661010-f43a-4353-9fb3-854034b72595: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ee661010-f43a-4353-9fb3-854034b72595 in namespace emptydir-wrapper-7478, will wait for the garbage collector to delete the pods
Jul  2 13:19:00.908: INFO: Deleting ReplicationController wrapped-volume-race-ee661010-f43a-4353-9fb3-854034b72595 took: 8.868289ms
Jul  2 13:19:01.009: INFO: Terminating ReplicationController wrapped-volume-race-ee661010-f43a-4353-9fb3-854034b72595 pods took: 101.026245ms
STEP: Creating RC which spawns configmap-volume pods
Jul  2 13:19:04.337: INFO: Pod name wrapped-volume-race-463a51cc-59e1-46f6-97fe-2d9ed7550d5f: Found 0 pods out of 5
Jul  2 13:19:09.351: INFO: Pod name wrapped-volume-race-463a51cc-59e1-46f6-97fe-2d9ed7550d5f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-463a51cc-59e1-46f6-97fe-2d9ed7550d5f in namespace emptydir-wrapper-7478, will wait for the garbage collector to delete the pods
Jul  2 13:19:19.442: INFO: Deleting ReplicationController wrapped-volume-race-463a51cc-59e1-46f6-97fe-2d9ed7550d5f took: 8.680299ms
Jul  2 13:19:19.542: INFO: Terminating ReplicationController wrapped-volume-race-463a51cc-59e1-46f6-97fe-2d9ed7550d5f pods took: 100.430776ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:188
Jul  2 13:19:23.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7478" for this suite.

• [SLOW TEST:59.320 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":356,"completed":334,"skipped":6114,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:19:23.811: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2312
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2312 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2312;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2312 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2312;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2312.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2312.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2312.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2312.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2312.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2312.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2312.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2312.svc;check="$$(dig +notcp +noall +answer +search 65.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.65_udp@PTR;check="$$(dig +tcp +noall +answer +search 65.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.65_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2312 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2312;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2312 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2312;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2312.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2312.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2312.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2312.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2312.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2312.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2312.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2312.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2312.svc;check="$$(dig +notcp +noall +answer +search 65.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.65_udp@PTR;check="$$(dig +tcp +noall +answer +search 65.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.65_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jul  2 13:19:26.000: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.004: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.009: INFO: Unable to read wheezy_udp@dns-test-service.dns-2312 from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.012: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2312 from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.016: INFO: Unable to read wheezy_udp@dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.021: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.024: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.028: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.047: INFO: Unable to read jessie_udp@dns-test-service from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.051: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.055: INFO: Unable to read jessie_udp@dns-test-service.dns-2312 from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.059: INFO: Unable to read jessie_tcp@dns-test-service.dns-2312 from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.063: INFO: Unable to read jessie_udp@dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.067: INFO: Unable to read jessie_tcp@dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.071: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.075: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:26.091: INFO: Lookups using dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-2312 wheezy_tcp@dns-test-service.dns-2312 wheezy_udp@dns-test-service.dns-2312.svc wheezy_tcp@dns-test-service.dns-2312.svc wheezy_udp@_http._tcp.dns-test-service.dns-2312.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2312.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-2312 jessie_tcp@dns-test-service.dns-2312 jessie_udp@dns-test-service.dns-2312.svc jessie_tcp@dns-test-service.dns-2312.svc jessie_udp@_http._tcp.dns-test-service.dns-2312.svc jessie_tcp@_http._tcp.dns-test-service.dns-2312.svc]

Jul  2 13:19:31.121: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:31.125: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2312.svc from pod dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f: the server could not find the requested resource (get pods dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f)
Jul  2 13:19:31.186: INFO: Lookups using dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-2312.svc wheezy_tcp@_http._tcp.dns-test-service.dns-2312.svc]

Jul  2 13:19:36.191: INFO: DNS probes using dns-2312/dns-test-4540bebb-56b0-4efd-b3fc-cb7c80fd561f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:188
Jul  2 13:19:36.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2312" for this suite.

• [SLOW TEST:12.445 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":356,"completed":335,"skipped":6163,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:19:36.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6687
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:19:36.814: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jul  2 13:19:38.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.July, 2, 13, 19, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 19, 36, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.July, 2, 13, 19, 36, 0, time.Local), LastTransitionTime:time.Date(2022, time.July, 2, 13, 19, 36, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-68c7bd4684\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:19:41.853: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:19:41.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6687" for this suite.
STEP: Destroying namespace "webhook-6687-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:5.706 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":356,"completed":336,"skipped":6163,"failed":0}
[sig-node] RuntimeClass 
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:19:41.962: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename runtimeclass
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in runtimeclass-8766
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:188
Jul  2 13:19:44.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8766" for this suite.
•{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","total":356,"completed":337,"skipped":6163,"failed":0}
SSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:19:44.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8979
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating service nodeport-test with type=NodePort in namespace services-8979
STEP: creating replication controller nodeport-test in namespace services-8979
I0702 13:19:44.308864      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8979, replica count: 2
I0702 13:19:47.359690      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 13:19:47.359: INFO: Creating new exec pod
Jul  2 13:19:50.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8979 exec execpodmlbr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Jul  2 13:19:50.524: INFO: stderr: "+ nc -v -t -w 2 nodeport-test 80\n+ echo hostName\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jul  2 13:19:50.524: INFO: stdout: "nodeport-test-m5zvn"
Jul  2 13:19:50.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8979 exec execpodmlbr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.22 80'
Jul  2 13:19:50.629: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.22 80\nConnection to 10.152.183.22 80 port [tcp/http] succeeded!\n"
Jul  2 13:19:50.629: INFO: stdout: "nodeport-test-75lds"
Jul  2 13:19:50.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8979 exec execpodmlbr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.9.92 30514'
Jul  2 13:19:50.744: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.9.92 30514\nConnection to 172.31.9.92 30514 port [tcp/*] succeeded!\n"
Jul  2 13:19:50.744: INFO: stdout: "nodeport-test-75lds"
Jul  2 13:19:50.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=services-8979 exec execpodmlbr4 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.69.95 30514'
Jul  2 13:19:50.876: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.69.95 30514\nConnection to 172.31.69.95 30514 port [tcp/*] succeeded!\n"
Jul  2 13:19:50.876: INFO: stdout: "nodeport-test-75lds"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:188
Jul  2 13:19:50.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8979" for this suite.
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762

• [SLOW TEST:6.741 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":356,"completed":338,"skipped":6168,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:19:50.891: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2123
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating projection with configMap that has name projected-configmap-test-upd-f7ac6189-9448-4fc7-a12c-01a4403ef382
STEP: Creating the pod
Jul  2 13:19:51.055: INFO: The status of Pod pod-projected-configmaps-11d7df5d-d555-4728-99cd-bb6e2a4eddee is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:19:53.064: INFO: The status of Pod pod-projected-configmaps-11d7df5d-d555-4728-99cd-bb6e2a4eddee is Running (Ready = true)
STEP: Updating configmap projected-configmap-test-upd-f7ac6189-9448-4fc7-a12c-01a4403ef382
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:188
Jul  2 13:19:57.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2123" for this suite.

• [SLOW TEST:6.230 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":356,"completed":339,"skipped":6181,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:19:57.122: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7757
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 13:19:57.270: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b" in namespace "projected-7757" to be "Succeeded or Failed"
Jul  2 13:19:57.273: INFO: Pod "downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.554819ms
Jul  2 13:19:59.282: INFO: Pod "downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012321682s
Jul  2 13:20:01.289: INFO: Pod "downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019540291s
STEP: Saw pod success
Jul  2 13:20:01.289: INFO: Pod "downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b" satisfied condition "Succeeded or Failed"
Jul  2 13:20:01.293: INFO: Trying to get logs from node ip-172-31-9-92 pod downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b container client-container: <nil>
STEP: delete the pod
Jul  2 13:20:01.318: INFO: Waiting for pod downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b to disappear
Jul  2 13:20:01.322: INFO: Pod downwardapi-volume-4fc197a9-e7c7-435d-a9c7-3a8fe9932b6b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:188
Jul  2 13:20:01.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7757" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":356,"completed":340,"skipped":6191,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:01.336: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-604
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
STEP: set up a multi version CRD
Jul  2 13:20:01.469: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:20:16.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-604" for this suite.

• [SLOW TEST:14.767 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":356,"completed":341,"skipped":6237,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:16.104: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-4043
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating server pod server in namespace prestop-4043
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4043
STEP: Deleting pre-stop pod
Jul  2 13:20:25.303: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:188
Jul  2 13:20:25.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4043" for this suite.

• [SLOW TEST:9.229 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":356,"completed":342,"skipped":6275,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:25.334: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-14
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating a pod to test downward API volume plugin
Jul  2 13:20:25.485: INFO: Waiting up to 5m0s for pod "downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925" in namespace "downward-api-14" to be "Succeeded or Failed"
Jul  2 13:20:25.492: INFO: Pod "downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925": Phase="Pending", Reason="", readiness=false. Elapsed: 6.470837ms
Jul  2 13:20:27.503: INFO: Pod "downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017764669s
Jul  2 13:20:29.514: INFO: Pod "downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029373176s
STEP: Saw pod success
Jul  2 13:20:29.514: INFO: Pod "downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925" satisfied condition "Succeeded or Failed"
Jul  2 13:20:29.520: INFO: Trying to get logs from node ip-172-31-69-95 pod downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925 container client-container: <nil>
STEP: delete the pod
Jul  2 13:20:29.554: INFO: Waiting for pod downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925 to disappear
Jul  2 13:20:29.558: INFO: Pod downwardapi-volume-179641c2-70c4-42bb-9200-571c5c436925 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:188
Jul  2 13:20:29.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-14" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":356,"completed":343,"skipped":6298,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:29.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3773
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:20:29.712: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Jul  2 13:20:31.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3773 --namespace=crd-publish-openapi-3773 create -f -'
Jul  2 13:20:32.528: INFO: stderr: ""
Jul  2 13:20:32.528: INFO: stdout: "e2e-test-crd-publish-openapi-2812-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jul  2 13:20:32.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3773 --namespace=crd-publish-openapi-3773 delete e2e-test-crd-publish-openapi-2812-crds test-cr'
Jul  2 13:20:32.590: INFO: stderr: ""
Jul  2 13:20:32.590: INFO: stdout: "e2e-test-crd-publish-openapi-2812-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Jul  2 13:20:32.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3773 --namespace=crd-publish-openapi-3773 apply -f -'
Jul  2 13:20:33.144: INFO: stderr: ""
Jul  2 13:20:33.144: INFO: stdout: "e2e-test-crd-publish-openapi-2812-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jul  2 13:20:33.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3773 --namespace=crd-publish-openapi-3773 delete e2e-test-crd-publish-openapi-2812-crds test-cr'
Jul  2 13:20:33.206: INFO: stderr: ""
Jul  2 13:20:33.206: INFO: stdout: "e2e-test-crd-publish-openapi-2812-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jul  2 13:20:33.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-3773 explain e2e-test-crd-publish-openapi-2812-crds'
Jul  2 13:20:33.349: INFO: stderr: ""
Jul  2 13:20:33.349: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2812-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:20:35.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3773" for this suite.

• [SLOW TEST:6.004 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":356,"completed":344,"skipped":6299,"failed":0}
SSSSSSS
------------------------------
[sig-apps] DisruptionController 
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:35.583: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename disruption
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in disruption-1106
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
STEP: creating the pdb
STEP: Waiting for the pdb to be processed
STEP: updating the pdb
STEP: Waiting for the pdb to be processed
STEP: patching the pdb
STEP: Waiting for the pdb to be processed
STEP: Waiting for the pdb to be deleted
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:188
Jul  2 13:20:41.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1106" for this suite.

• [SLOW TEST:6.221 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","total":356,"completed":345,"skipped":6306,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:41.804: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7513
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:20:41.936: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties
Jul  2 13:20:44.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7513 --namespace=crd-publish-openapi-7513 create -f -'
Jul  2 13:20:44.744: INFO: stderr: ""
Jul  2 13:20:44.744: INFO: stdout: "e2e-test-crd-publish-openapi-4500-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jul  2 13:20:44.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7513 --namespace=crd-publish-openapi-7513 delete e2e-test-crd-publish-openapi-4500-crds test-cr'
Jul  2 13:20:44.807: INFO: stderr: ""
Jul  2 13:20:44.807: INFO: stdout: "e2e-test-crd-publish-openapi-4500-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Jul  2 13:20:44.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7513 --namespace=crd-publish-openapi-7513 apply -f -'
Jul  2 13:20:45.395: INFO: stderr: ""
Jul  2 13:20:45.395: INFO: stdout: "e2e-test-crd-publish-openapi-4500-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jul  2 13:20:45.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7513 --namespace=crd-publish-openapi-7513 delete e2e-test-crd-publish-openapi-4500-crds test-cr'
Jul  2 13:20:45.461: INFO: stderr: ""
Jul  2 13:20:45.461: INFO: stdout: "e2e-test-crd-publish-openapi-4500-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Jul  2 13:20:45.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3899944901 --namespace=crd-publish-openapi-7513 explain e2e-test-crd-publish-openapi-4500-crds'
Jul  2 13:20:45.600: INFO: stderr: ""
Jul  2 13:20:45.600: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4500-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:20:47.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7513" for this suite.

• [SLOW TEST:5.954 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":356,"completed":346,"skipped":6314,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:47.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2707
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:20:48.345: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:20:51.374: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:20:51.382: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4027-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:20:54.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2707" for this suite.
STEP: Destroying namespace "webhook-2707-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104

• [SLOW TEST:6.838 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":356,"completed":347,"skipped":6319,"failed":0}
SSSSSSSS
------------------------------
[sig-network] EndpointSlice 
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:54.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename endpointslice
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in endpointslice-4002
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:20:54.770: INFO: Endpoints addresses: [172.31.41.146 172.31.75.221] , ports: [6443]
Jul  2 13:20:54.770: INFO: EndpointSlices addresses: [172.31.41.146 172.31.75.221] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:188
Jul  2 13:20:54.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4002" for this suite.
•{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","total":356,"completed":348,"skipped":6327,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:54.781: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6264
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/framework/framework.go:652
STEP: Given a Pod with a 'name' label pod-adoption is created
Jul  2 13:20:54.931: INFO: The status of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:20:56.939: INFO: The status of Pod pod-adoption is Running (Ready = true)
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:188
Jul  2 13:20:57.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6264" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":356,"completed":349,"skipped":6349,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:20:57.979: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6423
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  2 13:20:58.111: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  2 13:20:58.120: INFO: Waiting for terminating namespaces to be deleted...
Jul  2 13:20:58.123: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-69-95 before test
Jul  2 13:20:58.128: INFO: nginx-ingress-controller-kubernetes-worker-7hv6n from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:21 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.128: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 13:20:58.128: INFO: sonobuoy-e2e-job-6916416ad43a4efe from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:20:58.128: INFO: 	Container e2e ready: true, restart count 0
Jul  2 13:20:58.128: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:20:58.128: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-z6zqf from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:20:58.128: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:20:58.128: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 13:20:58.128: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-9-92 before test
Jul  2 13:20:58.134: INFO: nginx-ingress-controller-kubernetes-worker-j6wk6 from ingress-nginx-kubernetes-worker started at 2022-07-02 12:48:25 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.134: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 13:20:58.134: INFO: pod-adoption from replication-controller-6264 started at 2022-07-02 13:20:54 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.134: INFO: 	Container pod-adoption ready: true, restart count 0
Jul  2 13:20:58.134: INFO: sonobuoy from sonobuoy started at 2022-07-02 11:53:23 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.134: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  2 13:20:58.134: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-x2r94 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:20:58.134: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:20:58.134: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 13:20:58.134: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-91-232 before test
Jul  2 13:20:58.142: INFO: default-http-backend-kubernetes-worker-6c59687bf6-gqrng from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.142: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 1
Jul  2 13:20:58.142: INFO: nginx-ingress-controller-kubernetes-worker-xvwtz from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.142: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 13:20:58.142: INFO: calico-kube-controllers-7f4ccc6cf4-qt6b5 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.142: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  2 13:20:58.142: INFO: coredns-86c98bfcdb-tftgb from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.142: INFO: 	Container coredns ready: true, restart count 0
Jul  2 13:20:58.142: INFO: kube-state-metrics-5cdbfd47b4-xkmd6 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.143: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jul  2 13:20:58.143: INFO: metrics-server-v0.5.2-6bfd958b56-2pqsv from kube-system started at 2022-07-02 11:49:20 +0000 UTC (2 container statuses recorded)
Jul  2 13:20:58.143: INFO: 	Container metrics-server ready: true, restart count 0
Jul  2 13:20:58.143: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jul  2 13:20:58.143: INFO: dashboard-metrics-scraper-8669b59d4f-ftfm8 from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.143: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Jul  2 13:20:58.143: INFO: kubernetes-dashboard-585fc6bc87-ls4qj from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:20:58.143: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jul  2 13:20:58.143: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-4w8j4 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:20:58.143: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:20:58.143: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4c346f57-03d5-4832-895b-d098cbd58e20 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.69.95 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-4c346f57-03d5-4832-895b-d098cbd58e20 off the node ip-172-31-69-95
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4c346f57-03d5-4832-895b-d098cbd58e20
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:26:02.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6423" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83

• [SLOW TEST:304.309 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":356,"completed":350,"skipped":6485,"failed":0}
SSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:26:02.289: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3046
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request.
Jul  2 13:26:02.452: INFO: The status of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:26:04.459: INFO: The status of Pod pod-handle-http-request is Running (Ready = true)
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: create the pod with lifecycle hook
Jul  2 13:26:04.477: INFO: The status of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Jul  2 13:26:06.483: INFO: The status of Pod pod-with-poststart-exec-hook is Running (Ready = true)
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jul  2 13:26:06.518: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  2 13:26:06.524: INFO: Pod pod-with-poststart-exec-hook still exists
Jul  2 13:26:08.524: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jul  2 13:26:08.530: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:188
Jul  2 13:26:08.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3046" for this suite.

• [SLOW TEST:6.255 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":356,"completed":351,"skipped":6490,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:26:08.544: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6467
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:26:08.679: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6467
I0702 13:26:08.685169      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6467, replica count: 1
I0702 13:26:09.736582      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0702 13:26:10.737161      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jul  2 13:26:10.853: INFO: Created: latency-svc-v6hjm
Jul  2 13:26:10.877: INFO: Got endpoints: latency-svc-v6hjm [39.531164ms]
Jul  2 13:26:10.902: INFO: Created: latency-svc-58bpx
Jul  2 13:26:10.909: INFO: Got endpoints: latency-svc-58bpx [32.439673ms]
Jul  2 13:26:10.993: INFO: Created: latency-svc-b2wqs
Jul  2 13:26:10.996: INFO: Created: latency-svc-rr7lp
Jul  2 13:26:10.997: INFO: Created: latency-svc-ts6gd
Jul  2 13:26:10.997: INFO: Created: latency-svc-9rtkn
Jul  2 13:26:10.997: INFO: Created: latency-svc-hpwh5
Jul  2 13:26:11.000: INFO: Created: latency-svc-c78tm
Jul  2 13:26:11.002: INFO: Created: latency-svc-d5ft6
Jul  2 13:26:11.002: INFO: Created: latency-svc-zkpp5
Jul  2 13:26:11.003: INFO: Created: latency-svc-dwtst
Jul  2 13:26:11.003: INFO: Created: latency-svc-czn4n
Jul  2 13:26:11.003: INFO: Created: latency-svc-76wkh
Jul  2 13:26:11.005: INFO: Created: latency-svc-pl7t9
Jul  2 13:26:11.005: INFO: Created: latency-svc-dtspv
Jul  2 13:26:11.005: INFO: Created: latency-svc-97ghh
Jul  2 13:26:11.005: INFO: Got endpoints: latency-svc-b2wqs [126.664185ms]
Jul  2 13:26:11.006: INFO: Created: latency-svc-xr98k
Jul  2 13:26:11.024: INFO: Got endpoints: latency-svc-ts6gd [146.087815ms]
Jul  2 13:26:11.028: INFO: Got endpoints: latency-svc-9rtkn [149.853257ms]
Jul  2 13:26:11.029: INFO: Got endpoints: latency-svc-c78tm [150.204267ms]
Jul  2 13:26:11.035: INFO: Got endpoints: latency-svc-rr7lp [155.708229ms]
Jul  2 13:26:11.037: INFO: Created: latency-svc-snxxd
Jul  2 13:26:11.042: INFO: Got endpoints: latency-svc-dtspv [164.078886ms]
Jul  2 13:26:11.042: INFO: Got endpoints: latency-svc-hpwh5 [163.289089ms]
Jul  2 13:26:11.052: INFO: Got endpoints: latency-svc-pl7t9 [173.94919ms]
Jul  2 13:26:11.052: INFO: Got endpoints: latency-svc-xr98k [173.607687ms]
Jul  2 13:26:11.053: INFO: Got endpoints: latency-svc-97ghh [174.341484ms]
Jul  2 13:26:11.056: INFO: Got endpoints: latency-svc-d5ft6 [178.759292ms]
Jul  2 13:26:11.061: INFO: Created: latency-svc-2gtlp
Jul  2 13:26:11.066: INFO: Got endpoints: latency-svc-dwtst [156.817694ms]
Jul  2 13:26:11.067: INFO: Got endpoints: latency-svc-76wkh [187.930289ms]
Jul  2 13:26:11.067: INFO: Got endpoints: latency-svc-czn4n [188.852988ms]
Jul  2 13:26:11.067: INFO: Got endpoints: latency-svc-zkpp5 [189.306626ms]
Jul  2 13:26:11.071: INFO: Got endpoints: latency-svc-snxxd [65.557464ms]
Jul  2 13:26:11.072: INFO: Got endpoints: latency-svc-2gtlp [48.202322ms]
Jul  2 13:26:11.161: INFO: Created: latency-svc-6j8bs
Jul  2 13:26:11.164: INFO: Created: latency-svc-24zdj
Jul  2 13:26:11.164: INFO: Created: latency-svc-txfzh
Jul  2 13:26:11.164: INFO: Created: latency-svc-7mvt8
Jul  2 13:26:11.164: INFO: Created: latency-svc-wbk4c
Jul  2 13:26:11.164: INFO: Created: latency-svc-r99kj
Jul  2 13:26:11.165: INFO: Created: latency-svc-hnl7n
Jul  2 13:26:11.165: INFO: Created: latency-svc-9g2hk
Jul  2 13:26:11.165: INFO: Created: latency-svc-mrp4f
Jul  2 13:26:11.169: INFO: Created: latency-svc-8qkq4
Jul  2 13:26:11.169: INFO: Created: latency-svc-6hfkj
Jul  2 13:26:11.170: INFO: Created: latency-svc-wf42f
Jul  2 13:26:11.171: INFO: Created: latency-svc-vks58
Jul  2 13:26:11.171: INFO: Created: latency-svc-95w4w
Jul  2 13:26:11.171: INFO: Created: latency-svc-5h8m8
Jul  2 13:26:11.201: INFO: Got endpoints: latency-svc-txfzh [171.544799ms]
Jul  2 13:26:11.201: INFO: Got endpoints: latency-svc-r99kj [134.118017ms]
Jul  2 13:26:11.202: INFO: Got endpoints: latency-svc-24zdj [166.902277ms]
Jul  2 13:26:11.217: INFO: Got endpoints: latency-svc-7mvt8 [175.323872ms]
Jul  2 13:26:11.217: INFO: Got endpoints: latency-svc-6j8bs [175.36631ms]
Jul  2 13:26:11.250: INFO: Got endpoints: latency-svc-9g2hk [177.888527ms]
Jul  2 13:26:11.253: INFO: Created: latency-svc-vflxv
Jul  2 13:26:11.258: INFO: Got endpoints: latency-svc-hnl7n [202.345098ms]
Jul  2 13:26:11.263: INFO: Got endpoints: latency-svc-wf42f [210.753285ms]
Jul  2 13:26:11.264: INFO: Got endpoints: latency-svc-95w4w [192.561008ms]
Jul  2 13:26:11.264: INFO: Got endpoints: latency-svc-wbk4c [197.018362ms]
Jul  2 13:26:11.265: INFO: Got endpoints: latency-svc-6hfkj [212.715326ms]
Jul  2 13:26:11.274: INFO: Got endpoints: latency-svc-8qkq4 [246.325786ms]
Jul  2 13:26:11.274: INFO: Got endpoints: latency-svc-5h8m8 [208.057635ms]
Jul  2 13:26:11.275: INFO: Got endpoints: latency-svc-mrp4f [208.21ms]
Jul  2 13:26:11.276: INFO: Created: latency-svc-h6cv7
Jul  2 13:26:11.276: INFO: Got endpoints: latency-svc-vks58 [223.910988ms]
Jul  2 13:26:11.282: INFO: Got endpoints: latency-svc-vflxv [80.621087ms]
Jul  2 13:26:11.289: INFO: Got endpoints: latency-svc-h6cv7 [88.249165ms]
Jul  2 13:26:11.291: INFO: Created: latency-svc-qjmv6
Jul  2 13:26:11.295: INFO: Got endpoints: latency-svc-qjmv6 [93.794903ms]
Jul  2 13:26:11.378: INFO: Created: latency-svc-9rnv6
Jul  2 13:26:11.381: INFO: Created: latency-svc-vfzkd
Jul  2 13:26:11.382: INFO: Created: latency-svc-6grtc
Jul  2 13:26:11.383: INFO: Created: latency-svc-ghsk4
Jul  2 13:26:11.383: INFO: Created: latency-svc-jckvr
Jul  2 13:26:11.383: INFO: Created: latency-svc-fzbmd
Jul  2 13:26:11.385: INFO: Created: latency-svc-c7zcn
Jul  2 13:26:11.385: INFO: Created: latency-svc-qj2ks
Jul  2 13:26:11.389: INFO: Created: latency-svc-gj69w
Jul  2 13:26:11.389: INFO: Created: latency-svc-6f6cx
Jul  2 13:26:11.402: INFO: Created: latency-svc-4nkcl
Jul  2 13:26:11.402: INFO: Created: latency-svc-h9wgq
Jul  2 13:26:11.403: INFO: Created: latency-svc-jb2tt
Jul  2 13:26:11.403: INFO: Created: latency-svc-9cv2z
Jul  2 13:26:11.403: INFO: Created: latency-svc-g5f6b
Jul  2 13:26:11.406: INFO: Got endpoints: latency-svc-ghsk4 [130.822525ms]
Jul  2 13:26:11.406: INFO: Got endpoints: latency-svc-vfzkd [142.25773ms]
Jul  2 13:26:11.406: INFO: Got endpoints: latency-svc-9rnv6 [188.922027ms]
Jul  2 13:26:11.418: INFO: Created: latency-svc-c62c5
Jul  2 13:26:11.426: INFO: Created: latency-svc-j668w
Jul  2 13:26:11.434: INFO: Created: latency-svc-pdfb9
Jul  2 13:26:11.453: INFO: Got endpoints: latency-svc-fzbmd [235.753532ms]
Jul  2 13:26:11.465: INFO: Created: latency-svc-n5ls7
Jul  2 13:26:11.504: INFO: Got endpoints: latency-svc-6grtc [245.62941ms]
Jul  2 13:26:11.515: INFO: Created: latency-svc-5z9rt
Jul  2 13:26:11.551: INFO: Got endpoints: latency-svc-jckvr [256.137065ms]
Jul  2 13:26:11.568: INFO: Created: latency-svc-s4lbf
Jul  2 13:26:11.601: INFO: Got endpoints: latency-svc-qj2ks [319.463867ms]
Jul  2 13:26:11.613: INFO: Created: latency-svc-fbmmh
Jul  2 13:26:11.653: INFO: Got endpoints: latency-svc-6f6cx [378.481517ms]
Jul  2 13:26:11.665: INFO: Created: latency-svc-rp5kq
Jul  2 13:26:11.702: INFO: Got endpoints: latency-svc-jb2tt [451.771623ms]
Jul  2 13:26:11.715: INFO: Created: latency-svc-bkrzh
Jul  2 13:26:11.752: INFO: Got endpoints: latency-svc-h9wgq [475.887392ms]
Jul  2 13:26:11.764: INFO: Created: latency-svc-ls2qm
Jul  2 13:26:11.802: INFO: Got endpoints: latency-svc-g5f6b [528.001953ms]
Jul  2 13:26:11.816: INFO: Created: latency-svc-xwdtt
Jul  2 13:26:11.851: INFO: Got endpoints: latency-svc-gj69w [561.936218ms]
Jul  2 13:26:11.869: INFO: Created: latency-svc-bhz9m
Jul  2 13:26:11.903: INFO: Got endpoints: latency-svc-c7zcn [639.273595ms]
Jul  2 13:26:11.914: INFO: Created: latency-svc-jmf4w
Jul  2 13:26:11.952: INFO: Got endpoints: latency-svc-9cv2z [686.808748ms]
Jul  2 13:26:11.966: INFO: Created: latency-svc-pnwpj
Jul  2 13:26:12.003: INFO: Got endpoints: latency-svc-4nkcl [739.802921ms]
Jul  2 13:26:12.017: INFO: Created: latency-svc-2hnww
Jul  2 13:26:12.051: INFO: Got endpoints: latency-svc-c62c5 [644.962233ms]
Jul  2 13:26:12.065: INFO: Created: latency-svc-b5s59
Jul  2 13:26:12.101: INFO: Got endpoints: latency-svc-j668w [694.931335ms]
Jul  2 13:26:12.115: INFO: Created: latency-svc-sfrsd
Jul  2 13:26:12.151: INFO: Got endpoints: latency-svc-pdfb9 [745.195142ms]
Jul  2 13:26:12.166: INFO: Created: latency-svc-7nl5s
Jul  2 13:26:12.203: INFO: Got endpoints: latency-svc-n5ls7 [749.857096ms]
Jul  2 13:26:12.214: INFO: Created: latency-svc-j5hb7
Jul  2 13:26:12.253: INFO: Got endpoints: latency-svc-5z9rt [749.182426ms]
Jul  2 13:26:12.265: INFO: Created: latency-svc-67pqh
Jul  2 13:26:12.303: INFO: Got endpoints: latency-svc-s4lbf [751.381868ms]
Jul  2 13:26:12.317: INFO: Created: latency-svc-2wxj4
Jul  2 13:26:12.358: INFO: Got endpoints: latency-svc-fbmmh [757.14329ms]
Jul  2 13:26:12.375: INFO: Created: latency-svc-8vbf9
Jul  2 13:26:12.403: INFO: Got endpoints: latency-svc-rp5kq [750.025519ms]
Jul  2 13:26:12.418: INFO: Created: latency-svc-hc5pp
Jul  2 13:26:12.452: INFO: Got endpoints: latency-svc-bkrzh [749.550849ms]
Jul  2 13:26:12.466: INFO: Created: latency-svc-zvls2
Jul  2 13:26:12.503: INFO: Got endpoints: latency-svc-ls2qm [751.150817ms]
Jul  2 13:26:12.515: INFO: Created: latency-svc-tbhm2
Jul  2 13:26:12.553: INFO: Got endpoints: latency-svc-xwdtt [751.078613ms]
Jul  2 13:26:12.565: INFO: Created: latency-svc-gkt6s
Jul  2 13:26:12.601: INFO: Got endpoints: latency-svc-bhz9m [749.756154ms]
Jul  2 13:26:12.617: INFO: Created: latency-svc-n6hn4
Jul  2 13:26:12.652: INFO: Got endpoints: latency-svc-jmf4w [749.023976ms]
Jul  2 13:26:12.667: INFO: Created: latency-svc-c9mv4
Jul  2 13:26:12.703: INFO: Got endpoints: latency-svc-pnwpj [751.409288ms]
Jul  2 13:26:12.716: INFO: Created: latency-svc-sg5ct
Jul  2 13:26:12.754: INFO: Got endpoints: latency-svc-2hnww [751.052981ms]
Jul  2 13:26:12.768: INFO: Created: latency-svc-v98p4
Jul  2 13:26:12.800: INFO: Got endpoints: latency-svc-b5s59 [748.858775ms]
Jul  2 13:26:12.815: INFO: Created: latency-svc-qw5vz
Jul  2 13:26:12.852: INFO: Got endpoints: latency-svc-sfrsd [750.686712ms]
Jul  2 13:26:12.868: INFO: Created: latency-svc-x6hxw
Jul  2 13:26:12.905: INFO: Got endpoints: latency-svc-7nl5s [753.461246ms]
Jul  2 13:26:12.921: INFO: Created: latency-svc-sbgdt
Jul  2 13:26:12.954: INFO: Got endpoints: latency-svc-j5hb7 [751.011058ms]
Jul  2 13:26:12.970: INFO: Created: latency-svc-fvs7z
Jul  2 13:26:13.002: INFO: Got endpoints: latency-svc-67pqh [748.558583ms]
Jul  2 13:26:13.013: INFO: Created: latency-svc-bfwnw
Jul  2 13:26:13.052: INFO: Got endpoints: latency-svc-2wxj4 [748.544668ms]
Jul  2 13:26:13.065: INFO: Created: latency-svc-l2tlv
Jul  2 13:26:13.102: INFO: Got endpoints: latency-svc-8vbf9 [743.39431ms]
Jul  2 13:26:13.117: INFO: Created: latency-svc-4k4gt
Jul  2 13:26:13.153: INFO: Got endpoints: latency-svc-hc5pp [749.878953ms]
Jul  2 13:26:13.162: INFO: Created: latency-svc-t5t2p
Jul  2 13:26:13.203: INFO: Got endpoints: latency-svc-zvls2 [751.472277ms]
Jul  2 13:26:13.216: INFO: Created: latency-svc-s9p57
Jul  2 13:26:13.252: INFO: Got endpoints: latency-svc-tbhm2 [748.920297ms]
Jul  2 13:26:13.268: INFO: Created: latency-svc-kzvxz
Jul  2 13:26:13.301: INFO: Got endpoints: latency-svc-gkt6s [747.217847ms]
Jul  2 13:26:13.311: INFO: Created: latency-svc-fblj8
Jul  2 13:26:13.353: INFO: Got endpoints: latency-svc-n6hn4 [751.494212ms]
Jul  2 13:26:13.367: INFO: Created: latency-svc-gl7hs
Jul  2 13:26:13.402: INFO: Got endpoints: latency-svc-c9mv4 [749.715167ms]
Jul  2 13:26:13.417: INFO: Created: latency-svc-7c2m9
Jul  2 13:26:13.452: INFO: Got endpoints: latency-svc-sg5ct [748.441566ms]
Jul  2 13:26:13.462: INFO: Created: latency-svc-cns5l
Jul  2 13:26:13.502: INFO: Got endpoints: latency-svc-v98p4 [747.875508ms]
Jul  2 13:26:13.516: INFO: Created: latency-svc-lp85c
Jul  2 13:26:13.551: INFO: Got endpoints: latency-svc-qw5vz [751.044208ms]
Jul  2 13:26:13.574: INFO: Created: latency-svc-87j88
Jul  2 13:26:13.602: INFO: Got endpoints: latency-svc-x6hxw [749.419475ms]
Jul  2 13:26:13.612: INFO: Created: latency-svc-tqfpf
Jul  2 13:26:13.653: INFO: Got endpoints: latency-svc-sbgdt [748.618523ms]
Jul  2 13:26:13.667: INFO: Created: latency-svc-7jpsv
Jul  2 13:26:13.701: INFO: Got endpoints: latency-svc-fvs7z [746.715083ms]
Jul  2 13:26:13.717: INFO: Created: latency-svc-bgvvw
Jul  2 13:26:13.752: INFO: Got endpoints: latency-svc-bfwnw [749.764489ms]
Jul  2 13:26:13.763: INFO: Created: latency-svc-sdzs4
Jul  2 13:26:13.802: INFO: Got endpoints: latency-svc-l2tlv [749.995842ms]
Jul  2 13:26:13.815: INFO: Created: latency-svc-zmlpm
Jul  2 13:26:13.852: INFO: Got endpoints: latency-svc-4k4gt [750.400339ms]
Jul  2 13:26:13.867: INFO: Created: latency-svc-24q5h
Jul  2 13:26:13.904: INFO: Got endpoints: latency-svc-t5t2p [751.355476ms]
Jul  2 13:26:13.921: INFO: Created: latency-svc-xcwxl
Jul  2 13:26:13.952: INFO: Got endpoints: latency-svc-s9p57 [748.556447ms]
Jul  2 13:26:13.963: INFO: Created: latency-svc-7xmwd
Jul  2 13:26:14.003: INFO: Got endpoints: latency-svc-kzvxz [750.330521ms]
Jul  2 13:26:14.017: INFO: Created: latency-svc-zwfgp
Jul  2 13:26:14.051: INFO: Got endpoints: latency-svc-fblj8 [750.026213ms]
Jul  2 13:26:14.064: INFO: Created: latency-svc-cfq85
Jul  2 13:26:14.102: INFO: Got endpoints: latency-svc-gl7hs [749.42696ms]
Jul  2 13:26:14.112: INFO: Created: latency-svc-r4ldf
Jul  2 13:26:14.152: INFO: Got endpoints: latency-svc-7c2m9 [750.828915ms]
Jul  2 13:26:14.166: INFO: Created: latency-svc-hvz4n
Jul  2 13:26:14.201: INFO: Got endpoints: latency-svc-cns5l [748.818955ms]
Jul  2 13:26:14.221: INFO: Created: latency-svc-6mjzv
Jul  2 13:26:14.252: INFO: Got endpoints: latency-svc-lp85c [749.401414ms]
Jul  2 13:26:14.263: INFO: Created: latency-svc-s7jjt
Jul  2 13:26:14.303: INFO: Got endpoints: latency-svc-87j88 [751.895631ms]
Jul  2 13:26:14.316: INFO: Created: latency-svc-hx44s
Jul  2 13:26:14.353: INFO: Got endpoints: latency-svc-tqfpf [751.750126ms]
Jul  2 13:26:14.367: INFO: Created: latency-svc-929jp
Jul  2 13:26:14.402: INFO: Got endpoints: latency-svc-7jpsv [748.674988ms]
Jul  2 13:26:14.412: INFO: Created: latency-svc-zc69k
Jul  2 13:26:14.454: INFO: Got endpoints: latency-svc-bgvvw [752.803129ms]
Jul  2 13:26:14.469: INFO: Created: latency-svc-bjh7h
Jul  2 13:26:14.502: INFO: Got endpoints: latency-svc-sdzs4 [749.78661ms]
Jul  2 13:26:14.515: INFO: Created: latency-svc-c2vfs
Jul  2 13:26:14.552: INFO: Got endpoints: latency-svc-zmlpm [750.339493ms]
Jul  2 13:26:14.562: INFO: Created: latency-svc-78xvv
Jul  2 13:26:14.604: INFO: Got endpoints: latency-svc-24q5h [751.547188ms]
Jul  2 13:26:14.618: INFO: Created: latency-svc-b4vj4
Jul  2 13:26:14.652: INFO: Got endpoints: latency-svc-xcwxl [747.153239ms]
Jul  2 13:26:14.665: INFO: Created: latency-svc-85m2p
Jul  2 13:26:14.701: INFO: Got endpoints: latency-svc-7xmwd [748.787553ms]
Jul  2 13:26:14.712: INFO: Created: latency-svc-x88sr
Jul  2 13:26:14.752: INFO: Got endpoints: latency-svc-zwfgp [749.168644ms]
Jul  2 13:26:14.766: INFO: Created: latency-svc-dghw7
Jul  2 13:26:14.801: INFO: Got endpoints: latency-svc-cfq85 [750.462198ms]
Jul  2 13:26:14.814: INFO: Created: latency-svc-kmbvz
Jul  2 13:26:14.855: INFO: Got endpoints: latency-svc-r4ldf [752.50714ms]
Jul  2 13:26:14.869: INFO: Created: latency-svc-8qvpt
Jul  2 13:26:14.906: INFO: Got endpoints: latency-svc-hvz4n [753.162607ms]
Jul  2 13:26:14.921: INFO: Created: latency-svc-wwgw6
Jul  2 13:26:14.951: INFO: Got endpoints: latency-svc-6mjzv [750.359694ms]
Jul  2 13:26:14.965: INFO: Created: latency-svc-6b7s2
Jul  2 13:26:15.002: INFO: Got endpoints: latency-svc-s7jjt [750.676143ms]
Jul  2 13:26:15.013: INFO: Created: latency-svc-fhvb9
Jul  2 13:26:15.054: INFO: Got endpoints: latency-svc-hx44s [751.054943ms]
Jul  2 13:26:15.068: INFO: Created: latency-svc-h4ncf
Jul  2 13:26:15.106: INFO: Got endpoints: latency-svc-929jp [752.99536ms]
Jul  2 13:26:15.119: INFO: Created: latency-svc-sbmvd
Jul  2 13:26:15.152: INFO: Got endpoints: latency-svc-zc69k [749.698136ms]
Jul  2 13:26:15.165: INFO: Created: latency-svc-4rw2c
Jul  2 13:26:15.202: INFO: Got endpoints: latency-svc-bjh7h [748.099283ms]
Jul  2 13:26:15.229: INFO: Created: latency-svc-cfjln
Jul  2 13:26:15.253: INFO: Got endpoints: latency-svc-c2vfs [750.847896ms]
Jul  2 13:26:15.265: INFO: Created: latency-svc-b5rnq
Jul  2 13:26:15.304: INFO: Got endpoints: latency-svc-78xvv [751.472314ms]
Jul  2 13:26:15.314: INFO: Created: latency-svc-4t7dm
Jul  2 13:26:15.353: INFO: Got endpoints: latency-svc-b4vj4 [749.106174ms]
Jul  2 13:26:15.369: INFO: Created: latency-svc-tqn67
Jul  2 13:26:15.401: INFO: Got endpoints: latency-svc-85m2p [749.529371ms]
Jul  2 13:26:15.414: INFO: Created: latency-svc-lxlk5
Jul  2 13:26:15.453: INFO: Got endpoints: latency-svc-x88sr [751.911569ms]
Jul  2 13:26:15.466: INFO: Created: latency-svc-fx7tr
Jul  2 13:26:15.503: INFO: Got endpoints: latency-svc-dghw7 [751.272073ms]
Jul  2 13:26:15.518: INFO: Created: latency-svc-xg8rd
Jul  2 13:26:15.551: INFO: Got endpoints: latency-svc-kmbvz [749.390945ms]
Jul  2 13:26:15.565: INFO: Created: latency-svc-c8fvw
Jul  2 13:26:15.601: INFO: Got endpoints: latency-svc-8qvpt [746.650508ms]
Jul  2 13:26:15.613: INFO: Created: latency-svc-frpgc
Jul  2 13:26:15.653: INFO: Got endpoints: latency-svc-wwgw6 [746.945759ms]
Jul  2 13:26:15.668: INFO: Created: latency-svc-xw8wb
Jul  2 13:26:15.701: INFO: Got endpoints: latency-svc-6b7s2 [749.737399ms]
Jul  2 13:26:15.715: INFO: Created: latency-svc-8j6dv
Jul  2 13:26:15.752: INFO: Got endpoints: latency-svc-fhvb9 [749.693017ms]
Jul  2 13:26:15.763: INFO: Created: latency-svc-f6bwn
Jul  2 13:26:15.803: INFO: Got endpoints: latency-svc-h4ncf [748.395137ms]
Jul  2 13:26:15.816: INFO: Created: latency-svc-zrd82
Jul  2 13:26:15.851: INFO: Got endpoints: latency-svc-sbmvd [745.005652ms]
Jul  2 13:26:15.867: INFO: Created: latency-svc-v7hff
Jul  2 13:26:15.906: INFO: Got endpoints: latency-svc-4rw2c [753.803226ms]
Jul  2 13:26:15.924: INFO: Created: latency-svc-ngpjm
Jul  2 13:26:15.953: INFO: Got endpoints: latency-svc-cfjln [750.662729ms]
Jul  2 13:26:15.966: INFO: Created: latency-svc-qjmgr
Jul  2 13:26:16.003: INFO: Got endpoints: latency-svc-b5rnq [750.230392ms]
Jul  2 13:26:16.016: INFO: Created: latency-svc-rhbtr
Jul  2 13:26:16.054: INFO: Got endpoints: latency-svc-4t7dm [750.137758ms]
Jul  2 13:26:16.064: INFO: Created: latency-svc-klfzf
Jul  2 13:26:16.103: INFO: Got endpoints: latency-svc-tqn67 [749.38676ms]
Jul  2 13:26:16.118: INFO: Created: latency-svc-m2v5d
Jul  2 13:26:16.156: INFO: Got endpoints: latency-svc-lxlk5 [754.435112ms]
Jul  2 13:26:16.169: INFO: Created: latency-svc-bzr8m
Jul  2 13:26:16.201: INFO: Got endpoints: latency-svc-fx7tr [748.051281ms]
Jul  2 13:26:16.212: INFO: Created: latency-svc-vq77g
Jul  2 13:26:16.253: INFO: Got endpoints: latency-svc-xg8rd [749.868982ms]
Jul  2 13:26:16.267: INFO: Created: latency-svc-z865h
Jul  2 13:26:16.301: INFO: Got endpoints: latency-svc-c8fvw [749.51002ms]
Jul  2 13:26:16.314: INFO: Created: latency-svc-kvjmn
Jul  2 13:26:16.352: INFO: Got endpoints: latency-svc-frpgc [750.491775ms]
Jul  2 13:26:16.362: INFO: Created: latency-svc-vxfcg
Jul  2 13:26:16.403: INFO: Got endpoints: latency-svc-xw8wb [749.955134ms]
Jul  2 13:26:16.418: INFO: Created: latency-svc-69qsj
Jul  2 13:26:16.451: INFO: Got endpoints: latency-svc-8j6dv [749.84795ms]
Jul  2 13:26:16.464: INFO: Created: latency-svc-wfl9j
Jul  2 13:26:16.503: INFO: Got endpoints: latency-svc-f6bwn [750.310035ms]
Jul  2 13:26:16.513: INFO: Created: latency-svc-56bkr
Jul  2 13:26:16.553: INFO: Got endpoints: latency-svc-zrd82 [749.664271ms]
Jul  2 13:26:16.566: INFO: Created: latency-svc-crp7z
Jul  2 13:26:16.602: INFO: Got endpoints: latency-svc-v7hff [750.617813ms]
Jul  2 13:26:16.616: INFO: Created: latency-svc-dvgq4
Jul  2 13:26:16.654: INFO: Got endpoints: latency-svc-ngpjm [747.644141ms]
Jul  2 13:26:16.673: INFO: Created: latency-svc-7f6xb
Jul  2 13:26:16.703: INFO: Got endpoints: latency-svc-qjmgr [749.92818ms]
Jul  2 13:26:16.718: INFO: Created: latency-svc-2tkmp
Jul  2 13:26:16.753: INFO: Got endpoints: latency-svc-rhbtr [750.47737ms]
Jul  2 13:26:16.770: INFO: Created: latency-svc-7trq5
Jul  2 13:26:16.803: INFO: Got endpoints: latency-svc-klfzf [749.026811ms]
Jul  2 13:26:16.814: INFO: Created: latency-svc-6tv8p
Jul  2 13:26:16.853: INFO: Got endpoints: latency-svc-m2v5d [749.853727ms]
Jul  2 13:26:16.870: INFO: Created: latency-svc-pbqhz
Jul  2 13:26:16.905: INFO: Got endpoints: latency-svc-bzr8m [749.359297ms]
Jul  2 13:26:16.921: INFO: Created: latency-svc-l5hxp
Jul  2 13:26:16.952: INFO: Got endpoints: latency-svc-vq77g [751.360794ms]
Jul  2 13:26:16.963: INFO: Created: latency-svc-tvz6v
Jul  2 13:26:17.006: INFO: Got endpoints: latency-svc-z865h [752.228884ms]
Jul  2 13:26:17.019: INFO: Created: latency-svc-wwtfd
Jul  2 13:26:17.052: INFO: Got endpoints: latency-svc-kvjmn [750.934134ms]
Jul  2 13:26:17.065: INFO: Created: latency-svc-pc9ww
Jul  2 13:26:17.102: INFO: Got endpoints: latency-svc-vxfcg [750.247279ms]
Jul  2 13:26:17.113: INFO: Created: latency-svc-spwtc
Jul  2 13:26:17.152: INFO: Got endpoints: latency-svc-69qsj [749.182581ms]
Jul  2 13:26:17.168: INFO: Created: latency-svc-fllll
Jul  2 13:26:17.202: INFO: Got endpoints: latency-svc-wfl9j [751.155038ms]
Jul  2 13:26:17.216: INFO: Created: latency-svc-mwqmh
Jul  2 13:26:17.254: INFO: Got endpoints: latency-svc-56bkr [750.962573ms]
Jul  2 13:26:17.264: INFO: Created: latency-svc-k8fkg
Jul  2 13:26:17.304: INFO: Got endpoints: latency-svc-crp7z [751.153548ms]
Jul  2 13:26:17.317: INFO: Created: latency-svc-nhrnn
Jul  2 13:26:17.351: INFO: Got endpoints: latency-svc-dvgq4 [748.647628ms]
Jul  2 13:26:17.363: INFO: Created: latency-svc-g45mm
Jul  2 13:26:17.403: INFO: Got endpoints: latency-svc-7f6xb [749.655515ms]
Jul  2 13:26:17.417: INFO: Created: latency-svc-5zqnd
Jul  2 13:26:17.451: INFO: Got endpoints: latency-svc-2tkmp [748.565228ms]
Jul  2 13:26:17.466: INFO: Created: latency-svc-dmn6j
Jul  2 13:26:17.503: INFO: Got endpoints: latency-svc-7trq5 [749.621615ms]
Jul  2 13:26:17.513: INFO: Created: latency-svc-d7zgk
Jul  2 13:26:17.553: INFO: Got endpoints: latency-svc-6tv8p [750.288445ms]
Jul  2 13:26:17.566: INFO: Created: latency-svc-gm5bq
Jul  2 13:26:17.600: INFO: Got endpoints: latency-svc-pbqhz [747.844253ms]
Jul  2 13:26:17.616: INFO: Created: latency-svc-s9vl2
Jul  2 13:26:17.652: INFO: Got endpoints: latency-svc-l5hxp [746.417286ms]
Jul  2 13:26:17.662: INFO: Created: latency-svc-6tzdp
Jul  2 13:26:17.702: INFO: Got endpoints: latency-svc-tvz6v [749.152468ms]
Jul  2 13:26:17.714: INFO: Created: latency-svc-78ccg
Jul  2 13:26:17.752: INFO: Got endpoints: latency-svc-wwtfd [746.483792ms]
Jul  2 13:26:17.767: INFO: Created: latency-svc-xnz9b
Jul  2 13:26:17.802: INFO: Got endpoints: latency-svc-pc9ww [750.247457ms]
Jul  2 13:26:17.812: INFO: Created: latency-svc-kqr5w
Jul  2 13:26:17.853: INFO: Got endpoints: latency-svc-spwtc [750.921909ms]
Jul  2 13:26:17.869: INFO: Created: latency-svc-n4j4p
Jul  2 13:26:17.903: INFO: Got endpoints: latency-svc-fllll [750.642914ms]
Jul  2 13:26:17.920: INFO: Created: latency-svc-rp9dg
Jul  2 13:26:17.953: INFO: Got endpoints: latency-svc-mwqmh [750.455183ms]
Jul  2 13:26:17.963: INFO: Created: latency-svc-nh995
Jul  2 13:26:18.004: INFO: Got endpoints: latency-svc-k8fkg [750.132873ms]
Jul  2 13:26:18.016: INFO: Created: latency-svc-86mmr
Jul  2 13:26:18.052: INFO: Got endpoints: latency-svc-nhrnn [748.529028ms]
Jul  2 13:26:18.067: INFO: Created: latency-svc-dznd4
Jul  2 13:26:18.101: INFO: Got endpoints: latency-svc-g45mm [750.217131ms]
Jul  2 13:26:18.111: INFO: Created: latency-svc-796kp
Jul  2 13:26:18.153: INFO: Got endpoints: latency-svc-5zqnd [749.740723ms]
Jul  2 13:26:18.170: INFO: Created: latency-svc-5pbq2
Jul  2 13:26:18.200: INFO: Got endpoints: latency-svc-dmn6j [749.134338ms]
Jul  2 13:26:18.215: INFO: Created: latency-svc-5594w
Jul  2 13:26:18.253: INFO: Got endpoints: latency-svc-d7zgk [750.182509ms]
Jul  2 13:26:18.263: INFO: Created: latency-svc-plfxt
Jul  2 13:26:18.303: INFO: Got endpoints: latency-svc-gm5bq [749.834724ms]
Jul  2 13:26:18.315: INFO: Created: latency-svc-nplfq
Jul  2 13:26:18.352: INFO: Got endpoints: latency-svc-s9vl2 [751.146342ms]
Jul  2 13:26:18.367: INFO: Created: latency-svc-rssr9
Jul  2 13:26:18.402: INFO: Got endpoints: latency-svc-6tzdp [750.75322ms]
Jul  2 13:26:18.413: INFO: Created: latency-svc-c7hd7
Jul  2 13:26:18.452: INFO: Got endpoints: latency-svc-78ccg [750.734997ms]
Jul  2 13:26:18.465: INFO: Created: latency-svc-r55hb
Jul  2 13:26:18.502: INFO: Got endpoints: latency-svc-xnz9b [749.567069ms]
Jul  2 13:26:18.517: INFO: Created: latency-svc-6v7fs
Jul  2 13:26:18.553: INFO: Got endpoints: latency-svc-kqr5w [750.330778ms]
Jul  2 13:26:18.562: INFO: Created: latency-svc-2jzrp
Jul  2 13:26:18.602: INFO: Got endpoints: latency-svc-n4j4p [748.270133ms]
Jul  2 13:26:18.615: INFO: Created: latency-svc-vbzjh
Jul  2 13:26:18.651: INFO: Got endpoints: latency-svc-rp9dg [748.665859ms]
Jul  2 13:26:18.666: INFO: Created: latency-svc-mfg4k
Jul  2 13:26:18.702: INFO: Got endpoints: latency-svc-nh995 [748.470002ms]
Jul  2 13:26:18.711: INFO: Created: latency-svc-zcglc
Jul  2 13:26:18.754: INFO: Got endpoints: latency-svc-86mmr [750.443527ms]
Jul  2 13:26:18.801: INFO: Got endpoints: latency-svc-dznd4 [748.865546ms]
Jul  2 13:26:18.853: INFO: Got endpoints: latency-svc-796kp [751.82618ms]
Jul  2 13:26:18.907: INFO: Got endpoints: latency-svc-5pbq2 [754.050418ms]
Jul  2 13:26:18.951: INFO: Got endpoints: latency-svc-5594w [750.831798ms]
Jul  2 13:26:19.002: INFO: Got endpoints: latency-svc-plfxt [748.677877ms]
Jul  2 13:26:19.053: INFO: Got endpoints: latency-svc-nplfq [749.44639ms]
Jul  2 13:26:19.101: INFO: Got endpoints: latency-svc-rssr9 [749.571106ms]
Jul  2 13:26:19.153: INFO: Got endpoints: latency-svc-c7hd7 [749.934ms]
Jul  2 13:26:19.203: INFO: Got endpoints: latency-svc-r55hb [750.255398ms]
Jul  2 13:26:19.252: INFO: Got endpoints: latency-svc-6v7fs [750.222681ms]
Jul  2 13:26:19.302: INFO: Got endpoints: latency-svc-2jzrp [749.006707ms]
Jul  2 13:26:19.353: INFO: Got endpoints: latency-svc-vbzjh [751.362223ms]
Jul  2 13:26:19.403: INFO: Got endpoints: latency-svc-mfg4k [751.3292ms]
Jul  2 13:26:19.451: INFO: Got endpoints: latency-svc-zcglc [749.945804ms]
Jul  2 13:26:19.452: INFO: Latencies: [32.439673ms 48.202322ms 65.557464ms 80.621087ms 88.249165ms 93.794903ms 126.664185ms 130.822525ms 134.118017ms 142.25773ms 146.087815ms 149.853257ms 150.204267ms 155.708229ms 156.817694ms 163.289089ms 164.078886ms 166.902277ms 171.544799ms 173.607687ms 173.94919ms 174.341484ms 175.323872ms 175.36631ms 177.888527ms 178.759292ms 187.930289ms 188.852988ms 188.922027ms 189.306626ms 192.561008ms 197.018362ms 202.345098ms 208.057635ms 208.21ms 210.753285ms 212.715326ms 223.910988ms 235.753532ms 245.62941ms 246.325786ms 256.137065ms 319.463867ms 378.481517ms 451.771623ms 475.887392ms 528.001953ms 561.936218ms 639.273595ms 644.962233ms 686.808748ms 694.931335ms 739.802921ms 743.39431ms 745.005652ms 745.195142ms 746.417286ms 746.483792ms 746.650508ms 746.715083ms 746.945759ms 747.153239ms 747.217847ms 747.644141ms 747.844253ms 747.875508ms 748.051281ms 748.099283ms 748.270133ms 748.395137ms 748.441566ms 748.470002ms 748.529028ms 748.544668ms 748.556447ms 748.558583ms 748.565228ms 748.618523ms 748.647628ms 748.665859ms 748.674988ms 748.677877ms 748.787553ms 748.818955ms 748.858775ms 748.865546ms 748.920297ms 749.006707ms 749.023976ms 749.026811ms 749.106174ms 749.134338ms 749.152468ms 749.168644ms 749.182426ms 749.182581ms 749.359297ms 749.38676ms 749.390945ms 749.401414ms 749.419475ms 749.42696ms 749.44639ms 749.51002ms 749.529371ms 749.550849ms 749.567069ms 749.571106ms 749.621615ms 749.655515ms 749.664271ms 749.693017ms 749.698136ms 749.715167ms 749.737399ms 749.740723ms 749.756154ms 749.764489ms 749.78661ms 749.834724ms 749.84795ms 749.853727ms 749.857096ms 749.868982ms 749.878953ms 749.92818ms 749.934ms 749.945804ms 749.955134ms 749.995842ms 750.025519ms 750.026213ms 750.132873ms 750.137758ms 750.182509ms 750.217131ms 750.222681ms 750.230392ms 750.247279ms 750.247457ms 750.255398ms 750.288445ms 750.310035ms 750.330521ms 750.330778ms 750.339493ms 750.359694ms 750.400339ms 750.443527ms 750.455183ms 750.462198ms 750.47737ms 750.491775ms 750.617813ms 750.642914ms 750.662729ms 750.676143ms 750.686712ms 750.734997ms 750.75322ms 750.828915ms 750.831798ms 750.847896ms 750.921909ms 750.934134ms 750.962573ms 751.011058ms 751.044208ms 751.052981ms 751.054943ms 751.078613ms 751.146342ms 751.150817ms 751.153548ms 751.155038ms 751.272073ms 751.3292ms 751.355476ms 751.360794ms 751.362223ms 751.381868ms 751.409288ms 751.472277ms 751.472314ms 751.494212ms 751.547188ms 751.750126ms 751.82618ms 751.895631ms 751.911569ms 752.228884ms 752.50714ms 752.803129ms 752.99536ms 753.162607ms 753.461246ms 753.803226ms 754.050418ms 754.435112ms 757.14329ms]
Jul  2 13:26:19.452: INFO: 50 %ile: 749.419475ms
Jul  2 13:26:19.452: INFO: 90 %ile: 751.381868ms
Jul  2 13:26:19.452: INFO: 99 %ile: 754.435112ms
Jul  2 13:26:19.452: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:188
Jul  2 13:26:19.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6467" for this suite.

• [SLOW TEST:10.925 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/framework/framework.go:652
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":356,"completed":352,"skipped":6537,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:26:19.470: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9848
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Jul  2 13:26:19.603: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jul  2 13:26:19.612: INFO: Waiting for terminating namespaces to be deleted...
Jul  2 13:26:19.617: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-69-95 before test
Jul  2 13:26:19.624: INFO: nginx-ingress-controller-kubernetes-worker-7hv6n from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:21 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.624: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 13:26:19.624: INFO: sonobuoy-e2e-job-6916416ad43a4efe from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:26:19.624: INFO: 	Container e2e ready: true, restart count 0
Jul  2 13:26:19.624: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:26:19.624: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-z6zqf from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:26:19.624: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:26:19.624: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 13:26:19.624: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-9-92 before test
Jul  2 13:26:19.629: INFO: nginx-ingress-controller-kubernetes-worker-j6wk6 from ingress-nginx-kubernetes-worker started at 2022-07-02 12:48:25 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.629: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 13:26:19.629: INFO: sonobuoy from sonobuoy started at 2022-07-02 11:53:23 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.629: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jul  2 13:26:19.629: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-x2r94 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:26:19.629: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:26:19.629: INFO: 	Container systemd-logs ready: true, restart count 0
Jul  2 13:26:19.629: INFO: svc-latency-rc-7kdl8 from svc-latency-6467 started at 2022-07-02 13:26:08 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.629: INFO: 	Container svc-latency-rc ready: true, restart count 0
Jul  2 13:26:19.629: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-91-232 before test
Jul  2 13:26:19.636: INFO: default-http-backend-kubernetes-worker-6c59687bf6-gqrng from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 1
Jul  2 13:26:19.636: INFO: nginx-ingress-controller-kubernetes-worker-xvwtz from ingress-nginx-kubernetes-worker started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Jul  2 13:26:19.636: INFO: calico-kube-controllers-7f4ccc6cf4-qt6b5 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Jul  2 13:26:19.636: INFO: coredns-86c98bfcdb-tftgb from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container coredns ready: true, restart count 0
Jul  2 13:26:19.636: INFO: kube-state-metrics-5cdbfd47b4-xkmd6 from kube-system started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container kube-state-metrics ready: true, restart count 0
Jul  2 13:26:19.636: INFO: metrics-server-v0.5.2-6bfd958b56-2pqsv from kube-system started at 2022-07-02 11:49:20 +0000 UTC (2 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container metrics-server ready: true, restart count 0
Jul  2 13:26:19.636: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Jul  2 13:26:19.636: INFO: dashboard-metrics-scraper-8669b59d4f-ftfm8 from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Jul  2 13:26:19.636: INFO: kubernetes-dashboard-585fc6bc87-ls4qj from kubernetes-dashboard started at 2022-07-02 11:49:20 +0000 UTC (1 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jul  2 13:26:19.636: INFO: sonobuoy-systemd-logs-daemon-set-3dc031e2279e43e3-4w8j4 from sonobuoy started at 2022-07-02 11:53:25 +0000 UTC (2 container statuses recorded)
Jul  2 13:26:19.636: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jul  2 13:26:19.636: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/framework/framework.go:652
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16fe061038d39906], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {juju.is/kubernetes-control-plane: true}, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:188
Jul  2 13:26:20.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9848" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":356,"completed":353,"skipped":6584,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:26:20.683: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-801
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jul  2 13:26:21.062: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jul  2 13:26:24.092: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/framework/framework.go:652
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:188
Jul  2 13:26:24.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-801" for this suite.
STEP: Destroying namespace "webhook-801-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":356,"completed":354,"skipped":6587,"failed":0}
SSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:26:24.412: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5382
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:48
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
Jul  2 13:26:24.571: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-89e8aa38-8af9-451d-b650-2efa1c1379f0" in namespace "security-context-test-5382" to be "Succeeded or Failed"
Jul  2 13:26:24.578: INFO: Pod "busybox-readonly-false-89e8aa38-8af9-451d-b650-2efa1c1379f0": Phase="Pending", Reason="", readiness=false. Elapsed: 7.621215ms
Jul  2 13:26:26.585: INFO: Pod "busybox-readonly-false-89e8aa38-8af9-451d-b650-2efa1c1379f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014850493s
Jul  2 13:26:28.592: INFO: Pod "busybox-readonly-false-89e8aa38-8af9-451d-b650-2efa1c1379f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021747578s
Jul  2 13:26:28.592: INFO: Pod "busybox-readonly-false-89e8aa38-8af9-451d-b650-2efa1c1379f0" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:188
Jul  2 13:26:28.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5382" for this suite.
•{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":356,"completed":355,"skipped":6594,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
STEP: Creating a kubernetes client
Jul  2 13:26:28.608: INFO: >>> kubeConfig: /tmp/kubeconfig-3899944901
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-723
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/framework/framework.go:652
STEP: Creating configMap with name configmap-projected-all-test-volume-bfe7a647-8d32-4af5-8175-4ad4f69ffede
STEP: Creating secret with name secret-projected-all-test-volume-e6502095-6964-4f77-8a2e-92287f49aa8a
STEP: Creating a pod to test Check all projections for projected volume plugin
Jul  2 13:26:28.771: INFO: Waiting up to 5m0s for pod "projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a" in namespace "projected-723" to be "Succeeded or Failed"
Jul  2 13:26:28.778: INFO: Pod "projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.873393ms
Jul  2 13:26:30.785: INFO: Pod "projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014464624s
Jul  2 13:26:32.795: INFO: Pod "projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02411029s
STEP: Saw pod success
Jul  2 13:26:32.795: INFO: Pod "projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a" satisfied condition "Succeeded or Failed"
Jul  2 13:26:32.798: INFO: Trying to get logs from node ip-172-31-9-92 pod projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a container projected-all-volume-test: <nil>
STEP: delete the pod
Jul  2 13:26:32.835: INFO: Waiting for pod projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a to disappear
Jul  2 13:26:32.838: INFO: Pod projected-volume-14ee2126-fee0-4170-afe9-f690bd89308a no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:188
Jul  2 13:26:32.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-723" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":356,"completed":356,"skipped":6609,"failed":0}
SSSSSSJul  2 13:26:32.852: INFO: Running AfterSuite actions on all nodes
Jul  2 13:26:32.852: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func19.2
Jul  2 13:26:32.852: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Jul  2 13:26:32.852: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func8.2
Jul  2 13:26:32.852: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Jul  2 13:26:32.852: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Jul  2 13:26:32.852: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Jul  2 13:26:32.852: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
Jul  2 13:26:32.852: INFO: Running AfterSuite actions on node 1
Jul  2 13:26:32.852: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/sonobuoy/results/junit_01.xml
{"msg":"Test Suite completed","total":356,"completed":356,"skipped":6615,"failed":0}

Ran 356 of 6971 Specs in 5571.217 seconds
SUCCESS! -- 356 Passed | 0 Failed | 0 Pending | 6615 Skipped
PASS

Ginkgo ran 1 suite in 1h32m53.413331326s
Test Suite Passed
